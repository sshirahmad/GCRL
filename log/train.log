2022-11-12 16:21:45,517:INFO: Initializing Training Set
2022-11-12 16:21:49,362:INFO: Initializing Validation Set
2022-11-12 16:21:49,800:INFO: Initializing Validation O Set
2022-11-12 16:21:52,989:INFO: 
===> EPOCH: 251 (P3)
2022-11-12 16:21:52,990:INFO: - Computing loss (training)
2022-11-12 16:22:01,044:INFO: Dataset: hotel               Batch: 1/8	Loss 48.0445 (48.0445)
2022-11-12 16:22:02,352:INFO: Dataset: hotel               Batch: 2/8	Loss 46.2908 (47.1317)
2022-11-12 16:22:03,660:INFO: Dataset: hotel               Batch: 3/8	Loss 46.2704 (46.8544)
2022-11-12 16:22:04,888:INFO: Dataset: hotel               Batch: 4/8	Loss 46.1338 (46.6814)
2022-11-12 16:22:06,189:INFO: Dataset: hotel               Batch: 5/8	Loss 45.2011 (46.3995)
2022-11-12 16:22:07,453:INFO: Dataset: hotel               Batch: 6/8	Loss 45.9086 (46.3189)
2022-11-12 16:22:08,703:INFO: Dataset: hotel               Batch: 7/8	Loss 46.2016 (46.3017)
2022-11-12 16:22:09,871:INFO: Dataset: hotel               Batch: 8/8	Loss 10.1846 (45.2535)
2022-11-12 16:22:34,191:INFO: Dataset: univ                Batch:  1/29	Loss 46.4422 (46.4422)
2022-11-12 16:22:35,460:INFO: Dataset: univ                Batch:  2/29	Loss 45.5977 (46.0122)
2022-11-12 16:22:36,671:INFO: Dataset: univ                Batch:  3/29	Loss 45.4100 (45.7972)
2022-11-12 16:22:37,902:INFO: Dataset: univ                Batch:  4/29	Loss 42.9710 (44.9880)
2022-11-12 16:22:39,119:INFO: Dataset: univ                Batch:  5/29	Loss 43.2417 (44.6327)
2022-11-12 16:22:40,362:INFO: Dataset: univ                Batch:  6/29	Loss 44.0607 (44.5357)
2022-11-12 16:22:41,581:INFO: Dataset: univ                Batch:  7/29	Loss 42.8748 (44.2776)
2022-11-12 16:22:42,818:INFO: Dataset: univ                Batch:  8/29	Loss 44.2667 (44.2763)
2022-11-12 16:22:44,092:INFO: Dataset: univ                Batch:  9/29	Loss 44.1856 (44.2667)
2022-11-12 16:22:45,366:INFO: Dataset: univ                Batch: 10/29	Loss 43.1765 (44.1585)
2022-11-12 16:22:46,571:INFO: Dataset: univ                Batch: 11/29	Loss 42.7643 (44.0236)
2022-11-12 16:22:47,792:INFO: Dataset: univ                Batch: 12/29	Loss 42.4873 (43.8967)
2022-11-12 16:22:49,024:INFO: Dataset: univ                Batch: 13/29	Loss 43.4036 (43.8647)
2022-11-12 16:22:50,275:INFO: Dataset: univ                Batch: 14/29	Loss 43.3666 (43.8325)
2022-11-12 16:22:51,486:INFO: Dataset: univ                Batch: 15/29	Loss 42.7063 (43.7606)
2022-11-12 16:22:52,745:INFO: Dataset: univ                Batch: 16/29	Loss 41.8069 (43.6333)
2022-11-12 16:22:53,969:INFO: Dataset: univ                Batch: 17/29	Loss 41.7459 (43.5147)
2022-11-12 16:22:55,188:INFO: Dataset: univ                Batch: 18/29	Loss 42.3197 (43.4594)
2022-11-12 16:22:56,504:INFO: Dataset: univ                Batch: 19/29	Loss 42.1003 (43.3916)
2022-11-12 16:22:58,048:INFO: Dataset: univ                Batch: 20/29	Loss 42.7975 (43.3626)
2022-11-12 16:22:59,309:INFO: Dataset: univ                Batch: 21/29	Loss 41.6062 (43.2780)
2022-11-12 16:23:00,562:INFO: Dataset: univ                Batch: 22/29	Loss 42.1654 (43.2272)
2022-11-12 16:23:01,898:INFO: Dataset: univ                Batch: 23/29	Loss 42.7651 (43.2101)
2022-11-12 16:23:03,435:INFO: Dataset: univ                Batch: 24/29	Loss 42.7689 (43.1944)
2022-11-12 16:23:05,033:INFO: Dataset: univ                Batch: 25/29	Loss 42.9048 (43.1845)
2022-11-12 16:23:06,578:INFO: Dataset: univ                Batch: 26/29	Loss 40.5134 (43.0796)
2022-11-12 16:23:08,267:INFO: Dataset: univ                Batch: 27/29	Loss 41.7121 (43.0298)
2022-11-12 16:23:09,771:INFO: Dataset: univ                Batch: 28/29	Loss 41.5789 (42.9730)
2022-11-12 16:23:11,314:INFO: Dataset: univ                Batch: 29/29	Loss 15.7318 (42.7045)
2022-11-12 16:23:20,932:INFO: Dataset: zara1               Batch:  1/16	Loss 44.8650 (44.8650)
2022-11-12 16:23:22,652:INFO: Dataset: zara1               Batch:  2/16	Loss 43.8703 (44.3722)
2022-11-12 16:23:24,143:INFO: Dataset: zara1               Batch:  3/16	Loss 44.0846 (44.2798)
2022-11-12 16:23:25,753:INFO: Dataset: zara1               Batch:  4/16	Loss 43.9281 (44.1883)
2022-11-12 16:23:27,471:INFO: Dataset: zara1               Batch:  5/16	Loss 44.0437 (44.1574)
2022-11-12 16:23:29,313:INFO: Dataset: zara1               Batch:  6/16	Loss 43.1989 (43.9911)
2022-11-12 16:23:31,062:INFO: Dataset: zara1               Batch:  7/16	Loss 43.4894 (43.9158)
2022-11-12 16:23:32,790:INFO: Dataset: zara1               Batch:  8/16	Loss 43.1712 (43.8353)
2022-11-12 16:23:34,492:INFO: Dataset: zara1               Batch:  9/16	Loss 43.8777 (43.8405)
2022-11-12 16:23:36,193:INFO: Dataset: zara1               Batch: 10/16	Loss 43.7850 (43.8348)
2022-11-12 16:23:37,916:INFO: Dataset: zara1               Batch: 11/16	Loss 43.3969 (43.7830)
2022-11-12 16:23:39,625:INFO: Dataset: zara1               Batch: 12/16	Loss 44.2062 (43.8222)
2022-11-12 16:23:41,247:INFO: Dataset: zara1               Batch: 13/16	Loss 44.4281 (43.8710)
2022-11-12 16:23:43,875:INFO: Dataset: zara1               Batch: 14/16	Loss 43.7721 (43.8642)
2022-11-12 16:23:45,657:INFO: Dataset: zara1               Batch: 15/16	Loss 44.3103 (43.8972)
2022-11-12 16:23:47,018:INFO: Dataset: zara1               Batch: 16/16	Loss 31.4024 (43.2330)
2022-11-12 16:24:11,442:INFO: Dataset: zara2               Batch:  1/36	Loss 41.6452 (41.6452)
2022-11-12 16:24:12,684:INFO: Dataset: zara2               Batch:  2/36	Loss 42.2104 (41.9075)
2022-11-12 16:24:13,948:INFO: Dataset: zara2               Batch:  3/36	Loss 41.6287 (41.8195)
2022-11-12 16:24:15,163:INFO: Dataset: zara2               Batch:  4/36	Loss 42.7575 (42.0342)
2022-11-12 16:24:16,388:INFO: Dataset: zara2               Batch:  5/36	Loss 41.6399 (41.9522)
2022-11-12 16:24:17,688:INFO: Dataset: zara2               Batch:  6/36	Loss 41.9109 (41.9456)
2022-11-12 16:24:18,906:INFO: Dataset: zara2               Batch:  7/36	Loss 41.1145 (41.8303)
2022-11-12 16:24:20,108:INFO: Dataset: zara2               Batch:  8/36	Loss 41.6480 (41.8089)
2022-11-12 16:24:21,352:INFO: Dataset: zara2               Batch:  9/36	Loss 40.6912 (41.6727)
2022-11-12 16:24:22,592:INFO: Dataset: zara2               Batch: 10/36	Loss 41.6998 (41.6753)
2022-11-12 16:24:23,841:INFO: Dataset: zara2               Batch: 11/36	Loss 41.4500 (41.6536)
2022-11-12 16:24:25,083:INFO: Dataset: zara2               Batch: 12/36	Loss 42.4221 (41.7122)
2022-11-12 16:24:26,345:INFO: Dataset: zara2               Batch: 13/36	Loss 42.0337 (41.7351)
2022-11-12 16:24:27,598:INFO: Dataset: zara2               Batch: 14/36	Loss 42.6099 (41.8019)
2022-11-12 16:24:28,848:INFO: Dataset: zara2               Batch: 15/36	Loss 41.3828 (41.7745)
2022-11-12 16:24:30,097:INFO: Dataset: zara2               Batch: 16/36	Loss 42.7362 (41.8402)
2022-11-12 16:24:31,320:INFO: Dataset: zara2               Batch: 17/36	Loss 42.5976 (41.8830)
2022-11-12 16:24:32,563:INFO: Dataset: zara2               Batch: 18/36	Loss 41.4013 (41.8543)
2022-11-12 16:24:33,831:INFO: Dataset: zara2               Batch: 19/36	Loss 41.1665 (41.8179)
2022-11-12 16:24:35,037:INFO: Dataset: zara2               Batch: 20/36	Loss 41.9032 (41.8223)
2022-11-12 16:24:36,290:INFO: Dataset: zara2               Batch: 21/36	Loss 43.0009 (41.8704)
2022-11-12 16:24:37,595:INFO: Dataset: zara2               Batch: 22/36	Loss 42.1610 (41.8827)
2022-11-12 16:24:38,905:INFO: Dataset: zara2               Batch: 23/36	Loss 40.6184 (41.8277)
2022-11-12 16:24:40,178:INFO: Dataset: zara2               Batch: 24/36	Loss 41.6117 (41.8182)
2022-11-12 16:24:41,416:INFO: Dataset: zara2               Batch: 25/36	Loss 41.7278 (41.8144)
2022-11-12 16:24:42,715:INFO: Dataset: zara2               Batch: 26/36	Loss 41.6200 (41.8083)
2022-11-12 16:24:44,020:INFO: Dataset: zara2               Batch: 27/36	Loss 42.2087 (41.8235)
2022-11-12 16:24:45,287:INFO: Dataset: zara2               Batch: 28/36	Loss 40.5044 (41.7795)
2022-11-12 16:24:46,591:INFO: Dataset: zara2               Batch: 29/36	Loss 41.3212 (41.7636)
2022-11-12 16:24:47,900:INFO: Dataset: zara2               Batch: 30/36	Loss 41.2088 (41.7459)
