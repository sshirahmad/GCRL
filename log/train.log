2022-11-14 14:47:26,127:INFO: Initializing Training Set
2022-11-14 14:47:29,999:INFO: Initializing Validation Set
2022-11-14 14:47:30,433:INFO: Initializing Validation O Set
2022-11-14 14:47:33,565:INFO: 
===> EPOCH: 401 (P4)
2022-11-14 14:47:33,566:INFO: - Computing loss (training)
2022-11-14 14:47:41,868:INFO: Dataset: hotel               Batch:  1/15	Loss 52.7461 (52.7461)
2022-11-14 14:47:43,347:INFO: Dataset: hotel               Batch:  2/15	Loss 38.2675 (44.9604)
2022-11-14 14:47:44,816:INFO: Dataset: hotel               Batch:  3/15	Loss 31.3808 (40.7278)
2022-11-14 14:47:46,273:INFO: Dataset: hotel               Batch:  4/15	Loss 28.7209 (37.7849)
2022-11-14 14:47:47,631:INFO: Dataset: hotel               Batch:  5/15	Loss 28.8495 (36.0260)
2022-11-14 14:47:48,992:INFO: Dataset: hotel               Batch:  6/15	Loss 27.9538 (34.6324)
2022-11-14 14:47:50,361:INFO: Dataset: hotel               Batch:  7/15	Loss 27.4883 (33.6665)
2022-11-14 14:47:51,747:INFO: Dataset: hotel               Batch:  8/15	Loss 26.6473 (32.5661)
2022-11-14 14:47:53,118:INFO: Dataset: hotel               Batch:  9/15	Loss 25.9959 (31.8686)
2022-11-14 14:47:55,144:INFO: Dataset: hotel               Batch: 10/15	Loss 26.7694 (31.3441)
2022-11-14 14:47:57,163:INFO: Dataset: hotel               Batch: 11/15	Loss 25.9449 (30.8575)
2022-11-14 14:47:58,530:INFO: Dataset: hotel               Batch: 12/15	Loss 26.3974 (30.5019)
2022-11-14 14:48:00,257:INFO: Dataset: hotel               Batch: 13/15	Loss 26.1255 (30.1906)
2022-11-14 14:48:02,049:INFO: Dataset: hotel               Batch: 14/15	Loss 24.4931 (29.7327)
2022-11-14 14:48:03,734:INFO: Dataset: hotel               Batch: 15/15	Loss 10.8999 (29.1364)
2022-11-14 14:48:31,072:INFO: Dataset: univ                Batch:  1/57	Loss 37.0920 (37.0920)
2022-11-14 14:48:32,747:INFO: Dataset: univ                Batch:  2/57	Loss 34.8818 (35.9781)
2022-11-14 14:48:34,122:INFO: Dataset: univ                Batch:  3/57	Loss 32.7622 (34.9590)
2022-11-14 14:48:35,460:INFO: Dataset: univ                Batch:  4/57	Loss 30.9522 (34.0951)
2022-11-14 14:48:36,846:INFO: Dataset: univ                Batch:  5/57	Loss 28.4624 (32.7522)
2022-11-14 14:48:38,326:INFO: Dataset: univ                Batch:  6/57	Loss 27.2982 (31.8055)
2022-11-14 14:48:39,721:INFO: Dataset: univ                Batch:  7/57	Loss 26.8972 (31.1748)
2022-11-14 14:48:41,094:INFO: Dataset: univ                Batch:  8/57	Loss 26.3905 (30.5561)
2022-11-14 14:48:42,470:INFO: Dataset: univ                Batch:  9/57	Loss 26.2052 (30.0614)
2022-11-14 14:48:43,833:INFO: Dataset: univ                Batch: 10/57	Loss 26.5800 (29.7474)
2022-11-14 14:48:45,228:INFO: Dataset: univ                Batch: 11/57	Loss 27.0881 (29.5548)
2022-11-14 14:48:46,595:INFO: Dataset: univ                Batch: 12/57	Loss 26.1585 (29.2574)
2022-11-14 14:48:47,964:INFO: Dataset: univ                Batch: 13/57	Loss 26.1782 (29.0353)
2022-11-14 14:48:49,327:INFO: Dataset: univ                Batch: 14/57	Loss 25.7817 (28.8011)
2022-11-14 14:48:50,714:INFO: Dataset: univ                Batch: 15/57	Loss 25.6249 (28.5441)
2022-11-14 14:48:52,084:INFO: Dataset: univ                Batch: 16/57	Loss 25.9192 (28.3757)
2022-11-14 14:48:53,446:INFO: Dataset: univ                Batch: 17/57	Loss 26.4434 (28.2783)
2022-11-14 14:48:54,825:INFO: Dataset: univ                Batch: 18/57	Loss 25.9608 (28.1328)
2022-11-14 14:48:56,183:INFO: Dataset: univ                Batch: 19/57	Loss 25.3463 (27.9807)
2022-11-14 14:48:57,541:INFO: Dataset: univ                Batch: 20/57	Loss 25.5186 (27.8345)
2022-11-14 14:48:59,012:INFO: Dataset: univ                Batch: 21/57	Loss 26.1076 (27.7751)
2022-11-14 14:49:00,367:INFO: Dataset: univ                Batch: 22/57	Loss 25.2948 (27.6459)
2022-11-14 14:49:01,736:INFO: Dataset: univ                Batch: 23/57	Loss 24.9854 (27.5180)
2022-11-14 14:49:03,185:INFO: Dataset: univ                Batch: 24/57	Loss 25.6234 (27.4230)
2022-11-14 14:49:04,572:INFO: Dataset: univ                Batch: 25/57	Loss 25.0539 (27.3287)
2022-11-14 14:49:05,969:INFO: Dataset: univ                Batch: 26/57	Loss 25.0467 (27.2308)
2022-11-14 14:49:07,466:INFO: Dataset: univ                Batch: 27/57	Loss 25.6241 (27.1765)
2022-11-14 14:49:08,853:INFO: Dataset: univ                Batch: 28/57	Loss 25.6239 (27.1198)
2022-11-14 14:49:10,340:INFO: Dataset: univ                Batch: 29/57	Loss 25.1163 (27.0381)
2022-11-14 14:49:11,764:INFO: Dataset: univ                Batch: 30/57	Loss 25.5440 (26.9949)
2022-11-14 14:49:13,217:INFO: Dataset: univ                Batch: 31/57	Loss 25.9794 (26.9654)
2022-11-14 14:49:14,718:INFO: Dataset: univ                Batch: 32/57	Loss 25.8039 (26.9338)
2022-11-14 14:49:16,167:INFO: Dataset: univ                Batch: 33/57	Loss 24.8141 (26.8624)
2022-11-14 14:49:17,649:INFO: Dataset: univ                Batch: 34/57	Loss 24.7099 (26.7805)
2022-11-14 14:49:19,320:INFO: Dataset: univ                Batch: 35/57	Loss 25.5065 (26.7493)
2022-11-14 14:49:21,136:INFO: Dataset: univ                Batch: 36/57	Loss 25.5151 (26.7129)
2022-11-14 14:49:22,541:INFO: Dataset: univ                Batch: 37/57	Loss 25.8250 (26.6931)
2022-11-14 14:49:23,937:INFO: Dataset: univ                Batch: 38/57	Loss 25.1948 (26.6490)
2022-11-14 14:49:25,397:INFO: Dataset: univ                Batch: 39/57	Loss 24.7461 (26.5903)
2022-11-14 14:49:26,796:INFO: Dataset: univ                Batch: 40/57	Loss 25.6552 (26.5707)
2022-11-14 14:49:28,169:INFO: Dataset: univ                Batch: 41/57	Loss 25.1967 (26.5373)
2022-11-14 14:49:29,546:INFO: Dataset: univ                Batch: 42/57	Loss 25.1075 (26.4980)
2022-11-14 14:49:30,929:INFO: Dataset: univ                Batch: 43/57	Loss 26.0841 (26.4901)
2022-11-14 14:49:32,337:INFO: Dataset: univ                Batch: 44/57	Loss 25.3489 (26.4687)
2022-11-14 14:49:33,716:INFO: Dataset: univ                Batch: 45/57	Loss 25.3609 (26.4461)
2022-11-14 14:49:35,140:INFO: Dataset: univ                Batch: 46/57	Loss 25.9508 (26.4359)
2022-11-14 14:49:36,671:INFO: Dataset: univ                Batch: 47/57	Loss 24.6693 (26.3886)
2022-11-14 14:49:38,241:INFO: Dataset: univ                Batch: 48/57	Loss 25.3174 (26.3654)
2022-11-14 14:49:39,721:INFO: Dataset: univ                Batch: 49/57	Loss 25.4131 (26.3448)
2022-11-14 14:49:41,949:INFO: Dataset: univ                Batch: 50/57	Loss 25.5301 (26.3294)
