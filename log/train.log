2022-11-12 19:36:00,592:INFO: Initializing Training Set
2022-11-12 19:36:04,794:INFO: Initializing Validation Set
2022-11-12 19:36:05,241:INFO: Initializing Validation O Set
2022-11-12 19:36:08,391:INFO: 
===> EPOCH: 551 (P4)
2022-11-12 19:36:08,392:INFO: - Computing loss (training)
2022-11-12 19:36:18,557:INFO: Dataset: hotel               Batch: 1/8	Loss 49.0721 (49.0721)
2022-11-12 19:36:20,801:INFO: Dataset: hotel               Batch: 2/8	Loss 48.0814 (48.5719)
2022-11-12 19:36:22,611:INFO: Dataset: hotel               Batch: 3/8	Loss 48.0713 (48.3977)
2022-11-12 19:36:24,050:INFO: Dataset: hotel               Batch: 4/8	Loss 46.4567 (47.9490)
2022-11-12 19:36:25,467:INFO: Dataset: hotel               Batch: 5/8	Loss 46.8822 (47.7470)
2022-11-12 19:36:26,909:INFO: Dataset: hotel               Batch: 6/8	Loss 46.2547 (47.4790)
2022-11-12 19:36:28,395:INFO: Dataset: hotel               Batch: 7/8	Loss 44.5069 (47.0059)
2022-11-12 19:36:29,769:INFO: Dataset: hotel               Batch: 8/8	Loss 9.8880 (45.8796)
2022-11-12 19:36:56,796:INFO: Dataset: univ                Batch:  1/29	Loss 53.5834 (53.5834)
2022-11-12 19:36:58,393:INFO: Dataset: univ                Batch:  2/29	Loss 51.8970 (52.6331)
2022-11-12 19:37:00,130:INFO: Dataset: univ                Batch:  3/29	Loss 52.6343 (52.6335)
2022-11-12 19:37:01,575:INFO: Dataset: univ                Batch:  4/29	Loss 51.5479 (52.3483)
2022-11-12 19:37:03,074:INFO: Dataset: univ                Batch:  5/29	Loss 49.7971 (51.7628)
2022-11-12 19:37:04,749:INFO: Dataset: univ                Batch:  6/29	Loss 51.3504 (51.6962)
2022-11-12 19:37:06,735:INFO: Dataset: univ                Batch:  7/29	Loss 48.4661 (51.1640)
2022-11-12 19:37:08,397:INFO: Dataset: univ                Batch:  8/29	Loss 49.4316 (50.9459)
2022-11-12 19:37:10,653:INFO: Dataset: univ                Batch:  9/29	Loss 50.5457 (50.9021)
2022-11-12 19:37:12,104:INFO: Dataset: univ                Batch: 10/29	Loss 49.3400 (50.7573)
2022-11-12 19:37:14,408:INFO: Dataset: univ                Batch: 11/29	Loss 49.3181 (50.6383)
2022-11-12 19:37:15,871:INFO: Dataset: univ                Batch: 12/29	Loss 48.3479 (50.4399)
2022-11-12 19:37:17,289:INFO: Dataset: univ                Batch: 13/29	Loss 48.1839 (50.2631)
2022-11-12 19:37:18,700:INFO: Dataset: univ                Batch: 14/29	Loss 48.4344 (50.1445)
2022-11-12 19:37:20,126:INFO: Dataset: univ                Batch: 15/29	Loss 46.6491 (49.8880)
2022-11-12 19:37:21,599:INFO: Dataset: univ                Batch: 16/29	Loss 47.7748 (49.7575)
2022-11-12 19:37:22,985:INFO: Dataset: univ                Batch: 17/29	Loss 47.3052 (49.6082)
2022-11-12 19:37:24,362:INFO: Dataset: univ                Batch: 18/29	Loss 47.4194 (49.4838)
2022-11-12 19:37:25,794:INFO: Dataset: univ                Batch: 19/29	Loss 46.9894 (49.3606)
2022-11-12 19:37:27,213:INFO: Dataset: univ                Batch: 20/29	Loss 46.5231 (49.1986)
2022-11-12 19:37:28,678:INFO: Dataset: univ                Batch: 21/29	Loss 46.7097 (49.0889)
2022-11-12 19:37:30,147:INFO: Dataset: univ                Batch: 22/29	Loss 45.2608 (48.8743)
2022-11-12 19:37:31,591:INFO: Dataset: univ                Batch: 23/29	Loss 46.1911 (48.7706)
2022-11-12 19:37:33,019:INFO: Dataset: univ                Batch: 24/29	Loss 45.2044 (48.6197)
2022-11-12 19:37:34,549:INFO: Dataset: univ                Batch: 25/29	Loss 45.3546 (48.4711)
2022-11-12 19:37:36,021:INFO: Dataset: univ                Batch: 26/29	Loss 45.3596 (48.3470)
2022-11-12 19:37:37,565:INFO: Dataset: univ                Batch: 27/29	Loss 45.0999 (48.2188)
2022-11-12 19:37:39,059:INFO: Dataset: univ                Batch: 28/29	Loss 45.2541 (48.1171)
2022-11-12 19:37:40,587:INFO: Dataset: univ                Batch: 29/29	Loss 17.1171 (47.7528)
2022-11-12 19:37:51,719:INFO: Dataset: zara1               Batch:  1/16	Loss 51.1544 (51.1544)
2022-11-12 19:37:53,144:INFO: Dataset: zara1               Batch:  2/16	Loss 49.6858 (50.5186)
2022-11-12 19:37:54,556:INFO: Dataset: zara1               Batch:  3/16	Loss 50.8722 (50.6274)
2022-11-12 19:37:55,920:INFO: Dataset: zara1               Batch:  4/16	Loss 50.4353 (50.5843)
2022-11-12 19:37:57,312:INFO: Dataset: zara1               Batch:  5/16	Loss 49.9790 (50.4751)
2022-11-12 19:37:58,824:INFO: Dataset: zara1               Batch:  6/16	Loss 49.3491 (50.2909)
2022-11-12 19:38:00,325:INFO: Dataset: zara1               Batch:  7/16	Loss 49.5559 (50.1770)
2022-11-12 19:38:01,991:INFO: Dataset: zara1               Batch:  8/16	Loss 48.6511 (49.9641)
2022-11-12 19:38:03,432:INFO: Dataset: zara1               Batch:  9/16	Loss 48.8018 (49.8311)
2022-11-12 19:38:04,794:INFO: Dataset: zara1               Batch: 10/16	Loss 48.5998 (49.7083)
2022-11-12 19:38:06,175:INFO: Dataset: zara1               Batch: 11/16	Loss 47.6390 (49.5390)
2022-11-12 19:38:07,776:INFO: Dataset: zara1               Batch: 12/16	Loss 47.2537 (49.3343)
2022-11-12 19:38:09,237:INFO: Dataset: zara1               Batch: 13/16	Loss 47.2935 (49.1820)
2022-11-12 19:38:10,908:INFO: Dataset: zara1               Batch: 14/16	Loss 46.2735 (48.9784)
2022-11-12 19:38:12,396:INFO: Dataset: zara1               Batch: 15/16	Loss 47.2181 (48.8806)
2022-11-12 19:38:13,901:INFO: Dataset: zara1               Batch: 16/16	Loss 32.5806 (48.0227)
2022-11-12 19:38:38,274:INFO: Dataset: zara2               Batch:  1/36	Loss 47.3757 (47.3757)
2022-11-12 19:38:39,687:INFO: Dataset: zara2               Batch:  2/36	Loss 46.5306 (47.0073)
2022-11-12 19:38:41,138:INFO: Dataset: zara2               Batch:  3/36	Loss 46.4174 (46.8052)
2022-11-12 19:38:42,690:INFO: Dataset: zara2               Batch:  4/36	Loss 46.8758 (46.8232)
2022-11-12 19:38:44,085:INFO: Dataset: zara2               Batch:  5/36	Loss 45.4999 (46.5372)
2022-11-12 19:38:45,520:INFO: Dataset: zara2               Batch:  6/36	Loss 46.0663 (46.4679)
2022-11-12 19:38:46,924:INFO: Dataset: zara2               Batch:  7/36	Loss 45.0853 (46.2509)
2022-11-12 19:38:48,331:INFO: Dataset: zara2               Batch:  8/36	Loss 46.1545 (46.2401)
2022-11-12 19:38:49,716:INFO: Dataset: zara2               Batch:  9/36	Loss 44.8905 (46.1085)
2022-11-12 19:38:51,092:INFO: Dataset: zara2               Batch: 10/36	Loss 44.6722 (45.9675)
2022-11-12 19:38:52,486:INFO: Dataset: zara2               Batch: 11/36	Loss 45.1256 (45.8922)
2022-11-12 19:38:53,919:INFO: Dataset: zara2               Batch: 12/36	Loss 44.4473 (45.7761)
2022-11-12 19:38:55,374:INFO: Dataset: zara2               Batch: 13/36	Loss 44.1826 (45.6590)
2022-11-12 19:38:56,759:INFO: Dataset: zara2               Batch: 14/36	Loss 44.3234 (45.5594)
2022-11-12 19:38:58,145:INFO: Dataset: zara2               Batch: 15/36	Loss 44.1070 (45.4762)
2022-11-12 19:38:59,518:INFO: Dataset: zara2               Batch: 16/36	Loss 44.4731 (45.4168)
2022-11-12 19:39:00,936:INFO: Dataset: zara2               Batch: 17/36	Loss 43.6911 (45.3185)
2022-11-12 19:39:02,367:INFO: Dataset: zara2               Batch: 18/36	Loss 43.3941 (45.2120)
2022-11-12 19:39:04,552:INFO: Dataset: zara2               Batch: 19/36	Loss 43.2565 (45.1128)
2022-11-12 19:39:05,984:INFO: Dataset: zara2               Batch: 20/36	Loss 42.2600 (44.9806)
2022-11-12 19:39:07,530:INFO: Dataset: zara2               Batch: 21/36	Loss 43.1383 (44.8946)
2022-11-12 19:39:09,750:INFO: Dataset: zara2               Batch: 22/36	Loss 42.8390 (44.8293)
2022-11-12 19:39:11,747:INFO: Dataset: zara2               Batch: 23/36	Loss 42.1756 (44.7113)
2022-11-12 19:39:13,356:INFO: Dataset: zara2               Batch: 24/36	Loss 42.3737 (44.6167)
2022-11-12 19:39:14,968:INFO: Dataset: zara2               Batch: 25/36	Loss 40.8362 (44.4492)
2022-11-12 19:39:16,773:INFO: Dataset: zara2               Batch: 26/36	Loss 40.2905 (44.2862)
2022-11-12 19:39:18,223:INFO: Dataset: zara2               Batch: 27/36	Loss 41.4247 (44.1831)
2022-11-12 19:39:19,977:INFO: Dataset: zara2               Batch: 28/36	Loss 40.6577 (44.0771)
2022-11-12 19:39:21,544:INFO: Dataset: zara2               Batch: 29/36	Loss 40.9411 (43.9472)
2022-11-12 19:39:23,569:INFO: Dataset: zara2               Batch: 30/36	Loss 40.8213 (43.8543)
2022-11-12 19:39:25,193:INFO: Dataset: zara2               Batch: 31/36	Loss 39.9248 (43.7262)
2022-11-12 19:39:26,599:INFO: Dataset: zara2               Batch: 32/36	Loss 40.4991 (43.6095)
2022-11-12 19:39:28,100:INFO: Dataset: zara2               Batch: 33/36	Loss 40.1059 (43.5010)
2022-11-12 19:39:29,451:INFO: Dataset: zara2               Batch: 34/36	Loss 39.6071 (43.3814)
2022-11-12 19:39:30,880:INFO: Dataset: zara2               Batch: 35/36	Loss 38.1763 (43.2425)
2022-11-12 19:39:32,300:INFO: Dataset: zara2               Batch: 36/36	Loss 28.1468 (43.0104)
2022-11-12 19:39:33,562:INFO: - Computing ADE (validation)
2022-11-12 19:39:43,760:INFO: 		 ADE on hotel                     dataset:	 1.3363828659057617
2022-11-12 19:39:53,723:INFO: 		 ADE on univ                      dataset:	 1.6065526008605957
2022-11-12 19:40:03,791:INFO: 		 ADE on zara1                     dataset:	 2.357212543487549
