2022-11-25 20:43:03,155:INFO: Initializing Training Set
2022-11-25 20:43:04,844:INFO: Initializing Validation Set
2022-11-25 20:43:05,047:INFO: Initializing Validation O Set
2022-11-25 20:43:07,271:INFO: 
===> EPOCH: 251 (P3)
2022-11-25 20:43:07,271:INFO: - Computing loss (training)
2022-11-25 20:43:08,022:INFO: Dataset: hotel               Batch: 1/4	Loss 219.4841 (219.4841)
2022-11-25 20:43:08,526:INFO: Dataset: hotel               Batch: 2/4	Loss 218.8920 (219.1859)
2022-11-25 20:43:09,024:INFO: Dataset: hotel               Batch: 3/4	Loss 217.7569 (218.6861)
2022-11-25 20:43:09,482:INFO: Dataset: hotel               Batch: 4/4	Loss 135.0785 (204.4574)
2022-11-25 20:43:10,378:INFO: Dataset: univ                Batch:  1/15	Loss 206.7784 (206.7784)
2022-11-25 20:43:11,012:INFO: Dataset: univ                Batch:  2/15	Loss 206.6589 (206.7195)
2022-11-25 20:43:11,567:INFO: Dataset: univ                Batch:  3/15	Loss 206.9528 (206.8019)
2022-11-25 20:43:12,122:INFO: Dataset: univ                Batch:  4/15	Loss 206.3738 (206.6893)
2022-11-25 20:43:12,665:INFO: Dataset: univ                Batch:  5/15	Loss 207.2736 (206.7987)
2022-11-25 20:43:13,227:INFO: Dataset: univ                Batch:  6/15	Loss 206.2079 (206.6950)
2022-11-25 20:43:13,777:INFO: Dataset: univ                Batch:  7/15	Loss 206.3268 (206.6416)
2022-11-25 20:43:14,318:INFO: Dataset: univ                Batch:  8/15	Loss 206.5389 (206.6291)
2022-11-25 20:43:14,858:INFO: Dataset: univ                Batch:  9/15	Loss 206.8938 (206.6561)
2022-11-25 20:43:15,388:INFO: Dataset: univ                Batch: 10/15	Loss 207.1959 (206.7012)
2022-11-25 20:43:15,960:INFO: Dataset: univ                Batch: 11/15	Loss 206.7523 (206.7064)
2022-11-25 20:43:16,500:INFO: Dataset: univ                Batch: 12/15	Loss 207.4619 (206.7624)
2022-11-25 20:43:17,041:INFO: Dataset: univ                Batch: 13/15	Loss 206.4535 (206.7388)
2022-11-25 20:43:17,587:INFO: Dataset: univ                Batch: 14/15	Loss 206.8238 (206.7450)
2022-11-25 20:43:18,028:INFO: Dataset: univ                Batch: 15/15	Loss 38.7504 (204.3965)
2022-11-25 20:43:18,837:INFO: Dataset: zara1               Batch: 1/8	Loss 220.1252 (220.1252)
2022-11-25 20:43:19,350:INFO: Dataset: zara1               Batch: 2/8	Loss 219.9828 (220.0519)
2022-11-25 20:43:19,857:INFO: Dataset: zara1               Batch: 3/8	Loss 219.3579 (219.8196)
2022-11-25 20:43:20,359:INFO: Dataset: zara1               Batch: 4/8	Loss 219.2629 (219.6847)
2022-11-25 20:43:20,862:INFO: Dataset: zara1               Batch: 5/8	Loss 219.6821 (219.6842)
2022-11-25 20:43:21,365:INFO: Dataset: zara1               Batch: 6/8	Loss 219.6031 (219.6710)
2022-11-25 20:43:21,866:INFO: Dataset: zara1               Batch: 7/8	Loss 219.5532 (219.6553)
2022-11-25 20:43:22,361:INFO: Dataset: zara1               Batch: 8/8	Loss 187.2700 (215.9566)
2022-11-25 20:43:23,200:INFO: Dataset: zara2               Batch:  1/18	Loss 213.8969 (213.8969)
2022-11-25 20:43:23,733:INFO: Dataset: zara2               Batch:  2/18	Loss 212.7601 (213.3712)
2022-11-25 20:43:24,248:INFO: Dataset: zara2               Batch:  3/18	Loss 213.6008 (213.4528)
2022-11-25 20:43:24,781:INFO: Dataset: zara2               Batch:  4/18	Loss 212.2832 (213.1343)
2022-11-25 20:43:25,302:INFO: Dataset: zara2               Batch:  5/18	Loss 212.6781 (213.0452)
2022-11-25 20:43:25,816:INFO: Dataset: zara2               Batch:  6/18	Loss 212.1347 (212.9069)
2022-11-25 20:43:26,327:INFO: Dataset: zara2               Batch:  7/18	Loss 211.6517 (212.7244)
2022-11-25 20:43:26,840:INFO: Dataset: zara2               Batch:  8/18	Loss 211.8991 (212.6149)
2022-11-25 20:43:27,385:INFO: Dataset: zara2               Batch:  9/18	Loss 212.8618 (212.6409)
2022-11-25 20:43:27,910:INFO: Dataset: zara2               Batch: 10/18	Loss 212.1340 (212.5899)
2022-11-25 20:43:28,423:INFO: Dataset: zara2               Batch: 11/18	Loss 212.8683 (212.6131)
2022-11-25 20:43:28,932:INFO: Dataset: zara2               Batch: 12/18	Loss 212.7898 (212.6273)
2022-11-25 20:43:29,460:INFO: Dataset: zara2               Batch: 13/18	Loss 211.8841 (212.5663)
2022-11-25 20:43:29,976:INFO: Dataset: zara2               Batch: 14/18	Loss 212.2149 (212.5427)
2022-11-25 20:43:30,490:INFO: Dataset: zara2               Batch: 15/18	Loss 212.9799 (212.5719)
2022-11-25 20:43:31,009:INFO: Dataset: zara2               Batch: 16/18	Loss 211.5284 (212.4991)
2022-11-25 20:43:31,524:INFO: Dataset: zara2               Batch: 17/18	Loss 212.0391 (212.4719)
2022-11-25 20:43:32,038:INFO: Dataset: zara2               Batch: 18/18	Loss 181.6676 (211.1122)
2022-11-25 20:43:32,103:INFO: - Computing ADE (validation)
2022-11-25 20:43:32,462:INFO: 		 ADE on hotel                     dataset:	 3.022686004638672
2022-11-25 20:43:32,914:INFO: 		 ADE on univ                      dataset:	 3.617619037628174
2022-11-25 20:43:33,266:INFO: 		 ADE on zara1                     dataset:	 2.9393036365509033
2022-11-25 20:43:33,822:INFO: 		 ADE on zara2                     dataset:	 3.1598644256591797
2022-11-25 20:43:33,822:INFO: Average validation:	ADE  3.3777	FDE  4.5593
2022-11-25 20:43:33,823:INFO: - Computing ADE (validation o)
2022-11-25 20:43:34,125:INFO: 		 ADE on eth                       dataset:	 3.0412275791168213
2022-11-25 20:43:34,125:INFO: Average validation o:	ADE  3.0412	FDE  3.8477
2022-11-25 20:43:34,134:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_251.pth.tar
2022-11-25 20:43:34,134:INFO: 
===> EPOCH: 252 (P3)
2022-11-25 20:43:34,134:INFO: - Computing loss (training)
2022-11-25 20:43:34,855:INFO: Dataset: hotel               Batch: 1/4	Loss 217.7346 (217.7346)
2022-11-25 20:43:35,363:INFO: Dataset: hotel               Batch: 2/4	Loss 218.7572 (218.2198)
2022-11-25 20:43:35,878:INFO: Dataset: hotel               Batch: 3/4	Loss 217.9326 (218.1185)
2022-11-25 20:43:36,327:INFO: Dataset: hotel               Batch: 4/4	Loss 132.3655 (204.2034)
2022-11-25 20:43:37,170:INFO: Dataset: univ                Batch:  1/15	Loss 205.8574 (205.8574)
2022-11-25 20:43:37,722:INFO: Dataset: univ                Batch:  2/15	Loss 206.0635 (205.9653)
2022-11-25 20:43:38,272:INFO: Dataset: univ                Batch:  3/15	Loss 205.8407 (205.9235)
2022-11-25 20:43:38,823:INFO: Dataset: univ                Batch:  4/15	Loss 204.9718 (205.6747)
2022-11-25 20:43:39,372:INFO: Dataset: univ                Batch:  5/15	Loss 205.1594 (205.5720)
2022-11-25 20:43:39,922:INFO: Dataset: univ                Batch:  6/15	Loss 204.8970 (205.4600)
2022-11-25 20:43:40,469:INFO: Dataset: univ                Batch:  7/15	Loss 205.3902 (205.4501)
2022-11-25 20:43:41,025:INFO: Dataset: univ                Batch:  8/15	Loss 204.3519 (205.2996)
2022-11-25 20:43:41,659:INFO: Dataset: univ                Batch:  9/15	Loss 204.3309 (205.1919)
2022-11-25 20:43:42,204:INFO: Dataset: univ                Batch: 10/15	Loss 206.1894 (205.2890)
2022-11-25 20:43:42,747:INFO: Dataset: univ                Batch: 11/15	Loss 204.7304 (205.2404)
2022-11-25 20:43:43,289:INFO: Dataset: univ                Batch: 12/15	Loss 206.3264 (205.3273)
2022-11-25 20:43:43,827:INFO: Dataset: univ                Batch: 13/15	Loss 206.1725 (205.3869)
2022-11-25 20:43:44,371:INFO: Dataset: univ                Batch: 14/15	Loss 205.4023 (205.3880)
2022-11-25 20:43:44,803:INFO: Dataset: univ                Batch: 15/15	Loss 38.4515 (203.5922)
2022-11-25 20:43:45,599:INFO: Dataset: zara1               Batch: 1/8	Loss 219.5934 (219.5934)
2022-11-25 20:43:46,137:INFO: Dataset: zara1               Batch: 2/8	Loss 217.7248 (218.6253)
2022-11-25 20:43:46,690:INFO: Dataset: zara1               Batch: 3/8	Loss 218.3382 (218.5357)
2022-11-25 20:43:47,200:INFO: Dataset: zara1               Batch: 4/8	Loss 217.9812 (218.3909)
2022-11-25 20:43:47,701:INFO: Dataset: zara1               Batch: 5/8	Loss 218.1884 (218.3540)
2022-11-25 20:43:48,200:INFO: Dataset: zara1               Batch: 6/8	Loss 217.6493 (218.2430)
2022-11-25 20:43:48,713:INFO: Dataset: zara1               Batch: 7/8	Loss 217.6328 (218.1466)
2022-11-25 20:43:49,202:INFO: Dataset: zara1               Batch: 8/8	Loss 186.8667 (214.6728)
2022-11-25 20:43:50,024:INFO: Dataset: zara2               Batch:  1/18	Loss 210.4669 (210.4669)
2022-11-25 20:43:50,545:INFO: Dataset: zara2               Batch:  2/18	Loss 210.8331 (210.6555)
2022-11-25 20:43:51,055:INFO: Dataset: zara2               Batch:  3/18	Loss 210.7837 (210.6960)
2022-11-25 20:43:51,571:INFO: Dataset: zara2               Batch:  4/18	Loss 211.2583 (210.8325)
2022-11-25 20:43:52,098:INFO: Dataset: zara2               Batch:  5/18	Loss 210.6181 (210.7832)
2022-11-25 20:43:52,630:INFO: Dataset: zara2               Batch:  6/18	Loss 209.3957 (210.5636)
2022-11-25 20:43:53,146:INFO: Dataset: zara2               Batch:  7/18	Loss 210.7517 (210.5930)
2022-11-25 20:43:53,675:INFO: Dataset: zara2               Batch:  8/18	Loss 210.7329 (210.6102)
2022-11-25 20:43:54,205:INFO: Dataset: zara2               Batch:  9/18	Loss 209.9702 (210.5327)
2022-11-25 20:43:54,717:INFO: Dataset: zara2               Batch: 10/18	Loss 209.9152 (210.4716)
2022-11-25 20:43:55,227:INFO: Dataset: zara2               Batch: 11/18	Loss 211.2762 (210.5329)
2022-11-25 20:43:55,732:INFO: Dataset: zara2               Batch: 12/18	Loss 210.8824 (210.5624)
2022-11-25 20:43:56,237:INFO: Dataset: zara2               Batch: 13/18	Loss 210.7898 (210.5800)
2022-11-25 20:43:56,742:INFO: Dataset: zara2               Batch: 14/18	Loss 209.3343 (210.4794)
2022-11-25 20:43:57,249:INFO: Dataset: zara2               Batch: 15/18	Loss 210.8408 (210.5011)
2022-11-25 20:43:57,754:INFO: Dataset: zara2               Batch: 16/18	Loss 209.5256 (210.4402)
2022-11-25 20:43:58,270:INFO: Dataset: zara2               Batch: 17/18	Loss 209.9138 (210.4087)
2022-11-25 20:43:58,774:INFO: Dataset: zara2               Batch: 18/18	Loss 180.0960 (208.9104)
2022-11-25 20:43:58,836:INFO: - Computing ADE (validation)
2022-11-25 20:43:59,209:INFO: 		 ADE on hotel                     dataset:	 2.950298309326172
2022-11-25 20:43:59,651:INFO: 		 ADE on univ                      dataset:	 3.573301076889038
2022-11-25 20:44:00,027:INFO: 		 ADE on zara1                     dataset:	 2.978189468383789
2022-11-25 20:44:00,598:INFO: 		 ADE on zara2                     dataset:	 3.1278393268585205
2022-11-25 20:44:00,598:INFO: Average validation:	ADE  3.3412	FDE  4.4559
2022-11-25 20:44:00,599:INFO: - Computing ADE (validation o)
2022-11-25 20:44:00,910:INFO: 		 ADE on eth                       dataset:	 3.18886137008667
2022-11-25 20:44:00,910:INFO: Average validation o:	ADE  3.1889	FDE  4.1043
2022-11-25 20:44:00,920:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_252.pth.tar
2022-11-25 20:44:00,920:INFO: 
===> EPOCH: 253 (P3)
2022-11-25 20:44:00,921:INFO: - Computing loss (training)
2022-11-25 20:44:01,664:INFO: Dataset: hotel               Batch: 1/4	Loss 217.2210 (217.2210)
2022-11-25 20:44:02,186:INFO: Dataset: hotel               Batch: 2/4	Loss 215.4674 (216.3483)
2022-11-25 20:44:02,702:INFO: Dataset: hotel               Batch: 3/4	Loss 217.0631 (216.5782)
2022-11-25 20:44:03,183:INFO: Dataset: hotel               Batch: 4/4	Loss 131.2984 (201.2773)
2022-11-25 20:44:04,040:INFO: Dataset: univ                Batch:  1/15	Loss 204.8320 (204.8320)
2022-11-25 20:44:04,605:INFO: Dataset: univ                Batch:  2/15	Loss 204.4905 (204.6559)
2022-11-25 20:44:05,159:INFO: Dataset: univ                Batch:  3/15	Loss 205.2048 (204.8205)
2022-11-25 20:44:05,716:INFO: Dataset: univ                Batch:  4/15	Loss 203.6585 (204.5249)
2022-11-25 20:44:06,298:INFO: Dataset: univ                Batch:  5/15	Loss 203.7350 (204.3708)
2022-11-25 20:44:06,942:INFO: Dataset: univ                Batch:  6/15	Loss 204.4588 (204.3853)
2022-11-25 20:44:07,544:INFO: Dataset: univ                Batch:  7/15	Loss 204.2457 (204.3644)
2022-11-25 20:44:08,133:INFO: Dataset: univ                Batch:  8/15	Loss 204.2867 (204.3552)
2022-11-25 20:44:08,699:INFO: Dataset: univ                Batch:  9/15	Loss 203.6824 (204.2722)
2022-11-25 20:44:09,261:INFO: Dataset: univ                Batch: 10/15	Loss 203.8132 (204.2245)
2022-11-25 20:44:09,825:INFO: Dataset: univ                Batch: 11/15	Loss 203.4515 (204.1549)
2022-11-25 20:44:10,407:INFO: Dataset: univ                Batch: 12/15	Loss 203.0241 (204.0454)
2022-11-25 20:44:10,965:INFO: Dataset: univ                Batch: 13/15	Loss 203.2200 (203.9784)
2022-11-25 20:44:11,531:INFO: Dataset: univ                Batch: 14/15	Loss 203.6127 (203.9522)
2022-11-25 20:44:11,981:INFO: Dataset: univ                Batch: 15/15	Loss 38.2840 (201.4949)
2022-11-25 20:44:12,859:INFO: Dataset: zara1               Batch: 1/8	Loss 217.3986 (217.3986)
2022-11-25 20:44:13,413:INFO: Dataset: zara1               Batch: 2/8	Loss 216.0023 (216.7413)
2022-11-25 20:44:13,987:INFO: Dataset: zara1               Batch: 3/8	Loss 217.3017 (216.9529)
2022-11-25 20:44:14,550:INFO: Dataset: zara1               Batch: 4/8	Loss 215.9266 (216.7001)
2022-11-25 20:44:15,113:INFO: Dataset: zara1               Batch: 5/8	Loss 216.9805 (216.7545)
2022-11-25 20:44:15,685:INFO: Dataset: zara1               Batch: 6/8	Loss 217.1584 (216.8151)
2022-11-25 20:44:16,229:INFO: Dataset: zara1               Batch: 7/8	Loss 216.6410 (216.7909)
2022-11-25 20:44:16,773:INFO: Dataset: zara1               Batch: 8/8	Loss 185.8639 (213.9587)
2022-11-25 20:44:17,703:INFO: Dataset: zara2               Batch:  1/18	Loss 208.9193 (208.9193)
2022-11-25 20:44:18,251:INFO: Dataset: zara2               Batch:  2/18	Loss 208.6542 (208.7892)
2022-11-25 20:44:18,767:INFO: Dataset: zara2               Batch:  3/18	Loss 208.9972 (208.8571)
2022-11-25 20:44:19,284:INFO: Dataset: zara2               Batch:  4/18	Loss 208.6111 (208.8041)
2022-11-25 20:44:19,799:INFO: Dataset: zara2               Batch:  5/18	Loss 209.4921 (208.9494)
2022-11-25 20:44:20,310:INFO: Dataset: zara2               Batch:  6/18	Loss 207.7159 (208.7466)
2022-11-25 20:44:20,825:INFO: Dataset: zara2               Batch:  7/18	Loss 208.5708 (208.7190)
2022-11-25 20:44:21,342:INFO: Dataset: zara2               Batch:  8/18	Loss 208.8465 (208.7351)
2022-11-25 20:44:21,865:INFO: Dataset: zara2               Batch:  9/18	Loss 208.6974 (208.7313)
2022-11-25 20:44:22,393:INFO: Dataset: zara2               Batch: 10/18	Loss 208.2270 (208.6801)
2022-11-25 20:44:22,920:INFO: Dataset: zara2               Batch: 11/18	Loss 207.9787 (208.6197)
2022-11-25 20:44:23,433:INFO: Dataset: zara2               Batch: 12/18	Loss 208.4451 (208.6048)
2022-11-25 20:44:23,942:INFO: Dataset: zara2               Batch: 13/18	Loss 207.7196 (208.5317)
2022-11-25 20:44:24,453:INFO: Dataset: zara2               Batch: 14/18	Loss 207.4485 (208.4510)
2022-11-25 20:44:24,963:INFO: Dataset: zara2               Batch: 15/18	Loss 208.6134 (208.4618)
2022-11-25 20:44:25,473:INFO: Dataset: zara2               Batch: 16/18	Loss 208.9433 (208.4938)
2022-11-25 20:44:25,989:INFO: Dataset: zara2               Batch: 17/18	Loss 207.7769 (208.4490)
2022-11-25 20:44:26,505:INFO: Dataset: zara2               Batch: 18/18	Loss 178.7018 (207.1311)
2022-11-25 20:44:26,566:INFO: - Computing ADE (validation)
2022-11-25 20:44:26,941:INFO: 		 ADE on hotel                     dataset:	 2.9822311401367188
2022-11-25 20:44:27,391:INFO: 		 ADE on univ                      dataset:	 3.5664846897125244
2022-11-25 20:44:27,748:INFO: 		 ADE on zara1                     dataset:	 2.882577896118164
2022-11-25 20:44:28,311:INFO: 		 ADE on zara2                     dataset:	 3.127537250518799
2022-11-25 20:44:28,312:INFO: Average validation:	ADE  3.3337	FDE  4.4793
2022-11-25 20:44:28,312:INFO: - Computing ADE (validation o)
2022-11-25 20:44:28,619:INFO: 		 ADE on eth                       dataset:	 3.226569414138794
2022-11-25 20:44:28,619:INFO: Average validation o:	ADE  3.2266	FDE  4.1365
2022-11-25 20:44:28,628:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_253.pth.tar
2022-11-25 20:44:28,628:INFO: 
===> EPOCH: 254 (P3)
2022-11-25 20:44:28,629:INFO: - Computing loss (training)
2022-11-25 20:44:29,345:INFO: Dataset: hotel               Batch: 1/4	Loss 215.3249 (215.3249)
2022-11-25 20:44:29,852:INFO: Dataset: hotel               Batch: 2/4	Loss 214.8143 (215.0672)
2022-11-25 20:44:30,351:INFO: Dataset: hotel               Batch: 3/4	Loss 218.0632 (216.0690)
2022-11-25 20:44:30,793:INFO: Dataset: hotel               Batch: 4/4	Loss 130.5451 (202.4168)
2022-11-25 20:44:31,660:INFO: Dataset: univ                Batch:  1/15	Loss 202.0557 (202.0557)
2022-11-25 20:44:32,217:INFO: Dataset: univ                Batch:  2/15	Loss 203.8501 (202.8908)
2022-11-25 20:44:32,774:INFO: Dataset: univ                Batch:  3/15	Loss 202.6233 (202.8070)
2022-11-25 20:44:33,385:INFO: Dataset: univ                Batch:  4/15	Loss 202.1487 (202.6376)
2022-11-25 20:44:34,149:INFO: Dataset: univ                Batch:  5/15	Loss 202.3153 (202.5679)
2022-11-25 20:44:34,715:INFO: Dataset: univ                Batch:  6/15	Loss 202.6720 (202.5851)
2022-11-25 20:44:35,254:INFO: Dataset: univ                Batch:  7/15	Loss 203.1106 (202.6565)
2022-11-25 20:44:35,815:INFO: Dataset: univ                Batch:  8/15	Loss 202.4596 (202.6304)
2022-11-25 20:44:36,378:INFO: Dataset: univ                Batch:  9/15	Loss 202.6160 (202.6289)
2022-11-25 20:44:36,925:INFO: Dataset: univ                Batch: 10/15	Loss 201.9359 (202.5579)
2022-11-25 20:44:37,495:INFO: Dataset: univ                Batch: 11/15	Loss 202.6573 (202.5668)
2022-11-25 20:44:38,053:INFO: Dataset: univ                Batch: 12/15	Loss 201.9033 (202.5098)
2022-11-25 20:44:38,615:INFO: Dataset: univ                Batch: 13/15	Loss 203.2843 (202.5660)
2022-11-25 20:44:39,225:INFO: Dataset: univ                Batch: 14/15	Loss 202.3228 (202.5488)
2022-11-25 20:44:39,670:INFO: Dataset: univ                Batch: 15/15	Loss 37.5779 (200.0081)
2022-11-25 20:44:40,551:INFO: Dataset: zara1               Batch: 1/8	Loss 215.2265 (215.2265)
2022-11-25 20:44:41,069:INFO: Dataset: zara1               Batch: 2/8	Loss 214.8423 (215.0320)
2022-11-25 20:44:41,615:INFO: Dataset: zara1               Batch: 3/8	Loss 216.1268 (215.4127)
2022-11-25 20:44:42,153:INFO: Dataset: zara1               Batch: 4/8	Loss 214.1231 (215.1045)
2022-11-25 20:44:42,692:INFO: Dataset: zara1               Batch: 5/8	Loss 215.0263 (215.0885)
2022-11-25 20:44:43,216:INFO: Dataset: zara1               Batch: 6/8	Loss 216.0628 (215.2437)
2022-11-25 20:44:43,746:INFO: Dataset: zara1               Batch: 7/8	Loss 214.3162 (215.1139)
2022-11-25 20:44:44,276:INFO: Dataset: zara1               Batch: 8/8	Loss 184.7713 (211.8241)
2022-11-25 20:44:45,166:INFO: Dataset: zara2               Batch:  1/18	Loss 206.7683 (206.7683)
2022-11-25 20:44:46,010:INFO: Dataset: zara2               Batch:  2/18	Loss 207.4113 (207.0982)
2022-11-25 20:44:46,540:INFO: Dataset: zara2               Batch:  3/18	Loss 207.7022 (207.3086)
2022-11-25 20:44:47,060:INFO: Dataset: zara2               Batch:  4/18	Loss 205.7927 (206.9095)
2022-11-25 20:44:47,578:INFO: Dataset: zara2               Batch:  5/18	Loss 206.9171 (206.9110)
2022-11-25 20:44:48,105:INFO: Dataset: zara2               Batch:  6/18	Loss 206.7567 (206.8843)
2022-11-25 20:44:48,623:INFO: Dataset: zara2               Batch:  7/18	Loss 206.2446 (206.7907)
2022-11-25 20:44:49,134:INFO: Dataset: zara2               Batch:  8/18	Loss 205.8889 (206.6862)
2022-11-25 20:44:49,644:INFO: Dataset: zara2               Batch:  9/18	Loss 205.9925 (206.6053)
2022-11-25 20:44:50,188:INFO: Dataset: zara2               Batch: 10/18	Loss 206.5645 (206.6012)
2022-11-25 20:44:50,709:INFO: Dataset: zara2               Batch: 11/18	Loss 206.1084 (206.5598)
2022-11-25 20:44:51,237:INFO: Dataset: zara2               Batch: 12/18	Loss 206.4812 (206.5533)
2022-11-25 20:44:51,765:INFO: Dataset: zara2               Batch: 13/18	Loss 206.5378 (206.5521)
2022-11-25 20:44:52,286:INFO: Dataset: zara2               Batch: 14/18	Loss 207.4635 (206.6178)
2022-11-25 20:44:52,797:INFO: Dataset: zara2               Batch: 15/18	Loss 206.5344 (206.6123)
2022-11-25 20:44:53,330:INFO: Dataset: zara2               Batch: 16/18	Loss 205.1305 (206.5167)
2022-11-25 20:44:53,847:INFO: Dataset: zara2               Batch: 17/18	Loss 205.6067 (206.4671)
2022-11-25 20:44:54,364:INFO: Dataset: zara2               Batch: 18/18	Loss 176.8741 (205.0484)
2022-11-25 20:44:54,425:INFO: - Computing ADE (validation)
2022-11-25 20:44:54,792:INFO: 		 ADE on hotel                     dataset:	 2.9629337787628174
2022-11-25 20:44:55,240:INFO: 		 ADE on univ                      dataset:	 3.5924081802368164
2022-11-25 20:44:55,600:INFO: 		 ADE on zara1                     dataset:	 2.970517635345459
2022-11-25 20:44:56,168:INFO: 		 ADE on zara2                     dataset:	 3.152219533920288
2022-11-25 20:44:56,169:INFO: Average validation:	ADE  3.3603	FDE  4.5395
2022-11-25 20:44:56,169:INFO: - Computing ADE (validation o)
2022-11-25 20:44:56,477:INFO: 		 ADE on eth                       dataset:	 3.129652976989746
2022-11-25 20:44:56,477:INFO: Average validation o:	ADE  3.1297	FDE  4.0771
2022-11-25 20:44:56,486:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_254.pth.tar
2022-11-25 20:44:56,486:INFO: 
===> EPOCH: 255 (P3)
2022-11-25 20:44:56,487:INFO: - Computing loss (training)
2022-11-25 20:44:57,212:INFO: Dataset: hotel               Batch: 1/4	Loss 215.8419 (215.8419)
2022-11-25 20:44:57,718:INFO: Dataset: hotel               Batch: 2/4	Loss 213.1124 (214.5131)
2022-11-25 20:44:58,240:INFO: Dataset: hotel               Batch: 3/4	Loss 214.8631 (214.6318)
2022-11-25 20:44:58,701:INFO: Dataset: hotel               Batch: 4/4	Loss 130.9665 (200.6140)
2022-11-25 20:44:59,659:INFO: Dataset: univ                Batch:  1/15	Loss 200.9497 (200.9497)
2022-11-25 20:45:00,342:INFO: Dataset: univ                Batch:  2/15	Loss 200.8588 (200.9030)
2022-11-25 20:45:00,929:INFO: Dataset: univ                Batch:  3/15	Loss 201.2760 (201.0262)
2022-11-25 20:45:01,507:INFO: Dataset: univ                Batch:  4/15	Loss 200.8877 (200.9942)
2022-11-25 20:45:02,087:INFO: Dataset: univ                Batch:  5/15	Loss 200.3453 (200.8589)
2022-11-25 20:45:02,642:INFO: Dataset: univ                Batch:  6/15	Loss 201.3181 (200.9374)
2022-11-25 20:45:03,215:INFO: Dataset: univ                Batch:  7/15	Loss 201.3439 (200.9948)
2022-11-25 20:45:03,757:INFO: Dataset: univ                Batch:  8/15	Loss 201.1153 (201.0088)
2022-11-25 20:45:04,311:INFO: Dataset: univ                Batch:  9/15	Loss 201.3894 (201.0493)
2022-11-25 20:45:04,865:INFO: Dataset: univ                Batch: 10/15	Loss 200.3598 (200.9782)
2022-11-25 20:45:05,448:INFO: Dataset: univ                Batch: 11/15	Loss 200.3767 (200.9217)
2022-11-25 20:45:06,143:INFO: Dataset: univ                Batch: 12/15	Loss 200.3382 (200.8711)
2022-11-25 20:45:06,697:INFO: Dataset: univ                Batch: 13/15	Loss 200.6758 (200.8562)
2022-11-25 20:45:07,258:INFO: Dataset: univ                Batch: 14/15	Loss 200.4717 (200.8272)
2022-11-25 20:45:07,717:INFO: Dataset: univ                Batch: 15/15	Loss 37.6238 (198.4065)
2022-11-25 20:45:08,521:INFO: Dataset: zara1               Batch: 1/8	Loss 213.0956 (213.0956)
2022-11-25 20:45:09,112:INFO: Dataset: zara1               Batch: 2/8	Loss 213.9190 (213.5184)
2022-11-25 20:45:09,654:INFO: Dataset: zara1               Batch: 3/8	Loss 212.8468 (213.3232)
2022-11-25 20:45:10,166:INFO: Dataset: zara1               Batch: 4/8	Loss 214.6293 (213.6065)
2022-11-25 20:45:10,672:INFO: Dataset: zara1               Batch: 5/8	Loss 213.0302 (213.4964)
2022-11-25 20:45:11,192:INFO: Dataset: zara1               Batch: 6/8	Loss 212.9597 (213.3934)
2022-11-25 20:45:11,701:INFO: Dataset: zara1               Batch: 7/8	Loss 213.8741 (213.4638)
2022-11-25 20:45:12,214:INFO: Dataset: zara1               Batch: 8/8	Loss 182.5164 (209.8479)
2022-11-25 20:45:13,043:INFO: Dataset: zara2               Batch:  1/18	Loss 203.9458 (203.9458)
2022-11-25 20:45:13,556:INFO: Dataset: zara2               Batch:  2/18	Loss 205.1725 (204.4827)
2022-11-25 20:45:14,073:INFO: Dataset: zara2               Batch:  3/18	Loss 204.3493 (204.4376)
2022-11-25 20:45:14,591:INFO: Dataset: zara2               Batch:  4/18	Loss 204.6740 (204.4962)
2022-11-25 20:45:15,110:INFO: Dataset: zara2               Batch:  5/18	Loss 204.5716 (204.5111)
2022-11-25 20:45:15,628:INFO: Dataset: zara2               Batch:  6/18	Loss 205.1132 (204.6121)
2022-11-25 20:45:16,197:INFO: Dataset: zara2               Batch:  7/18	Loss 204.4792 (204.5935)
2022-11-25 20:45:16,740:INFO: Dataset: zara2               Batch:  8/18	Loss 204.2882 (204.5595)
2022-11-25 20:45:17,329:INFO: Dataset: zara2               Batch:  9/18	Loss 204.5594 (204.5595)
2022-11-25 20:45:17,905:INFO: Dataset: zara2               Batch: 10/18	Loss 203.2113 (204.4170)
2022-11-25 20:45:18,451:INFO: Dataset: zara2               Batch: 11/18	Loss 204.4551 (204.4207)
2022-11-25 20:45:19,000:INFO: Dataset: zara2               Batch: 12/18	Loss 203.8406 (204.3767)
2022-11-25 20:45:19,685:INFO: Dataset: zara2               Batch: 13/18	Loss 203.8388 (204.3335)
2022-11-25 20:45:20,230:INFO: Dataset: zara2               Batch: 14/18	Loss 203.4438 (204.2709)
2022-11-25 20:45:20,780:INFO: Dataset: zara2               Batch: 15/18	Loss 204.8633 (204.3104)
2022-11-25 20:45:21,310:INFO: Dataset: zara2               Batch: 16/18	Loss 204.0307 (204.2931)
2022-11-25 20:45:21,824:INFO: Dataset: zara2               Batch: 17/18	Loss 203.0820 (204.2252)
2022-11-25 20:45:22,342:INFO: Dataset: zara2               Batch: 18/18	Loss 175.5724 (202.7757)
2022-11-25 20:45:22,418:INFO: - Computing ADE (validation)
2022-11-25 20:45:22,827:INFO: 		 ADE on hotel                     dataset:	 2.9597432613372803
2022-11-25 20:45:23,286:INFO: 		 ADE on univ                      dataset:	 3.566645383834839
2022-11-25 20:45:23,648:INFO: 		 ADE on zara1                     dataset:	 3.0000264644622803
2022-11-25 20:45:24,234:INFO: 		 ADE on zara2                     dataset:	 3.1537771224975586
2022-11-25 20:45:24,234:INFO: Average validation:	ADE  3.3490	FDE  4.5024
2022-11-25 20:45:24,235:INFO: - Computing ADE (validation o)
2022-11-25 20:45:24,541:INFO: 		 ADE on eth                       dataset:	 3.0692527294158936
2022-11-25 20:45:24,541:INFO: Average validation o:	ADE  3.0693	FDE  4.0056
2022-11-25 20:45:24,550:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_255.pth.tar
2022-11-25 20:45:24,550:INFO: 
===> EPOCH: 256 (P3)
2022-11-25 20:45:24,551:INFO: - Computing loss (training)
2022-11-25 20:45:25,289:INFO: Dataset: hotel               Batch: 1/4	Loss 211.5186 (211.5186)
2022-11-25 20:45:25,795:INFO: Dataset: hotel               Batch: 2/4	Loss 213.1446 (212.2801)
2022-11-25 20:45:26,305:INFO: Dataset: hotel               Batch: 3/4	Loss 213.7458 (212.7304)
2022-11-25 20:45:26,748:INFO: Dataset: hotel               Batch: 4/4	Loss 130.1207 (199.6524)
2022-11-25 20:45:27,592:INFO: Dataset: univ                Batch:  1/15	Loss 199.8536 (199.8536)
2022-11-25 20:45:28,153:INFO: Dataset: univ                Batch:  2/15	Loss 199.9355 (199.8963)
2022-11-25 20:45:28,696:INFO: Dataset: univ                Batch:  3/15	Loss 199.4062 (199.7284)
2022-11-25 20:45:29,256:INFO: Dataset: univ                Batch:  4/15	Loss 198.5127 (199.4077)
2022-11-25 20:45:29,817:INFO: Dataset: univ                Batch:  5/15	Loss 199.5049 (199.4272)
2022-11-25 20:45:30,383:INFO: Dataset: univ                Batch:  6/15	Loss 198.2913 (199.2067)
2022-11-25 20:45:30,993:INFO: Dataset: univ                Batch:  7/15	Loss 198.2321 (199.0528)
2022-11-25 20:45:31,677:INFO: Dataset: univ                Batch:  8/15	Loss 199.0115 (199.0476)
2022-11-25 20:45:32,309:INFO: Dataset: univ                Batch:  9/15	Loss 198.0208 (198.9288)
2022-11-25 20:45:32,885:INFO: Dataset: univ                Batch: 10/15	Loss 198.4521 (198.8806)
2022-11-25 20:45:33,462:INFO: Dataset: univ                Batch: 11/15	Loss 199.0979 (198.9001)
2022-11-25 20:45:34,062:INFO: Dataset: univ                Batch: 12/15	Loss 198.4437 (198.8629)
2022-11-25 20:45:34,684:INFO: Dataset: univ                Batch: 13/15	Loss 199.1569 (198.8849)
2022-11-25 20:45:35,258:INFO: Dataset: univ                Batch: 14/15	Loss 198.6855 (198.8715)
2022-11-25 20:45:35,759:INFO: Dataset: univ                Batch: 15/15	Loss 37.1261 (196.4340)
2022-11-25 20:45:36,587:INFO: Dataset: zara1               Batch: 1/8	Loss 211.3202 (211.3202)
2022-11-25 20:45:37,101:INFO: Dataset: zara1               Batch: 2/8	Loss 211.5834 (211.4487)
2022-11-25 20:45:37,627:INFO: Dataset: zara1               Batch: 3/8	Loss 211.5168 (211.4716)
2022-11-25 20:45:38,163:INFO: Dataset: zara1               Batch: 4/8	Loss 211.2075 (211.4005)
2022-11-25 20:45:38,690:INFO: Dataset: zara1               Batch: 5/8	Loss 211.7673 (211.4673)
2022-11-25 20:45:39,223:INFO: Dataset: zara1               Batch: 6/8	Loss 210.9126 (211.3683)
2022-11-25 20:45:39,779:INFO: Dataset: zara1               Batch: 7/8	Loss 211.3418 (211.3645)
2022-11-25 20:45:40,279:INFO: Dataset: zara1               Batch: 8/8	Loss 180.7184 (208.0257)
2022-11-25 20:45:41,106:INFO: Dataset: zara2               Batch:  1/18	Loss 202.1059 (202.1059)
2022-11-25 20:45:41,620:INFO: Dataset: zara2               Batch:  2/18	Loss 201.5714 (201.8304)
2022-11-25 20:45:42,128:INFO: Dataset: zara2               Batch:  3/18	Loss 202.5236 (202.0491)
2022-11-25 20:45:42,634:INFO: Dataset: zara2               Batch:  4/18	Loss 201.4847 (201.9153)
2022-11-25 20:45:43,141:INFO: Dataset: zara2               Batch:  5/18	Loss 202.1998 (201.9705)
2022-11-25 20:45:43,660:INFO: Dataset: zara2               Batch:  6/18	Loss 201.8880 (201.9568)
2022-11-25 20:45:44,165:INFO: Dataset: zara2               Batch:  7/18	Loss 201.7550 (201.9288)
2022-11-25 20:45:44,710:INFO: Dataset: zara2               Batch:  8/18	Loss 201.2592 (201.8411)
2022-11-25 20:45:45,366:INFO: Dataset: zara2               Batch:  9/18	Loss 202.3697 (201.9005)
2022-11-25 20:45:45,912:INFO: Dataset: zara2               Batch: 10/18	Loss 201.3047 (201.8448)
2022-11-25 20:45:46,437:INFO: Dataset: zara2               Batch: 11/18	Loss 202.1693 (201.8731)
2022-11-25 20:45:46,959:INFO: Dataset: zara2               Batch: 12/18	Loss 202.1545 (201.8959)
2022-11-25 20:45:47,472:INFO: Dataset: zara2               Batch: 13/18	Loss 201.1845 (201.8365)
2022-11-25 20:45:48,009:INFO: Dataset: zara2               Batch: 14/18	Loss 200.8875 (201.7732)
2022-11-25 20:45:48,560:INFO: Dataset: zara2               Batch: 15/18	Loss 201.2682 (201.7358)
2022-11-25 20:45:49,095:INFO: Dataset: zara2               Batch: 16/18	Loss 201.4200 (201.7159)
2022-11-25 20:45:49,639:INFO: Dataset: zara2               Batch: 17/18	Loss 201.2255 (201.6869)
2022-11-25 20:45:50,158:INFO: Dataset: zara2               Batch: 18/18	Loss 173.0952 (200.3587)
2022-11-25 20:45:50,220:INFO: - Computing ADE (validation)
2022-11-25 20:45:50,588:INFO: 		 ADE on hotel                     dataset:	 3.001091241836548
2022-11-25 20:45:51,041:INFO: 		 ADE on univ                      dataset:	 3.571284294128418
2022-11-25 20:45:51,403:INFO: 		 ADE on zara1                     dataset:	 2.9587831497192383
2022-11-25 20:45:51,990:INFO: 		 ADE on zara2                     dataset:	 3.1633412837982178
2022-11-25 20:45:51,990:INFO: Average validation:	ADE  3.3548	FDE  4.5153
2022-11-25 20:45:51,991:INFO: - Computing ADE (validation o)
2022-11-25 20:45:52,301:INFO: 		 ADE on eth                       dataset:	 3.079777717590332
2022-11-25 20:45:52,301:INFO: Average validation o:	ADE  3.0798	FDE  4.0637
2022-11-25 20:45:52,310:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_256.pth.tar
2022-11-25 20:45:52,310:INFO: 
===> EPOCH: 257 (P3)
2022-11-25 20:45:52,311:INFO: - Computing loss (training)
2022-11-25 20:45:53,050:INFO: Dataset: hotel               Batch: 1/4	Loss 211.6314 (211.6314)
2022-11-25 20:45:53,550:INFO: Dataset: hotel               Batch: 2/4	Loss 212.6104 (212.1292)
2022-11-25 20:45:54,136:INFO: Dataset: hotel               Batch: 3/4	Loss 209.3843 (211.1982)
2022-11-25 20:45:54,594:INFO: Dataset: hotel               Batch: 4/4	Loss 128.4728 (197.0105)
2022-11-25 20:45:55,459:INFO: Dataset: univ                Batch:  1/15	Loss 195.9096 (195.9096)
2022-11-25 20:45:55,998:INFO: Dataset: univ                Batch:  2/15	Loss 196.9486 (196.3905)
2022-11-25 20:45:56,540:INFO: Dataset: univ                Batch:  3/15	Loss 196.4197 (196.4002)
2022-11-25 20:45:57,087:INFO: Dataset: univ                Batch:  4/15	Loss 197.9053 (196.7483)
2022-11-25 20:45:57,632:INFO: Dataset: univ                Batch:  5/15	Loss 196.9567 (196.7886)
2022-11-25 20:45:58,175:INFO: Dataset: univ                Batch:  6/15	Loss 197.1958 (196.8501)
2022-11-25 20:45:58,729:INFO: Dataset: univ                Batch:  7/15	Loss 195.6988 (196.6733)
2022-11-25 20:45:59,275:INFO: Dataset: univ                Batch:  8/15	Loss 196.0933 (196.5974)
2022-11-25 20:45:59,815:INFO: Dataset: univ                Batch:  9/15	Loss 196.2759 (196.5639)
2022-11-25 20:46:00,368:INFO: Dataset: univ                Batch: 10/15	Loss 195.7983 (196.4874)
2022-11-25 20:46:00,932:INFO: Dataset: univ                Batch: 11/15	Loss 195.7496 (196.4169)
2022-11-25 20:46:01,510:INFO: Dataset: univ                Batch: 12/15	Loss 195.4565 (196.3339)
2022-11-25 20:46:02,081:INFO: Dataset: univ                Batch: 13/15	Loss 195.8767 (196.2994)
2022-11-25 20:46:02,651:INFO: Dataset: univ                Batch: 14/15	Loss 194.6469 (196.1697)
2022-11-25 20:46:03,150:INFO: Dataset: univ                Batch: 15/15	Loss 36.6630 (193.8869)
2022-11-25 20:46:04,050:INFO: Dataset: zara1               Batch: 1/8	Loss 209.2196 (209.2196)
2022-11-25 20:46:04,580:INFO: Dataset: zara1               Batch: 2/8	Loss 208.6734 (208.9481)
2022-11-25 20:46:05,093:INFO: Dataset: zara1               Batch: 3/8	Loss 207.3866 (208.4367)
2022-11-25 20:46:05,618:INFO: Dataset: zara1               Batch: 4/8	Loss 208.3764 (208.4218)
2022-11-25 20:46:06,498:INFO: Dataset: zara1               Batch: 5/8	Loss 207.1749 (208.2029)
2022-11-25 20:46:07,060:INFO: Dataset: zara1               Batch: 6/8	Loss 207.4131 (208.0636)
2022-11-25 20:46:07,571:INFO: Dataset: zara1               Batch: 7/8	Loss 208.9733 (208.1890)
2022-11-25 20:46:08,069:INFO: Dataset: zara1               Batch: 8/8	Loss 178.1957 (204.7792)
2022-11-25 20:46:08,906:INFO: Dataset: zara2               Batch:  1/18	Loss 199.3702 (199.3702)
2022-11-25 20:46:09,423:INFO: Dataset: zara2               Batch:  2/18	Loss 199.2578 (199.3159)
2022-11-25 20:46:09,960:INFO: Dataset: zara2               Batch:  3/18	Loss 198.9276 (199.1847)
2022-11-25 20:46:10,550:INFO: Dataset: zara2               Batch:  4/18	Loss 198.5173 (199.0133)
2022-11-25 20:46:11,137:INFO: Dataset: zara2               Batch:  5/18	Loss 199.1001 (199.0317)
2022-11-25 20:46:11,725:INFO: Dataset: zara2               Batch:  6/18	Loss 198.3494 (198.9215)
2022-11-25 20:46:12,286:INFO: Dataset: zara2               Batch:  7/18	Loss 198.7395 (198.8958)
2022-11-25 20:46:12,838:INFO: Dataset: zara2               Batch:  8/18	Loss 198.4700 (198.8435)
2022-11-25 20:46:13,373:INFO: Dataset: zara2               Batch:  9/18	Loss 198.7423 (198.8317)
2022-11-25 20:46:13,906:INFO: Dataset: zara2               Batch: 10/18	Loss 198.0551 (198.7624)
2022-11-25 20:46:14,428:INFO: Dataset: zara2               Batch: 11/18	Loss 198.0301 (198.7046)
2022-11-25 20:46:14,995:INFO: Dataset: zara2               Batch: 12/18	Loss 197.4616 (198.5991)
2022-11-25 20:46:15,516:INFO: Dataset: zara2               Batch: 13/18	Loss 197.0568 (198.4894)
2022-11-25 20:46:16,076:INFO: Dataset: zara2               Batch: 14/18	Loss 197.4054 (198.4119)
2022-11-25 20:46:16,636:INFO: Dataset: zara2               Batch: 15/18	Loss 197.9233 (198.3802)
2022-11-25 20:46:17,204:INFO: Dataset: zara2               Batch: 16/18	Loss 196.7972 (198.2774)
2022-11-25 20:46:17,724:INFO: Dataset: zara2               Batch: 17/18	Loss 197.3672 (198.2277)
2022-11-25 20:46:18,229:INFO: Dataset: zara2               Batch: 18/18	Loss 168.6539 (196.8539)
2022-11-25 20:46:18,288:INFO: - Computing ADE (validation)
2022-11-25 20:46:18,660:INFO: 		 ADE on hotel                     dataset:	 2.95892333984375
2022-11-25 20:46:19,107:INFO: 		 ADE on univ                      dataset:	 3.58027982711792
2022-11-25 20:46:19,472:INFO: 		 ADE on zara1                     dataset:	 2.931683301925659
2022-11-25 20:46:20,031:INFO: 		 ADE on zara2                     dataset:	 3.1390645503997803
2022-11-25 20:46:20,031:INFO: Average validation:	ADE  3.3467	FDE  4.4903
2022-11-25 20:46:20,032:INFO: - Computing ADE (validation o)
2022-11-25 20:46:20,337:INFO: 		 ADE on eth                       dataset:	 3.138868570327759
2022-11-25 20:46:20,337:INFO: Average validation o:	ADE  3.1389	FDE  4.1411
2022-11-25 20:46:20,346:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_257.pth.tar
2022-11-25 20:46:20,346:INFO: 
===> EPOCH: 258 (P3)
2022-11-25 20:46:20,347:INFO: - Computing loss (training)
2022-11-25 20:46:21,071:INFO: Dataset: hotel               Batch: 1/4	Loss 210.6460 (210.6460)
2022-11-25 20:46:21,576:INFO: Dataset: hotel               Batch: 2/4	Loss 210.7434 (210.6939)
2022-11-25 20:46:22,075:INFO: Dataset: hotel               Batch: 3/4	Loss 213.9315 (211.7504)
2022-11-25 20:46:22,535:INFO: Dataset: hotel               Batch: 4/4	Loss 127.5250 (196.3054)
2022-11-25 20:46:23,431:INFO: Dataset: univ                Batch:  1/15	Loss 191.7091 (191.7091)
2022-11-25 20:46:24,020:INFO: Dataset: univ                Batch:  2/15	Loss 191.9352 (191.8257)
2022-11-25 20:46:24,616:INFO: Dataset: univ                Batch:  3/15	Loss 191.9617 (191.8705)
2022-11-25 20:46:25,235:INFO: Dataset: univ                Batch:  4/15	Loss 192.1375 (191.9384)
2022-11-25 20:46:25,807:INFO: Dataset: univ                Batch:  5/15	Loss 192.1965 (191.9851)
2022-11-25 20:46:26,489:INFO: Dataset: univ                Batch:  6/15	Loss 192.5954 (192.0758)
2022-11-25 20:46:27,096:INFO: Dataset: univ                Batch:  7/15	Loss 193.0265 (192.2103)
2022-11-25 20:46:27,695:INFO: Dataset: univ                Batch:  8/15	Loss 192.4449 (192.2356)
2022-11-25 20:46:28,303:INFO: Dataset: univ                Batch:  9/15	Loss 191.1113 (192.1116)
2022-11-25 20:46:28,895:INFO: Dataset: univ                Batch: 10/15	Loss 191.3102 (192.0311)
2022-11-25 20:46:29,532:INFO: Dataset: univ                Batch: 11/15	Loss 191.3788 (191.9766)
2022-11-25 20:46:30,145:INFO: Dataset: univ                Batch: 12/15	Loss 191.8806 (191.9691)
2022-11-25 20:46:30,735:INFO: Dataset: univ                Batch: 13/15	Loss 192.6895 (192.0202)
2022-11-25 20:46:31,342:INFO: Dataset: univ                Batch: 14/15	Loss 191.7844 (192.0050)
2022-11-25 20:46:31,813:INFO: Dataset: univ                Batch: 15/15	Loss 35.8366 (189.8588)
2022-11-25 20:46:32,643:INFO: Dataset: zara1               Batch: 1/8	Loss 203.7428 (203.7428)
2022-11-25 20:46:33,181:INFO: Dataset: zara1               Batch: 2/8	Loss 204.0567 (203.9040)
2022-11-25 20:46:33,768:INFO: Dataset: zara1               Batch: 3/8	Loss 203.5747 (203.8013)
2022-11-25 20:46:34,315:INFO: Dataset: zara1               Batch: 4/8	Loss 203.2030 (203.6479)
2022-11-25 20:46:34,836:INFO: Dataset: zara1               Batch: 5/8	Loss 202.2732 (203.3720)
2022-11-25 20:46:35,359:INFO: Dataset: zara1               Batch: 6/8	Loss 202.5394 (203.2324)
2022-11-25 20:46:35,892:INFO: Dataset: zara1               Batch: 7/8	Loss 202.7254 (203.1559)
2022-11-25 20:46:36,396:INFO: Dataset: zara1               Batch: 8/8	Loss 174.2808 (199.6757)
2022-11-25 20:46:37,226:INFO: Dataset: zara2               Batch:  1/18	Loss 193.2997 (193.2997)
2022-11-25 20:46:37,754:INFO: Dataset: zara2               Batch:  2/18	Loss 193.4467 (193.3717)
2022-11-25 20:46:38,281:INFO: Dataset: zara2               Batch:  3/18	Loss 193.4263 (193.3911)
2022-11-25 20:46:38,807:INFO: Dataset: zara2               Batch:  4/18	Loss 193.4600 (193.4072)
2022-11-25 20:46:39,357:INFO: Dataset: zara2               Batch:  5/18	Loss 192.1008 (193.1331)
2022-11-25 20:46:39,899:INFO: Dataset: zara2               Batch:  6/18	Loss 191.6663 (192.8944)
2022-11-25 20:46:40,449:INFO: Dataset: zara2               Batch:  7/18	Loss 192.1111 (192.7801)
2022-11-25 20:46:41,013:INFO: Dataset: zara2               Batch:  8/18	Loss 192.1943 (192.7112)
2022-11-25 20:46:41,608:INFO: Dataset: zara2               Batch:  9/18	Loss 192.4420 (192.6801)
2022-11-25 20:46:42,240:INFO: Dataset: zara2               Batch: 10/18	Loss 193.2044 (192.7350)
2022-11-25 20:46:42,804:INFO: Dataset: zara2               Batch: 11/18	Loss 191.3753 (192.6182)
2022-11-25 20:46:43,411:INFO: Dataset: zara2               Batch: 12/18	Loss 191.0040 (192.4948)
2022-11-25 20:46:43,963:INFO: Dataset: zara2               Batch: 13/18	Loss 190.3454 (192.3404)
2022-11-25 20:46:44,545:INFO: Dataset: zara2               Batch: 14/18	Loss 192.6693 (192.3597)
2022-11-25 20:46:45,103:INFO: Dataset: zara2               Batch: 15/18	Loss 190.2015 (192.2122)
2022-11-25 20:46:45,658:INFO: Dataset: zara2               Batch: 16/18	Loss 190.0552 (192.0810)
2022-11-25 20:46:46,209:INFO: Dataset: zara2               Batch: 17/18	Loss 190.3420 (191.9838)
2022-11-25 20:46:46,749:INFO: Dataset: zara2               Batch: 18/18	Loss 162.4231 (190.4982)
2022-11-25 20:46:46,816:INFO: - Computing ADE (validation)
2022-11-25 20:46:47,249:INFO: 		 ADE on hotel                     dataset:	 2.93556809425354
2022-11-25 20:46:47,712:INFO: 		 ADE on univ                      dataset:	 3.6048169136047363
2022-11-25 20:46:48,082:INFO: 		 ADE on zara1                     dataset:	 2.981433868408203
2022-11-25 20:46:48,662:INFO: 		 ADE on zara2                     dataset:	 3.132270097732544
2022-11-25 20:46:48,662:INFO: Average validation:	ADE  3.3586	FDE  4.5350
2022-11-25 20:46:48,663:INFO: - Computing ADE (validation o)
2022-11-25 20:46:48,993:INFO: 		 ADE on eth                       dataset:	 3.1637158393859863
2022-11-25 20:46:48,993:INFO: Average validation o:	ADE  3.1637	FDE  3.9776
2022-11-25 20:46:49,002:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_258.pth.tar
2022-11-25 20:46:49,003:INFO: 
===> EPOCH: 259 (P3)
2022-11-25 20:46:49,003:INFO: - Computing loss (training)
2022-11-25 20:46:49,746:INFO: Dataset: hotel               Batch: 1/4	Loss 214.3239 (214.3239)
2022-11-25 20:46:50,316:INFO: Dataset: hotel               Batch: 2/4	Loss 208.6367 (211.4473)
2022-11-25 20:46:50,858:INFO: Dataset: hotel               Batch: 3/4	Loss 212.8501 (211.8980)
2022-11-25 20:46:51,325:INFO: Dataset: hotel               Batch: 4/4	Loss 123.1321 (197.4940)
2022-11-25 20:46:52,196:INFO: Dataset: univ                Batch:  1/15	Loss 185.3899 (185.3899)
2022-11-25 20:46:52,748:INFO: Dataset: univ                Batch:  2/15	Loss 185.2789 (185.3341)
2022-11-25 20:46:53,283:INFO: Dataset: univ                Batch:  3/15	Loss 185.4239 (185.3605)
2022-11-25 20:46:53,839:INFO: Dataset: univ                Batch:  4/15	Loss 183.6863 (184.9480)
2022-11-25 20:46:54,392:INFO: Dataset: univ                Batch:  5/15	Loss 184.6792 (184.8932)
2022-11-25 20:46:54,936:INFO: Dataset: univ                Batch:  6/15	Loss 184.3642 (184.8055)
2022-11-25 20:46:55,478:INFO: Dataset: univ                Batch:  7/15	Loss 184.4180 (184.7562)
2022-11-25 20:46:56,011:INFO: Dataset: univ                Batch:  8/15	Loss 185.2616 (184.8095)
2022-11-25 20:46:56,555:INFO: Dataset: univ                Batch:  9/15	Loss 184.7980 (184.8083)
2022-11-25 20:46:57,092:INFO: Dataset: univ                Batch: 10/15	Loss 184.0545 (184.7332)
2022-11-25 20:46:57,640:INFO: Dataset: univ                Batch: 11/15	Loss 182.1198 (184.4688)
2022-11-25 20:46:58,186:INFO: Dataset: univ                Batch: 12/15	Loss 184.3961 (184.4629)
2022-11-25 20:46:58,807:INFO: Dataset: univ                Batch: 13/15	Loss 181.9090 (184.2649)
2022-11-25 20:46:59,348:INFO: Dataset: univ                Batch: 14/15	Loss 183.8103 (184.2332)
2022-11-25 20:46:59,788:INFO: Dataset: univ                Batch: 15/15	Loss 34.9053 (182.0536)
2022-11-25 20:47:00,599:INFO: Dataset: zara1               Batch: 1/8	Loss 192.2570 (192.2570)
2022-11-25 20:47:01,105:INFO: Dataset: zara1               Batch: 2/8	Loss 193.4549 (192.8162)
2022-11-25 20:47:01,610:INFO: Dataset: zara1               Batch: 3/8	Loss 191.9463 (192.5319)
2022-11-25 20:47:02,122:INFO: Dataset: zara1               Batch: 4/8	Loss 191.6097 (192.3174)
2022-11-25 20:47:02,629:INFO: Dataset: zara1               Batch: 5/8	Loss 192.1376 (192.2801)
2022-11-25 20:47:03,139:INFO: Dataset: zara1               Batch: 6/8	Loss 191.3997 (192.1239)
2022-11-25 20:47:03,641:INFO: Dataset: zara1               Batch: 7/8	Loss 189.6879 (191.7765)
2022-11-25 20:47:04,133:INFO: Dataset: zara1               Batch: 8/8	Loss 162.5520 (188.2234)
2022-11-25 20:47:04,960:INFO: Dataset: zara2               Batch:  1/18	Loss 182.0861 (182.0861)
2022-11-25 20:47:05,487:INFO: Dataset: zara2               Batch:  2/18	Loss 182.1016 (182.0941)
2022-11-25 20:47:06,010:INFO: Dataset: zara2               Batch:  3/18	Loss 181.1228 (181.7655)
2022-11-25 20:47:06,541:INFO: Dataset: zara2               Batch:  4/18	Loss 181.6135 (181.7273)
2022-11-25 20:47:07,071:INFO: Dataset: zara2               Batch:  5/18	Loss 181.1311 (181.6134)
2022-11-25 20:47:07,624:INFO: Dataset: zara2               Batch:  6/18	Loss 179.2937 (181.2267)
2022-11-25 20:47:08,203:INFO: Dataset: zara2               Batch:  7/18	Loss 179.8165 (181.0227)
2022-11-25 20:47:08,843:INFO: Dataset: zara2               Batch:  8/18	Loss 179.1614 (180.7749)
2022-11-25 20:47:09,409:INFO: Dataset: zara2               Batch:  9/18	Loss 180.2045 (180.7142)
2022-11-25 20:47:10,003:INFO: Dataset: zara2               Batch: 10/18	Loss 178.2030 (180.4498)
2022-11-25 20:47:10,554:INFO: Dataset: zara2               Batch: 11/18	Loss 178.4299 (180.2761)
2022-11-25 20:47:11,089:INFO: Dataset: zara2               Batch: 12/18	Loss 178.6375 (180.1520)
2022-11-25 20:47:11,638:INFO: Dataset: zara2               Batch: 13/18	Loss 177.0373 (179.8963)
2022-11-25 20:47:12,211:INFO: Dataset: zara2               Batch: 14/18	Loss 176.7096 (179.6447)
2022-11-25 20:47:12,804:INFO: Dataset: zara2               Batch: 15/18	Loss 176.8347 (179.4631)
2022-11-25 20:47:13,355:INFO: Dataset: zara2               Batch: 16/18	Loss 175.6254 (179.2117)
2022-11-25 20:47:13,913:INFO: Dataset: zara2               Batch: 17/18	Loss 176.1967 (179.0429)
2022-11-25 20:47:14,462:INFO: Dataset: zara2               Batch: 18/18	Loss 152.1969 (177.8091)
2022-11-25 20:47:14,531:INFO: - Computing ADE (validation)
2022-11-25 20:47:14,920:INFO: 		 ADE on hotel                     dataset:	 3.070552110671997
2022-11-25 20:47:15,379:INFO: 		 ADE on univ                      dataset:	 3.603182077407837
2022-11-25 20:47:15,748:INFO: 		 ADE on zara1                     dataset:	 3.0116190910339355
2022-11-25 20:47:16,344:INFO: 		 ADE on zara2                     dataset:	 3.1583917140960693
2022-11-25 20:47:16,344:INFO: Average validation:	ADE  3.3765	FDE  4.6314
2022-11-25 20:47:16,345:INFO: - Computing ADE (validation o)
2022-11-25 20:47:16,681:INFO: 		 ADE on eth                       dataset:	 3.049281358718872
2022-11-25 20:47:16,681:INFO: Average validation o:	ADE  3.0493	FDE  3.8234
2022-11-25 20:47:16,690:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_259.pth.tar
2022-11-25 20:47:16,690:INFO: 
===> EPOCH: 260 (P3)
2022-11-25 20:47:16,690:INFO: - Computing loss (training)
2022-11-25 20:47:17,447:INFO: Dataset: hotel               Batch: 1/4	Loss 214.7048 (214.7048)
2022-11-25 20:47:17,967:INFO: Dataset: hotel               Batch: 2/4	Loss 200.4673 (207.5523)
2022-11-25 20:47:18,483:INFO: Dataset: hotel               Batch: 3/4	Loss 196.9912 (204.0993)
2022-11-25 20:47:18,966:INFO: Dataset: hotel               Batch: 4/4	Loss 127.1483 (190.8004)
2022-11-25 20:47:19,829:INFO: Dataset: univ                Batch:  1/15	Loss 174.3709 (174.3709)
2022-11-25 20:47:20,386:INFO: Dataset: univ                Batch:  2/15	Loss 174.3422 (174.3565)
2022-11-25 20:47:20,964:INFO: Dataset: univ                Batch:  3/15	Loss 172.6024 (173.7520)
2022-11-25 20:47:21,520:INFO: Dataset: univ                Batch:  4/15	Loss 172.8283 (173.5466)
2022-11-25 20:47:22,109:INFO: Dataset: univ                Batch:  5/15	Loss 172.7366 (173.3770)
2022-11-25 20:47:22,714:INFO: Dataset: univ                Batch:  6/15	Loss 172.3115 (173.1823)
2022-11-25 20:47:23,286:INFO: Dataset: univ                Batch:  7/15	Loss 171.9159 (173.0060)
2022-11-25 20:47:23,881:INFO: Dataset: univ                Batch:  8/15	Loss 171.3182 (172.7931)
2022-11-25 20:47:24,452:INFO: Dataset: univ                Batch:  9/15	Loss 172.5590 (172.7669)
2022-11-25 20:47:25,034:INFO: Dataset: univ                Batch: 10/15	Loss 170.8012 (172.5647)
2022-11-25 20:47:25,617:INFO: Dataset: univ                Batch: 11/15	Loss 171.7640 (172.4963)
2022-11-25 20:47:26,190:INFO: Dataset: univ                Batch: 12/15	Loss 172.4601 (172.4933)
2022-11-25 20:47:26,767:INFO: Dataset: univ                Batch: 13/15	Loss 170.8748 (172.3624)
2022-11-25 20:47:27,378:INFO: Dataset: univ                Batch: 14/15	Loss 171.3697 (172.2989)
2022-11-25 20:47:27,872:INFO: Dataset: univ                Batch: 15/15	Loss 32.2011 (170.0018)
2022-11-25 20:47:28,700:INFO: Dataset: zara1               Batch: 1/8	Loss 180.4193 (180.4193)
2022-11-25 20:47:29,225:INFO: Dataset: zara1               Batch: 2/8	Loss 179.7808 (180.0612)
2022-11-25 20:47:29,738:INFO: Dataset: zara1               Batch: 3/8	Loss 176.7972 (179.0769)
2022-11-25 20:47:30,256:INFO: Dataset: zara1               Batch: 4/8	Loss 178.3575 (178.9053)
2022-11-25 20:47:30,773:INFO: Dataset: zara1               Batch: 5/8	Loss 177.0100 (178.5415)
2022-11-25 20:47:31,293:INFO: Dataset: zara1               Batch: 6/8	Loss 176.8670 (178.2842)
2022-11-25 20:47:31,802:INFO: Dataset: zara1               Batch: 7/8	Loss 175.8587 (177.9379)
2022-11-25 20:47:32,314:INFO: Dataset: zara1               Batch: 8/8	Loss 153.2913 (175.5511)
2022-11-25 20:47:33,362:INFO: Dataset: zara2               Batch:  1/18	Loss 172.1915 (172.1915)
2022-11-25 20:47:34,272:INFO: Dataset: zara2               Batch:  2/18	Loss 171.5805 (171.8755)
2022-11-25 20:47:34,832:INFO: Dataset: zara2               Batch:  3/18	Loss 170.2135 (171.2962)
2022-11-25 20:47:35,383:INFO: Dataset: zara2               Batch:  4/18	Loss 168.5661 (170.6383)
2022-11-25 20:47:35,921:INFO: Dataset: zara2               Batch:  5/18	Loss 171.8231 (170.8673)
2022-11-25 20:47:36,456:INFO: Dataset: zara2               Batch:  6/18	Loss 172.2169 (171.1128)
2022-11-25 20:47:36,993:INFO: Dataset: zara2               Batch:  7/18	Loss 172.2699 (171.2757)
2022-11-25 20:47:37,529:INFO: Dataset: zara2               Batch:  8/18	Loss 171.0301 (171.2454)
2022-11-25 20:47:38,056:INFO: Dataset: zara2               Batch:  9/18	Loss 170.7730 (171.2002)
2022-11-25 20:47:38,583:INFO: Dataset: zara2               Batch: 10/18	Loss 170.6437 (171.1419)
2022-11-25 20:47:39,127:INFO: Dataset: zara2               Batch: 11/18	Loss 169.4812 (170.9943)
2022-11-25 20:47:39,760:INFO: Dataset: zara2               Batch: 12/18	Loss 170.8783 (170.9847)
2022-11-25 20:47:40,338:INFO: Dataset: zara2               Batch: 13/18	Loss 170.4149 (170.9360)
2022-11-25 20:47:40,966:INFO: Dataset: zara2               Batch: 14/18	Loss 171.6866 (170.9891)
2022-11-25 20:47:41,520:INFO: Dataset: zara2               Batch: 15/18	Loss 170.2069 (170.9372)
2022-11-25 20:47:42,104:INFO: Dataset: zara2               Batch: 16/18	Loss 171.1592 (170.9506)
2022-11-25 20:47:42,639:INFO: Dataset: zara2               Batch: 17/18	Loss 169.8834 (170.8877)
2022-11-25 20:47:43,181:INFO: Dataset: zara2               Batch: 18/18	Loss 146.3761 (169.6842)
2022-11-25 20:47:43,262:INFO: - Computing ADE (validation)
2022-11-25 20:47:43,649:INFO: 		 ADE on hotel                     dataset:	 3.0299320220947266
2022-11-25 20:47:44,137:INFO: 		 ADE on univ                      dataset:	 3.6657228469848633
2022-11-25 20:47:44,497:INFO: 		 ADE on zara1                     dataset:	 3.0578908920288086
2022-11-25 20:47:45,071:INFO: 		 ADE on zara2                     dataset:	 3.21539306640625
2022-11-25 20:47:45,072:INFO: Average validation:	ADE  3.4304	FDE  4.8490
2022-11-25 20:47:45,073:INFO: - Computing ADE (validation o)
2022-11-25 20:47:45,429:INFO: 		 ADE on eth                       dataset:	 3.10357928276062
2022-11-25 20:47:45,429:INFO: Average validation o:	ADE  3.1036	FDE  4.2988
2022-11-25 20:47:45,440:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_260.pth.tar
2022-11-25 20:47:45,440:INFO: 
===> EPOCH: 261 (P3)
2022-11-25 20:47:45,440:INFO: - Computing loss (training)
2022-11-25 20:47:46,204:INFO: Dataset: hotel               Batch: 1/4	Loss 319.3658 (319.3658)
2022-11-25 20:47:46,762:INFO: Dataset: hotel               Batch: 2/4	Loss 190.4250 (256.2736)
2022-11-25 20:47:47,290:INFO: Dataset: hotel               Batch: 3/4	Loss 196.5556 (236.3361)
2022-11-25 20:47:47,764:INFO: Dataset: hotel               Batch: 4/4	Loss 173.2028 (225.8417)
2022-11-25 20:47:48,669:INFO: Dataset: univ                Batch:  1/15	Loss 177.3465 (177.3465)
2022-11-25 20:47:49,234:INFO: Dataset: univ                Batch:  2/15	Loss 170.4400 (173.8624)
2022-11-25 20:47:49,818:INFO: Dataset: univ                Batch:  3/15	Loss 173.0061 (173.5318)
2022-11-25 20:47:50,436:INFO: Dataset: univ                Batch:  4/15	Loss 177.1158 (174.4150)
2022-11-25 20:47:51,354:INFO: Dataset: univ                Batch:  5/15	Loss 170.8617 (173.8177)
2022-11-25 20:47:51,967:INFO: Dataset: univ                Batch:  6/15	Loss 169.7250 (173.0538)
2022-11-25 20:47:52,527:INFO: Dataset: univ                Batch:  7/15	Loss 169.4486 (172.5105)
2022-11-25 20:47:53,078:INFO: Dataset: univ                Batch:  8/15	Loss 169.2826 (172.0899)
2022-11-25 20:47:53,621:INFO: Dataset: univ                Batch:  9/15	Loss 169.7176 (171.8298)
2022-11-25 20:47:54,182:INFO: Dataset: univ                Batch: 10/15	Loss 170.2764 (171.6693)
2022-11-25 20:47:54,739:INFO: Dataset: univ                Batch: 11/15	Loss 172.7880 (171.7787)
2022-11-25 20:47:55,303:INFO: Dataset: univ                Batch: 12/15	Loss 170.7666 (171.6933)
2022-11-25 20:47:55,884:INFO: Dataset: univ                Batch: 13/15	Loss 171.0533 (171.6388)
2022-11-25 20:47:56,543:INFO: Dataset: univ                Batch: 14/15	Loss 172.3077 (171.6887)
2022-11-25 20:47:57,063:INFO: Dataset: univ                Batch: 15/15	Loss 32.0986 (169.9556)
2022-11-25 20:47:57,999:INFO: Dataset: zara1               Batch: 1/8	Loss 178.6537 (178.6537)
2022-11-25 20:47:58,570:INFO: Dataset: zara1               Batch: 2/8	Loss 182.5767 (180.5410)
2022-11-25 20:47:59,149:INFO: Dataset: zara1               Batch: 3/8	Loss 177.6173 (179.4704)
2022-11-25 20:47:59,690:INFO: Dataset: zara1               Batch: 4/8	Loss 175.5294 (178.5070)
2022-11-25 20:48:00,237:INFO: Dataset: zara1               Batch: 5/8	Loss 177.3190 (178.2790)
2022-11-25 20:48:00,788:INFO: Dataset: zara1               Batch: 6/8	Loss 178.5858 (178.3254)
2022-11-25 20:48:01,357:INFO: Dataset: zara1               Batch: 7/8	Loss 180.1931 (178.5657)
2022-11-25 20:48:01,881:INFO: Dataset: zara1               Batch: 8/8	Loss 151.4962 (175.1892)
2022-11-25 20:48:02,765:INFO: Dataset: zara2               Batch:  1/18	Loss 172.9742 (172.9742)
2022-11-25 20:48:03,340:INFO: Dataset: zara2               Batch:  2/18	Loss 175.4438 (174.2253)
2022-11-25 20:48:03,920:INFO: Dataset: zara2               Batch:  3/18	Loss 172.8201 (173.7555)
2022-11-25 20:48:04,460:INFO: Dataset: zara2               Batch:  4/18	Loss 175.7135 (174.2838)
2022-11-25 20:48:05,024:INFO: Dataset: zara2               Batch:  5/18	Loss 175.9416 (174.6076)
2022-11-25 20:48:05,581:INFO: Dataset: zara2               Batch:  6/18	Loss 172.7091 (174.3066)
2022-11-25 20:48:06,156:INFO: Dataset: zara2               Batch:  7/18	Loss 171.1326 (173.8768)
2022-11-25 20:48:06,857:INFO: Dataset: zara2               Batch:  8/18	Loss 176.9381 (174.2587)
2022-11-25 20:48:07,689:INFO: Dataset: zara2               Batch:  9/18	Loss 172.0844 (174.0385)
2022-11-25 20:48:08,254:INFO: Dataset: zara2               Batch: 10/18	Loss 175.2353 (174.1482)
2022-11-25 20:48:08,801:INFO: Dataset: zara2               Batch: 11/18	Loss 173.8943 (174.1251)
2022-11-25 20:48:09,351:INFO: Dataset: zara2               Batch: 12/18	Loss 172.7519 (174.0081)
2022-11-25 20:48:09,910:INFO: Dataset: zara2               Batch: 13/18	Loss 177.2519 (174.2427)
2022-11-25 20:48:10,428:INFO: Dataset: zara2               Batch: 14/18	Loss 171.4882 (174.0373)
2022-11-25 20:48:10,944:INFO: Dataset: zara2               Batch: 15/18	Loss 171.1808 (173.8253)
2022-11-25 20:48:11,464:INFO: Dataset: zara2               Batch: 16/18	Loss 170.1869 (173.6131)
2022-11-25 20:48:11,982:INFO: Dataset: zara2               Batch: 17/18	Loss 170.5620 (173.4253)
2022-11-25 20:48:12,487:INFO: Dataset: zara2               Batch: 18/18	Loss 148.0480 (172.1079)
2022-11-25 20:48:12,553:INFO: - Computing ADE (validation)
2022-11-25 20:48:12,922:INFO: 		 ADE on hotel                     dataset:	 3.0371737480163574
2022-11-25 20:48:13,364:INFO: 		 ADE on univ                      dataset:	 3.6280677318573
2022-11-25 20:48:13,713:INFO: 		 ADE on zara1                     dataset:	 3.0896761417388916
2022-11-25 20:48:14,268:INFO: 		 ADE on zara2                     dataset:	 3.202031373977661
2022-11-25 20:48:14,268:INFO: Average validation:	ADE  3.4081	FDE  4.7362
2022-11-25 20:48:14,269:INFO: - Computing ADE (validation o)
2022-11-25 20:48:14,572:INFO: 		 ADE on eth                       dataset:	 3.135514497756958
2022-11-25 20:48:14,572:INFO: Average validation o:	ADE  3.1355	FDE  4.1290
2022-11-25 20:48:14,581:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_261.pth.tar
2022-11-25 20:48:14,582:INFO: 
===> EPOCH: 262 (P3)
2022-11-25 20:48:14,582:INFO: - Computing loss (training)
2022-11-25 20:48:15,327:INFO: Dataset: hotel               Batch: 1/4	Loss 207.0008 (207.0008)
2022-11-25 20:48:15,833:INFO: Dataset: hotel               Batch: 2/4	Loss 222.1894 (214.5772)
2022-11-25 20:48:16,328:INFO: Dataset: hotel               Batch: 3/4	Loss 203.7415 (210.9258)
2022-11-25 20:48:16,768:INFO: Dataset: hotel               Batch: 4/4	Loss 126.4381 (197.8849)
2022-11-25 20:48:17,612:INFO: Dataset: univ                Batch:  1/15	Loss 168.4849 (168.4849)
2022-11-25 20:48:18,152:INFO: Dataset: univ                Batch:  2/15	Loss 169.8743 (169.1815)
2022-11-25 20:48:18,694:INFO: Dataset: univ                Batch:  3/15	Loss 170.1636 (169.5192)
2022-11-25 20:48:19,238:INFO: Dataset: univ                Batch:  4/15	Loss 170.7802 (169.8356)
2022-11-25 20:48:19,787:INFO: Dataset: univ                Batch:  5/15	Loss 170.5331 (169.9841)
2022-11-25 20:48:20,331:INFO: Dataset: univ                Batch:  6/15	Loss 172.7194 (170.4158)
2022-11-25 20:48:20,868:INFO: Dataset: univ                Batch:  7/15	Loss 170.5059 (170.4280)
2022-11-25 20:48:21,410:INFO: Dataset: univ                Batch:  8/15	Loss 172.0973 (170.6369)
2022-11-25 20:48:21,956:INFO: Dataset: univ                Batch:  9/15	Loss 169.6689 (170.5219)
2022-11-25 20:48:22,507:INFO: Dataset: univ                Batch: 10/15	Loss 171.3646 (170.6129)
2022-11-25 20:48:23,044:INFO: Dataset: univ                Batch: 11/15	Loss 169.1784 (170.4927)
2022-11-25 20:48:23,589:INFO: Dataset: univ                Batch: 12/15	Loss 176.8835 (171.0392)
2022-11-25 20:48:24,134:INFO: Dataset: univ                Batch: 13/15	Loss 173.2509 (171.2182)
2022-11-25 20:48:24,678:INFO: Dataset: univ                Batch: 14/15	Loss 169.5092 (171.0927)
2022-11-25 20:48:25,107:INFO: Dataset: univ                Batch: 15/15	Loss 31.9980 (169.5041)
2022-11-25 20:48:25,908:INFO: Dataset: zara1               Batch: 1/8	Loss 175.4662 (175.4662)
2022-11-25 20:48:26,414:INFO: Dataset: zara1               Batch: 2/8	Loss 175.2957 (175.3752)
2022-11-25 20:48:26,912:INFO: Dataset: zara1               Batch: 3/8	Loss 175.2835 (175.3461)
2022-11-25 20:48:27,410:INFO: Dataset: zara1               Batch: 4/8	Loss 180.4182 (176.6273)
2022-11-25 20:48:27,917:INFO: Dataset: zara1               Batch: 5/8	Loss 174.7698 (176.2261)
2022-11-25 20:48:28,419:INFO: Dataset: zara1               Batch: 6/8	Loss 174.6444 (175.9829)
2022-11-25 20:48:28,915:INFO: Dataset: zara1               Batch: 7/8	Loss 175.8710 (175.9669)
2022-11-25 20:48:29,399:INFO: Dataset: zara1               Batch: 8/8	Loss 149.8310 (173.1057)
2022-11-25 20:48:30,248:INFO: Dataset: zara2               Batch:  1/18	Loss 170.7207 (170.7207)
2022-11-25 20:48:30,826:INFO: Dataset: zara2               Batch:  2/18	Loss 170.7058 (170.7135)
2022-11-25 20:48:31,342:INFO: Dataset: zara2               Batch:  3/18	Loss 170.5168 (170.6444)
2022-11-25 20:48:31,853:INFO: Dataset: zara2               Batch:  4/18	Loss 170.3593 (170.5768)
2022-11-25 20:48:32,368:INFO: Dataset: zara2               Batch:  5/18	Loss 173.9363 (171.2220)
2022-11-25 20:48:32,887:INFO: Dataset: zara2               Batch:  6/18	Loss 169.3780 (170.9333)
2022-11-25 20:48:33,399:INFO: Dataset: zara2               Batch:  7/18	Loss 171.2193 (170.9729)
2022-11-25 20:48:33,910:INFO: Dataset: zara2               Batch:  8/18	Loss 170.4654 (170.9045)
2022-11-25 20:48:34,422:INFO: Dataset: zara2               Batch:  9/18	Loss 170.3031 (170.8362)
2022-11-25 20:48:34,938:INFO: Dataset: zara2               Batch: 10/18	Loss 169.3543 (170.6866)
2022-11-25 20:48:35,448:INFO: Dataset: zara2               Batch: 11/18	Loss 168.7639 (170.4878)
2022-11-25 20:48:35,959:INFO: Dataset: zara2               Batch: 12/18	Loss 169.6491 (170.4116)
2022-11-25 20:48:36,479:INFO: Dataset: zara2               Batch: 13/18	Loss 169.0304 (170.3108)
2022-11-25 20:48:37,003:INFO: Dataset: zara2               Batch: 14/18	Loss 169.6607 (170.2689)
2022-11-25 20:48:37,517:INFO: Dataset: zara2               Batch: 15/18	Loss 172.5778 (170.4122)
2022-11-25 20:48:38,027:INFO: Dataset: zara2               Batch: 16/18	Loss 168.9184 (170.3275)
2022-11-25 20:48:38,626:INFO: Dataset: zara2               Batch: 17/18	Loss 172.4789 (170.4510)
2022-11-25 20:48:39,127:INFO: Dataset: zara2               Batch: 18/18	Loss 145.9370 (169.3649)
2022-11-25 20:48:39,192:INFO: - Computing ADE (validation)
2022-11-25 20:48:39,559:INFO: 		 ADE on hotel                     dataset:	 2.981609582901001
2022-11-25 20:48:40,015:INFO: 		 ADE on univ                      dataset:	 3.609652280807495
2022-11-25 20:48:40,376:INFO: 		 ADE on zara1                     dataset:	 2.9932847023010254
2022-11-25 20:48:40,937:INFO: 		 ADE on zara2                     dataset:	 3.1771883964538574
2022-11-25 20:48:40,937:INFO: Average validation:	ADE  3.3808	FDE  4.6887
2022-11-25 20:48:40,938:INFO: - Computing ADE (validation o)
2022-11-25 20:48:41,240:INFO: 		 ADE on eth                       dataset:	 2.9403324127197266
2022-11-25 20:48:41,240:INFO: Average validation o:	ADE  2.9403	FDE  4.0368
2022-11-25 20:48:41,249:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_262.pth.tar
2022-11-25 20:48:41,249:INFO: 
===> EPOCH: 263 (P3)
2022-11-25 20:48:41,250:INFO: - Computing loss (training)
2022-11-25 20:48:41,991:INFO: Dataset: hotel               Batch: 1/4	Loss 201.8422 (201.8422)
2022-11-25 20:48:42,503:INFO: Dataset: hotel               Batch: 2/4	Loss 216.7889 (209.4559)
2022-11-25 20:48:43,007:INFO: Dataset: hotel               Batch: 3/4	Loss 188.1074 (202.3844)
2022-11-25 20:48:43,452:INFO: Dataset: hotel               Batch: 4/4	Loss 118.7081 (189.0271)
2022-11-25 20:48:44,291:INFO: Dataset: univ                Batch:  1/15	Loss 167.4930 (167.4930)
2022-11-25 20:48:44,842:INFO: Dataset: univ                Batch:  2/15	Loss 167.5938 (167.5458)
2022-11-25 20:48:45,393:INFO: Dataset: univ                Batch:  3/15	Loss 168.4673 (167.8511)
2022-11-25 20:48:45,943:INFO: Dataset: univ                Batch:  4/15	Loss 168.9613 (168.1175)
2022-11-25 20:48:46,490:INFO: Dataset: univ                Batch:  5/15	Loss 169.5395 (168.3907)
2022-11-25 20:48:47,039:INFO: Dataset: univ                Batch:  6/15	Loss 167.5536 (168.2515)
2022-11-25 20:48:47,584:INFO: Dataset: univ                Batch:  7/15	Loss 166.9416 (168.0667)
2022-11-25 20:48:48,127:INFO: Dataset: univ                Batch:  8/15	Loss 169.1805 (168.1973)
2022-11-25 20:48:48,670:INFO: Dataset: univ                Batch:  9/15	Loss 167.6091 (168.1380)
2022-11-25 20:48:49,228:INFO: Dataset: univ                Batch: 10/15	Loss 168.3114 (168.1573)
2022-11-25 20:48:49,777:INFO: Dataset: univ                Batch: 11/15	Loss 167.6532 (168.1098)
2022-11-25 20:48:50,323:INFO: Dataset: univ                Batch: 12/15	Loss 167.1752 (168.0338)
2022-11-25 20:48:50,866:INFO: Dataset: univ                Batch: 13/15	Loss 168.5831 (168.0738)
2022-11-25 20:48:51,410:INFO: Dataset: univ                Batch: 14/15	Loss 167.7958 (168.0547)
2022-11-25 20:48:51,845:INFO: Dataset: univ                Batch: 15/15	Loss 31.6577 (166.4258)
2022-11-25 20:48:52,671:INFO: Dataset: zara1               Batch: 1/8	Loss 176.1629 (176.1629)
2022-11-25 20:48:53,172:INFO: Dataset: zara1               Batch: 2/8	Loss 174.2968 (175.2613)
2022-11-25 20:48:53,680:INFO: Dataset: zara1               Batch: 3/8	Loss 173.8353 (174.7816)
2022-11-25 20:48:54,199:INFO: Dataset: zara1               Batch: 4/8	Loss 173.4755 (174.4887)
2022-11-25 20:48:54,699:INFO: Dataset: zara1               Batch: 5/8	Loss 175.7938 (174.7418)
2022-11-25 20:48:55,202:INFO: Dataset: zara1               Batch: 6/8	Loss 175.0786 (174.7965)
2022-11-25 20:48:55,702:INFO: Dataset: zara1               Batch: 7/8	Loss 174.1179 (174.7027)
2022-11-25 20:48:56,188:INFO: Dataset: zara1               Batch: 8/8	Loss 151.1506 (172.0500)
2022-11-25 20:48:57,011:INFO: Dataset: zara2               Batch:  1/18	Loss 169.4510 (169.4510)
2022-11-25 20:48:57,540:INFO: Dataset: zara2               Batch:  2/18	Loss 169.6386 (169.5445)
2022-11-25 20:48:58,065:INFO: Dataset: zara2               Batch:  3/18	Loss 169.1448 (169.4037)
2022-11-25 20:48:58,588:INFO: Dataset: zara2               Batch:  4/18	Loss 169.7523 (169.4949)
2022-11-25 20:48:59,111:INFO: Dataset: zara2               Batch:  5/18	Loss 169.5879 (169.5137)
2022-11-25 20:48:59,634:INFO: Dataset: zara2               Batch:  6/18	Loss 167.9896 (169.2707)
2022-11-25 20:49:00,157:INFO: Dataset: zara2               Batch:  7/18	Loss 170.8248 (169.5056)
2022-11-25 20:49:00,675:INFO: Dataset: zara2               Batch:  8/18	Loss 168.5249 (169.3749)
2022-11-25 20:49:01,195:INFO: Dataset: zara2               Batch:  9/18	Loss 170.9885 (169.5637)
2022-11-25 20:49:01,715:INFO: Dataset: zara2               Batch: 10/18	Loss 170.0715 (169.6175)
2022-11-25 20:49:02,232:INFO: Dataset: zara2               Batch: 11/18	Loss 167.9934 (169.4660)
2022-11-25 20:49:02,752:INFO: Dataset: zara2               Batch: 12/18	Loss 169.6626 (169.4825)
2022-11-25 20:49:03,267:INFO: Dataset: zara2               Batch: 13/18	Loss 170.2126 (169.5309)
2022-11-25 20:49:03,786:INFO: Dataset: zara2               Batch: 14/18	Loss 169.7544 (169.5482)
2022-11-25 20:49:04,304:INFO: Dataset: zara2               Batch: 15/18	Loss 169.4063 (169.5396)
2022-11-25 20:49:04,823:INFO: Dataset: zara2               Batch: 16/18	Loss 168.5058 (169.4724)
2022-11-25 20:49:05,343:INFO: Dataset: zara2               Batch: 17/18	Loss 168.3994 (169.4126)
2022-11-25 20:49:05,849:INFO: Dataset: zara2               Batch: 18/18	Loss 145.4012 (168.2138)
2022-11-25 20:49:05,909:INFO: - Computing ADE (validation)
2022-11-25 20:49:06,292:INFO: 		 ADE on hotel                     dataset:	 2.9218978881835938
2022-11-25 20:49:06,741:INFO: 		 ADE on univ                      dataset:	 3.6384758949279785
2022-11-25 20:49:07,100:INFO: 		 ADE on zara1                     dataset:	 3.037014961242676
2022-11-25 20:49:07,673:INFO: 		 ADE on zara2                     dataset:	 3.1915090084075928
2022-11-25 20:49:07,674:INFO: Average validation:	ADE  3.4003	FDE  4.7372
2022-11-25 20:49:07,675:INFO: - Computing ADE (validation o)
2022-11-25 20:49:07,985:INFO: 		 ADE on eth                       dataset:	 3.0383541584014893
2022-11-25 20:49:07,985:INFO: Average validation o:	ADE  3.0384	FDE  4.1459
2022-11-25 20:49:07,994:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_263.pth.tar
2022-11-25 20:49:07,994:INFO: 
===> EPOCH: 264 (P3)
2022-11-25 20:49:07,994:INFO: - Computing loss (training)
2022-11-25 20:49:08,738:INFO: Dataset: hotel               Batch: 1/4	Loss 212.4442 (212.4442)
2022-11-25 20:49:09,253:INFO: Dataset: hotel               Batch: 2/4	Loss 189.1696 (200.6706)
2022-11-25 20:49:09,775:INFO: Dataset: hotel               Batch: 3/4	Loss 472.5461 (290.5856)
2022-11-25 20:49:10,219:INFO: Dataset: hotel               Batch: 4/4	Loss 116.3725 (263.0057)
2022-11-25 20:49:11,074:INFO: Dataset: univ                Batch:  1/15	Loss 167.1416 (167.1416)
2022-11-25 20:49:11,631:INFO: Dataset: univ                Batch:  2/15	Loss 167.7951 (167.4787)
2022-11-25 20:49:12,173:INFO: Dataset: univ                Batch:  3/15	Loss 168.1293 (167.6852)
2022-11-25 20:49:12,725:INFO: Dataset: univ                Batch:  4/15	Loss 167.9016 (167.7407)
2022-11-25 20:49:13,352:INFO: Dataset: univ                Batch:  5/15	Loss 168.7094 (167.9198)
2022-11-25 20:49:13,906:INFO: Dataset: univ                Batch:  6/15	Loss 168.2398 (167.9748)
2022-11-25 20:49:14,458:INFO: Dataset: univ                Batch:  7/15	Loss 168.6694 (168.0814)
2022-11-25 20:49:15,006:INFO: Dataset: univ                Batch:  8/15	Loss 168.6863 (168.1582)
2022-11-25 20:49:15,555:INFO: Dataset: univ                Batch:  9/15	Loss 170.7668 (168.4447)
2022-11-25 20:49:16,093:INFO: Dataset: univ                Batch: 10/15	Loss 169.4900 (168.5400)
2022-11-25 20:49:16,628:INFO: Dataset: univ                Batch: 11/15	Loss 167.7815 (168.4791)
2022-11-25 20:49:17,167:INFO: Dataset: univ                Batch: 12/15	Loss 169.2888 (168.5429)
2022-11-25 20:49:17,704:INFO: Dataset: univ                Batch: 13/15	Loss 169.5703 (168.6178)
2022-11-25 20:49:18,246:INFO: Dataset: univ                Batch: 14/15	Loss 169.1863 (168.6569)
2022-11-25 20:49:18,685:INFO: Dataset: univ                Batch: 15/15	Loss 31.6821 (166.6382)
2022-11-25 20:49:19,499:INFO: Dataset: zara1               Batch: 1/8	Loss 175.3727 (175.3727)
2022-11-25 20:49:20,000:INFO: Dataset: zara1               Batch: 2/8	Loss 177.3332 (176.2922)
2022-11-25 20:49:20,496:INFO: Dataset: zara1               Batch: 3/8	Loss 176.1998 (176.2614)
2022-11-25 20:49:21,009:INFO: Dataset: zara1               Batch: 4/8	Loss 178.1194 (176.7513)
2022-11-25 20:49:21,509:INFO: Dataset: zara1               Batch: 5/8	Loss 177.3339 (176.8600)
2022-11-25 20:49:22,018:INFO: Dataset: zara1               Batch: 6/8	Loss 177.1782 (176.9167)
2022-11-25 20:49:22,514:INFO: Dataset: zara1               Batch: 7/8	Loss 180.3946 (177.3823)
2022-11-25 20:49:22,996:INFO: Dataset: zara1               Batch: 8/8	Loss 151.6002 (174.7091)
2022-11-25 20:49:23,810:INFO: Dataset: zara2               Batch:  1/18	Loss 171.7458 (171.7458)
2022-11-25 20:49:24,320:INFO: Dataset: zara2               Batch:  2/18	Loss 171.6983 (171.7222)
2022-11-25 20:49:24,829:INFO: Dataset: zara2               Batch:  3/18	Loss 170.1638 (171.1970)
2022-11-25 20:49:25,344:INFO: Dataset: zara2               Batch:  4/18	Loss 168.7763 (170.6047)
2022-11-25 20:49:25,855:INFO: Dataset: zara2               Batch:  5/18	Loss 170.1047 (170.5119)
2022-11-25 20:49:26,365:INFO: Dataset: zara2               Batch:  6/18	Loss 170.7795 (170.5635)
2022-11-25 20:49:26,875:INFO: Dataset: zara2               Batch:  7/18	Loss 171.7880 (170.7254)
2022-11-25 20:49:27,385:INFO: Dataset: zara2               Batch:  8/18	Loss 173.0434 (170.9753)
2022-11-25 20:49:27,892:INFO: Dataset: zara2               Batch:  9/18	Loss 169.8619 (170.8459)
2022-11-25 20:49:28,400:INFO: Dataset: zara2               Batch: 10/18	Loss 171.0453 (170.8698)
2022-11-25 20:49:28,907:INFO: Dataset: zara2               Batch: 11/18	Loss 170.4134 (170.8267)
2022-11-25 20:49:29,415:INFO: Dataset: zara2               Batch: 12/18	Loss 168.9946 (170.6605)
2022-11-25 20:49:29,922:INFO: Dataset: zara2               Batch: 13/18	Loss 170.6201 (170.6572)
2022-11-25 20:49:30,437:INFO: Dataset: zara2               Batch: 14/18	Loss 169.6787 (170.5903)
2022-11-25 20:49:30,950:INFO: Dataset: zara2               Batch: 15/18	Loss 168.6577 (170.4540)
2022-11-25 20:49:31,466:INFO: Dataset: zara2               Batch: 16/18	Loss 170.2840 (170.4418)
2022-11-25 20:49:31,983:INFO: Dataset: zara2               Batch: 17/18	Loss 170.8715 (170.4665)
2022-11-25 20:49:32,486:INFO: Dataset: zara2               Batch: 18/18	Loss 147.1286 (169.4595)
2022-11-25 20:49:32,548:INFO: - Computing ADE (validation)
2022-11-25 20:49:32,921:INFO: 		 ADE on hotel                     dataset:	 2.9831883907318115
2022-11-25 20:49:33,362:INFO: 		 ADE on univ                      dataset:	 3.609044075012207
2022-11-25 20:49:33,721:INFO: 		 ADE on zara1                     dataset:	 3.023775339126587
2022-11-25 20:49:34,276:INFO: 		 ADE on zara2                     dataset:	 3.155734062194824
2022-11-25 20:49:34,276:INFO: Average validation:	ADE  3.3745	FDE  4.6768
2022-11-25 20:49:34,277:INFO: - Computing ADE (validation o)
2022-11-25 20:49:34,582:INFO: 		 ADE on eth                       dataset:	 3.0860025882720947
2022-11-25 20:49:34,582:INFO: Average validation o:	ADE  3.0860	FDE  4.2417
2022-11-25 20:49:34,591:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_264.pth.tar
2022-11-25 20:49:34,591:INFO: 
===> EPOCH: 265 (P3)
2022-11-25 20:49:34,591:INFO: - Computing loss (training)
2022-11-25 20:49:35,315:INFO: Dataset: hotel               Batch: 1/4	Loss 206.9607 (206.9607)
2022-11-25 20:49:35,822:INFO: Dataset: hotel               Batch: 2/4	Loss 259.6544 (234.0059)
2022-11-25 20:49:36,327:INFO: Dataset: hotel               Batch: 3/4	Loss 203.6806 (223.6885)
2022-11-25 20:49:36,788:INFO: Dataset: hotel               Batch: 4/4	Loss 128.5041 (207.4896)
2022-11-25 20:49:37,631:INFO: Dataset: univ                Batch:  1/15	Loss 168.6277 (168.6277)
2022-11-25 20:49:38,185:INFO: Dataset: univ                Batch:  2/15	Loss 168.0997 (168.3704)
2022-11-25 20:49:38,734:INFO: Dataset: univ                Batch:  3/15	Loss 167.1199 (167.9491)
2022-11-25 20:49:39,279:INFO: Dataset: univ                Batch:  4/15	Loss 167.2510 (167.7840)
2022-11-25 20:49:39,835:INFO: Dataset: univ                Batch:  5/15	Loss 166.9528 (167.6099)
2022-11-25 20:49:40,383:INFO: Dataset: univ                Batch:  6/15	Loss 167.9271 (167.6614)
2022-11-25 20:49:40,925:INFO: Dataset: univ                Batch:  7/15	Loss 169.0796 (167.8546)
2022-11-25 20:49:41,465:INFO: Dataset: univ                Batch:  8/15	Loss 167.3477 (167.7971)
2022-11-25 20:49:42,016:INFO: Dataset: univ                Batch:  9/15	Loss 166.9106 (167.6932)
2022-11-25 20:49:42,570:INFO: Dataset: univ                Batch: 10/15	Loss 168.9672 (167.8303)
2022-11-25 20:49:43,113:INFO: Dataset: univ                Batch: 11/15	Loss 168.4059 (167.8813)
2022-11-25 20:49:43,668:INFO: Dataset: univ                Batch: 12/15	Loss 169.1276 (167.9925)
2022-11-25 20:49:44,215:INFO: Dataset: univ                Batch: 13/15	Loss 168.5816 (168.0367)
2022-11-25 20:49:44,854:INFO: Dataset: univ                Batch: 14/15	Loss 167.3733 (167.9868)
2022-11-25 20:49:45,303:INFO: Dataset: univ                Batch: 15/15	Loss 31.4170 (166.1941)
2022-11-25 20:49:46,113:INFO: Dataset: zara1               Batch: 1/8	Loss 174.9670 (174.9670)
2022-11-25 20:49:46,618:INFO: Dataset: zara1               Batch: 2/8	Loss 175.1183 (175.0517)
2022-11-25 20:49:47,118:INFO: Dataset: zara1               Batch: 3/8	Loss 175.1814 (175.0943)
2022-11-25 20:49:47,615:INFO: Dataset: zara1               Batch: 4/8	Loss 176.3094 (175.3966)
2022-11-25 20:49:48,111:INFO: Dataset: zara1               Batch: 5/8	Loss 176.2802 (175.5611)
2022-11-25 20:49:48,608:INFO: Dataset: zara1               Batch: 6/8	Loss 176.6874 (175.7457)
2022-11-25 20:49:49,105:INFO: Dataset: zara1               Batch: 7/8	Loss 173.6912 (175.4585)
2022-11-25 20:49:49,588:INFO: Dataset: zara1               Batch: 8/8	Loss 151.5617 (173.1569)
2022-11-25 20:49:50,413:INFO: Dataset: zara2               Batch:  1/18	Loss 170.3490 (170.3490)
2022-11-25 20:49:50,922:INFO: Dataset: zara2               Batch:  2/18	Loss 169.8432 (170.0806)
2022-11-25 20:49:51,434:INFO: Dataset: zara2               Batch:  3/18	Loss 168.6872 (169.6161)
2022-11-25 20:49:51,939:INFO: Dataset: zara2               Batch:  4/18	Loss 170.1091 (169.7353)
2022-11-25 20:49:52,447:INFO: Dataset: zara2               Batch:  5/18	Loss 170.3352 (169.8633)
2022-11-25 20:49:52,954:INFO: Dataset: zara2               Batch:  6/18	Loss 169.4446 (169.7923)
2022-11-25 20:49:53,461:INFO: Dataset: zara2               Batch:  7/18	Loss 169.5602 (169.7610)
2022-11-25 20:49:53,968:INFO: Dataset: zara2               Batch:  8/18	Loss 170.0446 (169.7924)
2022-11-25 20:49:54,475:INFO: Dataset: zara2               Batch:  9/18	Loss 168.9836 (169.6968)
2022-11-25 20:49:54,981:INFO: Dataset: zara2               Batch: 10/18	Loss 168.6428 (169.5850)
2022-11-25 20:49:55,487:INFO: Dataset: zara2               Batch: 11/18	Loss 168.6793 (169.5092)
2022-11-25 20:49:55,994:INFO: Dataset: zara2               Batch: 12/18	Loss 168.8150 (169.4523)
2022-11-25 20:49:56,500:INFO: Dataset: zara2               Batch: 13/18	Loss 169.8237 (169.4798)
2022-11-25 20:49:57,006:INFO: Dataset: zara2               Batch: 14/18	Loss 169.2018 (169.4613)
2022-11-25 20:49:57,514:INFO: Dataset: zara2               Batch: 15/18	Loss 169.6222 (169.4726)
2022-11-25 20:49:58,020:INFO: Dataset: zara2               Batch: 16/18	Loss 168.8791 (169.4361)
2022-11-25 20:49:58,525:INFO: Dataset: zara2               Batch: 17/18	Loss 168.3415 (169.3654)
2022-11-25 20:49:59,023:INFO: Dataset: zara2               Batch: 18/18	Loss 145.1402 (168.1880)
2022-11-25 20:49:59,085:INFO: - Computing ADE (validation)
2022-11-25 20:49:59,450:INFO: 		 ADE on hotel                     dataset:	 2.94903302192688
2022-11-25 20:49:59,876:INFO: 		 ADE on univ                      dataset:	 3.59407114982605
2022-11-25 20:50:00,233:INFO: 		 ADE on zara1                     dataset:	 2.9670138359069824
2022-11-25 20:50:00,790:INFO: 		 ADE on zara2                     dataset:	 3.140839099884033
2022-11-25 20:50:00,790:INFO: Average validation:	ADE  3.3560	FDE  4.6749
2022-11-25 20:50:00,791:INFO: - Computing ADE (validation o)
2022-11-25 20:50:01,096:INFO: 		 ADE on eth                       dataset:	 2.996755599975586
2022-11-25 20:50:01,096:INFO: Average validation o:	ADE  2.9968	FDE  4.2281
2022-11-25 20:50:01,105:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_265.pth.tar
2022-11-25 20:50:01,105:INFO: 
===> EPOCH: 266 (P3)
2022-11-25 20:50:01,105:INFO: - Computing loss (training)
2022-11-25 20:50:01,824:INFO: Dataset: hotel               Batch: 1/4	Loss 192.8856 (192.8856)
2022-11-25 20:50:02,322:INFO: Dataset: hotel               Batch: 2/4	Loss 211.3773 (202.7479)
2022-11-25 20:50:02,815:INFO: Dataset: hotel               Batch: 3/4	Loss 192.5263 (199.3407)
2022-11-25 20:50:03,271:INFO: Dataset: hotel               Batch: 4/4	Loss 124.2229 (186.6559)
2022-11-25 20:50:04,103:INFO: Dataset: univ                Batch:  1/15	Loss 167.9535 (167.9535)
2022-11-25 20:50:04,658:INFO: Dataset: univ                Batch:  2/15	Loss 167.1627 (167.5361)
2022-11-25 20:50:05,199:INFO: Dataset: univ                Batch:  3/15	Loss 166.9663 (167.3586)
2022-11-25 20:50:05,744:INFO: Dataset: univ                Batch:  4/15	Loss 167.2488 (167.3326)
2022-11-25 20:50:06,288:INFO: Dataset: univ                Batch:  5/15	Loss 167.7136 (167.4078)
2022-11-25 20:50:06,831:INFO: Dataset: univ                Batch:  6/15	Loss 166.0575 (167.1779)
2022-11-25 20:50:07,370:INFO: Dataset: univ                Batch:  7/15	Loss 166.8880 (167.1377)
2022-11-25 20:50:07,903:INFO: Dataset: univ                Batch:  8/15	Loss 166.6606 (167.0822)
2022-11-25 20:50:08,444:INFO: Dataset: univ                Batch:  9/15	Loss 168.0552 (167.1896)
2022-11-25 20:50:08,982:INFO: Dataset: univ                Batch: 10/15	Loss 179.6391 (168.4629)
2022-11-25 20:50:09,529:INFO: Dataset: univ                Batch: 11/15	Loss 167.5400 (168.3774)
2022-11-25 20:50:10,073:INFO: Dataset: univ                Batch: 12/15	Loss 166.9684 (168.2543)
2022-11-25 20:50:10,612:INFO: Dataset: univ                Batch: 13/15	Loss 167.1820 (168.1736)
2022-11-25 20:50:11,151:INFO: Dataset: univ                Batch: 14/15	Loss 167.4395 (168.1224)
2022-11-25 20:50:11,581:INFO: Dataset: univ                Batch: 15/15	Loss 31.3053 (166.5793)
2022-11-25 20:50:12,399:INFO: Dataset: zara1               Batch: 1/8	Loss 174.1530 (174.1530)
2022-11-25 20:50:12,893:INFO: Dataset: zara1               Batch: 2/8	Loss 174.6869 (174.3948)
2022-11-25 20:50:13,387:INFO: Dataset: zara1               Batch: 3/8	Loss 175.9263 (174.8766)
2022-11-25 20:50:13,891:INFO: Dataset: zara1               Batch: 4/8	Loss 175.4203 (175.0184)
2022-11-25 20:50:14,396:INFO: Dataset: zara1               Batch: 5/8	Loss 173.5444 (174.7106)
2022-11-25 20:50:14,893:INFO: Dataset: zara1               Batch: 6/8	Loss 173.2500 (174.4803)
2022-11-25 20:50:15,387:INFO: Dataset: zara1               Batch: 7/8	Loss 173.5164 (174.3520)
2022-11-25 20:50:15,954:INFO: Dataset: zara1               Batch: 8/8	Loss 150.5859 (171.9129)
2022-11-25 20:50:16,766:INFO: Dataset: zara2               Batch:  1/18	Loss 168.2961 (168.2961)
2022-11-25 20:50:17,281:INFO: Dataset: zara2               Batch:  2/18	Loss 167.8995 (168.1062)
2022-11-25 20:50:17,802:INFO: Dataset: zara2               Batch:  3/18	Loss 167.6743 (167.9667)
2022-11-25 20:50:18,317:INFO: Dataset: zara2               Batch:  4/18	Loss 168.4110 (168.0754)
2022-11-25 20:50:18,834:INFO: Dataset: zara2               Batch:  5/18	Loss 170.4286 (168.5556)
2022-11-25 20:50:19,351:INFO: Dataset: zara2               Batch:  6/18	Loss 169.4345 (168.7008)
2022-11-25 20:50:19,866:INFO: Dataset: zara2               Batch:  7/18	Loss 167.4202 (168.5096)
2022-11-25 20:50:20,381:INFO: Dataset: zara2               Batch:  8/18	Loss 167.4970 (168.3811)
2022-11-25 20:50:20,894:INFO: Dataset: zara2               Batch:  9/18	Loss 168.8732 (168.4344)
2022-11-25 20:50:21,408:INFO: Dataset: zara2               Batch: 10/18	Loss 168.0231 (168.3905)
2022-11-25 20:50:21,920:INFO: Dataset: zara2               Batch: 11/18	Loss 170.5927 (168.6036)
2022-11-25 20:50:22,437:INFO: Dataset: zara2               Batch: 12/18	Loss 169.4877 (168.6784)
2022-11-25 20:50:22,950:INFO: Dataset: zara2               Batch: 13/18	Loss 168.0207 (168.6257)
2022-11-25 20:50:23,466:INFO: Dataset: zara2               Batch: 14/18	Loss 168.3116 (168.6024)
2022-11-25 20:50:23,977:INFO: Dataset: zara2               Batch: 15/18	Loss 170.9737 (168.7854)
2022-11-25 20:50:24,493:INFO: Dataset: zara2               Batch: 16/18	Loss 168.1794 (168.7472)
2022-11-25 20:50:25,009:INFO: Dataset: zara2               Batch: 17/18	Loss 168.8599 (168.7539)
2022-11-25 20:50:25,513:INFO: Dataset: zara2               Batch: 18/18	Loss 143.8368 (167.4687)
2022-11-25 20:50:25,577:INFO: - Computing ADE (validation)
2022-11-25 20:50:25,960:INFO: 		 ADE on hotel                     dataset:	 2.9980220794677734
2022-11-25 20:50:26,396:INFO: 		 ADE on univ                      dataset:	 3.6014974117279053
2022-11-25 20:50:26,756:INFO: 		 ADE on zara1                     dataset:	 3.0086066722869873
2022-11-25 20:50:27,316:INFO: 		 ADE on zara2                     dataset:	 3.1596696376800537
2022-11-25 20:50:27,317:INFO: Average validation:	ADE  3.3719	FDE  4.6879
2022-11-25 20:50:27,317:INFO: - Computing ADE (validation o)
2022-11-25 20:50:27,624:INFO: 		 ADE on eth                       dataset:	 3.313755989074707
2022-11-25 20:50:27,624:INFO: Average validation o:	ADE  3.3138	FDE  4.2962
2022-11-25 20:50:27,633:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_266.pth.tar
2022-11-25 20:50:27,633:INFO: 
===> EPOCH: 267 (P3)
2022-11-25 20:50:27,634:INFO: - Computing loss (training)
2022-11-25 20:50:28,357:INFO: Dataset: hotel               Batch: 1/4	Loss 221.3166 (221.3166)
2022-11-25 20:50:28,863:INFO: Dataset: hotel               Batch: 2/4	Loss 197.7456 (208.9941)
2022-11-25 20:50:29,361:INFO: Dataset: hotel               Batch: 3/4	Loss 201.3786 (206.4434)
2022-11-25 20:50:29,825:INFO: Dataset: hotel               Batch: 4/4	Loss 115.7476 (190.7691)
2022-11-25 20:50:30,667:INFO: Dataset: univ                Batch:  1/15	Loss 165.2578 (165.2578)
2022-11-25 20:50:31,205:INFO: Dataset: univ                Batch:  2/15	Loss 165.5386 (165.4025)
2022-11-25 20:50:31,762:INFO: Dataset: univ                Batch:  3/15	Loss 167.1676 (166.0431)
2022-11-25 20:50:32,309:INFO: Dataset: univ                Batch:  4/15	Loss 166.7589 (166.2306)
2022-11-25 20:50:32,841:INFO: Dataset: univ                Batch:  5/15	Loss 167.6364 (166.4902)
2022-11-25 20:50:33,373:INFO: Dataset: univ                Batch:  6/15	Loss 170.2331 (167.0465)
2022-11-25 20:50:33,915:INFO: Dataset: univ                Batch:  7/15	Loss 166.9753 (167.0357)
2022-11-25 20:50:34,455:INFO: Dataset: univ                Batch:  8/15	Loss 166.0135 (166.9022)
2022-11-25 20:50:34,999:INFO: Dataset: univ                Batch:  9/15	Loss 167.0368 (166.9180)
2022-11-25 20:50:35,536:INFO: Dataset: univ                Batch: 10/15	Loss 166.1927 (166.8513)
2022-11-25 20:50:36,072:INFO: Dataset: univ                Batch: 11/15	Loss 167.3820 (166.8976)
2022-11-25 20:50:36,618:INFO: Dataset: univ                Batch: 12/15	Loss 165.3801 (166.7622)
2022-11-25 20:50:37,152:INFO: Dataset: univ                Batch: 13/15	Loss 165.3954 (166.6605)
2022-11-25 20:50:37,700:INFO: Dataset: univ                Batch: 14/15	Loss 166.0994 (166.6164)
2022-11-25 20:50:38,136:INFO: Dataset: univ                Batch: 15/15	Loss 31.1656 (164.5687)
2022-11-25 20:50:38,940:INFO: Dataset: zara1               Batch: 1/8	Loss 174.1609 (174.1609)
2022-11-25 20:50:39,442:INFO: Dataset: zara1               Batch: 2/8	Loss 172.9453 (173.5678)
2022-11-25 20:50:39,938:INFO: Dataset: zara1               Batch: 3/8	Loss 174.4412 (173.8319)
2022-11-25 20:50:40,436:INFO: Dataset: zara1               Batch: 4/8	Loss 175.5708 (174.2883)
2022-11-25 20:50:40,944:INFO: Dataset: zara1               Batch: 5/8	Loss 172.5602 (173.9234)
2022-11-25 20:50:41,441:INFO: Dataset: zara1               Batch: 6/8	Loss 174.8478 (174.0709)
2022-11-25 20:50:41,939:INFO: Dataset: zara1               Batch: 7/8	Loss 173.3659 (173.9746)
2022-11-25 20:50:42,423:INFO: Dataset: zara1               Batch: 8/8	Loss 153.6170 (171.6603)
2022-11-25 20:50:43,250:INFO: Dataset: zara2               Batch:  1/18	Loss 166.5061 (166.5061)
2022-11-25 20:50:43,759:INFO: Dataset: zara2               Batch:  2/18	Loss 167.2488 (166.8982)
2022-11-25 20:50:44,266:INFO: Dataset: zara2               Batch:  3/18	Loss 167.4204 (167.0868)
2022-11-25 20:50:44,773:INFO: Dataset: zara2               Batch:  4/18	Loss 167.4521 (167.1729)
2022-11-25 20:50:45,284:INFO: Dataset: zara2               Batch:  5/18	Loss 167.3250 (167.2021)
2022-11-25 20:50:45,876:INFO: Dataset: zara2               Batch:  6/18	Loss 167.0250 (167.1705)
2022-11-25 20:50:46,380:INFO: Dataset: zara2               Batch:  7/18	Loss 166.9527 (167.1389)
2022-11-25 20:50:46,893:INFO: Dataset: zara2               Batch:  8/18	Loss 167.2830 (167.1579)
2022-11-25 20:50:47,414:INFO: Dataset: zara2               Batch:  9/18	Loss 168.7642 (167.3175)
2022-11-25 20:50:47,937:INFO: Dataset: zara2               Batch: 10/18	Loss 166.7125 (167.2607)
2022-11-25 20:50:48,460:INFO: Dataset: zara2               Batch: 11/18	Loss 169.2535 (167.4317)
2022-11-25 20:50:48,987:INFO: Dataset: zara2               Batch: 12/18	Loss 167.4069 (167.4297)
2022-11-25 20:50:49,574:INFO: Dataset: zara2               Batch: 13/18	Loss 166.9868 (167.3978)
2022-11-25 20:50:50,364:INFO: Dataset: zara2               Batch: 14/18	Loss 166.9122 (167.3615)
2022-11-25 20:50:50,975:INFO: Dataset: zara2               Batch: 15/18	Loss 166.1824 (167.2782)
2022-11-25 20:50:51,576:INFO: Dataset: zara2               Batch: 16/18	Loss 167.1168 (167.2671)
2022-11-25 20:50:52,149:INFO: Dataset: zara2               Batch: 17/18	Loss 165.9456 (167.1861)
2022-11-25 20:50:52,710:INFO: Dataset: zara2               Batch: 18/18	Loss 144.2147 (166.1341)
2022-11-25 20:50:52,771:INFO: - Computing ADE (validation)
2022-11-25 20:50:53,153:INFO: 		 ADE on hotel                     dataset:	 2.8710784912109375
2022-11-25 20:50:53,590:INFO: 		 ADE on univ                      dataset:	 3.565603017807007
2022-11-25 20:50:53,972:INFO: 		 ADE on zara1                     dataset:	 2.9994866847991943
2022-11-25 20:50:54,533:INFO: 		 ADE on zara2                     dataset:	 3.1757452487945557
2022-11-25 20:50:54,533:INFO: Average validation:	ADE  3.3516	FDE  4.6282
2022-11-25 20:50:54,534:INFO: - Computing ADE (validation o)
2022-11-25 20:50:54,846:INFO: 		 ADE on eth                       dataset:	 3.0443363189697266
2022-11-25 20:50:54,846:INFO: Average validation o:	ADE  3.0443	FDE  4.2454
2022-11-25 20:50:54,855:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_267.pth.tar
2022-11-25 20:50:54,855:INFO: 
===> EPOCH: 268 (P3)
2022-11-25 20:50:54,856:INFO: - Computing loss (training)
2022-11-25 20:50:55,620:INFO: Dataset: hotel               Batch: 1/4	Loss 194.8307 (194.8307)
2022-11-25 20:50:56,139:INFO: Dataset: hotel               Batch: 2/4	Loss 191.1557 (193.0191)
2022-11-25 20:50:56,674:INFO: Dataset: hotel               Batch: 3/4	Loss 192.3248 (192.7973)
2022-11-25 20:50:57,160:INFO: Dataset: hotel               Batch: 4/4	Loss 112.7017 (178.8492)
2022-11-25 20:50:58,067:INFO: Dataset: univ                Batch:  1/15	Loss 165.3629 (165.3629)
2022-11-25 20:50:58,645:INFO: Dataset: univ                Batch:  2/15	Loss 165.2588 (165.3113)
2022-11-25 20:50:59,386:INFO: Dataset: univ                Batch:  3/15	Loss 163.9413 (164.8236)
2022-11-25 20:50:59,980:INFO: Dataset: univ                Batch:  4/15	Loss 166.4895 (165.2792)
2022-11-25 20:51:00,538:INFO: Dataset: univ                Batch:  5/15	Loss 178.7156 (167.8859)
2022-11-25 20:51:01,104:INFO: Dataset: univ                Batch:  6/15	Loss 167.5450 (167.8297)
2022-11-25 20:51:01,654:INFO: Dataset: univ                Batch:  7/15	Loss 164.6641 (167.3767)
2022-11-25 20:51:02,204:INFO: Dataset: univ                Batch:  8/15	Loss 165.7677 (167.1792)
2022-11-25 20:51:02,749:INFO: Dataset: univ                Batch:  9/15	Loss 167.2948 (167.1916)
2022-11-25 20:51:03,298:INFO: Dataset: univ                Batch: 10/15	Loss 165.2172 (166.9839)
2022-11-25 20:51:03,842:INFO: Dataset: univ                Batch: 11/15	Loss 165.0248 (166.8025)
2022-11-25 20:51:04,376:INFO: Dataset: univ                Batch: 12/15	Loss 165.7265 (166.7221)
2022-11-25 20:51:04,904:INFO: Dataset: univ                Batch: 13/15	Loss 172.6793 (167.1101)
2022-11-25 20:51:05,459:INFO: Dataset: univ                Batch: 14/15	Loss 163.9742 (166.8591)
2022-11-25 20:51:05,900:INFO: Dataset: univ                Batch: 15/15	Loss 30.9323 (165.0942)
2022-11-25 20:51:06,714:INFO: Dataset: zara1               Batch: 1/8	Loss 175.8705 (175.8705)
2022-11-25 20:51:07,210:INFO: Dataset: zara1               Batch: 2/8	Loss 173.2365 (174.6027)
2022-11-25 20:51:07,708:INFO: Dataset: zara1               Batch: 3/8	Loss 172.7216 (173.9711)
2022-11-25 20:51:08,206:INFO: Dataset: zara1               Batch: 4/8	Loss 172.3257 (173.5337)
2022-11-25 20:51:08,702:INFO: Dataset: zara1               Batch: 5/8	Loss 173.2278 (173.4771)
2022-11-25 20:51:09,212:INFO: Dataset: zara1               Batch: 6/8	Loss 174.1978 (173.6100)
2022-11-25 20:51:09,719:INFO: Dataset: zara1               Batch: 7/8	Loss 172.9240 (173.5035)
2022-11-25 20:51:10,200:INFO: Dataset: zara1               Batch: 8/8	Loss 148.7722 (170.4056)
2022-11-25 20:51:11,002:INFO: Dataset: zara2               Batch:  1/18	Loss 168.3535 (168.3535)
2022-11-25 20:51:11,511:INFO: Dataset: zara2               Batch:  2/18	Loss 165.9796 (167.1878)
2022-11-25 20:51:12,021:INFO: Dataset: zara2               Batch:  3/18	Loss 166.4181 (166.9427)
2022-11-25 20:51:12,546:INFO: Dataset: zara2               Batch:  4/18	Loss 168.2357 (167.3011)
2022-11-25 20:51:13,053:INFO: Dataset: zara2               Batch:  5/18	Loss 165.3905 (166.9418)
2022-11-25 20:51:13,561:INFO: Dataset: zara2               Batch:  6/18	Loss 166.0178 (166.7855)
2022-11-25 20:51:14,069:INFO: Dataset: zara2               Batch:  7/18	Loss 168.1563 (166.9692)
2022-11-25 20:51:14,575:INFO: Dataset: zara2               Batch:  8/18	Loss 166.3704 (166.8854)
2022-11-25 20:51:15,080:INFO: Dataset: zara2               Batch:  9/18	Loss 166.2887 (166.8135)
2022-11-25 20:51:15,586:INFO: Dataset: zara2               Batch: 10/18	Loss 165.5840 (166.6902)
2022-11-25 20:51:16,096:INFO: Dataset: zara2               Batch: 11/18	Loss 168.6750 (166.8900)
2022-11-25 20:51:16,607:INFO: Dataset: zara2               Batch: 12/18	Loss 166.7949 (166.8823)
2022-11-25 20:51:17,122:INFO: Dataset: zara2               Batch: 13/18	Loss 165.8322 (166.7955)
2022-11-25 20:51:17,641:INFO: Dataset: zara2               Batch: 14/18	Loss 165.6182 (166.7147)
2022-11-25 20:51:18,250:INFO: Dataset: zara2               Batch: 15/18	Loss 166.6201 (166.7090)
2022-11-25 20:51:18,775:INFO: Dataset: zara2               Batch: 16/18	Loss 166.4822 (166.6957)
2022-11-25 20:51:19,305:INFO: Dataset: zara2               Batch: 17/18	Loss 166.8857 (166.7051)
2022-11-25 20:51:19,862:INFO: Dataset: zara2               Batch: 18/18	Loss 141.7326 (165.5244)
2022-11-25 20:51:19,941:INFO: - Computing ADE (validation)
2022-11-25 20:51:20,359:INFO: 		 ADE on hotel                     dataset:	 2.898843288421631
2022-11-25 20:51:20,882:INFO: 		 ADE on univ                      dataset:	 3.6163430213928223
2022-11-25 20:51:21,280:INFO: 		 ADE on zara1                     dataset:	 2.9993908405303955
2022-11-25 20:51:21,837:INFO: 		 ADE on zara2                     dataset:	 3.1374564170837402
2022-11-25 20:51:21,837:INFO: Average validation:	ADE  3.3655	FDE  4.6838
2022-11-25 20:51:21,838:INFO: - Computing ADE (validation o)
2022-11-25 20:51:22,146:INFO: 		 ADE on eth                       dataset:	 3.0859882831573486
2022-11-25 20:51:22,146:INFO: Average validation o:	ADE  3.0860	FDE  4.3304
2022-11-25 20:51:22,156:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_268.pth.tar
2022-11-25 20:51:22,156:INFO: 
===> EPOCH: 269 (P3)
2022-11-25 20:51:22,156:INFO: - Computing loss (training)
2022-11-25 20:51:22,896:INFO: Dataset: hotel               Batch: 1/4	Loss 197.4545 (197.4545)
2022-11-25 20:51:23,418:INFO: Dataset: hotel               Batch: 2/4	Loss 181.7513 (189.4284)
2022-11-25 20:51:23,912:INFO: Dataset: hotel               Batch: 3/4	Loss 192.7159 (190.5615)
2022-11-25 20:51:24,376:INFO: Dataset: hotel               Batch: 4/4	Loss 113.7077 (176.3669)
2022-11-25 20:51:25,238:INFO: Dataset: univ                Batch:  1/15	Loss 164.7604 (164.7604)
2022-11-25 20:51:25,791:INFO: Dataset: univ                Batch:  2/15	Loss 164.8694 (164.8155)
2022-11-25 20:51:26,368:INFO: Dataset: univ                Batch:  3/15	Loss 163.9367 (164.5308)
2022-11-25 20:51:26,937:INFO: Dataset: univ                Batch:  4/15	Loss 164.1405 (164.4260)
2022-11-25 20:51:27,522:INFO: Dataset: univ                Batch:  5/15	Loss 163.6264 (164.2485)
2022-11-25 20:51:28,094:INFO: Dataset: univ                Batch:  6/15	Loss 164.6815 (164.3220)
2022-11-25 20:51:28,661:INFO: Dataset: univ                Batch:  7/15	Loss 163.6859 (164.2224)
2022-11-25 20:51:29,252:INFO: Dataset: univ                Batch:  8/15	Loss 164.8072 (164.2961)
2022-11-25 20:51:29,861:INFO: Dataset: univ                Batch:  9/15	Loss 164.2088 (164.2869)
2022-11-25 20:51:30,437:INFO: Dataset: univ                Batch: 10/15	Loss 164.3083 (164.2892)
2022-11-25 20:51:31,000:INFO: Dataset: univ                Batch: 11/15	Loss 168.5983 (164.6979)
2022-11-25 20:51:31,565:INFO: Dataset: univ                Batch: 12/15	Loss 164.5450 (164.6849)
2022-11-25 20:51:32,142:INFO: Dataset: univ                Batch: 13/15	Loss 165.9949 (164.7994)
2022-11-25 20:51:32,700:INFO: Dataset: univ                Batch: 14/15	Loss 165.5111 (164.8462)
2022-11-25 20:51:33,166:INFO: Dataset: univ                Batch: 15/15	Loss 30.5110 (163.0764)
2022-11-25 20:51:34,052:INFO: Dataset: zara1               Batch: 1/8	Loss 170.8291 (170.8291)
2022-11-25 20:51:34,594:INFO: Dataset: zara1               Batch: 2/8	Loss 172.1304 (171.5325)
2022-11-25 20:51:35,185:INFO: Dataset: zara1               Batch: 3/8	Loss 172.1946 (171.7794)
2022-11-25 20:51:35,800:INFO: Dataset: zara1               Batch: 4/8	Loss 172.1770 (171.8823)
2022-11-25 20:51:36,361:INFO: Dataset: zara1               Batch: 5/8	Loss 170.8537 (171.6689)
2022-11-25 20:51:36,922:INFO: Dataset: zara1               Batch: 6/8	Loss 172.3638 (171.7883)
2022-11-25 20:51:37,441:INFO: Dataset: zara1               Batch: 7/8	Loss 170.8221 (171.6466)
2022-11-25 20:51:37,989:INFO: Dataset: zara1               Batch: 8/8	Loss 147.0401 (169.1212)
2022-11-25 20:51:38,867:INFO: Dataset: zara2               Batch:  1/18	Loss 166.9660 (166.9660)
2022-11-25 20:51:39,553:INFO: Dataset: zara2               Batch:  2/18	Loss 165.9157 (166.4284)
2022-11-25 20:51:40,380:INFO: Dataset: zara2               Batch:  3/18	Loss 165.6541 (166.1545)
2022-11-25 20:51:40,905:INFO: Dataset: zara2               Batch:  4/18	Loss 164.2668 (165.7070)
2022-11-25 20:51:41,419:INFO: Dataset: zara2               Batch:  5/18	Loss 164.9506 (165.5515)
2022-11-25 20:51:41,946:INFO: Dataset: zara2               Batch:  6/18	Loss 166.2463 (165.6572)
2022-11-25 20:51:42,460:INFO: Dataset: zara2               Batch:  7/18	Loss 164.6629 (165.5211)
2022-11-25 20:51:43,002:INFO: Dataset: zara2               Batch:  8/18	Loss 164.6635 (165.4035)
2022-11-25 20:51:43,530:INFO: Dataset: zara2               Batch:  9/18	Loss 165.7796 (165.4417)
2022-11-25 20:51:44,067:INFO: Dataset: zara2               Batch: 10/18	Loss 164.8286 (165.3825)
2022-11-25 20:51:44,689:INFO: Dataset: zara2               Batch: 11/18	Loss 167.7469 (165.6062)
2022-11-25 20:51:45,360:INFO: Dataset: zara2               Batch: 12/18	Loss 164.3522 (165.5185)
2022-11-25 20:51:45,904:INFO: Dataset: zara2               Batch: 13/18	Loss 164.9497 (165.4719)
2022-11-25 20:51:46,487:INFO: Dataset: zara2               Batch: 14/18	Loss 167.8739 (165.6599)
2022-11-25 20:51:47,033:INFO: Dataset: zara2               Batch: 15/18	Loss 166.0719 (165.6881)
2022-11-25 20:51:47,568:INFO: Dataset: zara2               Batch: 16/18	Loss 167.7949 (165.8163)
2022-11-25 20:51:48,128:INFO: Dataset: zara2               Batch: 17/18	Loss 165.2234 (165.7827)
2022-11-25 20:51:48,663:INFO: Dataset: zara2               Batch: 18/18	Loss 140.4171 (164.4366)
2022-11-25 20:51:48,724:INFO: - Computing ADE (validation)
2022-11-25 20:51:49,145:INFO: 		 ADE on hotel                     dataset:	 2.9355101585388184
2022-11-25 20:51:49,638:INFO: 		 ADE on univ                      dataset:	 3.6136698722839355
2022-11-25 20:51:49,999:INFO: 		 ADE on zara1                     dataset:	 3.0034573078155518
2022-11-25 20:51:50,548:INFO: 		 ADE on zara2                     dataset:	 3.1250417232513428
2022-11-25 20:51:50,549:INFO: Average validation:	ADE  3.3618	FDE  4.7268
2022-11-25 20:51:50,549:INFO: - Computing ADE (validation o)
2022-11-25 20:51:50,868:INFO: 		 ADE on eth                       dataset:	 3.0026092529296875
2022-11-25 20:51:50,869:INFO: Average validation o:	ADE  3.0026	FDE  3.9579
2022-11-25 20:51:50,879:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_269.pth.tar
2022-11-25 20:51:50,879:INFO: 
===> EPOCH: 270 (P3)
2022-11-25 20:51:50,880:INFO: - Computing loss (training)
2022-11-25 20:51:51,712:INFO: Dataset: hotel               Batch: 1/4	Loss 187.9844 (187.9844)
2022-11-25 20:51:52,256:INFO: Dataset: hotel               Batch: 2/4	Loss 194.1608 (191.1541)
2022-11-25 20:51:52,792:INFO: Dataset: hotel               Batch: 3/4	Loss 181.2171 (187.8790)
2022-11-25 20:51:53,252:INFO: Dataset: hotel               Batch: 4/4	Loss 113.8983 (174.6054)
2022-11-25 20:51:54,226:INFO: Dataset: univ                Batch:  1/15	Loss 164.7048 (164.7048)
2022-11-25 20:51:54,814:INFO: Dataset: univ                Batch:  2/15	Loss 165.0943 (164.8995)
2022-11-25 20:51:55,580:INFO: Dataset: univ                Batch:  3/15	Loss 163.4730 (164.4266)
2022-11-25 20:51:56,276:INFO: Dataset: univ                Batch:  4/15	Loss 164.9470 (164.5536)
2022-11-25 20:51:56,820:INFO: Dataset: univ                Batch:  5/15	Loss 163.8440 (164.4175)
2022-11-25 20:51:57,372:INFO: Dataset: univ                Batch:  6/15	Loss 164.3271 (164.4017)
2022-11-25 20:51:57,917:INFO: Dataset: univ                Batch:  7/15	Loss 164.5601 (164.4239)
2022-11-25 20:51:58,471:INFO: Dataset: univ                Batch:  8/15	Loss 163.6597 (164.3199)
2022-11-25 20:51:59,022:INFO: Dataset: univ                Batch:  9/15	Loss 167.8533 (164.6659)
2022-11-25 20:51:59,582:INFO: Dataset: univ                Batch: 10/15	Loss 165.4241 (164.7352)
2022-11-25 20:52:00,236:INFO: Dataset: univ                Batch: 11/15	Loss 163.4171 (164.6146)
2022-11-25 20:52:00,810:INFO: Dataset: univ                Batch: 12/15	Loss 163.9342 (164.5542)
2022-11-25 20:52:01,360:INFO: Dataset: univ                Batch: 13/15	Loss 166.6136 (164.7040)
2022-11-25 20:52:01,903:INFO: Dataset: univ                Batch: 14/15	Loss 163.4081 (164.6112)
2022-11-25 20:52:02,367:INFO: Dataset: univ                Batch: 15/15	Loss 30.4720 (162.8885)
2022-11-25 20:52:03,277:INFO: Dataset: zara1               Batch: 1/8	Loss 171.6480 (171.6480)
2022-11-25 20:52:03,834:INFO: Dataset: zara1               Batch: 2/8	Loss 170.4453 (171.0728)
2022-11-25 20:52:04,377:INFO: Dataset: zara1               Batch: 3/8	Loss 169.8917 (170.6731)
2022-11-25 20:52:04,904:INFO: Dataset: zara1               Batch: 4/8	Loss 169.4012 (170.3316)
2022-11-25 20:52:05,433:INFO: Dataset: zara1               Batch: 5/8	Loss 170.3177 (170.3292)
2022-11-25 20:52:05,946:INFO: Dataset: zara1               Batch: 6/8	Loss 172.6326 (170.7302)
2022-11-25 20:52:06,500:INFO: Dataset: zara1               Batch: 7/8	Loss 170.4690 (170.6949)
2022-11-25 20:52:07,038:INFO: Dataset: zara1               Batch: 8/8	Loss 146.7180 (168.0070)
2022-11-25 20:52:07,863:INFO: Dataset: zara2               Batch:  1/18	Loss 166.4287 (166.4287)
2022-11-25 20:52:08,395:INFO: Dataset: zara2               Batch:  2/18	Loss 164.9217 (165.5812)
2022-11-25 20:52:08,918:INFO: Dataset: zara2               Batch:  3/18	Loss 168.4221 (166.5689)
2022-11-25 20:52:09,437:INFO: Dataset: zara2               Batch:  4/18	Loss 164.8849 (166.1692)
2022-11-25 20:52:09,963:INFO: Dataset: zara2               Batch:  5/18	Loss 163.0223 (165.5851)
2022-11-25 20:52:10,499:INFO: Dataset: zara2               Batch:  6/18	Loss 165.1971 (165.5230)
2022-11-25 20:52:11,018:INFO: Dataset: zara2               Batch:  7/18	Loss 164.5030 (165.3712)
2022-11-25 20:52:11,533:INFO: Dataset: zara2               Batch:  8/18	Loss 163.4346 (165.1290)
2022-11-25 20:52:12,044:INFO: Dataset: zara2               Batch:  9/18	Loss 163.6207 (164.9570)
2022-11-25 20:52:12,558:INFO: Dataset: zara2               Batch: 10/18	Loss 164.1027 (164.8713)
2022-11-25 20:52:13,068:INFO: Dataset: zara2               Batch: 11/18	Loss 163.6363 (164.7627)
2022-11-25 20:52:13,580:INFO: Dataset: zara2               Batch: 12/18	Loss 164.8467 (164.7694)
2022-11-25 20:52:14,092:INFO: Dataset: zara2               Batch: 13/18	Loss 166.1406 (164.8665)
2022-11-25 20:52:14,602:INFO: Dataset: zara2               Batch: 14/18	Loss 164.5415 (164.8396)
2022-11-25 20:52:15,115:INFO: Dataset: zara2               Batch: 15/18	Loss 165.5838 (164.8899)
2022-11-25 20:52:15,628:INFO: Dataset: zara2               Batch: 16/18	Loss 164.7692 (164.8820)
2022-11-25 20:52:16,138:INFO: Dataset: zara2               Batch: 17/18	Loss 164.9299 (164.8850)
2022-11-25 20:52:16,636:INFO: Dataset: zara2               Batch: 18/18	Loss 140.8540 (163.7607)
2022-11-25 20:52:16,699:INFO: - Computing ADE (validation)
2022-11-25 20:52:17,067:INFO: 		 ADE on hotel                     dataset:	 2.856179714202881
2022-11-25 20:52:17,511:INFO: 		 ADE on univ                      dataset:	 3.578277587890625
2022-11-25 20:52:17,875:INFO: 		 ADE on zara1                     dataset:	 2.930577039718628
2022-11-25 20:52:18,442:INFO: 		 ADE on zara2                     dataset:	 3.1439049243927
2022-11-25 20:52:18,443:INFO: Average validation:	ADE  3.3417	FDE  4.6834
2022-11-25 20:52:18,443:INFO: - Computing ADE (validation o)
2022-11-25 20:52:18,749:INFO: 		 ADE on eth                       dataset:	 3.0869839191436768
2022-11-25 20:52:18,749:INFO: Average validation o:	ADE  3.0870	FDE  4.4374
2022-11-25 20:52:18,758:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_270.pth.tar
2022-11-25 20:52:18,758:INFO: 
===> EPOCH: 271 (P3)
2022-11-25 20:52:18,759:INFO: - Computing loss (training)
2022-11-25 20:52:19,496:INFO: Dataset: hotel               Batch: 1/4	Loss 179.3206 (179.3206)
2022-11-25 20:52:19,998:INFO: Dataset: hotel               Batch: 2/4	Loss 193.0802 (186.4822)
2022-11-25 20:52:20,495:INFO: Dataset: hotel               Batch: 3/4	Loss 191.9283 (188.2888)
2022-11-25 20:52:20,952:INFO: Dataset: hotel               Batch: 4/4	Loss 113.9918 (174.8605)
2022-11-25 20:52:21,802:INFO: Dataset: univ                Batch:  1/15	Loss 162.5761 (162.5761)
2022-11-25 20:52:22,345:INFO: Dataset: univ                Batch:  2/15	Loss 163.0267 (162.8001)
2022-11-25 20:52:22,901:INFO: Dataset: univ                Batch:  3/15	Loss 162.8855 (162.8303)
2022-11-25 20:52:23,453:INFO: Dataset: univ                Batch:  4/15	Loss 162.6352 (162.7832)
2022-11-25 20:52:23,996:INFO: Dataset: univ                Batch:  5/15	Loss 163.1152 (162.8473)
2022-11-25 20:52:24,539:INFO: Dataset: univ                Batch:  6/15	Loss 162.9357 (162.8614)
2022-11-25 20:52:25,078:INFO: Dataset: univ                Batch:  7/15	Loss 161.9559 (162.7314)
2022-11-25 20:52:25,610:INFO: Dataset: univ                Batch:  8/15	Loss 162.3694 (162.6928)
2022-11-25 20:52:26,162:INFO: Dataset: univ                Batch:  9/15	Loss 163.9409 (162.8468)
2022-11-25 20:52:26,700:INFO: Dataset: univ                Batch: 10/15	Loss 162.8572 (162.8478)
2022-11-25 20:52:27,248:INFO: Dataset: univ                Batch: 11/15	Loss 163.3530 (162.8947)
2022-11-25 20:52:27,876:INFO: Dataset: univ                Batch: 12/15	Loss 163.0504 (162.9067)
2022-11-25 20:52:28,426:INFO: Dataset: univ                Batch: 13/15	Loss 221.5416 (167.4832)
2022-11-25 20:52:28,970:INFO: Dataset: univ                Batch: 14/15	Loss 166.2715 (167.3980)
2022-11-25 20:52:29,419:INFO: Dataset: univ                Batch: 15/15	Loss 30.5505 (165.5951)
2022-11-25 20:52:30,238:INFO: Dataset: zara1               Batch: 1/8	Loss 171.0354 (171.0354)
2022-11-25 20:52:30,759:INFO: Dataset: zara1               Batch: 2/8	Loss 173.0273 (172.0747)
2022-11-25 20:52:31,272:INFO: Dataset: zara1               Batch: 3/8	Loss 170.5013 (171.5105)
2022-11-25 20:52:31,775:INFO: Dataset: zara1               Batch: 4/8	Loss 171.6743 (171.5470)
2022-11-25 20:52:32,275:INFO: Dataset: zara1               Batch: 5/8	Loss 171.0728 (171.4504)
2022-11-25 20:52:32,819:INFO: Dataset: zara1               Batch: 6/8	Loss 171.6455 (171.4826)
2022-11-25 20:52:33,402:INFO: Dataset: zara1               Batch: 7/8	Loss 173.1901 (171.7038)
2022-11-25 20:52:33,908:INFO: Dataset: zara1               Batch: 8/8	Loss 147.1711 (168.7987)
2022-11-25 20:52:34,789:INFO: Dataset: zara2               Batch:  1/18	Loss 165.4404 (165.4404)
2022-11-25 20:52:35,321:INFO: Dataset: zara2               Batch:  2/18	Loss 170.4717 (167.9289)
2022-11-25 20:52:35,857:INFO: Dataset: zara2               Batch:  3/18	Loss 166.8283 (167.5556)
2022-11-25 20:52:36,428:INFO: Dataset: zara2               Batch:  4/18	Loss 165.9370 (167.1513)
2022-11-25 20:52:36,972:INFO: Dataset: zara2               Batch:  5/18	Loss 164.3356 (166.5830)
2022-11-25 20:52:37,538:INFO: Dataset: zara2               Batch:  6/18	Loss 165.4685 (166.3982)
2022-11-25 20:52:38,058:INFO: Dataset: zara2               Batch:  7/18	Loss 165.6140 (166.2869)
2022-11-25 20:52:38,588:INFO: Dataset: zara2               Batch:  8/18	Loss 164.9044 (166.0893)
2022-11-25 20:52:39,116:INFO: Dataset: zara2               Batch:  9/18	Loss 165.6535 (166.0420)
2022-11-25 20:52:39,684:INFO: Dataset: zara2               Batch: 10/18	Loss 166.1264 (166.0516)
2022-11-25 20:52:40,337:INFO: Dataset: zara2               Batch: 11/18	Loss 165.1631 (165.9673)
2022-11-25 20:52:40,878:INFO: Dataset: zara2               Batch: 12/18	Loss 164.9102 (165.8839)
2022-11-25 20:52:41,459:INFO: Dataset: zara2               Batch: 13/18	Loss 164.2633 (165.7568)
2022-11-25 20:52:42,033:INFO: Dataset: zara2               Batch: 14/18	Loss 165.2909 (165.7202)
2022-11-25 20:52:42,596:INFO: Dataset: zara2               Batch: 15/18	Loss 166.4713 (165.7699)
2022-11-25 20:52:43,160:INFO: Dataset: zara2               Batch: 16/18	Loss 164.3569 (165.6859)
2022-11-25 20:52:43,702:INFO: Dataset: zara2               Batch: 17/18	Loss 162.9356 (165.5213)
2022-11-25 20:52:44,242:INFO: Dataset: zara2               Batch: 18/18	Loss 141.9107 (164.4089)
2022-11-25 20:52:44,306:INFO: - Computing ADE (validation)
2022-11-25 20:52:44,701:INFO: 		 ADE on hotel                     dataset:	 2.9353857040405273
2022-11-25 20:52:45,194:INFO: 		 ADE on univ                      dataset:	 3.6271679401397705
2022-11-25 20:52:45,572:INFO: 		 ADE on zara1                     dataset:	 3.0581512451171875
2022-11-25 20:52:46,128:INFO: 		 ADE on zara2                     dataset:	 3.1293752193450928
2022-11-25 20:52:46,128:INFO: Average validation:	ADE  3.3736	FDE  4.7443
2022-11-25 20:52:46,129:INFO: - Computing ADE (validation o)
2022-11-25 20:52:46,440:INFO: 		 ADE on eth                       dataset:	 3.0902092456817627
2022-11-25 20:52:46,440:INFO: Average validation o:	ADE  3.0902	FDE  4.1969
2022-11-25 20:52:46,449:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_271.pth.tar
2022-11-25 20:52:46,449:INFO: 
===> EPOCH: 272 (P3)
2022-11-25 20:52:46,450:INFO: - Computing loss (training)
2022-11-25 20:52:47,190:INFO: Dataset: hotel               Batch: 1/4	Loss 198.5559 (198.5559)
2022-11-25 20:52:47,711:INFO: Dataset: hotel               Batch: 2/4	Loss 198.6713 (198.6143)
2022-11-25 20:52:48,216:INFO: Dataset: hotel               Batch: 3/4	Loss 181.7245 (192.6852)
2022-11-25 20:52:48,687:INFO: Dataset: hotel               Batch: 4/4	Loss 109.7133 (177.6890)
2022-11-25 20:52:49,538:INFO: Dataset: univ                Batch:  1/15	Loss 164.9067 (164.9067)
2022-11-25 20:52:50,090:INFO: Dataset: univ                Batch:  2/15	Loss 165.2702 (165.0851)
2022-11-25 20:52:50,633:INFO: Dataset: univ                Batch:  3/15	Loss 163.6802 (164.6560)
2022-11-25 20:52:51,196:INFO: Dataset: univ                Batch:  4/15	Loss 162.7995 (164.1700)
2022-11-25 20:52:51,742:INFO: Dataset: univ                Batch:  5/15	Loss 163.5545 (164.0533)
2022-11-25 20:52:52,293:INFO: Dataset: univ                Batch:  6/15	Loss 164.3961 (164.1094)
2022-11-25 20:52:52,834:INFO: Dataset: univ                Batch:  7/15	Loss 165.0713 (164.2326)
2022-11-25 20:52:53,387:INFO: Dataset: univ                Batch:  8/15	Loss 162.8438 (164.0512)
2022-11-25 20:52:53,936:INFO: Dataset: univ                Batch:  9/15	Loss 162.9566 (163.9318)
2022-11-25 20:52:54,502:INFO: Dataset: univ                Batch: 10/15	Loss 162.5611 (163.7789)
2022-11-25 20:52:55,051:INFO: Dataset: univ                Batch: 11/15	Loss 165.2116 (163.8908)
2022-11-25 20:52:55,621:INFO: Dataset: univ                Batch: 12/15	Loss 162.8806 (163.8006)
2022-11-25 20:52:56,175:INFO: Dataset: univ                Batch: 13/15	Loss 163.3523 (163.7668)
2022-11-25 20:52:56,754:INFO: Dataset: univ                Batch: 14/15	Loss 163.0198 (163.7101)
2022-11-25 20:52:57,489:INFO: Dataset: univ                Batch: 15/15	Loss 30.8279 (162.0666)
2022-11-25 20:52:58,417:INFO: Dataset: zara1               Batch: 1/8	Loss 172.6698 (172.6698)
2022-11-25 20:52:58,925:INFO: Dataset: zara1               Batch: 2/8	Loss 174.7957 (173.7373)
2022-11-25 20:52:59,437:INFO: Dataset: zara1               Batch: 3/8	Loss 171.6736 (173.0611)
2022-11-25 20:53:00,140:INFO: Dataset: zara1               Batch: 4/8	Loss 173.2816 (173.1216)
2022-11-25 20:53:00,698:INFO: Dataset: zara1               Batch: 5/8	Loss 174.3943 (173.3712)
2022-11-25 20:53:01,297:INFO: Dataset: zara1               Batch: 6/8	Loss 170.4081 (172.8413)
2022-11-25 20:53:01,827:INFO: Dataset: zara1               Batch: 7/8	Loss 171.2544 (172.6179)
2022-11-25 20:53:02,371:INFO: Dataset: zara1               Batch: 8/8	Loss 146.2454 (169.9113)
2022-11-25 20:53:03,210:INFO: Dataset: zara2               Batch:  1/18	Loss 166.5053 (166.5053)
2022-11-25 20:53:03,780:INFO: Dataset: zara2               Batch:  2/18	Loss 167.1641 (166.8267)
2022-11-25 20:53:04,308:INFO: Dataset: zara2               Batch:  3/18	Loss 165.3352 (166.3523)
2022-11-25 20:53:04,829:INFO: Dataset: zara2               Batch:  4/18	Loss 171.3661 (167.6285)
2022-11-25 20:53:05,353:INFO: Dataset: zara2               Batch:  5/18	Loss 165.5414 (167.2474)
2022-11-25 20:53:05,871:INFO: Dataset: zara2               Batch:  6/18	Loss 164.2921 (166.7182)
2022-11-25 20:53:06,388:INFO: Dataset: zara2               Batch:  7/18	Loss 164.4028 (166.3953)
2022-11-25 20:53:06,903:INFO: Dataset: zara2               Batch:  8/18	Loss 166.2503 (166.3779)
2022-11-25 20:53:07,417:INFO: Dataset: zara2               Batch:  9/18	Loss 166.4452 (166.3859)
2022-11-25 20:53:07,937:INFO: Dataset: zara2               Batch: 10/18	Loss 164.5328 (166.2059)
2022-11-25 20:53:08,454:INFO: Dataset: zara2               Batch: 11/18	Loss 163.5247 (165.9659)
2022-11-25 20:53:09,040:INFO: Dataset: zara2               Batch: 12/18	Loss 163.0355 (165.7049)
2022-11-25 20:53:09,580:INFO: Dataset: zara2               Batch: 13/18	Loss 165.3171 (165.6757)
2022-11-25 20:53:10,116:INFO: Dataset: zara2               Batch: 14/18	Loss 163.4453 (165.5351)
2022-11-25 20:53:10,641:INFO: Dataset: zara2               Batch: 15/18	Loss 164.0457 (165.4368)
2022-11-25 20:53:11,167:INFO: Dataset: zara2               Batch: 16/18	Loss 163.3823 (165.2990)
2022-11-25 20:53:11,692:INFO: Dataset: zara2               Batch: 17/18	Loss 163.3169 (165.1828)
2022-11-25 20:53:12,211:INFO: Dataset: zara2               Batch: 18/18	Loss 141.0621 (164.1141)
2022-11-25 20:53:12,273:INFO: - Computing ADE (validation)
2022-11-25 20:53:12,647:INFO: 		 ADE on hotel                     dataset:	 2.8720338344573975
2022-11-25 20:53:13,093:INFO: 		 ADE on univ                      dataset:	 3.600513458251953
2022-11-25 20:53:13,457:INFO: 		 ADE on zara1                     dataset:	 3.0236806869506836
2022-11-25 20:53:14,030:INFO: 		 ADE on zara2                     dataset:	 3.128880262374878
2022-11-25 20:53:14,031:INFO: Average validation:	ADE  3.3541	FDE  4.7569
2022-11-25 20:53:14,031:INFO: - Computing ADE (validation o)
2022-11-25 20:53:14,351:INFO: 		 ADE on eth                       dataset:	 3.0170483589172363
2022-11-25 20:53:14,351:INFO: Average validation o:	ADE  3.0170	FDE  4.1326
2022-11-25 20:53:14,360:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_272.pth.tar
2022-11-25 20:53:14,360:INFO: 
===> EPOCH: 273 (P3)
2022-11-25 20:53:14,360:INFO: - Computing loss (training)
2022-11-25 20:53:15,099:INFO: Dataset: hotel               Batch: 1/4	Loss 191.4080 (191.4080)
2022-11-25 20:53:15,608:INFO: Dataset: hotel               Batch: 2/4	Loss 188.5448 (189.9798)
2022-11-25 20:53:16,134:INFO: Dataset: hotel               Batch: 3/4	Loss 182.8741 (187.5699)
2022-11-25 20:53:16,598:INFO: Dataset: hotel               Batch: 4/4	Loss 108.4042 (174.3060)
2022-11-25 20:53:17,514:INFO: Dataset: univ                Batch:  1/15	Loss 165.5363 (165.5363)
2022-11-25 20:53:18,079:INFO: Dataset: univ                Batch:  2/15	Loss 166.1495 (165.8462)
2022-11-25 20:53:18,623:INFO: Dataset: univ                Batch:  3/15	Loss 165.2837 (165.6685)
2022-11-25 20:53:19,169:INFO: Dataset: univ                Batch:  4/15	Loss 164.5700 (165.3917)
2022-11-25 20:53:19,727:INFO: Dataset: univ                Batch:  5/15	Loss 164.4197 (165.1852)
2022-11-25 20:53:20,267:INFO: Dataset: univ                Batch:  6/15	Loss 164.2808 (165.0379)
2022-11-25 20:53:20,811:INFO: Dataset: univ                Batch:  7/15	Loss 163.4603 (164.8096)
2022-11-25 20:53:21,350:INFO: Dataset: univ                Batch:  8/15	Loss 163.0730 (164.5940)
2022-11-25 20:53:21,895:INFO: Dataset: univ                Batch:  9/15	Loss 163.9606 (164.5206)
2022-11-25 20:53:22,449:INFO: Dataset: univ                Batch: 10/15	Loss 164.5721 (164.5259)
2022-11-25 20:53:23,077:INFO: Dataset: univ                Batch: 11/15	Loss 163.3489 (164.4029)
2022-11-25 20:53:23,631:INFO: Dataset: univ                Batch: 12/15	Loss 162.7001 (164.2536)
2022-11-25 20:53:24,229:INFO: Dataset: univ                Batch: 13/15	Loss 162.2690 (164.1099)
2022-11-25 20:53:24,810:INFO: Dataset: univ                Batch: 14/15	Loss 162.0124 (163.9522)
2022-11-25 20:53:25,283:INFO: Dataset: univ                Batch: 15/15	Loss 30.2370 (162.1463)
2022-11-25 20:53:26,110:INFO: Dataset: zara1               Batch: 1/8	Loss 170.9884 (170.9884)
2022-11-25 20:53:26,695:INFO: Dataset: zara1               Batch: 2/8	Loss 168.6978 (169.8799)
2022-11-25 20:53:27,425:INFO: Dataset: zara1               Batch: 3/8	Loss 169.5143 (169.7432)
2022-11-25 20:53:28,032:INFO: Dataset: zara1               Batch: 4/8	Loss 168.4341 (169.4398)
2022-11-25 20:53:28,552:INFO: Dataset: zara1               Batch: 5/8	Loss 168.9253 (169.3455)
2022-11-25 20:53:29,132:INFO: Dataset: zara1               Batch: 6/8	Loss 170.2235 (169.4985)
2022-11-25 20:53:29,662:INFO: Dataset: zara1               Batch: 7/8	Loss 171.3492 (169.7524)
2022-11-25 20:53:30,232:INFO: Dataset: zara1               Batch: 8/8	Loss 146.6222 (166.9403)
2022-11-25 20:53:31,103:INFO: Dataset: zara2               Batch:  1/18	Loss 162.2513 (162.2513)
2022-11-25 20:53:31,679:INFO: Dataset: zara2               Batch:  2/18	Loss 162.7312 (162.4920)
2022-11-25 20:53:32,332:INFO: Dataset: zara2               Batch:  3/18	Loss 161.3659 (162.1352)
2022-11-25 20:53:32,853:INFO: Dataset: zara2               Batch:  4/18	Loss 162.9387 (162.3361)
2022-11-25 20:53:33,436:INFO: Dataset: zara2               Batch:  5/18	Loss 162.3079 (162.3305)
2022-11-25 20:53:33,980:INFO: Dataset: zara2               Batch:  6/18	Loss 161.6109 (162.2028)
2022-11-25 20:53:34,523:INFO: Dataset: zara2               Batch:  7/18	Loss 162.3328 (162.2234)
2022-11-25 20:53:35,085:INFO: Dataset: zara2               Batch:  8/18	Loss 163.9854 (162.4602)
2022-11-25 20:53:35,650:INFO: Dataset: zara2               Batch:  9/18	Loss 162.7451 (162.4926)
2022-11-25 20:53:36,249:INFO: Dataset: zara2               Batch: 10/18	Loss 163.0683 (162.5493)
2022-11-25 20:53:36,811:INFO: Dataset: zara2               Batch: 11/18	Loss 163.8711 (162.6623)
2022-11-25 20:53:37,361:INFO: Dataset: zara2               Batch: 12/18	Loss 162.6231 (162.6589)
2022-11-25 20:53:37,917:INFO: Dataset: zara2               Batch: 13/18	Loss 162.1788 (162.6210)
2022-11-25 20:53:38,473:INFO: Dataset: zara2               Batch: 14/18	Loss 164.0178 (162.7228)
2022-11-25 20:53:39,010:INFO: Dataset: zara2               Batch: 15/18	Loss 163.3075 (162.7603)
2022-11-25 20:53:39,540:INFO: Dataset: zara2               Batch: 16/18	Loss 162.8372 (162.7651)
2022-11-25 20:53:40,074:INFO: Dataset: zara2               Batch: 17/18	Loss 162.0535 (162.7237)
2022-11-25 20:53:40,643:INFO: Dataset: zara2               Batch: 18/18	Loss 138.8220 (161.4751)
2022-11-25 20:53:40,713:INFO: - Computing ADE (validation)
2022-11-25 20:53:41,329:INFO: 		 ADE on hotel                     dataset:	 2.9011714458465576
2022-11-25 20:53:41,972:INFO: 		 ADE on univ                      dataset:	 3.558837652206421
2022-11-25 20:53:42,328:INFO: 		 ADE on zara1                     dataset:	 3.0518710613250732
2022-11-25 20:53:42,892:INFO: 		 ADE on zara2                     dataset:	 3.1189262866973877
2022-11-25 20:53:42,892:INFO: Average validation:	ADE  3.3320	FDE  4.6796
2022-11-25 20:53:42,893:INFO: - Computing ADE (validation o)
2022-11-25 20:53:43,197:INFO: 		 ADE on eth                       dataset:	 3.2074127197265625
2022-11-25 20:53:43,198:INFO: Average validation o:	ADE  3.2074	FDE  4.5071
2022-11-25 20:53:43,207:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_273.pth.tar
2022-11-25 20:53:43,207:INFO: 
===> EPOCH: 274 (P3)
2022-11-25 20:53:43,207:INFO: - Computing loss (training)
2022-11-25 20:53:43,955:INFO: Dataset: hotel               Batch: 1/4	Loss 184.2868 (184.2868)
2022-11-25 20:53:44,466:INFO: Dataset: hotel               Batch: 2/4	Loss 177.6560 (180.9635)
2022-11-25 20:53:44,975:INFO: Dataset: hotel               Batch: 3/4	Loss 177.9902 (179.9400)
2022-11-25 20:53:45,431:INFO: Dataset: hotel               Batch: 4/4	Loss 113.3491 (169.7493)
2022-11-25 20:53:46,295:INFO: Dataset: univ                Batch:  1/15	Loss 162.7002 (162.7002)
2022-11-25 20:53:46,855:INFO: Dataset: univ                Batch:  2/15	Loss 161.4807 (162.0570)
2022-11-25 20:53:47,432:INFO: Dataset: univ                Batch:  3/15	Loss 162.3649 (162.1524)
2022-11-25 20:53:48,097:INFO: Dataset: univ                Batch:  4/15	Loss 161.2652 (161.9168)
2022-11-25 20:53:48,729:INFO: Dataset: univ                Batch:  5/15	Loss 162.3642 (162.0057)
2022-11-25 20:53:49,358:INFO: Dataset: univ                Batch:  6/15	Loss 162.2788 (162.0500)
2022-11-25 20:53:49,959:INFO: Dataset: univ                Batch:  7/15	Loss 162.0864 (162.0555)
2022-11-25 20:53:50,575:INFO: Dataset: univ                Batch:  8/15	Loss 163.2022 (162.1915)
2022-11-25 20:53:51,195:INFO: Dataset: univ                Batch:  9/15	Loss 159.9314 (161.9232)
2022-11-25 20:53:51,759:INFO: Dataset: univ                Batch: 10/15	Loss 161.6153 (161.8938)
2022-11-25 20:53:52,341:INFO: Dataset: univ                Batch: 11/15	Loss 161.5603 (161.8652)
2022-11-25 20:53:52,944:INFO: Dataset: univ                Batch: 12/15	Loss 161.1870 (161.8014)
2022-11-25 20:53:53,549:INFO: Dataset: univ                Batch: 13/15	Loss 161.9419 (161.8118)
2022-11-25 20:53:54,107:INFO: Dataset: univ                Batch: 14/15	Loss 160.4709 (161.7182)
2022-11-25 20:53:54,563:INFO: Dataset: univ                Batch: 15/15	Loss 30.2767 (160.2233)
2022-11-25 20:53:55,443:INFO: Dataset: zara1               Batch: 1/8	Loss 169.8192 (169.8192)
2022-11-25 20:53:55,978:INFO: Dataset: zara1               Batch: 2/8	Loss 166.8726 (168.3639)
2022-11-25 20:53:56,496:INFO: Dataset: zara1               Batch: 3/8	Loss 168.0035 (168.2539)
2022-11-25 20:53:57,015:INFO: Dataset: zara1               Batch: 4/8	Loss 167.1043 (167.9434)
2022-11-25 20:53:57,622:INFO: Dataset: zara1               Batch: 5/8	Loss 168.1132 (167.9770)
2022-11-25 20:53:58,150:INFO: Dataset: zara1               Batch: 6/8	Loss 168.2755 (168.0240)
2022-11-25 20:53:58,685:INFO: Dataset: zara1               Batch: 7/8	Loss 165.6186 (167.6419)
2022-11-25 20:53:59,196:INFO: Dataset: zara1               Batch: 8/8	Loss 144.5251 (165.2815)
2022-11-25 20:54:00,091:INFO: Dataset: zara2               Batch:  1/18	Loss 162.4211 (162.4211)
2022-11-25 20:54:00,785:INFO: Dataset: zara2               Batch:  2/18	Loss 164.6509 (163.5306)
2022-11-25 20:54:01,619:INFO: Dataset: zara2               Batch:  3/18	Loss 161.4323 (162.8334)
2022-11-25 20:54:02,163:INFO: Dataset: zara2               Batch:  4/18	Loss 163.2797 (162.9485)
2022-11-25 20:54:02,703:INFO: Dataset: zara2               Batch:  5/18	Loss 161.0990 (162.5340)
2022-11-25 20:54:03,237:INFO: Dataset: zara2               Batch:  6/18	Loss 161.9070 (162.4211)
2022-11-25 20:54:03,769:INFO: Dataset: zara2               Batch:  7/18	Loss 162.2988 (162.4035)
2022-11-25 20:54:04,299:INFO: Dataset: zara2               Batch:  8/18	Loss 162.1020 (162.3655)
2022-11-25 20:54:04,921:INFO: Dataset: zara2               Batch:  9/18	Loss 162.4535 (162.3754)
2022-11-25 20:54:05,457:INFO: Dataset: zara2               Batch: 10/18	Loss 160.0763 (162.1217)
2022-11-25 20:54:05,983:INFO: Dataset: zara2               Batch: 11/18	Loss 160.7021 (161.9707)
2022-11-25 20:54:06,513:INFO: Dataset: zara2               Batch: 12/18	Loss 162.4443 (162.0094)
2022-11-25 20:54:07,038:INFO: Dataset: zara2               Batch: 13/18	Loss 162.3000 (162.0333)
2022-11-25 20:54:07,563:INFO: Dataset: zara2               Batch: 14/18	Loss 160.9088 (161.9590)
2022-11-25 20:54:08,100:INFO: Dataset: zara2               Batch: 15/18	Loss 160.9231 (161.8956)
2022-11-25 20:54:08,630:INFO: Dataset: zara2               Batch: 16/18	Loss 160.9084 (161.8326)
2022-11-25 20:54:09,153:INFO: Dataset: zara2               Batch: 17/18	Loss 163.2976 (161.9183)
2022-11-25 20:54:09,663:INFO: Dataset: zara2               Batch: 18/18	Loss 138.8069 (160.7568)
2022-11-25 20:54:09,729:INFO: - Computing ADE (validation)
2022-11-25 20:54:10,100:INFO: 		 ADE on hotel                     dataset:	 2.9145853519439697
2022-11-25 20:54:10,547:INFO: 		 ADE on univ                      dataset:	 3.5279312133789062
2022-11-25 20:54:10,898:INFO: 		 ADE on zara1                     dataset:	 2.916339874267578
2022-11-25 20:54:11,462:INFO: 		 ADE on zara2                     dataset:	 3.1292665004730225
2022-11-25 20:54:11,462:INFO: Average validation:	ADE  3.3125	FDE  4.6597
2022-11-25 20:54:11,463:INFO: - Computing ADE (validation o)
2022-11-25 20:54:11,773:INFO: 		 ADE on eth                       dataset:	 3.3218812942504883
2022-11-25 20:54:11,774:INFO: Average validation o:	ADE  3.3219	FDE  4.3801
2022-11-25 20:54:11,783:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_274.pth.tar
2022-11-25 20:54:11,783:INFO: 
===> EPOCH: 275 (P3)
2022-11-25 20:54:11,783:INFO: - Computing loss (training)
2022-11-25 20:54:12,521:INFO: Dataset: hotel               Batch: 1/4	Loss 184.2153 (184.2153)
2022-11-25 20:54:13,029:INFO: Dataset: hotel               Batch: 2/4	Loss 190.7670 (187.3932)
2022-11-25 20:54:13,528:INFO: Dataset: hotel               Batch: 3/4	Loss 177.4838 (184.2936)
2022-11-25 20:54:13,969:INFO: Dataset: hotel               Batch: 4/4	Loss 111.4894 (172.2876)
2022-11-25 20:54:14,813:INFO: Dataset: univ                Batch:  1/15	Loss 163.0605 (163.0605)
2022-11-25 20:54:15,354:INFO: Dataset: univ                Batch:  2/15	Loss 162.4056 (162.7510)
2022-11-25 20:54:15,901:INFO: Dataset: univ                Batch:  3/15	Loss 162.4340 (162.6420)
2022-11-25 20:54:16,435:INFO: Dataset: univ                Batch:  4/15	Loss 160.5659 (162.1547)
2022-11-25 20:54:16,991:INFO: Dataset: univ                Batch:  5/15	Loss 159.3496 (161.5356)
2022-11-25 20:54:17,550:INFO: Dataset: univ                Batch:  6/15	Loss 161.3194 (161.4979)
2022-11-25 20:54:18,087:INFO: Dataset: univ                Batch:  7/15	Loss 160.6810 (161.3824)
2022-11-25 20:54:18,624:INFO: Dataset: univ                Batch:  8/15	Loss 161.5491 (161.4023)
2022-11-25 20:54:19,164:INFO: Dataset: univ                Batch:  9/15	Loss 160.3730 (161.2881)
2022-11-25 20:54:19,690:INFO: Dataset: univ                Batch: 10/15	Loss 161.2349 (161.2837)
2022-11-25 20:54:20,233:INFO: Dataset: univ                Batch: 11/15	Loss 160.2949 (161.1912)
2022-11-25 20:54:20,771:INFO: Dataset: univ                Batch: 12/15	Loss 160.4411 (161.1289)
2022-11-25 20:54:21,314:INFO: Dataset: univ                Batch: 13/15	Loss 159.7771 (161.0207)
2022-11-25 20:54:21,851:INFO: Dataset: univ                Batch: 14/15	Loss 159.3109 (160.9044)
2022-11-25 20:54:22,289:INFO: Dataset: univ                Batch: 15/15	Loss 30.0208 (158.8948)
2022-11-25 20:54:23,113:INFO: Dataset: zara1               Batch: 1/8	Loss 166.5417 (166.5417)
2022-11-25 20:54:23,616:INFO: Dataset: zara1               Batch: 2/8	Loss 167.7861 (167.1507)
2022-11-25 20:54:24,119:INFO: Dataset: zara1               Batch: 3/8	Loss 167.3788 (167.2251)
2022-11-25 20:54:24,623:INFO: Dataset: zara1               Batch: 4/8	Loss 167.8359 (167.3674)
2022-11-25 20:54:25,126:INFO: Dataset: zara1               Batch: 5/8	Loss 167.6703 (167.4276)
2022-11-25 20:54:25,629:INFO: Dataset: zara1               Batch: 6/8	Loss 169.0135 (167.6543)
2022-11-25 20:54:26,129:INFO: Dataset: zara1               Batch: 7/8	Loss 167.6342 (167.6515)
2022-11-25 20:54:26,617:INFO: Dataset: zara1               Batch: 8/8	Loss 144.0003 (165.1246)
2022-11-25 20:54:27,429:INFO: Dataset: zara2               Batch:  1/18	Loss 161.0011 (161.0011)
2022-11-25 20:54:27,952:INFO: Dataset: zara2               Batch:  2/18	Loss 161.4990 (161.2413)
2022-11-25 20:54:28,459:INFO: Dataset: zara2               Batch:  3/18	Loss 160.8047 (161.1066)
2022-11-25 20:54:28,970:INFO: Dataset: zara2               Batch:  4/18	Loss 162.1523 (161.3582)
2022-11-25 20:54:29,473:INFO: Dataset: zara2               Batch:  5/18	Loss 160.2583 (161.1349)
2022-11-25 20:54:29,982:INFO: Dataset: zara2               Batch:  6/18	Loss 162.1704 (161.2937)
2022-11-25 20:54:30,488:INFO: Dataset: zara2               Batch:  7/18	Loss 160.8426 (161.2308)
2022-11-25 20:54:30,992:INFO: Dataset: zara2               Batch:  8/18	Loss 160.8732 (161.1875)
2022-11-25 20:54:31,497:INFO: Dataset: zara2               Batch:  9/18	Loss 160.9583 (161.1637)
2022-11-25 20:54:32,002:INFO: Dataset: zara2               Batch: 10/18	Loss 160.0639 (161.0628)
2022-11-25 20:54:32,506:INFO: Dataset: zara2               Batch: 11/18	Loss 159.1604 (160.8904)
2022-11-25 20:54:33,012:INFO: Dataset: zara2               Batch: 12/18	Loss 160.1036 (160.8276)
2022-11-25 20:54:33,516:INFO: Dataset: zara2               Batch: 13/18	Loss 160.4156 (160.7935)
2022-11-25 20:54:34,022:INFO: Dataset: zara2               Batch: 14/18	Loss 160.3102 (160.7580)
2022-11-25 20:54:34,529:INFO: Dataset: zara2               Batch: 15/18	Loss 160.6180 (160.7489)
2022-11-25 20:54:35,035:INFO: Dataset: zara2               Batch: 16/18	Loss 159.7095 (160.6911)
2022-11-25 20:54:35,541:INFO: Dataset: zara2               Batch: 17/18	Loss 159.3692 (160.6145)
2022-11-25 20:54:36,121:INFO: Dataset: zara2               Batch: 18/18	Loss 140.4411 (159.6074)
2022-11-25 20:54:36,183:INFO: - Computing ADE (validation)
2022-11-25 20:54:36,559:INFO: 		 ADE on hotel                     dataset:	 2.8918306827545166
2022-11-25 20:54:37,001:INFO: 		 ADE on univ                      dataset:	 3.571953296661377
2022-11-25 20:54:37,360:INFO: 		 ADE on zara1                     dataset:	 2.944032669067383
2022-11-25 20:54:37,926:INFO: 		 ADE on zara2                     dataset:	 3.1127021312713623
2022-11-25 20:54:37,926:INFO: Average validation:	ADE  3.3297	FDE  4.7034
2022-11-25 20:54:37,927:INFO: - Computing ADE (validation o)
2022-11-25 20:54:38,241:INFO: 		 ADE on eth                       dataset:	 3.0935630798339844
2022-11-25 20:54:38,241:INFO: Average validation o:	ADE  3.0936	FDE  4.1622
2022-11-25 20:54:38,250:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_275.pth.tar
2022-11-25 20:54:38,250:INFO: 
===> EPOCH: 276 (P3)
2022-11-25 20:54:38,251:INFO: - Computing loss (training)
2022-11-25 20:54:38,971:INFO: Dataset: hotel               Batch: 1/4	Loss 174.2288 (174.2288)
2022-11-25 20:54:39,473:INFO: Dataset: hotel               Batch: 2/4	Loss 172.6694 (173.4417)
2022-11-25 20:54:39,966:INFO: Dataset: hotel               Batch: 3/4	Loss 180.7726 (175.7834)
2022-11-25 20:54:40,424:INFO: Dataset: hotel               Batch: 4/4	Loss 110.9932 (164.2442)
2022-11-25 20:54:41,246:INFO: Dataset: univ                Batch:  1/15	Loss 159.3711 (159.3711)
2022-11-25 20:54:41,788:INFO: Dataset: univ                Batch:  2/15	Loss 159.6593 (159.5154)
2022-11-25 20:54:42,325:INFO: Dataset: univ                Batch:  3/15	Loss 163.9219 (160.9593)
2022-11-25 20:54:42,857:INFO: Dataset: univ                Batch:  4/15	Loss 175.8482 (164.3919)
2022-11-25 20:54:43,407:INFO: Dataset: univ                Batch:  5/15	Loss 159.5640 (163.3046)
2022-11-25 20:54:43,947:INFO: Dataset: univ                Batch:  6/15	Loss 159.0902 (162.5911)
2022-11-25 20:54:44,492:INFO: Dataset: univ                Batch:  7/15	Loss 161.0773 (162.3734)
2022-11-25 20:54:45,039:INFO: Dataset: univ                Batch:  8/15	Loss 159.2182 (161.9373)
2022-11-25 20:54:45,593:INFO: Dataset: univ                Batch:  9/15	Loss 159.6239 (161.6539)
2022-11-25 20:54:46,125:INFO: Dataset: univ                Batch: 10/15	Loss 160.1939 (161.5194)
2022-11-25 20:54:46,669:INFO: Dataset: univ                Batch: 11/15	Loss 160.5888 (161.4319)
2022-11-25 20:54:47,208:INFO: Dataset: univ                Batch: 12/15	Loss 159.5650 (161.2719)
2022-11-25 20:54:47,746:INFO: Dataset: univ                Batch: 13/15	Loss 160.9614 (161.2476)
2022-11-25 20:54:48,271:INFO: Dataset: univ                Batch: 14/15	Loss 160.4571 (161.2009)
2022-11-25 20:54:48,707:INFO: Dataset: univ                Batch: 15/15	Loss 29.9112 (159.3656)
2022-11-25 20:54:49,508:INFO: Dataset: zara1               Batch: 1/8	Loss 171.1371 (171.1371)
2022-11-25 20:54:50,006:INFO: Dataset: zara1               Batch: 2/8	Loss 178.2463 (174.9233)
2022-11-25 20:54:50,515:INFO: Dataset: zara1               Batch: 3/8	Loss 166.9095 (171.8148)
2022-11-25 20:54:51,011:INFO: Dataset: zara1               Batch: 4/8	Loss 167.7854 (170.8560)
2022-11-25 20:54:51,514:INFO: Dataset: zara1               Batch: 5/8	Loss 166.4440 (169.9662)
2022-11-25 20:54:52,024:INFO: Dataset: zara1               Batch: 6/8	Loss 165.7039 (169.2118)
2022-11-25 20:54:52,528:INFO: Dataset: zara1               Batch: 7/8	Loss 167.8989 (169.0269)
2022-11-25 20:54:53,019:INFO: Dataset: zara1               Batch: 8/8	Loss 143.2473 (166.1776)
2022-11-25 20:54:53,832:INFO: Dataset: zara2               Batch:  1/18	Loss 159.4332 (159.4332)
2022-11-25 20:54:54,347:INFO: Dataset: zara2               Batch:  2/18	Loss 159.5688 (159.5032)
2022-11-25 20:54:54,859:INFO: Dataset: zara2               Batch:  3/18	Loss 160.4778 (159.8165)
2022-11-25 20:54:55,376:INFO: Dataset: zara2               Batch:  4/18	Loss 160.1345 (159.8894)
2022-11-25 20:54:55,887:INFO: Dataset: zara2               Batch:  5/18	Loss 160.6578 (160.0474)
2022-11-25 20:54:56,402:INFO: Dataset: zara2               Batch:  6/18	Loss 159.5037 (159.9587)
2022-11-25 20:54:56,912:INFO: Dataset: zara2               Batch:  7/18	Loss 161.0614 (160.1166)
2022-11-25 20:54:57,425:INFO: Dataset: zara2               Batch:  8/18	Loss 160.2758 (160.1366)
2022-11-25 20:54:57,936:INFO: Dataset: zara2               Batch:  9/18	Loss 159.5763 (160.0766)
2022-11-25 20:54:58,445:INFO: Dataset: zara2               Batch: 10/18	Loss 162.1988 (160.2941)
2022-11-25 20:54:58,954:INFO: Dataset: zara2               Batch: 11/18	Loss 161.1801 (160.3722)
2022-11-25 20:54:59,469:INFO: Dataset: zara2               Batch: 12/18	Loss 160.1306 (160.3512)
2022-11-25 20:54:59,980:INFO: Dataset: zara2               Batch: 13/18	Loss 159.8083 (160.3098)
2022-11-25 20:55:00,492:INFO: Dataset: zara2               Batch: 14/18	Loss 159.9133 (160.2811)
2022-11-25 20:55:01,003:INFO: Dataset: zara2               Batch: 15/18	Loss 158.8853 (160.1829)
2022-11-25 20:55:01,516:INFO: Dataset: zara2               Batch: 16/18	Loss 159.8214 (160.1610)
2022-11-25 20:55:02,027:INFO: Dataset: zara2               Batch: 17/18	Loss 160.9156 (160.2036)
2022-11-25 20:55:02,527:INFO: Dataset: zara2               Batch: 18/18	Loss 137.1370 (159.0253)
2022-11-25 20:55:02,586:INFO: - Computing ADE (validation)
2022-11-25 20:55:02,950:INFO: 		 ADE on hotel                     dataset:	 2.870363473892212
2022-11-25 20:55:03,384:INFO: 		 ADE on univ                      dataset:	 3.5469398498535156
2022-11-25 20:55:03,743:INFO: 		 ADE on zara1                     dataset:	 2.975423574447632
2022-11-25 20:55:04,309:INFO: 		 ADE on zara2                     dataset:	 3.095445394515991
2022-11-25 20:55:04,309:INFO: Average validation:	ADE  3.3110	FDE  4.6731
2022-11-25 20:55:04,310:INFO: - Computing ADE (validation o)
2022-11-25 20:55:04,622:INFO: 		 ADE on eth                       dataset:	 3.1268112659454346
2022-11-25 20:55:04,622:INFO: Average validation o:	ADE  3.1268	FDE  4.2649
2022-11-25 20:55:04,631:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_276.pth.tar
2022-11-25 20:55:04,631:INFO: 
===> EPOCH: 277 (P3)
2022-11-25 20:55:04,631:INFO: - Computing loss (training)
2022-11-25 20:55:05,350:INFO: Dataset: hotel               Batch: 1/4	Loss 173.4479 (173.4479)
2022-11-25 20:55:05,853:INFO: Dataset: hotel               Batch: 2/4	Loss 170.4088 (171.9283)
2022-11-25 20:55:06,345:INFO: Dataset: hotel               Batch: 3/4	Loss 172.7698 (172.1871)
2022-11-25 20:55:06,802:INFO: Dataset: hotel               Batch: 4/4	Loss 110.8794 (160.8637)
2022-11-25 20:55:07,767:INFO: Dataset: univ                Batch:  1/15	Loss 159.2166 (159.2166)
2022-11-25 20:55:08,297:INFO: Dataset: univ                Batch:  2/15	Loss 160.5438 (159.8405)
2022-11-25 20:55:08,849:INFO: Dataset: univ                Batch:  3/15	Loss 159.3342 (159.6497)
2022-11-25 20:55:09,387:INFO: Dataset: univ                Batch:  4/15	Loss 160.8639 (159.9535)
2022-11-25 20:55:09,915:INFO: Dataset: univ                Batch:  5/15	Loss 159.0516 (159.7886)
2022-11-25 20:55:10,455:INFO: Dataset: univ                Batch:  6/15	Loss 158.7075 (159.6123)
2022-11-25 20:55:11,000:INFO: Dataset: univ                Batch:  7/15	Loss 159.6696 (159.6214)
2022-11-25 20:55:11,535:INFO: Dataset: univ                Batch:  8/15	Loss 158.6183 (159.4978)
2022-11-25 20:55:12,072:INFO: Dataset: univ                Batch:  9/15	Loss 159.0025 (159.4429)
2022-11-25 20:55:12,612:INFO: Dataset: univ                Batch: 10/15	Loss 162.3931 (159.7287)
2022-11-25 20:55:13,159:INFO: Dataset: univ                Batch: 11/15	Loss 158.0717 (159.5618)
2022-11-25 20:55:13,703:INFO: Dataset: univ                Batch: 12/15	Loss 160.6385 (159.6564)
2022-11-25 20:55:14,231:INFO: Dataset: univ                Batch: 13/15	Loss 161.2125 (159.7620)
2022-11-25 20:55:14,771:INFO: Dataset: univ                Batch: 14/15	Loss 158.5713 (159.6741)
2022-11-25 20:55:15,207:INFO: Dataset: univ                Batch: 15/15	Loss 30.4070 (158.0998)
2022-11-25 20:55:16,007:INFO: Dataset: zara1               Batch: 1/8	Loss 163.9056 (163.9056)
2022-11-25 20:55:16,507:INFO: Dataset: zara1               Batch: 2/8	Loss 167.1659 (165.5256)
2022-11-25 20:55:17,006:INFO: Dataset: zara1               Batch: 3/8	Loss 165.0630 (165.3708)
2022-11-25 20:55:17,506:INFO: Dataset: zara1               Batch: 4/8	Loss 165.9538 (165.5156)
2022-11-25 20:55:18,004:INFO: Dataset: zara1               Batch: 5/8	Loss 165.1888 (165.4504)
2022-11-25 20:55:18,506:INFO: Dataset: zara1               Batch: 6/8	Loss 165.7850 (165.5072)
2022-11-25 20:55:19,003:INFO: Dataset: zara1               Batch: 7/8	Loss 164.9983 (165.4380)
2022-11-25 20:55:19,490:INFO: Dataset: zara1               Batch: 8/8	Loss 144.1938 (163.0117)
2022-11-25 20:55:20,301:INFO: Dataset: zara2               Batch:  1/18	Loss 159.6301 (159.6301)
2022-11-25 20:55:20,812:INFO: Dataset: zara2               Batch:  2/18	Loss 160.8951 (160.2834)
2022-11-25 20:55:21,326:INFO: Dataset: zara2               Batch:  3/18	Loss 165.4497 (161.9504)
2022-11-25 20:55:21,835:INFO: Dataset: zara2               Batch:  4/18	Loss 158.4392 (161.1016)
2022-11-25 20:55:22,345:INFO: Dataset: zara2               Batch:  5/18	Loss 159.0397 (160.7111)
2022-11-25 20:55:22,858:INFO: Dataset: zara2               Batch:  6/18	Loss 161.1535 (160.7851)
2022-11-25 20:55:23,366:INFO: Dataset: zara2               Batch:  7/18	Loss 158.6319 (160.4767)
2022-11-25 20:55:23,874:INFO: Dataset: zara2               Batch:  8/18	Loss 158.3332 (160.2109)
2022-11-25 20:55:24,382:INFO: Dataset: zara2               Batch:  9/18	Loss 159.2062 (160.0945)
2022-11-25 20:55:24,890:INFO: Dataset: zara2               Batch: 10/18	Loss 158.8073 (159.9578)
2022-11-25 20:55:25,400:INFO: Dataset: zara2               Batch: 11/18	Loss 158.1142 (159.7844)
2022-11-25 20:55:25,909:INFO: Dataset: zara2               Batch: 12/18	Loss 159.0300 (159.7181)
2022-11-25 20:55:26,416:INFO: Dataset: zara2               Batch: 13/18	Loss 159.2207 (159.6816)
2022-11-25 20:55:26,925:INFO: Dataset: zara2               Batch: 14/18	Loss 158.9716 (159.6315)
2022-11-25 20:55:27,437:INFO: Dataset: zara2               Batch: 15/18	Loss 158.6476 (159.5658)
2022-11-25 20:55:27,948:INFO: Dataset: zara2               Batch: 16/18	Loss 158.6580 (159.5088)
2022-11-25 20:55:28,458:INFO: Dataset: zara2               Batch: 17/18	Loss 159.2101 (159.4912)
2022-11-25 20:55:28,942:INFO: Dataset: zara2               Batch: 18/18	Loss 135.8220 (158.5286)
2022-11-25 20:55:29,005:INFO: - Computing ADE (validation)
2022-11-25 20:55:29,374:INFO: 		 ADE on hotel                     dataset:	 2.8601667881011963
2022-11-25 20:55:29,809:INFO: 		 ADE on univ                      dataset:	 3.5175719261169434
2022-11-25 20:55:30,161:INFO: 		 ADE on zara1                     dataset:	 2.946427345275879
2022-11-25 20:55:30,717:INFO: 		 ADE on zara2                     dataset:	 3.0961153507232666
2022-11-25 20:55:30,717:INFO: Average validation:	ADE  3.2938	FDE  4.6261
2022-11-25 20:55:30,718:INFO: - Computing ADE (validation o)
2022-11-25 20:55:31,022:INFO: 		 ADE on eth                       dataset:	 3.1892926692962646
2022-11-25 20:55:31,022:INFO: Average validation o:	ADE  3.1893	FDE  3.9337
2022-11-25 20:55:31,031:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_277.pth.tar
2022-11-25 20:55:31,031:INFO: 
===> EPOCH: 278 (P3)
2022-11-25 20:55:31,032:INFO: - Computing loss (training)
2022-11-25 20:55:31,757:INFO: Dataset: hotel               Batch: 1/4	Loss 176.5227 (176.5227)
2022-11-25 20:55:32,256:INFO: Dataset: hotel               Batch: 2/4	Loss 172.9850 (174.7188)
2022-11-25 20:55:32,750:INFO: Dataset: hotel               Batch: 3/4	Loss 178.3976 (176.0082)
2022-11-25 20:55:33,207:INFO: Dataset: hotel               Batch: 4/4	Loss 105.0608 (163.2788)
2022-11-25 20:55:34,048:INFO: Dataset: univ                Batch:  1/15	Loss 161.3301 (161.3301)
2022-11-25 20:55:34,594:INFO: Dataset: univ                Batch:  2/15	Loss 159.6647 (160.4652)
2022-11-25 20:55:35,136:INFO: Dataset: univ                Batch:  3/15	Loss 158.9380 (159.9528)
2022-11-25 20:55:35,764:INFO: Dataset: univ                Batch:  4/15	Loss 158.4292 (159.5783)
2022-11-25 20:55:36,302:INFO: Dataset: univ                Batch:  5/15	Loss 159.0027 (159.4683)
2022-11-25 20:55:36,843:INFO: Dataset: univ                Batch:  6/15	Loss 163.2874 (160.0960)
2022-11-25 20:55:37,376:INFO: Dataset: univ                Batch:  7/15	Loss 159.1573 (159.9675)
2022-11-25 20:55:37,921:INFO: Dataset: univ                Batch:  8/15	Loss 157.9020 (159.6910)
2022-11-25 20:55:38,465:INFO: Dataset: univ                Batch:  9/15	Loss 158.3563 (159.5326)
2022-11-25 20:55:38,999:INFO: Dataset: univ                Batch: 10/15	Loss 157.7691 (159.3648)
2022-11-25 20:55:39,531:INFO: Dataset: univ                Batch: 11/15	Loss 159.3359 (159.3624)
2022-11-25 20:55:40,065:INFO: Dataset: univ                Batch: 12/15	Loss 160.0934 (159.4193)
2022-11-25 20:55:40,602:INFO: Dataset: univ                Batch: 13/15	Loss 159.0515 (159.3912)
2022-11-25 20:55:41,136:INFO: Dataset: univ                Batch: 14/15	Loss 159.8313 (159.4211)
2022-11-25 20:55:41,571:INFO: Dataset: univ                Batch: 15/15	Loss 29.7163 (157.7554)
2022-11-25 20:55:42,358:INFO: Dataset: zara1               Batch: 1/8	Loss 165.4307 (165.4307)
2022-11-25 20:55:42,857:INFO: Dataset: zara1               Batch: 2/8	Loss 164.4816 (164.9177)
2022-11-25 20:55:43,366:INFO: Dataset: zara1               Batch: 3/8	Loss 165.1164 (164.9930)
2022-11-25 20:55:43,865:INFO: Dataset: zara1               Batch: 4/8	Loss 165.5083 (165.1133)
2022-11-25 20:55:44,362:INFO: Dataset: zara1               Batch: 5/8	Loss 165.0279 (165.0960)
2022-11-25 20:55:44,859:INFO: Dataset: zara1               Batch: 6/8	Loss 166.1387 (165.2729)
2022-11-25 20:55:45,356:INFO: Dataset: zara1               Batch: 7/8	Loss 165.3605 (165.2858)
2022-11-25 20:55:45,840:INFO: Dataset: zara1               Batch: 8/8	Loss 141.0406 (162.7336)
2022-11-25 20:55:46,679:INFO: Dataset: zara2               Batch:  1/18	Loss 158.0163 (158.0163)
2022-11-25 20:55:47,200:INFO: Dataset: zara2               Batch:  2/18	Loss 157.9280 (157.9712)
2022-11-25 20:55:47,709:INFO: Dataset: zara2               Batch:  3/18	Loss 157.3418 (157.7546)
2022-11-25 20:55:48,217:INFO: Dataset: zara2               Batch:  4/18	Loss 160.8588 (158.5580)
2022-11-25 20:55:48,724:INFO: Dataset: zara2               Batch:  5/18	Loss 158.4427 (158.5357)
2022-11-25 20:55:49,235:INFO: Dataset: zara2               Batch:  6/18	Loss 158.6184 (158.5509)
2022-11-25 20:55:49,740:INFO: Dataset: zara2               Batch:  7/18	Loss 160.0182 (158.7656)
2022-11-25 20:55:50,246:INFO: Dataset: zara2               Batch:  8/18	Loss 161.1043 (159.0527)
2022-11-25 20:55:50,752:INFO: Dataset: zara2               Batch:  9/18	Loss 158.2507 (158.9601)
2022-11-25 20:55:51,257:INFO: Dataset: zara2               Batch: 10/18	Loss 158.9764 (158.9619)
2022-11-25 20:55:51,764:INFO: Dataset: zara2               Batch: 11/18	Loss 158.8760 (158.9542)
2022-11-25 20:55:52,270:INFO: Dataset: zara2               Batch: 12/18	Loss 158.9466 (158.9536)
2022-11-25 20:55:52,775:INFO: Dataset: zara2               Batch: 13/18	Loss 158.7734 (158.9410)
2022-11-25 20:55:53,282:INFO: Dataset: zara2               Batch: 14/18	Loss 158.2709 (158.8907)
2022-11-25 20:55:53,788:INFO: Dataset: zara2               Batch: 15/18	Loss 157.0500 (158.7692)
2022-11-25 20:55:54,296:INFO: Dataset: zara2               Batch: 16/18	Loss 157.4747 (158.6972)
2022-11-25 20:55:54,803:INFO: Dataset: zara2               Batch: 17/18	Loss 157.1669 (158.6149)
2022-11-25 20:55:55,296:INFO: Dataset: zara2               Batch: 18/18	Loss 136.0907 (157.6095)
2022-11-25 20:55:55,357:INFO: - Computing ADE (validation)
2022-11-25 20:55:55,721:INFO: 		 ADE on hotel                     dataset:	 2.7544660568237305
2022-11-25 20:55:56,168:INFO: 		 ADE on univ                      dataset:	 3.5135204792022705
2022-11-25 20:55:56,527:INFO: 		 ADE on zara1                     dataset:	 2.9776415824890137
2022-11-25 20:55:57,085:INFO: 		 ADE on zara2                     dataset:	 3.0675806999206543
2022-11-25 20:55:57,085:INFO: Average validation:	ADE  3.2772	FDE  4.6002
2022-11-25 20:55:57,086:INFO: - Computing ADE (validation o)
2022-11-25 20:55:57,401:INFO: 		 ADE on eth                       dataset:	 3.061110734939575
2022-11-25 20:55:57,401:INFO: Average validation o:	ADE  3.0611	FDE  4.1395
2022-11-25 20:55:57,410:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_278.pth.tar
2022-11-25 20:55:57,410:INFO: 
===> EPOCH: 279 (P3)
2022-11-25 20:55:57,410:INFO: - Computing loss (training)
2022-11-25 20:55:58,138:INFO: Dataset: hotel               Batch: 1/4	Loss 178.9375 (178.9375)
2022-11-25 20:55:58,647:INFO: Dataset: hotel               Batch: 2/4	Loss 171.3124 (174.8481)
2022-11-25 20:55:59,147:INFO: Dataset: hotel               Batch: 3/4	Loss 170.0962 (173.2866)
2022-11-25 20:55:59,591:INFO: Dataset: hotel               Batch: 4/4	Loss 105.2294 (162.3328)
2022-11-25 20:56:00,439:INFO: Dataset: univ                Batch:  1/15	Loss 158.9323 (158.9323)
2022-11-25 20:56:00,993:INFO: Dataset: univ                Batch:  2/15	Loss 157.8796 (158.3957)
2022-11-25 20:56:01,549:INFO: Dataset: univ                Batch:  3/15	Loss 160.8392 (159.1680)
2022-11-25 20:56:02,090:INFO: Dataset: univ                Batch:  4/15	Loss 157.2378 (158.7171)
2022-11-25 20:56:02,635:INFO: Dataset: univ                Batch:  5/15	Loss 157.7840 (158.5291)
2022-11-25 20:56:03,187:INFO: Dataset: univ                Batch:  6/15	Loss 157.9264 (158.4233)
2022-11-25 20:56:03,732:INFO: Dataset: univ                Batch:  7/15	Loss 159.4249 (158.5651)
2022-11-25 20:56:04,284:INFO: Dataset: univ                Batch:  8/15	Loss 157.3237 (158.3993)
2022-11-25 20:56:04,836:INFO: Dataset: univ                Batch:  9/15	Loss 157.0967 (158.2471)
2022-11-25 20:56:05,384:INFO: Dataset: univ                Batch: 10/15	Loss 157.3100 (158.1510)
2022-11-25 20:56:05,942:INFO: Dataset: univ                Batch: 11/15	Loss 157.3077 (158.0657)
2022-11-25 20:56:06,478:INFO: Dataset: univ                Batch: 12/15	Loss 157.3226 (158.0131)
2022-11-25 20:56:07,116:INFO: Dataset: univ                Batch: 13/15	Loss 156.8263 (157.9187)
2022-11-25 20:56:07,661:INFO: Dataset: univ                Batch: 14/15	Loss 157.5942 (157.8955)
2022-11-25 20:56:08,106:INFO: Dataset: univ                Batch: 15/15	Loss 29.3242 (156.2687)
2022-11-25 20:56:08,903:INFO: Dataset: zara1               Batch: 1/8	Loss 164.9871 (164.9871)
2022-11-25 20:56:09,398:INFO: Dataset: zara1               Batch: 2/8	Loss 164.3471 (164.6782)
2022-11-25 20:56:09,891:INFO: Dataset: zara1               Batch: 3/8	Loss 162.8159 (164.0068)
2022-11-25 20:56:10,386:INFO: Dataset: zara1               Batch: 4/8	Loss 163.7254 (163.9302)
2022-11-25 20:56:10,879:INFO: Dataset: zara1               Batch: 5/8	Loss 167.6437 (164.6844)
2022-11-25 20:56:11,387:INFO: Dataset: zara1               Batch: 6/8	Loss 168.3704 (165.3939)
2022-11-25 20:56:11,892:INFO: Dataset: zara1               Batch: 7/8	Loss 165.9512 (165.4800)
2022-11-25 20:56:12,373:INFO: Dataset: zara1               Batch: 8/8	Loss 140.2812 (162.8541)
2022-11-25 20:56:13,201:INFO: Dataset: zara2               Batch:  1/18	Loss 157.4629 (157.4629)
2022-11-25 20:56:13,712:INFO: Dataset: zara2               Batch:  2/18	Loss 157.6715 (157.5597)
2022-11-25 20:56:14,219:INFO: Dataset: zara2               Batch:  3/18	Loss 157.6505 (157.5895)
2022-11-25 20:56:14,724:INFO: Dataset: zara2               Batch:  4/18	Loss 156.5473 (157.3395)
2022-11-25 20:56:15,236:INFO: Dataset: zara2               Batch:  5/18	Loss 157.8814 (157.4471)
2022-11-25 20:56:15,744:INFO: Dataset: zara2               Batch:  6/18	Loss 157.5804 (157.4690)
2022-11-25 20:56:16,251:INFO: Dataset: zara2               Batch:  7/18	Loss 157.3173 (157.4477)
2022-11-25 20:56:16,755:INFO: Dataset: zara2               Batch:  8/18	Loss 157.3510 (157.4345)
2022-11-25 20:56:17,260:INFO: Dataset: zara2               Batch:  9/18	Loss 158.9633 (157.5988)
2022-11-25 20:56:17,767:INFO: Dataset: zara2               Batch: 10/18	Loss 157.6118 (157.6000)
2022-11-25 20:56:18,273:INFO: Dataset: zara2               Batch: 11/18	Loss 156.2802 (157.4892)
2022-11-25 20:56:18,779:INFO: Dataset: zara2               Batch: 12/18	Loss 158.9277 (157.6078)
2022-11-25 20:56:19,285:INFO: Dataset: zara2               Batch: 13/18	Loss 157.4187 (157.5936)
2022-11-25 20:56:19,793:INFO: Dataset: zara2               Batch: 14/18	Loss 156.2626 (157.4998)
2022-11-25 20:56:20,298:INFO: Dataset: zara2               Batch: 15/18	Loss 157.5372 (157.5025)
2022-11-25 20:56:20,802:INFO: Dataset: zara2               Batch: 16/18	Loss 156.2460 (157.4186)
2022-11-25 20:56:21,308:INFO: Dataset: zara2               Batch: 17/18	Loss 158.1707 (157.4621)
2022-11-25 20:56:21,802:INFO: Dataset: zara2               Batch: 18/18	Loss 135.6773 (156.4033)
2022-11-25 20:56:21,865:INFO: - Computing ADE (validation)
2022-11-25 20:56:22,245:INFO: 		 ADE on hotel                     dataset:	 2.791642427444458
2022-11-25 20:56:22,692:INFO: 		 ADE on univ                      dataset:	 3.4667515754699707
2022-11-25 20:56:23,049:INFO: 		 ADE on zara1                     dataset:	 2.891791343688965
2022-11-25 20:56:23,602:INFO: 		 ADE on zara2                     dataset:	 3.042337417602539
2022-11-25 20:56:23,602:INFO: Average validation:	ADE  3.2407	FDE  4.5667
2022-11-25 20:56:23,603:INFO: - Computing ADE (validation o)
2022-11-25 20:56:23,910:INFO: 		 ADE on eth                       dataset:	 3.0281994342803955
2022-11-25 20:56:23,910:INFO: Average validation o:	ADE  3.0282	FDE  4.3738
2022-11-25 20:56:23,919:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_279.pth.tar
2022-11-25 20:56:23,919:INFO: 
===> EPOCH: 280 (P3)
2022-11-25 20:56:23,920:INFO: - Computing loss (training)
2022-11-25 20:56:24,643:INFO: Dataset: hotel               Batch: 1/4	Loss 175.6489 (175.6489)
2022-11-25 20:56:25,140:INFO: Dataset: hotel               Batch: 2/4	Loss 170.5241 (173.1601)
2022-11-25 20:56:25,636:INFO: Dataset: hotel               Batch: 3/4	Loss 225.7072 (190.8979)
2022-11-25 20:56:26,079:INFO: Dataset: hotel               Batch: 4/4	Loss 103.1904 (176.2028)
2022-11-25 20:56:26,931:INFO: Dataset: univ                Batch:  1/15	Loss 155.6046 (155.6046)
2022-11-25 20:56:27,467:INFO: Dataset: univ                Batch:  2/15	Loss 156.5488 (156.0541)
2022-11-25 20:56:28,003:INFO: Dataset: univ                Batch:  3/15	Loss 156.4224 (156.1706)
2022-11-25 20:56:28,532:INFO: Dataset: univ                Batch:  4/15	Loss 156.9541 (156.3559)
2022-11-25 20:56:29,066:INFO: Dataset: univ                Batch:  5/15	Loss 158.3178 (156.7333)
2022-11-25 20:56:29,611:INFO: Dataset: univ                Batch:  6/15	Loss 156.4290 (156.6783)
2022-11-25 20:56:30,148:INFO: Dataset: univ                Batch:  7/15	Loss 158.6968 (156.9765)
2022-11-25 20:56:30,684:INFO: Dataset: univ                Batch:  8/15	Loss 157.4142 (157.0320)
2022-11-25 20:56:31,220:INFO: Dataset: univ                Batch:  9/15	Loss 156.7348 (156.9984)
2022-11-25 20:56:31,749:INFO: Dataset: univ                Batch: 10/15	Loss 158.0716 (157.0998)
2022-11-25 20:56:32,286:INFO: Dataset: univ                Batch: 11/15	Loss 157.2204 (157.1109)
2022-11-25 20:56:32,829:INFO: Dataset: univ                Batch: 12/15	Loss 156.5010 (157.0570)
2022-11-25 20:56:33,370:INFO: Dataset: univ                Batch: 13/15	Loss 156.4945 (157.0116)
2022-11-25 20:56:33,910:INFO: Dataset: univ                Batch: 14/15	Loss 157.3162 (157.0340)
2022-11-25 20:56:34,336:INFO: Dataset: univ                Batch: 15/15	Loss 30.5007 (155.9067)
2022-11-25 20:56:35,125:INFO: Dataset: zara1               Batch: 1/8	Loss 164.1696 (164.1696)
2022-11-25 20:56:35,628:INFO: Dataset: zara1               Batch: 2/8	Loss 163.6589 (163.9083)
2022-11-25 20:56:36,122:INFO: Dataset: zara1               Batch: 3/8	Loss 164.4855 (164.0977)
2022-11-25 20:56:36,615:INFO: Dataset: zara1               Batch: 4/8	Loss 167.0621 (164.8699)
2022-11-25 20:56:37,108:INFO: Dataset: zara1               Batch: 5/8	Loss 164.7992 (164.8558)
2022-11-25 20:56:37,613:INFO: Dataset: zara1               Batch: 6/8	Loss 162.7486 (164.4638)
2022-11-25 20:56:38,193:INFO: Dataset: zara1               Batch: 7/8	Loss 163.1865 (164.2960)
2022-11-25 20:56:38,674:INFO: Dataset: zara1               Batch: 8/8	Loss 140.1779 (161.5415)
2022-11-25 20:56:39,490:INFO: Dataset: zara2               Batch:  1/18	Loss 157.0522 (157.0522)
2022-11-25 20:56:40,003:INFO: Dataset: zara2               Batch:  2/18	Loss 158.2937 (157.6212)
2022-11-25 20:56:40,511:INFO: Dataset: zara2               Batch:  3/18	Loss 156.9097 (157.3784)
2022-11-25 20:56:41,020:INFO: Dataset: zara2               Batch:  4/18	Loss 157.2721 (157.3545)
2022-11-25 20:56:41,530:INFO: Dataset: zara2               Batch:  5/18	Loss 156.9442 (157.2792)
2022-11-25 20:56:42,041:INFO: Dataset: zara2               Batch:  6/18	Loss 156.0903 (157.0899)
2022-11-25 20:56:42,551:INFO: Dataset: zara2               Batch:  7/18	Loss 156.7672 (157.0411)
2022-11-25 20:56:43,061:INFO: Dataset: zara2               Batch:  8/18	Loss 156.0042 (156.9150)
2022-11-25 20:56:43,568:INFO: Dataset: zara2               Batch:  9/18	Loss 158.9070 (157.1401)
2022-11-25 20:56:44,077:INFO: Dataset: zara2               Batch: 10/18	Loss 156.8023 (157.1102)
2022-11-25 20:56:44,586:INFO: Dataset: zara2               Batch: 11/18	Loss 157.4700 (157.1444)
2022-11-25 20:56:45,100:INFO: Dataset: zara2               Batch: 12/18	Loss 156.7577 (157.1146)
2022-11-25 20:56:45,611:INFO: Dataset: zara2               Batch: 13/18	Loss 156.6021 (157.0776)
2022-11-25 20:56:46,121:INFO: Dataset: zara2               Batch: 14/18	Loss 156.7317 (157.0516)
2022-11-25 20:56:46,630:INFO: Dataset: zara2               Batch: 15/18	Loss 157.4248 (157.0757)
2022-11-25 20:56:47,139:INFO: Dataset: zara2               Batch: 16/18	Loss 156.7090 (157.0534)
2022-11-25 20:56:47,649:INFO: Dataset: zara2               Batch: 17/18	Loss 156.9367 (157.0467)
2022-11-25 20:56:48,146:INFO: Dataset: zara2               Batch: 18/18	Loss 134.4498 (155.9148)
2022-11-25 20:56:48,210:INFO: - Computing ADE (validation)
2022-11-25 20:56:48,581:INFO: 		 ADE on hotel                     dataset:	 2.8139681816101074
2022-11-25 20:56:49,030:INFO: 		 ADE on univ                      dataset:	 3.515704870223999
2022-11-25 20:56:49,394:INFO: 		 ADE on zara1                     dataset:	 2.917752504348755
2022-11-25 20:56:49,962:INFO: 		 ADE on zara2                     dataset:	 3.0582501888275146
2022-11-25 20:56:49,962:INFO: Average validation:	ADE  3.2747	FDE  4.6442
2022-11-25 20:56:49,963:INFO: - Computing ADE (validation o)
2022-11-25 20:56:50,273:INFO: 		 ADE on eth                       dataset:	 3.0403687953948975
2022-11-25 20:56:50,273:INFO: Average validation o:	ADE  3.0404	FDE  4.0654
2022-11-25 20:56:50,282:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_280.pth.tar
2022-11-25 20:56:50,282:INFO: 
===> EPOCH: 281 (P3)
2022-11-25 20:56:50,283:INFO: - Computing loss (training)
2022-11-25 20:56:51,006:INFO: Dataset: hotel               Batch: 1/4	Loss 169.5345 (169.5345)
2022-11-25 20:56:51,507:INFO: Dataset: hotel               Batch: 2/4	Loss 176.5192 (172.9924)
2022-11-25 20:56:52,001:INFO: Dataset: hotel               Batch: 3/4	Loss 168.0854 (171.2578)
2022-11-25 20:56:52,457:INFO: Dataset: hotel               Batch: 4/4	Loss 103.9041 (159.7064)
2022-11-25 20:56:53,279:INFO: Dataset: univ                Batch:  1/15	Loss 173.4518 (173.4518)
2022-11-25 20:56:53,818:INFO: Dataset: univ                Batch:  2/15	Loss 165.2867 (169.3679)
2022-11-25 20:56:54,359:INFO: Dataset: univ                Batch:  3/15	Loss 159.3851 (166.0744)
2022-11-25 20:56:54,907:INFO: Dataset: univ                Batch:  4/15	Loss 157.4410 (163.8580)
2022-11-25 20:56:55,445:INFO: Dataset: univ                Batch:  5/15	Loss 156.4866 (162.4491)
2022-11-25 20:56:55,978:INFO: Dataset: univ                Batch:  6/15	Loss 155.9212 (161.4986)
2022-11-25 20:56:56,520:INFO: Dataset: univ                Batch:  7/15	Loss 155.7030 (160.6446)
2022-11-25 20:56:57,055:INFO: Dataset: univ                Batch:  8/15	Loss 157.5993 (160.2746)
2022-11-25 20:56:57,595:INFO: Dataset: univ                Batch:  9/15	Loss 157.6345 (159.9825)
2022-11-25 20:56:58,132:INFO: Dataset: univ                Batch: 10/15	Loss 156.1788 (159.6056)
2022-11-25 20:56:58,668:INFO: Dataset: univ                Batch: 11/15	Loss 156.3171 (159.3037)
2022-11-25 20:56:59,214:INFO: Dataset: univ                Batch: 12/15	Loss 156.2841 (159.0328)
2022-11-25 20:56:59,746:INFO: Dataset: univ                Batch: 13/15	Loss 158.2292 (158.9746)
2022-11-25 20:57:00,285:INFO: Dataset: univ                Batch: 14/15	Loss 157.7367 (158.8886)
2022-11-25 20:57:00,720:INFO: Dataset: univ                Batch: 15/15	Loss 29.4705 (157.2450)
2022-11-25 20:57:01,517:INFO: Dataset: zara1               Batch: 1/8	Loss 162.9354 (162.9354)
2022-11-25 20:57:02,010:INFO: Dataset: zara1               Batch: 2/8	Loss 162.3390 (162.6326)
2022-11-25 20:57:02,516:INFO: Dataset: zara1               Batch: 3/8	Loss 162.3397 (162.5258)
2022-11-25 20:57:03,020:INFO: Dataset: zara1               Batch: 4/8	Loss 162.0001 (162.3841)
2022-11-25 20:57:03,513:INFO: Dataset: zara1               Batch: 5/8	Loss 162.0485 (162.3210)
2022-11-25 20:57:04,006:INFO: Dataset: zara1               Batch: 6/8	Loss 164.1669 (162.6250)
2022-11-25 20:57:04,497:INFO: Dataset: zara1               Batch: 7/8	Loss 162.9110 (162.6634)
2022-11-25 20:57:04,974:INFO: Dataset: zara1               Batch: 8/8	Loss 140.4603 (159.8822)
2022-11-25 20:57:05,803:INFO: Dataset: zara2               Batch:  1/18	Loss 159.8510 (159.8510)
2022-11-25 20:57:06,318:INFO: Dataset: zara2               Batch:  2/18	Loss 159.4393 (159.6439)
2022-11-25 20:57:06,827:INFO: Dataset: zara2               Batch:  3/18	Loss 159.7928 (159.6949)
2022-11-25 20:57:07,339:INFO: Dataset: zara2               Batch:  4/18	Loss 158.7761 (159.4651)
2022-11-25 20:57:07,847:INFO: Dataset: zara2               Batch:  5/18	Loss 157.5633 (159.0702)
2022-11-25 20:57:08,358:INFO: Dataset: zara2               Batch:  6/18	Loss 157.8232 (158.8644)
2022-11-25 20:57:08,867:INFO: Dataset: zara2               Batch:  7/18	Loss 156.4169 (158.5124)
2022-11-25 20:57:09,462:INFO: Dataset: zara2               Batch:  8/18	Loss 155.5685 (158.1423)
2022-11-25 20:57:09,971:INFO: Dataset: zara2               Batch:  9/18	Loss 155.8638 (157.8971)
2022-11-25 20:57:10,481:INFO: Dataset: zara2               Batch: 10/18	Loss 154.7144 (157.5676)
2022-11-25 20:57:10,992:INFO: Dataset: zara2               Batch: 11/18	Loss 155.1217 (157.3518)
2022-11-25 20:57:11,500:INFO: Dataset: zara2               Batch: 12/18	Loss 155.9434 (157.2269)
2022-11-25 20:57:12,010:INFO: Dataset: zara2               Batch: 13/18	Loss 155.4350 (157.0943)
2022-11-25 20:57:12,522:INFO: Dataset: zara2               Batch: 14/18	Loss 156.2537 (157.0380)
2022-11-25 20:57:13,032:INFO: Dataset: zara2               Batch: 15/18	Loss 156.6996 (157.0140)
2022-11-25 20:57:13,541:INFO: Dataset: zara2               Batch: 16/18	Loss 155.4413 (156.9157)
2022-11-25 20:57:14,052:INFO: Dataset: zara2               Batch: 17/18	Loss 154.9274 (156.8061)
2022-11-25 20:57:14,548:INFO: Dataset: zara2               Batch: 18/18	Loss 133.8020 (155.7489)
2022-11-25 20:57:14,609:INFO: - Computing ADE (validation)
2022-11-25 20:57:14,987:INFO: 		 ADE on hotel                     dataset:	 2.7899081707000732
2022-11-25 20:57:15,431:INFO: 		 ADE on univ                      dataset:	 3.4590003490448
2022-11-25 20:57:15,784:INFO: 		 ADE on zara1                     dataset:	 2.8969714641571045
2022-11-25 20:57:16,343:INFO: 		 ADE on zara2                     dataset:	 3.024434804916382
2022-11-25 20:57:16,344:INFO: Average validation:	ADE  3.2303	FDE  4.5153
2022-11-25 20:57:16,344:INFO: - Computing ADE (validation o)
2022-11-25 20:57:16,649:INFO: 		 ADE on eth                       dataset:	 3.0355424880981445
2022-11-25 20:57:16,650:INFO: Average validation o:	ADE  3.0355	FDE  4.2483
2022-11-25 20:57:16,658:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_281.pth.tar
2022-11-25 20:57:16,658:INFO: 
===> EPOCH: 282 (P3)
2022-11-25 20:57:16,659:INFO: - Computing loss (training)
2022-11-25 20:57:17,390:INFO: Dataset: hotel               Batch: 1/4	Loss 172.6379 (172.6379)
2022-11-25 20:57:17,883:INFO: Dataset: hotel               Batch: 2/4	Loss 174.2386 (173.4196)
2022-11-25 20:57:18,370:INFO: Dataset: hotel               Batch: 3/4	Loss 167.5791 (171.5974)
2022-11-25 20:57:18,822:INFO: Dataset: hotel               Batch: 4/4	Loss 102.9850 (159.5585)
2022-11-25 20:57:19,662:INFO: Dataset: univ                Batch:  1/15	Loss 157.9891 (157.9891)
2022-11-25 20:57:20,191:INFO: Dataset: univ                Batch:  2/15	Loss 155.7615 (156.9722)
2022-11-25 20:57:20,729:INFO: Dataset: univ                Batch:  3/15	Loss 155.1077 (156.3318)
2022-11-25 20:57:21,265:INFO: Dataset: univ                Batch:  4/15	Loss 155.8317 (156.2060)
2022-11-25 20:57:21,811:INFO: Dataset: univ                Batch:  5/15	Loss 154.3299 (155.7992)
2022-11-25 20:57:22,349:INFO: Dataset: univ                Batch:  6/15	Loss 156.1316 (155.8534)
2022-11-25 20:57:22,875:INFO: Dataset: univ                Batch:  7/15	Loss 155.0771 (155.7517)
2022-11-25 20:57:23,422:INFO: Dataset: univ                Batch:  8/15	Loss 155.0059 (155.6468)
2022-11-25 20:57:23,956:INFO: Dataset: univ                Batch:  9/15	Loss 155.5641 (155.6377)
2022-11-25 20:57:24,500:INFO: Dataset: univ                Batch: 10/15	Loss 153.6548 (155.4237)
2022-11-25 20:57:25,043:INFO: Dataset: univ                Batch: 11/15	Loss 154.3517 (155.3201)
2022-11-25 20:57:25,583:INFO: Dataset: univ                Batch: 12/15	Loss 154.8362 (155.2816)
2022-11-25 20:57:26,115:INFO: Dataset: univ                Batch: 13/15	Loss 154.8935 (155.2526)
2022-11-25 20:57:26,646:INFO: Dataset: univ                Batch: 14/15	Loss 154.0458 (155.1725)
2022-11-25 20:57:27,082:INFO: Dataset: univ                Batch: 15/15	Loss 28.7950 (153.3638)
2022-11-25 20:57:27,879:INFO: Dataset: zara1               Batch: 1/8	Loss 162.1583 (162.1583)
2022-11-25 20:57:28,371:INFO: Dataset: zara1               Batch: 2/8	Loss 159.6759 (160.8698)
2022-11-25 20:57:28,873:INFO: Dataset: zara1               Batch: 3/8	Loss 163.0537 (161.6775)
2022-11-25 20:57:29,368:INFO: Dataset: zara1               Batch: 4/8	Loss 163.8614 (162.2141)
2022-11-25 20:57:29,858:INFO: Dataset: zara1               Batch: 5/8	Loss 159.9647 (161.7822)
2022-11-25 20:57:30,351:INFO: Dataset: zara1               Batch: 6/8	Loss 159.9951 (161.4781)
2022-11-25 20:57:30,843:INFO: Dataset: zara1               Batch: 7/8	Loss 158.7586 (161.1139)
2022-11-25 20:57:31,322:INFO: Dataset: zara1               Batch: 8/8	Loss 136.6539 (158.6679)
2022-11-25 20:57:32,141:INFO: Dataset: zara2               Batch:  1/18	Loss 154.9231 (154.9231)
2022-11-25 20:57:32,652:INFO: Dataset: zara2               Batch:  2/18	Loss 153.3445 (154.1327)
2022-11-25 20:57:33,164:INFO: Dataset: zara2               Batch:  3/18	Loss 153.1626 (153.7983)
2022-11-25 20:57:33,673:INFO: Dataset: zara2               Batch:  4/18	Loss 155.4842 (154.1824)
2022-11-25 20:57:34,182:INFO: Dataset: zara2               Batch:  5/18	Loss 155.0299 (154.3357)
2022-11-25 20:57:34,695:INFO: Dataset: zara2               Batch:  6/18	Loss 154.4630 (154.3540)
2022-11-25 20:57:35,204:INFO: Dataset: zara2               Batch:  7/18	Loss 154.0120 (154.3068)
2022-11-25 20:57:35,711:INFO: Dataset: zara2               Batch:  8/18	Loss 155.1263 (154.4065)
2022-11-25 20:57:36,217:INFO: Dataset: zara2               Batch:  9/18	Loss 154.2731 (154.3931)
2022-11-25 20:57:36,722:INFO: Dataset: zara2               Batch: 10/18	Loss 153.6436 (154.3096)
2022-11-25 20:57:37,227:INFO: Dataset: zara2               Batch: 11/18	Loss 154.2735 (154.3063)
2022-11-25 20:57:37,734:INFO: Dataset: zara2               Batch: 12/18	Loss 154.2651 (154.3030)
2022-11-25 20:57:38,237:INFO: Dataset: zara2               Batch: 13/18	Loss 153.6711 (154.2491)
2022-11-25 20:57:38,741:INFO: Dataset: zara2               Batch: 14/18	Loss 153.8676 (154.2207)
2022-11-25 20:57:39,248:INFO: Dataset: zara2               Batch: 15/18	Loss 153.4819 (154.1705)
2022-11-25 20:57:39,753:INFO: Dataset: zara2               Batch: 16/18	Loss 155.7251 (154.2678)
2022-11-25 20:57:40,342:INFO: Dataset: zara2               Batch: 17/18	Loss 153.2950 (154.2067)
2022-11-25 20:57:40,834:INFO: Dataset: zara2               Batch: 18/18	Loss 132.8626 (153.0917)
2022-11-25 20:57:40,899:INFO: - Computing ADE (validation)
2022-11-25 20:57:41,261:INFO: 		 ADE on hotel                     dataset:	 2.7764170169830322
2022-11-25 20:57:41,701:INFO: 		 ADE on univ                      dataset:	 3.4979522228240967
2022-11-25 20:57:42,063:INFO: 		 ADE on zara1                     dataset:	 2.901393175125122
2022-11-25 20:57:42,609:INFO: 		 ADE on zara2                     dataset:	 3.011739492416382
2022-11-25 20:57:42,609:INFO: Average validation:	ADE  3.2454	FDE  4.5796
2022-11-25 20:57:42,610:INFO: - Computing ADE (validation o)
2022-11-25 20:57:42,914:INFO: 		 ADE on eth                       dataset:	 2.954941511154175
2022-11-25 20:57:42,914:INFO: Average validation o:	ADE  2.9549	FDE  3.6587
2022-11-25 20:57:42,923:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_282.pth.tar
2022-11-25 20:57:42,923:INFO: 
===> EPOCH: 283 (P3)
2022-11-25 20:57:42,923:INFO: - Computing loss (training)
2022-11-25 20:57:43,638:INFO: Dataset: hotel               Batch: 1/4	Loss 178.9151 (178.9151)
2022-11-25 20:57:44,131:INFO: Dataset: hotel               Batch: 2/4	Loss 173.8748 (176.3583)
2022-11-25 20:57:44,618:INFO: Dataset: hotel               Batch: 3/4	Loss 172.0409 (174.8688)
2022-11-25 20:57:45,070:INFO: Dataset: hotel               Batch: 4/4	Loss 99.0201 (161.9605)
2022-11-25 20:57:45,924:INFO: Dataset: univ                Batch:  1/15	Loss 153.5702 (153.5702)
2022-11-25 20:57:46,466:INFO: Dataset: univ                Batch:  2/15	Loss 153.5656 (153.5680)
2022-11-25 20:57:46,998:INFO: Dataset: univ                Batch:  3/15	Loss 153.6936 (153.6063)
2022-11-25 20:57:47,543:INFO: Dataset: univ                Batch:  4/15	Loss 153.7854 (153.6524)
2022-11-25 20:57:48,081:INFO: Dataset: univ                Batch:  5/15	Loss 153.9992 (153.7193)
2022-11-25 20:57:48,619:INFO: Dataset: univ                Batch:  6/15	Loss 153.9174 (153.7505)
2022-11-25 20:57:49,148:INFO: Dataset: univ                Batch:  7/15	Loss 154.7851 (153.8834)
2022-11-25 20:57:49,685:INFO: Dataset: univ                Batch:  8/15	Loss 160.8698 (154.7296)
2022-11-25 20:57:50,224:INFO: Dataset: univ                Batch:  9/15	Loss 155.8106 (154.8543)
2022-11-25 20:57:50,757:INFO: Dataset: univ                Batch: 10/15	Loss 153.7560 (154.7510)
2022-11-25 20:57:51,293:INFO: Dataset: univ                Batch: 11/15	Loss 153.6764 (154.6551)
2022-11-25 20:57:51,827:INFO: Dataset: univ                Batch: 12/15	Loss 154.0909 (154.6117)
2022-11-25 20:57:52,372:INFO: Dataset: univ                Batch: 13/15	Loss 153.0668 (154.4835)
2022-11-25 20:57:52,908:INFO: Dataset: univ                Batch: 14/15	Loss 158.1581 (154.7400)
2022-11-25 20:57:53,343:INFO: Dataset: univ                Batch: 15/15	Loss 28.5637 (152.9462)
2022-11-25 20:57:54,150:INFO: Dataset: zara1               Batch: 1/8	Loss 163.1660 (163.1660)
2022-11-25 20:57:54,643:INFO: Dataset: zara1               Batch: 2/8	Loss 163.1922 (163.1775)
2022-11-25 20:57:55,134:INFO: Dataset: zara1               Batch: 3/8	Loss 159.9600 (162.1759)
2022-11-25 20:57:55,638:INFO: Dataset: zara1               Batch: 4/8	Loss 161.7394 (162.0556)
2022-11-25 20:57:56,141:INFO: Dataset: zara1               Batch: 5/8	Loss 160.5589 (161.7284)
2022-11-25 20:57:56,634:INFO: Dataset: zara1               Batch: 6/8	Loss 159.7153 (161.4112)
2022-11-25 20:57:57,125:INFO: Dataset: zara1               Batch: 7/8	Loss 158.6544 (161.0317)
2022-11-25 20:57:57,608:INFO: Dataset: zara1               Batch: 8/8	Loss 136.0410 (157.8223)
2022-11-25 20:57:58,405:INFO: Dataset: zara2               Batch:  1/18	Loss 153.0121 (153.0121)
2022-11-25 20:57:58,923:INFO: Dataset: zara2               Batch:  2/18	Loss 152.9680 (152.9921)
2022-11-25 20:57:59,425:INFO: Dataset: zara2               Batch:  3/18	Loss 153.6472 (153.2164)
2022-11-25 20:57:59,932:INFO: Dataset: zara2               Batch:  4/18	Loss 153.5692 (153.3063)
2022-11-25 20:58:00,436:INFO: Dataset: zara2               Batch:  5/18	Loss 152.9205 (153.2292)
2022-11-25 20:58:00,945:INFO: Dataset: zara2               Batch:  6/18	Loss 153.2027 (153.2252)
2022-11-25 20:58:01,449:INFO: Dataset: zara2               Batch:  7/18	Loss 153.5838 (153.2769)
2022-11-25 20:58:01,951:INFO: Dataset: zara2               Batch:  8/18	Loss 153.7906 (153.3400)
2022-11-25 20:58:02,454:INFO: Dataset: zara2               Batch:  9/18	Loss 153.8070 (153.3871)
2022-11-25 20:58:02,957:INFO: Dataset: zara2               Batch: 10/18	Loss 154.4437 (153.5066)
2022-11-25 20:58:03,460:INFO: Dataset: zara2               Batch: 11/18	Loss 152.6769 (153.4242)
2022-11-25 20:58:03,963:INFO: Dataset: zara2               Batch: 12/18	Loss 153.2228 (153.4065)
2022-11-25 20:58:04,466:INFO: Dataset: zara2               Batch: 13/18	Loss 153.8024 (153.4413)
2022-11-25 20:58:04,969:INFO: Dataset: zara2               Batch: 14/18	Loss 153.4907 (153.4449)
2022-11-25 20:58:05,473:INFO: Dataset: zara2               Batch: 15/18	Loss 153.3572 (153.4396)
2022-11-25 20:58:05,977:INFO: Dataset: zara2               Batch: 16/18	Loss 153.1938 (153.4243)
2022-11-25 20:58:06,481:INFO: Dataset: zara2               Batch: 17/18	Loss 154.0158 (153.4607)
2022-11-25 20:58:06,972:INFO: Dataset: zara2               Batch: 18/18	Loss 130.8499 (152.2645)
2022-11-25 20:58:07,037:INFO: - Computing ADE (validation)
2022-11-25 20:58:07,402:INFO: 		 ADE on hotel                     dataset:	 2.721130847930908
2022-11-25 20:58:07,842:INFO: 		 ADE on univ                      dataset:	 3.5475707054138184
2022-11-25 20:58:08,197:INFO: 		 ADE on zara1                     dataset:	 2.878131628036499
2022-11-25 20:58:08,750:INFO: 		 ADE on zara2                     dataset:	 3.0354108810424805
2022-11-25 20:58:08,750:INFO: Average validation:	ADE  3.2755	FDE  4.7199
2022-11-25 20:58:08,751:INFO: - Computing ADE (validation o)
2022-11-25 20:58:09,058:INFO: 		 ADE on eth                       dataset:	 3.0807693004608154
2022-11-25 20:58:09,058:INFO: Average validation o:	ADE  3.0808	FDE  3.9089
2022-11-25 20:58:09,067:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_283.pth.tar
2022-11-25 20:58:09,067:INFO: 
===> EPOCH: 284 (P3)
2022-11-25 20:58:09,067:INFO: - Computing loss (training)
2022-11-25 20:58:09,786:INFO: Dataset: hotel               Batch: 1/4	Loss 161.0720 (161.0720)
2022-11-25 20:58:10,285:INFO: Dataset: hotel               Batch: 2/4	Loss 166.4068 (163.7268)
2022-11-25 20:58:10,775:INFO: Dataset: hotel               Batch: 3/4	Loss 162.7659 (163.4147)
2022-11-25 20:58:11,226:INFO: Dataset: hotel               Batch: 4/4	Loss 112.5313 (154.6880)
2022-11-25 20:58:12,195:INFO: Dataset: univ                Batch:  1/15	Loss 158.8183 (158.8183)
2022-11-25 20:58:12,740:INFO: Dataset: univ                Batch:  2/15	Loss 157.7215 (158.2482)
2022-11-25 20:58:13,285:INFO: Dataset: univ                Batch:  3/15	Loss 155.6560 (157.3371)
2022-11-25 20:58:13,817:INFO: Dataset: univ                Batch:  4/15	Loss 157.2048 (157.3061)
2022-11-25 20:58:14,360:INFO: Dataset: univ                Batch:  5/15	Loss 153.3309 (156.4806)
2022-11-25 20:58:14,893:INFO: Dataset: univ                Batch:  6/15	Loss 156.1727 (156.4374)
2022-11-25 20:58:15,435:INFO: Dataset: univ                Batch:  7/15	Loss 152.7754 (155.8948)
2022-11-25 20:58:15,971:INFO: Dataset: univ                Batch:  8/15	Loss 152.5802 (155.4958)
2022-11-25 20:58:16,504:INFO: Dataset: univ                Batch:  9/15	Loss 154.5448 (155.3929)
2022-11-25 20:58:17,052:INFO: Dataset: univ                Batch: 10/15	Loss 152.2394 (155.0379)
2022-11-25 20:58:17,588:INFO: Dataset: univ                Batch: 11/15	Loss 152.2942 (154.7813)
2022-11-25 20:58:18,124:INFO: Dataset: univ                Batch: 12/15	Loss 152.7418 (154.6132)
2022-11-25 20:58:18,652:INFO: Dataset: univ                Batch: 13/15	Loss 153.1712 (154.5150)
2022-11-25 20:58:19,181:INFO: Dataset: univ                Batch: 14/15	Loss 153.1108 (154.4234)
2022-11-25 20:58:19,615:INFO: Dataset: univ                Batch: 15/15	Loss 29.0868 (152.8137)
2022-11-25 20:58:20,407:INFO: Dataset: zara1               Batch: 1/8	Loss 159.6071 (159.6071)
2022-11-25 20:58:20,900:INFO: Dataset: zara1               Batch: 2/8	Loss 161.1753 (160.4090)
2022-11-25 20:58:21,394:INFO: Dataset: zara1               Batch: 3/8	Loss 158.2908 (159.6981)
2022-11-25 20:58:21,888:INFO: Dataset: zara1               Batch: 4/8	Loss 157.6714 (159.1935)
2022-11-25 20:58:22,379:INFO: Dataset: zara1               Batch: 5/8	Loss 158.4996 (159.0565)
2022-11-25 20:58:22,874:INFO: Dataset: zara1               Batch: 6/8	Loss 159.2422 (159.0830)
2022-11-25 20:58:23,377:INFO: Dataset: zara1               Batch: 7/8	Loss 156.8459 (158.7161)
2022-11-25 20:58:23,856:INFO: Dataset: zara1               Batch: 8/8	Loss 135.9266 (156.1852)
2022-11-25 20:58:24,680:INFO: Dataset: zara2               Batch:  1/18	Loss 160.7764 (160.7764)
2022-11-25 20:58:25,200:INFO: Dataset: zara2               Batch:  2/18	Loss 160.0588 (160.3976)
2022-11-25 20:58:25,704:INFO: Dataset: zara2               Batch:  3/18	Loss 157.3687 (159.4088)
2022-11-25 20:58:26,209:INFO: Dataset: zara2               Batch:  4/18	Loss 158.2447 (159.1041)
2022-11-25 20:58:26,718:INFO: Dataset: zara2               Batch:  5/18	Loss 153.6168 (158.1969)
2022-11-25 20:58:27,225:INFO: Dataset: zara2               Batch:  6/18	Loss 153.4630 (157.4521)
2022-11-25 20:58:27,736:INFO: Dataset: zara2               Batch:  7/18	Loss 151.5821 (156.6329)
2022-11-25 20:58:28,241:INFO: Dataset: zara2               Batch:  8/18	Loss 152.8316 (156.2235)
2022-11-25 20:58:28,744:INFO: Dataset: zara2               Batch:  9/18	Loss 152.4587 (155.8088)
2022-11-25 20:58:29,248:INFO: Dataset: zara2               Batch: 10/18	Loss 152.3582 (155.4918)
2022-11-25 20:58:29,751:INFO: Dataset: zara2               Batch: 11/18	Loss 152.2275 (155.1917)
2022-11-25 20:58:30,255:INFO: Dataset: zara2               Batch: 12/18	Loss 154.5939 (155.1401)
2022-11-25 20:58:30,758:INFO: Dataset: zara2               Batch: 13/18	Loss 155.5814 (155.1732)
2022-11-25 20:58:31,260:INFO: Dataset: zara2               Batch: 14/18	Loss 153.8244 (155.0743)
2022-11-25 20:58:31,763:INFO: Dataset: zara2               Batch: 15/18	Loss 154.3091 (155.0182)
2022-11-25 20:58:32,266:INFO: Dataset: zara2               Batch: 16/18	Loss 153.3354 (154.9047)
2022-11-25 20:58:32,769:INFO: Dataset: zara2               Batch: 17/18	Loss 152.7520 (154.7600)
2022-11-25 20:58:33,260:INFO: Dataset: zara2               Batch: 18/18	Loss 132.0349 (153.7156)
2022-11-25 20:58:33,324:INFO: - Computing ADE (validation)
2022-11-25 20:58:33,694:INFO: 		 ADE on hotel                     dataset:	 2.7545459270477295
2022-11-25 20:58:34,132:INFO: 		 ADE on univ                      dataset:	 3.5167880058288574
2022-11-25 20:58:34,491:INFO: 		 ADE on zara1                     dataset:	 2.988285541534424
2022-11-25 20:58:35,048:INFO: 		 ADE on zara2                     dataset:	 3.021670341491699
2022-11-25 20:58:35,048:INFO: Average validation:	ADE  3.2627	FDE  4.7207
2022-11-25 20:58:35,049:INFO: - Computing ADE (validation o)
2022-11-25 20:58:35,361:INFO: 		 ADE on eth                       dataset:	 3.0733370780944824
2022-11-25 20:58:35,361:INFO: Average validation o:	ADE  3.0733	FDE  4.0985
2022-11-25 20:58:35,370:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_284.pth.tar
2022-11-25 20:58:35,370:INFO: 
===> EPOCH: 285 (P3)
2022-11-25 20:58:35,370:INFO: - Computing loss (training)
2022-11-25 20:58:36,099:INFO: Dataset: hotel               Batch: 1/4	Loss 160.4534 (160.4534)
2022-11-25 20:58:36,593:INFO: Dataset: hotel               Batch: 2/4	Loss 168.6930 (164.7412)
2022-11-25 20:58:37,079:INFO: Dataset: hotel               Batch: 3/4	Loss 164.9419 (164.8092)
2022-11-25 20:58:37,516:INFO: Dataset: hotel               Batch: 4/4	Loss 98.0632 (153.6262)
2022-11-25 20:58:38,363:INFO: Dataset: univ                Batch:  1/15	Loss 155.7784 (155.7784)
2022-11-25 20:58:38,903:INFO: Dataset: univ                Batch:  2/15	Loss 154.2368 (155.0522)
2022-11-25 20:58:39,441:INFO: Dataset: univ                Batch:  3/15	Loss 153.1760 (154.4549)
2022-11-25 20:58:39,972:INFO: Dataset: univ                Batch:  4/15	Loss 153.8120 (154.3067)
2022-11-25 20:58:40,526:INFO: Dataset: univ                Batch:  5/15	Loss 152.4161 (153.8654)
2022-11-25 20:58:41,073:INFO: Dataset: univ                Batch:  6/15	Loss 157.6145 (154.4933)
2022-11-25 20:58:41,613:INFO: Dataset: univ                Batch:  7/15	Loss 153.1920 (154.3005)
2022-11-25 20:58:42,159:INFO: Dataset: univ                Batch:  8/15	Loss 150.6876 (153.8205)
2022-11-25 20:58:42,690:INFO: Dataset: univ                Batch:  9/15	Loss 157.3668 (154.1543)
2022-11-25 20:58:43,310:INFO: Dataset: univ                Batch: 10/15	Loss 150.8967 (153.8370)
2022-11-25 20:58:43,845:INFO: Dataset: univ                Batch: 11/15	Loss 151.8975 (153.6683)
2022-11-25 20:58:44,389:INFO: Dataset: univ                Batch: 12/15	Loss 150.7928 (153.4190)
2022-11-25 20:58:44,926:INFO: Dataset: univ                Batch: 13/15	Loss 151.5363 (153.2731)
2022-11-25 20:58:45,468:INFO: Dataset: univ                Batch: 14/15	Loss 152.3108 (153.2046)
2022-11-25 20:58:45,911:INFO: Dataset: univ                Batch: 15/15	Loss 29.1136 (151.4816)
2022-11-25 20:58:46,702:INFO: Dataset: zara1               Batch: 1/8	Loss 156.2480 (156.2480)
2022-11-25 20:58:47,198:INFO: Dataset: zara1               Batch: 2/8	Loss 157.3520 (156.8103)
2022-11-25 20:58:47,696:INFO: Dataset: zara1               Batch: 3/8	Loss 156.6807 (156.7655)
2022-11-25 20:58:48,194:INFO: Dataset: zara1               Batch: 4/8	Loss 158.1068 (157.0853)
2022-11-25 20:58:48,692:INFO: Dataset: zara1               Batch: 5/8	Loss 154.9949 (156.6552)
2022-11-25 20:58:49,188:INFO: Dataset: zara1               Batch: 6/8	Loss 155.7159 (156.5122)
2022-11-25 20:58:49,695:INFO: Dataset: zara1               Batch: 7/8	Loss 155.8290 (156.4050)
2022-11-25 20:58:50,178:INFO: Dataset: zara1               Batch: 8/8	Loss 133.8808 (154.1170)
2022-11-25 20:58:50,987:INFO: Dataset: zara2               Batch:  1/18	Loss 153.7910 (153.7910)
2022-11-25 20:58:51,512:INFO: Dataset: zara2               Batch:  2/18	Loss 154.6893 (154.2429)
2022-11-25 20:58:52,018:INFO: Dataset: zara2               Batch:  3/18	Loss 152.4650 (153.5850)
2022-11-25 20:58:52,524:INFO: Dataset: zara2               Batch:  4/18	Loss 151.6236 (153.0968)
2022-11-25 20:58:53,031:INFO: Dataset: zara2               Batch:  5/18	Loss 153.8267 (153.2378)
2022-11-25 20:58:53,540:INFO: Dataset: zara2               Batch:  6/18	Loss 155.6281 (153.6510)
2022-11-25 20:58:54,048:INFO: Dataset: zara2               Batch:  7/18	Loss 151.3099 (153.3167)
2022-11-25 20:58:54,552:INFO: Dataset: zara2               Batch:  8/18	Loss 150.4241 (152.9406)
2022-11-25 20:58:55,057:INFO: Dataset: zara2               Batch:  9/18	Loss 150.5108 (152.6742)
2022-11-25 20:58:55,562:INFO: Dataset: zara2               Batch: 10/18	Loss 150.7215 (152.4859)
2022-11-25 20:58:56,064:INFO: Dataset: zara2               Batch: 11/18	Loss 150.6658 (152.3157)
2022-11-25 20:58:56,570:INFO: Dataset: zara2               Batch: 12/18	Loss 150.6519 (152.1790)
2022-11-25 20:58:57,076:INFO: Dataset: zara2               Batch: 13/18	Loss 149.1632 (151.9656)
2022-11-25 20:58:57,586:INFO: Dataset: zara2               Batch: 14/18	Loss 150.3579 (151.8590)
2022-11-25 20:58:58,093:INFO: Dataset: zara2               Batch: 15/18	Loss 150.3510 (151.7673)
2022-11-25 20:58:58,598:INFO: Dataset: zara2               Batch: 16/18	Loss 150.9259 (151.7121)
2022-11-25 20:58:59,104:INFO: Dataset: zara2               Batch: 17/18	Loss 151.3730 (151.6931)
2022-11-25 20:58:59,597:INFO: Dataset: zara2               Batch: 18/18	Loss 130.9137 (150.6866)
2022-11-25 20:58:59,660:INFO: - Computing ADE (validation)
2022-11-25 20:59:00,027:INFO: 		 ADE on hotel                     dataset:	 2.7064368724823
2022-11-25 20:59:00,464:INFO: 		 ADE on univ                      dataset:	 3.398285388946533
2022-11-25 20:59:00,822:INFO: 		 ADE on zara1                     dataset:	 2.8513917922973633
2022-11-25 20:59:01,378:INFO: 		 ADE on zara2                     dataset:	 3.008608341217041
2022-11-25 20:59:01,378:INFO: Average validation:	ADE  3.1857	FDE  4.5120
2022-11-25 20:59:01,379:INFO: - Computing ADE (validation o)
2022-11-25 20:59:01,694:INFO: 		 ADE on eth                       dataset:	 2.8989319801330566
2022-11-25 20:59:01,694:INFO: Average validation o:	ADE  2.8989	FDE  3.8198
2022-11-25 20:59:01,703:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_285.pth.tar
2022-11-25 20:59:01,703:INFO: 
===> EPOCH: 286 (P3)
2022-11-25 20:59:01,703:INFO: - Computing loss (training)
2022-11-25 20:59:02,428:INFO: Dataset: hotel               Batch: 1/4	Loss 160.8661 (160.8661)
2022-11-25 20:59:02,925:INFO: Dataset: hotel               Batch: 2/4	Loss 158.6156 (159.7543)
2022-11-25 20:59:03,418:INFO: Dataset: hotel               Batch: 3/4	Loss 158.3883 (159.2910)
2022-11-25 20:59:03,862:INFO: Dataset: hotel               Batch: 4/4	Loss 104.1013 (150.0442)
2022-11-25 20:59:04,706:INFO: Dataset: univ                Batch:  1/15	Loss 151.4185 (151.4185)
2022-11-25 20:59:05,243:INFO: Dataset: univ                Batch:  2/15	Loss 152.1720 (151.7952)
2022-11-25 20:59:05,781:INFO: Dataset: univ                Batch:  3/15	Loss 151.1181 (151.5608)
2022-11-25 20:59:06,314:INFO: Dataset: univ                Batch:  4/15	Loss 151.7756 (151.6156)
2022-11-25 20:59:06,847:INFO: Dataset: univ                Batch:  5/15	Loss 150.6973 (151.4438)
2022-11-25 20:59:07,407:INFO: Dataset: univ                Batch:  6/15	Loss 150.6856 (151.3103)
2022-11-25 20:59:07,941:INFO: Dataset: univ                Batch:  7/15	Loss 150.2952 (151.1615)
2022-11-25 20:59:08,487:INFO: Dataset: univ                Batch:  8/15	Loss 151.2542 (151.1745)
2022-11-25 20:59:09,033:INFO: Dataset: univ                Batch:  9/15	Loss 149.8329 (151.0107)
2022-11-25 20:59:09,577:INFO: Dataset: univ                Batch: 10/15	Loss 149.3275 (150.8297)
2022-11-25 20:59:10,125:INFO: Dataset: univ                Batch: 11/15	Loss 149.5465 (150.7007)
2022-11-25 20:59:10,661:INFO: Dataset: univ                Batch: 12/15	Loss 149.4619 (150.5997)
2022-11-25 20:59:11,197:INFO: Dataset: univ                Batch: 13/15	Loss 150.0787 (150.5587)
2022-11-25 20:59:11,734:INFO: Dataset: univ                Batch: 14/15	Loss 149.9277 (150.5149)
2022-11-25 20:59:12,170:INFO: Dataset: univ                Batch: 15/15	Loss 27.7393 (148.3913)
2022-11-25 20:59:12,955:INFO: Dataset: zara1               Batch: 1/8	Loss 153.8325 (153.8325)
2022-11-25 20:59:13,447:INFO: Dataset: zara1               Batch: 2/8	Loss 153.6910 (153.7587)
2022-11-25 20:59:13,937:INFO: Dataset: zara1               Batch: 3/8	Loss 155.2343 (154.2321)
2022-11-25 20:59:14,512:INFO: Dataset: zara1               Batch: 4/8	Loss 153.5925 (154.0663)
2022-11-25 20:59:15,002:INFO: Dataset: zara1               Batch: 5/8	Loss 153.3670 (153.9306)
2022-11-25 20:59:15,509:INFO: Dataset: zara1               Batch: 6/8	Loss 155.6718 (154.2472)
2022-11-25 20:59:16,001:INFO: Dataset: zara1               Batch: 7/8	Loss 154.9111 (154.3361)
2022-11-25 20:59:16,479:INFO: Dataset: zara1               Batch: 8/8	Loss 132.1948 (152.0288)
2022-11-25 20:59:17,300:INFO: Dataset: zara2               Batch:  1/18	Loss 149.5538 (149.5538)
2022-11-25 20:59:17,807:INFO: Dataset: zara2               Batch:  2/18	Loss 149.7325 (149.6400)
2022-11-25 20:59:18,320:INFO: Dataset: zara2               Batch:  3/18	Loss 149.2168 (149.5003)
2022-11-25 20:59:18,827:INFO: Dataset: zara2               Batch:  4/18	Loss 150.2903 (149.7161)
2022-11-25 20:59:19,333:INFO: Dataset: zara2               Batch:  5/18	Loss 148.2881 (149.4405)
2022-11-25 20:59:19,838:INFO: Dataset: zara2               Batch:  6/18	Loss 149.0243 (149.3683)
2022-11-25 20:59:20,339:INFO: Dataset: zara2               Batch:  7/18	Loss 150.3703 (149.5050)
2022-11-25 20:59:20,842:INFO: Dataset: zara2               Batch:  8/18	Loss 149.1307 (149.4606)
2022-11-25 20:59:21,345:INFO: Dataset: zara2               Batch:  9/18	Loss 148.9211 (149.4001)
2022-11-25 20:59:21,850:INFO: Dataset: zara2               Batch: 10/18	Loss 149.9809 (149.4559)
2022-11-25 20:59:22,353:INFO: Dataset: zara2               Batch: 11/18	Loss 148.8685 (149.3964)
2022-11-25 20:59:22,858:INFO: Dataset: zara2               Batch: 12/18	Loss 149.7921 (149.4276)
2022-11-25 20:59:23,361:INFO: Dataset: zara2               Batch: 13/18	Loss 150.6112 (149.5157)
2022-11-25 20:59:23,866:INFO: Dataset: zara2               Batch: 14/18	Loss 149.2860 (149.5005)
2022-11-25 20:59:24,371:INFO: Dataset: zara2               Batch: 15/18	Loss 148.1591 (149.4101)
2022-11-25 20:59:24,875:INFO: Dataset: zara2               Batch: 16/18	Loss 148.3849 (149.3451)
2022-11-25 20:59:25,378:INFO: Dataset: zara2               Batch: 17/18	Loss 148.3173 (149.2859)
2022-11-25 20:59:25,870:INFO: Dataset: zara2               Batch: 18/18	Loss 127.7553 (148.2857)
2022-11-25 20:59:25,931:INFO: - Computing ADE (validation)
2022-11-25 20:59:26,291:INFO: 		 ADE on hotel                     dataset:	 2.69199538230896
2022-11-25 20:59:26,733:INFO: 		 ADE on univ                      dataset:	 3.381716728210449
2022-11-25 20:59:27,087:INFO: 		 ADE on zara1                     dataset:	 2.877823829650879
2022-11-25 20:59:27,654:INFO: 		 ADE on zara2                     dataset:	 2.9465808868408203
2022-11-25 20:59:27,654:INFO: Average validation:	ADE  3.1550	FDE  4.4287
2022-11-25 20:59:27,655:INFO: - Computing ADE (validation o)
2022-11-25 20:59:27,966:INFO: 		 ADE on eth                       dataset:	 3.015720844268799
2022-11-25 20:59:27,966:INFO: Average validation o:	ADE  3.0157	FDE  4.2457
2022-11-25 20:59:27,975:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_286.pth.tar
2022-11-25 20:59:27,975:INFO: 
===> EPOCH: 287 (P3)
2022-11-25 20:59:27,975:INFO: - Computing loss (training)
2022-11-25 20:59:28,697:INFO: Dataset: hotel               Batch: 1/4	Loss 158.9751 (158.9751)
2022-11-25 20:59:29,194:INFO: Dataset: hotel               Batch: 2/4	Loss 153.9078 (156.4539)
2022-11-25 20:59:29,687:INFO: Dataset: hotel               Batch: 3/4	Loss 153.2158 (155.3330)
2022-11-25 20:59:30,142:INFO: Dataset: hotel               Batch: 4/4	Loss 94.0303 (144.4958)
2022-11-25 20:59:30,985:INFO: Dataset: univ                Batch:  1/15	Loss 149.8037 (149.8037)
2022-11-25 20:59:31,534:INFO: Dataset: univ                Batch:  2/15	Loss 148.6537 (149.1942)
2022-11-25 20:59:32,070:INFO: Dataset: univ                Batch:  3/15	Loss 150.1585 (149.5192)
2022-11-25 20:59:32,595:INFO: Dataset: univ                Batch:  4/15	Loss 150.8474 (149.8137)
2022-11-25 20:59:33,130:INFO: Dataset: univ                Batch:  5/15	Loss 147.9453 (149.4461)
2022-11-25 20:59:33,668:INFO: Dataset: univ                Batch:  6/15	Loss 148.2825 (149.2439)
2022-11-25 20:59:34,206:INFO: Dataset: univ                Batch:  7/15	Loss 148.5052 (149.1337)
2022-11-25 20:59:34,743:INFO: Dataset: univ                Batch:  8/15	Loss 148.3959 (149.0386)
2022-11-25 20:59:35,273:INFO: Dataset: univ                Batch:  9/15	Loss 148.9517 (149.0294)
2022-11-25 20:59:35,802:INFO: Dataset: univ                Batch: 10/15	Loss 148.0827 (148.9421)
2022-11-25 20:59:36,349:INFO: Dataset: univ                Batch: 11/15	Loss 148.2213 (148.8710)
2022-11-25 20:59:36,892:INFO: Dataset: univ                Batch: 12/15	Loss 147.8466 (148.7825)
2022-11-25 20:59:37,426:INFO: Dataset: univ                Batch: 13/15	Loss 148.1490 (148.7343)
2022-11-25 20:59:37,962:INFO: Dataset: univ                Batch: 14/15	Loss 148.6694 (148.7297)
2022-11-25 20:59:38,395:INFO: Dataset: univ                Batch: 15/15	Loss 27.7445 (146.8434)
2022-11-25 20:59:39,193:INFO: Dataset: zara1               Batch: 1/8	Loss 153.9240 (153.9240)
2022-11-25 20:59:39,688:INFO: Dataset: zara1               Batch: 2/8	Loss 151.9547 (152.9546)
2022-11-25 20:59:40,183:INFO: Dataset: zara1               Batch: 3/8	Loss 154.1976 (153.3635)
2022-11-25 20:59:40,676:INFO: Dataset: zara1               Batch: 4/8	Loss 152.7027 (153.2039)
2022-11-25 20:59:41,167:INFO: Dataset: zara1               Batch: 5/8	Loss 152.6477 (153.1036)
2022-11-25 20:59:41,672:INFO: Dataset: zara1               Batch: 6/8	Loss 151.7539 (152.9101)
2022-11-25 20:59:42,163:INFO: Dataset: zara1               Batch: 7/8	Loss 152.3141 (152.8243)
2022-11-25 20:59:42,646:INFO: Dataset: zara1               Batch: 8/8	Loss 130.5842 (150.3310)
2022-11-25 20:59:43,450:INFO: Dataset: zara2               Batch:  1/18	Loss 147.5624 (147.5624)
2022-11-25 20:59:43,956:INFO: Dataset: zara2               Batch:  2/18	Loss 146.7318 (147.1527)
2022-11-25 20:59:44,465:INFO: Dataset: zara2               Batch:  3/18	Loss 148.1914 (147.5068)
2022-11-25 20:59:44,968:INFO: Dataset: zara2               Batch:  4/18	Loss 148.0764 (147.6411)
2022-11-25 20:59:45,472:INFO: Dataset: zara2               Batch:  5/18	Loss 148.9533 (147.8991)
2022-11-25 20:59:46,063:INFO: Dataset: zara2               Batch:  6/18	Loss 147.4214 (147.8123)
2022-11-25 20:59:46,566:INFO: Dataset: zara2               Batch:  7/18	Loss 146.5029 (147.6194)
2022-11-25 20:59:47,069:INFO: Dataset: zara2               Batch:  8/18	Loss 147.1941 (147.5669)
2022-11-25 20:59:47,572:INFO: Dataset: zara2               Batch:  9/18	Loss 147.1445 (147.5210)
2022-11-25 20:59:48,074:INFO: Dataset: zara2               Batch: 10/18	Loss 149.5741 (147.7324)
2022-11-25 20:59:48,580:INFO: Dataset: zara2               Batch: 11/18	Loss 147.4726 (147.7082)
2022-11-25 20:59:49,084:INFO: Dataset: zara2               Batch: 12/18	Loss 146.4663 (147.6154)
2022-11-25 20:59:49,586:INFO: Dataset: zara2               Batch: 13/18	Loss 147.0352 (147.5702)
2022-11-25 20:59:50,088:INFO: Dataset: zara2               Batch: 14/18	Loss 147.1315 (147.5398)
2022-11-25 20:59:50,590:INFO: Dataset: zara2               Batch: 15/18	Loss 148.2804 (147.5907)
2022-11-25 20:59:51,094:INFO: Dataset: zara2               Batch: 16/18	Loss 147.5106 (147.5857)
2022-11-25 20:59:51,599:INFO: Dataset: zara2               Batch: 17/18	Loss 148.1341 (147.6179)
2022-11-25 20:59:52,089:INFO: Dataset: zara2               Batch: 18/18	Loss 127.1037 (146.5293)
2022-11-25 20:59:52,163:INFO: - Computing ADE (validation)
2022-11-25 20:59:52,520:INFO: 		 ADE on hotel                     dataset:	 2.7194926738739014
2022-11-25 20:59:52,969:INFO: 		 ADE on univ                      dataset:	 3.4017691612243652
2022-11-25 20:59:53,318:INFO: 		 ADE on zara1                     dataset:	 2.841421604156494
2022-11-25 20:59:53,876:INFO: 		 ADE on zara2                     dataset:	 2.9658799171447754
2022-11-25 20:59:53,877:INFO: Average validation:	ADE  3.1719	FDE  4.4957
2022-11-25 20:59:53,877:INFO: - Computing ADE (validation o)
2022-11-25 20:59:54,186:INFO: 		 ADE on eth                       dataset:	 3.022998094558716
2022-11-25 20:59:54,187:INFO: Average validation o:	ADE  3.0230	FDE  4.4873
2022-11-25 20:59:54,195:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_287.pth.tar
2022-11-25 20:59:54,195:INFO: 
===> EPOCH: 288 (P3)
2022-11-25 20:59:54,196:INFO: - Computing loss (training)
2022-11-25 20:59:54,923:INFO: Dataset: hotel               Batch: 1/4	Loss 154.0479 (154.0479)
2022-11-25 20:59:55,425:INFO: Dataset: hotel               Batch: 2/4	Loss 154.0429 (154.0455)
2022-11-25 20:59:55,919:INFO: Dataset: hotel               Batch: 3/4	Loss 153.4721 (153.8538)
2022-11-25 20:59:56,359:INFO: Dataset: hotel               Batch: 4/4	Loss 93.2518 (143.9400)
2022-11-25 20:59:57,202:INFO: Dataset: univ                Batch:  1/15	Loss 148.5146 (148.5146)
2022-11-25 20:59:57,749:INFO: Dataset: univ                Batch:  2/15	Loss 148.6508 (148.5801)
2022-11-25 20:59:58,295:INFO: Dataset: univ                Batch:  3/15	Loss 149.8129 (149.0473)
2022-11-25 20:59:58,836:INFO: Dataset: univ                Batch:  4/15	Loss 146.5995 (148.4187)
2022-11-25 20:59:59,385:INFO: Dataset: univ                Batch:  5/15	Loss 146.4844 (147.9945)
2022-11-25 20:59:59,933:INFO: Dataset: univ                Batch:  6/15	Loss 147.6700 (147.9362)
2022-11-25 21:00:00,485:INFO: Dataset: univ                Batch:  7/15	Loss 146.2266 (147.6642)
2022-11-25 21:00:01,029:INFO: Dataset: univ                Batch:  8/15	Loss 146.7019 (147.5391)
2022-11-25 21:00:01,565:INFO: Dataset: univ                Batch:  9/15	Loss 147.3112 (147.5156)
2022-11-25 21:00:02,109:INFO: Dataset: univ                Batch: 10/15	Loss 147.2497 (147.4876)
2022-11-25 21:00:02,656:INFO: Dataset: univ                Batch: 11/15	Loss 147.6512 (147.5033)
2022-11-25 21:00:03,192:INFO: Dataset: univ                Batch: 12/15	Loss 147.3637 (147.4921)
2022-11-25 21:00:03,737:INFO: Dataset: univ                Batch: 13/15	Loss 147.0611 (147.4576)
2022-11-25 21:00:04,272:INFO: Dataset: univ                Batch: 14/15	Loss 147.8069 (147.4799)
2022-11-25 21:00:04,711:INFO: Dataset: univ                Batch: 15/15	Loss 27.3255 (145.7831)
2022-11-25 21:00:05,498:INFO: Dataset: zara1               Batch: 1/8	Loss 150.3163 (150.3163)
2022-11-25 21:00:05,998:INFO: Dataset: zara1               Batch: 2/8	Loss 149.9374 (150.1355)
2022-11-25 21:00:06,495:INFO: Dataset: zara1               Batch: 3/8	Loss 149.3156 (149.8577)
2022-11-25 21:00:07,006:INFO: Dataset: zara1               Batch: 4/8	Loss 150.0179 (149.9003)
2022-11-25 21:00:07,508:INFO: Dataset: zara1               Batch: 5/8	Loss 150.1366 (149.9454)
2022-11-25 21:00:08,008:INFO: Dataset: zara1               Batch: 6/8	Loss 148.9399 (149.7925)
2022-11-25 21:00:08,504:INFO: Dataset: zara1               Batch: 7/8	Loss 150.7168 (149.9212)
2022-11-25 21:00:08,995:INFO: Dataset: zara1               Batch: 8/8	Loss 128.1043 (147.4065)
2022-11-25 21:00:09,815:INFO: Dataset: zara2               Batch:  1/18	Loss 153.6361 (153.6361)
2022-11-25 21:00:10,325:INFO: Dataset: zara2               Batch:  2/18	Loss 146.9222 (150.1457)
2022-11-25 21:00:10,836:INFO: Dataset: zara2               Batch:  3/18	Loss 145.3088 (148.4278)
2022-11-25 21:00:11,348:INFO: Dataset: zara2               Batch:  4/18	Loss 146.9638 (148.0776)
2022-11-25 21:00:11,861:INFO: Dataset: zara2               Batch:  5/18	Loss 145.8646 (147.6652)
2022-11-25 21:00:12,371:INFO: Dataset: zara2               Batch:  6/18	Loss 144.9541 (147.2715)
2022-11-25 21:00:12,880:INFO: Dataset: zara2               Batch:  7/18	Loss 145.8604 (147.0635)
2022-11-25 21:00:13,389:INFO: Dataset: zara2               Batch:  8/18	Loss 145.5817 (146.8660)
2022-11-25 21:00:13,896:INFO: Dataset: zara2               Batch:  9/18	Loss 148.9055 (147.0886)
2022-11-25 21:00:14,404:INFO: Dataset: zara2               Batch: 10/18	Loss 145.1862 (146.9106)
2022-11-25 21:00:14,912:INFO: Dataset: zara2               Batch: 11/18	Loss 145.3442 (146.7669)
2022-11-25 21:00:15,420:INFO: Dataset: zara2               Batch: 12/18	Loss 146.7110 (146.7619)
2022-11-25 21:00:16,016:INFO: Dataset: zara2               Batch: 13/18	Loss 145.5009 (146.6619)
2022-11-25 21:00:16,525:INFO: Dataset: zara2               Batch: 14/18	Loss 146.0911 (146.6182)
2022-11-25 21:00:17,032:INFO: Dataset: zara2               Batch: 15/18	Loss 146.0215 (146.5799)
2022-11-25 21:00:17,541:INFO: Dataset: zara2               Batch: 16/18	Loss 145.6119 (146.5219)
2022-11-25 21:00:18,049:INFO: Dataset: zara2               Batch: 17/18	Loss 145.9585 (146.4869)
2022-11-25 21:00:18,545:INFO: Dataset: zara2               Batch: 18/18	Loss 124.7522 (145.3874)
2022-11-25 21:00:18,606:INFO: - Computing ADE (validation)
2022-11-25 21:00:18,960:INFO: 		 ADE on hotel                     dataset:	 2.67448353767395
2022-11-25 21:00:19,399:INFO: 		 ADE on univ                      dataset:	 3.3475890159606934
2022-11-25 21:00:19,766:INFO: 		 ADE on zara1                     dataset:	 2.8310863971710205
2022-11-25 21:00:20,326:INFO: 		 ADE on zara2                     dataset:	 2.958909511566162
2022-11-25 21:00:20,326:INFO: Average validation:	ADE  3.1381	FDE  4.4120
2022-11-25 21:00:20,327:INFO: - Computing ADE (validation o)
2022-11-25 21:00:20,637:INFO: 		 ADE on eth                       dataset:	 3.0258240699768066
2022-11-25 21:00:20,637:INFO: Average validation o:	ADE  3.0258	FDE  4.4470
2022-11-25 21:00:20,646:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_288.pth.tar
2022-11-25 21:00:20,646:INFO: 
===> EPOCH: 289 (P3)
2022-11-25 21:00:20,646:INFO: - Computing loss (training)
2022-11-25 21:00:21,373:INFO: Dataset: hotel               Batch: 1/4	Loss 151.7280 (151.7280)
2022-11-25 21:00:21,874:INFO: Dataset: hotel               Batch: 2/4	Loss 147.6060 (149.7523)
2022-11-25 21:00:22,368:INFO: Dataset: hotel               Batch: 3/4	Loss 150.5483 (150.0282)
2022-11-25 21:00:22,822:INFO: Dataset: hotel               Batch: 4/4	Loss 90.1968 (139.8458)
2022-11-25 21:00:23,674:INFO: Dataset: univ                Batch:  1/15	Loss 146.3131 (146.3131)
2022-11-25 21:00:24,220:INFO: Dataset: univ                Batch:  2/15	Loss 146.6839 (146.4990)
2022-11-25 21:00:24,754:INFO: Dataset: univ                Batch:  3/15	Loss 146.0999 (146.3788)
2022-11-25 21:00:25,289:INFO: Dataset: univ                Batch:  4/15	Loss 145.1007 (146.0697)
2022-11-25 21:00:25,841:INFO: Dataset: univ                Batch:  5/15	Loss 144.8692 (145.7955)
2022-11-25 21:00:26,377:INFO: Dataset: univ                Batch:  6/15	Loss 144.5485 (145.6019)
2022-11-25 21:00:26,921:INFO: Dataset: univ                Batch:  7/15	Loss 145.5351 (145.5918)
2022-11-25 21:00:27,458:INFO: Dataset: univ                Batch:  8/15	Loss 144.5883 (145.4707)
2022-11-25 21:00:28,002:INFO: Dataset: univ                Batch:  9/15	Loss 145.0745 (145.4252)
2022-11-25 21:00:28,552:INFO: Dataset: univ                Batch: 10/15	Loss 144.2031 (145.2916)
2022-11-25 21:00:29,098:INFO: Dataset: univ                Batch: 11/15	Loss 144.4101 (145.2078)
2022-11-25 21:00:29,639:INFO: Dataset: univ                Batch: 12/15	Loss 145.3366 (145.2184)
2022-11-25 21:00:30,183:INFO: Dataset: univ                Batch: 13/15	Loss 144.7952 (145.1845)
2022-11-25 21:00:30,721:INFO: Dataset: univ                Batch: 14/15	Loss 145.9603 (145.2361)
2022-11-25 21:00:31,160:INFO: Dataset: univ                Batch: 15/15	Loss 26.8516 (143.4689)
2022-11-25 21:00:31,980:INFO: Dataset: zara1               Batch: 1/8	Loss 146.9232 (146.9232)
2022-11-25 21:00:32,483:INFO: Dataset: zara1               Batch: 2/8	Loss 149.0401 (147.8226)
2022-11-25 21:00:32,978:INFO: Dataset: zara1               Batch: 3/8	Loss 146.8610 (147.5081)
2022-11-25 21:00:33,473:INFO: Dataset: zara1               Batch: 4/8	Loss 148.8843 (147.8304)
2022-11-25 21:00:33,970:INFO: Dataset: zara1               Batch: 5/8	Loss 148.3199 (147.9246)
2022-11-25 21:00:34,469:INFO: Dataset: zara1               Batch: 6/8	Loss 147.3512 (147.8278)
2022-11-25 21:00:34,965:INFO: Dataset: zara1               Batch: 7/8	Loss 146.4629 (147.6306)
2022-11-25 21:00:35,451:INFO: Dataset: zara1               Batch: 8/8	Loss 126.1533 (145.4829)
2022-11-25 21:00:36,261:INFO: Dataset: zara2               Batch:  1/18	Loss 147.1821 (147.1821)
2022-11-25 21:00:36,768:INFO: Dataset: zara2               Batch:  2/18	Loss 145.7328 (146.4308)
2022-11-25 21:00:37,272:INFO: Dataset: zara2               Batch:  3/18	Loss 145.5013 (146.1216)
2022-11-25 21:00:37,774:INFO: Dataset: zara2               Batch:  4/18	Loss 145.6828 (146.0175)
2022-11-25 21:00:38,278:INFO: Dataset: zara2               Batch:  5/18	Loss 144.7770 (145.7932)
2022-11-25 21:00:38,786:INFO: Dataset: zara2               Batch:  6/18	Loss 144.5213 (145.6006)
2022-11-25 21:00:39,288:INFO: Dataset: zara2               Batch:  7/18	Loss 143.8202 (145.3394)
2022-11-25 21:00:39,790:INFO: Dataset: zara2               Batch:  8/18	Loss 143.8805 (145.1519)
2022-11-25 21:00:40,292:INFO: Dataset: zara2               Batch:  9/18	Loss 143.6546 (144.9713)
2022-11-25 21:00:40,793:INFO: Dataset: zara2               Batch: 10/18	Loss 144.1319 (144.8854)
2022-11-25 21:00:41,294:INFO: Dataset: zara2               Batch: 11/18	Loss 143.1580 (144.7237)
2022-11-25 21:00:41,797:INFO: Dataset: zara2               Batch: 12/18	Loss 143.1274 (144.5899)
2022-11-25 21:00:42,298:INFO: Dataset: zara2               Batch: 13/18	Loss 143.8988 (144.5398)
2022-11-25 21:00:42,807:INFO: Dataset: zara2               Batch: 14/18	Loss 143.9620 (144.4976)
2022-11-25 21:00:43,312:INFO: Dataset: zara2               Batch: 15/18	Loss 143.3712 (144.4268)
2022-11-25 21:00:43,814:INFO: Dataset: zara2               Batch: 16/18	Loss 145.2436 (144.4806)
2022-11-25 21:00:44,404:INFO: Dataset: zara2               Batch: 17/18	Loss 143.8578 (144.4476)
2022-11-25 21:00:44,896:INFO: Dataset: zara2               Batch: 18/18	Loss 123.3104 (143.4343)
2022-11-25 21:00:44,959:INFO: - Computing ADE (validation)
2022-11-25 21:00:45,307:INFO: 		 ADE on hotel                     dataset:	 2.5792860984802246
2022-11-25 21:00:45,754:INFO: 		 ADE on univ                      dataset:	 3.3472442626953125
2022-11-25 21:00:46,110:INFO: 		 ADE on zara1                     dataset:	 2.884373188018799
2022-11-25 21:00:46,674:INFO: 		 ADE on zara2                     dataset:	 2.9405410289764404
2022-11-25 21:00:46,675:INFO: Average validation:	ADE  3.1291	FDE  4.4608
2022-11-25 21:00:46,675:INFO: - Computing ADE (validation o)
2022-11-25 21:00:46,981:INFO: 		 ADE on eth                       dataset:	 2.894026517868042
2022-11-25 21:00:46,981:INFO: Average validation o:	ADE  2.8940	FDE  4.0307
2022-11-25 21:00:46,990:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_289.pth.tar
2022-11-25 21:00:46,990:INFO: 
===> EPOCH: 290 (P3)
2022-11-25 21:00:46,990:INFO: - Computing loss (training)
2022-11-25 21:00:47,710:INFO: Dataset: hotel               Batch: 1/4	Loss 145.9828 (145.9828)
2022-11-25 21:00:48,217:INFO: Dataset: hotel               Batch: 2/4	Loss 146.4930 (146.2457)
2022-11-25 21:00:48,718:INFO: Dataset: hotel               Batch: 3/4	Loss 144.7654 (145.7500)
2022-11-25 21:00:49,162:INFO: Dataset: hotel               Batch: 4/4	Loss 90.9022 (137.1393)
2022-11-25 21:00:49,986:INFO: Dataset: univ                Batch:  1/15	Loss 144.3321 (144.3321)
2022-11-25 21:00:50,521:INFO: Dataset: univ                Batch:  2/15	Loss 143.7795 (144.0478)
2022-11-25 21:00:51,068:INFO: Dataset: univ                Batch:  3/15	Loss 142.5877 (143.5178)
2022-11-25 21:00:51,611:INFO: Dataset: univ                Batch:  4/15	Loss 142.8679 (143.3452)
2022-11-25 21:00:52,160:INFO: Dataset: univ                Batch:  5/15	Loss 142.3768 (143.1327)
2022-11-25 21:00:52,697:INFO: Dataset: univ                Batch:  6/15	Loss 142.8791 (143.0923)
2022-11-25 21:00:53,228:INFO: Dataset: univ                Batch:  7/15	Loss 142.2526 (142.9797)
2022-11-25 21:00:53,762:INFO: Dataset: univ                Batch:  8/15	Loss 143.7586 (143.0769)
2022-11-25 21:00:54,294:INFO: Dataset: univ                Batch:  9/15	Loss 142.6939 (143.0343)
2022-11-25 21:00:54,824:INFO: Dataset: univ                Batch: 10/15	Loss 143.1665 (143.0466)
2022-11-25 21:00:55,359:INFO: Dataset: univ                Batch: 11/15	Loss 143.6479 (143.0999)
2022-11-25 21:00:55,893:INFO: Dataset: univ                Batch: 12/15	Loss 143.1633 (143.1049)
2022-11-25 21:00:56,422:INFO: Dataset: univ                Batch: 13/15	Loss 144.6049 (143.2132)
2022-11-25 21:00:56,952:INFO: Dataset: univ                Batch: 14/15	Loss 143.0621 (143.2032)
2022-11-25 21:00:57,385:INFO: Dataset: univ                Batch: 15/15	Loss 26.5947 (141.2968)
2022-11-25 21:00:58,197:INFO: Dataset: zara1               Batch: 1/8	Loss 144.5901 (144.5901)
2022-11-25 21:00:58,702:INFO: Dataset: zara1               Batch: 2/8	Loss 145.6508 (145.1170)
2022-11-25 21:00:59,219:INFO: Dataset: zara1               Batch: 3/8	Loss 145.2399 (145.1610)
2022-11-25 21:00:59,723:INFO: Dataset: zara1               Batch: 4/8	Loss 145.2909 (145.1920)
2022-11-25 21:01:00,229:INFO: Dataset: zara1               Batch: 5/8	Loss 145.0971 (145.1721)
2022-11-25 21:01:00,745:INFO: Dataset: zara1               Batch: 6/8	Loss 145.3732 (145.2081)
2022-11-25 21:01:01,249:INFO: Dataset: zara1               Batch: 7/8	Loss 146.0078 (145.3210)
2022-11-25 21:01:01,740:INFO: Dataset: zara1               Batch: 8/8	Loss 124.2484 (143.1694)
2022-11-25 21:01:02,548:INFO: Dataset: zara2               Batch:  1/18	Loss 144.2321 (144.2321)
2022-11-25 21:01:03,064:INFO: Dataset: zara2               Batch:  2/18	Loss 144.5431 (144.3981)
2022-11-25 21:01:03,581:INFO: Dataset: zara2               Batch:  3/18	Loss 143.3223 (144.0113)
2022-11-25 21:01:04,095:INFO: Dataset: zara2               Batch:  4/18	Loss 142.4130 (143.6382)
2022-11-25 21:01:04,610:INFO: Dataset: zara2               Batch:  5/18	Loss 141.8939 (143.3072)
2022-11-25 21:01:05,126:INFO: Dataset: zara2               Batch:  6/18	Loss 142.4211 (143.1506)
2022-11-25 21:01:05,645:INFO: Dataset: zara2               Batch:  7/18	Loss 143.1782 (143.1543)
2022-11-25 21:01:06,159:INFO: Dataset: zara2               Batch:  8/18	Loss 141.7335 (142.9781)
2022-11-25 21:01:06,675:INFO: Dataset: zara2               Batch:  9/18	Loss 142.1958 (142.8877)
2022-11-25 21:01:07,190:INFO: Dataset: zara2               Batch: 10/18	Loss 141.9009 (142.7822)
2022-11-25 21:01:07,705:INFO: Dataset: zara2               Batch: 11/18	Loss 141.2017 (142.6391)
2022-11-25 21:01:08,219:INFO: Dataset: zara2               Batch: 12/18	Loss 142.0026 (142.5882)
2022-11-25 21:01:08,732:INFO: Dataset: zara2               Batch: 13/18	Loss 141.9198 (142.5356)
2022-11-25 21:01:09,247:INFO: Dataset: zara2               Batch: 14/18	Loss 141.7149 (142.4758)
2022-11-25 21:01:09,763:INFO: Dataset: zara2               Batch: 15/18	Loss 141.7784 (142.4216)
2022-11-25 21:01:10,279:INFO: Dataset: zara2               Batch: 16/18	Loss 141.7613 (142.3777)
2022-11-25 21:01:10,793:INFO: Dataset: zara2               Batch: 17/18	Loss 141.7414 (142.3388)
2022-11-25 21:01:11,301:INFO: Dataset: zara2               Batch: 18/18	Loss 122.0717 (141.3671)
2022-11-25 21:01:11,363:INFO: - Computing ADE (validation)
2022-11-25 21:01:11,741:INFO: 		 ADE on hotel                     dataset:	 2.6316990852355957
2022-11-25 21:01:12,182:INFO: 		 ADE on univ                      dataset:	 3.283416271209717
2022-11-25 21:01:12,530:INFO: 		 ADE on zara1                     dataset:	 2.7722253799438477
2022-11-25 21:01:13,082:INFO: 		 ADE on zara2                     dataset:	 2.930341958999634
2022-11-25 21:01:13,083:INFO: Average validation:	ADE  3.0885	FDE  4.3571
2022-11-25 21:01:13,083:INFO: - Computing ADE (validation o)
2022-11-25 21:01:13,380:INFO: 		 ADE on eth                       dataset:	 2.754718780517578
2022-11-25 21:01:13,380:INFO: Average validation o:	ADE  2.7547	FDE  4.0051
2022-11-25 21:01:13,389:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_290.pth.tar
2022-11-25 21:01:13,390:INFO: 
===> EPOCH: 291 (P3)
2022-11-25 21:01:13,390:INFO: - Computing loss (training)
2022-11-25 21:01:14,113:INFO: Dataset: hotel               Batch: 1/4	Loss 144.7615 (144.7615)
2022-11-25 21:01:14,612:INFO: Dataset: hotel               Batch: 2/4	Loss 144.5322 (144.6490)
2022-11-25 21:01:15,103:INFO: Dataset: hotel               Batch: 3/4	Loss 145.8416 (145.0440)
2022-11-25 21:01:15,564:INFO: Dataset: hotel               Batch: 4/4	Loss 87.6506 (134.9737)
2022-11-25 21:01:16,421:INFO: Dataset: univ                Batch:  1/15	Loss 140.8066 (140.8066)
2022-11-25 21:01:16,964:INFO: Dataset: univ                Batch:  2/15	Loss 141.3999 (141.0851)
2022-11-25 21:01:17,511:INFO: Dataset: univ                Batch:  3/15	Loss 141.4186 (141.1943)
2022-11-25 21:01:18,066:INFO: Dataset: univ                Batch:  4/15	Loss 141.5962 (141.2906)
2022-11-25 21:01:18,605:INFO: Dataset: univ                Batch:  5/15	Loss 142.0786 (141.4357)
2022-11-25 21:01:19,151:INFO: Dataset: univ                Batch:  6/15	Loss 142.0898 (141.5400)
2022-11-25 21:01:19,781:INFO: Dataset: univ                Batch:  7/15	Loss 140.7668 (141.4300)
2022-11-25 21:01:20,322:INFO: Dataset: univ                Batch:  8/15	Loss 141.2183 (141.4035)
2022-11-25 21:01:20,878:INFO: Dataset: univ                Batch:  9/15	Loss 140.5811 (141.2988)
2022-11-25 21:01:21,426:INFO: Dataset: univ                Batch: 10/15	Loss 142.4415 (141.4188)
2022-11-25 21:01:21,980:INFO: Dataset: univ                Batch: 11/15	Loss 142.2540 (141.5011)
2022-11-25 21:01:22,520:INFO: Dataset: univ                Batch: 12/15	Loss 141.2909 (141.4850)
2022-11-25 21:01:23,056:INFO: Dataset: univ                Batch: 13/15	Loss 142.8602 (141.5782)
2022-11-25 21:01:23,611:INFO: Dataset: univ                Batch: 14/15	Loss 140.4047 (141.4872)
2022-11-25 21:01:24,056:INFO: Dataset: univ                Batch: 15/15	Loss 27.8274 (140.0490)
2022-11-25 21:01:24,853:INFO: Dataset: zara1               Batch: 1/8	Loss 144.1620 (144.1620)
2022-11-25 21:01:25,353:INFO: Dataset: zara1               Batch: 2/8	Loss 143.9082 (144.0466)
2022-11-25 21:01:25,852:INFO: Dataset: zara1               Batch: 3/8	Loss 142.9500 (143.7115)
2022-11-25 21:01:26,346:INFO: Dataset: zara1               Batch: 4/8	Loss 142.4712 (143.3808)
2022-11-25 21:01:26,847:INFO: Dataset: zara1               Batch: 5/8	Loss 142.8518 (143.2541)
2022-11-25 21:01:27,342:INFO: Dataset: zara1               Batch: 6/8	Loss 142.7405 (143.1652)
2022-11-25 21:01:27,839:INFO: Dataset: zara1               Batch: 7/8	Loss 143.1217 (143.1587)
2022-11-25 21:01:28,321:INFO: Dataset: zara1               Batch: 8/8	Loss 122.3861 (141.0596)
2022-11-25 21:01:29,124:INFO: Dataset: zara2               Batch:  1/18	Loss 140.7695 (140.7695)
2022-11-25 21:01:29,636:INFO: Dataset: zara2               Batch:  2/18	Loss 141.1229 (140.9462)
2022-11-25 21:01:30,143:INFO: Dataset: zara2               Batch:  3/18	Loss 141.2956 (141.0620)
2022-11-25 21:01:30,653:INFO: Dataset: zara2               Batch:  4/18	Loss 141.5433 (141.1845)
2022-11-25 21:01:31,163:INFO: Dataset: zara2               Batch:  5/18	Loss 141.0492 (141.1555)
2022-11-25 21:01:31,673:INFO: Dataset: zara2               Batch:  6/18	Loss 140.0426 (140.9929)
2022-11-25 21:01:32,180:INFO: Dataset: zara2               Batch:  7/18	Loss 141.1445 (141.0140)
2022-11-25 21:01:32,686:INFO: Dataset: zara2               Batch:  8/18	Loss 140.4077 (140.9348)
2022-11-25 21:01:33,193:INFO: Dataset: zara2               Batch:  9/18	Loss 140.8321 (140.9238)
2022-11-25 21:01:33,702:INFO: Dataset: zara2               Batch: 10/18	Loss 139.7560 (140.8085)
2022-11-25 21:01:34,212:INFO: Dataset: zara2               Batch: 11/18	Loss 139.8417 (140.7257)
2022-11-25 21:01:34,720:INFO: Dataset: zara2               Batch: 12/18	Loss 140.1826 (140.6768)
2022-11-25 21:01:35,226:INFO: Dataset: zara2               Batch: 13/18	Loss 139.6389 (140.5974)
2022-11-25 21:01:35,735:INFO: Dataset: zara2               Batch: 14/18	Loss 140.2222 (140.5714)
2022-11-25 21:01:36,244:INFO: Dataset: zara2               Batch: 15/18	Loss 140.0870 (140.5417)
2022-11-25 21:01:36,754:INFO: Dataset: zara2               Batch: 16/18	Loss 139.5991 (140.4778)
2022-11-25 21:01:37,261:INFO: Dataset: zara2               Batch: 17/18	Loss 139.8498 (140.4376)
2022-11-25 21:01:37,756:INFO: Dataset: zara2               Batch: 18/18	Loss 120.5336 (139.4274)
2022-11-25 21:01:37,818:INFO: - Computing ADE (validation)
2022-11-25 21:01:38,196:INFO: 		 ADE on hotel                     dataset:	 2.5453951358795166
2022-11-25 21:01:38,636:INFO: 		 ADE on univ                      dataset:	 3.2948412895202637
2022-11-25 21:01:38,996:INFO: 		 ADE on zara1                     dataset:	 2.8732717037200928
2022-11-25 21:01:39,559:INFO: 		 ADE on zara2                     dataset:	 2.8876864910125732
2022-11-25 21:01:39,560:INFO: Average validation:	ADE  3.0799	FDE  4.3517
2022-11-25 21:01:39,561:INFO: - Computing ADE (validation o)
2022-11-25 21:01:39,869:INFO: 		 ADE on eth                       dataset:	 2.7982418537139893
2022-11-25 21:01:39,870:INFO: Average validation o:	ADE  2.7982	FDE  3.8333
2022-11-25 21:01:39,879:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_291.pth.tar
2022-11-25 21:01:39,879:INFO: 
===> EPOCH: 292 (P3)
2022-11-25 21:01:39,879:INFO: - Computing loss (training)
2022-11-25 21:01:40,610:INFO: Dataset: hotel               Batch: 1/4	Loss 141.0812 (141.0812)
2022-11-25 21:01:41,121:INFO: Dataset: hotel               Batch: 2/4	Loss 143.4845 (142.2629)
2022-11-25 21:01:41,624:INFO: Dataset: hotel               Batch: 3/4	Loss 142.5887 (142.3760)
2022-11-25 21:01:42,068:INFO: Dataset: hotel               Batch: 4/4	Loss 86.4338 (134.0364)
2022-11-25 21:01:42,897:INFO: Dataset: univ                Batch:  1/15	Loss 140.0627 (140.0627)
2022-11-25 21:01:43,436:INFO: Dataset: univ                Batch:  2/15	Loss 139.5571 (139.7977)
2022-11-25 21:01:43,972:INFO: Dataset: univ                Batch:  3/15	Loss 139.7181 (139.7712)
2022-11-25 21:01:44,504:INFO: Dataset: univ                Batch:  4/15	Loss 139.5980 (139.7299)
2022-11-25 21:01:45,051:INFO: Dataset: univ                Batch:  5/15	Loss 139.1252 (139.5970)
2022-11-25 21:01:45,589:INFO: Dataset: univ                Batch:  6/15	Loss 139.4357 (139.5705)
2022-11-25 21:01:46,125:INFO: Dataset: univ                Batch:  7/15	Loss 140.2006 (139.6617)
2022-11-25 21:01:46,663:INFO: Dataset: univ                Batch:  8/15	Loss 141.7492 (139.9337)
2022-11-25 21:01:47,198:INFO: Dataset: univ                Batch:  9/15	Loss 139.4783 (139.8826)
2022-11-25 21:01:47,745:INFO: Dataset: univ                Batch: 10/15	Loss 139.3707 (139.8243)
2022-11-25 21:01:48,285:INFO: Dataset: univ                Batch: 11/15	Loss 139.7043 (139.8131)
2022-11-25 21:01:48,810:INFO: Dataset: univ                Batch: 12/15	Loss 140.0801 (139.8327)
2022-11-25 21:01:49,355:INFO: Dataset: univ                Batch: 13/15	Loss 138.9028 (139.7563)
2022-11-25 21:01:49,976:INFO: Dataset: univ                Batch: 14/15	Loss 139.8360 (139.7618)
2022-11-25 21:01:50,403:INFO: Dataset: univ                Batch: 15/15	Loss 26.0076 (138.3926)
2022-11-25 21:01:51,190:INFO: Dataset: zara1               Batch: 1/8	Loss 141.4441 (141.4441)
2022-11-25 21:01:51,685:INFO: Dataset: zara1               Batch: 2/8	Loss 140.7158 (141.0971)
2022-11-25 21:01:52,177:INFO: Dataset: zara1               Batch: 3/8	Loss 141.1368 (141.1114)
2022-11-25 21:01:52,681:INFO: Dataset: zara1               Batch: 4/8	Loss 142.8677 (141.5916)
2022-11-25 21:01:53,175:INFO: Dataset: zara1               Batch: 5/8	Loss 148.7012 (143.0627)
2022-11-25 21:01:53,670:INFO: Dataset: zara1               Batch: 6/8	Loss 140.8040 (142.6716)
2022-11-25 21:01:54,163:INFO: Dataset: zara1               Batch: 7/8	Loss 140.9766 (142.4541)
2022-11-25 21:01:54,644:INFO: Dataset: zara1               Batch: 8/8	Loss 122.1184 (140.1315)
2022-11-25 21:01:55,444:INFO: Dataset: zara2               Batch:  1/18	Loss 138.5499 (138.5499)
2022-11-25 21:01:55,962:INFO: Dataset: zara2               Batch:  2/18	Loss 138.9364 (138.7543)
2022-11-25 21:01:56,468:INFO: Dataset: zara2               Batch:  3/18	Loss 139.4309 (138.9678)
2022-11-25 21:01:56,974:INFO: Dataset: zara2               Batch:  4/18	Loss 138.5416 (138.8534)
2022-11-25 21:01:57,480:INFO: Dataset: zara2               Batch:  5/18	Loss 139.7649 (139.0231)
2022-11-25 21:01:57,990:INFO: Dataset: zara2               Batch:  6/18	Loss 138.3124 (138.9046)
2022-11-25 21:01:58,494:INFO: Dataset: zara2               Batch:  7/18	Loss 139.3342 (138.9675)
2022-11-25 21:01:58,998:INFO: Dataset: zara2               Batch:  8/18	Loss 138.5851 (138.9188)
2022-11-25 21:01:59,504:INFO: Dataset: zara2               Batch:  9/18	Loss 138.6520 (138.8901)
2022-11-25 21:02:00,009:INFO: Dataset: zara2               Batch: 10/18	Loss 138.6758 (138.8691)
2022-11-25 21:02:00,518:INFO: Dataset: zara2               Batch: 11/18	Loss 138.4501 (138.8312)
2022-11-25 21:02:01,024:INFO: Dataset: zara2               Batch: 12/18	Loss 138.0611 (138.7691)
2022-11-25 21:02:01,527:INFO: Dataset: zara2               Batch: 13/18	Loss 137.9059 (138.7084)
2022-11-25 21:02:02,031:INFO: Dataset: zara2               Batch: 14/18	Loss 137.9902 (138.6563)
2022-11-25 21:02:02,535:INFO: Dataset: zara2               Batch: 15/18	Loss 138.5619 (138.6497)
2022-11-25 21:02:03,041:INFO: Dataset: zara2               Batch: 16/18	Loss 138.5181 (138.6424)
2022-11-25 21:02:03,544:INFO: Dataset: zara2               Batch: 17/18	Loss 138.1356 (138.6111)
2022-11-25 21:02:04,036:INFO: Dataset: zara2               Batch: 18/18	Loss 119.8979 (137.7016)
2022-11-25 21:02:04,096:INFO: - Computing ADE (validation)
2022-11-25 21:02:04,454:INFO: 		 ADE on hotel                     dataset:	 2.499183177947998
2022-11-25 21:02:04,908:INFO: 		 ADE on univ                      dataset:	 3.2329928874969482
2022-11-25 21:02:05,261:INFO: 		 ADE on zara1                     dataset:	 2.7384915351867676
2022-11-25 21:02:05,816:INFO: 		 ADE on zara2                     dataset:	 2.8405110836029053
2022-11-25 21:02:05,816:INFO: Average validation:	ADE  3.0201	FDE  4.2628
2022-11-25 21:02:05,817:INFO: - Computing ADE (validation o)
2022-11-25 21:02:06,130:INFO: 		 ADE on eth                       dataset:	 2.908963680267334
2022-11-25 21:02:06,130:INFO: Average validation o:	ADE  2.9090	FDE  4.0713
2022-11-25 21:02:06,139:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_292.pth.tar
2022-11-25 21:02:06,139:INFO: 
===> EPOCH: 293 (P3)
2022-11-25 21:02:06,139:INFO: - Computing loss (training)
2022-11-25 21:02:06,855:INFO: Dataset: hotel               Batch: 1/4	Loss 139.8425 (139.8425)
2022-11-25 21:02:07,357:INFO: Dataset: hotel               Batch: 2/4	Loss 139.4171 (139.6333)
2022-11-25 21:02:07,853:INFO: Dataset: hotel               Batch: 3/4	Loss 140.6665 (139.9739)
2022-11-25 21:02:08,295:INFO: Dataset: hotel               Batch: 4/4	Loss 84.3922 (130.6614)
2022-11-25 21:02:09,144:INFO: Dataset: univ                Batch:  1/15	Loss 137.6596 (137.6596)
2022-11-25 21:02:09,683:INFO: Dataset: univ                Batch:  2/15	Loss 138.0126 (137.8284)
2022-11-25 21:02:10,226:INFO: Dataset: univ                Batch:  3/15	Loss 140.5506 (138.7117)
2022-11-25 21:02:10,760:INFO: Dataset: univ                Batch:  4/15	Loss 137.8812 (138.5147)
2022-11-25 21:02:11,296:INFO: Dataset: univ                Batch:  5/15	Loss 137.6793 (138.3499)
2022-11-25 21:02:11,842:INFO: Dataset: univ                Batch:  6/15	Loss 137.8345 (138.2607)
2022-11-25 21:02:12,380:INFO: Dataset: univ                Batch:  7/15	Loss 137.7435 (138.1854)
2022-11-25 21:02:12,915:INFO: Dataset: univ                Batch:  8/15	Loss 138.8698 (138.2669)
2022-11-25 21:02:13,460:INFO: Dataset: univ                Batch:  9/15	Loss 137.9653 (138.2314)
2022-11-25 21:02:13,983:INFO: Dataset: univ                Batch: 10/15	Loss 138.3252 (138.2391)
2022-11-25 21:02:14,521:INFO: Dataset: univ                Batch: 11/15	Loss 137.7184 (138.1926)
2022-11-25 21:02:15,051:INFO: Dataset: univ                Batch: 12/15	Loss 137.6748 (138.1534)
2022-11-25 21:02:15,599:INFO: Dataset: univ                Batch: 13/15	Loss 137.6055 (138.1087)
2022-11-25 21:02:16,142:INFO: Dataset: univ                Batch: 14/15	Loss 137.6240 (138.0723)
2022-11-25 21:02:16,569:INFO: Dataset: univ                Batch: 15/15	Loss 25.5998 (136.7399)
2022-11-25 21:02:17,368:INFO: Dataset: zara1               Batch: 1/8	Loss 139.1745 (139.1745)
2022-11-25 21:02:17,869:INFO: Dataset: zara1               Batch: 2/8	Loss 139.4798 (139.3243)
2022-11-25 21:02:18,370:INFO: Dataset: zara1               Batch: 3/8	Loss 138.9541 (139.2073)
2022-11-25 21:02:18,871:INFO: Dataset: zara1               Batch: 4/8	Loss 139.8156 (139.3640)
2022-11-25 21:02:19,371:INFO: Dataset: zara1               Batch: 5/8	Loss 139.0402 (139.3011)
2022-11-25 21:02:19,871:INFO: Dataset: zara1               Batch: 6/8	Loss 138.8978 (139.2325)
2022-11-25 21:02:20,368:INFO: Dataset: zara1               Batch: 7/8	Loss 138.4073 (139.1210)
2022-11-25 21:02:20,853:INFO: Dataset: zara1               Batch: 8/8	Loss 118.6739 (136.5920)
2022-11-25 21:02:21,776:INFO: Dataset: zara2               Batch:  1/18	Loss 137.5891 (137.5891)
2022-11-25 21:02:22,283:INFO: Dataset: zara2               Batch:  2/18	Loss 137.2065 (137.4030)
2022-11-25 21:02:22,786:INFO: Dataset: zara2               Batch:  3/18	Loss 137.0113 (137.2688)
2022-11-25 21:02:23,301:INFO: Dataset: zara2               Batch:  4/18	Loss 138.8489 (137.6789)
2022-11-25 21:02:23,806:INFO: Dataset: zara2               Batch:  5/18	Loss 136.6801 (137.4703)
2022-11-25 21:02:24,314:INFO: Dataset: zara2               Batch:  6/18	Loss 136.9942 (137.3948)
2022-11-25 21:02:24,818:INFO: Dataset: zara2               Batch:  7/18	Loss 137.1332 (137.3559)
2022-11-25 21:02:25,321:INFO: Dataset: zara2               Batch:  8/18	Loss 136.7185 (137.2746)
2022-11-25 21:02:25,825:INFO: Dataset: zara2               Batch:  9/18	Loss 136.6052 (137.2011)
2022-11-25 21:02:26,329:INFO: Dataset: zara2               Batch: 10/18	Loss 136.3590 (137.1250)
2022-11-25 21:02:26,834:INFO: Dataset: zara2               Batch: 11/18	Loss 136.8038 (137.0971)
2022-11-25 21:02:27,338:INFO: Dataset: zara2               Batch: 12/18	Loss 137.0408 (137.0926)
2022-11-25 21:02:27,843:INFO: Dataset: zara2               Batch: 13/18	Loss 136.3455 (137.0322)
2022-11-25 21:02:28,348:INFO: Dataset: zara2               Batch: 14/18	Loss 141.9439 (137.3872)
2022-11-25 21:02:28,852:INFO: Dataset: zara2               Batch: 15/18	Loss 136.6587 (137.3416)
2022-11-25 21:02:29,356:INFO: Dataset: zara2               Batch: 16/18	Loss 136.6680 (137.2987)
2022-11-25 21:02:29,859:INFO: Dataset: zara2               Batch: 17/18	Loss 136.2894 (137.2360)
2022-11-25 21:02:30,349:INFO: Dataset: zara2               Batch: 18/18	Loss 117.4903 (136.3612)
2022-11-25 21:02:30,418:INFO: - Computing ADE (validation)
2022-11-25 21:02:30,784:INFO: 		 ADE on hotel                     dataset:	 2.5758473873138428
2022-11-25 21:02:31,220:INFO: 		 ADE on univ                      dataset:	 3.205206871032715
2022-11-25 21:02:31,576:INFO: 		 ADE on zara1                     dataset:	 2.6586039066314697
2022-11-25 21:02:32,129:INFO: 		 ADE on zara2                     dataset:	 2.8013291358947754
2022-11-25 21:02:32,129:INFO: Average validation:	ADE  2.9908	FDE  4.2262
2022-11-25 21:02:32,130:INFO: - Computing ADE (validation o)
2022-11-25 21:02:32,437:INFO: 		 ADE on eth                       dataset:	 2.723724365234375
2022-11-25 21:02:32,437:INFO: Average validation o:	ADE  2.7237	FDE  3.6045
2022-11-25 21:02:32,446:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_293.pth.tar
2022-11-25 21:02:32,446:INFO: 
===> EPOCH: 294 (P3)
2022-11-25 21:02:32,447:INFO: - Computing loss (training)
2022-11-25 21:02:33,163:INFO: Dataset: hotel               Batch: 1/4	Loss 137.6543 (137.6543)
2022-11-25 21:02:33,673:INFO: Dataset: hotel               Batch: 2/4	Loss 137.4538 (137.5548)
2022-11-25 21:02:34,164:INFO: Dataset: hotel               Batch: 3/4	Loss 137.6845 (137.5986)
2022-11-25 21:02:34,602:INFO: Dataset: hotel               Batch: 4/4	Loss 84.0441 (128.7671)
2022-11-25 21:02:35,456:INFO: Dataset: univ                Batch:  1/15	Loss 136.4784 (136.4784)
2022-11-25 21:02:35,992:INFO: Dataset: univ                Batch:  2/15	Loss 136.2719 (136.3732)
2022-11-25 21:02:36,520:INFO: Dataset: univ                Batch:  3/15	Loss 136.6269 (136.4514)
2022-11-25 21:02:37,052:INFO: Dataset: univ                Batch:  4/15	Loss 135.9586 (136.3286)
2022-11-25 21:02:37,595:INFO: Dataset: univ                Batch:  5/15	Loss 136.1184 (136.2837)
2022-11-25 21:02:38,150:INFO: Dataset: univ                Batch:  6/15	Loss 137.2351 (136.4584)
2022-11-25 21:02:38,701:INFO: Dataset: univ                Batch:  7/15	Loss 135.4194 (136.3012)
2022-11-25 21:02:39,270:INFO: Dataset: univ                Batch:  8/15	Loss 136.2134 (136.2896)
2022-11-25 21:02:39,835:INFO: Dataset: univ                Batch:  9/15	Loss 136.0841 (136.2669)
2022-11-25 21:02:40,389:INFO: Dataset: univ                Batch: 10/15	Loss 135.9370 (136.2373)
2022-11-25 21:02:40,956:INFO: Dataset: univ                Batch: 11/15	Loss 135.3662 (136.1475)
2022-11-25 21:02:41,547:INFO: Dataset: univ                Batch: 12/15	Loss 136.7509 (136.2036)
2022-11-25 21:02:42,253:INFO: Dataset: univ                Batch: 13/15	Loss 135.5767 (136.1534)
2022-11-25 21:02:42,853:INFO: Dataset: univ                Batch: 14/15	Loss 135.4648 (136.1005)
2022-11-25 21:02:43,310:INFO: Dataset: univ                Batch: 15/15	Loss 25.4271 (134.4799)
2022-11-25 21:02:44,159:INFO: Dataset: zara1               Batch: 1/8	Loss 137.8543 (137.8543)
2022-11-25 21:02:44,679:INFO: Dataset: zara1               Batch: 2/8	Loss 136.5234 (137.1121)
2022-11-25 21:02:45,209:INFO: Dataset: zara1               Batch: 3/8	Loss 137.6823 (137.3077)
2022-11-25 21:02:45,752:INFO: Dataset: zara1               Batch: 4/8	Loss 137.3175 (137.3103)
2022-11-25 21:02:46,267:INFO: Dataset: zara1               Batch: 5/8	Loss 136.9616 (137.2425)
2022-11-25 21:02:46,802:INFO: Dataset: zara1               Batch: 6/8	Loss 137.2662 (137.2463)
2022-11-25 21:02:47,341:INFO: Dataset: zara1               Batch: 7/8	Loss 137.0810 (137.2243)
2022-11-25 21:02:47,857:INFO: Dataset: zara1               Batch: 8/8	Loss 117.5974 (135.0550)
2022-11-25 21:02:48,743:INFO: Dataset: zara2               Batch:  1/18	Loss 135.7847 (135.7847)
2022-11-25 21:02:49,322:INFO: Dataset: zara2               Batch:  2/18	Loss 135.8076 (135.7957)
2022-11-25 21:02:49,883:INFO: Dataset: zara2               Batch:  3/18	Loss 135.8910 (135.8257)
2022-11-25 21:02:50,475:INFO: Dataset: zara2               Batch:  4/18	Loss 135.9169 (135.8478)
2022-11-25 21:02:51,038:INFO: Dataset: zara2               Batch:  5/18	Loss 136.7351 (136.0270)
2022-11-25 21:02:51,571:INFO: Dataset: zara2               Batch:  6/18	Loss 135.5770 (135.9398)
2022-11-25 21:02:52,136:INFO: Dataset: zara2               Batch:  7/18	Loss 134.6740 (135.7635)
2022-11-25 21:02:52,695:INFO: Dataset: zara2               Batch:  8/18	Loss 135.3499 (135.7143)
2022-11-25 21:02:53,356:INFO: Dataset: zara2               Batch:  9/18	Loss 135.2632 (135.6648)
2022-11-25 21:02:53,913:INFO: Dataset: zara2               Batch: 10/18	Loss 134.9818 (135.5950)
2022-11-25 21:02:54,459:INFO: Dataset: zara2               Batch: 11/18	Loss 135.1824 (135.5560)
2022-11-25 21:02:54,994:INFO: Dataset: zara2               Batch: 12/18	Loss 134.8761 (135.4969)
2022-11-25 21:02:55,570:INFO: Dataset: zara2               Batch: 13/18	Loss 135.7339 (135.5143)
2022-11-25 21:02:56,136:INFO: Dataset: zara2               Batch: 14/18	Loss 134.8354 (135.4637)
2022-11-25 21:02:56,691:INFO: Dataset: zara2               Batch: 15/18	Loss 134.7216 (135.4164)
2022-11-25 21:02:57,217:INFO: Dataset: zara2               Batch: 16/18	Loss 134.5891 (135.3624)
2022-11-25 21:02:57,804:INFO: Dataset: zara2               Batch: 17/18	Loss 135.4792 (135.3696)
2022-11-25 21:02:58,346:INFO: Dataset: zara2               Batch: 18/18	Loss 115.8054 (134.4931)
2022-11-25 21:02:58,411:INFO: - Computing ADE (validation)
2022-11-25 21:02:58,815:INFO: 		 ADE on hotel                     dataset:	 2.5848162174224854
2022-11-25 21:02:59,480:INFO: 		 ADE on univ                      dataset:	 3.2014405727386475
2022-11-25 21:03:00,174:INFO: 		 ADE on zara1                     dataset:	 2.6442530155181885
2022-11-25 21:03:00,789:INFO: 		 ADE on zara2                     dataset:	 2.801114559173584
2022-11-25 21:03:00,789:INFO: Average validation:	ADE  2.9884	FDE  4.2098
2022-11-25 21:03:00,790:INFO: - Computing ADE (validation o)
2022-11-25 21:03:01,094:INFO: 		 ADE on eth                       dataset:	 2.6154587268829346
2022-11-25 21:03:01,094:INFO: Average validation o:	ADE  2.6155	FDE  3.6117
2022-11-25 21:03:01,104:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_294.pth.tar
2022-11-25 21:03:01,104:INFO: 
===> EPOCH: 295 (P3)
2022-11-25 21:03:01,104:INFO: - Computing loss (training)
2022-11-25 21:03:01,838:INFO: Dataset: hotel               Batch: 1/4	Loss 134.8259 (134.8259)
2022-11-25 21:03:02,336:INFO: Dataset: hotel               Batch: 2/4	Loss 136.2230 (135.5074)
2022-11-25 21:03:02,835:INFO: Dataset: hotel               Batch: 3/4	Loss 136.7431 (135.9402)
2022-11-25 21:03:03,289:INFO: Dataset: hotel               Batch: 4/4	Loss 81.8485 (126.6633)
2022-11-25 21:03:04,129:INFO: Dataset: univ                Batch:  1/15	Loss 134.9889 (134.9889)
2022-11-25 21:03:04,685:INFO: Dataset: univ                Batch:  2/15	Loss 134.6766 (134.8262)
2022-11-25 21:03:05,311:INFO: Dataset: univ                Batch:  3/15	Loss 134.6118 (134.7483)
2022-11-25 21:03:05,991:INFO: Dataset: univ                Batch:  4/15	Loss 135.5297 (134.9378)
2022-11-25 21:03:06,592:INFO: Dataset: univ                Batch:  5/15	Loss 134.6180 (134.8738)
2022-11-25 21:03:07,172:INFO: Dataset: univ                Batch:  6/15	Loss 134.7187 (134.8508)
2022-11-25 21:03:07,765:INFO: Dataset: univ                Batch:  7/15	Loss 134.5162 (134.8021)
2022-11-25 21:03:08,316:INFO: Dataset: univ                Batch:  8/15	Loss 134.7934 (134.8011)
2022-11-25 21:03:08,893:INFO: Dataset: univ                Batch:  9/15	Loss 134.9770 (134.8195)
2022-11-25 21:03:09,510:INFO: Dataset: univ                Batch: 10/15	Loss 134.7861 (134.8160)
2022-11-25 21:03:10,096:INFO: Dataset: univ                Batch: 11/15	Loss 134.2123 (134.7581)
2022-11-25 21:03:10,680:INFO: Dataset: univ                Batch: 12/15	Loss 134.4902 (134.7352)
2022-11-25 21:03:11,227:INFO: Dataset: univ                Batch: 13/15	Loss 135.4705 (134.7909)
2022-11-25 21:03:11,777:INFO: Dataset: univ                Batch: 14/15	Loss 134.3885 (134.7632)
2022-11-25 21:03:12,243:INFO: Dataset: univ                Batch: 15/15	Loss 25.0685 (133.6508)
2022-11-25 21:03:13,081:INFO: Dataset: zara1               Batch: 1/8	Loss 135.5995 (135.5995)
2022-11-25 21:03:13,585:INFO: Dataset: zara1               Batch: 2/8	Loss 135.7854 (135.6862)
2022-11-25 21:03:14,100:INFO: Dataset: zara1               Batch: 3/8	Loss 135.4608 (135.6221)
2022-11-25 21:03:14,622:INFO: Dataset: zara1               Batch: 4/8	Loss 134.9891 (135.4762)
2022-11-25 21:03:15,120:INFO: Dataset: zara1               Batch: 5/8	Loss 134.8769 (135.3572)
2022-11-25 21:03:15,622:INFO: Dataset: zara1               Batch: 6/8	Loss 134.9633 (135.2937)
2022-11-25 21:03:16,125:INFO: Dataset: zara1               Batch: 7/8	Loss 134.5810 (135.1995)
2022-11-25 21:03:16,608:INFO: Dataset: zara1               Batch: 8/8	Loss 117.2433 (133.3283)
2022-11-25 21:03:17,444:INFO: Dataset: zara2               Batch:  1/18	Loss 134.3839 (134.3839)
2022-11-25 21:03:17,972:INFO: Dataset: zara2               Batch:  2/18	Loss 133.7831 (134.0909)
2022-11-25 21:03:18,484:INFO: Dataset: zara2               Batch:  3/18	Loss 134.5010 (134.2391)
2022-11-25 21:03:18,996:INFO: Dataset: zara2               Batch:  4/18	Loss 133.8430 (134.1291)
2022-11-25 21:03:19,575:INFO: Dataset: zara2               Batch:  5/18	Loss 133.9066 (134.0822)
2022-11-25 21:03:20,160:INFO: Dataset: zara2               Batch:  6/18	Loss 134.0758 (134.0812)
2022-11-25 21:03:20,699:INFO: Dataset: zara2               Batch:  7/18	Loss 134.0809 (134.0811)
2022-11-25 21:03:21,235:INFO: Dataset: zara2               Batch:  8/18	Loss 134.0938 (134.0828)
2022-11-25 21:03:21,747:INFO: Dataset: zara2               Batch:  9/18	Loss 133.6957 (134.0427)
2022-11-25 21:03:22,299:INFO: Dataset: zara2               Batch: 10/18	Loss 134.1534 (134.0545)
2022-11-25 21:03:22,825:INFO: Dataset: zara2               Batch: 11/18	Loss 133.8192 (134.0342)
2022-11-25 21:03:23,374:INFO: Dataset: zara2               Batch: 12/18	Loss 133.4658 (133.9896)
2022-11-25 21:03:23,890:INFO: Dataset: zara2               Batch: 13/18	Loss 133.5348 (133.9535)
2022-11-25 21:03:24,457:INFO: Dataset: zara2               Batch: 14/18	Loss 133.9116 (133.9505)
2022-11-25 21:03:25,014:INFO: Dataset: zara2               Batch: 15/18	Loss 133.4010 (133.9123)
2022-11-25 21:03:25,553:INFO: Dataset: zara2               Batch: 16/18	Loss 133.4866 (133.8834)
2022-11-25 21:03:26,116:INFO: Dataset: zara2               Batch: 17/18	Loss 133.0821 (133.8356)
2022-11-25 21:03:26,853:INFO: Dataset: zara2               Batch: 18/18	Loss 114.7254 (132.9068)
2022-11-25 21:03:26,922:INFO: - Computing ADE (validation)
2022-11-25 21:03:27,293:INFO: 		 ADE on hotel                     dataset:	 2.477123975753784
2022-11-25 21:03:27,776:INFO: 		 ADE on univ                      dataset:	 3.1542019844055176
2022-11-25 21:03:28,164:INFO: 		 ADE on zara1                     dataset:	 2.54897403717041
2022-11-25 21:03:28,734:INFO: 		 ADE on zara2                     dataset:	 2.768948793411255
2022-11-25 21:03:28,734:INFO: Average validation:	ADE  2.9406	FDE  4.1371
2022-11-25 21:03:28,735:INFO: - Computing ADE (validation o)
2022-11-25 21:03:29,049:INFO: 		 ADE on eth                       dataset:	 2.56278920173645
2022-11-25 21:03:29,049:INFO: Average validation o:	ADE  2.5628	FDE  3.3772
2022-11-25 21:03:29,058:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_295.pth.tar
2022-11-25 21:03:29,058:INFO: 
===> EPOCH: 296 (P3)
2022-11-25 21:03:29,058:INFO: - Computing loss (training)
2022-11-25 21:03:29,890:INFO: Dataset: hotel               Batch: 1/4	Loss 135.5011 (135.5011)
2022-11-25 21:03:30,695:INFO: Dataset: hotel               Batch: 2/4	Loss 134.4776 (134.9808)
2022-11-25 21:03:31,203:INFO: Dataset: hotel               Batch: 3/4	Loss 133.7147 (134.5608)
2022-11-25 21:03:31,666:INFO: Dataset: hotel               Batch: 4/4	Loss 83.0924 (125.8696)
2022-11-25 21:03:32,536:INFO: Dataset: univ                Batch:  1/15	Loss 133.2678 (133.2678)
2022-11-25 21:03:33,103:INFO: Dataset: univ                Batch:  2/15	Loss 133.5588 (133.4177)
2022-11-25 21:03:33,659:INFO: Dataset: univ                Batch:  3/15	Loss 133.4083 (133.4146)
2022-11-25 21:03:34,223:INFO: Dataset: univ                Batch:  4/15	Loss 133.8417 (133.5232)
2022-11-25 21:03:34,775:INFO: Dataset: univ                Batch:  5/15	Loss 134.0041 (133.6170)
2022-11-25 21:03:35,338:INFO: Dataset: univ                Batch:  6/15	Loss 133.5994 (133.6138)
2022-11-25 21:03:35,887:INFO: Dataset: univ                Batch:  7/15	Loss 133.0930 (133.5465)
2022-11-25 21:03:36,433:INFO: Dataset: univ                Batch:  8/15	Loss 133.2745 (133.5143)
2022-11-25 21:03:36,995:INFO: Dataset: univ                Batch:  9/15	Loss 132.7078 (133.4181)
2022-11-25 21:03:37,541:INFO: Dataset: univ                Batch: 10/15	Loss 133.0102 (133.3803)
2022-11-25 21:03:38,109:INFO: Dataset: univ                Batch: 11/15	Loss 132.5001 (133.2912)
2022-11-25 21:03:38,659:INFO: Dataset: univ                Batch: 12/15	Loss 133.2690 (133.2894)
2022-11-25 21:03:39,210:INFO: Dataset: univ                Batch: 13/15	Loss 133.1355 (133.2777)
2022-11-25 21:03:39,752:INFO: Dataset: univ                Batch: 14/15	Loss 134.7990 (133.3698)
2022-11-25 21:03:40,193:INFO: Dataset: univ                Batch: 15/15	Loss 24.8940 (132.1207)
2022-11-25 21:03:40,999:INFO: Dataset: zara1               Batch: 1/8	Loss 134.5093 (134.5093)
2022-11-25 21:03:41,501:INFO: Dataset: zara1               Batch: 2/8	Loss 133.7591 (134.1358)
2022-11-25 21:03:42,012:INFO: Dataset: zara1               Batch: 3/8	Loss 133.7215 (133.9689)
2022-11-25 21:03:42,513:INFO: Dataset: zara1               Batch: 4/8	Loss 133.8709 (133.9462)
2022-11-25 21:03:43,021:INFO: Dataset: zara1               Batch: 5/8	Loss 133.6576 (133.8895)
2022-11-25 21:03:43,522:INFO: Dataset: zara1               Batch: 6/8	Loss 133.2607 (133.7905)
2022-11-25 21:03:44,020:INFO: Dataset: zara1               Batch: 7/8	Loss 132.6507 (133.6443)
2022-11-25 21:03:44,507:INFO: Dataset: zara1               Batch: 8/8	Loss 115.1140 (131.6059)
2022-11-25 21:03:45,331:INFO: Dataset: zara2               Batch:  1/18	Loss 132.6069 (132.6069)
2022-11-25 21:03:45,850:INFO: Dataset: zara2               Batch:  2/18	Loss 133.1400 (132.8715)
2022-11-25 21:03:46,364:INFO: Dataset: zara2               Batch:  3/18	Loss 132.7131 (132.8139)
2022-11-25 21:03:46,876:INFO: Dataset: zara2               Batch:  4/18	Loss 133.7808 (133.0444)
2022-11-25 21:03:47,388:INFO: Dataset: zara2               Batch:  5/18	Loss 133.2439 (133.0847)
2022-11-25 21:03:47,901:INFO: Dataset: zara2               Batch:  6/18	Loss 132.2829 (132.9628)
2022-11-25 21:03:48,410:INFO: Dataset: zara2               Batch:  7/18	Loss 132.7571 (132.9368)
2022-11-25 21:03:48,921:INFO: Dataset: zara2               Batch:  8/18	Loss 137.2565 (133.4577)
2022-11-25 21:03:49,432:INFO: Dataset: zara2               Batch:  9/18	Loss 132.3736 (133.3277)
2022-11-25 21:03:49,946:INFO: Dataset: zara2               Batch: 10/18	Loss 132.4272 (133.2385)
2022-11-25 21:03:50,497:INFO: Dataset: zara2               Batch: 11/18	Loss 132.7201 (133.1920)
2022-11-25 21:03:51,011:INFO: Dataset: zara2               Batch: 12/18	Loss 132.8217 (133.1616)
2022-11-25 21:03:51,521:INFO: Dataset: zara2               Batch: 13/18	Loss 133.3833 (133.1781)
2022-11-25 21:03:52,034:INFO: Dataset: zara2               Batch: 14/18	Loss 132.5676 (133.1359)
2022-11-25 21:03:52,545:INFO: Dataset: zara2               Batch: 15/18	Loss 133.1739 (133.1384)
2022-11-25 21:03:53,058:INFO: Dataset: zara2               Batch: 16/18	Loss 133.0264 (133.1320)
2022-11-25 21:03:53,567:INFO: Dataset: zara2               Batch: 17/18	Loss 131.9697 (133.0599)
2022-11-25 21:03:54,065:INFO: Dataset: zara2               Batch: 18/18	Loss 113.5713 (131.9677)
2022-11-25 21:03:54,143:INFO: - Computing ADE (validation)
2022-11-25 21:03:54,507:INFO: 		 ADE on hotel                     dataset:	 2.4887850284576416
2022-11-25 21:03:54,947:INFO: 		 ADE on univ                      dataset:	 3.1666953563690186
2022-11-25 21:03:55,303:INFO: 		 ADE on zara1                     dataset:	 2.5185186862945557
2022-11-25 21:03:55,858:INFO: 		 ADE on zara2                     dataset:	 2.726567268371582
2022-11-25 21:03:55,859:INFO: Average validation:	ADE  2.9304	FDE  4.1455
2022-11-25 21:03:55,860:INFO: - Computing ADE (validation o)
2022-11-25 21:03:56,169:INFO: 		 ADE on eth                       dataset:	 2.5174057483673096
2022-11-25 21:03:56,169:INFO: Average validation o:	ADE  2.5174	FDE  3.1350
2022-11-25 21:03:56,178:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_296.pth.tar
2022-11-25 21:03:56,178:INFO: 
===> EPOCH: 297 (P3)
2022-11-25 21:03:56,179:INFO: - Computing loss (training)
2022-11-25 21:03:56,904:INFO: Dataset: hotel               Batch: 1/4	Loss 133.6551 (133.6551)
2022-11-25 21:03:57,402:INFO: Dataset: hotel               Batch: 2/4	Loss 133.9149 (133.7790)
2022-11-25 21:03:57,898:INFO: Dataset: hotel               Batch: 3/4	Loss 135.1864 (134.2534)
2022-11-25 21:03:58,353:INFO: Dataset: hotel               Batch: 4/4	Loss 81.5491 (124.6582)
2022-11-25 21:03:59,196:INFO: Dataset: univ                Batch:  1/15	Loss 132.3719 (132.3719)
2022-11-25 21:03:59,732:INFO: Dataset: univ                Batch:  2/15	Loss 132.5263 (132.4466)
2022-11-25 21:04:00,376:INFO: Dataset: univ                Batch:  3/15	Loss 132.4811 (132.4591)
2022-11-25 21:04:00,926:INFO: Dataset: univ                Batch:  4/15	Loss 132.6923 (132.5153)
2022-11-25 21:04:01,487:INFO: Dataset: univ                Batch:  5/15	Loss 132.9490 (132.6027)
2022-11-25 21:04:02,172:INFO: Dataset: univ                Batch:  6/15	Loss 131.8277 (132.4679)
2022-11-25 21:04:02,784:INFO: Dataset: univ                Batch:  7/15	Loss 131.9770 (132.4017)
2022-11-25 21:04:03,439:INFO: Dataset: univ                Batch:  8/15	Loss 131.8514 (132.3298)
2022-11-25 21:04:04,012:INFO: Dataset: univ                Batch:  9/15	Loss 132.0923 (132.3048)
2022-11-25 21:04:04,589:INFO: Dataset: univ                Batch: 10/15	Loss 132.8686 (132.3602)
2022-11-25 21:04:05,140:INFO: Dataset: univ                Batch: 11/15	Loss 131.8182 (132.3095)
2022-11-25 21:04:05,708:INFO: Dataset: univ                Batch: 12/15	Loss 132.8471 (132.3512)
2022-11-25 21:04:06,250:INFO: Dataset: univ                Batch: 13/15	Loss 131.6700 (132.2980)
2022-11-25 21:04:06,790:INFO: Dataset: univ                Batch: 14/15	Loss 131.5594 (132.2458)
2022-11-25 21:04:07,230:INFO: Dataset: univ                Batch: 15/15	Loss 24.6762 (130.5992)
2022-11-25 21:04:08,032:INFO: Dataset: zara1               Batch: 1/8	Loss 132.3934 (132.3934)
2022-11-25 21:04:08,541:INFO: Dataset: zara1               Batch: 2/8	Loss 131.9437 (132.1634)
2022-11-25 21:04:09,046:INFO: Dataset: zara1               Batch: 3/8	Loss 131.8436 (132.0584)
2022-11-25 21:04:09,556:INFO: Dataset: zara1               Batch: 4/8	Loss 132.2963 (132.1141)
2022-11-25 21:04:10,062:INFO: Dataset: zara1               Batch: 5/8	Loss 132.5304 (132.1910)
2022-11-25 21:04:10,571:INFO: Dataset: zara1               Batch: 6/8	Loss 132.5215 (132.2502)
2022-11-25 21:04:11,076:INFO: Dataset: zara1               Batch: 7/8	Loss 131.6310 (132.1571)
2022-11-25 21:04:11,580:INFO: Dataset: zara1               Batch: 8/8	Loss 113.4128 (129.5625)
2022-11-25 21:04:12,388:INFO: Dataset: zara2               Batch:  1/18	Loss 132.0053 (132.0053)
2022-11-25 21:04:12,901:INFO: Dataset: zara2               Batch:  2/18	Loss 130.8669 (131.4198)
2022-11-25 21:04:13,413:INFO: Dataset: zara2               Batch:  3/18	Loss 131.0530 (131.2969)
2022-11-25 21:04:13,927:INFO: Dataset: zara2               Batch:  4/18	Loss 131.5440 (131.3600)
2022-11-25 21:04:14,439:INFO: Dataset: zara2               Batch:  5/18	Loss 131.4451 (131.3767)
2022-11-25 21:04:14,962:INFO: Dataset: zara2               Batch:  6/18	Loss 131.4722 (131.3917)
2022-11-25 21:04:15,481:INFO: Dataset: zara2               Batch:  7/18	Loss 135.1104 (131.9378)
2022-11-25 21:04:16,065:INFO: Dataset: zara2               Batch:  8/18	Loss 131.7460 (131.9143)
2022-11-25 21:04:16,612:INFO: Dataset: zara2               Batch:  9/18	Loss 131.0330 (131.8150)
2022-11-25 21:04:17,159:INFO: Dataset: zara2               Batch: 10/18	Loss 130.7241 (131.7022)
2022-11-25 21:04:17,725:INFO: Dataset: zara2               Batch: 11/18	Loss 130.9676 (131.6353)
2022-11-25 21:04:18,288:INFO: Dataset: zara2               Batch: 12/18	Loss 131.3784 (131.6100)
2022-11-25 21:04:18,818:INFO: Dataset: zara2               Batch: 13/18	Loss 131.3039 (131.5853)
2022-11-25 21:04:19,353:INFO: Dataset: zara2               Batch: 14/18	Loss 130.8672 (131.5396)
2022-11-25 21:04:19,919:INFO: Dataset: zara2               Batch: 15/18	Loss 130.8221 (131.4907)
2022-11-25 21:04:20,457:INFO: Dataset: zara2               Batch: 16/18	Loss 130.8325 (131.4476)
2022-11-25 21:04:21,042:INFO: Dataset: zara2               Batch: 17/18	Loss 130.9584 (131.4185)
2022-11-25 21:04:21,561:INFO: Dataset: zara2               Batch: 18/18	Loss 112.4350 (130.5021)
2022-11-25 21:04:21,629:INFO: - Computing ADE (validation)
2022-11-25 21:04:22,006:INFO: 		 ADE on hotel                     dataset:	 2.5014407634735107
2022-11-25 21:04:22,482:INFO: 		 ADE on univ                      dataset:	 3.082512855529785
2022-11-25 21:04:22,851:INFO: 		 ADE on zara1                     dataset:	 2.4710094928741455
2022-11-25 21:04:23,445:INFO: 		 ADE on zara2                     dataset:	 2.662174940109253
2022-11-25 21:04:23,445:INFO: Average validation:	ADE  2.8610	FDE  4.0262
2022-11-25 21:04:23,446:INFO: - Computing ADE (validation o)
2022-11-25 21:04:23,777:INFO: 		 ADE on eth                       dataset:	 2.3989455699920654
2022-11-25 21:04:23,777:INFO: Average validation o:	ADE  2.3989	FDE  2.9090
2022-11-25 21:04:23,786:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_297.pth.tar
2022-11-25 21:04:23,786:INFO: 
===> EPOCH: 298 (P3)
2022-11-25 21:04:23,787:INFO: - Computing loss (training)
2022-11-25 21:04:24,582:INFO: Dataset: hotel               Batch: 1/4	Loss 136.5173 (136.5173)
2022-11-25 21:04:25,105:INFO: Dataset: hotel               Batch: 2/4	Loss 131.0295 (133.8060)
2022-11-25 21:04:25,620:INFO: Dataset: hotel               Batch: 3/4	Loss 131.8454 (133.1875)
2022-11-25 21:04:26,101:INFO: Dataset: hotel               Batch: 4/4	Loss 80.3217 (123.2142)
2022-11-25 21:04:27,042:INFO: Dataset: univ                Batch:  1/15	Loss 131.8648 (131.8648)
2022-11-25 21:04:27,668:INFO: Dataset: univ                Batch:  2/15	Loss 130.7822 (131.3319)
2022-11-25 21:04:28,235:INFO: Dataset: univ                Batch:  3/15	Loss 130.8356 (131.1712)
2022-11-25 21:04:28,851:INFO: Dataset: univ                Batch:  4/15	Loss 131.2612 (131.1940)
2022-11-25 21:04:29,456:INFO: Dataset: univ                Batch:  5/15	Loss 130.3807 (131.0291)
2022-11-25 21:04:30,311:INFO: Dataset: univ                Batch:  6/15	Loss 130.7657 (130.9865)
2022-11-25 21:04:30,855:INFO: Dataset: univ                Batch:  7/15	Loss 130.5691 (130.9293)
2022-11-25 21:04:31,397:INFO: Dataset: univ                Batch:  8/15	Loss 130.3392 (130.8551)
2022-11-25 21:04:31,937:INFO: Dataset: univ                Batch:  9/15	Loss 130.3538 (130.8003)
2022-11-25 21:04:32,473:INFO: Dataset: univ                Batch: 10/15	Loss 130.7860 (130.7990)
2022-11-25 21:04:33,026:INFO: Dataset: univ                Batch: 11/15	Loss 130.7283 (130.7920)
2022-11-25 21:04:33,575:INFO: Dataset: univ                Batch: 12/15	Loss 130.4567 (130.7623)
2022-11-25 21:04:34,123:INFO: Dataset: univ                Batch: 13/15	Loss 130.8918 (130.7731)
2022-11-25 21:04:34,672:INFO: Dataset: univ                Batch: 14/15	Loss 130.5521 (130.7582)
2022-11-25 21:04:35,134:INFO: Dataset: univ                Batch: 15/15	Loss 24.3537 (129.2253)
2022-11-25 21:04:36,010:INFO: Dataset: zara1               Batch: 1/8	Loss 130.7277 (130.7277)
2022-11-25 21:04:36,511:INFO: Dataset: zara1               Batch: 2/8	Loss 131.0574 (130.8933)
2022-11-25 21:04:37,025:INFO: Dataset: zara1               Batch: 3/8	Loss 130.7314 (130.8332)
2022-11-25 21:04:37,535:INFO: Dataset: zara1               Batch: 4/8	Loss 130.8141 (130.8283)
2022-11-25 21:04:38,034:INFO: Dataset: zara1               Batch: 5/8	Loss 131.0007 (130.8609)
2022-11-25 21:04:38,535:INFO: Dataset: zara1               Batch: 6/8	Loss 130.2561 (130.7695)
2022-11-25 21:04:39,036:INFO: Dataset: zara1               Batch: 7/8	Loss 130.7474 (130.7665)
2022-11-25 21:04:39,519:INFO: Dataset: zara1               Batch: 8/8	Loss 112.9464 (128.9282)
2022-11-25 21:04:40,338:INFO: Dataset: zara2               Batch:  1/18	Loss 130.4290 (130.4290)
2022-11-25 21:04:40,856:INFO: Dataset: zara2               Batch:  2/18	Loss 129.9305 (130.1867)
2022-11-25 21:04:41,364:INFO: Dataset: zara2               Batch:  3/18	Loss 129.8415 (130.0681)
2022-11-25 21:04:41,875:INFO: Dataset: zara2               Batch:  4/18	Loss 129.3448 (129.8894)
2022-11-25 21:04:42,395:INFO: Dataset: zara2               Batch:  5/18	Loss 129.7901 (129.8702)
2022-11-25 21:04:42,908:INFO: Dataset: zara2               Batch:  6/18	Loss 129.3511 (129.7857)
2022-11-25 21:04:43,417:INFO: Dataset: zara2               Batch:  7/18	Loss 129.7513 (129.7807)
2022-11-25 21:04:43,924:INFO: Dataset: zara2               Batch:  8/18	Loss 130.0571 (129.8183)
2022-11-25 21:04:44,433:INFO: Dataset: zara2               Batch:  9/18	Loss 129.3389 (129.7617)
2022-11-25 21:04:44,939:INFO: Dataset: zara2               Batch: 10/18	Loss 129.4420 (129.7263)
2022-11-25 21:04:45,450:INFO: Dataset: zara2               Batch: 11/18	Loss 129.9180 (129.7453)
2022-11-25 21:04:45,960:INFO: Dataset: zara2               Batch: 12/18	Loss 128.7773 (129.6608)
2022-11-25 21:04:46,469:INFO: Dataset: zara2               Batch: 13/18	Loss 129.2194 (129.6273)
2022-11-25 21:04:46,981:INFO: Dataset: zara2               Batch: 14/18	Loss 129.5381 (129.6215)
2022-11-25 21:04:47,488:INFO: Dataset: zara2               Batch: 15/18	Loss 129.3564 (129.6015)
2022-11-25 21:04:47,997:INFO: Dataset: zara2               Batch: 16/18	Loss 128.8889 (129.5579)
2022-11-25 21:04:48,508:INFO: Dataset: zara2               Batch: 17/18	Loss 129.2316 (129.5403)
2022-11-25 21:04:49,005:INFO: Dataset: zara2               Batch: 18/18	Loss 110.9426 (128.7286)
2022-11-25 21:04:49,066:INFO: - Computing ADE (validation)
2022-11-25 21:04:49,460:INFO: 		 ADE on hotel                     dataset:	 2.462594747543335
2022-11-25 21:04:49,912:INFO: 		 ADE on univ                      dataset:	 3.051478862762451
2022-11-25 21:04:50,259:INFO: 		 ADE on zara1                     dataset:	 2.4258651733398438
2022-11-25 21:04:50,824:INFO: 		 ADE on zara2                     dataset:	 2.6604623794555664
2022-11-25 21:04:50,824:INFO: Average validation:	ADE  2.8394	FDE  4.0180
2022-11-25 21:04:50,825:INFO: - Computing ADE (validation o)
2022-11-25 21:04:51,129:INFO: 		 ADE on eth                       dataset:	 2.380631685256958
2022-11-25 21:04:51,129:INFO: Average validation o:	ADE  2.3806	FDE  3.1199
2022-11-25 21:04:51,138:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_298.pth.tar
2022-11-25 21:04:51,138:INFO: 
===> EPOCH: 299 (P3)
2022-11-25 21:04:51,139:INFO: - Computing loss (training)
2022-11-25 21:04:51,874:INFO: Dataset: hotel               Batch: 1/4	Loss 130.2135 (130.2135)
2022-11-25 21:04:52,385:INFO: Dataset: hotel               Batch: 2/4	Loss 130.6333 (130.4156)
2022-11-25 21:04:52,890:INFO: Dataset: hotel               Batch: 3/4	Loss 129.4824 (130.1203)
2022-11-25 21:04:53,343:INFO: Dataset: hotel               Batch: 4/4	Loss 79.1180 (121.6423)
2022-11-25 21:04:54,219:INFO: Dataset: univ                Batch:  1/15	Loss 129.6219 (129.6219)
2022-11-25 21:04:54,813:INFO: Dataset: univ                Batch:  2/15	Loss 129.6504 (129.6358)
2022-11-25 21:04:55,389:INFO: Dataset: univ                Batch:  3/15	Loss 129.3163 (129.5394)
2022-11-25 21:04:55,938:INFO: Dataset: univ                Batch:  4/15	Loss 129.6088 (129.5553)
2022-11-25 21:04:56,498:INFO: Dataset: univ                Batch:  5/15	Loss 129.5392 (129.5520)
2022-11-25 21:04:57,077:INFO: Dataset: univ                Batch:  6/15	Loss 129.0519 (129.4704)
2022-11-25 21:04:57,651:INFO: Dataset: univ                Batch:  7/15	Loss 128.9087 (129.3907)
2022-11-25 21:04:58,288:INFO: Dataset: univ                Batch:  8/15	Loss 130.6573 (129.5364)
2022-11-25 21:04:58,963:INFO: Dataset: univ                Batch:  9/15	Loss 128.6788 (129.4316)
2022-11-25 21:04:59,553:INFO: Dataset: univ                Batch: 10/15	Loss 129.0966 (129.3976)
2022-11-25 21:05:00,127:INFO: Dataset: univ                Batch: 11/15	Loss 128.9266 (129.3551)
2022-11-25 21:05:00,693:INFO: Dataset: univ                Batch: 12/15	Loss 128.9909 (129.3220)
2022-11-25 21:05:01,234:INFO: Dataset: univ                Batch: 13/15	Loss 129.0701 (129.3024)
2022-11-25 21:05:01,780:INFO: Dataset: univ                Batch: 14/15	Loss 129.1850 (129.2939)
2022-11-25 21:05:02,247:INFO: Dataset: univ                Batch: 15/15	Loss 24.2299 (128.3827)
2022-11-25 21:05:03,140:INFO: Dataset: zara1               Batch: 1/8	Loss 129.4389 (129.4389)
2022-11-25 21:05:03,678:INFO: Dataset: zara1               Batch: 2/8	Loss 128.5503 (128.9973)
2022-11-25 21:05:04,238:INFO: Dataset: zara1               Batch: 3/8	Loss 129.1278 (129.0379)
2022-11-25 21:05:04,799:INFO: Dataset: zara1               Batch: 4/8	Loss 130.1569 (129.3136)
2022-11-25 21:05:05,330:INFO: Dataset: zara1               Batch: 5/8	Loss 129.9463 (129.4483)
2022-11-25 21:05:05,873:INFO: Dataset: zara1               Batch: 6/8	Loss 128.9093 (129.3655)
2022-11-25 21:05:06,391:INFO: Dataset: zara1               Batch: 7/8	Loss 129.4053 (129.3710)
2022-11-25 21:05:06,886:INFO: Dataset: zara1               Batch: 8/8	Loss 111.6468 (127.0762)
2022-11-25 21:05:07,772:INFO: Dataset: zara2               Batch:  1/18	Loss 128.9921 (128.9921)
2022-11-25 21:05:08,438:INFO: Dataset: zara2               Batch:  2/18	Loss 128.4444 (128.7279)
2022-11-25 21:05:08,990:INFO: Dataset: zara2               Batch:  3/18	Loss 127.7531 (128.3832)
2022-11-25 21:05:09,555:INFO: Dataset: zara2               Batch:  4/18	Loss 128.5004 (128.4075)
2022-11-25 21:05:10,097:INFO: Dataset: zara2               Batch:  5/18	Loss 128.1909 (128.3660)
2022-11-25 21:05:10,665:INFO: Dataset: zara2               Batch:  6/18	Loss 128.3331 (128.3608)
2022-11-25 21:05:11,210:INFO: Dataset: zara2               Batch:  7/18	Loss 128.3108 (128.3535)
2022-11-25 21:05:11,740:INFO: Dataset: zara2               Batch:  8/18	Loss 127.9886 (128.3043)
2022-11-25 21:05:12,290:INFO: Dataset: zara2               Batch:  9/18	Loss 127.9780 (128.2671)
2022-11-25 21:05:12,821:INFO: Dataset: zara2               Batch: 10/18	Loss 127.5444 (128.1885)
2022-11-25 21:05:13,343:INFO: Dataset: zara2               Batch: 11/18	Loss 127.6499 (128.1409)
2022-11-25 21:05:13,887:INFO: Dataset: zara2               Batch: 12/18	Loss 128.2036 (128.1462)
2022-11-25 21:05:14,637:INFO: Dataset: zara2               Batch: 13/18	Loss 127.9747 (128.1323)
2022-11-25 21:05:15,452:INFO: Dataset: zara2               Batch: 14/18	Loss 127.7860 (128.1064)
2022-11-25 21:05:16,001:INFO: Dataset: zara2               Batch: 15/18	Loss 127.1441 (128.0399)
2022-11-25 21:05:16,550:INFO: Dataset: zara2               Batch: 16/18	Loss 127.9702 (128.0353)
2022-11-25 21:05:17,091:INFO: Dataset: zara2               Batch: 17/18	Loss 127.7918 (128.0210)
2022-11-25 21:05:17,605:INFO: Dataset: zara2               Batch: 18/18	Loss 109.7040 (127.1610)
2022-11-25 21:05:17,670:INFO: - Computing ADE (validation)
2022-11-25 21:05:18,032:INFO: 		 ADE on hotel                     dataset:	 2.4118409156799316
2022-11-25 21:05:18,476:INFO: 		 ADE on univ                      dataset:	 3.024372100830078
2022-11-25 21:05:18,840:INFO: 		 ADE on zara1                     dataset:	 2.346130609512329
2022-11-25 21:05:19,398:INFO: 		 ADE on zara2                     dataset:	 2.625941276550293
2022-11-25 21:05:19,398:INFO: Average validation:	ADE  2.8052	FDE  3.9557
2022-11-25 21:05:19,399:INFO: - Computing ADE (validation o)
2022-11-25 21:05:19,700:INFO: 		 ADE on eth                       dataset:	 2.2964975833892822
2022-11-25 21:05:19,700:INFO: Average validation o:	ADE  2.2965	FDE  3.0728
2022-11-25 21:05:19,709:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_299.pth.tar
2022-11-25 21:05:19,709:INFO: 
===> EPOCH: 300 (P3)
2022-11-25 21:05:19,709:INFO: - Computing loss (training)
2022-11-25 21:05:20,437:INFO: Dataset: hotel               Batch: 1/4	Loss 129.6993 (129.6993)
2022-11-25 21:05:20,943:INFO: Dataset: hotel               Batch: 2/4	Loss 127.9163 (128.8231)
2022-11-25 21:05:21,442:INFO: Dataset: hotel               Batch: 3/4	Loss 128.9686 (128.8729)
2022-11-25 21:05:21,922:INFO: Dataset: hotel               Batch: 4/4	Loss 78.2884 (119.7971)
2022-11-25 21:05:22,772:INFO: Dataset: univ                Batch:  1/15	Loss 127.8732 (127.8732)
2022-11-25 21:05:23,338:INFO: Dataset: univ                Batch:  2/15	Loss 128.1601 (128.0250)
2022-11-25 21:05:23,926:INFO: Dataset: univ                Batch:  3/15	Loss 132.3459 (129.3482)
2022-11-25 21:05:24,506:INFO: Dataset: univ                Batch:  4/15	Loss 127.8955 (128.9875)
2022-11-25 21:05:25,049:INFO: Dataset: univ                Batch:  5/15	Loss 127.8224 (128.7607)
2022-11-25 21:05:25,596:INFO: Dataset: univ                Batch:  6/15	Loss 129.2349 (128.8422)
2022-11-25 21:05:26,145:INFO: Dataset: univ                Batch:  7/15	Loss 128.1552 (128.7374)
2022-11-25 21:05:26,693:INFO: Dataset: univ                Batch:  8/15	Loss 128.8754 (128.7554)
2022-11-25 21:05:27,233:INFO: Dataset: univ                Batch:  9/15	Loss 128.6436 (128.7432)
2022-11-25 21:05:27,778:INFO: Dataset: univ                Batch: 10/15	Loss 128.4194 (128.7114)
2022-11-25 21:05:28,317:INFO: Dataset: univ                Batch: 11/15	Loss 128.7156 (128.7117)
2022-11-25 21:05:28,860:INFO: Dataset: univ                Batch: 12/15	Loss 128.2911 (128.6761)
2022-11-25 21:05:29,398:INFO: Dataset: univ                Batch: 13/15	Loss 129.2384 (128.7180)
2022-11-25 21:05:29,943:INFO: Dataset: univ                Batch: 14/15	Loss 127.4562 (128.6244)
2022-11-25 21:05:30,376:INFO: Dataset: univ                Batch: 15/15	Loss 23.9259 (127.3592)
2022-11-25 21:05:31,167:INFO: Dataset: zara1               Batch: 1/8	Loss 127.5316 (127.5316)
2022-11-25 21:05:31,676:INFO: Dataset: zara1               Batch: 2/8	Loss 127.4891 (127.5094)
2022-11-25 21:05:32,173:INFO: Dataset: zara1               Batch: 3/8	Loss 127.7060 (127.5735)
2022-11-25 21:05:32,674:INFO: Dataset: zara1               Batch: 4/8	Loss 127.7456 (127.6128)
2022-11-25 21:05:33,173:INFO: Dataset: zara1               Batch: 5/8	Loss 127.6046 (127.6113)
2022-11-25 21:05:33,693:INFO: Dataset: zara1               Batch: 6/8	Loss 127.3011 (127.5529)
2022-11-25 21:05:34,189:INFO: Dataset: zara1               Batch: 7/8	Loss 127.4694 (127.5415)
2022-11-25 21:05:34,672:INFO: Dataset: zara1               Batch: 8/8	Loss 108.7356 (125.4926)
2022-11-25 21:05:35,495:INFO: Dataset: zara2               Batch:  1/18	Loss 127.1269 (127.1269)
2022-11-25 21:05:36,003:INFO: Dataset: zara2               Batch:  2/18	Loss 126.5936 (126.8522)
2022-11-25 21:05:36,515:INFO: Dataset: zara2               Batch:  3/18	Loss 126.8739 (126.8598)
2022-11-25 21:05:37,033:INFO: Dataset: zara2               Batch:  4/18	Loss 126.7026 (126.8215)
2022-11-25 21:05:37,613:INFO: Dataset: zara2               Batch:  5/18	Loss 126.4269 (126.7472)
2022-11-25 21:05:38,450:INFO: Dataset: zara2               Batch:  6/18	Loss 126.1723 (126.6545)
2022-11-25 21:05:38,988:INFO: Dataset: zara2               Batch:  7/18	Loss 126.0116 (126.5628)
2022-11-25 21:05:39,511:INFO: Dataset: zara2               Batch:  8/18	Loss 126.3390 (126.5347)
2022-11-25 21:05:40,060:INFO: Dataset: zara2               Batch:  9/18	Loss 126.5080 (126.5318)
2022-11-25 21:05:40,592:INFO: Dataset: zara2               Batch: 10/18	Loss 126.8165 (126.5588)
2022-11-25 21:05:41,208:INFO: Dataset: zara2               Batch: 11/18	Loss 126.8416 (126.5817)
2022-11-25 21:05:41,737:INFO: Dataset: zara2               Batch: 12/18	Loss 126.6251 (126.5852)
2022-11-25 21:05:42,257:INFO: Dataset: zara2               Batch: 13/18	Loss 126.2792 (126.5639)
2022-11-25 21:05:42,775:INFO: Dataset: zara2               Batch: 14/18	Loss 126.6722 (126.5725)
