2022-11-03 14:12:17,245:INFO: Initializing Training Set
2022-11-03 14:12:21,364:INFO: Initializing Validation Set
2022-11-03 14:12:21,873:INFO: Initializing Validation O Set
2022-11-03 14:12:24,774:INFO: => loaded checkpoint './models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_550.pth.tar' (epoch 551)
2022-11-03 14:12:24,775:INFO: 
===> EPOCH: 551 (P4)
2022-11-03 14:12:24,775:INFO: - Computing loss (training)
2022-11-03 14:12:48,291:INFO: Batch:  1/31	Total Loss 94.1080 (94.1080)
2022-11-03 14:12:50,133:INFO: Batch:  2/31	Total Loss 93.3412 (93.7174)
2022-11-03 14:12:51,948:INFO: Batch:  3/31	Total Loss 96.0436 (94.4381)
2022-11-03 14:12:54,168:INFO: Batch:  4/31	Total Loss 97.4904 (95.2113)
2022-11-03 14:12:56,062:INFO: Batch:  5/31	Total Loss 96.8468 (95.5139)
2022-11-03 14:12:57,754:INFO: Batch:  6/31	Total Loss 93.9215 (95.2549)
2022-11-03 14:12:59,317:INFO: Batch:  7/31	Total Loss 97.1185 (95.4932)
2022-11-03 14:13:00,969:INFO: Batch:  8/31	Total Loss 95.3969 (95.4812)
2022-11-03 14:13:02,592:INFO: Batch:  9/31	Total Loss 95.6345 (95.4976)
2022-11-03 14:13:04,140:INFO: Batch: 10/31	Total Loss 97.1519 (95.6347)
2022-11-03 14:13:05,649:INFO: Batch: 11/31	Total Loss 95.7073 (95.6416)
2022-11-03 14:13:07,294:INFO: Batch: 12/31	Total Loss 93.5160 (95.4527)
2022-11-03 14:13:08,666:INFO: Batch: 13/31	Total Loss 95.4193 (95.4501)
2022-11-03 14:13:10,028:INFO: Batch: 14/31	Total Loss 96.3273 (95.5127)
2022-11-03 14:13:11,391:INFO: Batch: 15/31	Total Loss 96.2046 (95.5625)
2022-11-03 14:13:12,734:INFO: Batch: 16/31	Total Loss 97.3747 (95.6683)
2022-11-03 14:13:14,131:INFO: Batch: 17/31	Total Loss 94.8856 (95.6207)
2022-11-03 14:13:15,538:INFO: Batch: 18/31	Total Loss 95.5746 (95.6184)
2022-11-03 14:13:17,283:INFO: Batch: 19/31	Total Loss 95.8383 (95.6293)
2022-11-03 14:13:18,884:INFO: Batch: 20/31	Total Loss 95.1920 (95.6069)
2022-11-03 14:13:20,500:INFO: Batch: 21/31	Total Loss 95.8701 (95.6189)
2022-11-03 14:13:22,310:INFO: Batch: 22/31	Total Loss 94.4427 (95.5663)
2022-11-03 14:13:24,056:INFO: Batch: 23/31	Total Loss 96.1764 (95.5953)
2022-11-03 14:13:25,857:INFO: Batch: 24/31	Total Loss 92.1389 (95.4347)
2022-11-03 14:13:27,570:INFO: Batch: 25/31	Total Loss 96.6688 (95.4812)
2022-11-03 14:13:29,364:INFO: Batch: 26/31	Total Loss 96.1972 (95.5077)
2022-11-03 14:13:31,183:INFO: Batch: 27/31	Total Loss 95.2868 (95.4985)
2022-11-03 14:13:33,032:INFO: Batch: 28/31	Total Loss 95.1801 (95.4868)
2022-11-03 14:13:34,774:INFO: Batch: 29/31	Total Loss 96.9222 (95.5319)
2022-11-03 14:13:36,446:INFO: Batch: 30/31	Total Loss 99.3083 (95.6484)
2022-11-03 14:13:37,833:INFO: Batch: 31/31	Total Loss -17.7654 (94.5083)
2022-11-03 14:13:40,717:INFO: - Computing ADE (validation o)
2022-11-03 14:13:48,646:INFO: 		 ADE on eth                       dataset:	 2.8654067516326904
2022-11-03 14:13:48,646:INFO: Average validation o:	ADE  2.8654	FDE  4.8447
2022-11-03 14:13:48,648:INFO: - Computing ADE (validation)
2022-11-03 14:13:55,668:INFO: 		 ADE on hotel                     dataset:	 0.9448704123497009
2022-11-03 14:14:03,238:INFO: 		 ADE on univ                      dataset:	 1.5022486448287964
2022-11-03 14:14:09,348:INFO: 		 ADE on zara1                     dataset:	 2.538203477859497
2022-11-03 14:14:15,550:INFO: 		 ADE on zara2                     dataset:	 1.4249584674835205
2022-11-03 14:14:15,550:INFO: Average validation:	ADE  1.5036	FDE  2.7195
2022-11-03 14:14:15,551:INFO: - Computing ADE (training)
