2022-11-25 21:52:03,655:INFO: Initializing Training Set
2022-11-25 21:52:05,293:INFO: Initializing Validation Set
2022-11-25 21:52:05,487:INFO: Initializing Validation O Set
2022-11-25 21:52:07,724:INFO: 
===> EPOCH: 251 (P3)
2022-11-25 21:52:07,724:INFO: - Computing loss (training)
2022-11-25 21:52:08,469:INFO: Dataset: hotel               Batch: 1/4	Loss 219.7869 (219.7869)
2022-11-25 21:52:08,969:INFO: Dataset: hotel               Batch: 2/4	Loss 219.1708 (219.4766)
2022-11-25 21:52:09,476:INFO: Dataset: hotel               Batch: 3/4	Loss 217.2637 (218.7026)
2022-11-25 21:52:09,935:INFO: Dataset: hotel               Batch: 4/4	Loss 135.1136 (204.4771)
2022-11-25 21:52:10,803:INFO: Dataset: univ                Batch:  1/15	Loss 207.0331 (207.0331)
2022-11-25 21:52:11,341:INFO: Dataset: univ                Batch:  2/15	Loss 206.8725 (206.9540)
2022-11-25 21:52:11,977:INFO: Dataset: univ                Batch:  3/15	Loss 206.8473 (206.9163)
2022-11-25 21:52:12,528:INFO: Dataset: univ                Batch:  4/15	Loss 206.8821 (206.9073)
2022-11-25 21:52:13,065:INFO: Dataset: univ                Batch:  5/15	Loss 207.7239 (207.0603)
2022-11-25 21:52:13,612:INFO: Dataset: univ                Batch:  6/15	Loss 206.5736 (206.9748)
2022-11-25 21:52:14,154:INFO: Dataset: univ                Batch:  7/15	Loss 206.3585 (206.8854)
2022-11-25 21:52:14,692:INFO: Dataset: univ                Batch:  8/15	Loss 206.5217 (206.8411)
2022-11-25 21:52:15,231:INFO: Dataset: univ                Batch:  9/15	Loss 207.1259 (206.8702)
2022-11-25 21:52:15,762:INFO: Dataset: univ                Batch: 10/15	Loss 207.9603 (206.9612)
2022-11-25 21:52:16,327:INFO: Dataset: univ                Batch: 11/15	Loss 206.4199 (206.9062)
2022-11-25 21:52:16,862:INFO: Dataset: univ                Batch: 12/15	Loss 207.6184 (206.9590)
2022-11-25 21:52:17,410:INFO: Dataset: univ                Batch: 13/15	Loss 206.6872 (206.9382)
2022-11-25 21:52:17,955:INFO: Dataset: univ                Batch: 14/15	Loss 207.2022 (206.9576)
2022-11-25 21:52:18,396:INFO: Dataset: univ                Batch: 15/15	Loss 38.5590 (204.6034)
2022-11-25 21:52:19,193:INFO: Dataset: zara1               Batch: 1/8	Loss 220.2784 (220.2784)
2022-11-25 21:52:19,696:INFO: Dataset: zara1               Batch: 2/8	Loss 219.8864 (220.0765)
2022-11-25 21:52:20,192:INFO: Dataset: zara1               Batch: 3/8	Loss 220.0016 (220.0514)
2022-11-25 21:52:20,686:INFO: Dataset: zara1               Batch: 4/8	Loss 219.1398 (219.8304)
2022-11-25 21:52:21,180:INFO: Dataset: zara1               Batch: 5/8	Loss 219.5517 (219.7766)
2022-11-25 21:52:21,676:INFO: Dataset: zara1               Batch: 6/8	Loss 219.7516 (219.7726)
2022-11-25 21:52:22,174:INFO: Dataset: zara1               Batch: 7/8	Loss 219.5117 (219.7378)
2022-11-25 21:52:22,657:INFO: Dataset: zara1               Batch: 8/8	Loss 188.4246 (216.1615)
2022-11-25 21:52:23,519:INFO: Dataset: zara2               Batch:  1/18	Loss 214.2690 (214.2690)
2022-11-25 21:52:24,031:INFO: Dataset: zara2               Batch:  2/18	Loss 213.9146 (214.1051)
2022-11-25 21:52:24,556:INFO: Dataset: zara2               Batch:  3/18	Loss 213.5851 (213.9203)
2022-11-25 21:52:25,062:INFO: Dataset: zara2               Batch:  4/18	Loss 212.5315 (213.5421)
2022-11-25 21:52:25,574:INFO: Dataset: zara2               Batch:  5/18	Loss 212.5655 (213.3513)
2022-11-25 21:52:26,079:INFO: Dataset: zara2               Batch:  6/18	Loss 213.0339 (213.3031)
2022-11-25 21:52:26,583:INFO: Dataset: zara2               Batch:  7/18	Loss 212.3221 (213.1605)
2022-11-25 21:52:27,085:INFO: Dataset: zara2               Batch:  8/18	Loss 212.1824 (213.0307)
2022-11-25 21:52:27,598:INFO: Dataset: zara2               Batch:  9/18	Loss 213.5582 (213.0861)
2022-11-25 21:52:28,124:INFO: Dataset: zara2               Batch: 10/18	Loss 212.6073 (213.0379)
2022-11-25 21:52:28,633:INFO: Dataset: zara2               Batch: 11/18	Loss 213.4076 (213.0688)
2022-11-25 21:52:29,138:INFO: Dataset: zara2               Batch: 12/18	Loss 212.7025 (213.0392)
2022-11-25 21:52:29,654:INFO: Dataset: zara2               Batch: 13/18	Loss 211.6207 (212.9227)
2022-11-25 21:52:30,166:INFO: Dataset: zara2               Batch: 14/18	Loss 212.3954 (212.8874)
2022-11-25 21:52:30,674:INFO: Dataset: zara2               Batch: 15/18	Loss 213.7448 (212.9445)
2022-11-25 21:52:31,177:INFO: Dataset: zara2               Batch: 16/18	Loss 212.0923 (212.8852)
2022-11-25 21:52:31,693:INFO: Dataset: zara2               Batch: 17/18	Loss 212.3550 (212.8537)
2022-11-25 21:52:32,246:INFO: Dataset: zara2               Batch: 18/18	Loss 181.7440 (211.4805)
2022-11-25 21:52:32,316:INFO: - Computing ADE (validation)
2022-11-25 21:52:32,697:INFO: 		 ADE on hotel                     dataset:	 2.9354066848754883
2022-11-25 21:52:33,131:INFO: 		 ADE on univ                      dataset:	 3.5982391834259033
2022-11-25 21:52:33,490:INFO: 		 ADE on zara1                     dataset:	 2.991422653198242
2022-11-25 21:52:34,045:INFO: 		 ADE on zara2                     dataset:	 3.126084804534912
2022-11-25 21:52:34,045:INFO: Average validation:	ADE  3.3535	FDE  4.4949
2022-11-25 21:52:34,046:INFO: - Computing ADE (validation o)
2022-11-25 21:52:34,346:INFO: 		 ADE on eth                       dataset:	 3.3080906867980957
2022-11-25 21:52:34,346:INFO: Average validation o:	ADE  3.3081	FDE  4.2250
2022-11-25 21:52:34,356:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_251.pth.tar
2022-11-25 21:52:34,356:INFO: 
===> EPOCH: 252 (P3)
2022-11-25 21:52:34,356:INFO: - Computing loss (training)
2022-11-25 21:52:35,077:INFO: Dataset: hotel               Batch: 1/4	Loss 217.2639 (217.2639)
2022-11-25 21:52:35,592:INFO: Dataset: hotel               Batch: 2/4	Loss 218.4398 (217.8218)
2022-11-25 21:52:36,090:INFO: Dataset: hotel               Batch: 3/4	Loss 217.5200 (217.7153)
2022-11-25 21:52:36,536:INFO: Dataset: hotel               Batch: 4/4	Loss 132.9670 (203.9633)
2022-11-25 21:52:37,398:INFO: Dataset: univ                Batch:  1/15	Loss 206.3634 (206.3634)
2022-11-25 21:52:37,969:INFO: Dataset: univ                Batch:  2/15	Loss 206.2785 (206.3190)
2022-11-25 21:52:38,539:INFO: Dataset: univ                Batch:  3/15	Loss 206.3058 (206.3146)
2022-11-25 21:52:39,087:INFO: Dataset: univ                Batch:  4/15	Loss 205.7880 (206.1769)
2022-11-25 21:52:39,634:INFO: Dataset: univ                Batch:  5/15	Loss 205.9608 (206.1338)
2022-11-25 21:52:40,178:INFO: Dataset: univ                Batch:  6/15	Loss 205.3103 (205.9972)
2022-11-25 21:52:40,716:INFO: Dataset: univ                Batch:  7/15	Loss 206.1283 (206.0158)
2022-11-25 21:52:41,261:INFO: Dataset: univ                Batch:  8/15	Loss 204.9486 (205.8696)
2022-11-25 21:52:41,808:INFO: Dataset: univ                Batch:  9/15	Loss 204.5753 (205.7257)
2022-11-25 21:52:42,362:INFO: Dataset: univ                Batch: 10/15	Loss 206.5179 (205.8028)
2022-11-25 21:52:42,916:INFO: Dataset: univ                Batch: 11/15	Loss 204.9907 (205.7322)
2022-11-25 21:52:43,452:INFO: Dataset: univ                Batch: 12/15	Loss 206.6082 (205.8023)
2022-11-25 21:52:44,004:INFO: Dataset: univ                Batch: 13/15	Loss 206.4570 (205.8485)
2022-11-25 21:52:44,671:INFO: Dataset: univ                Batch: 14/15	Loss 205.9051 (205.8525)
2022-11-25 21:52:45,097:INFO: Dataset: univ                Batch: 15/15	Loss 38.5069 (204.0523)
2022-11-25 21:52:45,955:INFO: Dataset: zara1               Batch: 1/8	Loss 220.4448 (220.4448)
2022-11-25 21:52:46,457:INFO: Dataset: zara1               Batch: 2/8	Loss 218.0508 (219.2045)
2022-11-25 21:52:46,971:INFO: Dataset: zara1               Batch: 3/8	Loss 218.5615 (219.0038)
2022-11-25 21:52:47,495:INFO: Dataset: zara1               Batch: 4/8	Loss 218.4497 (218.8591)
2022-11-25 21:52:47,986:INFO: Dataset: zara1               Batch: 5/8	Loss 218.8656 (218.8603)
2022-11-25 21:52:48,486:INFO: Dataset: zara1               Batch: 6/8	Loss 218.4357 (218.7934)
2022-11-25 21:52:49,023:INFO: Dataset: zara1               Batch: 7/8	Loss 218.5974 (218.7624)
2022-11-25 21:52:49,671:INFO: Dataset: zara1               Batch: 8/8	Loss 187.2398 (215.2617)
2022-11-25 21:52:50,496:INFO: Dataset: zara2               Batch:  1/18	Loss 212.3900 (212.3900)
2022-11-25 21:52:51,101:INFO: Dataset: zara2               Batch:  2/18	Loss 211.6752 (212.0220)
2022-11-25 21:52:51,768:INFO: Dataset: zara2               Batch:  3/18	Loss 211.9346 (211.9943)
2022-11-25 21:52:52,397:INFO: Dataset: zara2               Batch:  4/18	Loss 212.2984 (212.0681)
2022-11-25 21:52:52,984:INFO: Dataset: zara2               Batch:  5/18	Loss 212.3877 (212.1417)
2022-11-25 21:52:53,558:INFO: Dataset: zara2               Batch:  6/18	Loss 211.0754 (211.9729)
2022-11-25 21:52:54,131:INFO: Dataset: zara2               Batch:  7/18	Loss 211.3844 (211.8810)
2022-11-25 21:52:54,701:INFO: Dataset: zara2               Batch:  8/18	Loss 211.5016 (211.8343)
2022-11-25 21:52:55,211:INFO: Dataset: zara2               Batch:  9/18	Loss 211.5222 (211.7965)
2022-11-25 21:52:55,713:INFO: Dataset: zara2               Batch: 10/18	Loss 211.0913 (211.7268)
2022-11-25 21:52:56,277:INFO: Dataset: zara2               Batch: 11/18	Loss 211.8406 (211.7354)
2022-11-25 21:52:56,881:INFO: Dataset: zara2               Batch: 12/18	Loss 211.4714 (211.7132)
2022-11-25 21:52:57,457:INFO: Dataset: zara2               Batch: 13/18	Loss 211.8290 (211.7221)
2022-11-25 21:52:57,980:INFO: Dataset: zara2               Batch: 14/18	Loss 210.4534 (211.6196)
2022-11-25 21:52:58,494:INFO: Dataset: zara2               Batch: 15/18	Loss 211.5772 (211.6171)
2022-11-25 21:52:59,015:INFO: Dataset: zara2               Batch: 16/18	Loss 209.7962 (211.5036)
2022-11-25 21:52:59,535:INFO: Dataset: zara2               Batch: 17/18	Loss 209.8538 (211.4049)
2022-11-25 21:53:00,081:INFO: Dataset: zara2               Batch: 18/18	Loss 181.0242 (209.9032)
2022-11-25 21:53:00,148:INFO: - Computing ADE (validation)
2022-11-25 21:53:00,509:INFO: 		 ADE on hotel                     dataset:	 3.0110859870910645
2022-11-25 21:53:01,004:INFO: 		 ADE on univ                      dataset:	 3.5957908630371094
2022-11-25 21:53:01,377:INFO: 		 ADE on zara1                     dataset:	 3.0420095920562744
2022-11-25 21:53:01,994:INFO: 		 ADE on zara2                     dataset:	 3.1381421089172363
2022-11-25 21:53:01,995:INFO: Average validation:	ADE  3.3637	FDE  4.5040
2022-11-25 21:53:01,996:INFO: - Computing ADE (validation o)
2022-11-25 21:53:02,301:INFO: 		 ADE on eth                       dataset:	 3.1892547607421875
2022-11-25 21:53:02,301:INFO: Average validation o:	ADE  3.1893	FDE  4.3498
2022-11-25 21:53:02,310:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_252.pth.tar
2022-11-25 21:53:02,311:INFO: 
===> EPOCH: 253 (P3)
2022-11-25 21:53:02,311:INFO: - Computing loss (training)
2022-11-25 21:53:03,054:INFO: Dataset: hotel               Batch: 1/4	Loss 217.4814 (217.4814)
2022-11-25 21:53:03,555:INFO: Dataset: hotel               Batch: 2/4	Loss 216.3607 (216.9237)
2022-11-25 21:53:04,096:INFO: Dataset: hotel               Batch: 3/4	Loss 216.9492 (216.9319)
2022-11-25 21:53:04,593:INFO: Dataset: hotel               Batch: 4/4	Loss 132.2191 (201.7328)
2022-11-25 21:53:05,487:INFO: Dataset: univ                Batch:  1/15	Loss 205.7789 (205.7789)
2022-11-25 21:53:06,074:INFO: Dataset: univ                Batch:  2/15	Loss 205.3181 (205.5413)
2022-11-25 21:53:06,656:INFO: Dataset: univ                Batch:  3/15	Loss 206.3673 (205.7890)
2022-11-25 21:53:07,239:INFO: Dataset: univ                Batch:  4/15	Loss 205.0773 (205.6079)
2022-11-25 21:53:07,832:INFO: Dataset: univ                Batch:  5/15	Loss 204.4364 (205.3794)
2022-11-25 21:53:08,378:INFO: Dataset: univ                Batch:  6/15	Loss 205.1135 (205.3355)
2022-11-25 21:53:08,927:INFO: Dataset: univ                Batch:  7/15	Loss 205.2455 (205.3220)
2022-11-25 21:53:09,529:INFO: Dataset: univ                Batch:  8/15	Loss 204.5900 (205.2361)
2022-11-25 21:53:10,145:INFO: Dataset: univ                Batch:  9/15	Loss 204.2362 (205.1126)
2022-11-25 21:53:10,700:INFO: Dataset: univ                Batch: 10/15	Loss 205.1469 (205.1162)
2022-11-25 21:53:11,306:INFO: Dataset: univ                Batch: 11/15	Loss 204.3598 (205.0481)
2022-11-25 21:53:11,942:INFO: Dataset: univ                Batch: 12/15	Loss 203.9710 (204.9438)
2022-11-25 21:53:12,547:INFO: Dataset: univ                Batch: 13/15	Loss 204.4917 (204.9071)
2022-11-25 21:53:13,158:INFO: Dataset: univ                Batch: 14/15	Loss 204.6448 (204.8883)
2022-11-25 21:53:13,659:INFO: Dataset: univ                Batch: 15/15	Loss 38.3288 (202.4178)
2022-11-25 21:53:14,535:INFO: Dataset: zara1               Batch: 1/8	Loss 218.1038 (218.1038)
2022-11-25 21:53:15,112:INFO: Dataset: zara1               Batch: 2/8	Loss 216.5876 (217.3901)
2022-11-25 21:53:15,657:INFO: Dataset: zara1               Batch: 3/8	Loss 219.0882 (218.0313)
2022-11-25 21:53:16,190:INFO: Dataset: zara1               Batch: 4/8	Loss 218.0185 (218.0282)
2022-11-25 21:53:16,748:INFO: Dataset: zara1               Batch: 5/8	Loss 217.4877 (217.9234)
2022-11-25 21:53:17,443:INFO: Dataset: zara1               Batch: 6/8	Loss 218.2972 (217.9795)
2022-11-25 21:53:17,999:INFO: Dataset: zara1               Batch: 7/8	Loss 217.9912 (217.9811)
2022-11-25 21:53:18,540:INFO: Dataset: zara1               Batch: 8/8	Loss 187.5098 (215.1906)
2022-11-25 21:53:19,406:INFO: Dataset: zara2               Batch:  1/18	Loss 209.8109 (209.8109)
2022-11-25 21:53:19,915:INFO: Dataset: zara2               Batch:  2/18	Loss 209.5197 (209.6680)
2022-11-25 21:53:20,423:INFO: Dataset: zara2               Batch:  3/18	Loss 209.9211 (209.7506)
2022-11-25 21:53:20,930:INFO: Dataset: zara2               Batch:  4/18	Loss 210.1447 (209.8355)
2022-11-25 21:53:21,437:INFO: Dataset: zara2               Batch:  5/18	Loss 210.1313 (209.8980)
2022-11-25 21:53:21,952:INFO: Dataset: zara2               Batch:  6/18	Loss 208.7890 (209.7156)
2022-11-25 21:53:22,458:INFO: Dataset: zara2               Batch:  7/18	Loss 209.7916 (209.7276)
2022-11-25 21:53:22,964:INFO: Dataset: zara2               Batch:  8/18	Loss 210.1629 (209.7825)
2022-11-25 21:53:23,471:INFO: Dataset: zara2               Batch:  9/18	Loss 210.0434 (209.8082)
2022-11-25 21:53:23,975:INFO: Dataset: zara2               Batch: 10/18	Loss 209.2870 (209.7552)
2022-11-25 21:53:24,482:INFO: Dataset: zara2               Batch: 11/18	Loss 209.8656 (209.7647)
2022-11-25 21:53:24,987:INFO: Dataset: zara2               Batch: 12/18	Loss 210.3524 (209.8148)
2022-11-25 21:53:25,493:INFO: Dataset: zara2               Batch: 13/18	Loss 209.6951 (209.8049)
2022-11-25 21:53:25,999:INFO: Dataset: zara2               Batch: 14/18	Loss 208.7988 (209.7299)
2022-11-25 21:53:26,507:INFO: Dataset: zara2               Batch: 15/18	Loss 209.8177 (209.7358)
2022-11-25 21:53:27,011:INFO: Dataset: zara2               Batch: 16/18	Loss 210.8067 (209.8069)
2022-11-25 21:53:27,517:INFO: Dataset: zara2               Batch: 17/18	Loss 209.6674 (209.7982)
2022-11-25 21:53:28,009:INFO: Dataset: zara2               Batch: 18/18	Loss 180.5698 (208.5032)
2022-11-25 21:53:28,071:INFO: - Computing ADE (validation)
2022-11-25 21:53:28,429:INFO: 		 ADE on hotel                     dataset:	 3.010560989379883
2022-11-25 21:53:28,873:INFO: 		 ADE on univ                      dataset:	 3.6182358264923096
2022-11-25 21:53:29,232:INFO: 		 ADE on zara1                     dataset:	 3.0126214027404785
2022-11-25 21:53:29,776:INFO: 		 ADE on zara2                     dataset:	 3.133941411972046
2022-11-25 21:53:29,776:INFO: Average validation:	ADE  3.3721	FDE  4.5500
2022-11-25 21:53:29,777:INFO: - Computing ADE (validation o)
2022-11-25 21:53:30,089:INFO: 		 ADE on eth                       dataset:	 2.966510534286499
2022-11-25 21:53:30,089:INFO: Average validation o:	ADE  2.9665	FDE  3.7019
2022-11-25 21:53:30,098:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_253.pth.tar
2022-11-25 21:53:30,098:INFO: 
===> EPOCH: 254 (P3)
2022-11-25 21:53:30,098:INFO: - Computing loss (training)
2022-11-25 21:53:30,813:INFO: Dataset: hotel               Batch: 1/4	Loss 215.6166 (215.6166)
2022-11-25 21:53:31,317:INFO: Dataset: hotel               Batch: 2/4	Loss 216.5330 (216.0791)
2022-11-25 21:53:31,816:INFO: Dataset: hotel               Batch: 3/4	Loss 218.3024 (216.8226)
2022-11-25 21:53:32,258:INFO: Dataset: hotel               Batch: 4/4	Loss 130.8618 (203.1006)
2022-11-25 21:53:33,101:INFO: Dataset: univ                Batch:  1/15	Loss 203.4628 (203.4628)
2022-11-25 21:53:33,643:INFO: Dataset: univ                Batch:  2/15	Loss 205.2415 (204.2906)
2022-11-25 21:53:34,185:INFO: Dataset: univ                Batch:  3/15	Loss 203.7531 (204.1222)
2022-11-25 21:53:34,731:INFO: Dataset: univ                Batch:  4/15	Loss 203.8069 (204.0411)
2022-11-25 21:53:35,287:INFO: Dataset: univ                Batch:  5/15	Loss 203.9878 (204.0295)
2022-11-25 21:53:35,836:INFO: Dataset: univ                Batch:  6/15	Loss 203.8740 (204.0038)
2022-11-25 21:53:36,376:INFO: Dataset: univ                Batch:  7/15	Loss 204.4294 (204.0616)
2022-11-25 21:53:36,930:INFO: Dataset: univ                Batch:  8/15	Loss 203.7530 (204.0207)
2022-11-25 21:53:37,473:INFO: Dataset: univ                Batch:  9/15	Loss 204.2000 (204.0397)
2022-11-25 21:53:38,018:INFO: Dataset: univ                Batch: 10/15	Loss 203.3882 (203.9730)
2022-11-25 21:53:38,563:INFO: Dataset: univ                Batch: 11/15	Loss 204.6254 (204.0315)
2022-11-25 21:53:39,113:INFO: Dataset: univ                Batch: 12/15	Loss 203.5092 (203.9866)
2022-11-25 21:53:39,653:INFO: Dataset: univ                Batch: 13/15	Loss 204.7744 (204.0438)
2022-11-25 21:53:40,199:INFO: Dataset: univ                Batch: 14/15	Loss 203.8581 (204.0306)
2022-11-25 21:53:40,642:INFO: Dataset: univ                Batch: 15/15	Loss 37.7738 (201.4701)
2022-11-25 21:53:41,420:INFO: Dataset: zara1               Batch: 1/8	Loss 217.4312 (217.4312)
2022-11-25 21:53:41,914:INFO: Dataset: zara1               Batch: 2/8	Loss 216.3456 (216.8817)
2022-11-25 21:53:42,417:INFO: Dataset: zara1               Batch: 3/8	Loss 216.8041 (216.8547)
2022-11-25 21:53:42,912:INFO: Dataset: zara1               Batch: 4/8	Loss 215.5708 (216.5479)
2022-11-25 21:53:43,407:INFO: Dataset: zara1               Batch: 5/8	Loss 216.9878 (216.6377)
2022-11-25 21:53:43,902:INFO: Dataset: zara1               Batch: 6/8	Loss 217.7738 (216.8186)
2022-11-25 21:53:44,395:INFO: Dataset: zara1               Batch: 7/8	Loss 216.9854 (216.8419)
2022-11-25 21:53:44,875:INFO: Dataset: zara1               Batch: 8/8	Loss 186.7028 (213.5742)
2022-11-25 21:53:45,672:INFO: Dataset: zara2               Batch:  1/18	Loss 209.0892 (209.0892)
2022-11-25 21:53:46,172:INFO: Dataset: zara2               Batch:  2/18	Loss 210.4086 (209.7662)
2022-11-25 21:53:46,681:INFO: Dataset: zara2               Batch:  3/18	Loss 209.1649 (209.5567)
2022-11-25 21:53:47,199:INFO: Dataset: zara2               Batch:  4/18	Loss 207.6917 (209.0657)
2022-11-25 21:53:47,714:INFO: Dataset: zara2               Batch:  5/18	Loss 208.2444 (208.9007)
2022-11-25 21:53:48,230:INFO: Dataset: zara2               Batch:  6/18	Loss 208.6587 (208.8588)
2022-11-25 21:53:48,835:INFO: Dataset: zara2               Batch:  7/18	Loss 208.4079 (208.7928)
2022-11-25 21:53:49,353:INFO: Dataset: zara2               Batch:  8/18	Loss 207.7650 (208.6737)
2022-11-25 21:53:49,866:INFO: Dataset: zara2               Batch:  9/18	Loss 208.3616 (208.6373)
2022-11-25 21:53:50,378:INFO: Dataset: zara2               Batch: 10/18	Loss 207.9602 (208.5699)
2022-11-25 21:53:50,891:INFO: Dataset: zara2               Batch: 11/18	Loss 207.4369 (208.4746)
2022-11-25 21:53:51,404:INFO: Dataset: zara2               Batch: 12/18	Loss 208.8372 (208.5046)
2022-11-25 21:53:51,924:INFO: Dataset: zara2               Batch: 13/18	Loss 208.9313 (208.5381)
2022-11-25 21:53:52,437:INFO: Dataset: zara2               Batch: 14/18	Loss 209.2382 (208.5886)
2022-11-25 21:53:52,942:INFO: Dataset: zara2               Batch: 15/18	Loss 209.0091 (208.6163)
2022-11-25 21:53:53,447:INFO: Dataset: zara2               Batch: 16/18	Loss 206.9511 (208.5090)
2022-11-25 21:53:53,953:INFO: Dataset: zara2               Batch: 17/18	Loss 207.6891 (208.4643)
2022-11-25 21:53:54,446:INFO: Dataset: zara2               Batch: 18/18	Loss 178.9547 (207.0495)
2022-11-25 21:53:54,509:INFO: - Computing ADE (validation)
2022-11-25 21:53:54,885:INFO: 		 ADE on hotel                     dataset:	 3.0087430477142334
2022-11-25 21:53:55,339:INFO: 		 ADE on univ                      dataset:	 3.5385851860046387
2022-11-25 21:53:55,717:INFO: 		 ADE on zara1                     dataset:	 2.9257943630218506
2022-11-25 21:53:56,332:INFO: 		 ADE on zara2                     dataset:	 3.140704393386841
2022-11-25 21:53:56,332:INFO: Average validation:	ADE  3.3280	FDE  4.4696
2022-11-25 21:53:56,333:INFO: - Computing ADE (validation o)
2022-11-25 21:53:56,692:INFO: 		 ADE on eth                       dataset:	 3.1172993183135986
2022-11-25 21:53:56,692:INFO: Average validation o:	ADE  3.1173	FDE  4.0979
2022-11-25 21:53:56,702:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_254.pth.tar
2022-11-25 21:53:56,702:INFO: 
===> EPOCH: 255 (P3)
2022-11-25 21:53:56,703:INFO: - Computing loss (training)
2022-11-25 21:53:57,462:INFO: Dataset: hotel               Batch: 1/4	Loss 216.9961 (216.9961)
2022-11-25 21:53:58,018:INFO: Dataset: hotel               Batch: 2/4	Loss 214.6891 (215.8730)
2022-11-25 21:53:58,566:INFO: Dataset: hotel               Batch: 3/4	Loss 216.3374 (216.0305)
2022-11-25 21:53:59,023:INFO: Dataset: hotel               Batch: 4/4	Loss 131.4799 (201.8644)
2022-11-25 21:53:59,894:INFO: Dataset: univ                Batch:  1/15	Loss 203.3063 (203.3063)
2022-11-25 21:54:00,443:INFO: Dataset: univ                Batch:  2/15	Loss 202.9344 (203.1152)
2022-11-25 21:54:00,980:INFO: Dataset: univ                Batch:  3/15	Loss 203.3184 (203.1823)
2022-11-25 21:54:01,519:INFO: Dataset: univ                Batch:  4/15	Loss 203.2044 (203.1874)
2022-11-25 21:54:02,064:INFO: Dataset: univ                Batch:  5/15	Loss 202.9134 (203.1303)
2022-11-25 21:54:02,621:INFO: Dataset: univ                Batch:  6/15	Loss 202.9565 (203.1006)
2022-11-25 21:54:03,170:INFO: Dataset: univ                Batch:  7/15	Loss 203.5972 (203.1707)
2022-11-25 21:54:03,715:INFO: Dataset: univ                Batch:  8/15	Loss 203.5586 (203.2157)
2022-11-25 21:54:04,267:INFO: Dataset: univ                Batch:  9/15	Loss 203.7196 (203.2694)
2022-11-25 21:54:04,862:INFO: Dataset: univ                Batch: 10/15	Loss 202.5758 (203.1979)
2022-11-25 21:54:05,517:INFO: Dataset: univ                Batch: 11/15	Loss 202.9446 (203.1741)
2022-11-25 21:54:06,118:INFO: Dataset: univ                Batch: 12/15	Loss 202.9482 (203.1545)
2022-11-25 21:54:06,667:INFO: Dataset: univ                Batch: 13/15	Loss 203.0356 (203.1454)
2022-11-25 21:54:07,245:INFO: Dataset: univ                Batch: 14/15	Loss 202.6369 (203.1071)
2022-11-25 21:54:07,683:INFO: Dataset: univ                Batch: 15/15	Loss 38.0301 (200.6585)
2022-11-25 21:54:08,477:INFO: Dataset: zara1               Batch: 1/8	Loss 216.3660 (216.3660)
2022-11-25 21:54:09,020:INFO: Dataset: zara1               Batch: 2/8	Loss 216.2913 (216.3276)
2022-11-25 21:54:09,550:INFO: Dataset: zara1               Batch: 3/8	Loss 215.5961 (216.1151)
2022-11-25 21:54:10,083:INFO: Dataset: zara1               Batch: 4/8	Loss 216.5334 (216.2058)
2022-11-25 21:54:10,596:INFO: Dataset: zara1               Batch: 5/8	Loss 216.0501 (216.1760)
2022-11-25 21:54:11,123:INFO: Dataset: zara1               Batch: 6/8	Loss 215.6215 (216.0696)
2022-11-25 21:54:11,682:INFO: Dataset: zara1               Batch: 7/8	Loss 217.0896 (216.2191)
2022-11-25 21:54:12,183:INFO: Dataset: zara1               Batch: 8/8	Loss 185.2611 (212.6019)
2022-11-25 21:54:12,995:INFO: Dataset: zara2               Batch:  1/18	Loss 207.4536 (207.4536)
2022-11-25 21:54:13,535:INFO: Dataset: zara2               Batch:  2/18	Loss 207.8698 (207.6358)
2022-11-25 21:54:14,063:INFO: Dataset: zara2               Batch:  3/18	Loss 207.3693 (207.5458)
2022-11-25 21:54:14,640:INFO: Dataset: zara2               Batch:  4/18	Loss 206.8615 (207.3763)
2022-11-25 21:54:15,359:INFO: Dataset: zara2               Batch:  5/18	Loss 207.6577 (207.4320)
2022-11-25 21:54:15,939:INFO: Dataset: zara2               Batch:  6/18	Loss 208.1926 (207.5596)
2022-11-25 21:54:16,478:INFO: Dataset: zara2               Batch:  7/18	Loss 207.8839 (207.6049)
2022-11-25 21:54:17,040:INFO: Dataset: zara2               Batch:  8/18	Loss 207.1879 (207.5585)
2022-11-25 21:54:17,618:INFO: Dataset: zara2               Batch:  9/18	Loss 207.6885 (207.5720)
2022-11-25 21:54:18,138:INFO: Dataset: zara2               Batch: 10/18	Loss 206.3279 (207.4405)
2022-11-25 21:54:18,653:INFO: Dataset: zara2               Batch: 11/18	Loss 207.5361 (207.4498)
2022-11-25 21:54:19,170:INFO: Dataset: zara2               Batch: 12/18	Loss 207.8841 (207.4827)
2022-11-25 21:54:19,684:INFO: Dataset: zara2               Batch: 13/18	Loss 207.3963 (207.4758)
2022-11-25 21:54:20,198:INFO: Dataset: zara2               Batch: 14/18	Loss 206.6158 (207.4153)
2022-11-25 21:54:20,711:INFO: Dataset: zara2               Batch: 15/18	Loss 207.7637 (207.4385)
2022-11-25 21:54:21,228:INFO: Dataset: zara2               Batch: 16/18	Loss 207.1683 (207.4218)
2022-11-25 21:54:21,741:INFO: Dataset: zara2               Batch: 17/18	Loss 206.6321 (207.3775)
2022-11-25 21:54:22,325:INFO: Dataset: zara2               Batch: 18/18	Loss 178.2073 (205.9019)
2022-11-25 21:54:22,388:INFO: - Computing ADE (validation)
2022-11-25 21:54:22,765:INFO: 		 ADE on hotel                     dataset:	 2.9248197078704834
2022-11-25 21:54:23,204:INFO: 		 ADE on univ                      dataset:	 3.5783467292785645
2022-11-25 21:54:23,560:INFO: 		 ADE on zara1                     dataset:	 2.975076675415039
2022-11-25 21:54:24,122:INFO: 		 ADE on zara2                     dataset:	 3.109722137451172
2022-11-25 21:54:24,122:INFO: Average validation:	ADE  3.3356	FDE  4.5080
2022-11-25 21:54:24,123:INFO: - Computing ADE (validation o)
2022-11-25 21:54:24,424:INFO: 		 ADE on eth                       dataset:	 3.1300296783447266
2022-11-25 21:54:24,424:INFO: Average validation o:	ADE  3.1300	FDE  4.0015
2022-11-25 21:54:24,433:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_255.pth.tar
2022-11-25 21:54:24,433:INFO: 
===> EPOCH: 256 (P3)
2022-11-25 21:54:24,433:INFO: - Computing loss (training)
2022-11-25 21:54:25,159:INFO: Dataset: hotel               Batch: 1/4	Loss 213.2741 (213.2741)
2022-11-25 21:54:25,668:INFO: Dataset: hotel               Batch: 2/4	Loss 215.2144 (214.1828)
2022-11-25 21:54:26,217:INFO: Dataset: hotel               Batch: 3/4	Loss 215.3017 (214.5266)
2022-11-25 21:54:26,678:INFO: Dataset: hotel               Batch: 4/4	Loss 131.2693 (201.3460)
2022-11-25 21:54:27,558:INFO: Dataset: univ                Batch:  1/15	Loss 202.6834 (202.6834)
2022-11-25 21:54:28,100:INFO: Dataset: univ                Batch:  2/15	Loss 202.9064 (202.7997)
2022-11-25 21:54:28,636:INFO: Dataset: univ                Batch:  3/15	Loss 202.2966 (202.6274)
2022-11-25 21:54:29,177:INFO: Dataset: univ                Batch:  4/15	Loss 201.5061 (202.3315)
2022-11-25 21:54:29,712:INFO: Dataset: univ                Batch:  5/15	Loss 202.3337 (202.3319)
2022-11-25 21:54:30,263:INFO: Dataset: univ                Batch:  6/15	Loss 201.3449 (202.1403)
2022-11-25 21:54:30,807:INFO: Dataset: univ                Batch:  7/15	Loss 200.9648 (201.9547)
2022-11-25 21:54:31,343:INFO: Dataset: univ                Batch:  8/15	Loss 202.2865 (201.9962)
2022-11-25 21:54:31,924:INFO: Dataset: univ                Batch:  9/15	Loss 201.4819 (201.9367)
2022-11-25 21:54:32,484:INFO: Dataset: univ                Batch: 10/15	Loss 201.2124 (201.8633)
2022-11-25 21:54:33,029:INFO: Dataset: univ                Batch: 11/15	Loss 202.1954 (201.8932)
2022-11-25 21:54:33,618:INFO: Dataset: univ                Batch: 12/15	Loss 201.7436 (201.8810)
2022-11-25 21:54:34,189:INFO: Dataset: univ                Batch: 13/15	Loss 202.0875 (201.8965)
2022-11-25 21:54:34,760:INFO: Dataset: univ                Batch: 14/15	Loss 201.7855 (201.8890)
2022-11-25 21:54:35,227:INFO: Dataset: univ                Batch: 15/15	Loss 37.7715 (199.4158)
2022-11-25 21:54:36,052:INFO: Dataset: zara1               Batch: 1/8	Loss 215.5766 (215.5766)
2022-11-25 21:54:36,606:INFO: Dataset: zara1               Batch: 2/8	Loss 215.4410 (215.5104)
2022-11-25 21:54:37,152:INFO: Dataset: zara1               Batch: 3/8	Loss 216.3651 (215.7973)
2022-11-25 21:54:37,699:INFO: Dataset: zara1               Batch: 4/8	Loss 215.0797 (215.6043)
2022-11-25 21:54:38,252:INFO: Dataset: zara1               Batch: 5/8	Loss 215.5428 (215.5930)
2022-11-25 21:54:38,810:INFO: Dataset: zara1               Batch: 6/8	Loss 214.6767 (215.4294)
2022-11-25 21:54:39,318:INFO: Dataset: zara1               Batch: 7/8	Loss 215.2784 (215.4077)
2022-11-25 21:54:39,810:INFO: Dataset: zara1               Batch: 8/8	Loss 183.9456 (211.9800)
2022-11-25 21:54:40,649:INFO: Dataset: zara2               Batch:  1/18	Loss 205.8556 (205.8556)
2022-11-25 21:54:41,236:INFO: Dataset: zara2               Batch:  2/18	Loss 205.1801 (205.5074)
2022-11-25 21:54:41,778:INFO: Dataset: zara2               Batch:  3/18	Loss 206.6003 (205.8522)
2022-11-25 21:54:42,306:INFO: Dataset: zara2               Batch:  4/18	Loss 206.1877 (205.9317)
2022-11-25 21:54:42,925:INFO: Dataset: zara2               Batch:  5/18	Loss 206.2423 (205.9919)
2022-11-25 21:54:43,480:INFO: Dataset: zara2               Batch:  6/18	Loss 206.7257 (206.1142)
2022-11-25 21:54:44,031:INFO: Dataset: zara2               Batch:  7/18	Loss 206.1353 (206.1171)
2022-11-25 21:54:44,581:INFO: Dataset: zara2               Batch:  8/18	Loss 206.0819 (206.1125)
2022-11-25 21:54:45,118:INFO: Dataset: zara2               Batch:  9/18	Loss 206.3327 (206.1372)
2022-11-25 21:54:45,680:INFO: Dataset: zara2               Batch: 10/18	Loss 205.2737 (206.0564)
2022-11-25 21:54:46,208:INFO: Dataset: zara2               Batch: 11/18	Loss 206.9337 (206.1330)
2022-11-25 21:54:46,771:INFO: Dataset: zara2               Batch: 12/18	Loss 206.8423 (206.1904)
2022-11-25 21:54:47,318:INFO: Dataset: zara2               Batch: 13/18	Loss 205.8479 (206.1618)
2022-11-25 21:54:47,851:INFO: Dataset: zara2               Batch: 14/18	Loss 205.2537 (206.1013)
2022-11-25 21:54:48,375:INFO: Dataset: zara2               Batch: 15/18	Loss 205.2843 (206.0408)
2022-11-25 21:54:48,943:INFO: Dataset: zara2               Batch: 16/18	Loss 206.0575 (206.0419)
2022-11-25 21:54:49,508:INFO: Dataset: zara2               Batch: 17/18	Loss 205.4198 (206.0051)
2022-11-25 21:54:50,058:INFO: Dataset: zara2               Batch: 18/18	Loss 176.4977 (204.6344)
2022-11-25 21:54:50,138:INFO: - Computing ADE (validation)
2022-11-25 21:54:50,528:INFO: 		 ADE on hotel                     dataset:	 2.975576400756836
2022-11-25 21:54:50,981:INFO: 		 ADE on univ                      dataset:	 3.6015281677246094
2022-11-25 21:54:51,368:INFO: 		 ADE on zara1                     dataset:	 2.9437575340270996
2022-11-25 21:54:51,960:INFO: 		 ADE on zara2                     dataset:	 3.1469736099243164
2022-11-25 21:54:51,961:INFO: Average validation:	ADE  3.3623	FDE  4.4923
2022-11-25 21:54:51,962:INFO: - Computing ADE (validation o)
2022-11-25 21:54:52,260:INFO: 		 ADE on eth                       dataset:	 3.141072988510132
2022-11-25 21:54:52,260:INFO: Average validation o:	ADE  3.1411	FDE  3.8084
2022-11-25 21:54:52,269:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_256.pth.tar
2022-11-25 21:54:52,269:INFO: 
===> EPOCH: 257 (P3)
2022-11-25 21:54:52,270:INFO: - Computing loss (training)
2022-11-25 21:54:53,023:INFO: Dataset: hotel               Batch: 1/4	Loss 214.5154 (214.5154)
2022-11-25 21:54:53,568:INFO: Dataset: hotel               Batch: 2/4	Loss 214.2675 (214.3893)
2022-11-25 21:54:54,098:INFO: Dataset: hotel               Batch: 3/4	Loss 211.4034 (213.3766)
2022-11-25 21:54:54,563:INFO: Dataset: hotel               Batch: 4/4	Loss 130.3177 (199.1317)
2022-11-25 21:54:55,441:INFO: Dataset: univ                Batch:  1/15	Loss 199.8821 (199.8821)
2022-11-25 21:54:55,986:INFO: Dataset: univ                Batch:  2/15	Loss 201.2112 (200.4973)
2022-11-25 21:54:56,541:INFO: Dataset: univ                Batch:  3/15	Loss 200.4975 (200.4974)
2022-11-25 21:54:57,223:INFO: Dataset: univ                Batch:  4/15	Loss 202.4145 (200.9409)
2022-11-25 21:54:57,900:INFO: Dataset: univ                Batch:  5/15	Loss 201.2491 (201.0005)
2022-11-25 21:54:58,446:INFO: Dataset: univ                Batch:  6/15	Loss 201.1293 (201.0199)
2022-11-25 21:54:58,993:INFO: Dataset: univ                Batch:  7/15	Loss 199.6085 (200.8031)
2022-11-25 21:54:59,536:INFO: Dataset: univ                Batch:  8/15	Loss 200.7775 (200.7998)
2022-11-25 21:55:00,069:INFO: Dataset: univ                Batch:  9/15	Loss 200.6811 (200.7874)
2022-11-25 21:55:00,608:INFO: Dataset: univ                Batch: 10/15	Loss 199.9973 (200.7085)
2022-11-25 21:55:01,151:INFO: Dataset: univ                Batch: 11/15	Loss 200.0599 (200.6465)
2022-11-25 21:55:01,692:INFO: Dataset: univ                Batch: 12/15	Loss 200.0942 (200.5988)
2022-11-25 21:55:02,229:INFO: Dataset: univ                Batch: 13/15	Loss 200.3051 (200.5766)
2022-11-25 21:55:02,778:INFO: Dataset: univ                Batch: 14/15	Loss 199.4926 (200.4915)
2022-11-25 21:55:03,218:INFO: Dataset: univ                Batch: 15/15	Loss 37.6241 (198.1607)
2022-11-25 21:55:04,028:INFO: Dataset: zara1               Batch: 1/8	Loss 214.7649 (214.7649)
2022-11-25 21:55:04,539:INFO: Dataset: zara1               Batch: 2/8	Loss 214.8579 (214.8112)
2022-11-25 21:55:05,067:INFO: Dataset: zara1               Batch: 3/8	Loss 213.2485 (214.2994)
2022-11-25 21:55:05,747:INFO: Dataset: zara1               Batch: 4/8	Loss 214.0881 (214.2471)
2022-11-25 21:55:06,276:INFO: Dataset: zara1               Batch: 5/8	Loss 212.9020 (214.0109)
2022-11-25 21:55:06,797:INFO: Dataset: zara1               Batch: 6/8	Loss 213.4427 (213.9108)
2022-11-25 21:55:07,300:INFO: Dataset: zara1               Batch: 7/8	Loss 215.3261 (214.1057)
2022-11-25 21:55:07,796:INFO: Dataset: zara1               Batch: 8/8	Loss 184.2171 (210.7079)
2022-11-25 21:55:08,653:INFO: Dataset: zara2               Batch:  1/18	Loss 205.0705 (205.0705)
2022-11-25 21:55:09,177:INFO: Dataset: zara2               Batch:  2/18	Loss 205.2212 (205.1432)
2022-11-25 21:55:09,710:INFO: Dataset: zara2               Batch:  3/18	Loss 205.3631 (205.2175)
2022-11-25 21:55:10,240:INFO: Dataset: zara2               Batch:  4/18	Loss 204.5592 (205.0484)
2022-11-25 21:55:10,774:INFO: Dataset: zara2               Batch:  5/18	Loss 205.3881 (205.1206)
2022-11-25 21:55:11,323:INFO: Dataset: zara2               Batch:  6/18	Loss 205.0625 (205.1112)
2022-11-25 21:55:11,855:INFO: Dataset: zara2               Batch:  7/18	Loss 205.5329 (205.1709)
2022-11-25 21:55:12,378:INFO: Dataset: zara2               Batch:  8/18	Loss 205.5653 (205.2193)
2022-11-25 21:55:12,896:INFO: Dataset: zara2               Batch:  9/18	Loss 204.9176 (205.1839)
2022-11-25 21:55:13,416:INFO: Dataset: zara2               Batch: 10/18	Loss 203.9123 (205.0706)
2022-11-25 21:55:13,939:INFO: Dataset: zara2               Batch: 11/18	Loss 204.2601 (205.0066)
2022-11-25 21:55:14,461:INFO: Dataset: zara2               Batch: 12/18	Loss 204.4326 (204.9579)
2022-11-25 21:55:14,981:INFO: Dataset: zara2               Batch: 13/18	Loss 203.9275 (204.8846)
2022-11-25 21:55:15,507:INFO: Dataset: zara2               Batch: 14/18	Loss 204.6286 (204.8663)
2022-11-25 21:55:16,027:INFO: Dataset: zara2               Batch: 15/18	Loss 204.5860 (204.8481)
2022-11-25 21:55:16,551:INFO: Dataset: zara2               Batch: 16/18	Loss 204.0586 (204.7968)
2022-11-25 21:55:17,076:INFO: Dataset: zara2               Batch: 17/18	Loss 204.1562 (204.7618)
2022-11-25 21:55:17,586:INFO: Dataset: zara2               Batch: 18/18	Loss 175.4319 (203.3993)
2022-11-25 21:55:17,649:INFO: - Computing ADE (validation)
2022-11-25 21:55:18,022:INFO: 		 ADE on hotel                     dataset:	 2.9732863903045654
2022-11-25 21:55:18,461:INFO: 		 ADE on univ                      dataset:	 3.590820074081421
2022-11-25 21:55:18,827:INFO: 		 ADE on zara1                     dataset:	 2.9317331314086914
2022-11-25 21:55:19,408:INFO: 		 ADE on zara2                     dataset:	 3.1606147289276123
2022-11-25 21:55:19,408:INFO: Average validation:	ADE  3.3609	FDE  4.5354
2022-11-25 21:55:19,409:INFO: - Computing ADE (validation o)
2022-11-25 21:55:19,726:INFO: 		 ADE on eth                       dataset:	 3.1563029289245605
2022-11-25 21:55:19,726:INFO: Average validation o:	ADE  3.1563	FDE  3.8724
2022-11-25 21:55:19,735:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_257.pth.tar
2022-11-25 21:55:19,735:INFO: 
===> EPOCH: 258 (P3)
2022-11-25 21:55:19,736:INFO: - Computing loss (training)
2022-11-25 21:55:20,466:INFO: Dataset: hotel               Batch: 1/4	Loss 211.7421 (211.7421)
2022-11-25 21:55:20,969:INFO: Dataset: hotel               Batch: 2/4	Loss 212.2577 (211.9955)
2022-11-25 21:55:21,467:INFO: Dataset: hotel               Batch: 3/4	Loss 212.9721 (212.3142)
2022-11-25 21:55:21,931:INFO: Dataset: hotel               Batch: 4/4	Loss 129.7165 (197.1677)
2022-11-25 21:55:22,789:INFO: Dataset: univ                Batch:  1/15	Loss 198.5406 (198.5406)
2022-11-25 21:55:23,349:INFO: Dataset: univ                Batch:  2/15	Loss 198.4301 (198.4836)
2022-11-25 21:55:23,906:INFO: Dataset: univ                Batch:  3/15	Loss 198.2907 (198.4200)
2022-11-25 21:55:24,465:INFO: Dataset: univ                Batch:  4/15	Loss 198.1173 (198.3430)
2022-11-25 21:55:25,013:INFO: Dataset: univ                Batch:  5/15	Loss 198.7906 (198.4240)
2022-11-25 21:55:25,567:INFO: Dataset: univ                Batch:  6/15	Loss 199.5286 (198.5882)
2022-11-25 21:55:26,116:INFO: Dataset: univ                Batch:  7/15	Loss 199.6031 (198.7318)
2022-11-25 21:55:26,651:INFO: Dataset: univ                Batch:  8/15	Loss 199.4467 (198.8087)
2022-11-25 21:55:27,192:INFO: Dataset: univ                Batch:  9/15	Loss 198.3288 (198.7558)
2022-11-25 21:55:27,733:INFO: Dataset: univ                Batch: 10/15	Loss 198.7662 (198.7568)
2022-11-25 21:55:28,353:INFO: Dataset: univ                Batch: 11/15	Loss 198.3342 (198.7215)
2022-11-25 21:55:28,898:INFO: Dataset: univ                Batch: 12/15	Loss 198.9704 (198.7408)
2022-11-25 21:55:29,432:INFO: Dataset: univ                Batch: 13/15	Loss 200.1951 (198.8439)
2022-11-25 21:55:29,965:INFO: Dataset: univ                Batch: 14/15	Loss 198.4189 (198.8166)
2022-11-25 21:55:30,420:INFO: Dataset: univ                Batch: 15/15	Loss 37.4289 (196.5986)
2022-11-25 21:55:31,222:INFO: Dataset: zara1               Batch: 1/8	Loss 213.3885 (213.3885)
2022-11-25 21:55:31,736:INFO: Dataset: zara1               Batch: 2/8	Loss 213.5800 (213.4869)
2022-11-25 21:55:32,250:INFO: Dataset: zara1               Batch: 3/8	Loss 213.8385 (213.5966)
2022-11-25 21:55:32,761:INFO: Dataset: zara1               Batch: 4/8	Loss 212.9657 (213.4349)
2022-11-25 21:55:33,272:INFO: Dataset: zara1               Batch: 5/8	Loss 212.2939 (213.2059)
2022-11-25 21:55:33,789:INFO: Dataset: zara1               Batch: 6/8	Loss 213.8528 (213.3144)
