2022-11-13 18:34:53,572:INFO: Initializing Training Set
2022-11-13 18:34:57,536:INFO: Initializing Validation Set
2022-11-13 18:34:58,005:INFO: Initializing Validation O Set
2022-11-13 18:35:01,178:INFO: 
===> EPOCH: 151 (P2)
2022-11-13 18:35:01,179:INFO: - Computing loss (training)
2022-11-13 18:35:10,854:INFO: Dataset: hotel               Batch: 1/8	Loss 315.9842 (315.9842)
2022-11-13 18:35:13,206:INFO: Dataset: hotel               Batch: 2/8	Loss 208.7322 (264.2257)
2022-11-13 18:35:15,515:INFO: Dataset: hotel               Batch: 3/8	Loss 155.9647 (226.3869)
2022-11-13 18:35:17,829:INFO: Dataset: hotel               Batch: 4/8	Loss 123.5921 (201.8276)
2022-11-13 18:35:20,175:INFO: Dataset: hotel               Batch: 5/8	Loss 103.0202 (181.8331)
2022-11-13 18:35:22,581:INFO: Dataset: hotel               Batch: 6/8	Loss 87.1793 (164.5129)
2022-11-13 18:35:24,922:INFO: Dataset: hotel               Batch: 7/8	Loss 76.5887 (151.7283)
2022-11-13 18:35:27,075:INFO: Dataset: hotel               Batch: 8/8	Loss 14.8632 (146.4920)
2022-11-13 18:35:54,877:INFO: Dataset: univ                Batch:  1/29	Loss 137.6743 (137.6743)
2022-11-13 18:35:57,550:INFO: Dataset: univ                Batch:  2/29	Loss 117.0445 (128.3418)
2022-11-13 18:35:59,958:INFO: Dataset: univ                Batch:  3/29	Loss 94.6949 (118.3462)
2022-11-13 18:36:02,471:INFO: Dataset: univ                Batch:  4/29	Loss 73.4614 (106.9848)
2022-11-13 18:36:04,902:INFO: Dataset: univ                Batch:  5/29	Loss 61.4707 (97.4423)
2022-11-13 18:36:07,475:INFO: Dataset: univ                Batch:  6/29	Loss 52.7958 (90.2910)
2022-11-13 18:36:10,590:INFO: Dataset: univ                Batch:  7/29	Loss 49.9718 (84.5118)
2022-11-13 18:36:13,123:INFO: Dataset: univ                Batch:  8/29	Loss 45.2439 (79.5652)
2022-11-13 18:36:15,689:INFO: Dataset: univ                Batch:  9/29	Loss 41.7920 (74.9430)
2022-11-13 18:36:18,105:INFO: Dataset: univ                Batch: 10/29	Loss 38.6919 (71.3698)
2022-11-13 18:36:21,856:INFO: Dataset: univ                Batch: 11/29	Loss 36.5699 (68.3462)
2022-11-13 18:36:25,234:INFO: Dataset: univ                Batch: 12/29	Loss 33.0963 (65.2993)
2022-11-13 18:36:27,695:INFO: Dataset: univ                Batch: 13/29	Loss 31.2262 (62.5983)
2022-11-13 18:36:30,854:INFO: Dataset: univ                Batch: 14/29	Loss 28.6356 (60.1069)
2022-11-13 18:36:33,775:INFO: Dataset: univ                Batch: 15/29	Loss 26.8995 (57.8935)
2022-11-13 18:36:36,884:INFO: Dataset: univ                Batch: 16/29	Loss 24.4358 (55.5803)
2022-11-13 18:36:39,978:INFO: Dataset: univ                Batch: 17/29	Loss 24.6535 (54.0233)
2022-11-13 18:36:43,061:INFO: Dataset: univ                Batch: 18/29	Loss 22.5577 (52.3130)
2022-11-13 18:36:45,582:INFO: Dataset: univ                Batch: 19/29	Loss 21.1919 (50.5944)
2022-11-13 18:36:48,284:INFO: Dataset: univ                Batch: 20/29	Loss 20.5268 (49.1882)
2022-11-13 18:36:50,764:INFO: Dataset: univ                Batch: 21/29	Loss 19.0310 (47.7379)
2022-11-13 18:36:53,167:INFO: Dataset: univ                Batch: 22/29	Loss 18.1909 (46.4927)
2022-11-13 18:36:55,635:INFO: Dataset: univ                Batch: 23/29	Loss 16.6692 (44.9571)
2022-11-13 18:36:58,105:INFO: Dataset: univ                Batch: 24/29	Loss 15.7137 (43.5956)
2022-11-13 18:37:01,484:INFO: Dataset: univ                Batch: 25/29	Loss 16.0008 (42.5006)
2022-11-13 18:37:04,302:INFO: Dataset: univ                Batch: 26/29	Loss 15.4571 (41.3379)
2022-11-13 18:37:07,350:INFO: Dataset: univ                Batch: 27/29	Loss 14.0065 (40.3760)
2022-11-13 18:37:10,446:INFO: Dataset: univ                Batch: 28/29	Loss 13.8559 (39.4227)
2022-11-13 18:37:13,232:INFO: Dataset: univ                Batch: 29/29	Loss 5.0691 (38.8985)
2022-11-13 18:37:25,052:INFO: Dataset: zara1               Batch:  1/16	Loss 76.3191 (76.3191)
2022-11-13 18:37:28,072:INFO: Dataset: zara1               Batch:  2/16	Loss 62.3825 (68.8325)
2022-11-13 18:37:32,868:INFO: Dataset: zara1               Batch:  3/16	Loss 48.2530 (62.6468)
2022-11-13 18:37:36,614:INFO: Dataset: zara1               Batch:  4/16	Loss 35.8740 (56.7375)
2022-11-13 18:37:39,921:INFO: Dataset: zara1               Batch:  5/16	Loss 26.6918 (50.9028)
2022-11-13 18:37:42,805:INFO: Dataset: zara1               Batch:  6/16	Loss 21.3042 (44.9745)
2022-11-13 18:37:46,825:INFO: Dataset: zara1               Batch:  7/16	Loss 18.6126 (40.9263)
2022-11-13 18:37:49,663:INFO: Dataset: zara1               Batch:  8/16	Loss 18.3628 (37.9435)
2022-11-13 18:37:52,901:INFO: Dataset: zara1               Batch:  9/16	Loss 17.9953 (35.4175)
2022-11-13 18:37:56,036:INFO: Dataset: zara1               Batch: 10/16	Loss 19.4078 (33.9301)
2022-11-13 18:37:59,705:INFO: Dataset: zara1               Batch: 11/16	Loss 19.8542 (32.5957)
2022-11-13 18:38:02,475:INFO: Dataset: zara1               Batch: 12/16	Loss 19.4130 (31.1829)
2022-11-13 18:38:05,418:INFO: Dataset: zara1               Batch: 13/16	Loss 19.9915 (30.3683)
2022-11-13 18:38:09,066:INFO: Dataset: zara1               Batch: 14/16	Loss 19.0998 (29.5976)
2022-11-13 18:38:11,942:INFO: Dataset: zara1               Batch: 15/16	Loss 18.1788 (28.8784)
2022-11-13 18:38:14,489:INFO: Dataset: zara1               Batch: 16/16	Loss 12.4171 (28.0987)
2022-11-13 18:38:42,409:INFO: Dataset: zara2               Batch:  1/36	Loss 79.5210 (79.5210)
2022-11-13 18:38:45,559:INFO: Dataset: zara2               Batch:  2/36	Loss 65.1762 (72.6220)
2022-11-13 18:38:48,684:INFO: Dataset: zara2               Batch:  3/36	Loss 50.1486 (65.3237)
2022-11-13 18:38:51,243:INFO: Dataset: zara2               Batch:  4/36	Loss 36.9803 (59.3800)
2022-11-13 18:38:53,670:INFO: Dataset: zara2               Batch:  5/36	Loss 26.7870 (52.7558)
2022-11-13 18:38:56,140:INFO: Dataset: zara2               Batch:  6/36	Loss 21.4780 (46.7396)
2022-11-13 18:38:58,620:INFO: Dataset: zara2               Batch:  7/36	Loss 20.2160 (42.7463)
2022-11-13 18:39:01,176:INFO: Dataset: zara2               Batch:  8/36	Loss 17.8848 (39.5737)
2022-11-13 18:39:03,854:INFO: Dataset: zara2               Batch:  9/36	Loss 17.1750 (36.8565)
2022-11-13 18:39:06,449:INFO: Dataset: zara2               Batch: 10/36	Loss 17.3395 (35.0558)
2022-11-13 18:39:09,066:INFO: Dataset: zara2               Batch: 11/36	Loss 17.2159 (33.3293)
2022-11-13 18:39:13,619:INFO: Dataset: zara2               Batch: 12/36	Loss 17.0429 (32.0468)
2022-11-13 18:39:16,245:INFO: Dataset: zara2               Batch: 13/36	Loss 15.4311 (30.7844)
2022-11-13 18:39:19,182:INFO: Dataset: zara2               Batch: 14/36	Loss 14.3489 (29.3936)
2022-11-13 18:39:21,984:INFO: Dataset: zara2               Batch: 15/36	Loss 14.2675 (28.3384)
2022-11-13 18:39:24,444:INFO: Dataset: zara2               Batch: 16/36	Loss 12.7674 (27.3549)
2022-11-13 18:39:26,956:INFO: Dataset: zara2               Batch: 17/36	Loss 13.4318 (26.4207)
2022-11-13 18:39:29,364:INFO: Dataset: zara2               Batch: 18/36	Loss 12.3742 (25.6391)
2022-11-13 18:39:31,744:INFO: Dataset: zara2               Batch: 19/36	Loss 12.7275 (25.0713)
2022-11-13 18:39:34,113:INFO: Dataset: zara2               Batch: 20/36	Loss 11.0272 (24.4049)
2022-11-13 18:39:36,541:INFO: Dataset: zara2               Batch: 21/36	Loss 11.0940 (23.8161)
2022-11-13 18:39:38,940:INFO: Dataset: zara2               Batch: 22/36	Loss 10.4673 (23.2507)
2022-11-13 18:39:41,432:INFO: Dataset: zara2               Batch: 23/36	Loss 10.0085 (22.6443)
2022-11-13 18:39:43,845:INFO: Dataset: zara2               Batch: 24/36	Loss 9.6261 (22.1385)
2022-11-13 18:39:46,226:INFO: Dataset: zara2               Batch: 25/36	Loss 10.0835 (21.6850)
2022-11-13 18:39:48,626:INFO: Dataset: zara2               Batch: 26/36	Loss 9.9912 (21.2790)
2022-11-13 18:39:51,029:INFO: Dataset: zara2               Batch: 27/36	Loss 9.3557 (20.8383)
2022-11-13 18:39:53,457:INFO: Dataset: zara2               Batch: 28/36	Loss 9.0991 (20.4416)
2022-11-13 18:39:55,906:INFO: Dataset: zara2               Batch: 29/36	Loss 8.3360 (20.0171)
2022-11-13 18:39:58,419:INFO: Dataset: zara2               Batch: 30/36	Loss 7.9580 (19.5855)
2022-11-13 18:40:00,941:INFO: Dataset: zara2               Batch: 31/36	Loss 7.9833 (19.2253)
2022-11-13 18:40:03,348:INFO: Dataset: zara2               Batch: 32/36	Loss 7.3469 (18.8357)
2022-11-13 18:40:06,034:INFO: Dataset: zara2               Batch: 33/36	Loss 7.7943 (18.5119)
2022-11-13 18:40:08,484:INFO: Dataset: zara2               Batch: 34/36	Loss 7.7043 (18.1894)
2022-11-13 18:40:10,951:INFO: Dataset: zara2               Batch: 35/36	Loss 7.3465 (17.8574)
2022-11-13 18:40:13,379:INFO: Dataset: zara2               Batch: 36/36	Loss 5.0654 (17.5656)
