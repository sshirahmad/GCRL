2022-11-22 14:37:46,948:INFO: Initializing Training Set
2022-11-22 14:37:53,122:INFO: Initializing Validation Set
2022-11-22 14:37:53,634:INFO: Initializing Validation O Set
2022-11-22 14:37:57,094:INFO: => loaded checkpoint './models/E1/P4/CRMF_epoch_1188.pth.tar' (epoch 1189)
2022-11-22 14:37:57,096:INFO: 
===> EPOCH: 1201 (P5)
2022-11-22 14:37:57,096:INFO: - Computing loss (training)
2022-11-22 14:38:05,128:INFO: Dataset: hotel               Batch: 1/4	Loss 17.8806 (17.8806)
2022-11-22 14:38:06,498:INFO: Dataset: hotel               Batch: 2/4	Loss 17.8630 (17.8718)
2022-11-22 14:38:07,093:INFO: Dataset: hotel               Batch: 3/4	Loss 17.8605 (17.8679)
2022-11-22 14:38:07,287:INFO: Dataset: hotel               Batch: 4/4	Loss 17.8523 (17.8652)
2022-11-22 14:38:36,135:INFO: Dataset: univ                Batch:  1/15	Loss 14.2998 (14.2998)
2022-11-22 14:38:36,331:INFO: Dataset: univ                Batch:  2/15	Loss 14.2907 (14.2955)
2022-11-22 14:38:36,506:INFO: Dataset: univ                Batch:  3/15	Loss 14.2861 (14.2921)
2022-11-22 14:38:36,676:INFO: Dataset: univ                Batch:  4/15	Loss 14.2826 (14.2897)
2022-11-22 14:38:36,876:INFO: Dataset: univ                Batch:  5/15	Loss 14.2708 (14.2859)
2022-11-22 14:38:37,063:INFO: Dataset: univ                Batch:  6/15	Loss 14.2697 (14.2832)
2022-11-22 14:38:37,264:INFO: Dataset: univ                Batch:  7/15	Loss 14.2688 (14.2810)
2022-11-22 14:38:37,458:INFO: Dataset: univ                Batch:  8/15	Loss 14.2505 (14.2777)
2022-11-22 14:38:37,649:INFO: Dataset: univ                Batch:  9/15	Loss 14.2533 (14.2749)
2022-11-22 14:38:37,824:INFO: Dataset: univ                Batch: 10/15	Loss 14.2474 (14.2722)
2022-11-22 14:38:38,000:INFO: Dataset: univ                Batch: 11/15	Loss 14.2352 (14.2690)
2022-11-22 14:38:38,190:INFO: Dataset: univ                Batch: 12/15	Loss 14.2141 (14.2648)
2022-11-22 14:38:38,424:INFO: Dataset: univ                Batch: 13/15	Loss 14.2142 (14.2608)
2022-11-22 14:38:38,640:INFO: Dataset: univ                Batch: 14/15	Loss 14.2014 (14.2567)
2022-11-22 14:38:38,695:INFO: Dataset: univ                Batch: 15/15	Loss 14.1643 (14.2557)
2022-11-22 14:38:47,072:INFO: Dataset: zara1               Batch: 1/8	Loss 17.1244 (17.1244)
2022-11-22 14:38:47,539:INFO: Dataset: zara1               Batch: 2/8	Loss 17.1168 (17.1207)
2022-11-22 14:38:47,906:INFO: Dataset: zara1               Batch: 3/8	Loss 17.1209 (17.1208)
2022-11-22 14:38:48,342:INFO: Dataset: zara1               Batch: 4/8	Loss 17.1295 (17.1232)
2022-11-22 14:38:48,523:INFO: Dataset: zara1               Batch: 5/8	Loss 17.1112 (17.1208)
2022-11-22 14:38:48,772:INFO: Dataset: zara1               Batch: 6/8	Loss 17.1196 (17.1206)
2022-11-22 14:38:48,935:INFO: Dataset: zara1               Batch: 7/8	Loss 17.0983 (17.1172)
2022-11-22 14:38:49,080:INFO: Dataset: zara1               Batch: 8/8	Loss 17.1041 (17.1158)
2022-11-22 14:39:16,169:INFO: Dataset: zara2               Batch:  1/18	Loss 10.2616 (10.2616)
2022-11-22 14:39:16,391:INFO: Dataset: zara2               Batch:  2/18	Loss 10.2365 (10.2483)
2022-11-22 14:39:16,618:INFO: Dataset: zara2               Batch:  3/18	Loss 10.2669 (10.2544)
2022-11-22 14:39:16,848:INFO: Dataset: zara2               Batch:  4/18	Loss 10.2416 (10.2514)
2022-11-22 14:39:17,078:INFO: Dataset: zara2               Batch:  5/18	Loss 10.2494 (10.2510)
2022-11-22 14:39:17,300:INFO: Dataset: zara2               Batch:  6/18	Loss 10.2421 (10.2495)
2022-11-22 14:39:17,510:INFO: Dataset: zara2               Batch:  7/18	Loss 10.2383 (10.2480)
2022-11-22 14:39:17,720:INFO: Dataset: zara2               Batch:  8/18	Loss 10.2427 (10.2473)
2022-11-22 14:39:17,947:INFO: Dataset: zara2               Batch:  9/18	Loss 10.2321 (10.2457)
2022-11-22 14:39:18,167:INFO: Dataset: zara2               Batch: 10/18	Loss 10.2142 (10.2425)
2022-11-22 14:39:18,370:INFO: Dataset: zara2               Batch: 11/18	Loss 10.1996 (10.2384)
2022-11-22 14:39:18,669:INFO: Dataset: zara2               Batch: 12/18	Loss 10.2130 (10.2364)
2022-11-22 14:39:18,886:INFO: Dataset: zara2               Batch: 13/18	Loss 10.2099 (10.2344)
2022-11-22 14:39:19,133:INFO: Dataset: zara2               Batch: 14/18	Loss 10.1928 (10.2313)
2022-11-22 14:39:19,336:INFO: Dataset: zara2               Batch: 15/18	Loss 10.2015 (10.2294)
2022-11-22 14:39:19,548:INFO: Dataset: zara2               Batch: 16/18	Loss 10.1750 (10.2261)
2022-11-22 14:39:19,787:INFO: Dataset: zara2               Batch: 17/18	Loss 10.1728 (10.2230)
2022-11-22 14:39:19,967:INFO: Dataset: zara2               Batch: 18/18	Loss 10.1724 (10.2207)
2022-11-22 14:39:20,977:INFO: - Computing ADE (validation o)
2022-11-22 14:39:31,381:INFO: 		 ADE on eth                       dataset:	 1.033889889717102
2022-11-22 14:39:31,381:INFO: Average validation o:	ADE  1.0339	FDE  2.1806
2022-11-22 14:39:31,383:INFO: - Computing loss (validation)
2022-11-22 14:39:39,336:INFO: Dataset: hotel               Batch: 1/2	Loss 17.7686 (17.7686)
2022-11-22 14:39:39,636:INFO: Dataset: hotel               Batch: 2/2	Loss 17.7625 (17.7681)
2022-11-22 14:39:51,509:INFO: Dataset: univ                Batch: 1/3	Loss 13.9689 (13.9689)
2022-11-22 14:39:51,994:INFO: Dataset: univ                Batch: 2/3	Loss 13.9664 (13.9676)
2022-11-22 14:39:52,194:INFO: Dataset: univ                Batch: 3/3	Loss 13.9989 (13.9769)
2022-11-22 14:40:00,629:INFO: Dataset: zara1               Batch: 1/2	Loss 17.0385 (17.0385)
2022-11-22 14:40:00,982:INFO: Dataset: zara1               Batch: 2/2	Loss 17.0271 (17.0353)
2022-11-22 14:40:09,611:INFO: Dataset: zara2               Batch: 1/5	Loss 10.1610 (10.1610)
2022-11-22 14:40:10,066:INFO: Dataset: zara2               Batch: 2/5	Loss 10.1497 (10.1553)
2022-11-22 14:40:10,428:INFO: Dataset: zara2               Batch: 3/5	Loss 10.1443 (10.1516)
2022-11-22 14:40:10,790:INFO: Dataset: zara2               Batch: 4/5	Loss 10.1415 (10.1489)
2022-11-22 14:40:11,033:INFO: Dataset: zara2               Batch: 5/5	Loss 10.1454 (10.1482)
2022-11-22 14:40:12,092:INFO:  --> Model Saved in ./models/E1//P5/CRMF_epoch_1201.pth.tar
2022-11-22 14:40:12,092:INFO: 
===> EPOCH: 1202 (P5)
2022-11-22 14:40:12,093:INFO: - Computing loss (training)
2022-11-22 14:40:19,060:INFO: Dataset: hotel               Batch: 1/4	Loss 17.7960 (17.7960)
2022-11-22 14:40:19,462:INFO: Dataset: hotel               Batch: 2/4	Loss 17.7812 (17.7889)
2022-11-22 14:40:19,831:INFO: Dataset: hotel               Batch: 3/4	Loss 17.7854 (17.7877)
2022-11-22 14:40:20,149:INFO: Dataset: hotel               Batch: 4/4	Loss 17.7863 (17.7875)
2022-11-22 14:40:47,122:INFO: Dataset: univ                Batch:  1/15	Loss 13.9210 (13.9210)
2022-11-22 14:40:47,374:INFO: Dataset: univ                Batch:  2/15	Loss 13.9441 (13.9339)
2022-11-22 14:40:47,602:INFO: Dataset: univ                Batch:  3/15	Loss 13.9278 (13.9320)
2022-11-22 14:40:47,825:INFO: Dataset: univ                Batch:  4/15	Loss 13.8993 (13.9238)
2022-11-22 14:40:48,078:INFO: Dataset: univ                Batch:  5/15	Loss 13.9164 (13.9222)
2022-11-22 14:40:48,312:INFO: Dataset: univ                Batch:  6/15	Loss 13.9006 (13.9184)
2022-11-22 14:40:48,562:INFO: Dataset: univ                Batch:  7/15	Loss 13.8984 (13.9154)
2022-11-22 14:40:48,793:INFO: Dataset: univ                Batch:  8/15	Loss 13.8742 (13.9102)
2022-11-22 14:40:49,024:INFO: Dataset: univ                Batch:  9/15	Loss 13.8238 (13.9014)
2022-11-22 14:40:49,247:INFO: Dataset: univ                Batch: 10/15	Loss 13.8288 (13.8947)
2022-11-22 14:40:49,476:INFO: Dataset: univ                Batch: 11/15	Loss 13.8214 (13.8884)
2022-11-22 14:40:49,704:INFO: Dataset: univ                Batch: 12/15	Loss 13.7967 (13.8806)
2022-11-22 14:40:49,916:INFO: Dataset: univ                Batch: 13/15	Loss 13.7815 (13.8729)
2022-11-22 14:40:50,139:INFO: Dataset: univ                Batch: 14/15	Loss 13.7534 (13.8645)
2022-11-22 14:40:50,192:INFO: Dataset: univ                Batch: 15/15	Loss 13.7744 (13.8636)
2022-11-22 14:40:59,245:INFO: Dataset: zara1               Batch: 1/8	Loss 16.9677 (16.9677)
2022-11-22 14:40:59,734:INFO: Dataset: zara1               Batch: 2/8	Loss 16.9446 (16.9561)
2022-11-22 14:41:00,190:INFO: Dataset: zara1               Batch: 3/8	Loss 16.9796 (16.9641)
2022-11-22 14:41:00,497:INFO: Dataset: zara1               Batch: 4/8	Loss 16.9559 (16.9621)
2022-11-22 14:41:00,922:INFO: Dataset: zara1               Batch: 5/8	Loss 16.9534 (16.9604)
2022-11-22 14:41:01,152:INFO: Dataset: zara1               Batch: 6/8	Loss 16.9594 (16.9602)
2022-11-22 14:41:01,404:INFO: Dataset: zara1               Batch: 7/8	Loss 16.9315 (16.9562)
2022-11-22 14:41:01,626:INFO: Dataset: zara1               Batch: 8/8	Loss 16.9354 (16.9540)
2022-11-22 14:41:29,957:INFO: Dataset: zara2               Batch:  1/18	Loss 9.9874 (9.9874)
2022-11-22 14:41:30,170:INFO: Dataset: zara2               Batch:  2/18	Loss 9.9869 (9.9872)
2022-11-22 14:41:30,370:INFO: Dataset: zara2               Batch:  3/18	Loss 9.9223 (9.9649)
2022-11-22 14:41:30,569:INFO: Dataset: zara2               Batch:  4/18	Loss 9.9624 (9.9642)
2022-11-22 14:41:30,743:INFO: Dataset: zara2               Batch:  5/18	Loss 9.9631 (9.9640)
2022-11-22 14:41:30,922:INFO: Dataset: zara2               Batch:  6/18	Loss 9.9331 (9.9590)
2022-11-22 14:41:31,097:INFO: Dataset: zara2               Batch:  7/18	Loss 9.9180 (9.9533)
2022-11-22 14:41:31,282:INFO: Dataset: zara2               Batch:  8/18	Loss 9.9056 (9.9475)
2022-11-22 14:41:31,475:INFO: Dataset: zara2               Batch:  9/18	Loss 9.8880 (9.9411)
2022-11-22 14:41:31,665:INFO: Dataset: zara2               Batch: 10/18	Loss 9.8845 (9.9350)
2022-11-22 14:41:31,856:INFO: Dataset: zara2               Batch: 11/18	Loss 9.8389 (9.9260)
2022-11-22 14:41:32,037:INFO: Dataset: zara2               Batch: 12/18	Loss 9.8144 (9.9165)
2022-11-22 14:41:32,283:INFO: Dataset: zara2               Batch: 13/18	Loss 9.8622 (9.9125)
2022-11-22 14:41:32,526:INFO: Dataset: zara2               Batch: 14/18	Loss 9.8164 (9.9059)
2022-11-22 14:41:32,785:INFO: Dataset: zara2               Batch: 15/18	Loss 9.7966 (9.8985)
2022-11-22 14:41:33,015:INFO: Dataset: zara2               Batch: 16/18	Loss 9.7817 (9.8906)
2022-11-22 14:41:33,193:INFO: Dataset: zara2               Batch: 17/18	Loss 9.7652 (9.8832)
2022-11-22 14:41:33,388:INFO: Dataset: zara2               Batch: 18/18	Loss 9.7414 (9.8767)
2022-11-22 14:41:34,427:INFO: - Computing ADE (validation o)
2022-11-22 14:41:43,027:INFO: 		 ADE on eth                       dataset:	 1.0645793676376343
2022-11-22 14:41:43,029:INFO: Average validation o:	ADE  1.0646	FDE  2.2253
2022-11-22 14:41:43,030:INFO: - Computing loss (validation)
2022-11-22 14:41:49,772:INFO: Dataset: hotel               Batch: 1/2	Loss 17.7139 (17.7139)
2022-11-22 14:41:50,126:INFO: Dataset: hotel               Batch: 2/2	Loss 17.7001 (17.7129)
2022-11-22 14:41:59,009:INFO: Dataset: univ                Batch: 1/3	Loss 13.3275 (13.3275)
2022-11-22 14:41:59,516:INFO: Dataset: univ                Batch: 2/3	Loss 13.3523 (13.3398)
2022-11-22 14:41:59,822:INFO: Dataset: univ                Batch: 3/3	Loss 13.3335 (13.3381)
2022-11-22 14:42:08,176:INFO: Dataset: zara1               Batch: 1/2	Loss 16.8247 (16.8247)
2022-11-22 14:42:08,514:INFO: Dataset: zara1               Batch: 2/2	Loss 16.8446 (16.8300)
2022-11-22 14:42:16,975:INFO: Dataset: zara2               Batch: 1/5	Loss 9.7341 (9.7341)
2022-11-22 14:42:17,397:INFO: Dataset: zara2               Batch: 2/5	Loss 9.7282 (9.7311)
2022-11-22 14:42:17,783:INFO: Dataset: zara2               Batch: 3/5	Loss 9.6850 (9.7162)
2022-11-22 14:42:18,124:INFO: Dataset: zara2               Batch: 4/5	Loss 9.7407 (9.7224)
2022-11-22 14:42:18,330:INFO: Dataset: zara2               Batch: 5/5	Loss 9.7712 (9.7326)
2022-11-22 14:42:19,432:INFO:  --> Model Saved in ./models/E1//P5/CRMF_epoch_1202.pth.tar
2022-11-22 14:42:19,432:INFO: 
===> EPOCH: 1203 (P5)
2022-11-22 14:42:19,434:INFO: - Computing loss (training)
2022-11-22 14:42:26,271:INFO: Dataset: hotel               Batch: 1/4	Loss 17.7425 (17.7425)
2022-11-22 14:42:26,755:INFO: Dataset: hotel               Batch: 2/4	Loss 17.7564 (17.7498)
2022-11-22 14:42:27,205:INFO: Dataset: hotel               Batch: 3/4	Loss 17.7285 (17.7425)
2022-11-22 14:42:27,451:INFO: Dataset: hotel               Batch: 4/4	Loss 17.7554 (17.7448)
