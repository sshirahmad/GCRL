2022-11-05 19:26:25,763:INFO: Initializing Training Set
2022-11-05 19:26:27,386:INFO: Initializing Validation Set
2022-11-05 19:26:27,598:INFO: Initializing Validation O Set
2022-11-05 19:26:29,598:INFO: 
===> EPOCH: 1 (P1)
2022-11-05 19:26:29,598:INFO: - Computing loss (training)
2022-11-05 19:26:30,052:INFO: Batch:  1/31	Total Loss 22.8018 (22.8018)
2022-11-05 19:26:30,105:INFO: Batch:  2/31	Total Loss 20.8655 (21.8534)
2022-11-05 19:26:30,153:INFO: Batch:  3/31	Total Loss 20.4021 (21.4020)
2022-11-05 19:26:30,202:INFO: Batch:  4/31	Total Loss 23.0766 (21.8411)
2022-11-05 19:26:30,253:INFO: Batch:  5/31	Total Loss 21.6777 (21.8083)
2022-11-05 19:26:30,300:INFO: Batch:  6/31	Total Loss 20.9810 (21.6733)
2022-11-05 19:26:30,347:INFO: Batch:  7/31	Total Loss 22.3536 (21.7605)
2022-11-05 19:26:30,393:INFO: Batch:  8/31	Total Loss 20.7261 (21.6353)
2022-11-05 19:26:30,441:INFO: Batch:  9/31	Total Loss 20.8164 (21.5396)
2022-11-05 19:26:30,490:INFO: Batch: 10/31	Total Loss 19.5755 (21.3206)
2022-11-05 19:26:30,540:INFO: Batch: 11/31	Total Loss 18.2631 (21.0193)
2022-11-05 19:26:30,591:INFO: Batch: 12/31	Total Loss 20.4944 (20.9745)
2022-11-05 19:26:30,640:INFO: Batch: 13/31	Total Loss 19.1264 (20.8332)
2022-11-05 19:26:30,690:INFO: Batch: 14/31	Total Loss 20.7218 (20.8246)
2022-11-05 19:26:30,740:INFO: Batch: 15/31	Total Loss 20.4925 (20.8027)
2022-11-05 19:26:30,793:INFO: Batch: 16/31	Total Loss 19.7900 (20.7313)
2022-11-05 19:26:30,844:INFO: Batch: 17/31	Total Loss 19.1616 (20.6456)
2022-11-05 19:26:30,894:INFO: Batch: 18/31	Total Loss 17.2375 (20.4446)
2022-11-05 19:26:30,944:INFO: Batch: 19/31	Total Loss 20.0910 (20.4265)
2022-11-05 19:26:30,994:INFO: Batch: 20/31	Total Loss 19.0225 (20.3516)
2022-11-05 19:26:31,045:INFO: Batch: 21/31	Total Loss 18.0632 (20.2331)
2022-11-05 19:26:31,096:INFO: Batch: 22/31	Total Loss 19.8531 (20.2177)
2022-11-05 19:26:31,147:INFO: Batch: 23/31	Total Loss 18.7297 (20.1526)
2022-11-05 19:26:31,199:INFO: Batch: 24/31	Total Loss 17.7449 (20.0566)
2022-11-05 19:26:31,251:INFO: Batch: 25/31	Total Loss 18.3925 (19.9834)
2022-11-05 19:26:31,301:INFO: Batch: 26/31	Total Loss 18.3799 (19.9194)
2022-11-05 19:26:31,351:INFO: Batch: 27/31	Total Loss 16.6494 (19.8072)
2022-11-05 19:26:31,403:INFO: Batch: 28/31	Total Loss 18.6086 (19.7619)
2022-11-05 19:26:31,452:INFO: Batch: 29/31	Total Loss 20.0106 (19.7696)
2022-11-05 19:26:31,505:INFO: Batch: 30/31	Total Loss 16.3755 (19.6452)
2022-11-05 19:26:31,540:INFO: Batch: 31/31	Total Loss 8.7485 (19.5700)
2022-11-05 19:26:31,697:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(2, 2, 2, 2, 2)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_1.pth.tar
2022-11-05 19:26:31,697:INFO: 
===> EPOCH: 2 (P1)
2022-11-05 19:26:31,698:INFO: - Computing loss (training)
2022-11-05 19:26:32,225:INFO: Batch:  1/31	Total Loss 17.4589 (17.4589)
2022-11-05 19:26:32,282:INFO: Batch:  2/31	Total Loss 17.2863 (17.3745)
2022-11-05 19:26:32,334:INFO: Batch:  3/31	Total Loss 17.3773 (17.3755)
2022-11-05 19:26:32,385:INFO: Batch:  4/31	Total Loss 17.4047 (17.3821)
2022-11-05 19:26:32,430:INFO: Batch:  5/31	Total Loss 18.1991 (17.5469)
2022-11-05 19:26:32,477:INFO: Batch:  6/31	Total Loss 18.3583 (17.6730)
2022-11-05 19:26:32,530:INFO: Batch:  7/31	Total Loss 19.6260 (17.9173)
2022-11-05 19:26:32,582:INFO: Batch:  8/31	Total Loss 18.8789 (18.0319)
2022-11-05 19:26:32,634:INFO: Batch:  9/31	Total Loss 18.3258 (18.0630)
2022-11-05 19:26:32,685:INFO: Batch: 10/31	Total Loss 16.6439 (17.9268)
2022-11-05 19:26:32,733:INFO: Batch: 11/31	Total Loss 18.0524 (17.9374)
2022-11-05 19:26:32,781:INFO: Batch: 12/31	Total Loss 19.3395 (18.0488)
2022-11-05 19:26:32,829:INFO: Batch: 13/31	Total Loss 18.4411 (18.0777)
2022-11-05 19:26:32,881:INFO: Batch: 14/31	Total Loss 16.2567 (17.9356)
2022-11-05 19:26:32,931:INFO: Batch: 15/31	Total Loss 18.2773 (17.9598)
2022-11-05 19:26:32,979:INFO: Batch: 16/31	Total Loss 17.4275 (17.9262)
2022-11-05 19:26:33,026:INFO: Batch: 17/31	Total Loss 14.7397 (17.7442)
2022-11-05 19:26:33,075:INFO: Batch: 18/31	Total Loss 17.5533 (17.7333)
2022-11-05 19:26:33,126:INFO: Batch: 19/31	Total Loss 16.6787 (17.6834)
2022-11-05 19:26:33,182:INFO: Batch: 20/31	Total Loss 16.2975 (17.6147)
2022-11-05 19:26:33,236:INFO: Batch: 21/31	Total Loss 15.5767 (17.5152)
2022-11-05 19:26:33,286:INFO: Batch: 22/31	Total Loss 13.9899 (17.3623)
2022-11-05 19:26:33,335:INFO: Batch: 23/31	Total Loss 16.1517 (17.3075)
2022-11-05 19:26:33,385:INFO: Batch: 24/31	Total Loss 14.3464 (17.1794)
2022-11-05 19:26:33,438:INFO: Batch: 25/31	Total Loss 16.5629 (17.1549)
2022-11-05 19:26:33,496:INFO: Batch: 26/31	Total Loss 16.2534 (17.1212)
2022-11-05 19:26:33,551:INFO: Batch: 27/31	Total Loss 14.1007 (17.0149)
2022-11-05 19:26:33,608:INFO: Batch: 28/31	Total Loss 16.7188 (17.0049)
2022-11-05 19:26:33,661:INFO: Batch: 29/31	Total Loss 15.9766 (16.9671)
2022-11-05 19:26:33,711:INFO: Batch: 30/31	Total Loss 16.4983 (16.9515)
2022-11-05 19:26:33,741:INFO: Batch: 31/31	Total Loss 5.8138 (16.8346)
2022-11-05 19:26:33,867:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(2, 2, 2, 2, 2)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_2.pth.tar
2022-11-05 19:26:33,868:INFO: 
===> EPOCH: 3 (P2)
2022-11-05 19:26:33,868:INFO: - Computing loss (training)
2022-11-05 19:26:34,559:INFO: Batch:  1/31	Total Loss 30.2929 (30.2929)
2022-11-05 19:26:34,822:INFO: Batch:  2/31	Total Loss 27.2533 (28.5858)
2022-11-05 19:26:35,067:INFO: Batch:  3/31	Total Loss 30.1290 (29.0639)
2022-11-05 19:26:35,307:INFO: Batch:  4/31	Total Loss 27.3888 (28.5847)
2022-11-05 19:26:35,546:INFO: Batch:  5/31	Total Loss 26.5419 (28.1361)
2022-11-05 19:26:35,803:INFO: Batch:  6/31	Total Loss 24.7875 (27.5432)
2022-11-05 19:26:36,046:INFO: Batch:  7/31	Total Loss 26.0093 (27.3542)
2022-11-05 19:26:36,284:INFO: Batch:  8/31	Total Loss 24.9623 (27.0536)
2022-11-05 19:26:36,527:INFO: Batch:  9/31	Total Loss 22.7902 (26.5677)
2022-11-05 19:26:36,767:INFO: Batch: 10/31	Total Loss 24.1827 (26.3055)
2022-11-05 19:26:37,009:INFO: Batch: 11/31	Total Loss 25.0974 (26.2019)
2022-11-05 19:26:37,250:INFO: Batch: 12/31	Total Loss 21.6635 (25.8276)
2022-11-05 19:26:37,561:INFO: Batch: 13/31	Total Loss 22.1331 (25.5256)
2022-11-05 19:26:37,807:INFO: Batch: 14/31	Total Loss 22.4692 (25.3053)
2022-11-05 19:26:38,053:INFO: Batch: 15/31	Total Loss 22.6461 (25.1503)
2022-11-05 19:26:38,305:INFO: Batch: 16/31	Total Loss 19.4693 (24.7967)
2022-11-05 19:26:38,572:INFO: Batch: 17/31	Total Loss 24.2685 (24.7703)
2022-11-05 19:26:38,840:INFO: Batch: 18/31	Total Loss 19.9806 (24.5085)
2022-11-05 19:26:39,111:INFO: Batch: 19/31	Total Loss 19.5300 (24.2875)
2022-11-05 19:26:39,371:INFO: Batch: 20/31	Total Loss 20.4377 (24.0893)
2022-11-05 19:26:39,644:INFO: Batch: 21/31	Total Loss 19.5206 (23.8837)
2022-11-05 19:26:39,922:INFO: Batch: 22/31	Total Loss 18.0968 (23.6187)
2022-11-05 19:26:40,166:INFO: Batch: 23/31	Total Loss 18.0255 (23.3582)
2022-11-05 19:26:40,408:INFO: Batch: 24/31	Total Loss 17.5219 (23.0932)
2022-11-05 19:26:40,665:INFO: Batch: 25/31	Total Loss 19.4825 (22.9366)
2022-11-05 19:26:40,928:INFO: Batch: 26/31	Total Loss 17.1216 (22.7193)
2022-11-05 19:26:41,191:INFO: Batch: 27/31	Total Loss 17.3980 (22.5230)
2022-11-05 19:26:41,448:INFO: Batch: 28/31	Total Loss 17.5390 (22.3413)
2022-11-05 19:26:41,719:INFO: Batch: 29/31	Total Loss 17.2839 (22.1646)
2022-11-05 19:26:41,964:INFO: Batch: 30/31	Total Loss 16.9840 (21.9817)
2022-11-05 19:26:42,080:INFO: Batch: 31/31	Total Loss 5.4337 (21.7920)
2022-11-05 19:26:42,209:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(2, 2, 2, 2, 2)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_3.pth.tar
2022-11-05 19:26:42,209:INFO: 
===> EPOCH: 4 (P2)
2022-11-05 19:26:42,209:INFO: - Computing loss (training)
2022-11-05 19:26:42,893:INFO: Batch:  1/31	Total Loss 16.3932 (16.3932)
2022-11-05 19:26:43,150:INFO: Batch:  2/31	Total Loss 20.9955 (18.5874)
2022-11-05 19:26:43,391:INFO: Batch:  3/31	Total Loss 15.8724 (17.6809)
2022-11-05 19:26:43,631:INFO: Batch:  4/31	Total Loss 19.2497 (18.0593)
2022-11-05 19:26:43,866:INFO: Batch:  5/31	Total Loss 15.6294 (17.5657)
2022-11-05 19:26:44,104:INFO: Batch:  6/31	Total Loss 15.7627 (17.2624)
2022-11-05 19:26:44,340:INFO: Batch:  7/31	Total Loss 20.3498 (17.6245)
2022-11-05 19:26:44,576:INFO: Batch:  8/31	Total Loss 14.6590 (17.2430)
2022-11-05 19:26:44,816:INFO: Batch:  9/31	Total Loss 16.9535 (17.2114)
2022-11-05 19:26:45,056:INFO: Batch: 10/31	Total Loss 16.8660 (17.1755)
2022-11-05 19:26:45,296:INFO: Batch: 11/31	Total Loss 15.4838 (17.0190)
2022-11-05 19:26:45,536:INFO: Batch: 12/31	Total Loss 15.1418 (16.8697)
2022-11-05 19:26:45,794:INFO: Batch: 13/31	Total Loss 16.2919 (16.8277)
2022-11-05 19:26:46,047:INFO: Batch: 14/31	Total Loss 16.0309 (16.7648)
2022-11-05 19:26:46,312:INFO: Batch: 15/31	Total Loss 15.0790 (16.6460)
2022-11-05 19:26:46,567:INFO: Batch: 16/31	Total Loss 14.5050 (16.4987)
2022-11-05 19:26:46,821:INFO: Batch: 17/31	Total Loss 15.2777 (16.4325)
2022-11-05 19:26:47,067:INFO: Batch: 18/31	Total Loss 15.1318 (16.3563)
2022-11-05 19:26:47,311:INFO: Batch: 19/31	Total Loss 16.2230 (16.3487)
2022-11-05 19:26:47,632:INFO: Batch: 20/31	Total Loss 17.0059 (16.3812)
2022-11-05 19:26:47,917:INFO: Batch: 21/31	Total Loss 16.1658 (16.3704)
2022-11-05 19:26:48,162:INFO: Batch: 22/31	Total Loss 13.4407 (16.2220)
2022-11-05 19:26:48,406:INFO: Batch: 23/31	Total Loss 14.9495 (16.1640)
2022-11-05 19:26:48,650:INFO: Batch: 24/31	Total Loss 13.6637 (16.0532)
2022-11-05 19:26:48,894:INFO: Batch: 25/31	Total Loss 12.8812 (15.9159)
2022-11-05 19:26:49,135:INFO: Batch: 26/31	Total Loss 14.0541 (15.8441)
2022-11-05 19:26:49,376:INFO: Batch: 27/31	Total Loss 15.2726 (15.8236)
2022-11-05 19:26:49,622:INFO: Batch: 28/31	Total Loss 12.4555 (15.6919)
2022-11-05 19:26:49,872:INFO: Batch: 29/31	Total Loss 13.6269 (15.6211)
2022-11-05 19:26:50,118:INFO: Batch: 30/31	Total Loss 11.9740 (15.5169)
2022-11-05 19:26:50,232:INFO: Batch: 31/31	Total Loss 4.7107 (15.3941)
2022-11-05 19:26:50,360:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(2, 2, 2, 2, 2)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_4.pth.tar
2022-11-05 19:26:50,360:INFO: 
===> EPOCH: 5 (P3)
2022-11-05 19:26:50,360:INFO: - Computing loss (training)
2022-11-05 19:26:51,205:INFO: Batch:  1/31	Total Loss 41.1896 (41.1896)
2022-11-05 19:26:51,664:INFO: Batch:  2/31	Total Loss 41.2465 (41.2181)
2022-11-05 19:26:52,109:INFO: Batch:  3/31	Total Loss 41.3458 (41.2583)
2022-11-05 19:26:52,550:INFO: Batch:  4/31	Total Loss 38.0783 (40.4550)
2022-11-05 19:26:52,983:INFO: Batch:  5/31	Total Loss 41.2527 (40.5997)
2022-11-05 19:26:53,419:INFO: Batch:  6/31	Total Loss 40.8552 (40.6460)
2022-11-05 19:26:53,900:INFO: Batch:  7/31	Total Loss 39.3909 (40.4725)
2022-11-05 19:26:54,463:INFO: Batch:  8/31	Total Loss 40.8043 (40.5107)
2022-11-05 19:26:54,928:INFO: Batch:  9/31	Total Loss 38.5339 (40.3037)
2022-11-05 19:26:55,372:INFO: Batch: 10/31	Total Loss 37.4328 (40.0426)
2022-11-05 19:26:55,819:INFO: Batch: 11/31	Total Loss 37.7533 (39.8384)
2022-11-05 19:26:56,255:INFO: Batch: 12/31	Total Loss 36.3588 (39.5536)
2022-11-05 19:26:56,695:INFO: Batch: 13/31	Total Loss 35.7278 (39.3049)
2022-11-05 19:26:57,138:INFO: Batch: 14/31	Total Loss 35.9736 (39.0715)
2022-11-05 19:26:57,586:INFO: Batch: 15/31	Total Loss 32.9842 (38.6463)
2022-11-05 19:26:58,034:INFO: Batch: 16/31	Total Loss 31.9809 (38.2803)
2022-11-05 19:26:58,536:INFO: Batch: 17/31	Total Loss 30.5693 (37.8510)
2022-11-05 19:26:59,313:INFO: Batch: 18/31	Total Loss 30.8530 (37.4981)
2022-11-05 19:26:59,794:INFO: Batch: 19/31	Total Loss 28.9830 (37.0407)
2022-11-05 19:27:00,320:INFO: Batch: 20/31	Total Loss 27.9985 (36.6051)
2022-11-05 19:27:00,776:INFO: Batch: 21/31	Total Loss 27.4299 (36.1724)
2022-11-05 19:27:01,228:INFO: Batch: 22/31	Total Loss 25.1463 (35.6451)
2022-11-05 19:27:01,681:INFO: Batch: 23/31	Total Loss 21.8400 (35.0104)
2022-11-05 19:27:02,130:INFO: Batch: 24/31	Total Loss 25.1407 (34.6617)
2022-11-05 19:27:02,580:INFO: Batch: 25/31	Total Loss 23.5168 (34.2629)
2022-11-05 19:27:03,030:INFO: Batch: 26/31	Total Loss 20.9386 (33.7290)
2022-11-05 19:27:03,484:INFO: Batch: 27/31	Total Loss 20.6749 (33.2034)
2022-11-05 19:27:03,937:INFO: Batch: 28/31	Total Loss 19.8475 (32.6934)
2022-11-05 19:27:04,388:INFO: Batch: 29/31	Total Loss 21.5631 (32.2949)
2022-11-05 19:27:04,839:INFO: Batch: 30/31	Total Loss 20.5479 (31.9290)
2022-11-05 19:27:05,211:INFO: Batch: 31/31	Total Loss 7.8777 (31.6807)
2022-11-05 19:27:05,335:INFO: - Computing ADE (validation o)
2022-11-05 19:27:05,835:INFO: 		 ADE on eth                       dataset:	 2.8496034145355225
2022-11-05 19:27:05,835:INFO: Average validation o:	ADE  2.8496	FDE  4.8279
2022-11-05 19:27:05,836:INFO: - Computing ADE (validation)
2022-11-05 19:27:06,040:INFO: 		 ADE on hotel                     dataset:	 0.918323278427124
2022-11-05 19:27:06,346:INFO: 		 ADE on univ                      dataset:	 1.4921231269836426
2022-11-05 19:27:06,538:INFO: 		 ADE on zara1                     dataset:	 2.530928611755371
2022-11-05 19:27:06,843:INFO: 		 ADE on zara2                     dataset:	 1.4053393602371216
2022-11-05 19:27:06,844:INFO: Average validation:	ADE  1.4893	FDE  2.7071
2022-11-05 19:27:06,844:INFO: - Computing ADE (training)
2022-11-05 19:27:07,217:INFO: 		 ADE on hotel                     dataset:	 1.2806695699691772
2022-11-05 19:27:07,835:INFO: 		 ADE on univ                      dataset:	 1.379772424697876
2022-11-05 19:27:08,290:INFO: 		 ADE on zara1                     dataset:	 2.473416328430176
2022-11-05 19:27:08,975:INFO: 		 ADE on zara2                     dataset:	 1.6782879829406738
2022-11-05 19:27:08,975:INFO: Average training:	ADE  1.5075	FDE  2.7457
2022-11-05 19:27:08,984:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(2, 2, 2, 2, 2)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_5.pth.tar
2022-11-05 19:27:08,984:INFO: 
===> EPOCH: 6 (P3)
2022-11-05 19:27:08,984:INFO: - Computing loss (training)
2022-11-05 19:27:09,869:INFO: Batch:  1/31	Total Loss 19.7195 (19.7195)
2022-11-05 19:27:10,336:INFO: Batch:  2/31	Total Loss 21.2508 (20.4621)
2022-11-05 19:27:10,811:INFO: Batch:  3/31	Total Loss 20.1156 (20.3356)
2022-11-05 19:27:11,299:INFO: Batch:  4/31	Total Loss 18.5936 (19.8478)
2022-11-05 19:27:11,740:INFO: Batch:  5/31	Total Loss 18.7091 (19.6153)
2022-11-05 19:27:12,175:INFO: Batch:  6/31	Total Loss 18.8443 (19.4854)
2022-11-05 19:27:12,620:INFO: Batch:  7/31	Total Loss 19.0625 (19.4262)
2022-11-05 19:27:13,055:INFO: Batch:  8/31	Total Loss 17.7375 (19.1930)
2022-11-05 19:27:13,493:INFO: Batch:  9/31	Total Loss 18.5255 (19.1211)
2022-11-05 19:27:13,937:INFO: Batch: 10/31	Total Loss 17.6501 (18.9906)
2022-11-05 19:27:14,379:INFO: Batch: 11/31	Total Loss 19.2577 (19.0153)
2022-11-05 19:27:14,816:INFO: Batch: 12/31	Total Loss 18.0175 (18.9262)
2022-11-05 19:27:15,253:INFO: Batch: 13/31	Total Loss 18.2038 (18.8691)
2022-11-05 19:27:15,691:INFO: Batch: 14/31	Total Loss 18.9015 (18.8717)
2022-11-05 19:27:16,133:INFO: Batch: 15/31	Total Loss 19.3613 (18.9035)
2022-11-05 19:27:16,579:INFO: Batch: 16/31	Total Loss 17.7078 (18.8294)
2022-11-05 19:27:17,020:INFO: Batch: 17/31	Total Loss 18.6381 (18.8177)
2022-11-05 19:27:17,461:INFO: Batch: 18/31	Total Loss 16.6704 (18.7008)
2022-11-05 19:27:17,904:INFO: Batch: 19/31	Total Loss 18.1883 (18.6753)
2022-11-05 19:27:18,375:INFO: Batch: 20/31	Total Loss 17.6659 (18.6202)
2022-11-05 19:27:18,820:INFO: Batch: 21/31	Total Loss 17.2891 (18.5571)
2022-11-05 19:27:19,264:INFO: Batch: 22/31	Total Loss 17.1842 (18.4888)
2022-11-05 19:27:19,726:INFO: Batch: 23/31	Total Loss 18.8477 (18.5039)
2022-11-05 19:27:20,203:INFO: Batch: 24/31	Total Loss 17.6881 (18.4690)
2022-11-05 19:27:20,672:INFO: Batch: 25/31	Total Loss 17.4550 (18.4281)
2022-11-05 19:27:21,122:INFO: Batch: 26/31	Total Loss 17.1235 (18.3784)
2022-11-05 19:27:21,572:INFO: Batch: 27/31	Total Loss 17.7868 (18.3585)
2022-11-05 19:27:22,023:INFO: Batch: 28/31	Total Loss 16.7012 (18.2946)
2022-11-05 19:27:22,525:INFO: Batch: 29/31	Total Loss 17.8291 (18.2806)
2022-11-05 19:27:23,010:INFO: Batch: 30/31	Total Loss 16.9181 (18.2342)
2022-11-05 19:27:23,418:INFO: Batch: 31/31	Total Loss 8.0725 (18.1501)
2022-11-05 19:27:23,554:INFO: - Computing ADE (validation o)
2022-11-05 19:27:24,068:INFO: 		 ADE on eth                       dataset:	 2.8448355197906494
2022-11-05 19:27:24,068:INFO: Average validation o:	ADE  2.8448	FDE  4.8239
2022-11-05 19:27:24,069:INFO: - Computing ADE (validation)
2022-11-05 19:27:24,290:INFO: 		 ADE on hotel                     dataset:	 0.9049637317657471
2022-11-05 19:27:24,551:INFO: 		 ADE on univ                      dataset:	 1.4900521039962769
2022-11-05 19:27:24,777:INFO: 		 ADE on zara1                     dataset:	 2.5307869911193848
2022-11-05 19:27:25,154:INFO: 		 ADE on zara2                     dataset:	 1.393019199371338
2022-11-05 19:27:25,155:INFO: Average validation:	ADE  1.4829	FDE  2.7022
2022-11-05 19:27:25,156:INFO: - Computing ADE (training)
2022-11-05 19:27:25,610:INFO: 		 ADE on hotel                     dataset:	 1.270042061805725
2022-11-05 19:27:26,258:INFO: 		 ADE on univ                      dataset:	 1.3761756420135498
2022-11-05 19:27:26,772:INFO: 		 ADE on zara1                     dataset:	 2.471947431564331
2022-11-05 19:27:27,491:INFO: 		 ADE on zara2                     dataset:	 1.6701050996780396
2022-11-05 19:27:27,491:INFO: Average training:	ADE  1.5030	FDE  2.7424
2022-11-05 19:27:27,501:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(2, 2, 2, 2, 2)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_6.pth.tar
2022-11-05 19:27:27,501:INFO: 
===> EPOCH: 7 (P4)
2022-11-05 19:27:27,501:INFO: - Computing loss (training)
2022-11-05 19:27:28,388:INFO: Batch:  1/31	Total Loss 20.8230 (20.8230)
2022-11-05 19:27:28,971:INFO: Batch:  2/31	Total Loss 19.1125 (19.9725)
2022-11-05 19:27:29,483:INFO: Batch:  3/31	Total Loss 18.2057 (19.3779)
2022-11-05 19:27:30,006:INFO: Batch:  4/31	Total Loss 23.2032 (20.3064)
2022-11-05 19:27:30,498:INFO: Batch:  5/31	Total Loss 21.0583 (20.4383)
2022-11-05 19:27:30,997:INFO: Batch:  6/31	Total Loss 20.3797 (20.4291)
2022-11-05 19:27:31,461:INFO: Batch:  7/31	Total Loss 19.3884 (20.2671)
2022-11-05 19:27:31,925:INFO: Batch:  8/31	Total Loss 19.3514 (20.1518)
2022-11-05 19:27:32,396:INFO: Batch:  9/31	Total Loss 22.5620 (20.4100)
2022-11-05 19:27:32,865:INFO: Batch: 10/31	Total Loss 20.2483 (20.3935)
2022-11-05 19:27:33,328:INFO: Batch: 11/31	Total Loss 18.2554 (20.1901)
2022-11-05 19:27:33,809:INFO: Batch: 12/31	Total Loss 19.9468 (20.1694)
2022-11-05 19:27:34,301:INFO: Batch: 13/31	Total Loss 18.6794 (20.0390)
2022-11-05 19:27:34,792:INFO: Batch: 14/31	Total Loss 20.5277 (20.0751)
2022-11-05 19:27:35,273:INFO: Batch: 15/31	Total Loss 19.1211 (20.0126)
2022-11-05 19:27:35,765:INFO: Batch: 16/31	Total Loss 21.9689 (20.1294)
2022-11-05 19:27:36,250:INFO: Batch: 17/31	Total Loss 18.5905 (20.0292)
2022-11-05 19:27:36,736:INFO: Batch: 18/31	Total Loss 18.7683 (19.9579)
2022-11-05 19:27:37,223:INFO: Batch: 19/31	Total Loss 20.5015 (19.9859)
2022-11-05 19:27:37,722:INFO: Batch: 20/31	Total Loss 20.5734 (20.0163)
2022-11-05 19:27:38,295:INFO: Batch: 21/31	Total Loss 19.2850 (19.9798)
2022-11-05 19:27:38,818:INFO: Batch: 22/31	Total Loss 19.2376 (19.9469)
2022-11-05 19:27:39,296:INFO: Batch: 23/31	Total Loss 18.6834 (19.8932)
2022-11-05 19:27:39,787:INFO: Batch: 24/31	Total Loss 19.1279 (19.8601)
2022-11-05 19:27:40,264:INFO: Batch: 25/31	Total Loss 17.2852 (19.7556)
2022-11-05 19:27:40,749:INFO: Batch: 26/31	Total Loss 18.7817 (19.7196)
2022-11-05 19:27:41,255:INFO: Batch: 27/31	Total Loss 17.3313 (19.6363)
2022-11-05 19:27:41,734:INFO: Batch: 28/31	Total Loss 17.9046 (19.5834)
2022-11-05 19:27:42,221:INFO: Batch: 29/31	Total Loss 19.1670 (19.5689)
2022-11-05 19:27:42,721:INFO: Batch: 30/31	Total Loss 19.4526 (19.5647)
2022-11-05 19:27:43,105:INFO: Batch: 31/31	Total Loss 8.2878 (19.4683)
2022-11-05 19:27:43,237:INFO: - Computing ADE (validation o)
2022-11-05 19:27:43,912:INFO: 		 ADE on eth                       dataset:	 2.8632330894470215
2022-11-05 19:27:43,913:INFO: Average validation o:	ADE  2.8632	FDE  4.8402
2022-11-05 19:27:43,913:INFO: - Computing ADE (validation)
2022-11-05 19:27:44,183:INFO: 		 ADE on hotel                     dataset:	 0.9320027232170105
2022-11-05 19:27:44,561:INFO: 		 ADE on univ                      dataset:	 1.4971562623977661
2022-11-05 19:27:44,793:INFO: 		 ADE on zara1                     dataset:	 2.5449466705322266
2022-11-05 19:27:45,202:INFO: 		 ADE on zara2                     dataset:	 1.4205693006515503
2022-11-05 19:27:45,203:INFO: Average validation:	ADE  1.4990	FDE  2.7161
2022-11-05 19:27:45,203:INFO: - Computing ADE (training)
2022-11-05 19:27:45,703:INFO: 		 ADE on hotel                     dataset:	 1.289940595626831
2022-11-05 19:27:46,713:INFO: 		 ADE on univ                      dataset:	 1.3871289491653442
2022-11-05 19:27:47,387:INFO: 		 ADE on zara1                     dataset:	 2.4843361377716064
2022-11-05 19:27:48,474:INFO: 		 ADE on zara2                     dataset:	 1.6937230825424194
2022-11-05 19:27:48,474:INFO: Average training:	ADE  1.5168	FDE  2.7545
2022-11-05 19:27:48,485:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(2, 2, 2, 2, 2)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_7.pth.tar
2022-11-05 19:27:48,485:INFO: 
===> EPOCH: 8 (P4)
2022-11-05 19:27:48,485:INFO: - Computing loss (training)
2022-11-05 19:27:49,370:INFO: Batch:  1/31	Total Loss 17.1648 (17.1648)
2022-11-05 19:27:49,860:INFO: Batch:  2/31	Total Loss 20.4176 (18.4715)
2022-11-05 19:27:50,426:INFO: Batch:  3/31	Total Loss 18.6930 (18.5445)
2022-11-05 19:27:50,959:INFO: Batch:  4/31	Total Loss 19.1362 (18.6881)
2022-11-05 19:27:51,588:INFO: Batch:  5/31	Total Loss 17.1558 (18.3566)
2022-11-05 19:27:52,065:INFO: Batch:  6/31	Total Loss 16.9156 (18.1208)
2022-11-05 19:27:52,543:INFO: Batch:  7/31	Total Loss 18.5061 (18.1801)
2022-11-05 19:27:53,018:INFO: Batch:  8/31	Total Loss 18.4113 (18.2095)
2022-11-05 19:27:53,504:INFO: Batch:  9/31	Total Loss 17.5212 (18.1281)
2022-11-05 19:27:53,978:INFO: Batch: 10/31	Total Loss 18.1141 (18.1267)
2022-11-05 19:27:54,468:INFO: Batch: 11/31	Total Loss 18.2493 (18.1390)
2022-11-05 19:27:54,968:INFO: Batch: 12/31	Total Loss 19.7091 (18.2598)
2022-11-05 19:27:55,454:INFO: Batch: 13/31	Total Loss 17.4806 (18.1900)
2022-11-05 19:27:55,954:INFO: Batch: 14/31	Total Loss 16.1275 (18.0234)
2022-11-05 19:27:56,446:INFO: Batch: 15/31	Total Loss 16.5754 (17.9193)
2022-11-05 19:27:56,925:INFO: Batch: 16/31	Total Loss 18.7892 (17.9659)
2022-11-05 19:27:57,418:INFO: Batch: 17/31	Total Loss 18.1799 (17.9802)
2022-11-05 19:27:57,902:INFO: Batch: 18/31	Total Loss 18.1798 (17.9922)
2022-11-05 19:27:58,412:INFO: Batch: 19/31	Total Loss 18.2585 (18.0063)
2022-11-05 19:27:58,933:INFO: Batch: 20/31	Total Loss 19.2766 (18.0617)
2022-11-05 19:27:59,430:INFO: Batch: 21/31	Total Loss 17.3406 (18.0277)
2022-11-05 19:27:59,938:INFO: Batch: 22/31	Total Loss 17.6821 (18.0135)
2022-11-05 19:28:00,420:INFO: Batch: 23/31	Total Loss 17.1630 (17.9736)
2022-11-05 19:28:00,916:INFO: Batch: 24/31	Total Loss 16.4282 (17.9114)
2022-11-05 19:28:01,399:INFO: Batch: 25/31	Total Loss 19.2002 (17.9621)
2022-11-05 19:28:01,874:INFO: Batch: 26/31	Total Loss 15.2733 (17.8612)
2022-11-05 19:28:02,366:INFO: Batch: 27/31	Total Loss 17.7366 (17.8564)
2022-11-05 19:28:02,841:INFO: Batch: 28/31	Total Loss 15.7375 (17.7756)
2022-11-05 19:28:03,317:INFO: Batch: 29/31	Total Loss 15.8913 (17.7133)
2022-11-05 19:28:03,788:INFO: Batch: 30/31	Total Loss 17.7913 (17.7160)
2022-11-05 19:28:04,167:INFO: Batch: 31/31	Total Loss 7.5768 (17.6359)
2022-11-05 19:28:04,300:INFO: - Computing ADE (validation o)
2022-11-05 19:28:04,911:INFO: 		 ADE on eth                       dataset:	 2.8554773330688477
2022-11-05 19:28:04,911:INFO: Average validation o:	ADE  2.8555	FDE  4.8372
2022-11-05 19:28:04,912:INFO: - Computing ADE (validation)
2022-11-05 19:28:05,175:INFO: 		 ADE on hotel                     dataset:	 0.9221450686454773
2022-11-05 19:28:05,500:INFO: 		 ADE on univ                      dataset:	 1.4855824708938599
2022-11-05 19:28:05,726:INFO: 		 ADE on zara1                     dataset:	 2.508169174194336
2022-11-05 19:28:06,147:INFO: 		 ADE on zara2                     dataset:	 1.401360273361206
2022-11-05 19:28:06,147:INFO: Average validation:	ADE  1.4833	FDE  2.6988
2022-11-05 19:28:06,148:INFO: - Computing ADE (training)
2022-11-05 19:28:06,657:INFO: 		 ADE on hotel                     dataset:	 1.2776998281478882
2022-11-05 19:28:07,647:INFO: 		 ADE on univ                      dataset:	 1.3749892711639404
2022-11-05 19:28:08,332:INFO: 		 ADE on zara1                     dataset:	 2.4696993827819824
2022-11-05 19:28:09,465:INFO: 		 ADE on zara2                     dataset:	 1.6793415546417236
2022-11-05 19:28:09,465:INFO: Average training:	ADE  1.5041	FDE  2.7417
2022-11-05 19:28:09,476:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(2, 2, 2, 2, 2)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_8.pth.tar
2022-11-05 19:28:09,476:INFO: 
===> EPOCH: 9 (P5)
2022-11-05 19:28:09,476:INFO: - Computing loss (training)
2022-11-05 19:28:09,906:INFO: Batch:  1/31	Total Loss 63.1341 (63.1341)
2022-11-05 19:28:09,919:INFO: Batch:  2/31	Total Loss 63.0073 (63.0661)
2022-11-05 19:28:09,926:INFO: Batch:  3/31	Total Loss 62.9086 (63.0077)
2022-11-05 19:28:09,935:INFO: Batch:  4/31	Total Loss 62.8226 (62.9608)
2022-11-05 19:28:09,941:INFO: Batch:  5/31	Total Loss 62.7066 (62.9117)
2022-11-05 19:28:09,947:INFO: Batch:  6/31	Total Loss 62.5769 (62.8523)
2022-11-05 19:28:09,951:INFO: Batch:  7/31	Total Loss 62.5167 (62.8002)
2022-11-05 19:28:09,958:INFO: Batch:  8/31	Total Loss 62.4143 (62.7523)
2022-11-05 19:28:09,965:INFO: Batch:  9/31	Total Loss 62.3261 (62.7047)
2022-11-05 19:28:09,972:INFO: Batch: 10/31	Total Loss 62.2125 (62.6511)
2022-11-05 19:28:09,980:INFO: Batch: 11/31	Total Loss 62.1266 (62.6014)
2022-11-05 19:28:09,987:INFO: Batch: 12/31	Total Loss 61.9888 (62.5513)
2022-11-05 19:28:09,994:INFO: Batch: 13/31	Total Loss 61.8852 (62.4939)
2022-11-05 19:28:10,001:INFO: Batch: 14/31	Total Loss 61.7768 (62.4400)
2022-11-05 19:28:10,008:INFO: Batch: 15/31	Total Loss 61.6114 (62.3855)
2022-11-05 19:28:10,016:INFO: Batch: 16/31	Total Loss 61.5798 (62.3355)
2022-11-05 19:28:10,023:INFO: Batch: 17/31	Total Loss 61.3772 (62.2791)
2022-11-05 19:28:10,030:INFO: Batch: 18/31	Total Loss 61.2316 (62.2270)
2022-11-05 19:28:10,037:INFO: Batch: 19/31	Total Loss 61.1781 (62.1698)
2022-11-05 19:28:10,044:INFO: Batch: 20/31	Total Loss 61.0103 (62.1187)
2022-11-05 19:28:10,051:INFO: Batch: 21/31	Total Loss 60.8494 (62.0626)
2022-11-05 19:28:10,058:INFO: Batch: 22/31	Total Loss 60.7402 (62.0007)
2022-11-05 19:28:10,065:INFO: Batch: 23/31	Total Loss 60.5215 (61.9317)
2022-11-05 19:28:10,072:INFO: Batch: 24/31	Total Loss 60.3080 (61.8797)
2022-11-05 19:28:10,079:INFO: Batch: 25/31	Total Loss 60.3433 (61.8156)
2022-11-05 19:28:10,086:INFO: Batch: 26/31	Total Loss 60.1136 (61.7502)
2022-11-05 19:28:10,092:INFO: Batch: 27/31	Total Loss 59.9130 (61.6774)
2022-11-05 19:28:10,099:INFO: Batch: 28/31	Total Loss 59.6561 (61.6011)
2022-11-05 19:28:10,105:INFO: Batch: 29/31	Total Loss 59.5909 (61.5351)
2022-11-05 19:28:10,112:INFO: Batch: 30/31	Total Loss 59.4061 (61.4629)
2022-11-05 19:28:10,118:INFO: Batch: 31/31	Total Loss 59.1378 (61.4380)
2022-11-05 19:28:10,257:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(2, 2, 2, 2, 2)_shuffle_true_seed_72/pretrain/P5/CRMF_epoch_9.pth.tar
2022-11-05 19:28:10,257:INFO: 
===> EPOCH: 10 (P5)
2022-11-05 19:28:10,258:INFO: - Computing loss (training)
2022-11-05 19:28:10,699:INFO: Batch:  1/31	Total Loss 58.9795 (58.9795)
2022-11-05 19:28:10,709:INFO: Batch:  2/31	Total Loss 58.7653 (58.8731)
2022-11-05 19:28:10,718:INFO: Batch:  3/31	Total Loss 58.5813 (58.7762)
2022-11-05 19:28:10,725:INFO: Batch:  4/31	Total Loss 58.4278 (58.6910)
2022-11-05 19:28:10,729:INFO: Batch:  5/31	Total Loss 58.1952 (58.5918)
2022-11-05 19:28:10,734:INFO: Batch:  6/31	Total Loss 57.5883 (58.4077)
2022-11-05 19:28:10,740:INFO: Batch:  7/31	Total Loss 57.6045 (58.2996)
2022-11-05 19:28:10,746:INFO: Batch:  8/31	Total Loss 57.3323 (58.1847)
2022-11-05 19:28:10,752:INFO: Batch:  9/31	Total Loss 57.2294 (58.0856)
2022-11-05 19:28:10,760:INFO: Batch: 10/31	Total Loss 57.0701 (57.9688)
2022-11-05 19:28:10,766:INFO: Batch: 11/31	Total Loss 56.7852 (57.8636)
2022-11-05 19:28:10,773:INFO: Batch: 12/31	Total Loss 56.3206 (57.7437)
2022-11-05 19:28:10,780:INFO: Batch: 13/31	Total Loss 55.7097 (57.6012)
2022-11-05 19:28:10,787:INFO: Batch: 14/31	Total Loss 55.7790 (57.4699)
2022-11-05 19:28:10,794:INFO: Batch: 15/31	Total Loss 55.5348 (57.3419)
2022-11-05 19:28:10,801:INFO: Batch: 16/31	Total Loss 55.5110 (57.2375)
2022-11-05 19:28:10,808:INFO: Batch: 17/31	Total Loss 54.9308 (57.1106)
2022-11-05 19:28:10,815:INFO: Batch: 18/31	Total Loss 54.8348 (56.9842)
2022-11-05 19:28:10,822:INFO: Batch: 19/31	Total Loss 54.5504 (56.8527)
2022-11-05 19:28:10,829:INFO: Batch: 20/31	Total Loss 53.7615 (56.7022)
2022-11-05 19:28:10,836:INFO: Batch: 21/31	Total Loss 53.6580 (56.5566)
2022-11-05 19:28:10,843:INFO: Batch: 22/31	Total Loss 53.8081 (56.4377)
2022-11-05 19:28:10,850:INFO: Batch: 23/31	Total Loss 53.1186 (56.2940)
2022-11-05 19:28:10,857:INFO: Batch: 24/31	Total Loss 53.1393 (56.1615)
2022-11-05 19:28:10,863:INFO: Batch: 25/31	Total Loss 52.7758 (56.0311)
2022-11-05 19:28:10,870:INFO: Batch: 26/31	Total Loss 52.5245 (55.8859)
2022-11-05 19:28:10,877:INFO: Batch: 27/31	Total Loss 51.8074 (55.7644)
2022-11-05 19:28:10,883:INFO: Batch: 28/31	Total Loss 52.0398 (55.6465)
2022-11-05 19:28:10,890:INFO: Batch: 29/31	Total Loss 51.6754 (55.5214)
2022-11-05 19:28:10,896:INFO: Batch: 30/31	Total Loss 51.4109 (55.4019)
2022-11-05 19:28:10,902:INFO: Batch: 31/31	Total Loss 51.0069 (55.3540)
2022-11-05 19:28:11,045:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(2, 2, 2, 2, 2)_shuffle_true_seed_72/pretrain/P5/CRMF_epoch_10.pth.tar
