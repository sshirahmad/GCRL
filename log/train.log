2022-11-02 23:30:57,258:INFO: Initializing Training Set
2022-11-02 23:30:59,017:INFO: Initializing Validation Set
2022-11-02 23:30:59,213:INFO: Initializing Validation O Set
2022-11-02 23:31:01,278:INFO: 
===> EPOCH: 1 (P1)
2022-11-02 23:31:01,278:INFO: - Computing loss (training)
2022-11-02 23:31:02,028:INFO: Batch:  0/31	Total Loss 19.6156 (19.6156)
2022-11-02 23:31:02,081:INFO: Batch:  1/31	Total Loss 19.1726 (19.3843)
2022-11-02 23:31:02,134:INFO: Batch:  2/31	Total Loss 21.1097 (19.9100)
2022-11-02 23:31:02,187:INFO: Batch:  3/31	Total Loss 20.9964 (20.1986)
2022-11-02 23:31:02,240:INFO: Batch:  4/31	Total Loss 21.0796 (20.3738)
2022-11-02 23:31:02,292:INFO: Batch:  5/31	Total Loss 17.9269 (19.9943)
2022-11-02 23:31:02,343:INFO: Batch:  6/31	Total Loss 19.5085 (19.9274)
2022-11-02 23:31:02,393:INFO: Batch:  7/31	Total Loss 20.6817 (20.0150)
2022-11-02 23:31:02,440:INFO: Batch:  8/31	Total Loss 19.1444 (19.9198)
2022-11-02 23:31:02,490:INFO: Batch:  9/31	Total Loss 18.5295 (19.7808)
2022-11-02 23:31:02,539:INFO: Batch: 10/31	Total Loss 21.1891 (19.9066)
2022-11-02 23:31:02,585:INFO: Batch: 11/31	Total Loss 19.8111 (19.8993)
2022-11-02 23:31:02,634:INFO: Batch: 12/31	Total Loss 20.0471 (19.9089)
2022-11-02 23:31:02,687:INFO: Batch: 13/31	Total Loss 20.6687 (19.9574)
2022-11-02 23:31:02,737:INFO: Batch: 14/31	Total Loss 20.9668 (20.0241)
2022-11-02 23:31:02,787:INFO: Batch: 15/31	Total Loss 21.4864 (20.1053)
2022-11-02 23:31:02,836:INFO: Batch: 16/31	Total Loss 19.1697 (20.0421)
2022-11-02 23:31:02,886:INFO: Batch: 17/31	Total Loss 17.3307 (19.8856)
2022-11-02 23:31:02,941:INFO: Batch: 18/31	Total Loss 20.1318 (19.8974)
2022-11-02 23:31:02,992:INFO: Batch: 19/31	Total Loss 19.1933 (19.8643)
2022-11-02 23:31:03,041:INFO: Batch: 20/31	Total Loss 18.7755 (19.8120)
2022-11-02 23:31:03,092:INFO: Batch: 21/31	Total Loss 18.1004 (19.7378)
2022-11-02 23:31:03,143:INFO: Batch: 22/31	Total Loss 21.0309 (19.7901)
2022-11-02 23:31:03,193:INFO: Batch: 23/31	Total Loss 19.1171 (19.7654)
2022-11-02 23:31:03,243:INFO: Batch: 24/31	Total Loss 16.9507 (19.6502)
2022-11-02 23:31:03,291:INFO: Batch: 25/31	Total Loss 18.5019 (19.6052)
2022-11-02 23:31:03,340:INFO: Batch: 26/31	Total Loss 18.2636 (19.5526)
2022-11-02 23:31:03,393:INFO: Batch: 27/31	Total Loss 18.6778 (19.5229)
2022-11-02 23:31:03,442:INFO: Batch: 28/31	Total Loss 19.4909 (19.5218)
2022-11-02 23:31:03,493:INFO: Batch: 29/31	Total Loss 21.6061 (19.5914)
2022-11-02 23:31:03,523:INFO: Batch: 30/31	Total Loss 7.5985 (19.4834)
2022-11-02 23:31:03,666:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_1.pth.tar
2022-11-02 23:31:03,667:INFO: 
===> EPOCH: 2 (P1)
2022-11-02 23:31:03,667:INFO: - Computing loss (training)
2022-11-02 23:31:04,371:INFO: Batch:  0/31	Total Loss 20.5536 (20.5536)
2022-11-02 23:31:04,420:INFO: Batch:  1/31	Total Loss 17.5514 (18.9444)
2022-11-02 23:31:04,473:INFO: Batch:  2/31	Total Loss 18.2696 (18.7213)
2022-11-02 23:31:04,523:INFO: Batch:  3/31	Total Loss 18.3997 (18.6425)
2022-11-02 23:31:04,574:INFO: Batch:  4/31	Total Loss 19.6622 (18.8364)
2022-11-02 23:31:04,627:INFO: Batch:  5/31	Total Loss 18.6748 (18.8109)
2022-11-02 23:31:04,677:INFO: Batch:  6/31	Total Loss 14.9752 (18.1566)
2022-11-02 23:31:04,726:INFO: Batch:  7/31	Total Loss 17.8694 (18.1171)
2022-11-02 23:31:04,774:INFO: Batch:  8/31	Total Loss 16.4189 (17.9346)
2022-11-02 23:31:04,824:INFO: Batch:  9/31	Total Loss 19.8129 (18.0988)
2022-11-02 23:31:04,874:INFO: Batch: 10/31	Total Loss 17.5444 (18.0412)
2022-11-02 23:31:04,923:INFO: Batch: 11/31	Total Loss 15.7041 (17.8296)
2022-11-02 23:31:04,974:INFO: Batch: 12/31	Total Loss 15.7519 (17.6792)
2022-11-02 23:31:05,027:INFO: Batch: 13/31	Total Loss 16.3528 (17.5801)
2022-11-02 23:31:05,077:INFO: Batch: 14/31	Total Loss 16.2700 (17.4909)
2022-11-02 23:31:05,127:INFO: Batch: 15/31	Total Loss 15.9362 (17.4010)
2022-11-02 23:31:05,178:INFO: Batch: 16/31	Total Loss 16.4239 (17.3441)
2022-11-02 23:31:05,232:INFO: Batch: 17/31	Total Loss 17.4504 (17.3499)
2022-11-02 23:31:05,284:INFO: Batch: 18/31	Total Loss 15.6005 (17.2582)
2022-11-02 23:31:05,333:INFO: Batch: 19/31	Total Loss 16.4392 (17.2144)
2022-11-02 23:31:05,382:INFO: Batch: 20/31	Total Loss 17.1721 (17.2125)
2022-11-02 23:31:05,434:INFO: Batch: 21/31	Total Loss 16.4122 (17.1806)
2022-11-02 23:31:05,485:INFO: Batch: 22/31	Total Loss 16.3880 (17.1454)
2022-11-02 23:31:05,534:INFO: Batch: 23/31	Total Loss 16.5105 (17.1184)
2022-11-02 23:31:05,584:INFO: Batch: 24/31	Total Loss 16.5598 (17.0985)
2022-11-02 23:31:05,638:INFO: Batch: 25/31	Total Loss 16.9651 (17.0932)
2022-11-02 23:31:05,688:INFO: Batch: 26/31	Total Loss 13.2764 (16.9475)
2022-11-02 23:31:05,739:INFO: Batch: 27/31	Total Loss 14.1276 (16.8389)
2022-11-02 23:31:05,791:INFO: Batch: 28/31	Total Loss 15.0986 (16.7811)
2022-11-02 23:31:05,845:INFO: Batch: 29/31	Total Loss 13.6043 (16.6714)
2022-11-02 23:31:05,878:INFO: Batch: 30/31	Total Loss 5.8600 (16.5787)
2022-11-02 23:31:06,020:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_2.pth.tar
2022-11-02 23:31:06,020:INFO: 
===> EPOCH: 3 (P1)
2022-11-02 23:31:06,021:INFO: - Computing loss (training)
2022-11-02 23:31:06,693:INFO: Batch:  0/31	Total Loss 14.8576 (14.8576)
2022-11-02 23:31:06,745:INFO: Batch:  1/31	Total Loss 15.7032 (15.2799)
2022-11-02 23:31:06,800:INFO: Batch:  2/31	Total Loss 14.7106 (15.0787)
2022-11-02 23:31:06,851:INFO: Batch:  3/31	Total Loss 16.0605 (15.2732)
2022-11-02 23:31:06,902:INFO: Batch:  4/31	Total Loss 15.3363 (15.2866)
2022-11-02 23:31:06,956:INFO: Batch:  5/31	Total Loss 14.5717 (15.1630)
2022-11-02 23:31:07,008:INFO: Batch:  6/31	Total Loss 14.6474 (15.0783)
2022-11-02 23:31:07,058:INFO: Batch:  7/31	Total Loss 15.3956 (15.1122)
2022-11-02 23:31:07,107:INFO: Batch:  8/31	Total Loss 13.7721 (14.9523)
2022-11-02 23:31:07,160:INFO: Batch:  9/31	Total Loss 14.4485 (14.9079)
2022-11-02 23:31:07,209:INFO: Batch: 10/31	Total Loss 14.0242 (14.8228)
2022-11-02 23:31:07,258:INFO: Batch: 11/31	Total Loss 14.0083 (14.7580)
2022-11-02 23:31:07,308:INFO: Batch: 12/31	Total Loss 13.2452 (14.6413)
2022-11-02 23:31:07,360:INFO: Batch: 13/31	Total Loss 14.2304 (14.6075)
2022-11-02 23:31:07,411:INFO: Batch: 14/31	Total Loss 15.0249 (14.6343)
2022-11-02 23:31:07,462:INFO: Batch: 15/31	Total Loss 13.0131 (14.5147)
2022-11-02 23:31:07,512:INFO: Batch: 16/31	Total Loss 12.9296 (14.4224)
2022-11-02 23:31:07,565:INFO: Batch: 17/31	Total Loss 12.6966 (14.3237)
2022-11-02 23:31:07,617:INFO: Batch: 18/31	Total Loss 11.6794 (14.1759)
2022-11-02 23:31:07,667:INFO: Batch: 19/31	Total Loss 14.7113 (14.2025)
2022-11-02 23:31:07,721:INFO: Batch: 20/31	Total Loss 11.7551 (14.0828)
2022-11-02 23:31:07,773:INFO: Batch: 21/31	Total Loss 12.0578 (13.9959)
2022-11-02 23:31:07,824:INFO: Batch: 22/31	Total Loss 11.0480 (13.8532)
2022-11-02 23:31:07,874:INFO: Batch: 23/31	Total Loss 12.6457 (13.7960)
2022-11-02 23:31:07,924:INFO: Batch: 24/31	Total Loss 11.6657 (13.7111)
2022-11-02 23:31:07,976:INFO: Batch: 25/31	Total Loss 13.0959 (13.6861)
2022-11-02 23:31:08,027:INFO: Batch: 26/31	Total Loss 10.8758 (13.5861)
2022-11-02 23:31:08,077:INFO: Batch: 27/31	Total Loss 11.4559 (13.5068)
2022-11-02 23:31:08,128:INFO: Batch: 28/31	Total Loss 11.6064 (13.4345)
2022-11-02 23:31:08,181:INFO: Batch: 29/31	Total Loss 11.7962 (13.3770)
2022-11-02 23:31:08,213:INFO: Batch: 30/31	Total Loss 3.9738 (13.2945)
2022-11-02 23:31:08,369:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_3.pth.tar
2022-11-02 23:31:08,369:INFO: 
===> EPOCH: 4 (P1)
2022-11-02 23:31:08,370:INFO: - Computing loss (training)
2022-11-02 23:31:09,054:INFO: Batch:  0/31	Total Loss 11.8320 (11.8320)
2022-11-02 23:31:09,110:INFO: Batch:  1/31	Total Loss 11.8912 (11.8588)
2022-11-02 23:31:09,165:INFO: Batch:  2/31	Total Loss 11.8148 (11.8447)
2022-11-02 23:31:09,213:INFO: Batch:  3/31	Total Loss 11.7346 (11.8165)
2022-11-02 23:31:09,261:INFO: Batch:  4/31	Total Loss 11.4648 (11.7414)
2022-11-02 23:31:09,316:INFO: Batch:  5/31	Total Loss 10.6744 (11.5474)
2022-11-02 23:31:09,368:INFO: Batch:  6/31	Total Loss 10.4142 (11.3874)
2022-11-02 23:31:09,417:INFO: Batch:  7/31	Total Loss 10.5892 (11.2858)
2022-11-02 23:31:09,467:INFO: Batch:  8/31	Total Loss 9.6849 (11.1040)
2022-11-02 23:31:09,518:INFO: Batch:  9/31	Total Loss 11.0401 (11.0979)
2022-11-02 23:31:09,567:INFO: Batch: 10/31	Total Loss 10.2952 (11.0345)
2022-11-02 23:31:09,620:INFO: Batch: 11/31	Total Loss 11.2111 (11.0497)
2022-11-02 23:31:09,674:INFO: Batch: 12/31	Total Loss 10.7427 (11.0252)
2022-11-02 23:31:09,728:INFO: Batch: 13/31	Total Loss 10.2334 (10.9760)
2022-11-02 23:31:09,780:INFO: Batch: 14/31	Total Loss 9.6769 (10.8838)
2022-11-02 23:31:09,833:INFO: Batch: 15/31	Total Loss 9.9226 (10.8195)
2022-11-02 23:31:09,884:INFO: Batch: 16/31	Total Loss 9.5519 (10.7491)
2022-11-02 23:31:09,939:INFO: Batch: 17/31	Total Loss 10.2637 (10.7247)
2022-11-02 23:31:09,992:INFO: Batch: 18/31	Total Loss 9.4496 (10.6491)
2022-11-02 23:31:10,043:INFO: Batch: 19/31	Total Loss 10.4785 (10.6405)
2022-11-02 23:31:10,093:INFO: Batch: 20/31	Total Loss 8.8590 (10.5412)
2022-11-02 23:31:10,145:INFO: Batch: 21/31	Total Loss 9.8925 (10.5151)
2022-11-02 23:31:10,195:INFO: Batch: 22/31	Total Loss 8.8534 (10.4407)
2022-11-02 23:31:10,244:INFO: Batch: 23/31	Total Loss 9.3694 (10.3952)
2022-11-02 23:31:10,294:INFO: Batch: 24/31	Total Loss 9.4503 (10.3599)
2022-11-02 23:31:10,348:INFO: Batch: 25/31	Total Loss 8.8394 (10.3046)
2022-11-02 23:31:10,398:INFO: Batch: 26/31	Total Loss 9.3424 (10.2692)
2022-11-02 23:31:10,447:INFO: Batch: 27/31	Total Loss 8.5839 (10.2055)
2022-11-02 23:31:10,495:INFO: Batch: 28/31	Total Loss 8.5137 (10.1564)
2022-11-02 23:31:10,546:INFO: Batch: 29/31	Total Loss 7.9772 (10.0710)
2022-11-02 23:31:10,578:INFO: Batch: 30/31	Total Loss 3.7226 (10.0226)
2022-11-02 23:31:10,722:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_4.pth.tar
2022-11-02 23:31:10,722:INFO: 
===> EPOCH: 5 (P1)
2022-11-02 23:31:10,722:INFO: - Computing loss (training)
2022-11-02 23:31:11,387:INFO: Batch:  0/31	Total Loss 9.0988 (9.0988)
2022-11-02 23:31:11,436:INFO: Batch:  1/31	Total Loss 8.5036 (8.7703)
2022-11-02 23:31:11,491:INFO: Batch:  2/31	Total Loss 8.4426 (8.6497)
2022-11-02 23:31:11,542:INFO: Batch:  3/31	Total Loss 8.1160 (8.5167)
2022-11-02 23:31:11,592:INFO: Batch:  4/31	Total Loss 8.4385 (8.5013)
2022-11-02 23:31:11,643:INFO: Batch:  5/31	Total Loss 7.3176 (8.2958)
2022-11-02 23:31:11,690:INFO: Batch:  6/31	Total Loss 7.4920 (8.1780)
2022-11-02 23:31:11,737:INFO: Batch:  7/31	Total Loss 8.1254 (8.1721)
2022-11-02 23:31:11,785:INFO: Batch:  8/31	Total Loss 7.5426 (8.0957)
2022-11-02 23:31:11,834:INFO: Batch:  9/31	Total Loss 8.2646 (8.1131)
2022-11-02 23:31:11,885:INFO: Batch: 10/31	Total Loss 7.3645 (8.0405)
2022-11-02 23:31:11,935:INFO: Batch: 11/31	Total Loss 7.9813 (8.0360)
2022-11-02 23:31:11,985:INFO: Batch: 12/31	Total Loss 6.4207 (7.9048)
2022-11-02 23:31:12,037:INFO: Batch: 13/31	Total Loss 7.5872 (7.8794)
2022-11-02 23:31:12,089:INFO: Batch: 14/31	Total Loss 6.6880 (7.8015)
2022-11-02 23:31:12,140:INFO: Batch: 15/31	Total Loss 7.2855 (7.7735)
2022-11-02 23:31:12,189:INFO: Batch: 16/31	Total Loss 6.7485 (7.7148)
2022-11-02 23:31:12,238:INFO: Batch: 17/31	Total Loss 6.7621 (7.6668)
2022-11-02 23:31:12,290:INFO: Batch: 18/31	Total Loss 8.4887 (7.7078)
2022-11-02 23:31:12,340:INFO: Batch: 19/31	Total Loss 7.1076 (7.6787)
2022-11-02 23:31:12,389:INFO: Batch: 20/31	Total Loss 6.3941 (7.6216)
2022-11-02 23:31:12,438:INFO: Batch: 21/31	Total Loss 6.8519 (7.5872)
2022-11-02 23:31:12,490:INFO: Batch: 22/31	Total Loss 7.8892 (7.5989)
2022-11-02 23:31:12,540:INFO: Batch: 23/31	Total Loss 6.8516 (7.5681)
2022-11-02 23:31:12,588:INFO: Batch: 24/31	Total Loss 6.7425 (7.5357)
2022-11-02 23:31:12,637:INFO: Batch: 25/31	Total Loss 6.3256 (7.4833)
2022-11-02 23:31:12,686:INFO: Batch: 26/31	Total Loss 6.6753 (7.4497)
2022-11-02 23:31:12,736:INFO: Batch: 27/31	Total Loss 6.7046 (7.4226)
2022-11-02 23:31:12,787:INFO: Batch: 28/31	Total Loss 6.8142 (7.4012)
2022-11-02 23:31:12,837:INFO: Batch: 29/31	Total Loss 6.1676 (7.3610)
2022-11-02 23:31:12,869:INFO: Batch: 30/31	Total Loss 2.4603 (7.3189)
2022-11-02 23:31:13,021:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_5.pth.tar
2022-11-02 23:31:13,022:INFO: 
===> EPOCH: 6 (P1)
2022-11-02 23:31:13,022:INFO: - Computing loss (training)
2022-11-02 23:31:13,757:INFO: Batch:  0/31	Total Loss 7.0209 (7.0209)
2022-11-02 23:31:13,804:INFO: Batch:  1/31	Total Loss 6.2568 (6.6314)
2022-11-02 23:31:13,857:INFO: Batch:  2/31	Total Loss 6.4909 (6.5809)
2022-11-02 23:31:13,906:INFO: Batch:  3/31	Total Loss 6.0455 (6.4564)
2022-11-02 23:31:13,955:INFO: Batch:  4/31	Total Loss 6.8207 (6.5260)
2022-11-02 23:31:14,009:INFO: Batch:  5/31	Total Loss 5.7712 (6.3814)
2022-11-02 23:31:14,057:INFO: Batch:  6/31	Total Loss 5.4422 (6.2456)
2022-11-02 23:31:14,106:INFO: Batch:  7/31	Total Loss 6.5994 (6.2888)
2022-11-02 23:31:14,152:INFO: Batch:  8/31	Total Loss 5.2537 (6.1856)
2022-11-02 23:31:14,199:INFO: Batch:  9/31	Total Loss 6.4271 (6.2081)
2022-11-02 23:31:14,247:INFO: Batch: 10/31	Total Loss 5.7028 (6.1626)
2022-11-02 23:31:14,295:INFO: Batch: 11/31	Total Loss 5.4067 (6.1046)
2022-11-02 23:31:14,344:INFO: Batch: 12/31	Total Loss 5.3093 (6.0445)
2022-11-02 23:31:14,393:INFO: Batch: 13/31	Total Loss 5.4656 (6.0006)
2022-11-02 23:31:14,442:INFO: Batch: 14/31	Total Loss 5.8450 (5.9911)
2022-11-02 23:31:14,493:INFO: Batch: 15/31	Total Loss 5.7224 (5.9731)
2022-11-02 23:31:14,544:INFO: Batch: 16/31	Total Loss 6.1149 (5.9822)
2022-11-02 23:31:14,595:INFO: Batch: 17/31	Total Loss 5.5745 (5.9589)
2022-11-02 23:31:14,645:INFO: Batch: 18/31	Total Loss 5.4630 (5.9334)
2022-11-02 23:31:14,696:INFO: Batch: 19/31	Total Loss 5.4736 (5.9112)
2022-11-02 23:31:14,747:INFO: Batch: 20/31	Total Loss 5.4314 (5.8899)
2022-11-02 23:31:14,796:INFO: Batch: 21/31	Total Loss 5.1398 (5.8564)
2022-11-02 23:31:14,846:INFO: Batch: 22/31	Total Loss 5.3243 (5.8329)
2022-11-02 23:31:14,896:INFO: Batch: 23/31	Total Loss 5.8185 (5.8323)
2022-11-02 23:31:14,948:INFO: Batch: 24/31	Total Loss 5.2572 (5.8090)
2022-11-02 23:31:14,997:INFO: Batch: 25/31	Total Loss 5.2424 (5.7865)
2022-11-02 23:31:15,047:INFO: Batch: 26/31	Total Loss 5.3168 (5.7701)
2022-11-02 23:31:15,097:INFO: Batch: 27/31	Total Loss 4.9469 (5.7387)
2022-11-02 23:31:15,148:INFO: Batch: 28/31	Total Loss 5.6540 (5.7360)
2022-11-02 23:31:15,199:INFO: Batch: 29/31	Total Loss 5.2852 (5.7201)
2022-11-02 23:31:15,230:INFO: Batch: 30/31	Total Loss 2.0799 (5.6806)
2022-11-02 23:31:15,376:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_6.pth.tar
2022-11-02 23:31:15,376:INFO: 
===> EPOCH: 7 (P1)
2022-11-02 23:31:15,377:INFO: - Computing loss (training)
2022-11-02 23:31:16,034:INFO: Batch:  0/31	Total Loss 5.1143 (5.1143)
2022-11-02 23:31:16,081:INFO: Batch:  1/31	Total Loss 4.9126 (5.0256)
2022-11-02 23:31:16,136:INFO: Batch:  2/31	Total Loss 5.1759 (5.0775)
2022-11-02 23:31:16,183:INFO: Batch:  3/31	Total Loss 4.7947 (5.0079)
2022-11-02 23:31:16,231:INFO: Batch:  4/31	Total Loss 4.9977 (5.0059)
2022-11-02 23:31:16,286:INFO: Batch:  5/31	Total Loss 4.9564 (4.9979)
2022-11-02 23:31:16,337:INFO: Batch:  6/31	Total Loss 4.6687 (4.9510)
2022-11-02 23:31:16,411:INFO: Batch:  7/31	Total Loss 4.3487 (4.8626)
2022-11-02 23:31:16,465:INFO: Batch:  8/31	Total Loss 4.7853 (4.8541)
2022-11-02 23:31:16,518:INFO: Batch:  9/31	Total Loss 4.8800 (4.8565)
2022-11-02 23:31:16,574:INFO: Batch: 10/31	Total Loss 4.8845 (4.8590)
2022-11-02 23:31:16,632:INFO: Batch: 11/31	Total Loss 5.0506 (4.8738)
2022-11-02 23:31:16,690:INFO: Batch: 12/31	Total Loss 4.4827 (4.8443)
2022-11-02 23:31:16,750:INFO: Batch: 13/31	Total Loss 4.6587 (4.8327)
2022-11-02 23:31:16,808:INFO: Batch: 14/31	Total Loss 4.4683 (4.8085)
2022-11-02 23:31:16,862:INFO: Batch: 15/31	Total Loss 4.4966 (4.7902)
2022-11-02 23:31:16,913:INFO: Batch: 16/31	Total Loss 4.5970 (4.7789)
2022-11-02 23:31:16,965:INFO: Batch: 17/31	Total Loss 4.3755 (4.7541)
2022-11-02 23:31:17,017:INFO: Batch: 18/31	Total Loss 4.2734 (4.7266)
2022-11-02 23:31:17,067:INFO: Batch: 19/31	Total Loss 4.8324 (4.7322)
2022-11-02 23:31:17,116:INFO: Batch: 20/31	Total Loss 4.5338 (4.7220)
2022-11-02 23:31:17,166:INFO: Batch: 21/31	Total Loss 4.3827 (4.7065)
2022-11-02 23:31:17,218:INFO: Batch: 22/31	Total Loss 4.6391 (4.7035)
2022-11-02 23:31:17,270:INFO: Batch: 23/31	Total Loss 4.2767 (4.6862)
2022-11-02 23:31:17,320:INFO: Batch: 24/31	Total Loss 4.2324 (4.6676)
2022-11-02 23:31:17,370:INFO: Batch: 25/31	Total Loss 4.5647 (4.6639)
2022-11-02 23:31:17,421:INFO: Batch: 26/31	Total Loss 3.9280 (4.6356)
2022-11-02 23:31:17,472:INFO: Batch: 27/31	Total Loss 4.2191 (4.6198)
2022-11-02 23:31:17,521:INFO: Batch: 28/31	Total Loss 4.1756 (4.6053)
2022-11-02 23:31:17,572:INFO: Batch: 29/31	Total Loss 4.9086 (4.6141)
2022-11-02 23:31:17,606:INFO: Batch: 30/31	Total Loss 1.8063 (4.5925)
2022-11-02 23:31:17,755:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_7.pth.tar
2022-11-02 23:31:17,755:INFO: 
===> EPOCH: 8 (P1)
2022-11-02 23:31:17,756:INFO: - Computing loss (training)
2022-11-02 23:31:18,408:INFO: Batch:  0/31	Total Loss 4.6940 (4.6940)
2022-11-02 23:31:18,458:INFO: Batch:  1/31	Total Loss 4.2952 (4.5025)
2022-11-02 23:31:18,514:INFO: Batch:  2/31	Total Loss 4.5188 (4.5079)
2022-11-02 23:31:18,565:INFO: Batch:  3/31	Total Loss 4.2988 (4.4553)
2022-11-02 23:31:18,613:INFO: Batch:  4/31	Total Loss 3.9558 (4.3547)
2022-11-02 23:31:18,668:INFO: Batch:  5/31	Total Loss 3.9330 (4.2796)
2022-11-02 23:31:18,717:INFO: Batch:  6/31	Total Loss 3.8178 (4.2042)
2022-11-02 23:31:18,766:INFO: Batch:  7/31	Total Loss 3.7655 (4.1508)
2022-11-02 23:31:18,812:INFO: Batch:  8/31	Total Loss 3.6966 (4.1092)
2022-11-02 23:31:18,861:INFO: Batch:  9/31	Total Loss 3.6783 (4.0682)
2022-11-02 23:31:18,909:INFO: Batch: 10/31	Total Loss 5.0053 (4.1489)
2022-11-02 23:31:18,957:INFO: Batch: 11/31	Total Loss 4.1720 (4.1508)
2022-11-02 23:31:19,006:INFO: Batch: 12/31	Total Loss 3.4790 (4.0950)
2022-11-02 23:31:19,056:INFO: Batch: 13/31	Total Loss 3.7353 (4.0685)
2022-11-02 23:31:19,108:INFO: Batch: 14/31	Total Loss 3.7963 (4.0500)
2022-11-02 23:31:19,159:INFO: Batch: 15/31	Total Loss 4.0925 (4.0529)
2022-11-02 23:31:19,209:INFO: Batch: 16/31	Total Loss 3.7906 (4.0371)
2022-11-02 23:31:19,259:INFO: Batch: 17/31	Total Loss 3.4605 (4.0049)
2022-11-02 23:31:19,309:INFO: Batch: 18/31	Total Loss 3.4274 (3.9691)
2022-11-02 23:31:19,361:INFO: Batch: 19/31	Total Loss 3.8836 (3.9645)
2022-11-02 23:31:19,412:INFO: Batch: 20/31	Total Loss 3.7393 (3.9530)
2022-11-02 23:31:19,462:INFO: Batch: 21/31	Total Loss 3.6228 (3.9384)
2022-11-02 23:31:19,512:INFO: Batch: 22/31	Total Loss 3.7476 (3.9311)
2022-11-02 23:31:19,562:INFO: Batch: 23/31	Total Loss 3.7348 (3.9234)
2022-11-02 23:31:19,613:INFO: Batch: 24/31	Total Loss 3.8144 (3.9194)
2022-11-02 23:31:19,663:INFO: Batch: 25/31	Total Loss 3.6470 (3.9091)
2022-11-02 23:31:19,712:INFO: Batch: 26/31	Total Loss 3.5958 (3.8969)
2022-11-02 23:31:19,767:INFO: Batch: 27/31	Total Loss 3.4459 (3.8807)
2022-11-02 23:31:19,829:INFO: Batch: 28/31	Total Loss 3.7289 (3.8757)
2022-11-02 23:31:19,890:INFO: Batch: 29/31	Total Loss 3.1969 (3.8534)
2022-11-02 23:31:19,930:INFO: Batch: 30/31	Total Loss 1.4380 (3.8304)
2022-11-02 23:31:20,109:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_8.pth.tar
2022-11-02 23:31:20,109:INFO: 
===> EPOCH: 9 (P1)
2022-11-02 23:31:20,110:INFO: - Computing loss (training)
2022-11-02 23:31:20,810:INFO: Batch:  0/31	Total Loss 3.5575 (3.5575)
2022-11-02 23:31:20,877:INFO: Batch:  1/31	Total Loss 3.1194 (3.3441)
2022-11-02 23:31:20,947:INFO: Batch:  2/31	Total Loss 3.2859 (3.3233)
2022-11-02 23:31:21,009:INFO: Batch:  3/31	Total Loss 3.5191 (3.3769)
2022-11-02 23:31:21,069:INFO: Batch:  4/31	Total Loss 3.3043 (3.3628)
2022-11-02 23:31:21,128:INFO: Batch:  5/31	Total Loss 3.6026 (3.4037)
2022-11-02 23:31:21,176:INFO: Batch:  6/31	Total Loss 3.1844 (3.3700)
2022-11-02 23:31:21,227:INFO: Batch:  7/31	Total Loss 3.4184 (3.3752)
2022-11-02 23:31:21,277:INFO: Batch:  8/31	Total Loss 3.2987 (3.3654)
2022-11-02 23:31:21,325:INFO: Batch:  9/31	Total Loss 3.2220 (3.3493)
2022-11-02 23:31:21,373:INFO: Batch: 10/31	Total Loss 3.6160 (3.3711)
2022-11-02 23:31:21,422:INFO: Batch: 11/31	Total Loss 3.1510 (3.3532)
2022-11-02 23:31:21,472:INFO: Batch: 12/31	Total Loss 3.3085 (3.3497)
2022-11-02 23:31:21,524:INFO: Batch: 13/31	Total Loss 3.4483 (3.3559)
2022-11-02 23:31:21,575:INFO: Batch: 14/31	Total Loss 3.0237 (3.3362)
2022-11-02 23:31:21,630:INFO: Batch: 15/31	Total Loss 3.3083 (3.3342)
2022-11-02 23:31:21,686:INFO: Batch: 16/31	Total Loss 3.2800 (3.3310)
2022-11-02 23:31:21,743:INFO: Batch: 17/31	Total Loss 3.1640 (3.3209)
2022-11-02 23:31:21,796:INFO: Batch: 18/31	Total Loss 3.2173 (3.3159)
2022-11-02 23:31:21,847:INFO: Batch: 19/31	Total Loss 3.3194 (3.3161)
2022-11-02 23:31:21,903:INFO: Batch: 20/31	Total Loss 3.1492 (3.3073)
2022-11-02 23:31:21,960:INFO: Batch: 21/31	Total Loss 3.0871 (3.2973)
2022-11-02 23:31:22,013:INFO: Batch: 22/31	Total Loss 3.0236 (3.2855)
2022-11-02 23:31:22,067:INFO: Batch: 23/31	Total Loss 2.8911 (3.2670)
2022-11-02 23:31:22,127:INFO: Batch: 24/31	Total Loss 3.1920 (3.2638)
2022-11-02 23:31:22,193:INFO: Batch: 25/31	Total Loss 3.0643 (3.2558)
2022-11-02 23:31:22,261:INFO: Batch: 26/31	Total Loss 3.0176 (3.2475)
2022-11-02 23:31:22,328:INFO: Batch: 27/31	Total Loss 3.0443 (3.2394)
2022-11-02 23:31:22,396:INFO: Batch: 28/31	Total Loss 2.9131 (3.2283)
2022-11-02 23:31:22,462:INFO: Batch: 29/31	Total Loss 2.9680 (3.2194)
2022-11-02 23:31:22,506:INFO: Batch: 30/31	Total Loss 1.1458 (3.1967)
2022-11-02 23:31:22,685:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_9.pth.tar
2022-11-02 23:31:22,685:INFO: 
===> EPOCH: 10 (P1)
2022-11-02 23:31:22,685:INFO: - Computing loss (training)
2022-11-02 23:31:23,401:INFO: Batch:  0/31	Total Loss 3.0855 (3.0855)
2022-11-02 23:31:23,451:INFO: Batch:  1/31	Total Loss 2.8871 (2.9876)
2022-11-02 23:31:23,505:INFO: Batch:  2/31	Total Loss 3.0291 (3.0012)
2022-11-02 23:31:23,550:INFO: Batch:  3/31	Total Loss 2.9175 (2.9836)
2022-11-02 23:31:23,596:INFO: Batch:  4/31	Total Loss 2.8623 (2.9565)
2022-11-02 23:31:23,649:INFO: Batch:  5/31	Total Loss 2.8804 (2.9433)
2022-11-02 23:31:23,698:INFO: Batch:  6/31	Total Loss 3.0722 (2.9628)
2022-11-02 23:31:23,754:INFO: Batch:  7/31	Total Loss 3.0420 (2.9714)
2022-11-02 23:31:23,806:INFO: Batch:  8/31	Total Loss 2.9157 (2.9657)
2022-11-02 23:31:23,855:INFO: Batch:  9/31	Total Loss 2.8211 (2.9514)
2022-11-02 23:31:23,904:INFO: Batch: 10/31	Total Loss 3.2183 (2.9758)
2022-11-02 23:31:23,953:INFO: Batch: 11/31	Total Loss 2.8424 (2.9656)
2022-11-02 23:31:24,003:INFO: Batch: 12/31	Total Loss 2.7704 (2.9511)
2022-11-02 23:31:24,052:INFO: Batch: 13/31	Total Loss 3.0558 (2.9586)
2022-11-02 23:31:24,106:INFO: Batch: 14/31	Total Loss 2.9639 (2.9589)
2022-11-02 23:31:24,157:INFO: Batch: 15/31	Total Loss 2.9803 (2.9606)
2022-11-02 23:31:24,206:INFO: Batch: 16/31	Total Loss 2.7082 (2.9453)
2022-11-02 23:31:24,256:INFO: Batch: 17/31	Total Loss 2.8624 (2.9408)
2022-11-02 23:31:24,306:INFO: Batch: 18/31	Total Loss 2.7957 (2.9335)
2022-11-02 23:31:24,359:INFO: Batch: 19/31	Total Loss 2.9451 (2.9341)
2022-11-02 23:31:24,409:INFO: Batch: 20/31	Total Loss 2.8435 (2.9300)
2022-11-02 23:31:24,458:INFO: Batch: 21/31	Total Loss 2.8693 (2.9274)
2022-11-02 23:31:24,507:INFO: Batch: 22/31	Total Loss 2.6288 (2.9114)
2022-11-02 23:31:24,559:INFO: Batch: 23/31	Total Loss 2.6820 (2.9012)
2022-11-02 23:31:24,608:INFO: Batch: 24/31	Total Loss 2.6808 (2.8924)
2022-11-02 23:31:24,657:INFO: Batch: 25/31	Total Loss 2.8129 (2.8890)
2022-11-02 23:31:24,707:INFO: Batch: 26/31	Total Loss 2.6896 (2.8805)
2022-11-02 23:31:24,756:INFO: Batch: 27/31	Total Loss 2.7759 (2.8769)
2022-11-02 23:31:24,808:INFO: Batch: 28/31	Total Loss 2.8763 (2.8769)
2022-11-02 23:31:24,858:INFO: Batch: 29/31	Total Loss 2.7235 (2.8720)
2022-11-02 23:31:24,888:INFO: Batch: 30/31	Total Loss 0.9103 (2.8493)
2022-11-02 23:31:25,037:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_10.pth.tar
2022-11-02 23:31:25,038:INFO: 
===> EPOCH: 11 (P1)
2022-11-02 23:31:25,038:INFO: - Computing loss (training)
2022-11-02 23:31:25,720:INFO: Batch:  0/31	Total Loss 2.5853 (2.5853)
2022-11-02 23:31:25,775:INFO: Batch:  1/31	Total Loss 2.6629 (2.6250)
2022-11-02 23:31:25,825:INFO: Batch:  2/31	Total Loss 2.5740 (2.6093)
2022-11-02 23:31:25,874:INFO: Batch:  3/31	Total Loss 2.4729 (2.5758)
2022-11-02 23:31:25,922:INFO: Batch:  4/31	Total Loss 2.5971 (2.5804)
2022-11-02 23:31:25,975:INFO: Batch:  5/31	Total Loss 2.4638 (2.5618)
2022-11-02 23:31:26,022:INFO: Batch:  6/31	Total Loss 2.4506 (2.5458)
2022-11-02 23:31:26,070:INFO: Batch:  7/31	Total Loss 2.7791 (2.5720)
2022-11-02 23:31:26,116:INFO: Batch:  8/31	Total Loss 2.4341 (2.5569)
2022-11-02 23:31:26,167:INFO: Batch:  9/31	Total Loss 2.6027 (2.5612)
2022-11-02 23:31:26,215:INFO: Batch: 10/31	Total Loss 2.4768 (2.5537)
2022-11-02 23:31:26,262:INFO: Batch: 11/31	Total Loss 2.4724 (2.5474)
2022-11-02 23:31:26,310:INFO: Batch: 12/31	Total Loss 2.5455 (2.5473)
2022-11-02 23:31:26,360:INFO: Batch: 13/31	Total Loss 2.4610 (2.5408)
2022-11-02 23:31:26,413:INFO: Batch: 14/31	Total Loss 2.5031 (2.5385)
2022-11-02 23:31:26,463:INFO: Batch: 15/31	Total Loss 2.5138 (2.5371)
2022-11-02 23:31:26,512:INFO: Batch: 16/31	Total Loss 2.4507 (2.5320)
2022-11-02 23:31:26,561:INFO: Batch: 17/31	Total Loss 2.3637 (2.5218)
2022-11-02 23:31:26,610:INFO: Batch: 18/31	Total Loss 2.2411 (2.5082)
2022-11-02 23:31:26,662:INFO: Batch: 19/31	Total Loss 2.6081 (2.5131)
2022-11-02 23:31:26,711:INFO: Batch: 20/31	Total Loss 2.4671 (2.5111)
2022-11-02 23:31:26,760:INFO: Batch: 21/31	Total Loss 2.4470 (2.5081)
2022-11-02 23:31:26,808:INFO: Batch: 22/31	Total Loss 2.3449 (2.5019)
2022-11-02 23:31:26,857:INFO: Batch: 23/31	Total Loss 2.3688 (2.4962)
2022-11-02 23:31:26,909:INFO: Batch: 24/31	Total Loss 2.3383 (2.4899)
2022-11-02 23:31:26,959:INFO: Batch: 25/31	Total Loss 2.4513 (2.4883)
2022-11-02 23:31:27,008:INFO: Batch: 26/31	Total Loss 2.3902 (2.4847)
2022-11-02 23:31:27,056:INFO: Batch: 27/31	Total Loss 2.4719 (2.4842)
2022-11-02 23:31:27,105:INFO: Batch: 28/31	Total Loss 2.3431 (2.4786)
2022-11-02 23:31:27,157:INFO: Batch: 29/31	Total Loss 2.3358 (2.4740)
2022-11-02 23:31:27,188:INFO: Batch: 30/31	Total Loss 0.9355 (2.4567)
2022-11-02 23:31:27,331:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_11.pth.tar
2022-11-02 23:31:27,332:INFO: 
===> EPOCH: 12 (P1)
2022-11-02 23:31:27,332:INFO: - Computing loss (training)
2022-11-02 23:31:27,995:INFO: Batch:  0/31	Total Loss 2.4128 (2.4128)
2022-11-02 23:31:28,043:INFO: Batch:  1/31	Total Loss 2.4699 (2.4409)
2022-11-02 23:31:28,098:INFO: Batch:  2/31	Total Loss 2.2452 (2.3697)
2022-11-02 23:31:28,151:INFO: Batch:  3/31	Total Loss 2.3831 (2.3725)
2022-11-02 23:31:28,196:INFO: Batch:  4/31	Total Loss 2.1577 (2.3312)
2022-11-02 23:31:28,247:INFO: Batch:  5/31	Total Loss 2.2506 (2.3175)
2022-11-02 23:31:28,294:INFO: Batch:  6/31	Total Loss 2.2947 (2.3142)
2022-11-02 23:31:28,341:INFO: Batch:  7/31	Total Loss 2.3234 (2.3154)
2022-11-02 23:31:28,387:INFO: Batch:  8/31	Total Loss 2.3330 (2.3174)
2022-11-02 23:31:28,437:INFO: Batch:  9/31	Total Loss 2.2205 (2.3082)
2022-11-02 23:31:28,486:INFO: Batch: 10/31	Total Loss 2.2995 (2.3075)
2022-11-02 23:31:28,531:INFO: Batch: 11/31	Total Loss 2.2881 (2.3060)
2022-11-02 23:31:28,579:INFO: Batch: 12/31	Total Loss 2.1420 (2.2945)
2022-11-02 23:31:28,628:INFO: Batch: 13/31	Total Loss 2.3901 (2.3012)
2022-11-02 23:31:28,680:INFO: Batch: 14/31	Total Loss 2.4946 (2.3145)
2022-11-02 23:31:28,730:INFO: Batch: 15/31	Total Loss 2.0793 (2.2993)
2022-11-02 23:31:28,779:INFO: Batch: 16/31	Total Loss 2.2956 (2.2991)
2022-11-02 23:31:28,828:INFO: Batch: 17/31	Total Loss 2.1925 (2.2930)
2022-11-02 23:31:28,877:INFO: Batch: 18/31	Total Loss 2.1901 (2.2877)
2022-11-02 23:31:28,928:INFO: Batch: 19/31	Total Loss 2.1210 (2.2803)
2022-11-02 23:31:28,978:INFO: Batch: 20/31	Total Loss 2.1866 (2.2756)
2022-11-02 23:31:29,026:INFO: Batch: 21/31	Total Loss 2.1580 (2.2703)
2022-11-02 23:31:29,074:INFO: Batch: 22/31	Total Loss 2.3127 (2.2724)
2022-11-02 23:31:29,123:INFO: Batch: 23/31	Total Loss 2.2500 (2.2715)
2022-11-02 23:31:29,173:INFO: Batch: 24/31	Total Loss 2.0305 (2.2624)
2022-11-02 23:31:29,222:INFO: Batch: 25/31	Total Loss 2.1668 (2.2587)
2022-11-02 23:31:29,270:INFO: Batch: 26/31	Total Loss 2.1310 (2.2540)
2022-11-02 23:31:29,319:INFO: Batch: 27/31	Total Loss 2.1452 (2.2498)
2022-11-02 23:31:29,367:INFO: Batch: 28/31	Total Loss 2.2523 (2.2499)
2022-11-02 23:31:29,417:INFO: Batch: 29/31	Total Loss 2.1058 (2.2444)
2022-11-02 23:31:29,448:INFO: Batch: 30/31	Total Loss 0.9433 (2.2314)
2022-11-02 23:31:29,592:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_12.pth.tar
2022-11-02 23:31:29,592:INFO: 
===> EPOCH: 13 (P1)
2022-11-02 23:31:29,593:INFO: - Computing loss (training)
2022-11-02 23:31:30,290:INFO: Batch:  0/31	Total Loss 2.0330 (2.0330)
2022-11-02 23:31:30,341:INFO: Batch:  1/31	Total Loss 2.1417 (2.0848)
2022-11-02 23:31:30,394:INFO: Batch:  2/31	Total Loss 2.2143 (2.1241)
2022-11-02 23:31:30,441:INFO: Batch:  3/31	Total Loss 2.0520 (2.1065)
2022-11-02 23:31:30,487:INFO: Batch:  4/31	Total Loss 2.1939 (2.1237)
2022-11-02 23:31:30,542:INFO: Batch:  5/31	Total Loss 1.8922 (2.0829)
2022-11-02 23:31:30,590:INFO: Batch:  6/31	Total Loss 2.0595 (2.0794)
2022-11-02 23:31:30,638:INFO: Batch:  7/31	Total Loss 2.0628 (2.0770)
2022-11-02 23:31:30,684:INFO: Batch:  8/31	Total Loss 2.0810 (2.0774)
2022-11-02 23:31:30,730:INFO: Batch:  9/31	Total Loss 2.1462 (2.0843)
2022-11-02 23:31:30,779:INFO: Batch: 10/31	Total Loss 2.0679 (2.0828)
2022-11-02 23:31:30,829:INFO: Batch: 11/31	Total Loss 2.1281 (2.0869)
2022-11-02 23:31:30,877:INFO: Batch: 12/31	Total Loss 2.0447 (2.0832)
2022-11-02 23:31:30,927:INFO: Batch: 13/31	Total Loss 2.0787 (2.0828)
2022-11-02 23:31:30,976:INFO: Batch: 14/31	Total Loss 1.9650 (2.0748)
2022-11-02 23:31:31,030:INFO: Batch: 15/31	Total Loss 2.0377 (2.0725)
2022-11-02 23:31:31,080:INFO: Batch: 16/31	Total Loss 1.8845 (2.0609)
2022-11-02 23:31:31,129:INFO: Batch: 17/31	Total Loss 2.0537 (2.0605)
2022-11-02 23:31:31,178:INFO: Batch: 18/31	Total Loss 1.8893 (2.0504)
2022-11-02 23:31:31,226:INFO: Batch: 19/31	Total Loss 2.0542 (2.0506)
2022-11-02 23:31:31,278:INFO: Batch: 20/31	Total Loss 1.8608 (2.0415)
2022-11-02 23:31:31,327:INFO: Batch: 21/31	Total Loss 1.9356 (2.0368)
2022-11-02 23:31:31,376:INFO: Batch: 22/31	Total Loss 1.9935 (2.0350)
2022-11-02 23:31:31,424:INFO: Batch: 23/31	Total Loss 1.8550 (2.0270)
2022-11-02 23:31:31,472:INFO: Batch: 24/31	Total Loss 1.8856 (2.0210)
2022-11-02 23:31:31,523:INFO: Batch: 25/31	Total Loss 2.0035 (2.0204)
2022-11-02 23:31:31,572:INFO: Batch: 26/31	Total Loss 1.9722 (2.0188)
2022-11-02 23:31:31,620:INFO: Batch: 27/31	Total Loss 1.9781 (2.0173)
2022-11-02 23:31:31,669:INFO: Batch: 28/31	Total Loss 1.9506 (2.0150)
2022-11-02 23:31:31,717:INFO: Batch: 29/31	Total Loss 1.8662 (2.0099)
2022-11-02 23:31:31,748:INFO: Batch: 30/31	Total Loss 0.7754 (1.9997)
2022-11-02 23:31:31,901:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_13.pth.tar
2022-11-02 23:31:31,901:INFO: 
===> EPOCH: 14 (P1)
2022-11-02 23:31:31,901:INFO: - Computing loss (training)
2022-11-02 23:31:32,582:INFO: Batch:  0/31	Total Loss 2.0416 (2.0416)
2022-11-02 23:31:32,632:INFO: Batch:  1/31	Total Loss 1.8908 (1.9631)
2022-11-02 23:31:32,686:INFO: Batch:  2/31	Total Loss 1.8639 (1.9286)
2022-11-02 23:31:32,739:INFO: Batch:  3/31	Total Loss 1.9015 (1.9213)
2022-11-02 23:31:32,788:INFO: Batch:  4/31	Total Loss 1.8635 (1.9095)
2022-11-02 23:31:32,839:INFO: Batch:  5/31	Total Loss 1.9092 (1.9095)
2022-11-02 23:31:32,887:INFO: Batch:  6/31	Total Loss 1.9538 (1.9161)
2022-11-02 23:31:32,933:INFO: Batch:  7/31	Total Loss 1.7744 (1.8988)
2022-11-02 23:31:32,981:INFO: Batch:  8/31	Total Loss 1.9812 (1.9074)
2022-11-02 23:31:33,029:INFO: Batch:  9/31	Total Loss 1.8786 (1.9047)
2022-11-02 23:31:33,079:INFO: Batch: 10/31	Total Loss 1.8778 (1.9022)
2022-11-02 23:31:33,125:INFO: Batch: 11/31	Total Loss 1.7900 (1.8930)
2022-11-02 23:31:33,174:INFO: Batch: 12/31	Total Loss 1.8240 (1.8879)
2022-11-02 23:31:33,223:INFO: Batch: 13/31	Total Loss 1.7999 (1.8821)
2022-11-02 23:31:33,274:INFO: Batch: 14/31	Total Loss 1.8347 (1.8787)
2022-11-02 23:31:33,324:INFO: Batch: 15/31	Total Loss 1.8011 (1.8741)
2022-11-02 23:31:33,373:INFO: Batch: 16/31	Total Loss 1.8790 (1.8744)
2022-11-02 23:31:33,422:INFO: Batch: 17/31	Total Loss 2.0075 (1.8819)
2022-11-02 23:31:33,472:INFO: Batch: 18/31	Total Loss 2.0220 (1.8884)
2022-11-02 23:31:33,524:INFO: Batch: 19/31	Total Loss 1.8028 (1.8841)
2022-11-02 23:31:33,573:INFO: Batch: 20/31	Total Loss 1.7276 (1.8759)
2022-11-02 23:31:33,622:INFO: Batch: 21/31	Total Loss 1.7564 (1.8701)
2022-11-02 23:31:33,671:INFO: Batch: 22/31	Total Loss 1.8867 (1.8708)
2022-11-02 23:31:33,719:INFO: Batch: 23/31	Total Loss 1.8338 (1.8692)
2022-11-02 23:31:33,770:INFO: Batch: 24/31	Total Loss 1.9386 (1.8720)
2022-11-02 23:31:33,819:INFO: Batch: 25/31	Total Loss 1.7363 (1.8669)
2022-11-02 23:31:33,867:INFO: Batch: 26/31	Total Loss 1.8009 (1.8642)
2022-11-02 23:31:33,915:INFO: Batch: 27/31	Total Loss 1.7983 (1.8621)
2022-11-02 23:31:33,964:INFO: Batch: 28/31	Total Loss 1.7316 (1.8578)
2022-11-02 23:31:34,014:INFO: Batch: 29/31	Total Loss 1.6712 (1.8513)
2022-11-02 23:31:34,045:INFO: Batch: 30/31	Total Loss 0.7354 (1.8409)
2022-11-02 23:31:34,197:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_14.pth.tar
2022-11-02 23:31:34,197:INFO: 
===> EPOCH: 15 (P1)
2022-11-02 23:31:34,197:INFO: - Computing loss (training)
2022-11-02 23:31:34,869:INFO: Batch:  0/31	Total Loss 1.7747 (1.7747)
2022-11-02 23:31:34,921:INFO: Batch:  1/31	Total Loss 1.7522 (1.7632)
2022-11-02 23:31:34,973:INFO: Batch:  2/31	Total Loss 1.7151 (1.7469)
2022-11-02 23:31:35,023:INFO: Batch:  3/31	Total Loss 1.6745 (1.7272)
2022-11-02 23:31:35,075:INFO: Batch:  4/31	Total Loss 1.7619 (1.7343)
2022-11-02 23:31:35,125:INFO: Batch:  5/31	Total Loss 1.8553 (1.7534)
2022-11-02 23:31:35,172:INFO: Batch:  6/31	Total Loss 1.8939 (1.7729)
2022-11-02 23:31:35,218:INFO: Batch:  7/31	Total Loss 1.7084 (1.7658)
2022-11-02 23:31:35,266:INFO: Batch:  8/31	Total Loss 1.7954 (1.7691)
2022-11-02 23:31:35,315:INFO: Batch:  9/31	Total Loss 1.7439 (1.7667)
2022-11-02 23:31:35,364:INFO: Batch: 10/31	Total Loss 1.6949 (1.7607)
2022-11-02 23:31:35,411:INFO: Batch: 11/31	Total Loss 1.8352 (1.7667)
2022-11-02 23:31:35,460:INFO: Batch: 12/31	Total Loss 1.8758 (1.7760)
2022-11-02 23:31:35,511:INFO: Batch: 13/31	Total Loss 1.6814 (1.7697)
2022-11-02 23:31:35,564:INFO: Batch: 14/31	Total Loss 1.6059 (1.7604)
2022-11-02 23:31:35,616:INFO: Batch: 15/31	Total Loss 1.7144 (1.7575)
2022-11-02 23:31:35,666:INFO: Batch: 16/31	Total Loss 1.7339 (1.7560)
2022-11-02 23:31:35,717:INFO: Batch: 17/31	Total Loss 1.6724 (1.7512)
2022-11-02 23:31:35,768:INFO: Batch: 18/31	Total Loss 1.8722 (1.7576)
2022-11-02 23:31:35,820:INFO: Batch: 19/31	Total Loss 1.7311 (1.7563)
2022-11-02 23:31:35,871:INFO: Batch: 20/31	Total Loss 1.5212 (1.7444)
2022-11-02 23:31:35,922:INFO: Batch: 21/31	Total Loss 1.5322 (1.7337)
2022-11-02 23:31:35,972:INFO: Batch: 22/31	Total Loss 1.7168 (1.7329)
2022-11-02 23:31:36,025:INFO: Batch: 23/31	Total Loss 1.5987 (1.7265)
2022-11-02 23:31:36,075:INFO: Batch: 24/31	Total Loss 1.6049 (1.7218)
2022-11-02 23:31:36,125:INFO: Batch: 25/31	Total Loss 1.7436 (1.7227)
2022-11-02 23:31:36,175:INFO: Batch: 26/31	Total Loss 1.5927 (1.7176)
2022-11-02 23:31:36,227:INFO: Batch: 27/31	Total Loss 1.6535 (1.7152)
2022-11-02 23:31:36,278:INFO: Batch: 28/31	Total Loss 1.6757 (1.7140)
2022-11-02 23:31:36,328:INFO: Batch: 29/31	Total Loss 1.5557 (1.7089)
2022-11-02 23:31:36,359:INFO: Batch: 30/31	Total Loss 0.6052 (1.7000)
2022-11-02 23:31:36,514:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_15.pth.tar
2022-11-02 23:31:36,514:INFO: 
===> EPOCH: 16 (P1)
2022-11-02 23:31:36,515:INFO: - Computing loss (training)
2022-11-02 23:31:37,186:INFO: Batch:  0/31	Total Loss 1.6340 (1.6340)
2022-11-02 23:31:37,241:INFO: Batch:  1/31	Total Loss 1.6727 (1.6533)
2022-11-02 23:31:37,296:INFO: Batch:  2/31	Total Loss 1.6361 (1.6476)
2022-11-02 23:31:37,344:INFO: Batch:  3/31	Total Loss 1.7320 (1.6654)
2022-11-02 23:31:37,395:INFO: Batch:  4/31	Total Loss 1.6636 (1.6650)
2022-11-02 23:31:37,447:INFO: Batch:  5/31	Total Loss 1.6841 (1.6681)
2022-11-02 23:31:37,494:INFO: Batch:  6/31	Total Loss 1.3712 (1.6224)
2022-11-02 23:31:37,542:INFO: Batch:  7/31	Total Loss 1.5934 (1.6188)
2022-11-02 23:31:37,590:INFO: Batch:  8/31	Total Loss 1.4820 (1.6020)
2022-11-02 23:31:37,638:INFO: Batch:  9/31	Total Loss 1.5782 (1.5996)
2022-11-02 23:31:37,687:INFO: Batch: 10/31	Total Loss 1.6046 (1.6001)
2022-11-02 23:31:37,734:INFO: Batch: 11/31	Total Loss 1.5623 (1.5970)
2022-11-02 23:31:37,783:INFO: Batch: 12/31	Total Loss 1.5630 (1.5945)
2022-11-02 23:31:37,832:INFO: Batch: 13/31	Total Loss 1.5263 (1.5896)
2022-11-02 23:31:37,882:INFO: Batch: 14/31	Total Loss 1.5333 (1.5861)
2022-11-02 23:31:37,932:INFO: Batch: 15/31	Total Loss 1.5594 (1.5845)
2022-11-02 23:31:37,981:INFO: Batch: 16/31	Total Loss 1.4272 (1.5741)
2022-11-02 23:31:38,030:INFO: Batch: 17/31	Total Loss 1.4807 (1.5686)
2022-11-02 23:31:38,079:INFO: Batch: 18/31	Total Loss 1.4841 (1.5638)
2022-11-02 23:31:38,132:INFO: Batch: 19/31	Total Loss 1.5034 (1.5606)
2022-11-02 23:31:38,181:INFO: Batch: 20/31	Total Loss 1.4474 (1.5553)
2022-11-02 23:31:38,229:INFO: Batch: 21/31	Total Loss 1.4449 (1.5497)
2022-11-02 23:31:38,278:INFO: Batch: 22/31	Total Loss 1.6399 (1.5539)
2022-11-02 23:31:38,327:INFO: Batch: 23/31	Total Loss 1.4185 (1.5485)
2022-11-02 23:31:38,379:INFO: Batch: 24/31	Total Loss 1.5145 (1.5472)
2022-11-02 23:31:38,428:INFO: Batch: 25/31	Total Loss 1.5321 (1.5466)
2022-11-02 23:31:38,477:INFO: Batch: 26/31	Total Loss 1.5977 (1.5484)
2022-11-02 23:31:38,526:INFO: Batch: 27/31	Total Loss 1.4932 (1.5464)
2022-11-02 23:31:38,575:INFO: Batch: 28/31	Total Loss 1.5117 (1.5451)
2022-11-02 23:31:38,627:INFO: Batch: 29/31	Total Loss 1.5092 (1.5439)
2022-11-02 23:31:38,657:INFO: Batch: 30/31	Total Loss 0.5790 (1.5342)
2022-11-02 23:31:38,820:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_16.pth.tar
2022-11-02 23:31:38,820:INFO: 
===> EPOCH: 17 (P1)
2022-11-02 23:31:38,821:INFO: - Computing loss (training)
2022-11-02 23:31:39,526:INFO: Batch:  0/31	Total Loss 1.4145 (1.4145)
2022-11-02 23:31:39,575:INFO: Batch:  1/31	Total Loss 1.4733 (1.4436)
2022-11-02 23:31:39,626:INFO: Batch:  2/31	Total Loss 1.5350 (1.4777)
2022-11-02 23:31:39,682:INFO: Batch:  3/31	Total Loss 1.3912 (1.4557)
2022-11-02 23:31:39,731:INFO: Batch:  4/31	Total Loss 1.4711 (1.4591)
2022-11-02 23:31:39,782:INFO: Batch:  5/31	Total Loss 1.5446 (1.4721)
2022-11-02 23:31:39,831:INFO: Batch:  6/31	Total Loss 1.3742 (1.4572)
2022-11-02 23:31:39,878:INFO: Batch:  7/31	Total Loss 1.4890 (1.4609)
2022-11-02 23:31:39,925:INFO: Batch:  8/31	Total Loss 1.4207 (1.4566)
2022-11-02 23:31:39,976:INFO: Batch:  9/31	Total Loss 1.5019 (1.4609)
2022-11-02 23:31:40,023:INFO: Batch: 10/31	Total Loss 1.4401 (1.4588)
2022-11-02 23:31:40,070:INFO: Batch: 11/31	Total Loss 1.4453 (1.4577)
2022-11-02 23:31:40,121:INFO: Batch: 12/31	Total Loss 1.4438 (1.4567)
2022-11-02 23:31:40,170:INFO: Batch: 13/31	Total Loss 1.4912 (1.4592)
2022-11-02 23:31:40,223:INFO: Batch: 14/31	Total Loss 1.3859 (1.4542)
2022-11-02 23:31:40,274:INFO: Batch: 15/31	Total Loss 1.5026 (1.4572)
2022-11-02 23:31:40,324:INFO: Batch: 16/31	Total Loss 1.3845 (1.4529)
2022-11-02 23:31:40,375:INFO: Batch: 17/31	Total Loss 1.4633 (1.4535)
2022-11-02 23:31:40,424:INFO: Batch: 18/31	Total Loss 1.4569 (1.4537)
2022-11-02 23:31:40,476:INFO: Batch: 19/31	Total Loss 1.4632 (1.4542)
2022-11-02 23:31:40,526:INFO: Batch: 20/31	Total Loss 1.6315 (1.4613)
2022-11-02 23:31:40,575:INFO: Batch: 21/31	Total Loss 1.4950 (1.4628)
2022-11-02 23:31:40,623:INFO: Batch: 22/31	Total Loss 1.3948 (1.4600)
2022-11-02 23:31:40,676:INFO: Batch: 23/31	Total Loss 1.4538 (1.4598)
2022-11-02 23:31:40,726:INFO: Batch: 24/31	Total Loss 1.4886 (1.4610)
2022-11-02 23:31:40,774:INFO: Batch: 25/31	Total Loss 1.4344 (1.4599)
2022-11-02 23:31:40,823:INFO: Batch: 26/31	Total Loss 1.3560 (1.4562)
2022-11-02 23:31:40,872:INFO: Batch: 27/31	Total Loss 1.3088 (1.4509)
2022-11-02 23:31:40,926:INFO: Batch: 28/31	Total Loss 1.2478 (1.4437)
2022-11-02 23:31:40,975:INFO: Batch: 29/31	Total Loss 1.4212 (1.4429)
2022-11-02 23:31:41,005:INFO: Batch: 30/31	Total Loss 0.6491 (1.4362)
2022-11-02 23:31:41,153:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_17.pth.tar
2022-11-02 23:31:41,153:INFO: 
===> EPOCH: 18 (P1)
2022-11-02 23:31:41,154:INFO: - Computing loss (training)
2022-11-02 23:31:41,844:INFO: Batch:  0/31	Total Loss 1.3261 (1.3261)
2022-11-02 23:31:41,893:INFO: Batch:  1/31	Total Loss 1.2945 (1.3104)
2022-11-02 23:31:41,948:INFO: Batch:  2/31	Total Loss 1.4276 (1.3495)
2022-11-02 23:31:41,995:INFO: Batch:  3/31	Total Loss 1.4796 (1.3832)
2022-11-02 23:31:42,043:INFO: Batch:  4/31	Total Loss 1.3348 (1.3734)
2022-11-02 23:31:42,097:INFO: Batch:  5/31	Total Loss 1.2939 (1.3610)
2022-11-02 23:31:42,145:INFO: Batch:  6/31	Total Loss 1.3638 (1.3614)
2022-11-02 23:31:42,192:INFO: Batch:  7/31	Total Loss 1.3504 (1.3599)
2022-11-02 23:31:42,239:INFO: Batch:  8/31	Total Loss 1.2975 (1.3527)
2022-11-02 23:31:42,288:INFO: Batch:  9/31	Total Loss 1.3313 (1.3506)
2022-11-02 23:31:42,337:INFO: Batch: 10/31	Total Loss 1.3414 (1.3498)
2022-11-02 23:31:42,385:INFO: Batch: 11/31	Total Loss 1.2729 (1.3438)
2022-11-02 23:31:42,434:INFO: Batch: 12/31	Total Loss 1.3352 (1.3431)
2022-11-02 23:31:42,483:INFO: Batch: 13/31	Total Loss 1.1969 (1.3325)
2022-11-02 23:31:42,534:INFO: Batch: 14/31	Total Loss 1.4832 (1.3414)
2022-11-02 23:31:42,585:INFO: Batch: 15/31	Total Loss 1.3427 (1.3415)
2022-11-02 23:31:42,635:INFO: Batch: 16/31	Total Loss 1.2778 (1.3373)
2022-11-02 23:31:42,763:INFO: Batch: 17/31	Total Loss 1.3661 (1.3389)
2022-11-02 23:31:42,814:INFO: Batch: 18/31	Total Loss 1.3611 (1.3400)
2022-11-02 23:31:42,864:INFO: Batch: 19/31	Total Loss 1.2748 (1.3366)
2022-11-02 23:31:42,913:INFO: Batch: 20/31	Total Loss 1.2826 (1.3340)
2022-11-02 23:31:42,962:INFO: Batch: 21/31	Total Loss 1.2937 (1.3321)
2022-11-02 23:31:43,014:INFO: Batch: 22/31	Total Loss 1.2694 (1.3292)
2022-11-02 23:31:43,063:INFO: Batch: 23/31	Total Loss 1.2655 (1.3265)
2022-11-02 23:31:43,112:INFO: Batch: 24/31	Total Loss 1.1797 (1.3203)
2022-11-02 23:31:43,162:INFO: Batch: 25/31	Total Loss 1.3197 (1.3203)
2022-11-02 23:31:43,211:INFO: Batch: 26/31	Total Loss 1.1839 (1.3150)
2022-11-02 23:31:43,262:INFO: Batch: 27/31	Total Loss 1.2557 (1.3129)
2022-11-02 23:31:43,312:INFO: Batch: 28/31	Total Loss 1.2429 (1.3107)
2022-11-02 23:31:43,361:INFO: Batch: 29/31	Total Loss 1.2704 (1.3092)
2022-11-02 23:31:43,391:INFO: Batch: 30/31	Total Loss 0.5330 (1.3028)
2022-11-02 23:31:43,541:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_18.pth.tar
2022-11-02 23:31:43,541:INFO: 
===> EPOCH: 19 (P1)
2022-11-02 23:31:43,542:INFO: - Computing loss (training)
2022-11-02 23:31:44,193:INFO: Batch:  0/31	Total Loss 1.3188 (1.3188)
2022-11-02 23:31:44,249:INFO: Batch:  1/31	Total Loss 1.2685 (1.2928)
2022-11-02 23:31:44,304:INFO: Batch:  2/31	Total Loss 1.1680 (1.2540)
2022-11-02 23:31:44,353:INFO: Batch:  3/31	Total Loss 1.2027 (1.2403)
2022-11-02 23:31:44,405:INFO: Batch:  4/31	Total Loss 1.2615 (1.2448)
2022-11-02 23:31:44,459:INFO: Batch:  5/31	Total Loss 1.3617 (1.2639)
2022-11-02 23:31:44,506:INFO: Batch:  6/31	Total Loss 1.3266 (1.2728)
2022-11-02 23:31:44,553:INFO: Batch:  7/31	Total Loss 1.2962 (1.2760)
2022-11-02 23:31:44,600:INFO: Batch:  8/31	Total Loss 1.2803 (1.2765)
2022-11-02 23:31:44,650:INFO: Batch:  9/31	Total Loss 1.1981 (1.2687)
2022-11-02 23:31:44,698:INFO: Batch: 10/31	Total Loss 1.2384 (1.2661)
2022-11-02 23:31:44,746:INFO: Batch: 11/31	Total Loss 1.3182 (1.2705)
2022-11-02 23:31:44,794:INFO: Batch: 12/31	Total Loss 1.2117 (1.2660)
2022-11-02 23:31:44,843:INFO: Batch: 13/31	Total Loss 1.1430 (1.2563)
2022-11-02 23:31:44,897:INFO: Batch: 14/31	Total Loss 1.2716 (1.2575)
2022-11-02 23:31:44,947:INFO: Batch: 15/31	Total Loss 1.2921 (1.2595)
2022-11-02 23:31:44,996:INFO: Batch: 16/31	Total Loss 1.2618 (1.2597)
2022-11-02 23:31:45,046:INFO: Batch: 17/31	Total Loss 1.2477 (1.2590)
2022-11-02 23:31:45,094:INFO: Batch: 18/31	Total Loss 1.2547 (1.2588)
2022-11-02 23:31:45,147:INFO: Batch: 19/31	Total Loss 1.3407 (1.2633)
2022-11-02 23:31:45,196:INFO: Batch: 20/31	Total Loss 1.1326 (1.2579)
2022-11-02 23:31:45,246:INFO: Batch: 21/31	Total Loss 1.2188 (1.2560)
2022-11-02 23:31:45,295:INFO: Batch: 22/31	Total Loss 1.2529 (1.2558)
2022-11-02 23:31:45,344:INFO: Batch: 23/31	Total Loss 1.1546 (1.2520)
2022-11-02 23:31:45,397:INFO: Batch: 24/31	Total Loss 1.1224 (1.2461)
2022-11-02 23:31:45,446:INFO: Batch: 25/31	Total Loss 1.2696 (1.2469)
2022-11-02 23:31:45,496:INFO: Batch: 26/31	Total Loss 1.1360 (1.2418)
2022-11-02 23:31:45,544:INFO: Batch: 27/31	Total Loss 1.1852 (1.2396)
2022-11-02 23:31:45,593:INFO: Batch: 28/31	Total Loss 1.2494 (1.2399)
2022-11-02 23:31:45,646:INFO: Batch: 29/31	Total Loss 1.2402 (1.2400)
2022-11-02 23:31:45,677:INFO: Batch: 30/31	Total Loss 0.4938 (1.2331)
2022-11-02 23:31:45,831:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_19.pth.tar
2022-11-02 23:31:45,831:INFO: 
===> EPOCH: 20 (P1)
2022-11-02 23:31:45,832:INFO: - Computing loss (training)
2022-11-02 23:31:46,515:INFO: Batch:  0/31	Total Loss 1.1525 (1.1525)
2022-11-02 23:31:46,566:INFO: Batch:  1/31	Total Loss 1.1240 (1.1378)
2022-11-02 23:31:46,622:INFO: Batch:  2/31	Total Loss 1.1871 (1.1540)
2022-11-02 23:31:46,676:INFO: Batch:  3/31	Total Loss 1.1795 (1.1601)
2022-11-02 23:31:46,727:INFO: Batch:  4/31	Total Loss 1.1569 (1.1595)
2022-11-02 23:31:46,782:INFO: Batch:  5/31	Total Loss 1.2089 (1.1675)
2022-11-02 23:31:46,831:INFO: Batch:  6/31	Total Loss 1.1601 (1.1665)
2022-11-02 23:31:46,879:INFO: Batch:  7/31	Total Loss 1.1522 (1.1645)
2022-11-02 23:31:46,927:INFO: Batch:  8/31	Total Loss 1.1308 (1.1609)
2022-11-02 23:31:46,977:INFO: Batch:  9/31	Total Loss 1.1674 (1.1615)
2022-11-02 23:31:47,025:INFO: Batch: 10/31	Total Loss 1.1814 (1.1632)
2022-11-02 23:31:47,074:INFO: Batch: 11/31	Total Loss 1.0986 (1.1579)
2022-11-02 23:31:47,124:INFO: Batch: 12/31	Total Loss 1.1234 (1.1551)
2022-11-02 23:31:47,174:INFO: Batch: 13/31	Total Loss 1.1953 (1.1579)
2022-11-02 23:31:47,226:INFO: Batch: 14/31	Total Loss 1.1926 (1.1600)
2022-11-02 23:31:47,277:INFO: Batch: 15/31	Total Loss 1.0729 (1.1544)
2022-11-02 23:31:47,328:INFO: Batch: 16/31	Total Loss 1.1839 (1.1561)
2022-11-02 23:31:47,379:INFO: Batch: 17/31	Total Loss 1.1585 (1.1562)
2022-11-02 23:31:47,430:INFO: Batch: 18/31	Total Loss 1.0915 (1.1525)
2022-11-02 23:31:47,483:INFO: Batch: 19/31	Total Loss 1.0986 (1.1496)
2022-11-02 23:31:47,534:INFO: Batch: 20/31	Total Loss 1.1321 (1.1488)
2022-11-02 23:31:47,584:INFO: Batch: 21/31	Total Loss 1.0704 (1.1453)
2022-11-02 23:31:47,635:INFO: Batch: 22/31	Total Loss 1.1339 (1.1448)
2022-11-02 23:31:47,685:INFO: Batch: 23/31	Total Loss 1.1071 (1.1433)
2022-11-02 23:31:47,735:INFO: Batch: 24/31	Total Loss 1.0901 (1.1411)
2022-11-02 23:31:47,784:INFO: Batch: 25/31	Total Loss 1.1334 (1.1408)
2022-11-02 23:31:47,834:INFO: Batch: 26/31	Total Loss 1.1035 (1.1396)
2022-11-02 23:31:47,886:INFO: Batch: 27/31	Total Loss 1.1151 (1.1387)
2022-11-02 23:31:47,936:INFO: Batch: 28/31	Total Loss 1.1201 (1.1382)
2022-11-02 23:31:47,986:INFO: Batch: 29/31	Total Loss 1.0971 (1.1368)
2022-11-02 23:31:48,017:INFO: Batch: 30/31	Total Loss 0.4361 (1.1308)
2022-11-02 23:31:48,169:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_20.pth.tar
2022-11-02 23:31:48,169:INFO: 
===> EPOCH: 21 (P1)
2022-11-02 23:31:48,169:INFO: - Computing loss (training)
2022-11-02 23:31:48,825:INFO: Batch:  0/31	Total Loss 1.0718 (1.0718)
2022-11-02 23:31:48,877:INFO: Batch:  1/31	Total Loss 1.0253 (1.0483)
2022-11-02 23:31:48,932:INFO: Batch:  2/31	Total Loss 1.1336 (1.0782)
2022-11-02 23:31:48,982:INFO: Batch:  3/31	Total Loss 1.1248 (1.0906)
2022-11-02 23:31:49,032:INFO: Batch:  4/31	Total Loss 1.1520 (1.1016)
2022-11-02 23:31:49,085:INFO: Batch:  5/31	Total Loss 1.1446 (1.1082)
2022-11-02 23:31:49,134:INFO: Batch:  6/31	Total Loss 1.1385 (1.1122)
2022-11-02 23:31:49,181:INFO: Batch:  7/31	Total Loss 1.0775 (1.1077)
2022-11-02 23:31:49,229:INFO: Batch:  8/31	Total Loss 1.0430 (1.1005)
2022-11-02 23:31:49,278:INFO: Batch:  9/31	Total Loss 1.1289 (1.1031)
2022-11-02 23:31:49,328:INFO: Batch: 10/31	Total Loss 1.0362 (1.0965)
2022-11-02 23:31:49,376:INFO: Batch: 11/31	Total Loss 1.1198 (1.0987)
2022-11-02 23:31:49,425:INFO: Batch: 12/31	Total Loss 1.0200 (1.0921)
2022-11-02 23:31:49,475:INFO: Batch: 13/31	Total Loss 1.1309 (1.0945)
2022-11-02 23:31:49,526:INFO: Batch: 14/31	Total Loss 1.0482 (1.0914)
2022-11-02 23:31:49,576:INFO: Batch: 15/31	Total Loss 1.0641 (1.0897)
2022-11-02 23:31:49,626:INFO: Batch: 16/31	Total Loss 1.0403 (1.0868)
2022-11-02 23:31:49,675:INFO: Batch: 17/31	Total Loss 0.9898 (1.0820)
2022-11-02 23:31:49,724:INFO: Batch: 18/31	Total Loss 1.0239 (1.0789)
2022-11-02 23:31:49,775:INFO: Batch: 19/31	Total Loss 1.0320 (1.0764)
2022-11-02 23:31:49,824:INFO: Batch: 20/31	Total Loss 1.0817 (1.0767)
2022-11-02 23:31:49,873:INFO: Batch: 21/31	Total Loss 1.0679 (1.0763)
2022-11-02 23:31:49,922:INFO: Batch: 22/31	Total Loss 1.0278 (1.0744)
2022-11-02 23:31:49,971:INFO: Batch: 23/31	Total Loss 1.0302 (1.0725)
2022-11-02 23:31:50,022:INFO: Batch: 24/31	Total Loss 1.0435 (1.0713)
2022-11-02 23:31:50,072:INFO: Batch: 25/31	Total Loss 0.9947 (1.0686)
2022-11-02 23:31:50,119:INFO: Batch: 26/31	Total Loss 1.0176 (1.0667)
2022-11-02 23:31:50,168:INFO: Batch: 27/31	Total Loss 1.0343 (1.0656)
2022-11-02 23:31:50,217:INFO: Batch: 28/31	Total Loss 1.0322 (1.0644)
2022-11-02 23:31:50,268:INFO: Batch: 29/31	Total Loss 1.0114 (1.0625)
2022-11-02 23:31:50,299:INFO: Batch: 30/31	Total Loss 0.4244 (1.0566)
2022-11-02 23:31:50,453:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_21.pth.tar
2022-11-02 23:31:50,453:INFO: 
===> EPOCH: 22 (P1)
2022-11-02 23:31:50,453:INFO: - Computing loss (training)
2022-11-02 23:31:51,095:INFO: Batch:  0/31	Total Loss 1.0281 (1.0281)
2022-11-02 23:31:51,151:INFO: Batch:  1/31	Total Loss 0.9755 (1.0029)
2022-11-02 23:31:51,205:INFO: Batch:  2/31	Total Loss 1.0245 (1.0107)
2022-11-02 23:31:51,252:INFO: Batch:  3/31	Total Loss 1.0262 (1.0147)
2022-11-02 23:31:51,298:INFO: Batch:  4/31	Total Loss 1.0057 (1.0128)
2022-11-02 23:31:51,352:INFO: Batch:  5/31	Total Loss 0.9640 (1.0047)
2022-11-02 23:31:51,400:INFO: Batch:  6/31	Total Loss 0.9321 (0.9945)
2022-11-02 23:31:51,446:INFO: Batch:  7/31	Total Loss 0.9793 (0.9926)
2022-11-02 23:31:51,494:INFO: Batch:  8/31	Total Loss 1.0419 (0.9985)
2022-11-02 23:31:51,542:INFO: Batch:  9/31	Total Loss 1.0096 (0.9995)
2022-11-02 23:31:51,589:INFO: Batch: 10/31	Total Loss 0.9904 (0.9987)
2022-11-02 23:31:51,637:INFO: Batch: 11/31	Total Loss 1.0029 (0.9990)
2022-11-02 23:31:51,686:INFO: Batch: 12/31	Total Loss 1.0221 (1.0007)
2022-11-02 23:31:51,735:INFO: Batch: 13/31	Total Loss 0.9888 (0.9999)
2022-11-02 23:31:51,791:INFO: Batch: 14/31	Total Loss 1.0198 (1.0013)
2022-11-02 23:31:51,844:INFO: Batch: 15/31	Total Loss 0.9616 (0.9989)
2022-11-02 23:31:51,894:INFO: Batch: 16/31	Total Loss 1.0353 (1.0010)
2022-11-02 23:31:51,946:INFO: Batch: 17/31	Total Loss 0.9711 (0.9994)
2022-11-02 23:31:51,995:INFO: Batch: 18/31	Total Loss 0.9720 (0.9980)
2022-11-02 23:31:52,047:INFO: Batch: 19/31	Total Loss 1.0184 (0.9990)
2022-11-02 23:31:52,097:INFO: Batch: 20/31	Total Loss 0.9990 (0.9990)
2022-11-02 23:31:52,146:INFO: Batch: 21/31	Total Loss 0.9732 (0.9979)
2022-11-02 23:31:52,196:INFO: Batch: 22/31	Total Loss 0.9250 (0.9944)
2022-11-02 23:31:52,248:INFO: Batch: 23/31	Total Loss 0.9462 (0.9926)
2022-11-02 23:31:52,298:INFO: Batch: 24/31	Total Loss 0.9911 (0.9925)
2022-11-02 23:31:52,347:INFO: Batch: 25/31	Total Loss 0.9680 (0.9916)
2022-11-02 23:31:52,396:INFO: Batch: 26/31	Total Loss 0.9746 (0.9910)
2022-11-02 23:31:52,448:INFO: Batch: 27/31	Total Loss 1.0274 (0.9923)
2022-11-02 23:31:52,496:INFO: Batch: 28/31	Total Loss 1.0153 (0.9929)
2022-11-02 23:31:52,545:INFO: Batch: 29/31	Total Loss 0.9855 (0.9927)
2022-11-02 23:31:52,574:INFO: Batch: 30/31	Total Loss 0.3573 (0.9863)
2022-11-02 23:31:52,724:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_22.pth.tar
2022-11-02 23:31:52,724:INFO: 
===> EPOCH: 23 (P1)
2022-11-02 23:31:52,725:INFO: - Computing loss (training)
2022-11-02 23:31:53,381:INFO: Batch:  0/31	Total Loss 0.9695 (0.9695)
2022-11-02 23:31:53,437:INFO: Batch:  1/31	Total Loss 0.9734 (0.9714)
2022-11-02 23:31:53,489:INFO: Batch:  2/31	Total Loss 0.9265 (0.9561)
2022-11-02 23:31:53,539:INFO: Batch:  3/31	Total Loss 0.9262 (0.9489)
2022-11-02 23:31:53,587:INFO: Batch:  4/31	Total Loss 0.9756 (0.9540)
2022-11-02 23:31:53,641:INFO: Batch:  5/31	Total Loss 0.9052 (0.9459)
2022-11-02 23:31:53,693:INFO: Batch:  6/31	Total Loss 0.9119 (0.9411)
2022-11-02 23:31:53,742:INFO: Batch:  7/31	Total Loss 0.9409 (0.9410)
2022-11-02 23:31:53,790:INFO: Batch:  8/31	Total Loss 1.0209 (0.9489)
2022-11-02 23:31:53,840:INFO: Batch:  9/31	Total Loss 0.9970 (0.9538)
2022-11-02 23:31:53,890:INFO: Batch: 10/31	Total Loss 0.9754 (0.9557)
2022-11-02 23:31:53,938:INFO: Batch: 11/31	Total Loss 0.9815 (0.9578)
2022-11-02 23:31:53,988:INFO: Batch: 12/31	Total Loss 0.9766 (0.9591)
2022-11-02 23:31:54,041:INFO: Batch: 13/31	Total Loss 0.9667 (0.9596)
2022-11-02 23:31:54,093:INFO: Batch: 14/31	Total Loss 0.9138 (0.9568)
2022-11-02 23:31:54,145:INFO: Batch: 15/31	Total Loss 0.9300 (0.9549)
2022-11-02 23:31:54,197:INFO: Batch: 16/31	Total Loss 0.9265 (0.9533)
2022-11-02 23:31:54,247:INFO: Batch: 17/31	Total Loss 0.9437 (0.9529)
2022-11-02 23:31:54,300:INFO: Batch: 18/31	Total Loss 1.0345 (0.9577)
2022-11-02 23:31:54,351:INFO: Batch: 19/31	Total Loss 0.9800 (0.9588)
2022-11-02 23:31:54,402:INFO: Batch: 20/31	Total Loss 0.9209 (0.9570)
2022-11-02 23:31:54,452:INFO: Batch: 21/31	Total Loss 0.9595 (0.9571)
2022-11-02 23:31:54,505:INFO: Batch: 22/31	Total Loss 0.8983 (0.9546)
2022-11-02 23:31:54,556:INFO: Batch: 23/31	Total Loss 0.9051 (0.9525)
2022-11-02 23:31:54,607:INFO: Batch: 24/31	Total Loss 0.9389 (0.9519)
2022-11-02 23:31:54,657:INFO: Batch: 25/31	Total Loss 0.9049 (0.9501)
2022-11-02 23:31:54,710:INFO: Batch: 26/31	Total Loss 0.9404 (0.9498)
2022-11-02 23:31:54,760:INFO: Batch: 27/31	Total Loss 0.8702 (0.9468)
2022-11-02 23:31:54,811:INFO: Batch: 28/31	Total Loss 0.8505 (0.9432)
2022-11-02 23:31:54,861:INFO: Batch: 29/31	Total Loss 0.8455 (0.9401)
2022-11-02 23:31:54,894:INFO: Batch: 30/31	Total Loss 0.3951 (0.9354)
2022-11-02 23:31:55,046:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_23.pth.tar
2022-11-02 23:31:55,046:INFO: 
===> EPOCH: 24 (P1)
2022-11-02 23:31:55,046:INFO: - Computing loss (training)
2022-11-02 23:31:55,725:INFO: Batch:  0/31	Total Loss 0.9782 (0.9782)
2022-11-02 23:31:55,776:INFO: Batch:  1/31	Total Loss 0.8955 (0.9348)
2022-11-02 23:31:55,833:INFO: Batch:  2/31	Total Loss 0.9372 (0.9356)
2022-11-02 23:31:55,882:INFO: Batch:  3/31	Total Loss 0.9098 (0.9290)
2022-11-02 23:31:55,931:INFO: Batch:  4/31	Total Loss 0.8758 (0.9186)
2022-11-02 23:31:55,983:INFO: Batch:  5/31	Total Loss 0.9368 (0.9214)
2022-11-02 23:31:56,031:INFO: Batch:  6/31	Total Loss 0.8936 (0.9173)
2022-11-02 23:31:56,078:INFO: Batch:  7/31	Total Loss 0.8957 (0.9145)
2022-11-02 23:31:56,125:INFO: Batch:  8/31	Total Loss 0.9702 (0.9205)
2022-11-02 23:31:56,174:INFO: Batch:  9/31	Total Loss 0.8680 (0.9143)
2022-11-02 23:31:56,223:INFO: Batch: 10/31	Total Loss 0.9575 (0.9181)
2022-11-02 23:31:56,270:INFO: Batch: 11/31	Total Loss 0.9475 (0.9205)
2022-11-02 23:31:56,319:INFO: Batch: 12/31	Total Loss 0.8921 (0.9183)
2022-11-02 23:31:56,368:INFO: Batch: 13/31	Total Loss 0.9336 (0.9196)
2022-11-02 23:31:56,420:INFO: Batch: 14/31	Total Loss 0.9070 (0.9187)
2022-11-02 23:31:56,471:INFO: Batch: 15/31	Total Loss 0.8602 (0.9149)
2022-11-02 23:31:56,520:INFO: Batch: 16/31	Total Loss 0.8996 (0.9140)
2022-11-02 23:31:56,570:INFO: Batch: 17/31	Total Loss 0.9013 (0.9134)
2022-11-02 23:31:56,619:INFO: Batch: 18/31	Total Loss 0.8743 (0.9111)
2022-11-02 23:31:56,670:INFO: Batch: 19/31	Total Loss 0.9025 (0.9107)
2022-11-02 23:31:56,720:INFO: Batch: 20/31	Total Loss 0.8474 (0.9076)
2022-11-02 23:31:56,770:INFO: Batch: 21/31	Total Loss 0.8156 (0.9038)
2022-11-02 23:31:56,820:INFO: Batch: 22/31	Total Loss 0.8453 (0.9015)
2022-11-02 23:31:56,869:INFO: Batch: 23/31	Total Loss 0.8506 (0.8993)
2022-11-02 23:31:56,922:INFO: Batch: 24/31	Total Loss 0.8921 (0.8990)
2022-11-02 23:31:56,972:INFO: Batch: 25/31	Total Loss 0.9189 (0.8997)
2022-11-02 23:31:57,022:INFO: Batch: 26/31	Total Loss 0.8508 (0.8979)
2022-11-02 23:31:57,071:INFO: Batch: 27/31	Total Loss 0.8263 (0.8952)
2022-11-02 23:31:57,120:INFO: Batch: 28/31	Total Loss 0.8324 (0.8927)
2022-11-02 23:31:57,171:INFO: Batch: 29/31	Total Loss 0.8632 (0.8916)
2022-11-02 23:31:57,202:INFO: Batch: 30/31	Total Loss 0.3636 (0.8868)
2022-11-02 23:31:57,357:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_24.pth.tar
2022-11-02 23:31:57,358:INFO: 
===> EPOCH: 25 (P1)
2022-11-02 23:31:57,358:INFO: - Computing loss (training)
2022-11-02 23:31:58,018:INFO: Batch:  0/31	Total Loss 0.8532 (0.8532)
2022-11-02 23:31:58,068:INFO: Batch:  1/31	Total Loss 0.8351 (0.8433)
2022-11-02 23:31:58,121:INFO: Batch:  2/31	Total Loss 0.8281 (0.8382)
2022-11-02 23:31:58,173:INFO: Batch:  3/31	Total Loss 0.8232 (0.8346)
2022-11-02 23:31:58,221:INFO: Batch:  4/31	Total Loss 0.8625 (0.8403)
2022-11-02 23:31:58,272:INFO: Batch:  5/31	Total Loss 0.7994 (0.8337)
2022-11-02 23:31:58,320:INFO: Batch:  6/31	Total Loss 0.8710 (0.8393)
2022-11-02 23:31:58,368:INFO: Batch:  7/31	Total Loss 0.8391 (0.8393)
2022-11-02 23:31:58,415:INFO: Batch:  8/31	Total Loss 0.8696 (0.8424)
2022-11-02 23:31:58,463:INFO: Batch:  9/31	Total Loss 0.7789 (0.8366)
2022-11-02 23:31:58,512:INFO: Batch: 10/31	Total Loss 0.7930 (0.8324)
2022-11-02 23:31:58,559:INFO: Batch: 11/31	Total Loss 0.8365 (0.8328)
2022-11-02 23:31:58,607:INFO: Batch: 12/31	Total Loss 0.8255 (0.8323)
2022-11-02 23:31:58,656:INFO: Batch: 13/31	Total Loss 0.7825 (0.8293)
2022-11-02 23:31:58,708:INFO: Batch: 14/31	Total Loss 0.8380 (0.8299)
2022-11-02 23:31:58,758:INFO: Batch: 15/31	Total Loss 0.8270 (0.8297)
2022-11-02 23:31:58,808:INFO: Batch: 16/31	Total Loss 0.8315 (0.8298)
2022-11-02 23:31:58,856:INFO: Batch: 17/31	Total Loss 0.7908 (0.8278)
2022-11-02 23:31:58,905:INFO: Batch: 18/31	Total Loss 0.8285 (0.8278)
2022-11-02 23:31:58,956:INFO: Batch: 19/31	Total Loss 0.8089 (0.8269)
2022-11-02 23:31:59,005:INFO: Batch: 20/31	Total Loss 0.8216 (0.8267)
2022-11-02 23:31:59,054:INFO: Batch: 21/31	Total Loss 0.7699 (0.8242)
2022-11-02 23:31:59,103:INFO: Batch: 22/31	Total Loss 0.8373 (0.8248)
2022-11-02 23:31:59,151:INFO: Batch: 23/31	Total Loss 0.7602 (0.8217)
2022-11-02 23:31:59,201:INFO: Batch: 24/31	Total Loss 0.8617 (0.8229)
2022-11-02 23:31:59,251:INFO: Batch: 25/31	Total Loss 0.8214 (0.8229)
2022-11-02 23:31:59,300:INFO: Batch: 26/31	Total Loss 0.8513 (0.8240)
2022-11-02 23:31:59,350:INFO: Batch: 27/31	Total Loss 0.7873 (0.8226)
2022-11-02 23:31:59,400:INFO: Batch: 28/31	Total Loss 0.7894 (0.8214)
2022-11-02 23:31:59,452:INFO: Batch: 29/31	Total Loss 0.7877 (0.8203)
2022-11-02 23:31:59,483:INFO: Batch: 30/31	Total Loss 0.2708 (0.8141)
2022-11-02 23:31:59,622:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_25.pth.tar
2022-11-02 23:31:59,622:INFO: 
===> EPOCH: 26 (P1)
2022-11-02 23:31:59,622:INFO: - Computing loss (training)
2022-11-02 23:32:00,316:INFO: Batch:  0/31	Total Loss 0.7992 (0.7992)
2022-11-02 23:32:00,369:INFO: Batch:  1/31	Total Loss 0.7719 (0.7864)
2022-11-02 23:32:00,423:INFO: Batch:  2/31	Total Loss 0.7374 (0.7698)
2022-11-02 23:32:00,471:INFO: Batch:  3/31	Total Loss 0.7768 (0.7713)
2022-11-02 23:32:00,518:INFO: Batch:  4/31	Total Loss 0.8146 (0.7790)
2022-11-02 23:32:00,573:INFO: Batch:  5/31	Total Loss 0.8317 (0.7871)
2022-11-02 23:32:00,622:INFO: Batch:  6/31	Total Loss 0.7895 (0.7875)
2022-11-02 23:32:00,671:INFO: Batch:  7/31	Total Loss 0.8535 (0.7960)
2022-11-02 23:32:00,718:INFO: Batch:  8/31	Total Loss 0.7749 (0.7937)
2022-11-02 23:32:00,764:INFO: Batch:  9/31	Total Loss 0.8381 (0.7981)
2022-11-02 23:32:00,812:INFO: Batch: 10/31	Total Loss 0.8171 (0.7998)
2022-11-02 23:32:00,862:INFO: Batch: 11/31	Total Loss 0.8323 (0.8026)
2022-11-02 23:32:00,910:INFO: Batch: 12/31	Total Loss 0.7364 (0.7971)
2022-11-02 23:32:00,960:INFO: Batch: 13/31	Total Loss 0.7590 (0.7941)
2022-11-02 23:32:01,010:INFO: Batch: 14/31	Total Loss 0.8272 (0.7963)
2022-11-02 23:32:01,062:INFO: Batch: 15/31	Total Loss 0.7471 (0.7936)
2022-11-02 23:32:01,113:INFO: Batch: 16/31	Total Loss 0.7636 (0.7917)
2022-11-02 23:32:01,164:INFO: Batch: 17/31	Total Loss 0.7284 (0.7879)
2022-11-02 23:32:01,214:INFO: Batch: 18/31	Total Loss 0.7653 (0.7867)
2022-11-02 23:32:01,263:INFO: Batch: 19/31	Total Loss 0.7924 (0.7870)
2022-11-02 23:32:01,316:INFO: Batch: 20/31	Total Loss 0.7618 (0.7858)
2022-11-02 23:32:01,365:INFO: Batch: 21/31	Total Loss 0.7266 (0.7829)
2022-11-02 23:32:01,414:INFO: Batch: 22/31	Total Loss 0.7101 (0.7798)
2022-11-02 23:32:01,463:INFO: Batch: 23/31	Total Loss 0.7471 (0.7784)
2022-11-02 23:32:01,512:INFO: Batch: 24/31	Total Loss 0.7325 (0.7768)
2022-11-02 23:32:01,563:INFO: Batch: 25/31	Total Loss 0.7834 (0.7771)
2022-11-02 23:32:01,613:INFO: Batch: 26/31	Total Loss 0.7294 (0.7753)
2022-11-02 23:32:01,663:INFO: Batch: 27/31	Total Loss 0.7430 (0.7742)
2022-11-02 23:32:01,711:INFO: Batch: 28/31	Total Loss 0.7468 (0.7732)
2022-11-02 23:32:01,761:INFO: Batch: 29/31	Total Loss 0.7590 (0.7727)
2022-11-02 23:32:01,793:INFO: Batch: 30/31	Total Loss 0.2724 (0.7670)
2022-11-02 23:32:01,937:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_26.pth.tar
2022-11-02 23:32:01,937:INFO: 
===> EPOCH: 27 (P1)
2022-11-02 23:32:01,938:INFO: - Computing loss (training)
2022-11-02 23:32:02,620:INFO: Batch:  0/31	Total Loss 0.6986 (0.6986)
2022-11-02 23:32:02,676:INFO: Batch:  1/31	Total Loss 0.7054 (0.7021)
2022-11-02 23:32:02,729:INFO: Batch:  2/31	Total Loss 0.7850 (0.7324)
2022-11-02 23:32:02,778:INFO: Batch:  3/31	Total Loss 0.8015 (0.7479)
2022-11-02 23:32:02,825:INFO: Batch:  4/31	Total Loss 0.7275 (0.7440)
2022-11-02 23:32:02,878:INFO: Batch:  5/31	Total Loss 0.7316 (0.7420)
2022-11-02 23:32:02,927:INFO: Batch:  6/31	Total Loss 0.7063 (0.7368)
2022-11-02 23:32:02,974:INFO: Batch:  7/31	Total Loss 0.7667 (0.7402)
2022-11-02 23:32:03,022:INFO: Batch:  8/31	Total Loss 0.7321 (0.7393)
2022-11-02 23:32:03,071:INFO: Batch:  9/31	Total Loss 0.7200 (0.7373)
2022-11-02 23:32:03,120:INFO: Batch: 10/31	Total Loss 0.7493 (0.7385)
2022-11-02 23:32:03,168:INFO: Batch: 11/31	Total Loss 0.7400 (0.7386)
2022-11-02 23:32:03,219:INFO: Batch: 12/31	Total Loss 0.7077 (0.7362)
2022-11-02 23:32:03,271:INFO: Batch: 13/31	Total Loss 0.7938 (0.7408)
2022-11-02 23:32:03,323:INFO: Batch: 14/31	Total Loss 0.7265 (0.7399)
2022-11-02 23:32:03,375:INFO: Batch: 15/31	Total Loss 0.7216 (0.7386)
2022-11-02 23:32:03,425:INFO: Batch: 16/31	Total Loss 0.7553 (0.7397)
2022-11-02 23:32:03,477:INFO: Batch: 17/31	Total Loss 0.7405 (0.7398)
2022-11-02 23:32:03,528:INFO: Batch: 18/31	Total Loss 0.7174 (0.7385)
2022-11-02 23:32:03,581:INFO: Batch: 19/31	Total Loss 0.7159 (0.7373)
2022-11-02 23:32:03,631:INFO: Batch: 20/31	Total Loss 0.6897 (0.7352)
2022-11-02 23:32:03,681:INFO: Batch: 21/31	Total Loss 0.7007 (0.7337)
2022-11-02 23:32:03,730:INFO: Batch: 22/31	Total Loss 0.7505 (0.7345)
2022-11-02 23:32:03,782:INFO: Batch: 23/31	Total Loss 0.7481 (0.7351)
2022-11-02 23:32:03,832:INFO: Batch: 24/31	Total Loss 0.7002 (0.7336)
2022-11-02 23:32:03,883:INFO: Batch: 25/31	Total Loss 0.7478 (0.7341)
2022-11-02 23:32:03,933:INFO: Batch: 26/31	Total Loss 0.7174 (0.7335)
2022-11-02 23:32:03,986:INFO: Batch: 27/31	Total Loss 0.7396 (0.7337)
2022-11-02 23:32:04,037:INFO: Batch: 28/31	Total Loss 0.7369 (0.7338)
2022-11-02 23:32:04,087:INFO: Batch: 29/31	Total Loss 0.7163 (0.7332)
2022-11-02 23:32:04,118:INFO: Batch: 30/31	Total Loss 0.2382 (0.7279)
2022-11-02 23:32:04,272:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_27.pth.tar
2022-11-02 23:32:04,272:INFO: 
===> EPOCH: 28 (P1)
2022-11-02 23:32:04,272:INFO: - Computing loss (training)
2022-11-02 23:32:04,943:INFO: Batch:  0/31	Total Loss 0.7086 (0.7086)
2022-11-02 23:32:04,999:INFO: Batch:  1/31	Total Loss 0.6514 (0.6802)
2022-11-02 23:32:05,054:INFO: Batch:  2/31	Total Loss 0.7508 (0.7033)
2022-11-02 23:32:05,101:INFO: Batch:  3/31	Total Loss 0.6888 (0.6995)
2022-11-02 23:32:05,154:INFO: Batch:  4/31	Total Loss 0.6949 (0.6986)
2022-11-02 23:32:05,205:INFO: Batch:  5/31	Total Loss 0.7255 (0.7030)
2022-11-02 23:32:05,252:INFO: Batch:  6/31	Total Loss 0.6683 (0.6987)
2022-11-02 23:32:05,299:INFO: Batch:  7/31	Total Loss 0.6819 (0.6967)
2022-11-02 23:32:05,346:INFO: Batch:  8/31	Total Loss 0.6721 (0.6941)
2022-11-02 23:32:05,394:INFO: Batch:  9/31	Total Loss 0.7262 (0.6973)
2022-11-02 23:32:05,444:INFO: Batch: 10/31	Total Loss 0.6757 (0.6953)
2022-11-02 23:32:05,492:INFO: Batch: 11/31	Total Loss 0.6509 (0.6917)
2022-11-02 23:32:05,541:INFO: Batch: 12/31	Total Loss 0.7519 (0.6965)
2022-11-02 23:32:05,593:INFO: Batch: 13/31	Total Loss 0.6744 (0.6949)
2022-11-02 23:32:05,646:INFO: Batch: 14/31	Total Loss 0.6714 (0.6932)
2022-11-02 23:32:05,696:INFO: Batch: 15/31	Total Loss 0.6821 (0.6925)
2022-11-02 23:32:05,746:INFO: Batch: 16/31	Total Loss 0.6559 (0.6902)
2022-11-02 23:32:05,795:INFO: Batch: 17/31	Total Loss 0.6535 (0.6884)
2022-11-02 23:32:05,843:INFO: Batch: 18/31	Total Loss 0.6936 (0.6886)
2022-11-02 23:32:05,896:INFO: Batch: 19/31	Total Loss 0.6441 (0.6865)
2022-11-02 23:32:05,946:INFO: Batch: 20/31	Total Loss 0.6963 (0.6870)
2022-11-02 23:32:05,995:INFO: Batch: 21/31	Total Loss 0.7237 (0.6887)
2022-11-02 23:32:06,044:INFO: Batch: 22/31	Total Loss 0.6968 (0.6890)
2022-11-02 23:32:06,093:INFO: Batch: 23/31	Total Loss 0.7153 (0.6902)
2022-11-02 23:32:06,146:INFO: Batch: 24/31	Total Loss 0.6500 (0.6885)
2022-11-02 23:32:06,196:INFO: Batch: 25/31	Total Loss 0.6602 (0.6875)
2022-11-02 23:32:06,245:INFO: Batch: 26/31	Total Loss 0.7410 (0.6893)
2022-11-02 23:32:06,294:INFO: Batch: 27/31	Total Loss 0.6773 (0.6889)
2022-11-02 23:32:06,344:INFO: Batch: 28/31	Total Loss 0.6563 (0.6876)
2022-11-02 23:32:06,397:INFO: Batch: 29/31	Total Loss 0.6613 (0.6867)
2022-11-02 23:32:06,428:INFO: Batch: 30/31	Total Loss 0.2447 (0.6824)
2022-11-02 23:32:06,577:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_28.pth.tar
2022-11-02 23:32:06,577:INFO: 
===> EPOCH: 29 (P1)
2022-11-02 23:32:06,578:INFO: - Computing loss (training)
2022-11-02 23:32:07,268:INFO: Batch:  0/31	Total Loss 0.6989 (0.6989)
2022-11-02 23:32:07,321:INFO: Batch:  1/31	Total Loss 0.6641 (0.6809)
2022-11-02 23:32:07,373:INFO: Batch:  2/31	Total Loss 0.6725 (0.6779)
2022-11-02 23:32:07,425:INFO: Batch:  3/31	Total Loss 0.6610 (0.6736)
2022-11-02 23:32:07,475:INFO: Batch:  4/31	Total Loss 0.7188 (0.6814)
2022-11-02 23:32:07,524:INFO: Batch:  5/31	Total Loss 0.6417 (0.6752)
2022-11-02 23:32:07,571:INFO: Batch:  6/31	Total Loss 0.6681 (0.6741)
2022-11-02 23:32:07,618:INFO: Batch:  7/31	Total Loss 0.6499 (0.6708)
2022-11-02 23:32:07,664:INFO: Batch:  8/31	Total Loss 0.6715 (0.6708)
2022-11-02 23:32:07,713:INFO: Batch:  9/31	Total Loss 0.6583 (0.6695)
2022-11-02 23:32:07,763:INFO: Batch: 10/31	Total Loss 0.6789 (0.6703)
2022-11-02 23:32:07,809:INFO: Batch: 11/31	Total Loss 0.6905 (0.6721)
2022-11-02 23:32:07,858:INFO: Batch: 12/31	Total Loss 0.6534 (0.6706)
2022-11-02 23:32:07,908:INFO: Batch: 13/31	Total Loss 0.6254 (0.6672)
2022-11-02 23:32:07,960:INFO: Batch: 14/31	Total Loss 0.6642 (0.6670)
2022-11-02 23:32:08,011:INFO: Batch: 15/31	Total Loss 0.6278 (0.6645)
2022-11-02 23:32:08,060:INFO: Batch: 16/31	Total Loss 0.7087 (0.6669)
2022-11-02 23:32:08,110:INFO: Batch: 17/31	Total Loss 0.6755 (0.6673)
2022-11-02 23:32:08,159:INFO: Batch: 18/31	Total Loss 0.6301 (0.6653)
2022-11-02 23:32:08,211:INFO: Batch: 19/31	Total Loss 0.6641 (0.6652)
2022-11-02 23:32:08,260:INFO: Batch: 20/31	Total Loss 0.6525 (0.6647)
2022-11-02 23:32:08,309:INFO: Batch: 21/31	Total Loss 0.6432 (0.6637)
2022-11-02 23:32:08,359:INFO: Batch: 22/31	Total Loss 0.6527 (0.6632)
2022-11-02 23:32:08,407:INFO: Batch: 23/31	Total Loss 0.6091 (0.6608)
2022-11-02 23:32:08,458:INFO: Batch: 24/31	Total Loss 0.6154 (0.6589)
2022-11-02 23:32:08,508:INFO: Batch: 25/31	Total Loss 0.6200 (0.6572)
2022-11-02 23:32:08,556:INFO: Batch: 26/31	Total Loss 0.6657 (0.6575)
2022-11-02 23:32:08,606:INFO: Batch: 27/31	Total Loss 0.6357 (0.6567)
2022-11-02 23:32:08,655:INFO: Batch: 28/31	Total Loss 0.6515 (0.6565)
2022-11-02 23:32:08,707:INFO: Batch: 29/31	Total Loss 0.7060 (0.6581)
2022-11-02 23:32:08,738:INFO: Batch: 30/31	Total Loss 0.2420 (0.6540)
2022-11-02 23:32:08,884:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_29.pth.tar
2022-11-02 23:32:08,884:INFO: 
===> EPOCH: 30 (P1)
2022-11-02 23:32:08,884:INFO: - Computing loss (training)
2022-11-02 23:32:09,556:INFO: Batch:  0/31	Total Loss 0.6351 (0.6351)
2022-11-02 23:32:09,606:INFO: Batch:  1/31	Total Loss 0.6640 (0.6501)
2022-11-02 23:32:09,663:INFO: Batch:  2/31	Total Loss 0.7160 (0.6724)
2022-11-02 23:32:09,714:INFO: Batch:  3/31	Total Loss 0.6473 (0.6666)
2022-11-02 23:32:09,765:INFO: Batch:  4/31	Total Loss 0.6540 (0.6641)
2022-11-02 23:32:09,816:INFO: Batch:  5/31	Total Loss 0.6337 (0.6593)
2022-11-02 23:32:09,864:INFO: Batch:  6/31	Total Loss 0.6386 (0.6564)
2022-11-02 23:32:09,910:INFO: Batch:  7/31	Total Loss 0.6265 (0.6526)
2022-11-02 23:32:09,959:INFO: Batch:  8/31	Total Loss 0.6650 (0.6540)
2022-11-02 23:32:10,009:INFO: Batch:  9/31	Total Loss 0.6316 (0.6517)
2022-11-02 23:32:10,060:INFO: Batch: 10/31	Total Loss 0.5610 (0.6432)
2022-11-02 23:32:10,107:INFO: Batch: 11/31	Total Loss 0.6061 (0.6401)
2022-11-02 23:32:10,156:INFO: Batch: 12/31	Total Loss 0.6223 (0.6386)
2022-11-02 23:32:10,205:INFO: Batch: 13/31	Total Loss 0.5943 (0.6356)
2022-11-02 23:32:10,259:INFO: Batch: 14/31	Total Loss 0.5866 (0.6325)
2022-11-02 23:32:10,310:INFO: Batch: 15/31	Total Loss 0.6607 (0.6342)
2022-11-02 23:32:10,360:INFO: Batch: 16/31	Total Loss 0.5964 (0.6319)
2022-11-02 23:32:10,411:INFO: Batch: 17/31	Total Loss 0.6525 (0.6331)
2022-11-02 23:32:10,461:INFO: Batch: 18/31	Total Loss 0.6051 (0.6316)
2022-11-02 23:32:10,515:INFO: Batch: 19/31	Total Loss 0.6336 (0.6317)
2022-11-02 23:32:10,564:INFO: Batch: 20/31	Total Loss 0.5978 (0.6301)
2022-11-02 23:32:10,613:INFO: Batch: 21/31	Total Loss 0.6066 (0.6290)
2022-11-02 23:32:10,662:INFO: Batch: 22/31	Total Loss 0.5824 (0.6270)
2022-11-02 23:32:10,716:INFO: Batch: 23/31	Total Loss 0.6295 (0.6271)
2022-11-02 23:32:10,769:INFO: Batch: 24/31	Total Loss 0.6318 (0.6273)
2022-11-02 23:32:10,818:INFO: Batch: 25/31	Total Loss 0.5991 (0.6262)
2022-11-02 23:32:10,867:INFO: Batch: 26/31	Total Loss 0.6079 (0.6255)
2022-11-02 23:32:10,918:INFO: Batch: 27/31	Total Loss 0.5990 (0.6247)
2022-11-02 23:32:10,968:INFO: Batch: 28/31	Total Loss 0.5970 (0.6237)
2022-11-02 23:32:11,017:INFO: Batch: 29/31	Total Loss 0.5990 (0.6229)
2022-11-02 23:32:11,048:INFO: Batch: 30/31	Total Loss 0.2225 (0.6189)
2022-11-02 23:32:11,200:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_30.pth.tar
2022-11-02 23:32:11,200:INFO: 
===> EPOCH: 31 (P1)
2022-11-02 23:32:11,201:INFO: - Computing loss (training)
2022-11-02 23:32:11,828:INFO: Batch:  0/31	Total Loss 0.5960 (0.5960)
2022-11-02 23:32:11,877:INFO: Batch:  1/31	Total Loss 0.5839 (0.5899)
2022-11-02 23:32:11,930:INFO: Batch:  2/31	Total Loss 0.5860 (0.5884)
2022-11-02 23:32:11,981:INFO: Batch:  3/31	Total Loss 0.6364 (0.6000)
2022-11-02 23:32:12,027:INFO: Batch:  4/31	Total Loss 0.5640 (0.5924)
2022-11-02 23:32:12,079:INFO: Batch:  5/31	Total Loss 0.5834 (0.5910)
2022-11-02 23:32:12,127:INFO: Batch:  6/31	Total Loss 0.5859 (0.5902)
2022-11-02 23:32:12,174:INFO: Batch:  7/31	Total Loss 0.6011 (0.5915)
2022-11-02 23:32:12,220:INFO: Batch:  8/31	Total Loss 0.5948 (0.5919)
2022-11-02 23:32:12,267:INFO: Batch:  9/31	Total Loss 0.5831 (0.5910)
2022-11-02 23:32:12,317:INFO: Batch: 10/31	Total Loss 0.5725 (0.5894)
2022-11-02 23:32:12,365:INFO: Batch: 11/31	Total Loss 0.6440 (0.5939)
2022-11-02 23:32:12,413:INFO: Batch: 12/31	Total Loss 0.6178 (0.5956)
2022-11-02 23:32:12,462:INFO: Batch: 13/31	Total Loss 0.5829 (0.5948)
2022-11-02 23:32:12,511:INFO: Batch: 14/31	Total Loss 0.5731 (0.5933)
2022-11-02 23:32:12,563:INFO: Batch: 15/31	Total Loss 0.5735 (0.5921)
2022-11-02 23:32:12,613:INFO: Batch: 16/31	Total Loss 0.6028 (0.5928)
2022-11-02 23:32:12,663:INFO: Batch: 17/31	Total Loss 0.5888 (0.5925)
2022-11-02 23:32:12,711:INFO: Batch: 18/31	Total Loss 0.5728 (0.5914)
2022-11-02 23:32:12,760:INFO: Batch: 19/31	Total Loss 0.5839 (0.5910)
2022-11-02 23:32:12,812:INFO: Batch: 20/31	Total Loss 0.5725 (0.5900)
2022-11-02 23:32:12,860:INFO: Batch: 21/31	Total Loss 0.6325 (0.5918)
2022-11-02 23:32:12,909:INFO: Batch: 22/31	Total Loss 0.6015 (0.5922)
2022-11-02 23:32:12,958:INFO: Batch: 23/31	Total Loss 0.5708 (0.5913)
2022-11-02 23:32:13,005:INFO: Batch: 24/31	Total Loss 0.5973 (0.5916)
2022-11-02 23:32:13,056:INFO: Batch: 25/31	Total Loss 0.5653 (0.5906)
2022-11-02 23:32:13,105:INFO: Batch: 26/31	Total Loss 0.5496 (0.5890)
2022-11-02 23:32:13,154:INFO: Batch: 27/31	Total Loss 0.5381 (0.5872)
2022-11-02 23:32:13,202:INFO: Batch: 28/31	Total Loss 0.5691 (0.5867)
2022-11-02 23:32:13,251:INFO: Batch: 29/31	Total Loss 0.6016 (0.5872)
2022-11-02 23:32:13,282:INFO: Batch: 30/31	Total Loss 0.2194 (0.5845)
2022-11-02 23:32:13,423:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_31.pth.tar
2022-11-02 23:32:13,423:INFO: 
===> EPOCH: 32 (P1)
2022-11-02 23:32:13,424:INFO: - Computing loss (training)
2022-11-02 23:32:14,098:INFO: Batch:  0/31	Total Loss 0.6088 (0.6088)
2022-11-02 23:32:14,146:INFO: Batch:  1/31	Total Loss 0.5792 (0.5936)
2022-11-02 23:32:14,199:INFO: Batch:  2/31	Total Loss 0.5574 (0.5801)
2022-11-02 23:32:14,247:INFO: Batch:  3/31	Total Loss 0.5879 (0.5821)
2022-11-02 23:32:14,297:INFO: Batch:  4/31	Total Loss 0.5376 (0.5730)
2022-11-02 23:32:14,349:INFO: Batch:  5/31	Total Loss 0.5585 (0.5703)
2022-11-02 23:32:14,398:INFO: Batch:  6/31	Total Loss 0.5204 (0.5640)
2022-11-02 23:32:14,446:INFO: Batch:  7/31	Total Loss 0.5593 (0.5634)
2022-11-02 23:32:14,492:INFO: Batch:  8/31	Total Loss 0.5513 (0.5622)
2022-11-02 23:32:14,539:INFO: Batch:  9/31	Total Loss 0.5471 (0.5606)
2022-11-02 23:32:14,590:INFO: Batch: 10/31	Total Loss 0.5542 (0.5600)
2022-11-02 23:32:14,638:INFO: Batch: 11/31	Total Loss 0.5759 (0.5612)
2022-11-02 23:32:14,688:INFO: Batch: 12/31	Total Loss 0.4991 (0.5569)
2022-11-02 23:32:14,738:INFO: Batch: 13/31	Total Loss 0.5611 (0.5572)
2022-11-02 23:32:14,788:INFO: Batch: 14/31	Total Loss 0.5400 (0.5561)
2022-11-02 23:32:14,840:INFO: Batch: 15/31	Total Loss 0.5274 (0.5542)
2022-11-02 23:32:14,891:INFO: Batch: 16/31	Total Loss 0.5884 (0.5561)
2022-11-02 23:32:14,941:INFO: Batch: 17/31	Total Loss 0.5578 (0.5562)
2022-11-02 23:32:14,991:INFO: Batch: 18/31	Total Loss 0.5825 (0.5575)
2022-11-02 23:32:15,040:INFO: Batch: 19/31	Total Loss 0.5575 (0.5575)
2022-11-02 23:32:15,091:INFO: Batch: 20/31	Total Loss 0.5057 (0.5551)
2022-11-02 23:32:15,140:INFO: Batch: 21/31	Total Loss 0.5470 (0.5548)
2022-11-02 23:32:15,190:INFO: Batch: 22/31	Total Loss 0.5727 (0.5556)
2022-11-02 23:32:15,239:INFO: Batch: 23/31	Total Loss 0.5341 (0.5548)
2022-11-02 23:32:15,288:INFO: Batch: 24/31	Total Loss 0.5480 (0.5545)
2022-11-02 23:32:15,338:INFO: Batch: 25/31	Total Loss 0.5227 (0.5533)
2022-11-02 23:32:15,388:INFO: Batch: 26/31	Total Loss 0.5439 (0.5530)
2022-11-02 23:32:15,438:INFO: Batch: 27/31	Total Loss 0.5238 (0.5520)
2022-11-02 23:32:15,487:INFO: Batch: 28/31	Total Loss 0.5676 (0.5525)
2022-11-02 23:32:15,536:INFO: Batch: 29/31	Total Loss 0.5290 (0.5517)
2022-11-02 23:32:15,568:INFO: Batch: 30/31	Total Loss 0.1915 (0.5484)
2022-11-02 23:32:15,723:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_32.pth.tar
2022-11-02 23:32:15,723:INFO: 
===> EPOCH: 33 (P1)
2022-11-02 23:32:15,723:INFO: - Computing loss (training)
2022-11-02 23:32:16,388:INFO: Batch:  0/31	Total Loss 0.5751 (0.5751)
2022-11-02 23:32:16,440:INFO: Batch:  1/31	Total Loss 0.5519 (0.5641)
2022-11-02 23:32:16,494:INFO: Batch:  2/31	Total Loss 0.5064 (0.5447)
2022-11-02 23:32:16,547:INFO: Batch:  3/31	Total Loss 0.5407 (0.5437)
2022-11-02 23:32:16,595:INFO: Batch:  4/31	Total Loss 0.5555 (0.5460)
2022-11-02 23:32:16,647:INFO: Batch:  5/31	Total Loss 0.5217 (0.5421)
2022-11-02 23:32:16,695:INFO: Batch:  6/31	Total Loss 0.5334 (0.5406)
2022-11-02 23:32:16,742:INFO: Batch:  7/31	Total Loss 0.5903 (0.5455)
2022-11-02 23:32:16,791:INFO: Batch:  8/31	Total Loss 0.5774 (0.5490)
2022-11-02 23:32:16,841:INFO: Batch:  9/31	Total Loss 0.5661 (0.5508)
2022-11-02 23:32:16,888:INFO: Batch: 10/31	Total Loss 0.5732 (0.5529)
2022-11-02 23:32:16,935:INFO: Batch: 11/31	Total Loss 0.5377 (0.5515)
2022-11-02 23:32:16,985:INFO: Batch: 12/31	Total Loss 0.5317 (0.5499)
2022-11-02 23:32:17,034:INFO: Batch: 13/31	Total Loss 0.5381 (0.5491)
2022-11-02 23:32:17,087:INFO: Batch: 14/31	Total Loss 0.5295 (0.5477)
2022-11-02 23:32:17,136:INFO: Batch: 15/31	Total Loss 0.5425 (0.5474)
2022-11-02 23:32:17,186:INFO: Batch: 16/31	Total Loss 0.5283 (0.5462)
2022-11-02 23:32:17,235:INFO: Batch: 17/31	Total Loss 0.5335 (0.5454)
2022-11-02 23:32:17,285:INFO: Batch: 18/31	Total Loss 0.5305 (0.5446)
2022-11-02 23:32:17,337:INFO: Batch: 19/31	Total Loss 0.5067 (0.5428)
2022-11-02 23:32:17,388:INFO: Batch: 20/31	Total Loss 0.5324 (0.5423)
2022-11-02 23:32:17,438:INFO: Batch: 21/31	Total Loss 0.5288 (0.5417)
2022-11-02 23:32:17,489:INFO: Batch: 22/31	Total Loss 0.5268 (0.5410)
2022-11-02 23:32:17,539:INFO: Batch: 23/31	Total Loss 0.4914 (0.5389)
2022-11-02 23:32:17,592:INFO: Batch: 24/31	Total Loss 0.4981 (0.5372)
2022-11-02 23:32:17,643:INFO: Batch: 25/31	Total Loss 0.5530 (0.5378)
2022-11-02 23:32:17,694:INFO: Batch: 26/31	Total Loss 0.5235 (0.5373)
2022-11-02 23:32:17,745:INFO: Batch: 27/31	Total Loss 0.5029 (0.5362)
2022-11-02 23:32:17,799:INFO: Batch: 28/31	Total Loss 0.5511 (0.5367)
2022-11-02 23:32:17,849:INFO: Batch: 29/31	Total Loss 0.4784 (0.5348)
2022-11-02 23:32:17,881:INFO: Batch: 30/31	Total Loss 0.1844 (0.5320)
2022-11-02 23:32:18,027:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_33.pth.tar
2022-11-02 23:32:18,027:INFO: 
===> EPOCH: 34 (P1)
2022-11-02 23:32:18,027:INFO: - Computing loss (training)
2022-11-02 23:32:18,727:INFO: Batch:  0/31	Total Loss 0.5026 (0.5026)
2022-11-02 23:32:18,780:INFO: Batch:  1/31	Total Loss 0.4879 (0.4954)
2022-11-02 23:32:18,837:INFO: Batch:  2/31	Total Loss 0.5133 (0.5010)
2022-11-02 23:32:18,887:INFO: Batch:  3/31	Total Loss 0.5045 (0.5018)
2022-11-02 23:32:18,938:INFO: Batch:  4/31	Total Loss 0.5139 (0.5039)
2022-11-02 23:32:18,995:INFO: Batch:  5/31	Total Loss 0.5254 (0.5073)
2022-11-02 23:32:19,044:INFO: Batch:  6/31	Total Loss 0.5157 (0.5085)
2022-11-02 23:32:19,093:INFO: Batch:  7/31	Total Loss 0.4899 (0.5059)
2022-11-02 23:32:19,143:INFO: Batch:  8/31	Total Loss 0.5235 (0.5077)
2022-11-02 23:32:19,193:INFO: Batch:  9/31	Total Loss 0.5152 (0.5084)
2022-11-02 23:32:19,243:INFO: Batch: 10/31	Total Loss 0.4991 (0.5075)
2022-11-02 23:32:19,292:INFO: Batch: 11/31	Total Loss 0.5458 (0.5105)
2022-11-02 23:32:19,343:INFO: Batch: 12/31	Total Loss 0.5050 (0.5101)
2022-11-02 23:32:19,400:INFO: Batch: 13/31	Total Loss 0.5266 (0.5112)
2022-11-02 23:32:19,453:INFO: Batch: 14/31	Total Loss 0.5088 (0.5111)
2022-11-02 23:32:19,504:INFO: Batch: 15/31	Total Loss 0.4902 (0.5097)
2022-11-02 23:32:19,556:INFO: Batch: 16/31	Total Loss 0.4788 (0.5078)
2022-11-02 23:32:19,609:INFO: Batch: 17/31	Total Loss 0.4759 (0.5059)
2022-11-02 23:32:19,663:INFO: Batch: 18/31	Total Loss 0.4856 (0.5047)
2022-11-02 23:32:19,714:INFO: Batch: 19/31	Total Loss 0.4664 (0.5028)
2022-11-02 23:32:19,765:INFO: Batch: 20/31	Total Loss 0.4859 (0.5021)
2022-11-02 23:32:19,817:INFO: Batch: 21/31	Total Loss 0.4854 (0.5013)
2022-11-02 23:32:19,871:INFO: Batch: 22/31	Total Loss 0.5050 (0.5015)
2022-11-02 23:32:19,922:INFO: Batch: 23/31	Total Loss 0.5118 (0.5020)
2022-11-02 23:32:19,973:INFO: Batch: 24/31	Total Loss 0.4888 (0.5014)
2022-11-02 23:32:20,025:INFO: Batch: 25/31	Total Loss 0.5227 (0.5022)
2022-11-02 23:32:20,079:INFO: Batch: 26/31	Total Loss 0.4784 (0.5014)
2022-11-02 23:32:20,130:INFO: Batch: 27/31	Total Loss 0.5042 (0.5015)
2022-11-02 23:32:20,181:INFO: Batch: 28/31	Total Loss 0.4902 (0.5011)
2022-11-02 23:32:20,232:INFO: Batch: 29/31	Total Loss 0.4529 (0.4995)
2022-11-02 23:32:20,266:INFO: Batch: 30/31	Total Loss 0.2071 (0.4970)
2022-11-02 23:32:20,416:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_34.pth.tar
2022-11-02 23:32:20,417:INFO: 
===> EPOCH: 35 (P1)
2022-11-02 23:32:20,417:INFO: - Computing loss (training)
2022-11-02 23:32:21,098:INFO: Batch:  0/31	Total Loss 0.4709 (0.4709)
2022-11-02 23:32:21,151:INFO: Batch:  1/31	Total Loss 0.4782 (0.4746)
2022-11-02 23:32:21,205:INFO: Batch:  2/31	Total Loss 0.4783 (0.4758)
2022-11-02 23:32:21,252:INFO: Batch:  3/31	Total Loss 0.5002 (0.4817)
2022-11-02 23:32:21,302:INFO: Batch:  4/31	Total Loss 0.4879 (0.4830)
2022-11-02 23:32:21,353:INFO: Batch:  5/31	Total Loss 0.5048 (0.4872)
2022-11-02 23:32:21,403:INFO: Batch:  6/31	Total Loss 0.4854 (0.4870)
2022-11-02 23:32:21,455:INFO: Batch:  7/31	Total Loss 0.4843 (0.4866)
2022-11-02 23:32:21,503:INFO: Batch:  8/31	Total Loss 0.4870 (0.4866)
2022-11-02 23:32:21,552:INFO: Batch:  9/31	Total Loss 0.4853 (0.4865)
2022-11-02 23:32:21,602:INFO: Batch: 10/31	Total Loss 0.4772 (0.4856)
2022-11-02 23:32:21,650:INFO: Batch: 11/31	Total Loss 0.4695 (0.4843)
2022-11-02 23:32:21,699:INFO: Batch: 12/31	Total Loss 0.4897 (0.4847)
2022-11-02 23:32:21,753:INFO: Batch: 13/31	Total Loss 0.4779 (0.4843)
2022-11-02 23:32:21,803:INFO: Batch: 14/31	Total Loss 0.4904 (0.4846)
2022-11-02 23:32:21,853:INFO: Batch: 15/31	Total Loss 0.4577 (0.4827)
2022-11-02 23:32:21,904:INFO: Batch: 16/31	Total Loss 0.5028 (0.4838)
2022-11-02 23:32:21,955:INFO: Batch: 17/31	Total Loss 0.4778 (0.4835)
2022-11-02 23:32:22,008:INFO: Batch: 18/31	Total Loss 0.4677 (0.4827)
2022-11-02 23:32:22,058:INFO: Batch: 19/31	Total Loss 0.5035 (0.4837)
2022-11-02 23:32:22,107:INFO: Batch: 20/31	Total Loss 0.5012 (0.4846)
2022-11-02 23:32:22,157:INFO: Batch: 21/31	Total Loss 0.4716 (0.4840)
2022-11-02 23:32:22,209:INFO: Batch: 22/31	Total Loss 0.5258 (0.4857)
2022-11-02 23:32:22,259:INFO: Batch: 23/31	Total Loss 0.4674 (0.4850)
2022-11-02 23:32:22,309:INFO: Batch: 24/31	Total Loss 0.4634 (0.4842)
2022-11-02 23:32:22,358:INFO: Batch: 25/31	Total Loss 0.4918 (0.4845)
2022-11-02 23:32:22,410:INFO: Batch: 26/31	Total Loss 0.4968 (0.4849)
2022-11-02 23:32:22,460:INFO: Batch: 27/31	Total Loss 0.4754 (0.4845)
2022-11-02 23:32:22,510:INFO: Batch: 28/31	Total Loss 0.4921 (0.4848)
2022-11-02 23:32:22,559:INFO: Batch: 29/31	Total Loss 0.4725 (0.4844)
2022-11-02 23:32:22,589:INFO: Batch: 30/31	Total Loss 0.1847 (0.4817)
2022-11-02 23:32:22,749:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_35.pth.tar
2022-11-02 23:32:22,749:INFO: 
===> EPOCH: 36 (P1)
2022-11-02 23:32:22,749:INFO: - Computing loss (training)
2022-11-02 23:32:23,420:INFO: Batch:  0/31	Total Loss 0.4716 (0.4716)
2022-11-02 23:32:23,471:INFO: Batch:  1/31	Total Loss 0.4402 (0.4558)
2022-11-02 23:32:23,526:INFO: Batch:  2/31	Total Loss 0.5191 (0.4789)
2022-11-02 23:32:23,582:INFO: Batch:  3/31	Total Loss 0.4576 (0.4735)
2022-11-02 23:32:23,633:INFO: Batch:  4/31	Total Loss 0.4709 (0.4730)
2022-11-02 23:32:23,687:INFO: Batch:  5/31	Total Loss 0.4587 (0.4707)
2022-11-02 23:32:23,738:INFO: Batch:  6/31	Total Loss 0.4723 (0.4710)
2022-11-02 23:32:23,786:INFO: Batch:  7/31	Total Loss 0.4604 (0.4698)
2022-11-02 23:32:23,833:INFO: Batch:  8/31	Total Loss 0.4395 (0.4663)
2022-11-02 23:32:23,883:INFO: Batch:  9/31	Total Loss 0.4609 (0.4658)
2022-11-02 23:32:23,932:INFO: Batch: 10/31	Total Loss 0.4825 (0.4674)
2022-11-02 23:32:23,980:INFO: Batch: 11/31	Total Loss 0.4359 (0.4648)
2022-11-02 23:32:24,031:INFO: Batch: 12/31	Total Loss 0.4519 (0.4638)
2022-11-02 23:32:24,082:INFO: Batch: 13/31	Total Loss 0.4600 (0.4635)
2022-11-02 23:32:24,135:INFO: Batch: 14/31	Total Loss 0.4498 (0.4625)
2022-11-02 23:32:24,185:INFO: Batch: 15/31	Total Loss 0.4676 (0.4628)
2022-11-02 23:32:24,236:INFO: Batch: 16/31	Total Loss 0.4336 (0.4608)
2022-11-02 23:32:24,287:INFO: Batch: 17/31	Total Loss 0.4470 (0.4601)
2022-11-02 23:32:24,338:INFO: Batch: 18/31	Total Loss 0.4627 (0.4602)
2022-11-02 23:32:24,390:INFO: Batch: 19/31	Total Loss 0.4435 (0.4594)
2022-11-02 23:32:24,440:INFO: Batch: 20/31	Total Loss 0.4231 (0.4578)
2022-11-02 23:32:24,489:INFO: Batch: 21/31	Total Loss 0.4438 (0.4572)
2022-11-02 23:32:24,538:INFO: Batch: 22/31	Total Loss 0.4124 (0.4554)
2022-11-02 23:32:24,590:INFO: Batch: 23/31	Total Loss 0.4400 (0.4547)
2022-11-02 23:32:24,640:INFO: Batch: 24/31	Total Loss 0.4518 (0.4546)
2022-11-02 23:32:24,690:INFO: Batch: 25/31	Total Loss 0.4334 (0.4538)
2022-11-02 23:32:24,740:INFO: Batch: 26/31	Total Loss 0.4506 (0.4536)
2022-11-02 23:32:24,791:INFO: Batch: 27/31	Total Loss 0.4401 (0.4531)
2022-11-02 23:32:24,841:INFO: Batch: 28/31	Total Loss 0.4776 (0.4540)
2022-11-02 23:32:24,891:INFO: Batch: 29/31	Total Loss 0.4395 (0.4535)
2022-11-02 23:32:24,921:INFO: Batch: 30/31	Total Loss 0.1643 (0.4509)
2022-11-02 23:32:25,072:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_36.pth.tar
2022-11-02 23:32:25,072:INFO: 
===> EPOCH: 37 (P1)
2022-11-02 23:32:25,072:INFO: - Computing loss (training)
2022-11-02 23:32:25,754:INFO: Batch:  0/31	Total Loss 0.4269 (0.4269)
2022-11-02 23:32:25,804:INFO: Batch:  1/31	Total Loss 0.4427 (0.4347)
2022-11-02 23:32:25,859:INFO: Batch:  2/31	Total Loss 0.4296 (0.4328)
2022-11-02 23:32:25,908:INFO: Batch:  3/31	Total Loss 0.4682 (0.4416)
2022-11-02 23:32:25,957:INFO: Batch:  4/31	Total Loss 0.4361 (0.4404)
2022-11-02 23:32:26,015:INFO: Batch:  5/31	Total Loss 0.4245 (0.4375)
2022-11-02 23:32:26,064:INFO: Batch:  6/31	Total Loss 0.4257 (0.4356)
2022-11-02 23:32:26,114:INFO: Batch:  7/31	Total Loss 0.4360 (0.4357)
2022-11-02 23:32:26,164:INFO: Batch:  8/31	Total Loss 0.4361 (0.4357)
2022-11-02 23:32:26,214:INFO: Batch:  9/31	Total Loss 0.4272 (0.4349)
2022-11-02 23:32:26,263:INFO: Batch: 10/31	Total Loss 0.4603 (0.4370)
2022-11-02 23:32:26,313:INFO: Batch: 11/31	Total Loss 0.4415 (0.4374)
2022-11-02 23:32:26,365:INFO: Batch: 12/31	Total Loss 0.4333 (0.4371)
2022-11-02 23:32:26,420:INFO: Batch: 13/31	Total Loss 0.4060 (0.4347)
2022-11-02 23:32:26,472:INFO: Batch: 14/31	Total Loss 0.4258 (0.4341)
2022-11-02 23:32:26,523:INFO: Batch: 15/31	Total Loss 0.4134 (0.4328)
2022-11-02 23:32:26,575:INFO: Batch: 16/31	Total Loss 0.4433 (0.4334)
2022-11-02 23:32:26,629:INFO: Batch: 17/31	Total Loss 0.4475 (0.4342)
2022-11-02 23:32:26,680:INFO: Batch: 18/31	Total Loss 0.4496 (0.4352)
2022-11-02 23:32:26,732:INFO: Batch: 19/31	Total Loss 0.4455 (0.4357)
2022-11-02 23:32:26,784:INFO: Batch: 20/31	Total Loss 0.3802 (0.4331)
2022-11-02 23:32:26,838:INFO: Batch: 21/31	Total Loss 0.4231 (0.4327)
2022-11-02 23:32:26,889:INFO: Batch: 22/31	Total Loss 0.4362 (0.4328)
2022-11-02 23:32:26,942:INFO: Batch: 23/31	Total Loss 0.4237 (0.4324)
2022-11-02 23:32:26,994:INFO: Batch: 24/31	Total Loss 0.4301 (0.4323)
2022-11-02 23:32:27,048:INFO: Batch: 25/31	Total Loss 0.4145 (0.4317)
2022-11-02 23:32:27,099:INFO: Batch: 26/31	Total Loss 0.4464 (0.4322)
2022-11-02 23:32:27,150:INFO: Batch: 27/31	Total Loss 0.4227 (0.4319)
2022-11-02 23:32:27,201:INFO: Batch: 28/31	Total Loss 0.4450 (0.4323)
2022-11-02 23:32:27,253:INFO: Batch: 29/31	Total Loss 0.4592 (0.4332)
2022-11-02 23:32:27,285:INFO: Batch: 30/31	Total Loss 0.1650 (0.4302)
2022-11-02 23:32:27,438:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_37.pth.tar
2022-11-02 23:32:27,438:INFO: 
===> EPOCH: 38 (P1)
2022-11-02 23:32:27,439:INFO: - Computing loss (training)
2022-11-02 23:32:28,121:INFO: Batch:  0/31	Total Loss 0.4156 (0.4156)
2022-11-02 23:32:28,172:INFO: Batch:  1/31	Total Loss 0.4291 (0.4220)
2022-11-02 23:32:28,224:INFO: Batch:  2/31	Total Loss 0.4482 (0.4309)
2022-11-02 23:32:28,278:INFO: Batch:  3/31	Total Loss 0.4375 (0.4325)
2022-11-02 23:32:28,329:INFO: Batch:  4/31	Total Loss 0.4057 (0.4268)
2022-11-02 23:32:28,382:INFO: Batch:  5/31	Total Loss 0.4253 (0.4266)
2022-11-02 23:32:28,433:INFO: Batch:  6/31	Total Loss 0.4133 (0.4247)
2022-11-02 23:32:28,481:INFO: Batch:  7/31	Total Loss 0.4156 (0.4236)
2022-11-02 23:32:28,529:INFO: Batch:  8/31	Total Loss 0.4406 (0.4255)
2022-11-02 23:32:28,580:INFO: Batch:  9/31	Total Loss 0.4074 (0.4239)
2022-11-02 23:32:28,631:INFO: Batch: 10/31	Total Loss 0.4205 (0.4236)
2022-11-02 23:32:28,679:INFO: Batch: 11/31	Total Loss 0.4341 (0.4244)
2022-11-02 23:32:28,729:INFO: Batch: 12/31	Total Loss 0.4340 (0.4252)
2022-11-02 23:32:28,779:INFO: Batch: 13/31	Total Loss 0.4091 (0.4240)
2022-11-02 23:32:28,834:INFO: Batch: 14/31	Total Loss 0.4092 (0.4231)
2022-11-02 23:32:28,885:INFO: Batch: 15/31	Total Loss 0.4173 (0.4228)
2022-11-02 23:32:28,935:INFO: Batch: 16/31	Total Loss 0.4297 (0.4231)
2022-11-02 23:32:28,986:INFO: Batch: 17/31	Total Loss 0.4136 (0.4225)
2022-11-02 23:32:29,036:INFO: Batch: 18/31	Total Loss 0.4133 (0.4220)
2022-11-02 23:32:29,090:INFO: Batch: 19/31	Total Loss 0.3847 (0.4200)
2022-11-02 23:32:29,140:INFO: Batch: 20/31	Total Loss 0.3925 (0.4185)
2022-11-02 23:32:29,190:INFO: Batch: 21/31	Total Loss 0.4125 (0.4183)
2022-11-02 23:32:29,240:INFO: Batch: 22/31	Total Loss 0.4504 (0.4197)
2022-11-02 23:32:29,290:INFO: Batch: 23/31	Total Loss 0.4261 (0.4200)
2022-11-02 23:32:29,345:INFO: Batch: 24/31	Total Loss 0.4150 (0.4198)
2022-11-02 23:32:29,397:INFO: Batch: 25/31	Total Loss 0.4235 (0.4199)
2022-11-02 23:32:29,449:INFO: Batch: 26/31	Total Loss 0.3944 (0.4189)
2022-11-02 23:32:29,499:INFO: Batch: 27/31	Total Loss 0.4016 (0.4183)
2022-11-02 23:32:29,548:INFO: Batch: 28/31	Total Loss 0.4249 (0.4185)
2022-11-02 23:32:29,601:INFO: Batch: 29/31	Total Loss 0.3994 (0.4179)
2022-11-02 23:32:29,632:INFO: Batch: 30/31	Total Loss 0.1436 (0.4156)
2022-11-02 23:32:29,793:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_38.pth.tar
2022-11-02 23:32:29,793:INFO: 
===> EPOCH: 39 (P1)
2022-11-02 23:32:29,793:INFO: - Computing loss (training)
2022-11-02 23:32:30,458:INFO: Batch:  0/31	Total Loss 0.3673 (0.3673)
2022-11-02 23:32:30,508:INFO: Batch:  1/31	Total Loss 0.4065 (0.3873)
2022-11-02 23:32:30,562:INFO: Batch:  2/31	Total Loss 0.3703 (0.3811)
2022-11-02 23:32:30,616:INFO: Batch:  3/31	Total Loss 0.3876 (0.3827)
2022-11-02 23:32:30,666:INFO: Batch:  4/31	Total Loss 0.3679 (0.3796)
2022-11-02 23:32:30,720:INFO: Batch:  5/31	Total Loss 0.4023 (0.3836)
2022-11-02 23:32:30,770:INFO: Batch:  6/31	Total Loss 0.4034 (0.3866)
2022-11-02 23:32:30,821:INFO: Batch:  7/31	Total Loss 0.3937 (0.3876)
2022-11-02 23:32:30,869:INFO: Batch:  8/31	Total Loss 0.4081 (0.3899)
2022-11-02 23:32:30,920:INFO: Batch:  9/31	Total Loss 0.3664 (0.3874)
2022-11-02 23:32:30,970:INFO: Batch: 10/31	Total Loss 0.3945 (0.3881)
2022-11-02 23:32:31,018:INFO: Batch: 11/31	Total Loss 0.3975 (0.3889)
2022-11-02 23:32:31,067:INFO: Batch: 12/31	Total Loss 0.3912 (0.3891)
2022-11-02 23:32:31,120:INFO: Batch: 13/31	Total Loss 0.4116 (0.3907)
2022-11-02 23:32:31,171:INFO: Batch: 14/31	Total Loss 0.3729 (0.3895)
2022-11-02 23:32:31,223:INFO: Batch: 15/31	Total Loss 0.3696 (0.3882)
2022-11-02 23:32:31,273:INFO: Batch: 16/31	Total Loss 0.3714 (0.3871)
2022-11-02 23:32:31,324:INFO: Batch: 17/31	Total Loss 0.3886 (0.3872)
2022-11-02 23:32:31,378:INFO: Batch: 18/31	Total Loss 0.3917 (0.3875)
2022-11-02 23:32:31,429:INFO: Batch: 19/31	Total Loss 0.3925 (0.3877)
2022-11-02 23:32:31,479:INFO: Batch: 20/31	Total Loss 0.3848 (0.3876)
2022-11-02 23:32:31,530:INFO: Batch: 21/31	Total Loss 0.3764 (0.3870)
2022-11-02 23:32:31,582:INFO: Batch: 22/31	Total Loss 0.3788 (0.3866)
2022-11-02 23:32:31,633:INFO: Batch: 23/31	Total Loss 0.3958 (0.3870)
2022-11-02 23:32:31,684:INFO: Batch: 24/31	Total Loss 0.3846 (0.3869)
2022-11-02 23:32:31,734:INFO: Batch: 25/31	Total Loss 0.3877 (0.3870)
2022-11-02 23:32:31,786:INFO: Batch: 26/31	Total Loss 0.3965 (0.3873)
2022-11-02 23:32:31,837:INFO: Batch: 27/31	Total Loss 0.3806 (0.3871)
2022-11-02 23:32:31,887:INFO: Batch: 28/31	Total Loss 0.3970 (0.3874)
2022-11-02 23:32:31,937:INFO: Batch: 29/31	Total Loss 0.3640 (0.3866)
2022-11-02 23:32:31,970:INFO: Batch: 30/31	Total Loss 0.1694 (0.3847)
2022-11-02 23:32:32,113:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_39.pth.tar
2022-11-02 23:32:32,113:INFO: 
===> EPOCH: 40 (P1)
2022-11-02 23:32:32,113:INFO: - Computing loss (training)
2022-11-02 23:32:32,791:INFO: Batch:  0/31	Total Loss 0.3961 (0.3961)
2022-11-02 23:32:32,841:INFO: Batch:  1/31	Total Loss 0.3571 (0.3770)
2022-11-02 23:32:32,899:INFO: Batch:  2/31	Total Loss 0.4046 (0.3857)
2022-11-02 23:32:32,953:INFO: Batch:  3/31	Total Loss 0.3650 (0.3805)
2022-11-02 23:32:33,002:INFO: Batch:  4/31	Total Loss 0.3604 (0.3766)
2022-11-02 23:32:33,057:INFO: Batch:  5/31	Total Loss 0.3786 (0.3769)
2022-11-02 23:32:33,106:INFO: Batch:  6/31	Total Loss 0.3823 (0.3776)
2022-11-02 23:32:33,152:INFO: Batch:  7/31	Total Loss 0.3564 (0.3748)
2022-11-02 23:32:33,200:INFO: Batch:  8/31	Total Loss 0.3549 (0.3727)
2022-11-02 23:32:33,249:INFO: Batch:  9/31	Total Loss 0.3714 (0.3726)
2022-11-02 23:32:33,296:INFO: Batch: 10/31	Total Loss 0.4230 (0.3769)
2022-11-02 23:32:33,344:INFO: Batch: 11/31	Total Loss 0.3433 (0.3741)
2022-11-02 23:32:33,392:INFO: Batch: 12/31	Total Loss 0.3597 (0.3730)
2022-11-02 23:32:33,440:INFO: Batch: 13/31	Total Loss 0.3817 (0.3735)
2022-11-02 23:32:33,492:INFO: Batch: 14/31	Total Loss 0.3569 (0.3723)
2022-11-02 23:32:33,544:INFO: Batch: 15/31	Total Loss 0.4069 (0.3747)
2022-11-02 23:32:33,593:INFO: Batch: 16/31	Total Loss 0.3999 (0.3762)
2022-11-02 23:32:33,642:INFO: Batch: 17/31	Total Loss 0.3526 (0.3749)
2022-11-02 23:32:33,691:INFO: Batch: 18/31	Total Loss 0.3639 (0.3744)
2022-11-02 23:32:33,742:INFO: Batch: 19/31	Total Loss 0.3852 (0.3749)
2022-11-02 23:32:33,792:INFO: Batch: 20/31	Total Loss 0.3860 (0.3754)
2022-11-02 23:32:33,841:INFO: Batch: 21/31	Total Loss 0.3704 (0.3752)
2022-11-02 23:32:33,889:INFO: Batch: 22/31	Total Loss 0.3880 (0.3758)
2022-11-02 23:32:33,939:INFO: Batch: 23/31	Total Loss 0.3697 (0.3755)
2022-11-02 23:32:33,989:INFO: Batch: 24/31	Total Loss 0.3645 (0.3751)
2022-11-02 23:32:34,039:INFO: Batch: 25/31	Total Loss 0.3952 (0.3758)
2022-11-02 23:32:34,088:INFO: Batch: 26/31	Total Loss 0.3596 (0.3752)
2022-11-02 23:32:34,138:INFO: Batch: 27/31	Total Loss 0.3860 (0.3756)
2022-11-02 23:32:34,189:INFO: Batch: 28/31	Total Loss 0.3676 (0.3753)
2022-11-02 23:32:34,240:INFO: Batch: 29/31	Total Loss 0.3695 (0.3752)
2022-11-02 23:32:34,272:INFO: Batch: 30/31	Total Loss 0.1416 (0.3730)
2022-11-02 23:32:34,420:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_40.pth.tar
2022-11-02 23:32:34,421:INFO: 
===> EPOCH: 41 (P1)
2022-11-02 23:32:34,421:INFO: - Computing loss (training)
2022-11-02 23:32:35,072:INFO: Batch:  0/31	Total Loss 0.3739 (0.3739)
2022-11-02 23:32:35,124:INFO: Batch:  1/31	Total Loss 0.3825 (0.3782)
2022-11-02 23:32:35,174:INFO: Batch:  2/31	Total Loss 0.3703 (0.3756)
2022-11-02 23:32:35,225:INFO: Batch:  3/31	Total Loss 0.3790 (0.3764)
2022-11-02 23:32:35,273:INFO: Batch:  4/31	Total Loss 0.3742 (0.3760)
2022-11-02 23:32:35,328:INFO: Batch:  5/31	Total Loss 0.3839 (0.3772)
2022-11-02 23:32:35,376:INFO: Batch:  6/31	Total Loss 0.3747 (0.3768)
2022-11-02 23:32:35,425:INFO: Batch:  7/31	Total Loss 0.3939 (0.3790)
2022-11-02 23:32:35,473:INFO: Batch:  8/31	Total Loss 0.3650 (0.3774)
2022-11-02 23:32:35,519:INFO: Batch:  9/31	Total Loss 0.4481 (0.3841)
2022-11-02 23:32:35,570:INFO: Batch: 10/31	Total Loss 0.3602 (0.3821)
2022-11-02 23:32:35,620:INFO: Batch: 11/31	Total Loss 0.3521 (0.3797)
2022-11-02 23:32:35,671:INFO: Batch: 12/31	Total Loss 0.3333 (0.3762)
2022-11-02 23:32:35,720:INFO: Batch: 13/31	Total Loss 0.3294 (0.3733)
2022-11-02 23:32:35,770:INFO: Batch: 14/31	Total Loss 0.3715 (0.3731)
2022-11-02 23:32:35,822:INFO: Batch: 15/31	Total Loss 0.3677 (0.3728)
2022-11-02 23:32:35,872:INFO: Batch: 16/31	Total Loss 0.3661 (0.3724)
2022-11-02 23:32:35,922:INFO: Batch: 17/31	Total Loss 0.3467 (0.3708)
2022-11-02 23:32:35,972:INFO: Batch: 18/31	Total Loss 0.3668 (0.3706)
2022-11-02 23:32:36,025:INFO: Batch: 19/31	Total Loss 0.3587 (0.3700)
2022-11-02 23:32:36,075:INFO: Batch: 20/31	Total Loss 0.3774 (0.3703)
2022-11-02 23:32:36,125:INFO: Batch: 21/31	Total Loss 0.3736 (0.3705)
2022-11-02 23:32:36,254:INFO: Batch: 22/31	Total Loss 0.3596 (0.3699)
2022-11-02 23:32:36,303:INFO: Batch: 23/31	Total Loss 0.3474 (0.3690)
2022-11-02 23:32:36,352:INFO: Batch: 24/31	Total Loss 0.3574 (0.3686)
2022-11-02 23:32:36,402:INFO: Batch: 25/31	Total Loss 0.3495 (0.3679)
2022-11-02 23:32:36,452:INFO: Batch: 26/31	Total Loss 0.3390 (0.3669)
2022-11-02 23:32:36,505:INFO: Batch: 27/31	Total Loss 0.3612 (0.3667)
2022-11-02 23:32:36,556:INFO: Batch: 28/31	Total Loss 0.3386 (0.3658)
2022-11-02 23:32:36,606:INFO: Batch: 29/31	Total Loss 0.3883 (0.3665)
2022-11-02 23:32:36,637:INFO: Batch: 30/31	Total Loss 0.1426 (0.3646)
2022-11-02 23:32:36,789:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_41.pth.tar
2022-11-02 23:32:36,789:INFO: 
===> EPOCH: 42 (P1)
2022-11-02 23:32:36,789:INFO: - Computing loss (training)
2022-11-02 23:32:37,493:INFO: Batch:  0/31	Total Loss 0.3493 (0.3493)
2022-11-02 23:32:37,544:INFO: Batch:  1/31	Total Loss 0.3917 (0.3683)
2022-11-02 23:32:37,595:INFO: Batch:  2/31	Total Loss 0.3626 (0.3665)
2022-11-02 23:32:37,643:INFO: Batch:  3/31	Total Loss 0.3660 (0.3663)
2022-11-02 23:32:37,693:INFO: Batch:  4/31	Total Loss 0.3603 (0.3652)
2022-11-02 23:32:37,743:INFO: Batch:  5/31	Total Loss 0.3618 (0.3646)
2022-11-02 23:32:37,792:INFO: Batch:  6/31	Total Loss 0.3567 (0.3636)
2022-11-02 23:32:37,839:INFO: Batch:  7/31	Total Loss 0.3426 (0.3608)
2022-11-02 23:32:37,885:INFO: Batch:  8/31	Total Loss 0.3669 (0.3614)
2022-11-02 23:32:37,933:INFO: Batch:  9/31	Total Loss 0.3367 (0.3587)
2022-11-02 23:32:37,982:INFO: Batch: 10/31	Total Loss 0.3427 (0.3572)
2022-11-02 23:32:38,029:INFO: Batch: 11/31	Total Loss 0.3580 (0.3573)
2022-11-02 23:32:38,077:INFO: Batch: 12/31	Total Loss 0.3416 (0.3561)
2022-11-02 23:32:38,126:INFO: Batch: 13/31	Total Loss 0.3396 (0.3550)
2022-11-02 23:32:38,177:INFO: Batch: 14/31	Total Loss 0.3309 (0.3535)
2022-11-02 23:32:38,228:INFO: Batch: 15/31	Total Loss 0.3340 (0.3523)
2022-11-02 23:32:38,277:INFO: Batch: 16/31	Total Loss 0.3012 (0.3493)
2022-11-02 23:32:38,325:INFO: Batch: 17/31	Total Loss 0.3389 (0.3487)
2022-11-02 23:32:38,375:INFO: Batch: 18/31	Total Loss 0.3357 (0.3480)
2022-11-02 23:32:38,427:INFO: Batch: 19/31	Total Loss 0.3282 (0.3470)
2022-11-02 23:32:38,477:INFO: Batch: 20/31	Total Loss 0.3510 (0.3472)
2022-11-02 23:32:38,525:INFO: Batch: 21/31	Total Loss 0.3260 (0.3462)
2022-11-02 23:32:38,573:INFO: Batch: 22/31	Total Loss 0.3895 (0.3481)
2022-11-02 23:32:38,622:INFO: Batch: 23/31	Total Loss 0.3487 (0.3481)
2022-11-02 23:32:38,674:INFO: Batch: 24/31	Total Loss 0.3621 (0.3486)
2022-11-02 23:32:38,724:INFO: Batch: 25/31	Total Loss 0.3382 (0.3482)
2022-11-02 23:32:38,772:INFO: Batch: 26/31	Total Loss 0.3511 (0.3483)
2022-11-02 23:32:38,820:INFO: Batch: 27/31	Total Loss 0.3289 (0.3477)
2022-11-02 23:32:38,869:INFO: Batch: 28/31	Total Loss 0.3423 (0.3475)
2022-11-02 23:32:38,919:INFO: Batch: 29/31	Total Loss 0.3737 (0.3483)
2022-11-02 23:32:38,951:INFO: Batch: 30/31	Total Loss 0.1342 (0.3461)
2022-11-02 23:32:39,094:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_42.pth.tar
2022-11-02 23:32:39,094:INFO: 
===> EPOCH: 43 (P1)
2022-11-02 23:32:39,094:INFO: - Computing loss (training)
2022-11-02 23:32:39,784:INFO: Batch:  0/31	Total Loss 0.3269 (0.3269)
2022-11-02 23:32:39,835:INFO: Batch:  1/31	Total Loss 0.3501 (0.3380)
2022-11-02 23:32:39,887:INFO: Batch:  2/31	Total Loss 0.3583 (0.3441)
2022-11-02 23:32:39,934:INFO: Batch:  3/31	Total Loss 0.3449 (0.3442)
2022-11-02 23:32:39,986:INFO: Batch:  4/31	Total Loss 0.3528 (0.3458)
2022-11-02 23:32:40,036:INFO: Batch:  5/31	Total Loss 0.3220 (0.3418)
2022-11-02 23:32:40,084:INFO: Batch:  6/31	Total Loss 0.3169 (0.3379)
2022-11-02 23:32:40,130:INFO: Batch:  7/31	Total Loss 0.3547 (0.3400)
2022-11-02 23:32:40,177:INFO: Batch:  8/31	Total Loss 0.3252 (0.3385)
2022-11-02 23:32:40,225:INFO: Batch:  9/31	Total Loss 0.3213 (0.3368)
2022-11-02 23:32:40,275:INFO: Batch: 10/31	Total Loss 0.3284 (0.3361)
2022-11-02 23:32:40,321:INFO: Batch: 11/31	Total Loss 0.3082 (0.3340)
2022-11-02 23:32:40,369:INFO: Batch: 12/31	Total Loss 0.3483 (0.3351)
2022-11-02 23:32:40,419:INFO: Batch: 13/31	Total Loss 0.3144 (0.3335)
2022-11-02 23:32:40,470:INFO: Batch: 14/31	Total Loss 0.3408 (0.3339)
2022-11-02 23:32:40,521:INFO: Batch: 15/31	Total Loss 0.3034 (0.3320)
2022-11-02 23:32:40,570:INFO: Batch: 16/31	Total Loss 0.3579 (0.3336)
2022-11-02 23:32:40,620:INFO: Batch: 17/31	Total Loss 0.3442 (0.3342)
2022-11-02 23:32:40,670:INFO: Batch: 18/31	Total Loss 0.3481 (0.3349)
2022-11-02 23:32:40,723:INFO: Batch: 19/31	Total Loss 0.3498 (0.3357)
2022-11-02 23:32:40,772:INFO: Batch: 20/31	Total Loss 0.3335 (0.3355)
2022-11-02 23:32:40,822:INFO: Batch: 21/31	Total Loss 0.3095 (0.3344)
2022-11-02 23:32:40,870:INFO: Batch: 22/31	Total Loss 0.3115 (0.3333)
2022-11-02 23:32:40,918:INFO: Batch: 23/31	Total Loss 0.3183 (0.3328)
2022-11-02 23:32:40,970:INFO: Batch: 24/31	Total Loss 0.3418 (0.3331)
2022-11-02 23:32:41,020:INFO: Batch: 25/31	Total Loss 0.3395 (0.3333)
2022-11-02 23:32:41,068:INFO: Batch: 26/31	Total Loss 0.3467 (0.3338)
2022-11-02 23:32:41,118:INFO: Batch: 27/31	Total Loss 0.3363 (0.3339)
2022-11-02 23:32:41,166:INFO: Batch: 28/31	Total Loss 0.3110 (0.3331)
2022-11-02 23:32:41,216:INFO: Batch: 29/31	Total Loss 0.3251 (0.3328)
2022-11-02 23:32:41,247:INFO: Batch: 30/31	Total Loss 0.1472 (0.3315)
2022-11-02 23:32:41,403:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_43.pth.tar
2022-11-02 23:32:41,403:INFO: 
===> EPOCH: 44 (P1)
2022-11-02 23:32:41,403:INFO: - Computing loss (training)
2022-11-02 23:32:42,088:INFO: Batch:  0/31	Total Loss 0.3436 (0.3436)
2022-11-02 23:32:42,136:INFO: Batch:  1/31	Total Loss 0.3158 (0.3307)
2022-11-02 23:32:42,188:INFO: Batch:  2/31	Total Loss 0.3081 (0.3236)
2022-11-02 23:32:42,239:INFO: Batch:  3/31	Total Loss 0.3100 (0.3204)
2022-11-02 23:32:42,286:INFO: Batch:  4/31	Total Loss 0.3304 (0.3223)
2022-11-02 23:32:42,336:INFO: Batch:  5/31	Total Loss 0.3076 (0.3200)
2022-11-02 23:32:42,385:INFO: Batch:  6/31	Total Loss 0.3350 (0.3222)
2022-11-02 23:32:42,432:INFO: Batch:  7/31	Total Loss 0.3188 (0.3218)
2022-11-02 23:32:42,480:INFO: Batch:  8/31	Total Loss 0.3317 (0.3229)
2022-11-02 23:32:42,528:INFO: Batch:  9/31	Total Loss 0.3267 (0.3233)
2022-11-02 23:32:42,577:INFO: Batch: 10/31	Total Loss 0.3159 (0.3227)
2022-11-02 23:32:42,625:INFO: Batch: 11/31	Total Loss 0.3207 (0.3225)
2022-11-02 23:32:42,676:INFO: Batch: 12/31	Total Loss 0.3557 (0.3251)
2022-11-02 23:32:42,727:INFO: Batch: 13/31	Total Loss 0.3105 (0.3242)
2022-11-02 23:32:42,776:INFO: Batch: 14/31	Total Loss 0.3402 (0.3253)
2022-11-02 23:32:42,828:INFO: Batch: 15/31	Total Loss 0.3124 (0.3245)
2022-11-02 23:32:42,878:INFO: Batch: 16/31	Total Loss 0.3132 (0.3237)
2022-11-02 23:32:42,929:INFO: Batch: 17/31	Total Loss 0.3222 (0.3237)
2022-11-02 23:32:42,978:INFO: Batch: 18/31	Total Loss 0.3113 (0.3230)
2022-11-02 23:32:43,027:INFO: Batch: 19/31	Total Loss 0.3052 (0.3221)
2022-11-02 23:32:43,079:INFO: Batch: 20/31	Total Loss 0.3058 (0.3214)
2022-11-02 23:32:43,129:INFO: Batch: 21/31	Total Loss 0.3335 (0.3220)
2022-11-02 23:32:43,178:INFO: Batch: 22/31	Total Loss 0.3141 (0.3217)
2022-11-02 23:32:43,228:INFO: Batch: 23/31	Total Loss 0.2961 (0.3206)
2022-11-02 23:32:43,277:INFO: Batch: 24/31	Total Loss 0.2993 (0.3197)
2022-11-02 23:32:43,329:INFO: Batch: 25/31	Total Loss 0.3594 (0.3213)
2022-11-02 23:32:43,379:INFO: Batch: 26/31	Total Loss 0.3042 (0.3206)
2022-11-02 23:32:43,428:INFO: Batch: 27/31	Total Loss 0.3269 (0.3208)
2022-11-02 23:32:43,477:INFO: Batch: 28/31	Total Loss 0.3503 (0.3218)
2022-11-02 23:32:43,526:INFO: Batch: 29/31	Total Loss 0.3303 (0.3221)
2022-11-02 23:32:43,559:INFO: Batch: 30/31	Total Loss 0.1020 (0.3202)
2022-11-02 23:32:43,710:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_44.pth.tar
2022-11-02 23:32:43,710:INFO: 
===> EPOCH: 45 (P1)
2022-11-02 23:32:43,710:INFO: - Computing loss (training)
2022-11-02 23:32:44,365:INFO: Batch:  0/31	Total Loss 0.3169 (0.3169)
2022-11-02 23:32:44,414:INFO: Batch:  1/31	Total Loss 0.2982 (0.3072)
2022-11-02 23:32:44,469:INFO: Batch:  2/31	Total Loss 0.2940 (0.3026)
2022-11-02 23:32:44,518:INFO: Batch:  3/31	Total Loss 0.3002 (0.3020)
2022-11-02 23:32:44,567:INFO: Batch:  4/31	Total Loss 0.3195 (0.3055)
2022-11-02 23:32:44,622:INFO: Batch:  5/31	Total Loss 0.3106 (0.3064)
2022-11-02 23:32:44,670:INFO: Batch:  6/31	Total Loss 0.3002 (0.3055)
2022-11-02 23:32:44,720:INFO: Batch:  7/31	Total Loss 0.3073 (0.3058)
2022-11-02 23:32:44,768:INFO: Batch:  8/31	Total Loss 0.3255 (0.3077)
2022-11-02 23:32:44,815:INFO: Batch:  9/31	Total Loss 0.3011 (0.3071)
2022-11-02 23:32:44,866:INFO: Batch: 10/31	Total Loss 0.3003 (0.3064)
2022-11-02 23:32:44,916:INFO: Batch: 11/31	Total Loss 0.2975 (0.3056)
2022-11-02 23:32:44,966:INFO: Batch: 12/31	Total Loss 0.3148 (0.3063)
2022-11-02 23:32:45,016:INFO: Batch: 13/31	Total Loss 0.2902 (0.3051)
2022-11-02 23:32:45,066:INFO: Batch: 14/31	Total Loss 0.3111 (0.3055)
2022-11-02 23:32:45,118:INFO: Batch: 15/31	Total Loss 0.3168 (0.3062)
2022-11-02 23:32:45,170:INFO: Batch: 16/31	Total Loss 0.3106 (0.3064)
2022-11-02 23:32:45,221:INFO: Batch: 17/31	Total Loss 0.3102 (0.3067)
2022-11-02 23:32:45,271:INFO: Batch: 18/31	Total Loss 0.2919 (0.3059)
2022-11-02 23:32:45,319:INFO: Batch: 19/31	Total Loss 0.3069 (0.3059)
2022-11-02 23:32:45,370:INFO: Batch: 20/31	Total Loss 0.3017 (0.3057)
2022-11-02 23:32:45,419:INFO: Batch: 21/31	Total Loss 0.2967 (0.3053)
2022-11-02 23:32:45,468:INFO: Batch: 22/31	Total Loss 0.3003 (0.3050)
2022-11-02 23:32:45,516:INFO: Batch: 23/31	Total Loss 0.3020 (0.3049)
2022-11-02 23:32:45,567:INFO: Batch: 24/31	Total Loss 0.3004 (0.3047)
2022-11-02 23:32:45,617:INFO: Batch: 25/31	Total Loss 0.2901 (0.3042)
2022-11-02 23:32:45,666:INFO: Batch: 26/31	Total Loss 0.2944 (0.3038)
2022-11-02 23:32:45,715:INFO: Batch: 27/31	Total Loss 0.3189 (0.3043)
2022-11-02 23:32:45,763:INFO: Batch: 28/31	Total Loss 0.3040 (0.3043)
2022-11-02 23:32:45,814:INFO: Batch: 29/31	Total Loss 0.3196 (0.3049)
2022-11-02 23:32:45,845:INFO: Batch: 30/31	Total Loss 0.1084 (0.3026)
2022-11-02 23:32:45,990:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_45.pth.tar
2022-11-02 23:32:45,990:INFO: 
===> EPOCH: 46 (P1)
2022-11-02 23:32:45,991:INFO: - Computing loss (training)
2022-11-02 23:32:46,683:INFO: Batch:  0/31	Total Loss 0.3091 (0.3091)
2022-11-02 23:32:46,731:INFO: Batch:  1/31	Total Loss 0.3070 (0.3081)
2022-11-02 23:32:46,790:INFO: Batch:  2/31	Total Loss 0.3026 (0.3063)
2022-11-02 23:32:46,840:INFO: Batch:  3/31	Total Loss 0.2884 (0.3015)
2022-11-02 23:32:46,888:INFO: Batch:  4/31	Total Loss 0.3020 (0.3016)
2022-11-02 23:32:46,940:INFO: Batch:  5/31	Total Loss 0.2873 (0.2991)
2022-11-02 23:32:46,988:INFO: Batch:  6/31	Total Loss 0.2683 (0.2948)
2022-11-02 23:32:47,034:INFO: Batch:  7/31	Total Loss 0.2989 (0.2953)
2022-11-02 23:32:47,081:INFO: Batch:  8/31	Total Loss 0.2803 (0.2937)
2022-11-02 23:32:47,129:INFO: Batch:  9/31	Total Loss 0.2775 (0.2922)
2022-11-02 23:32:47,176:INFO: Batch: 10/31	Total Loss 0.3175 (0.2943)
2022-11-02 23:32:47,224:INFO: Batch: 11/31	Total Loss 0.3157 (0.2961)
2022-11-02 23:32:47,273:INFO: Batch: 12/31	Total Loss 0.2762 (0.2944)
2022-11-02 23:32:47,323:INFO: Batch: 13/31	Total Loss 0.2893 (0.2940)
2022-11-02 23:32:47,374:INFO: Batch: 14/31	Total Loss 0.2775 (0.2929)
2022-11-02 23:32:47,424:INFO: Batch: 15/31	Total Loss 0.2907 (0.2928)
2022-11-02 23:32:47,474:INFO: Batch: 16/31	Total Loss 0.3139 (0.2941)
2022-11-02 23:32:47,524:INFO: Batch: 17/31	Total Loss 0.2998 (0.2944)
2022-11-02 23:32:47,573:INFO: Batch: 18/31	Total Loss 0.2980 (0.2946)
2022-11-02 23:32:47,624:INFO: Batch: 19/31	Total Loss 0.2931 (0.2945)
2022-11-02 23:32:47,674:INFO: Batch: 20/31	Total Loss 0.2799 (0.2938)
2022-11-02 23:32:47,724:INFO: Batch: 21/31	Total Loss 0.2884 (0.2935)
2022-11-02 23:32:47,773:INFO: Batch: 22/31	Total Loss 0.2763 (0.2927)
2022-11-02 23:32:47,824:INFO: Batch: 23/31	Total Loss 0.2888 (0.2926)
2022-11-02 23:32:47,874:INFO: Batch: 24/31	Total Loss 0.3094 (0.2933)
2022-11-02 23:32:47,922:INFO: Batch: 25/31	Total Loss 0.2825 (0.2928)
2022-11-02 23:32:47,972:INFO: Batch: 26/31	Total Loss 0.2683 (0.2918)
2022-11-02 23:32:48,020:INFO: Batch: 27/31	Total Loss 0.3067 (0.2923)
2022-11-02 23:32:48,072:INFO: Batch: 28/31	Total Loss 0.2876 (0.2921)
2022-11-02 23:32:48,122:INFO: Batch: 29/31	Total Loss 0.3005 (0.2924)
2022-11-02 23:32:48,153:INFO: Batch: 30/31	Total Loss 0.1176 (0.2908)
2022-11-02 23:32:48,307:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_46.pth.tar
2022-11-02 23:32:48,307:INFO: 
===> EPOCH: 47 (P1)
2022-11-02 23:32:48,308:INFO: - Computing loss (training)
2022-11-02 23:32:49,011:INFO: Batch:  0/31	Total Loss 0.2833 (0.2833)
2022-11-02 23:32:49,062:INFO: Batch:  1/31	Total Loss 0.2860 (0.2847)
2022-11-02 23:32:49,114:INFO: Batch:  2/31	Total Loss 0.2786 (0.2826)
2022-11-02 23:32:49,163:INFO: Batch:  3/31	Total Loss 0.2676 (0.2788)
2022-11-02 23:32:49,211:INFO: Batch:  4/31	Total Loss 0.2864 (0.2803)
2022-11-02 23:32:49,266:INFO: Batch:  5/31	Total Loss 0.2859 (0.2812)
2022-11-02 23:32:49,317:INFO: Batch:  6/31	Total Loss 0.2894 (0.2824)
2022-11-02 23:32:49,363:INFO: Batch:  7/31	Total Loss 0.2825 (0.2824)
2022-11-02 23:32:49,411:INFO: Batch:  8/31	Total Loss 0.2792 (0.2821)
2022-11-02 23:32:49,460:INFO: Batch:  9/31	Total Loss 0.2856 (0.2824)
2022-11-02 23:32:49,507:INFO: Batch: 10/31	Total Loss 0.2885 (0.2830)
2022-11-02 23:32:49,556:INFO: Batch: 11/31	Total Loss 0.2933 (0.2839)
2022-11-02 23:32:49,606:INFO: Batch: 12/31	Total Loss 0.3040 (0.2852)
2022-11-02 23:32:49,656:INFO: Batch: 13/31	Total Loss 0.2680 (0.2840)
2022-11-02 23:32:49,708:INFO: Batch: 14/31	Total Loss 0.2746 (0.2834)
2022-11-02 23:32:49,759:INFO: Batch: 15/31	Total Loss 0.3073 (0.2850)
2022-11-02 23:32:49,809:INFO: Batch: 16/31	Total Loss 0.2989 (0.2858)
2022-11-02 23:32:49,858:INFO: Batch: 17/31	Total Loss 0.2882 (0.2859)
2022-11-02 23:32:49,909:INFO: Batch: 18/31	Total Loss 0.2924 (0.2863)
2022-11-02 23:32:49,961:INFO: Batch: 19/31	Total Loss 0.2651 (0.2852)
2022-11-02 23:32:50,011:INFO: Batch: 20/31	Total Loss 0.2943 (0.2857)
2022-11-02 23:32:50,061:INFO: Batch: 21/31	Total Loss 0.2858 (0.2857)
2022-11-02 23:32:50,110:INFO: Batch: 22/31	Total Loss 0.2706 (0.2850)
2022-11-02 23:32:50,159:INFO: Batch: 23/31	Total Loss 0.2814 (0.2849)
2022-11-02 23:32:50,209:INFO: Batch: 24/31	Total Loss 0.2971 (0.2854)
2022-11-02 23:32:50,260:INFO: Batch: 25/31	Total Loss 0.2704 (0.2848)
2022-11-02 23:32:50,308:INFO: Batch: 26/31	Total Loss 0.2839 (0.2848)
2022-11-02 23:32:50,357:INFO: Batch: 27/31	Total Loss 0.2645 (0.2841)
2022-11-02 23:32:50,407:INFO: Batch: 28/31	Total Loss 0.2855 (0.2842)
2022-11-02 23:32:50,459:INFO: Batch: 29/31	Total Loss 0.2705 (0.2837)
2022-11-02 23:32:50,490:INFO: Batch: 30/31	Total Loss 0.1054 (0.2817)
2022-11-02 23:32:50,650:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_47.pth.tar
2022-11-02 23:32:50,650:INFO: 
===> EPOCH: 48 (P1)
2022-11-02 23:32:50,650:INFO: - Computing loss (training)
2022-11-02 23:32:51,364:INFO: Batch:  0/31	Total Loss 0.2802 (0.2802)
2022-11-02 23:32:51,420:INFO: Batch:  1/31	Total Loss 0.2620 (0.2716)
2022-11-02 23:32:51,472:INFO: Batch:  2/31	Total Loss 0.2667 (0.2699)
2022-11-02 23:32:51,519:INFO: Batch:  3/31	Total Loss 0.2966 (0.2766)
2022-11-02 23:32:51,566:INFO: Batch:  4/31	Total Loss 0.2864 (0.2788)
2022-11-02 23:32:51,623:INFO: Batch:  5/31	Total Loss 0.2923 (0.2811)
2022-11-02 23:32:51,672:INFO: Batch:  6/31	Total Loss 0.2816 (0.2812)
2022-11-02 23:32:51,722:INFO: Batch:  7/31	Total Loss 0.2964 (0.2831)
2022-11-02 23:32:51,769:INFO: Batch:  8/31	Total Loss 0.2577 (0.2799)
2022-11-02 23:32:51,816:INFO: Batch:  9/31	Total Loss 0.2772 (0.2796)
2022-11-02 23:32:51,865:INFO: Batch: 10/31	Total Loss 0.2562 (0.2772)
2022-11-02 23:32:51,914:INFO: Batch: 11/31	Total Loss 0.2519 (0.2749)
2022-11-02 23:32:51,964:INFO: Batch: 12/31	Total Loss 0.2900 (0.2762)
2022-11-02 23:32:52,014:INFO: Batch: 13/31	Total Loss 0.2784 (0.2764)
2022-11-02 23:32:52,064:INFO: Batch: 14/31	Total Loss 0.2785 (0.2765)
2022-11-02 23:32:52,116:INFO: Batch: 15/31	Total Loss 0.2679 (0.2759)
2022-11-02 23:32:52,167:INFO: Batch: 16/31	Total Loss 0.2701 (0.2756)
2022-11-02 23:32:52,217:INFO: Batch: 17/31	Total Loss 0.2592 (0.2746)
2022-11-02 23:32:52,267:INFO: Batch: 18/31	Total Loss 0.2603 (0.2739)
2022-11-02 23:32:52,316:INFO: Batch: 19/31	Total Loss 0.2461 (0.2725)
2022-11-02 23:32:52,368:INFO: Batch: 20/31	Total Loss 0.2639 (0.2721)
2022-11-02 23:32:52,418:INFO: Batch: 21/31	Total Loss 0.2802 (0.2724)
2022-11-02 23:32:52,468:INFO: Batch: 22/31	Total Loss 0.2658 (0.2721)
2022-11-02 23:32:52,518:INFO: Batch: 23/31	Total Loss 0.2528 (0.2713)
2022-11-02 23:32:52,569:INFO: Batch: 24/31	Total Loss 0.2691 (0.2712)
2022-11-02 23:32:52,619:INFO: Batch: 25/31	Total Loss 0.2616 (0.2709)
2022-11-02 23:32:52,668:INFO: Batch: 26/31	Total Loss 0.2608 (0.2704)
2022-11-02 23:32:52,717:INFO: Batch: 27/31	Total Loss 0.2777 (0.2707)
2022-11-02 23:32:52,770:INFO: Batch: 28/31	Total Loss 0.2575 (0.2702)
2022-11-02 23:32:52,821:INFO: Batch: 29/31	Total Loss 0.2717 (0.2702)
2022-11-02 23:32:52,852:INFO: Batch: 30/31	Total Loss 0.0963 (0.2685)
2022-11-02 23:32:53,016:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_48.pth.tar
2022-11-02 23:32:53,016:INFO: 
===> EPOCH: 49 (P1)
2022-11-02 23:32:53,016:INFO: - Computing loss (training)
2022-11-02 23:32:53,723:INFO: Batch:  0/31	Total Loss 0.2615 (0.2615)
2022-11-02 23:32:53,773:INFO: Batch:  1/31	Total Loss 0.2588 (0.2601)
2022-11-02 23:32:53,824:INFO: Batch:  2/31	Total Loss 0.2556 (0.2586)
2022-11-02 23:32:53,878:INFO: Batch:  3/31	Total Loss 0.2727 (0.2626)
2022-11-02 23:32:53,931:INFO: Batch:  4/31	Total Loss 0.2431 (0.2587)
2022-11-02 23:32:53,980:INFO: Batch:  5/31	Total Loss 0.2592 (0.2588)
2022-11-02 23:32:54,028:INFO: Batch:  6/31	Total Loss 0.2532 (0.2581)
2022-11-02 23:32:54,076:INFO: Batch:  7/31	Total Loss 0.2687 (0.2593)
2022-11-02 23:32:54,122:INFO: Batch:  8/31	Total Loss 0.2613 (0.2595)
2022-11-02 23:32:54,171:INFO: Batch:  9/31	Total Loss 0.2774 (0.2613)
2022-11-02 23:32:54,223:INFO: Batch: 10/31	Total Loss 0.2664 (0.2618)
2022-11-02 23:32:54,269:INFO: Batch: 11/31	Total Loss 0.2651 (0.2620)
2022-11-02 23:32:54,320:INFO: Batch: 12/31	Total Loss 0.2482 (0.2609)
2022-11-02 23:32:54,369:INFO: Batch: 13/31	Total Loss 0.2539 (0.2604)
2022-11-02 23:32:54,421:INFO: Batch: 14/31	Total Loss 0.2343 (0.2585)
2022-11-02 23:32:54,472:INFO: Batch: 15/31	Total Loss 0.2578 (0.2585)
2022-11-02 23:32:54,523:INFO: Batch: 16/31	Total Loss 0.2548 (0.2583)
2022-11-02 23:32:54,573:INFO: Batch: 17/31	Total Loss 0.2524 (0.2579)
2022-11-02 23:32:54,623:INFO: Batch: 18/31	Total Loss 0.2655 (0.2584)
2022-11-02 23:32:54,675:INFO: Batch: 19/31	Total Loss 0.2398 (0.2575)
2022-11-02 23:32:54,724:INFO: Batch: 20/31	Total Loss 0.2417 (0.2568)
2022-11-02 23:32:54,774:INFO: Batch: 21/31	Total Loss 0.2569 (0.2568)
2022-11-02 23:32:54,823:INFO: Batch: 22/31	Total Loss 0.2686 (0.2573)
2022-11-02 23:32:54,872:INFO: Batch: 23/31	Total Loss 0.2708 (0.2579)
2022-11-02 23:32:54,924:INFO: Batch: 24/31	Total Loss 0.2482 (0.2575)
2022-11-02 23:32:54,972:INFO: Batch: 25/31	Total Loss 0.2657 (0.2577)
2022-11-02 23:32:55,022:INFO: Batch: 26/31	Total Loss 0.2511 (0.2575)
2022-11-02 23:32:55,072:INFO: Batch: 27/31	Total Loss 0.2625 (0.2577)
2022-11-02 23:32:55,121:INFO: Batch: 28/31	Total Loss 0.2602 (0.2578)
2022-11-02 23:32:55,171:INFO: Batch: 29/31	Total Loss 0.2514 (0.2576)
2022-11-02 23:32:55,203:INFO: Batch: 30/31	Total Loss 0.0868 (0.2562)
2022-11-02 23:32:55,348:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_49.pth.tar
2022-11-02 23:32:55,348:INFO: 
===> EPOCH: 50 (P1)
2022-11-02 23:32:55,348:INFO: - Computing loss (training)
2022-11-02 23:32:56,019:INFO: Batch:  0/31	Total Loss 0.2812 (0.2812)
2022-11-02 23:32:56,070:INFO: Batch:  1/31	Total Loss 0.2729 (0.2773)
2022-11-02 23:32:56,122:INFO: Batch:  2/31	Total Loss 0.2580 (0.2709)
2022-11-02 23:32:56,171:INFO: Batch:  3/31	Total Loss 0.2530 (0.2661)
2022-11-02 23:32:56,219:INFO: Batch:  4/31	Total Loss 0.2668 (0.2662)
2022-11-02 23:32:56,276:INFO: Batch:  5/31	Total Loss 0.2538 (0.2642)
2022-11-02 23:32:56,323:INFO: Batch:  6/31	Total Loss 0.2582 (0.2633)
2022-11-02 23:32:56,369:INFO: Batch:  7/31	Total Loss 0.2630 (0.2633)
2022-11-02 23:32:56,416:INFO: Batch:  8/31	Total Loss 0.2519 (0.2620)
2022-11-02 23:32:56,463:INFO: Batch:  9/31	Total Loss 0.2451 (0.2603)
2022-11-02 23:32:56,512:INFO: Batch: 10/31	Total Loss 0.2425 (0.2587)
2022-11-02 23:32:56,561:INFO: Batch: 11/31	Total Loss 0.2576 (0.2586)
2022-11-02 23:32:56,611:INFO: Batch: 12/31	Total Loss 0.2582 (0.2586)
2022-11-02 23:32:56,660:INFO: Batch: 13/31	Total Loss 0.2616 (0.2588)
2022-11-02 23:32:56,709:INFO: Batch: 14/31	Total Loss 0.2756 (0.2599)
2022-11-02 23:32:56,761:INFO: Batch: 15/31	Total Loss 0.2641 (0.2601)
2022-11-02 23:32:56,812:INFO: Batch: 16/31	Total Loss 0.2462 (0.2593)
2022-11-02 23:32:56,862:INFO: Batch: 17/31	Total Loss 0.2287 (0.2575)
2022-11-02 23:32:56,912:INFO: Batch: 18/31	Total Loss 0.2360 (0.2563)
2022-11-02 23:32:56,963:INFO: Batch: 19/31	Total Loss 0.2590 (0.2565)
2022-11-02 23:32:57,015:INFO: Batch: 20/31	Total Loss 0.2426 (0.2558)
2022-11-02 23:32:57,066:INFO: Batch: 21/31	Total Loss 0.2733 (0.2565)
2022-11-02 23:32:57,116:INFO: Batch: 22/31	Total Loss 0.2447 (0.2560)
2022-11-02 23:32:57,166:INFO: Batch: 23/31	Total Loss 0.2572 (0.2561)
2022-11-02 23:32:57,217:INFO: Batch: 24/31	Total Loss 0.2360 (0.2552)
2022-11-02 23:32:57,268:INFO: Batch: 25/31	Total Loss 0.2607 (0.2554)
2022-11-02 23:32:57,319:INFO: Batch: 26/31	Total Loss 0.2470 (0.2550)
2022-11-02 23:32:57,369:INFO: Batch: 27/31	Total Loss 0.2436 (0.2547)
2022-11-02 23:32:57,421:INFO: Batch: 28/31	Total Loss 0.2470 (0.2544)
2022-11-02 23:32:57,470:INFO: Batch: 29/31	Total Loss 0.2808 (0.2552)
2022-11-02 23:32:57,501:INFO: Batch: 30/31	Total Loss 0.0914 (0.2535)
2022-11-02 23:32:57,655:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_50.pth.tar
2022-11-02 23:32:57,655:INFO: 
===> EPOCH: 51 (P1)
2022-11-02 23:32:57,655:INFO: - Computing loss (training)
2022-11-02 23:32:58,366:INFO: Batch:  0/31	Total Loss 0.2338 (0.2338)
2022-11-02 23:32:58,418:INFO: Batch:  1/31	Total Loss 0.2593 (0.2458)
2022-11-02 23:32:58,473:INFO: Batch:  2/31	Total Loss 0.2577 (0.2499)
2022-11-02 23:32:58,520:INFO: Batch:  3/31	Total Loss 0.2376 (0.2466)
2022-11-02 23:32:58,571:INFO: Batch:  4/31	Total Loss 0.2416 (0.2458)
2022-11-02 23:32:58,624:INFO: Batch:  5/31	Total Loss 0.2450 (0.2457)
2022-11-02 23:32:58,672:INFO: Batch:  6/31	Total Loss 0.2282 (0.2432)
2022-11-02 23:32:58,719:INFO: Batch:  7/31	Total Loss 0.2419 (0.2430)
2022-11-02 23:32:58,766:INFO: Batch:  8/31	Total Loss 0.2509 (0.2439)
2022-11-02 23:32:58,815:INFO: Batch:  9/31	Total Loss 0.2648 (0.2457)
2022-11-02 23:32:58,866:INFO: Batch: 10/31	Total Loss 0.2711 (0.2480)
2022-11-02 23:32:58,913:INFO: Batch: 11/31	Total Loss 0.2325 (0.2467)
2022-11-02 23:32:58,963:INFO: Batch: 12/31	Total Loss 0.2496 (0.2470)
2022-11-02 23:32:59,013:INFO: Batch: 13/31	Total Loss 0.2469 (0.2470)
2022-11-02 23:32:59,066:INFO: Batch: 14/31	Total Loss 0.2474 (0.2470)
2022-11-02 23:32:59,117:INFO: Batch: 15/31	Total Loss 0.2497 (0.2472)
2022-11-02 23:32:59,166:INFO: Batch: 16/31	Total Loss 0.2562 (0.2477)
2022-11-02 23:32:59,216:INFO: Batch: 17/31	Total Loss 0.2360 (0.2471)
2022-11-02 23:32:59,266:INFO: Batch: 18/31	Total Loss 0.2250 (0.2460)
2022-11-02 23:32:59,317:INFO: Batch: 19/31	Total Loss 0.2349 (0.2454)
2022-11-02 23:32:59,366:INFO: Batch: 20/31	Total Loss 0.2376 (0.2451)
2022-11-02 23:32:59,416:INFO: Batch: 21/31	Total Loss 0.2424 (0.2450)
2022-11-02 23:32:59,467:INFO: Batch: 22/31	Total Loss 0.2439 (0.2449)
2022-11-02 23:32:59,518:INFO: Batch: 23/31	Total Loss 0.2427 (0.2448)
2022-11-02 23:32:59,567:INFO: Batch: 24/31	Total Loss 0.2461 (0.2449)
2022-11-02 23:32:59,617:INFO: Batch: 25/31	Total Loss 0.2274 (0.2443)
2022-11-02 23:32:59,666:INFO: Batch: 26/31	Total Loss 0.2341 (0.2439)
2022-11-02 23:32:59,715:INFO: Batch: 27/31	Total Loss 0.2600 (0.2445)
2022-11-02 23:32:59,767:INFO: Batch: 28/31	Total Loss 0.2321 (0.2440)
2022-11-02 23:32:59,817:INFO: Batch: 29/31	Total Loss 0.2400 (0.2439)
2022-11-02 23:32:59,847:INFO: Batch: 30/31	Total Loss 0.0907 (0.2423)
2022-11-02 23:33:00,000:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_51.pth.tar
2022-11-02 23:33:00,000:INFO: 
===> EPOCH: 52 (P1)
2022-11-02 23:33:00,001:INFO: - Computing loss (training)
2022-11-02 23:33:00,737:INFO: Batch:  0/31	Total Loss 0.2387 (0.2387)
2022-11-02 23:33:00,788:INFO: Batch:  1/31	Total Loss 0.2329 (0.2359)
2022-11-02 23:33:00,842:INFO: Batch:  2/31	Total Loss 0.2412 (0.2376)
2022-11-02 23:33:00,892:INFO: Batch:  3/31	Total Loss 0.2281 (0.2355)
2022-11-02 23:33:00,939:INFO: Batch:  4/31	Total Loss 0.2274 (0.2337)
2022-11-02 23:33:00,992:INFO: Batch:  5/31	Total Loss 0.2390 (0.2345)
2022-11-02 23:33:01,041:INFO: Batch:  6/31	Total Loss 0.2440 (0.2358)
2022-11-02 23:33:01,088:INFO: Batch:  7/31	Total Loss 0.2470 (0.2373)
2022-11-02 23:33:01,136:INFO: Batch:  8/31	Total Loss 0.2390 (0.2375)
2022-11-02 23:33:01,186:INFO: Batch:  9/31	Total Loss 0.2347 (0.2372)
2022-11-02 23:33:01,235:INFO: Batch: 10/31	Total Loss 0.2322 (0.2368)
2022-11-02 23:33:01,283:INFO: Batch: 11/31	Total Loss 0.2229 (0.2357)
2022-11-02 23:33:01,333:INFO: Batch: 12/31	Total Loss 0.2259 (0.2350)
2022-11-02 23:33:01,384:INFO: Batch: 13/31	Total Loss 0.2203 (0.2339)
2022-11-02 23:33:01,435:INFO: Batch: 14/31	Total Loss 0.2242 (0.2331)
2022-11-02 23:33:01,487:INFO: Batch: 15/31	Total Loss 0.2285 (0.2329)
2022-11-02 23:33:01,539:INFO: Batch: 16/31	Total Loss 0.2539 (0.2342)
2022-11-02 23:33:01,590:INFO: Batch: 17/31	Total Loss 0.2429 (0.2347)
2022-11-02 23:33:01,643:INFO: Batch: 18/31	Total Loss 0.2380 (0.2349)
2022-11-02 23:33:01,696:INFO: Batch: 19/31	Total Loss 0.2369 (0.2349)
2022-11-02 23:33:01,746:INFO: Batch: 20/31	Total Loss 0.2461 (0.2355)
2022-11-02 23:33:01,794:INFO: Batch: 21/31	Total Loss 0.2341 (0.2355)
2022-11-02 23:33:01,842:INFO: Batch: 22/31	Total Loss 0.2394 (0.2356)
2022-11-02 23:33:01,894:INFO: Batch: 23/31	Total Loss 0.2359 (0.2356)
2022-11-02 23:33:01,944:INFO: Batch: 24/31	Total Loss 0.2288 (0.2353)
2022-11-02 23:33:01,993:INFO: Batch: 25/31	Total Loss 0.2231 (0.2349)
2022-11-02 23:33:02,042:INFO: Batch: 26/31	Total Loss 0.2191 (0.2343)
2022-11-02 23:33:02,090:INFO: Batch: 27/31	Total Loss 0.2209 (0.2339)
2022-11-02 23:33:02,143:INFO: Batch: 28/31	Total Loss 0.2243 (0.2335)
2022-11-02 23:33:02,192:INFO: Batch: 29/31	Total Loss 0.2394 (0.2337)
2022-11-02 23:33:02,223:INFO: Batch: 30/31	Total Loss 0.0826 (0.2324)
2022-11-02 23:33:02,372:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_52.pth.tar
2022-11-02 23:33:02,373:INFO: 
===> EPOCH: 53 (P1)
2022-11-02 23:33:02,373:INFO: - Computing loss (training)
2022-11-02 23:33:03,092:INFO: Batch:  0/31	Total Loss 0.2423 (0.2423)
2022-11-02 23:33:03,146:INFO: Batch:  1/31	Total Loss 0.2493 (0.2457)
2022-11-02 23:33:03,198:INFO: Batch:  2/31	Total Loss 0.2316 (0.2407)
2022-11-02 23:33:03,247:INFO: Batch:  3/31	Total Loss 0.2165 (0.2356)
2022-11-02 23:33:03,299:INFO: Batch:  4/31	Total Loss 0.2225 (0.2333)
2022-11-02 23:33:03,352:INFO: Batch:  5/31	Total Loss 0.2219 (0.2314)
2022-11-02 23:33:03,401:INFO: Batch:  6/31	Total Loss 0.2328 (0.2316)
2022-11-02 23:33:03,451:INFO: Batch:  7/31	Total Loss 0.2166 (0.2296)
2022-11-02 23:33:03,497:INFO: Batch:  8/31	Total Loss 0.2407 (0.2308)
2022-11-02 23:33:03,548:INFO: Batch:  9/31	Total Loss 0.2240 (0.2302)
2022-11-02 23:33:03,597:INFO: Batch: 10/31	Total Loss 0.2212 (0.2294)
2022-11-02 23:33:03,647:INFO: Batch: 11/31	Total Loss 0.2172 (0.2285)
2022-11-02 23:33:03,697:INFO: Batch: 12/31	Total Loss 0.2230 (0.2281)
2022-11-02 23:33:03,748:INFO: Batch: 13/31	Total Loss 0.2187 (0.2273)
2022-11-02 23:33:03,800:INFO: Batch: 14/31	Total Loss 0.2249 (0.2272)
2022-11-02 23:33:03,852:INFO: Batch: 15/31	Total Loss 0.2354 (0.2277)
2022-11-02 23:33:03,902:INFO: Batch: 16/31	Total Loss 0.2283 (0.2277)
2022-11-02 23:33:03,952:INFO: Batch: 17/31	Total Loss 0.2586 (0.2294)
2022-11-02 23:33:04,005:INFO: Batch: 18/31	Total Loss 0.2161 (0.2287)
2022-11-02 23:33:04,056:INFO: Batch: 19/31	Total Loss 0.2304 (0.2287)
2022-11-02 23:33:04,106:INFO: Batch: 20/31	Total Loss 0.2193 (0.2283)
2022-11-02 23:33:04,156:INFO: Batch: 21/31	Total Loss 0.2116 (0.2275)
2022-11-02 23:33:04,207:INFO: Batch: 22/31	Total Loss 0.2227 (0.2273)
2022-11-02 23:33:04,257:INFO: Batch: 23/31	Total Loss 0.2069 (0.2264)
2022-11-02 23:33:04,307:INFO: Batch: 24/31	Total Loss 0.2327 (0.2266)
2022-11-02 23:33:04,357:INFO: Batch: 25/31	Total Loss 0.2199 (0.2263)
2022-11-02 23:33:04,409:INFO: Batch: 26/31	Total Loss 0.2289 (0.2264)
2022-11-02 23:33:04,459:INFO: Batch: 27/31	Total Loss 0.2356 (0.2268)
2022-11-02 23:33:04,510:INFO: Batch: 28/31	Total Loss 0.2345 (0.2270)
2022-11-02 23:33:04,559:INFO: Batch: 29/31	Total Loss 0.2411 (0.2275)
2022-11-02 23:33:04,592:INFO: Batch: 30/31	Total Loss 0.0867 (0.2259)
2022-11-02 23:33:04,736:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_53.pth.tar
2022-11-02 23:33:04,736:INFO: 
===> EPOCH: 54 (P1)
2022-11-02 23:33:04,736:INFO: - Computing loss (training)
2022-11-02 23:33:05,439:INFO: Batch:  0/31	Total Loss 0.2297 (0.2297)
2022-11-02 23:33:05,494:INFO: Batch:  1/31	Total Loss 0.2296 (0.2297)
2022-11-02 23:33:05,547:INFO: Batch:  2/31	Total Loss 0.2065 (0.2217)
2022-11-02 23:33:05,601:INFO: Batch:  3/31	Total Loss 0.2132 (0.2196)
2022-11-02 23:33:05,652:INFO: Batch:  4/31	Total Loss 0.2177 (0.2193)
2022-11-02 23:33:05,709:INFO: Batch:  5/31	Total Loss 0.2350 (0.2219)
2022-11-02 23:33:05,758:INFO: Batch:  6/31	Total Loss 0.2140 (0.2208)
2022-11-02 23:33:05,806:INFO: Batch:  7/31	Total Loss 0.2356 (0.2226)
2022-11-02 23:33:05,855:INFO: Batch:  8/31	Total Loss 0.2076 (0.2209)
2022-11-02 23:33:05,907:INFO: Batch:  9/31	Total Loss 0.2274 (0.2217)
2022-11-02 23:33:05,957:INFO: Batch: 10/31	Total Loss 0.2181 (0.2214)
2022-11-02 23:33:06,007:INFO: Batch: 11/31	Total Loss 0.2033 (0.2197)
2022-11-02 23:33:06,057:INFO: Batch: 12/31	Total Loss 0.2434 (0.2214)
2022-11-02 23:33:06,112:INFO: Batch: 13/31	Total Loss 0.2053 (0.2202)
2022-11-02 23:33:06,164:INFO: Batch: 14/31	Total Loss 0.2268 (0.2207)
2022-11-02 23:33:06,217:INFO: Batch: 15/31	Total Loss 0.2194 (0.2206)
2022-11-02 23:33:06,269:INFO: Batch: 16/31	Total Loss 0.2092 (0.2200)
2022-11-02 23:33:06,320:INFO: Batch: 17/31	Total Loss 0.2102 (0.2194)
2022-11-02 23:33:06,375:INFO: Batch: 18/31	Total Loss 0.2098 (0.2190)
2022-11-02 23:33:06,426:INFO: Batch: 19/31	Total Loss 0.2141 (0.2187)
2022-11-02 23:33:06,478:INFO: Batch: 20/31	Total Loss 0.2126 (0.2184)
2022-11-02 23:33:06,529:INFO: Batch: 21/31	Total Loss 0.2287 (0.2189)
2022-11-02 23:33:06,582:INFO: Batch: 22/31	Total Loss 0.2221 (0.2190)
2022-11-02 23:33:06,635:INFO: Batch: 23/31	Total Loss 0.2052 (0.2185)
2022-11-02 23:33:06,684:INFO: Batch: 24/31	Total Loss 0.2299 (0.2189)
2022-11-02 23:33:06,733:INFO: Batch: 25/31	Total Loss 0.2276 (0.2192)
2022-11-02 23:33:06,784:INFO: Batch: 26/31	Total Loss 0.2060 (0.2187)
2022-11-02 23:33:06,834:INFO: Batch: 27/31	Total Loss 0.2154 (0.2186)
2022-11-02 23:33:06,884:INFO: Batch: 28/31	Total Loss 0.2203 (0.2187)
2022-11-02 23:33:06,933:INFO: Batch: 29/31	Total Loss 0.2116 (0.2184)
2022-11-02 23:33:06,965:INFO: Batch: 30/31	Total Loss 0.0758 (0.2168)
2022-11-02 23:33:07,124:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_54.pth.tar
2022-11-02 23:33:07,124:INFO: 
===> EPOCH: 55 (P1)
2022-11-02 23:33:07,124:INFO: - Computing loss (training)
2022-11-02 23:33:07,847:INFO: Batch:  0/31	Total Loss 0.2065 (0.2065)
2022-11-02 23:33:07,897:INFO: Batch:  1/31	Total Loss 0.2028 (0.2044)
2022-11-02 23:33:07,950:INFO: Batch:  2/31	Total Loss 0.2011 (0.2033)
2022-11-02 23:33:08,004:INFO: Batch:  3/31	Total Loss 0.2056 (0.2038)
2022-11-02 23:33:08,053:INFO: Batch:  4/31	Total Loss 0.2075 (0.2045)
2022-11-02 23:33:08,105:INFO: Batch:  5/31	Total Loss 0.2061 (0.2048)
2022-11-02 23:33:08,154:INFO: Batch:  6/31	Total Loss 0.2089 (0.2054)
2022-11-02 23:33:08,201:INFO: Batch:  7/31	Total Loss 0.2165 (0.2068)
2022-11-02 23:33:08,249:INFO: Batch:  8/31	Total Loss 0.2015 (0.2062)
2022-11-02 23:33:08,300:INFO: Batch:  9/31	Total Loss 0.2039 (0.2059)
2022-11-02 23:33:08,351:INFO: Batch: 10/31	Total Loss 0.2126 (0.2065)
2022-11-02 23:33:08,401:INFO: Batch: 11/31	Total Loss 0.2038 (0.2063)
2022-11-02 23:33:08,453:INFO: Batch: 12/31	Total Loss 0.1967 (0.2056)
2022-11-02 23:33:08,504:INFO: Batch: 13/31	Total Loss 0.1974 (0.2050)
2022-11-02 23:33:08,558:INFO: Batch: 14/31	Total Loss 0.2103 (0.2054)
2022-11-02 23:33:08,610:INFO: Batch: 15/31	Total Loss 0.2032 (0.2053)
2022-11-02 23:33:08,662:INFO: Batch: 16/31	Total Loss 0.1985 (0.2049)
2022-11-02 23:33:08,715:INFO: Batch: 17/31	Total Loss 0.2197 (0.2058)
2022-11-02 23:33:08,769:INFO: Batch: 18/31	Total Loss 0.2000 (0.2055)
2022-11-02 23:33:08,821:INFO: Batch: 19/31	Total Loss 0.2109 (0.2059)
2022-11-02 23:33:08,872:INFO: Batch: 20/31	Total Loss 0.1968 (0.2054)
2022-11-02 23:33:08,924:INFO: Batch: 21/31	Total Loss 0.2036 (0.2054)
2022-11-02 23:33:08,977:INFO: Batch: 22/31	Total Loss 0.2533 (0.2073)
2022-11-02 23:33:09,028:INFO: Batch: 23/31	Total Loss 0.2049 (0.2072)
2022-11-02 23:33:09,079:INFO: Batch: 24/31	Total Loss 0.2332 (0.2083)
2022-11-02 23:33:09,131:INFO: Batch: 25/31	Total Loss 0.2185 (0.2086)
2022-11-02 23:33:09,185:INFO: Batch: 26/31	Total Loss 0.2083 (0.2086)
2022-11-02 23:33:09,237:INFO: Batch: 27/31	Total Loss 0.2103 (0.2087)
2022-11-02 23:33:09,288:INFO: Batch: 28/31	Total Loss 0.2003 (0.2084)
2022-11-02 23:33:09,340:INFO: Batch: 29/31	Total Loss 0.2186 (0.2088)
2022-11-02 23:33:09,374:INFO: Batch: 30/31	Total Loss 0.0839 (0.2076)
2022-11-02 23:33:09,532:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_55.pth.tar
2022-11-02 23:33:09,532:INFO: 
===> EPOCH: 56 (P1)
2022-11-02 23:33:09,533:INFO: - Computing loss (training)
2022-11-02 23:33:10,194:INFO: Batch:  0/31	Total Loss 0.2206 (0.2206)
2022-11-02 23:33:10,246:INFO: Batch:  1/31	Total Loss 0.2046 (0.2126)
2022-11-02 23:33:10,304:INFO: Batch:  2/31	Total Loss 0.2133 (0.2128)
2022-11-02 23:33:10,353:INFO: Batch:  3/31	Total Loss 0.2042 (0.2107)
2022-11-02 23:33:10,403:INFO: Batch:  4/31	Total Loss 0.2040 (0.2093)
2022-11-02 23:33:10,455:INFO: Batch:  5/31	Total Loss 0.2285 (0.2126)
2022-11-02 23:33:10,504:INFO: Batch:  6/31	Total Loss 0.2055 (0.2116)
2022-11-02 23:33:10,552:INFO: Batch:  7/31	Total Loss 0.2020 (0.2104)
2022-11-02 23:33:10,599:INFO: Batch:  8/31	Total Loss 0.2126 (0.2107)
2022-11-02 23:33:10,649:INFO: Batch:  9/31	Total Loss 0.2125 (0.2108)
2022-11-02 23:33:10,697:INFO: Batch: 10/31	Total Loss 0.2059 (0.2104)
2022-11-02 23:33:10,745:INFO: Batch: 11/31	Total Loss 0.2029 (0.2097)
2022-11-02 23:33:10,796:INFO: Batch: 12/31	Total Loss 0.2084 (0.2096)
2022-11-02 23:33:10,846:INFO: Batch: 13/31	Total Loss 0.1963 (0.2087)
2022-11-02 23:33:10,901:INFO: Batch: 14/31	Total Loss 0.2015 (0.2082)
2022-11-02 23:33:10,951:INFO: Batch: 15/31	Total Loss 0.1866 (0.2067)
2022-11-02 23:33:11,000:INFO: Batch: 16/31	Total Loss 0.1951 (0.2060)
2022-11-02 23:33:11,050:INFO: Batch: 17/31	Total Loss 0.1892 (0.2051)
2022-11-02 23:33:11,099:INFO: Batch: 18/31	Total Loss 0.2118 (0.2054)
2022-11-02 23:33:11,151:INFO: Batch: 19/31	Total Loss 0.1893 (0.2046)
2022-11-02 23:33:11,201:INFO: Batch: 20/31	Total Loss 0.1968 (0.2043)
2022-11-02 23:33:11,250:INFO: Batch: 21/31	Total Loss 0.1911 (0.2037)
2022-11-02 23:33:11,299:INFO: Batch: 22/31	Total Loss 0.2022 (0.2036)
2022-11-02 23:33:11,347:INFO: Batch: 23/31	Total Loss 0.2023 (0.2036)
2022-11-02 23:33:11,400:INFO: Batch: 24/31	Total Loss 0.1727 (0.2024)
2022-11-02 23:33:11,449:INFO: Batch: 25/31	Total Loss 0.1792 (0.2015)
2022-11-02 23:33:11,498:INFO: Batch: 26/31	Total Loss 0.1974 (0.2013)
2022-11-02 23:33:11,547:INFO: Batch: 27/31	Total Loss 0.1935 (0.2011)
2022-11-02 23:33:11,596:INFO: Batch: 28/31	Total Loss 0.2108 (0.2014)
2022-11-02 23:33:11,649:INFO: Batch: 29/31	Total Loss 0.1979 (0.2013)
2022-11-02 23:33:11,680:INFO: Batch: 30/31	Total Loss 0.0671 (0.2000)
2022-11-02 23:33:11,829:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_56.pth.tar
2022-11-02 23:33:11,830:INFO: 
===> EPOCH: 57 (P1)
2022-11-02 23:33:11,830:INFO: - Computing loss (training)
2022-11-02 23:33:12,530:INFO: Batch:  0/31	Total Loss 0.1939 (0.1939)
2022-11-02 23:33:12,582:INFO: Batch:  1/31	Total Loss 0.2061 (0.2002)
2022-11-02 23:33:12,637:INFO: Batch:  2/31	Total Loss 0.1831 (0.1947)
2022-11-02 23:33:12,688:INFO: Batch:  3/31	Total Loss 0.2026 (0.1967)
2022-11-02 23:33:12,737:INFO: Batch:  4/31	Total Loss 0.1987 (0.1971)
2022-11-02 23:33:12,791:INFO: Batch:  5/31	Total Loss 0.2022 (0.1980)
2022-11-02 23:33:12,841:INFO: Batch:  6/31	Total Loss 0.2029 (0.1988)
2022-11-02 23:33:12,888:INFO: Batch:  7/31	Total Loss 0.1922 (0.1979)
2022-11-02 23:33:12,936:INFO: Batch:  8/31	Total Loss 0.2020 (0.1983)
2022-11-02 23:33:12,986:INFO: Batch:  9/31	Total Loss 0.1940 (0.1979)
2022-11-02 23:33:13,033:INFO: Batch: 10/31	Total Loss 0.1870 (0.1967)
2022-11-02 23:33:13,082:INFO: Batch: 11/31	Total Loss 0.1887 (0.1960)
2022-11-02 23:33:13,132:INFO: Batch: 12/31	Total Loss 0.1901 (0.1956)
2022-11-02 23:33:13,183:INFO: Batch: 13/31	Total Loss 0.1916 (0.1953)
2022-11-02 23:33:13,236:INFO: Batch: 14/31	Total Loss 0.1941 (0.1952)
2022-11-02 23:33:13,286:INFO: Batch: 15/31	Total Loss 0.2089 (0.1961)
2022-11-02 23:33:13,337:INFO: Batch: 16/31	Total Loss 0.1897 (0.1957)
2022-11-02 23:33:13,387:INFO: Batch: 17/31	Total Loss 0.1852 (0.1950)
2022-11-02 23:33:13,437:INFO: Batch: 18/31	Total Loss 0.1932 (0.1950)
2022-11-02 23:33:13,491:INFO: Batch: 19/31	Total Loss 0.2077 (0.1955)
2022-11-02 23:33:13,541:INFO: Batch: 20/31	Total Loss 0.2210 (0.1967)
2022-11-02 23:33:13,591:INFO: Batch: 21/31	Total Loss 0.1775 (0.1958)
2022-11-02 23:33:13,641:INFO: Batch: 22/31	Total Loss 0.1917 (0.1956)
2022-11-02 23:33:13,693:INFO: Batch: 23/31	Total Loss 0.1991 (0.1958)
2022-11-02 23:33:13,743:INFO: Batch: 24/31	Total Loss 0.2058 (0.1961)
2022-11-02 23:33:13,793:INFO: Batch: 25/31	Total Loss 0.1966 (0.1962)
2022-11-02 23:33:13,843:INFO: Batch: 26/31	Total Loss 0.1990 (0.1963)
2022-11-02 23:33:13,895:INFO: Batch: 27/31	Total Loss 0.2098 (0.1968)
2022-11-02 23:33:13,945:INFO: Batch: 28/31	Total Loss 0.1969 (0.1968)
2022-11-02 23:33:13,995:INFO: Batch: 29/31	Total Loss 0.1974 (0.1968)
2022-11-02 23:33:14,026:INFO: Batch: 30/31	Total Loss 0.0696 (0.1952)
2022-11-02 23:33:14,186:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_57.pth.tar
2022-11-02 23:33:14,186:INFO: 
===> EPOCH: 58 (P1)
2022-11-02 23:33:14,186:INFO: - Computing loss (training)
2022-11-02 23:33:14,872:INFO: Batch:  0/31	Total Loss 0.2019 (0.2019)
2022-11-02 23:33:14,925:INFO: Batch:  1/31	Total Loss 0.1917 (0.1965)
2022-11-02 23:33:14,984:INFO: Batch:  2/31	Total Loss 0.1780 (0.1905)
2022-11-02 23:33:15,035:INFO: Batch:  3/31	Total Loss 0.1962 (0.1920)
2022-11-02 23:33:15,082:INFO: Batch:  4/31	Total Loss 0.1901 (0.1916)
2022-11-02 23:33:15,136:INFO: Batch:  5/31	Total Loss 0.1884 (0.1911)
2022-11-02 23:33:15,183:INFO: Batch:  6/31	Total Loss 0.1993 (0.1920)
2022-11-02 23:33:15,230:INFO: Batch:  7/31	Total Loss 0.1785 (0.1902)
2022-11-02 23:33:15,277:INFO: Batch:  8/31	Total Loss 0.1770 (0.1887)
2022-11-02 23:33:15,327:INFO: Batch:  9/31	Total Loss 0.1875 (0.1886)
2022-11-02 23:33:15,377:INFO: Batch: 10/31	Total Loss 0.1918 (0.1889)
2022-11-02 23:33:15,426:INFO: Batch: 11/31	Total Loss 0.1951 (0.1894)
2022-11-02 23:33:15,475:INFO: Batch: 12/31	Total Loss 0.1832 (0.1889)
2022-11-02 23:33:15,525:INFO: Batch: 13/31	Total Loss 0.2012 (0.1897)
2022-11-02 23:33:15,578:INFO: Batch: 14/31	Total Loss 0.2069 (0.1908)
2022-11-02 23:33:15,628:INFO: Batch: 15/31	Total Loss 0.1856 (0.1905)
2022-11-02 23:33:15,678:INFO: Batch: 16/31	Total Loss 0.2109 (0.1917)
2022-11-02 23:33:15,727:INFO: Batch: 17/31	Total Loss 0.2103 (0.1927)
2022-11-02 23:33:15,777:INFO: Batch: 18/31	Total Loss 0.1829 (0.1922)
2022-11-02 23:33:15,829:INFO: Batch: 19/31	Total Loss 0.1815 (0.1917)
2022-11-02 23:33:15,879:INFO: Batch: 20/31	Total Loss 0.1981 (0.1920)
2022-11-02 23:33:15,928:INFO: Batch: 21/31	Total Loss 0.1911 (0.1920)
2022-11-02 23:33:15,976:INFO: Batch: 22/31	Total Loss 0.1785 (0.1914)
2022-11-02 23:33:16,026:INFO: Batch: 23/31	Total Loss 0.1898 (0.1913)
2022-11-02 23:33:16,077:INFO: Batch: 24/31	Total Loss 0.1797 (0.1908)
2022-11-02 23:33:16,128:INFO: Batch: 25/31	Total Loss 0.1906 (0.1908)
2022-11-02 23:33:16,178:INFO: Batch: 26/31	Total Loss 0.1980 (0.1910)
2022-11-02 23:33:16,227:INFO: Batch: 27/31	Total Loss 0.1888 (0.1909)
2022-11-02 23:33:16,276:INFO: Batch: 28/31	Total Loss 0.1841 (0.1907)
2022-11-02 23:33:16,328:INFO: Batch: 29/31	Total Loss 0.2122 (0.1914)
2022-11-02 23:33:16,360:INFO: Batch: 30/31	Total Loss 0.0772 (0.1903)
2022-11-02 23:33:16,510:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_58.pth.tar
2022-11-02 23:33:16,510:INFO: 
===> EPOCH: 59 (P1)
2022-11-02 23:33:16,510:INFO: - Computing loss (training)
2022-11-02 23:33:17,224:INFO: Batch:  0/31	Total Loss 0.1771 (0.1771)
2022-11-02 23:33:17,273:INFO: Batch:  1/31	Total Loss 0.1883 (0.1825)
2022-11-02 23:33:17,326:INFO: Batch:  2/31	Total Loss 0.1689 (0.1782)
2022-11-02 23:33:17,376:INFO: Batch:  3/31	Total Loss 0.1604 (0.1738)
2022-11-02 23:33:17,425:INFO: Batch:  4/31	Total Loss 0.1782 (0.1748)
2022-11-02 23:33:17,476:INFO: Batch:  5/31	Total Loss 0.1795 (0.1756)
2022-11-02 23:33:17,524:INFO: Batch:  6/31	Total Loss 0.1821 (0.1765)
2022-11-02 23:33:17,571:INFO: Batch:  7/31	Total Loss 0.1728 (0.1760)
2022-11-02 23:33:17,620:INFO: Batch:  8/31	Total Loss 0.1704 (0.1753)
2022-11-02 23:33:17,668:INFO: Batch:  9/31	Total Loss 0.1814 (0.1759)
2022-11-02 23:33:17,719:INFO: Batch: 10/31	Total Loss 0.1959 (0.1778)
2022-11-02 23:33:17,766:INFO: Batch: 11/31	Total Loss 0.1788 (0.1779)
2022-11-02 23:33:17,816:INFO: Batch: 12/31	Total Loss 0.1891 (0.1787)
2022-11-02 23:33:17,865:INFO: Batch: 13/31	Total Loss 0.1718 (0.1782)
2022-11-02 23:33:17,917:INFO: Batch: 14/31	Total Loss 0.1700 (0.1777)
2022-11-02 23:33:17,967:INFO: Batch: 15/31	Total Loss 0.1887 (0.1784)
2022-11-02 23:33:18,017:INFO: Batch: 16/31	Total Loss 0.1705 (0.1779)
2022-11-02 23:33:18,067:INFO: Batch: 17/31	Total Loss 0.1779 (0.1779)
2022-11-02 23:33:18,116:INFO: Batch: 18/31	Total Loss 0.1896 (0.1785)
2022-11-02 23:33:18,169:INFO: Batch: 19/31	Total Loss 0.1768 (0.1784)
2022-11-02 23:33:18,220:INFO: Batch: 20/31	Total Loss 0.1863 (0.1788)
2022-11-02 23:33:18,269:INFO: Batch: 21/31	Total Loss 0.1873 (0.1792)
2022-11-02 23:33:18,319:INFO: Batch: 22/31	Total Loss 0.1928 (0.1797)
2022-11-02 23:33:18,372:INFO: Batch: 23/31	Total Loss 0.1868 (0.1800)
2022-11-02 23:33:18,423:INFO: Batch: 24/31	Total Loss 0.1922 (0.1805)
2022-11-02 23:33:18,473:INFO: Batch: 25/31	Total Loss 0.1784 (0.1804)
2022-11-02 23:33:18,523:INFO: Batch: 26/31	Total Loss 0.1721 (0.1801)
2022-11-02 23:33:18,572:INFO: Batch: 27/31	Total Loss 0.1721 (0.1798)
2022-11-02 23:33:18,625:INFO: Batch: 28/31	Total Loss 0.1882 (0.1801)
2022-11-02 23:33:18,676:INFO: Batch: 29/31	Total Loss 0.1661 (0.1796)
2022-11-02 23:33:18,707:INFO: Batch: 30/31	Total Loss 0.0643 (0.1786)
2022-11-02 23:33:18,857:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_59.pth.tar
2022-11-02 23:33:18,857:INFO: 
===> EPOCH: 60 (P1)
2022-11-02 23:33:18,858:INFO: - Computing loss (training)
2022-11-02 23:33:19,554:INFO: Batch:  0/31	Total Loss 0.1769 (0.1769)
2022-11-02 23:33:19,605:INFO: Batch:  1/31	Total Loss 0.1865 (0.1816)
2022-11-02 23:33:19,664:INFO: Batch:  2/31	Total Loss 0.1929 (0.1853)
2022-11-02 23:33:19,715:INFO: Batch:  3/31	Total Loss 0.1757 (0.1827)
2022-11-02 23:33:19,765:INFO: Batch:  4/31	Total Loss 0.1695 (0.1801)
2022-11-02 23:33:19,816:INFO: Batch:  5/31	Total Loss 0.1744 (0.1791)
2022-11-02 23:33:19,864:INFO: Batch:  6/31	Total Loss 0.1821 (0.1796)
2022-11-02 23:33:19,913:INFO: Batch:  7/31	Total Loss 0.1829 (0.1800)
2022-11-02 23:33:19,962:INFO: Batch:  8/31	Total Loss 0.1797 (0.1800)
2022-11-02 23:33:20,012:INFO: Batch:  9/31	Total Loss 0.1743 (0.1794)
2022-11-02 23:33:20,061:INFO: Batch: 10/31	Total Loss 0.1952 (0.1808)
2022-11-02 23:33:20,109:INFO: Batch: 11/31	Total Loss 0.1730 (0.1802)
2022-11-02 23:33:20,158:INFO: Batch: 12/31	Total Loss 0.1834 (0.1804)
2022-11-02 23:33:20,207:INFO: Batch: 13/31	Total Loss 0.1974 (0.1816)
2022-11-02 23:33:20,259:INFO: Batch: 14/31	Total Loss 0.1751 (0.1812)
2022-11-02 23:33:20,310:INFO: Batch: 15/31	Total Loss 0.1714 (0.1806)
2022-11-02 23:33:20,361:INFO: Batch: 16/31	Total Loss 0.1745 (0.1803)
2022-11-02 23:33:20,411:INFO: Batch: 17/31	Total Loss 0.1769 (0.1801)
2022-11-02 23:33:20,461:INFO: Batch: 18/31	Total Loss 0.1764 (0.1799)
2022-11-02 23:33:20,514:INFO: Batch: 19/31	Total Loss 0.1646 (0.1791)
2022-11-02 23:33:20,567:INFO: Batch: 20/31	Total Loss 0.1614 (0.1783)
2022-11-02 23:33:20,618:INFO: Batch: 21/31	Total Loss 0.1818 (0.1784)
2022-11-02 23:33:20,667:INFO: Batch: 22/31	Total Loss 0.1684 (0.1780)
2022-11-02 23:33:20,720:INFO: Batch: 23/31	Total Loss 0.1727 (0.1778)
2022-11-02 23:33:20,770:INFO: Batch: 24/31	Total Loss 0.1828 (0.1780)
2022-11-02 23:33:20,820:INFO: Batch: 25/31	Total Loss 0.1875 (0.1784)
2022-11-02 23:33:20,870:INFO: Batch: 26/31	Total Loss 0.1657 (0.1779)
2022-11-02 23:33:20,923:INFO: Batch: 27/31	Total Loss 0.1721 (0.1777)
2022-11-02 23:33:20,974:INFO: Batch: 28/31	Total Loss 0.1887 (0.1780)
2022-11-02 23:33:21,024:INFO: Batch: 29/31	Total Loss 0.1939 (0.1785)
2022-11-02 23:33:21,055:INFO: Batch: 30/31	Total Loss 0.0690 (0.1773)
2022-11-02 23:33:21,213:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_60.pth.tar
2022-11-02 23:33:21,213:INFO: 
===> EPOCH: 61 (P1)
2022-11-02 23:33:21,213:INFO: - Computing loss (training)
2022-11-02 23:33:21,863:INFO: Batch:  0/31	Total Loss 0.2213 (0.2213)
2022-11-02 23:33:21,916:INFO: Batch:  1/31	Total Loss 0.2221 (0.2217)
2022-11-02 23:33:21,970:INFO: Batch:  2/31	Total Loss 0.1721 (0.2038)
2022-11-02 23:33:22,017:INFO: Batch:  3/31	Total Loss 0.1708 (0.1963)
2022-11-02 23:33:22,063:INFO: Batch:  4/31	Total Loss 0.1896 (0.1950)
2022-11-02 23:33:22,119:INFO: Batch:  5/31	Total Loss 0.1794 (0.1924)
2022-11-02 23:33:22,167:INFO: Batch:  6/31	Total Loss 0.1941 (0.1926)
2022-11-02 23:33:22,214:INFO: Batch:  7/31	Total Loss 0.1707 (0.1897)
2022-11-02 23:33:22,261:INFO: Batch:  8/31	Total Loss 0.1706 (0.1877)
2022-11-02 23:33:22,309:INFO: Batch:  9/31	Total Loss 0.1913 (0.1880)
2022-11-02 23:33:22,356:INFO: Batch: 10/31	Total Loss 0.1921 (0.1884)
2022-11-02 23:33:22,406:INFO: Batch: 11/31	Total Loss 0.1732 (0.1871)
2022-11-02 23:33:22,456:INFO: Batch: 12/31	Total Loss 0.1619 (0.1854)
2022-11-02 23:33:22,506:INFO: Batch: 13/31	Total Loss 0.1765 (0.1848)
2022-11-02 23:33:22,555:INFO: Batch: 14/31	Total Loss 0.1671 (0.1835)
2022-11-02 23:33:22,607:INFO: Batch: 15/31	Total Loss 0.1786 (0.1832)
2022-11-02 23:33:22,658:INFO: Batch: 16/31	Total Loss 0.1704 (0.1825)
2022-11-02 23:33:22,708:INFO: Batch: 17/31	Total Loss 0.1651 (0.1816)
2022-11-02 23:33:22,758:INFO: Batch: 18/31	Total Loss 0.1650 (0.1807)
2022-11-02 23:33:22,808:INFO: Batch: 19/31	Total Loss 0.1609 (0.1797)
2022-11-02 23:33:22,860:INFO: Batch: 20/31	Total Loss 0.1881 (0.1801)
2022-11-02 23:33:22,910:INFO: Batch: 21/31	Total Loss 0.1623 (0.1794)
2022-11-02 23:33:22,960:INFO: Batch: 22/31	Total Loss 0.1706 (0.1791)
2022-11-02 23:33:23,011:INFO: Batch: 23/31	Total Loss 0.1843 (0.1793)
2022-11-02 23:33:23,062:INFO: Batch: 24/31	Total Loss 0.1742 (0.1791)
2022-11-02 23:33:23,112:INFO: Batch: 25/31	Total Loss 0.1637 (0.1785)
2022-11-02 23:33:23,162:INFO: Batch: 26/31	Total Loss 0.1705 (0.1782)
2022-11-02 23:33:23,212:INFO: Batch: 27/31	Total Loss 0.1754 (0.1781)
2022-11-02 23:33:23,263:INFO: Batch: 28/31	Total Loss 0.1750 (0.1780)
2022-11-02 23:33:23,314:INFO: Batch: 29/31	Total Loss 0.1574 (0.1773)
2022-11-02 23:33:23,345:INFO: Batch: 30/31	Total Loss 0.0662 (0.1763)
2022-11-02 23:33:23,503:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_61.pth.tar
2022-11-02 23:33:23,503:INFO: 
===> EPOCH: 62 (P1)
2022-11-02 23:33:23,504:INFO: - Computing loss (training)
2022-11-02 23:33:24,212:INFO: Batch:  0/31	Total Loss 0.1670 (0.1670)
2022-11-02 23:33:24,263:INFO: Batch:  1/31	Total Loss 0.1645 (0.1658)
2022-11-02 23:33:24,314:INFO: Batch:  2/31	Total Loss 0.1787 (0.1695)
2022-11-02 23:33:24,367:INFO: Batch:  3/31	Total Loss 0.1655 (0.1685)
2022-11-02 23:33:24,421:INFO: Batch:  4/31	Total Loss 0.1630 (0.1674)
2022-11-02 23:33:24,471:INFO: Batch:  5/31	Total Loss 0.1633 (0.1666)
2022-11-02 23:33:24,519:INFO: Batch:  6/31	Total Loss 0.1775 (0.1682)
2022-11-02 23:33:24,566:INFO: Batch:  7/31	Total Loss 0.1583 (0.1669)
2022-11-02 23:33:24,613:INFO: Batch:  8/31	Total Loss 0.1767 (0.1680)
2022-11-02 23:33:24,663:INFO: Batch:  9/31	Total Loss 0.1659 (0.1678)
2022-11-02 23:33:24,713:INFO: Batch: 10/31	Total Loss 0.1947 (0.1703)
2022-11-02 23:33:24,761:INFO: Batch: 11/31	Total Loss 0.1730 (0.1705)
2022-11-02 23:33:24,810:INFO: Batch: 12/31	Total Loss 0.1613 (0.1698)
2022-11-02 23:33:24,861:INFO: Batch: 13/31	Total Loss 0.1703 (0.1698)
2022-11-02 23:33:24,912:INFO: Batch: 14/31	Total Loss 0.1577 (0.1690)
2022-11-02 23:33:24,963:INFO: Batch: 15/31	Total Loss 0.1644 (0.1687)
2022-11-02 23:33:25,013:INFO: Batch: 16/31	Total Loss 0.1613 (0.1683)
2022-11-02 23:33:25,063:INFO: Batch: 17/31	Total Loss 0.1563 (0.1676)
2022-11-02 23:33:25,112:INFO: Batch: 18/31	Total Loss 0.1634 (0.1674)
2022-11-02 23:33:25,164:INFO: Batch: 19/31	Total Loss 0.1567 (0.1669)
2022-11-02 23:33:25,215:INFO: Batch: 20/31	Total Loss 0.1664 (0.1668)
2022-11-02 23:33:25,265:INFO: Batch: 21/31	Total Loss 0.1537 (0.1662)
2022-11-02 23:33:25,315:INFO: Batch: 22/31	Total Loss 0.1642 (0.1661)
2022-11-02 23:33:25,364:INFO: Batch: 23/31	Total Loss 0.1550 (0.1657)
2022-11-02 23:33:25,415:INFO: Batch: 24/31	Total Loss 0.1586 (0.1654)
2022-11-02 23:33:25,464:INFO: Batch: 25/31	Total Loss 0.1818 (0.1659)
2022-11-02 23:33:25,513:INFO: Batch: 26/31	Total Loss 0.1587 (0.1656)
2022-11-02 23:33:25,562:INFO: Batch: 27/31	Total Loss 0.1747 (0.1660)
2022-11-02 23:33:25,611:INFO: Batch: 28/31	Total Loss 0.1647 (0.1660)
2022-11-02 23:33:25,661:INFO: Batch: 29/31	Total Loss 0.1610 (0.1658)
2022-11-02 23:33:25,693:INFO: Batch: 30/31	Total Loss 0.0593 (0.1646)
2022-11-02 23:33:25,848:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_62.pth.tar
2022-11-02 23:33:25,848:INFO: 
===> EPOCH: 63 (P1)
2022-11-02 23:33:25,848:INFO: - Computing loss (training)
2022-11-02 23:33:26,564:INFO: Batch:  0/31	Total Loss 0.1552 (0.1552)
2022-11-02 23:33:26,613:INFO: Batch:  1/31	Total Loss 0.1733 (0.1644)
2022-11-02 23:33:26,667:INFO: Batch:  2/31	Total Loss 0.1628 (0.1638)
2022-11-02 23:33:26,722:INFO: Batch:  3/31	Total Loss 0.1552 (0.1617)
2022-11-02 23:33:26,770:INFO: Batch:  4/31	Total Loss 0.1642 (0.1622)
2022-11-02 23:33:26,821:INFO: Batch:  5/31	Total Loss 0.1611 (0.1620)
2022-11-02 23:33:26,871:INFO: Batch:  6/31	Total Loss 0.1601 (0.1617)
2022-11-02 23:33:26,918:INFO: Batch:  7/31	Total Loss 0.1564 (0.1611)
2022-11-02 23:33:26,966:INFO: Batch:  8/31	Total Loss 0.1639 (0.1614)
2022-11-02 23:33:27,016:INFO: Batch:  9/31	Total Loss 0.1573 (0.1610)
2022-11-02 23:33:27,064:INFO: Batch: 10/31	Total Loss 0.1574 (0.1607)
2022-11-02 23:33:27,112:INFO: Batch: 11/31	Total Loss 0.1758 (0.1619)
2022-11-02 23:33:27,161:INFO: Batch: 12/31	Total Loss 0.1552 (0.1614)
2022-11-02 23:33:27,212:INFO: Batch: 13/31	Total Loss 0.1636 (0.1616)
2022-11-02 23:33:27,264:INFO: Batch: 14/31	Total Loss 0.1715 (0.1622)
2022-11-02 23:33:27,316:INFO: Batch: 15/31	Total Loss 0.1558 (0.1618)
2022-11-02 23:33:27,366:INFO: Batch: 16/31	Total Loss 0.1513 (0.1611)
2022-11-02 23:33:27,416:INFO: Batch: 17/31	Total Loss 0.1959 (0.1628)
2022-11-02 23:33:27,466:INFO: Batch: 18/31	Total Loss 0.1688 (0.1632)
2022-11-02 23:33:27,518:INFO: Batch: 19/31	Total Loss 0.1607 (0.1630)
2022-11-02 23:33:27,568:INFO: Batch: 20/31	Total Loss 0.1664 (0.1632)
2022-11-02 23:33:27,617:INFO: Batch: 21/31	Total Loss 0.1721 (0.1636)
2022-11-02 23:33:27,666:INFO: Batch: 22/31	Total Loss 0.1526 (0.1632)
2022-11-02 23:33:27,716:INFO: Batch: 23/31	Total Loss 0.1541 (0.1628)
2022-11-02 23:33:27,768:INFO: Batch: 24/31	Total Loss 0.1672 (0.1630)
2022-11-02 23:33:27,819:INFO: Batch: 25/31	Total Loss 0.1479 (0.1624)
2022-11-02 23:33:27,868:INFO: Batch: 26/31	Total Loss 0.1568 (0.1622)
2022-11-02 23:33:27,918:INFO: Batch: 27/31	Total Loss 0.1565 (0.1620)
2022-11-02 23:33:27,970:INFO: Batch: 28/31	Total Loss 0.1667 (0.1622)
2022-11-02 23:33:28,021:INFO: Batch: 29/31	Total Loss 0.1664 (0.1623)
2022-11-02 23:33:28,052:INFO: Batch: 30/31	Total Loss 0.0675 (0.1613)
2022-11-02 23:33:28,207:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_63.pth.tar
2022-11-02 23:33:28,207:INFO: 
===> EPOCH: 64 (P1)
2022-11-02 23:33:28,207:INFO: - Computing loss (training)
2022-11-02 23:33:28,888:INFO: Batch:  0/31	Total Loss 0.1598 (0.1598)
2022-11-02 23:33:28,937:INFO: Batch:  1/31	Total Loss 0.1552 (0.1576)
2022-11-02 23:33:28,987:INFO: Batch:  2/31	Total Loss 0.1574 (0.1575)
2022-11-02 23:33:29,040:INFO: Batch:  3/31	Total Loss 0.1671 (0.1602)
2022-11-02 23:33:29,091:INFO: Batch:  4/31	Total Loss 0.1583 (0.1598)
2022-11-02 23:33:29,145:INFO: Batch:  5/31	Total Loss 0.1424 (0.1570)
2022-11-02 23:33:29,195:INFO: Batch:  6/31	Total Loss 0.1544 (0.1567)
2022-11-02 23:33:29,242:INFO: Batch:  7/31	Total Loss 0.1569 (0.1567)
2022-11-02 23:33:29,289:INFO: Batch:  8/31	Total Loss 0.1517 (0.1561)
2022-11-02 23:33:29,336:INFO: Batch:  9/31	Total Loss 0.1620 (0.1567)
2022-11-02 23:33:29,385:INFO: Batch: 10/31	Total Loss 0.1675 (0.1576)
2022-11-02 23:33:29,437:INFO: Batch: 11/31	Total Loss 0.1519 (0.1571)
2022-11-02 23:33:29,487:INFO: Batch: 12/31	Total Loss 0.1451 (0.1562)
2022-11-02 23:33:29,537:INFO: Batch: 13/31	Total Loss 0.1479 (0.1556)
2022-11-02 23:33:29,586:INFO: Batch: 14/31	Total Loss 0.1403 (0.1547)
2022-11-02 23:33:29,638:INFO: Batch: 15/31	Total Loss 0.1696 (0.1557)
2022-11-02 23:33:29,688:INFO: Batch: 16/31	Total Loss 0.1561 (0.1557)
2022-11-02 23:33:29,738:INFO: Batch: 17/31	Total Loss 0.1748 (0.1567)
2022-11-02 23:33:29,790:INFO: Batch: 18/31	Total Loss 0.1464 (0.1562)
2022-11-02 23:33:29,843:INFO: Batch: 19/31	Total Loss 0.1412 (0.1555)
2022-11-02 23:33:29,894:INFO: Batch: 20/31	Total Loss 0.1468 (0.1551)
2022-11-02 23:33:29,944:INFO: Batch: 21/31	Total Loss 0.1660 (0.1556)
2022-11-02 23:33:29,994:INFO: Batch: 22/31	Total Loss 0.1453 (0.1551)
2022-11-02 23:33:30,045:INFO: Batch: 23/31	Total Loss 0.1594 (0.1553)
2022-11-02 23:33:30,096:INFO: Batch: 24/31	Total Loss 0.1553 (0.1553)
2022-11-02 23:33:30,145:INFO: Batch: 25/31	Total Loss 0.1601 (0.1555)
2022-11-02 23:33:30,195:INFO: Batch: 26/31	Total Loss 0.1460 (0.1551)
2022-11-02 23:33:30,248:INFO: Batch: 27/31	Total Loss 0.1489 (0.1549)
2022-11-02 23:33:30,299:INFO: Batch: 28/31	Total Loss 0.1485 (0.1546)
2022-11-02 23:33:30,349:INFO: Batch: 29/31	Total Loss 0.1681 (0.1551)
2022-11-02 23:33:30,381:INFO: Batch: 30/31	Total Loss 0.0526 (0.1540)
2022-11-02 23:33:30,529:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_64.pth.tar
2022-11-02 23:33:30,529:INFO: 
===> EPOCH: 65 (P1)
2022-11-02 23:33:30,529:INFO: - Computing loss (training)
2022-11-02 23:33:31,239:INFO: Batch:  0/31	Total Loss 0.1525 (0.1525)
2022-11-02 23:33:31,289:INFO: Batch:  1/31	Total Loss 0.1490 (0.1507)
2022-11-02 23:33:31,343:INFO: Batch:  2/31	Total Loss 0.1468 (0.1493)
2022-11-02 23:33:31,393:INFO: Batch:  3/31	Total Loss 0.1572 (0.1515)
2022-11-02 23:33:31,442:INFO: Batch:  4/31	Total Loss 0.1515 (0.1515)
2022-11-02 23:33:31,492:INFO: Batch:  5/31	Total Loss 0.1499 (0.1512)
2022-11-02 23:33:31,540:INFO: Batch:  6/31	Total Loss 0.1426 (0.1500)
2022-11-02 23:33:31,587:INFO: Batch:  7/31	Total Loss 0.1560 (0.1507)
2022-11-02 23:33:31,636:INFO: Batch:  8/31	Total Loss 0.1565 (0.1513)
2022-11-02 23:33:31,685:INFO: Batch:  9/31	Total Loss 0.1460 (0.1509)
2022-11-02 23:33:31,734:INFO: Batch: 10/31	Total Loss 0.1578 (0.1515)
2022-11-02 23:33:31,781:INFO: Batch: 11/31	Total Loss 0.1608 (0.1522)
2022-11-02 23:33:31,831:INFO: Batch: 12/31	Total Loss 0.1632 (0.1531)
2022-11-02 23:33:31,880:INFO: Batch: 13/31	Total Loss 0.1577 (0.1534)
2022-11-02 23:33:31,934:INFO: Batch: 14/31	Total Loss 0.1526 (0.1534)
2022-11-02 23:33:31,985:INFO: Batch: 15/31	Total Loss 0.1499 (0.1531)
2022-11-02 23:33:32,035:INFO: Batch: 16/31	Total Loss 0.1478 (0.1528)
2022-11-02 23:33:32,085:INFO: Batch: 17/31	Total Loss 0.1567 (0.1531)
2022-11-02 23:33:32,134:INFO: Batch: 18/31	Total Loss 0.1530 (0.1530)
2022-11-02 23:33:32,186:INFO: Batch: 19/31	Total Loss 0.1454 (0.1527)
2022-11-02 23:33:32,311:INFO: Batch: 20/31	Total Loss 0.1611 (0.1531)
2022-11-02 23:33:32,360:INFO: Batch: 21/31	Total Loss 0.1439 (0.1527)
2022-11-02 23:33:32,410:INFO: Batch: 22/31	Total Loss 0.1447 (0.1523)
2022-11-02 23:33:32,459:INFO: Batch: 23/31	Total Loss 0.1432 (0.1519)
2022-11-02 23:33:32,509:INFO: Batch: 24/31	Total Loss 0.1441 (0.1516)
2022-11-02 23:33:32,560:INFO: Batch: 25/31	Total Loss 0.1414 (0.1513)
2022-11-02 23:33:32,609:INFO: Batch: 26/31	Total Loss 0.1460 (0.1511)
2022-11-02 23:33:32,661:INFO: Batch: 27/31	Total Loss 0.1505 (0.1510)
2022-11-02 23:33:32,711:INFO: Batch: 28/31	Total Loss 0.1572 (0.1513)
2022-11-02 23:33:32,761:INFO: Batch: 29/31	Total Loss 0.1487 (0.1512)
2022-11-02 23:33:32,792:INFO: Batch: 30/31	Total Loss 0.0585 (0.1504)
2022-11-02 23:33:32,956:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_65.pth.tar
2022-11-02 23:33:32,956:INFO: 
===> EPOCH: 66 (P1)
2022-11-02 23:33:32,957:INFO: - Computing loss (training)
2022-11-02 23:33:33,653:INFO: Batch:  0/31	Total Loss 0.1446 (0.1446)
2022-11-02 23:33:33,704:INFO: Batch:  1/31	Total Loss 0.1503 (0.1474)
2022-11-02 23:33:33,755:INFO: Batch:  2/31	Total Loss 0.1475 (0.1474)
2022-11-02 23:33:33,810:INFO: Batch:  3/31	Total Loss 0.1534 (0.1489)
2022-11-02 23:33:33,858:INFO: Batch:  4/31	Total Loss 0.1482 (0.1487)
2022-11-02 23:33:33,909:INFO: Batch:  5/31	Total Loss 0.1403 (0.1474)
2022-11-02 23:33:33,957:INFO: Batch:  6/31	Total Loss 0.1385 (0.1461)
2022-11-02 23:33:34,004:INFO: Batch:  7/31	Total Loss 0.1488 (0.1465)
2022-11-02 23:33:34,050:INFO: Batch:  8/31	Total Loss 0.1424 (0.1460)
2022-11-02 23:33:34,101:INFO: Batch:  9/31	Total Loss 0.1385 (0.1452)
2022-11-02 23:33:34,150:INFO: Batch: 10/31	Total Loss 0.1443 (0.1451)
2022-11-02 23:33:34,197:INFO: Batch: 11/31	Total Loss 0.1400 (0.1447)
2022-11-02 23:33:34,247:INFO: Batch: 12/31	Total Loss 0.1550 (0.1455)
2022-11-02 23:33:34,296:INFO: Batch: 13/31	Total Loss 0.1518 (0.1459)
2022-11-02 23:33:34,349:INFO: Batch: 14/31	Total Loss 0.1564 (0.1466)
2022-11-02 23:33:34,400:INFO: Batch: 15/31	Total Loss 0.1451 (0.1465)
2022-11-02 23:33:34,451:INFO: Batch: 16/31	Total Loss 0.1452 (0.1464)
2022-11-02 23:33:34,500:INFO: Batch: 17/31	Total Loss 0.1438 (0.1463)
2022-11-02 23:33:34,550:INFO: Batch: 18/31	Total Loss 0.1438 (0.1461)
2022-11-02 23:33:34,602:INFO: Batch: 19/31	Total Loss 0.1528 (0.1465)
2022-11-02 23:33:34,651:INFO: Batch: 20/31	Total Loss 0.1478 (0.1466)
2022-11-02 23:33:34,700:INFO: Batch: 21/31	Total Loss 0.1436 (0.1464)
2022-11-02 23:33:34,749:INFO: Batch: 22/31	Total Loss 0.1438 (0.1463)
2022-11-02 23:33:34,801:INFO: Batch: 23/31	Total Loss 0.1410 (0.1461)
2022-11-02 23:33:34,851:INFO: Batch: 24/31	Total Loss 0.1423 (0.1460)
2022-11-02 23:33:34,900:INFO: Batch: 25/31	Total Loss 0.1413 (0.1458)
2022-11-02 23:33:34,951:INFO: Batch: 26/31	Total Loss 0.1397 (0.1455)
2022-11-02 23:33:34,999:INFO: Batch: 27/31	Total Loss 0.1355 (0.1452)
2022-11-02 23:33:35,051:INFO: Batch: 28/31	Total Loss 0.1440 (0.1452)
2022-11-02 23:33:35,101:INFO: Batch: 29/31	Total Loss 0.1409 (0.1450)
2022-11-02 23:33:35,131:INFO: Batch: 30/31	Total Loss 0.0568 (0.1443)
2022-11-02 23:33:35,281:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_66.pth.tar
2022-11-02 23:33:35,281:INFO: 
===> EPOCH: 67 (P1)
2022-11-02 23:33:35,281:INFO: - Computing loss (training)
2022-11-02 23:33:35,951:INFO: Batch:  0/31	Total Loss 0.1408 (0.1408)
2022-11-02 23:33:36,002:INFO: Batch:  1/31	Total Loss 0.1387 (0.1397)
2022-11-02 23:33:36,057:INFO: Batch:  2/31	Total Loss 0.1319 (0.1374)
2022-11-02 23:33:36,106:INFO: Batch:  3/31	Total Loss 0.1340 (0.1366)
2022-11-02 23:33:36,157:INFO: Batch:  4/31	Total Loss 0.1327 (0.1359)
2022-11-02 23:33:36,209:INFO: Batch:  5/31	Total Loss 0.1324 (0.1353)
2022-11-02 23:33:36,258:INFO: Batch:  6/31	Total Loss 0.1431 (0.1364)
2022-11-02 23:33:36,305:INFO: Batch:  7/31	Total Loss 0.1457 (0.1374)
2022-11-02 23:33:36,352:INFO: Batch:  8/31	Total Loss 0.1420 (0.1379)
2022-11-02 23:33:36,401:INFO: Batch:  9/31	Total Loss 0.1393 (0.1380)
2022-11-02 23:33:36,452:INFO: Batch: 10/31	Total Loss 0.1370 (0.1379)
2022-11-02 23:33:36,500:INFO: Batch: 11/31	Total Loss 0.1622 (0.1400)
2022-11-02 23:33:36,550:INFO: Batch: 12/31	Total Loss 0.1454 (0.1404)
2022-11-02 23:33:36,599:INFO: Batch: 13/31	Total Loss 0.1366 (0.1401)
2022-11-02 23:33:36,652:INFO: Batch: 14/31	Total Loss 0.1478 (0.1407)
2022-11-02 23:33:36,707:INFO: Batch: 15/31	Total Loss 0.1506 (0.1412)
2022-11-02 23:33:36,775:INFO: Batch: 16/31	Total Loss 0.1438 (0.1414)
2022-11-02 23:33:36,843:INFO: Batch: 17/31	Total Loss 0.1445 (0.1415)
2022-11-02 23:33:36,915:INFO: Batch: 18/31	Total Loss 0.1464 (0.1418)
2022-11-02 23:33:36,972:INFO: Batch: 19/31	Total Loss 0.1432 (0.1419)
2022-11-02 23:33:37,022:INFO: Batch: 20/31	Total Loss 0.1364 (0.1416)
2022-11-02 23:33:37,072:INFO: Batch: 21/31	Total Loss 0.1488 (0.1419)
2022-11-02 23:33:37,122:INFO: Batch: 22/31	Total Loss 0.1439 (0.1420)
2022-11-02 23:33:37,173:INFO: Batch: 23/31	Total Loss 0.1437 (0.1420)
2022-11-02 23:33:37,222:INFO: Batch: 24/31	Total Loss 0.1453 (0.1422)
2022-11-02 23:33:37,271:INFO: Batch: 25/31	Total Loss 0.1459 (0.1423)
2022-11-02 23:33:37,320:INFO: Batch: 26/31	Total Loss 0.1426 (0.1423)
2022-11-02 23:33:37,372:INFO: Batch: 27/31	Total Loss 0.1499 (0.1426)
2022-11-02 23:33:37,421:INFO: Batch: 28/31	Total Loss 0.1523 (0.1430)
2022-11-02 23:33:37,470:INFO: Batch: 29/31	Total Loss 0.1479 (0.1431)
2022-11-02 23:33:37,501:INFO: Batch: 30/31	Total Loss 0.0546 (0.1423)
2022-11-02 23:33:37,657:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_67.pth.tar
2022-11-02 23:33:37,657:INFO: 
===> EPOCH: 68 (P1)
2022-11-02 23:33:37,658:INFO: - Computing loss (training)
2022-11-02 23:33:38,342:INFO: Batch:  0/31	Total Loss 0.1411 (0.1411)
2022-11-02 23:33:38,394:INFO: Batch:  1/31	Total Loss 0.1420 (0.1416)
2022-11-02 23:33:38,446:INFO: Batch:  2/31	Total Loss 0.1449 (0.1427)
2022-11-02 23:33:38,497:INFO: Batch:  3/31	Total Loss 0.1336 (0.1406)
2022-11-02 23:33:38,546:INFO: Batch:  4/31	Total Loss 0.1357 (0.1396)
2022-11-02 23:33:38,600:INFO: Batch:  5/31	Total Loss 0.1497 (0.1414)
2022-11-02 23:33:38,648:INFO: Batch:  6/31	Total Loss 0.1531 (0.1432)
2022-11-02 23:33:38,697:INFO: Batch:  7/31	Total Loss 0.1315 (0.1418)
2022-11-02 23:33:38,744:INFO: Batch:  8/31	Total Loss 0.1382 (0.1414)
2022-11-02 23:33:38,791:INFO: Batch:  9/31	Total Loss 0.1404 (0.1413)
2022-11-02 23:33:38,842:INFO: Batch: 10/31	Total Loss 0.1246 (0.1397)
2022-11-02 23:33:38,890:INFO: Batch: 11/31	Total Loss 0.1329 (0.1391)
2022-11-02 23:33:38,940:INFO: Batch: 12/31	Total Loss 0.1488 (0.1399)
2022-11-02 23:33:38,989:INFO: Batch: 13/31	Total Loss 0.1393 (0.1399)
2022-11-02 23:33:39,041:INFO: Batch: 14/31	Total Loss 0.1448 (0.1403)
2022-11-02 23:33:39,092:INFO: Batch: 15/31	Total Loss 0.1408 (0.1403)
2022-11-02 23:33:39,143:INFO: Batch: 16/31	Total Loss 0.1411 (0.1403)
2022-11-02 23:33:39,192:INFO: Batch: 17/31	Total Loss 0.1507 (0.1410)
2022-11-02 23:33:39,242:INFO: Batch: 18/31	Total Loss 0.1330 (0.1406)
2022-11-02 23:33:39,294:INFO: Batch: 19/31	Total Loss 0.1348 (0.1402)
2022-11-02 23:33:39,344:INFO: Batch: 20/31	Total Loss 0.1274 (0.1396)
2022-11-02 23:33:39,394:INFO: Batch: 21/31	Total Loss 0.1321 (0.1393)
2022-11-02 23:33:39,444:INFO: Batch: 22/31	Total Loss 0.1289 (0.1388)
2022-11-02 23:33:39,494:INFO: Batch: 23/31	Total Loss 0.1341 (0.1386)
2022-11-02 23:33:39,544:INFO: Batch: 24/31	Total Loss 0.1526 (0.1392)
2022-11-02 23:33:39,593:INFO: Batch: 25/31	Total Loss 0.1256 (0.1387)
2022-11-02 23:33:39,642:INFO: Batch: 26/31	Total Loss 0.1337 (0.1385)
2022-11-02 23:33:39,691:INFO: Batch: 27/31	Total Loss 0.1335 (0.1383)
2022-11-02 23:33:39,742:INFO: Batch: 28/31	Total Loss 0.1329 (0.1381)
2022-11-02 23:33:39,792:INFO: Batch: 29/31	Total Loss 0.1235 (0.1376)
2022-11-02 23:33:39,822:INFO: Batch: 30/31	Total Loss 0.0543 (0.1369)
2022-11-02 23:33:39,959:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_68.pth.tar
2022-11-02 23:33:39,960:INFO: 
===> EPOCH: 69 (P1)
2022-11-02 23:33:39,960:INFO: - Computing loss (training)
2022-11-02 23:33:40,698:INFO: Batch:  0/31	Total Loss 0.1635 (0.1635)
2022-11-02 23:33:40,750:INFO: Batch:  1/31	Total Loss 0.1342 (0.1488)
2022-11-02 23:33:40,801:INFO: Batch:  2/31	Total Loss 0.1382 (0.1456)
2022-11-02 23:33:40,853:INFO: Batch:  3/31	Total Loss 0.1338 (0.1428)
2022-11-02 23:33:40,903:INFO: Batch:  4/31	Total Loss 0.1318 (0.1406)
2022-11-02 23:33:40,957:INFO: Batch:  5/31	Total Loss 0.1298 (0.1392)
2022-11-02 23:33:41,005:INFO: Batch:  6/31	Total Loss 0.1227 (0.1366)
2022-11-02 23:33:41,051:INFO: Batch:  7/31	Total Loss 0.1357 (0.1365)
2022-11-02 23:33:41,098:INFO: Batch:  8/31	Total Loss 0.1314 (0.1359)
2022-11-02 23:33:41,147:INFO: Batch:  9/31	Total Loss 0.1350 (0.1358)
2022-11-02 23:33:41,195:INFO: Batch: 10/31	Total Loss 0.1225 (0.1345)
2022-11-02 23:33:41,243:INFO: Batch: 11/31	Total Loss 0.1311 (0.1342)
2022-11-02 23:33:41,293:INFO: Batch: 12/31	Total Loss 0.1306 (0.1339)
2022-11-02 23:33:41,342:INFO: Batch: 13/31	Total Loss 0.1401 (0.1344)
2022-11-02 23:33:41,394:INFO: Batch: 14/31	Total Loss 0.1371 (0.1345)
2022-11-02 23:33:41,444:INFO: Batch: 15/31	Total Loss 0.1364 (0.1347)
2022-11-02 23:33:41,494:INFO: Batch: 16/31	Total Loss 0.1290 (0.1343)
2022-11-02 23:33:41,544:INFO: Batch: 17/31	Total Loss 0.1522 (0.1354)
2022-11-02 23:33:41,594:INFO: Batch: 18/31	Total Loss 0.1463 (0.1360)
2022-11-02 23:33:41,645:INFO: Batch: 19/31	Total Loss 0.1334 (0.1358)
2022-11-02 23:33:41,694:INFO: Batch: 20/31	Total Loss 0.1256 (0.1354)
2022-11-02 23:33:41,743:INFO: Batch: 21/31	Total Loss 0.1215 (0.1347)
2022-11-02 23:33:41,792:INFO: Batch: 22/31	Total Loss 0.1336 (0.1347)
2022-11-02 23:33:41,841:INFO: Batch: 23/31	Total Loss 0.1264 (0.1343)
2022-11-02 23:33:41,892:INFO: Batch: 24/31	Total Loss 0.1334 (0.1343)
2022-11-02 23:33:41,943:INFO: Batch: 25/31	Total Loss 0.1284 (0.1341)
2022-11-02 23:33:41,992:INFO: Batch: 26/31	Total Loss 0.1270 (0.1338)
2022-11-02 23:33:42,041:INFO: Batch: 27/31	Total Loss 0.1325 (0.1338)
2022-11-02 23:33:42,090:INFO: Batch: 28/31	Total Loss 0.1159 (0.1332)
2022-11-02 23:33:42,142:INFO: Batch: 29/31	Total Loss 0.1323 (0.1332)
2022-11-02 23:33:42,173:INFO: Batch: 30/31	Total Loss 0.0462 (0.1323)
2022-11-02 23:33:42,325:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_69.pth.tar
2022-11-02 23:33:42,326:INFO: 
===> EPOCH: 70 (P1)
2022-11-02 23:33:42,326:INFO: - Computing loss (training)
2022-11-02 23:33:42,991:INFO: Batch:  0/31	Total Loss 0.1259 (0.1259)
2022-11-02 23:33:43,040:INFO: Batch:  1/31	Total Loss 0.1295 (0.1274)
2022-11-02 23:33:43,095:INFO: Batch:  2/31	Total Loss 0.1348 (0.1301)
2022-11-02 23:33:43,143:INFO: Batch:  3/31	Total Loss 0.1291 (0.1299)
2022-11-02 23:33:43,191:INFO: Batch:  4/31	Total Loss 0.1423 (0.1322)
2022-11-02 23:33:43,243:INFO: Batch:  5/31	Total Loss 0.1378 (0.1331)
2022-11-02 23:33:43,290:INFO: Batch:  6/31	Total Loss 0.1272 (0.1322)
2022-11-02 23:33:43,337:INFO: Batch:  7/31	Total Loss 0.1293 (0.1318)
2022-11-02 23:33:43,384:INFO: Batch:  8/31	Total Loss 0.1205 (0.1305)
2022-11-02 23:33:43,430:INFO: Batch:  9/31	Total Loss 0.1416 (0.1315)
2022-11-02 23:33:43,478:INFO: Batch: 10/31	Total Loss 0.1251 (0.1310)
2022-11-02 23:33:43,527:INFO: Batch: 11/31	Total Loss 0.1278 (0.1307)
2022-11-02 23:33:43,576:INFO: Batch: 12/31	Total Loss 0.1336 (0.1309)
2022-11-02 23:33:43,625:INFO: Batch: 13/31	Total Loss 0.1312 (0.1309)
2022-11-02 23:33:43,674:INFO: Batch: 14/31	Total Loss 0.1228 (0.1304)
2022-11-02 23:33:43,725:INFO: Batch: 15/31	Total Loss 0.1195 (0.1298)
2022-11-02 23:33:43,776:INFO: Batch: 16/31	Total Loss 0.1225 (0.1293)
2022-11-02 23:33:43,824:INFO: Batch: 17/31	Total Loss 0.1330 (0.1295)
2022-11-02 23:33:43,874:INFO: Batch: 18/31	Total Loss 0.1268 (0.1294)
2022-11-02 23:33:43,922:INFO: Batch: 19/31	Total Loss 0.1294 (0.1294)
2022-11-02 23:33:43,974:INFO: Batch: 20/31	Total Loss 0.1299 (0.1294)
2022-11-02 23:33:44,024:INFO: Batch: 21/31	Total Loss 0.1278 (0.1293)
2022-11-02 23:33:44,072:INFO: Batch: 22/31	Total Loss 0.1365 (0.1297)
2022-11-02 23:33:44,121:INFO: Batch: 23/31	Total Loss 0.1300 (0.1297)
2022-11-02 23:33:44,170:INFO: Batch: 24/31	Total Loss 0.1237 (0.1294)
2022-11-02 23:33:44,221:INFO: Batch: 25/31	Total Loss 0.1301 (0.1295)
2022-11-02 23:33:44,271:INFO: Batch: 26/31	Total Loss 0.1397 (0.1298)
2022-11-02 23:33:44,320:INFO: Batch: 27/31	Total Loss 0.1270 (0.1297)
2022-11-02 23:33:44,368:INFO: Batch: 28/31	Total Loss 0.1321 (0.1298)
2022-11-02 23:33:44,417:INFO: Batch: 29/31	Total Loss 0.1274 (0.1297)
2022-11-02 23:33:44,449:INFO: Batch: 30/31	Total Loss 0.0487 (0.1288)
2022-11-02 23:33:44,600:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_70.pth.tar
2022-11-02 23:33:44,600:INFO: 
===> EPOCH: 71 (P1)
2022-11-02 23:33:44,600:INFO: - Computing loss (training)
2022-11-02 23:33:45,329:INFO: Batch:  0/31	Total Loss 0.1328 (0.1328)
2022-11-02 23:33:45,380:INFO: Batch:  1/31	Total Loss 0.1342 (0.1335)
2022-11-02 23:33:45,432:INFO: Batch:  2/31	Total Loss 0.1364 (0.1345)
2022-11-02 23:33:45,481:INFO: Batch:  3/31	Total Loss 0.1288 (0.1331)
2022-11-02 23:33:45,529:INFO: Batch:  4/31	Total Loss 0.1329 (0.1331)
2022-11-02 23:33:45,584:INFO: Batch:  5/31	Total Loss 0.1282 (0.1323)
2022-11-02 23:33:45,635:INFO: Batch:  6/31	Total Loss 0.1253 (0.1313)
2022-11-02 23:33:45,682:INFO: Batch:  7/31	Total Loss 0.1322 (0.1314)
2022-11-02 23:33:45,729:INFO: Batch:  8/31	Total Loss 0.1330 (0.1316)
2022-11-02 23:33:45,776:INFO: Batch:  9/31	Total Loss 0.1215 (0.1305)
2022-11-02 23:33:45,826:INFO: Batch: 10/31	Total Loss 0.1122 (0.1289)
2022-11-02 23:33:45,876:INFO: Batch: 11/31	Total Loss 0.1242 (0.1285)
2022-11-02 23:33:45,926:INFO: Batch: 12/31	Total Loss 0.1356 (0.1291)
2022-11-02 23:33:45,977:INFO: Batch: 13/31	Total Loss 0.1309 (0.1292)
2022-11-02 23:33:46,026:INFO: Batch: 14/31	Total Loss 0.1263 (0.1290)
2022-11-02 23:33:46,079:INFO: Batch: 15/31	Total Loss 0.1450 (0.1301)
2022-11-02 23:33:46,130:INFO: Batch: 16/31	Total Loss 0.1275 (0.1299)
2022-11-02 23:33:46,180:INFO: Batch: 17/31	Total Loss 0.1270 (0.1298)
2022-11-02 23:33:46,230:INFO: Batch: 18/31	Total Loss 0.1297 (0.1298)
2022-11-02 23:33:46,282:INFO: Batch: 19/31	Total Loss 0.1241 (0.1295)
2022-11-02 23:33:46,332:INFO: Batch: 20/31	Total Loss 0.1341 (0.1297)
2022-11-02 23:33:46,382:INFO: Batch: 21/31	Total Loss 0.1393 (0.1302)
2022-11-02 23:33:46,431:INFO: Batch: 22/31	Total Loss 0.1287 (0.1301)
2022-11-02 23:33:46,484:INFO: Batch: 23/31	Total Loss 0.1133 (0.1294)
2022-11-02 23:33:46,533:INFO: Batch: 24/31	Total Loss 0.1543 (0.1304)
2022-11-02 23:33:46,583:INFO: Batch: 25/31	Total Loss 0.1236 (0.1302)
2022-11-02 23:33:46,632:INFO: Batch: 26/31	Total Loss 0.1207 (0.1298)
2022-11-02 23:33:46,684:INFO: Batch: 27/31	Total Loss 0.1248 (0.1296)
2022-11-02 23:33:46,734:INFO: Batch: 28/31	Total Loss 0.1226 (0.1294)
2022-11-02 23:33:46,784:INFO: Batch: 29/31	Total Loss 0.1356 (0.1296)
2022-11-02 23:33:46,814:INFO: Batch: 30/31	Total Loss 0.0490 (0.1289)
2022-11-02 23:33:46,964:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_71.pth.tar
2022-11-02 23:33:46,965:INFO: 
===> EPOCH: 72 (P1)
2022-11-02 23:33:46,965:INFO: - Computing loss (training)
2022-11-02 23:33:47,615:INFO: Batch:  0/31	Total Loss 0.1312 (0.1312)
2022-11-02 23:33:47,670:INFO: Batch:  1/31	Total Loss 0.1222 (0.1266)
2022-11-02 23:33:47,723:INFO: Batch:  2/31	Total Loss 0.1224 (0.1252)
2022-11-02 23:33:47,769:INFO: Batch:  3/31	Total Loss 0.1278 (0.1259)
2022-11-02 23:33:47,817:INFO: Batch:  4/31	Total Loss 0.1334 (0.1273)
2022-11-02 23:33:47,867:INFO: Batch:  5/31	Total Loss 0.1204 (0.1262)
2022-11-02 23:33:47,915:INFO: Batch:  6/31	Total Loss 0.1271 (0.1263)
2022-11-02 23:33:47,964:INFO: Batch:  7/31	Total Loss 0.1295 (0.1267)
2022-11-02 23:33:48,010:INFO: Batch:  8/31	Total Loss 0.1236 (0.1263)
2022-11-02 23:33:48,056:INFO: Batch:  9/31	Total Loss 0.1137 (0.1252)
2022-11-02 23:33:48,106:INFO: Batch: 10/31	Total Loss 0.1243 (0.1251)
2022-11-02 23:33:48,153:INFO: Batch: 11/31	Total Loss 0.1149 (0.1242)
2022-11-02 23:33:48,202:INFO: Batch: 12/31	Total Loss 0.1166 (0.1236)
2022-11-02 23:33:48,251:INFO: Batch: 13/31	Total Loss 0.1228 (0.1235)
2022-11-02 23:33:48,300:INFO: Batch: 14/31	Total Loss 0.1174 (0.1231)
2022-11-02 23:33:48,352:INFO: Batch: 15/31	Total Loss 0.1209 (0.1230)
2022-11-02 23:33:48,402:INFO: Batch: 16/31	Total Loss 0.1349 (0.1236)
2022-11-02 23:33:48,452:INFO: Batch: 17/31	Total Loss 0.1210 (0.1235)
2022-11-02 23:33:48,500:INFO: Batch: 18/31	Total Loss 0.1168 (0.1231)
2022-11-02 23:33:48,549:INFO: Batch: 19/31	Total Loss 0.1117 (0.1225)
2022-11-02 23:33:48,601:INFO: Batch: 20/31	Total Loss 0.1372 (0.1231)
2022-11-02 23:33:48,650:INFO: Batch: 21/31	Total Loss 0.1098 (0.1226)
2022-11-02 23:33:48,699:INFO: Batch: 22/31	Total Loss 0.1138 (0.1222)
2022-11-02 23:33:48,747:INFO: Batch: 23/31	Total Loss 0.1180 (0.1220)
2022-11-02 23:33:48,796:INFO: Batch: 24/31	Total Loss 0.1194 (0.1219)
2022-11-02 23:33:48,847:INFO: Batch: 25/31	Total Loss 0.1239 (0.1220)
2022-11-02 23:33:48,897:INFO: Batch: 26/31	Total Loss 0.1162 (0.1218)
2022-11-02 23:33:48,945:INFO: Batch: 27/31	Total Loss 0.1116 (0.1214)
2022-11-02 23:33:48,994:INFO: Batch: 28/31	Total Loss 0.1288 (0.1216)
2022-11-02 23:33:49,042:INFO: Batch: 29/31	Total Loss 0.1208 (0.1216)
2022-11-02 23:33:49,074:INFO: Batch: 30/31	Total Loss 0.0420 (0.1208)
2022-11-02 23:33:49,232:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_72.pth.tar
2022-11-02 23:33:49,232:INFO: 
===> EPOCH: 73 (P1)
2022-11-02 23:33:49,232:INFO: - Computing loss (training)
2022-11-02 23:33:49,898:INFO: Batch:  0/31	Total Loss 0.1209 (0.1209)
2022-11-02 23:33:49,946:INFO: Batch:  1/31	Total Loss 0.1183 (0.1196)
2022-11-02 23:33:49,999:INFO: Batch:  2/31	Total Loss 0.1316 (0.1234)
2022-11-02 23:33:50,050:INFO: Batch:  3/31	Total Loss 0.1129 (0.1208)
2022-11-02 23:33:50,100:INFO: Batch:  4/31	Total Loss 0.1227 (0.1211)
2022-11-02 23:33:50,150:INFO: Batch:  5/31	Total Loss 0.1265 (0.1220)
2022-11-02 23:33:50,198:INFO: Batch:  6/31	Total Loss 0.1146 (0.1210)
2022-11-02 23:33:50,244:INFO: Batch:  7/31	Total Loss 0.1214 (0.1211)
2022-11-02 23:33:50,291:INFO: Batch:  8/31	Total Loss 0.1221 (0.1212)
2022-11-02 23:33:50,339:INFO: Batch:  9/31	Total Loss 0.1179 (0.1209)
2022-11-02 23:33:50,389:INFO: Batch: 10/31	Total Loss 0.1094 (0.1198)
2022-11-02 23:33:50,436:INFO: Batch: 11/31	Total Loss 0.1137 (0.1193)
2022-11-02 23:33:50,484:INFO: Batch: 12/31	Total Loss 0.1081 (0.1185)
2022-11-02 23:33:50,534:INFO: Batch: 13/31	Total Loss 0.1119 (0.1180)
2022-11-02 23:33:50,587:INFO: Batch: 14/31	Total Loss 0.1162 (0.1179)
2022-11-02 23:33:50,637:INFO: Batch: 15/31	Total Loss 0.1158 (0.1178)
2022-11-02 23:33:50,686:INFO: Batch: 16/31	Total Loss 0.1129 (0.1175)
2022-11-02 23:33:50,736:INFO: Batch: 17/31	Total Loss 0.1170 (0.1175)
2022-11-02 23:33:50,784:INFO: Batch: 18/31	Total Loss 0.1132 (0.1172)
2022-11-02 23:33:50,837:INFO: Batch: 19/31	Total Loss 0.1147 (0.1171)
2022-11-02 23:33:50,887:INFO: Batch: 20/31	Total Loss 0.1180 (0.1172)
2022-11-02 23:33:50,935:INFO: Batch: 21/31	Total Loss 0.1313 (0.1178)
2022-11-02 23:33:50,984:INFO: Batch: 22/31	Total Loss 0.1214 (0.1179)
2022-11-02 23:33:51,033:INFO: Batch: 23/31	Total Loss 0.1188 (0.1180)
2022-11-02 23:33:51,086:INFO: Batch: 24/31	Total Loss 0.1139 (0.1178)
2022-11-02 23:33:51,134:INFO: Batch: 25/31	Total Loss 0.1211 (0.1179)
2022-11-02 23:33:51,183:INFO: Batch: 26/31	Total Loss 0.1218 (0.1180)
2022-11-02 23:33:51,232:INFO: Batch: 27/31	Total Loss 0.1140 (0.1179)
2022-11-02 23:33:51,281:INFO: Batch: 28/31	Total Loss 0.1175 (0.1179)
2022-11-02 23:33:51,334:INFO: Batch: 29/31	Total Loss 0.1134 (0.1177)
2022-11-02 23:33:51,365:INFO: Batch: 30/31	Total Loss 0.0378 (0.1169)
2022-11-02 23:33:51,513:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_73.pth.tar
2022-11-02 23:33:51,513:INFO: 
===> EPOCH: 74 (P1)
2022-11-02 23:33:51,513:INFO: - Computing loss (training)
2022-11-02 23:33:52,177:INFO: Batch:  0/31	Total Loss 0.1320 (0.1320)
2022-11-02 23:33:52,225:INFO: Batch:  1/31	Total Loss 0.1143 (0.1230)
2022-11-02 23:33:52,278:INFO: Batch:  2/31	Total Loss 0.1234 (0.1232)
2022-11-02 23:33:52,328:INFO: Batch:  3/31	Total Loss 0.1159 (0.1213)
2022-11-02 23:33:52,374:INFO: Batch:  4/31	Total Loss 0.1182 (0.1206)
2022-11-02 23:33:52,426:INFO: Batch:  5/31	Total Loss 0.1093 (0.1187)
2022-11-02 23:33:52,475:INFO: Batch:  6/31	Total Loss 0.1232 (0.1194)
2022-11-02 23:33:52,521:INFO: Batch:  7/31	Total Loss 0.1174 (0.1191)
2022-11-02 23:33:52,568:INFO: Batch:  8/31	Total Loss 0.1190 (0.1191)
2022-11-02 23:33:52,614:INFO: Batch:  9/31	Total Loss 0.1105 (0.1182)
2022-11-02 23:33:52,663:INFO: Batch: 10/31	Total Loss 0.1169 (0.1181)
2022-11-02 23:33:52,711:INFO: Batch: 11/31	Total Loss 0.1150 (0.1178)
2022-11-02 23:33:52,761:INFO: Batch: 12/31	Total Loss 0.1107 (0.1173)
2022-11-02 23:33:52,810:INFO: Batch: 13/31	Total Loss 0.1140 (0.1171)
2022-11-02 23:33:52,859:INFO: Batch: 14/31	Total Loss 0.1082 (0.1165)
2022-11-02 23:33:52,910:INFO: Batch: 15/31	Total Loss 0.1152 (0.1164)
2022-11-02 23:33:52,959:INFO: Batch: 16/31	Total Loss 0.1176 (0.1165)
2022-11-02 23:33:53,009:INFO: Batch: 17/31	Total Loss 0.1128 (0.1163)
2022-11-02 23:33:53,058:INFO: Batch: 18/31	Total Loss 0.1287 (0.1169)
2022-11-02 23:33:53,107:INFO: Batch: 19/31	Total Loss 0.1095 (0.1165)
2022-11-02 23:33:53,157:INFO: Batch: 20/31	Total Loss 0.1104 (0.1163)
2022-11-02 23:33:53,207:INFO: Batch: 21/31	Total Loss 0.1083 (0.1159)
2022-11-02 23:33:53,256:INFO: Batch: 22/31	Total Loss 0.1113 (0.1157)
2022-11-02 23:33:53,304:INFO: Batch: 23/31	Total Loss 0.1097 (0.1154)
2022-11-02 23:33:53,353:INFO: Batch: 24/31	Total Loss 0.1066 (0.1151)
2022-11-02 23:33:53,404:INFO: Batch: 25/31	Total Loss 0.1047 (0.1147)
2022-11-02 23:33:53,455:INFO: Batch: 26/31	Total Loss 0.1040 (0.1143)
2022-11-02 23:33:53,503:INFO: Batch: 27/31	Total Loss 0.1141 (0.1143)
2022-11-02 23:33:53,552:INFO: Batch: 28/31	Total Loss 0.1167 (0.1143)
2022-11-02 23:33:53,600:INFO: Batch: 29/31	Total Loss 0.1059 (0.1141)
2022-11-02 23:33:53,631:INFO: Batch: 30/31	Total Loss 0.0467 (0.1134)
2022-11-02 23:33:53,786:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_74.pth.tar
2022-11-02 23:33:53,786:INFO: 
===> EPOCH: 75 (P1)
2022-11-02 23:33:53,787:INFO: - Computing loss (training)
2022-11-02 23:33:54,460:INFO: Batch:  0/31	Total Loss 0.1110 (0.1110)
2022-11-02 23:33:54,507:INFO: Batch:  1/31	Total Loss 0.1105 (0.1107)
2022-11-02 23:33:54,560:INFO: Batch:  2/31	Total Loss 0.1208 (0.1141)
2022-11-02 23:33:54,609:INFO: Batch:  3/31	Total Loss 0.1129 (0.1138)
2022-11-02 23:33:54,655:INFO: Batch:  4/31	Total Loss 0.1114 (0.1134)
2022-11-02 23:33:54,709:INFO: Batch:  5/31	Total Loss 0.1359 (0.1171)
2022-11-02 23:33:54,757:INFO: Batch:  6/31	Total Loss 0.1115 (0.1162)
2022-11-02 23:33:54,806:INFO: Batch:  7/31	Total Loss 0.1160 (0.1161)
2022-11-02 23:33:54,852:INFO: Batch:  8/31	Total Loss 0.1139 (0.1159)
2022-11-02 23:33:54,898:INFO: Batch:  9/31	Total Loss 0.1177 (0.1161)
2022-11-02 23:33:54,945:INFO: Batch: 10/31	Total Loss 0.1108 (0.1156)
2022-11-02 23:33:54,995:INFO: Batch: 11/31	Total Loss 0.1035 (0.1146)
2022-11-02 23:33:55,045:INFO: Batch: 12/31	Total Loss 0.1126 (0.1144)
2022-11-02 23:33:55,094:INFO: Batch: 13/31	Total Loss 0.1101 (0.1141)
2022-11-02 23:33:55,142:INFO: Batch: 14/31	Total Loss 0.1097 (0.1139)
2022-11-02 23:33:55,193:INFO: Batch: 15/31	Total Loss 0.1124 (0.1138)
2022-11-02 23:33:55,244:INFO: Batch: 16/31	Total Loss 0.1052 (0.1133)
2022-11-02 23:33:55,293:INFO: Batch: 17/31	Total Loss 0.1185 (0.1136)
2022-11-02 23:33:55,342:INFO: Batch: 18/31	Total Loss 0.1072 (0.1133)
2022-11-02 23:33:55,393:INFO: Batch: 19/31	Total Loss 0.1081 (0.1130)
2022-11-02 23:33:55,444:INFO: Batch: 20/31	Total Loss 0.1159 (0.1131)
2022-11-02 23:33:55,494:INFO: Batch: 21/31	Total Loss 0.1109 (0.1130)
2022-11-02 23:33:55,542:INFO: Batch: 22/31	Total Loss 0.1077 (0.1128)
2022-11-02 23:33:55,591:INFO: Batch: 23/31	Total Loss 0.1067 (0.1126)
2022-11-02 23:33:55,642:INFO: Batch: 24/31	Total Loss 0.1117 (0.1125)
2022-11-02 23:33:55,692:INFO: Batch: 25/31	Total Loss 0.1087 (0.1124)
2022-11-02 23:33:55,742:INFO: Batch: 26/31	Total Loss 0.1048 (0.1121)
2022-11-02 23:33:55,791:INFO: Batch: 27/31	Total Loss 0.1049 (0.1118)
2022-11-02 23:33:55,840:INFO: Batch: 28/31	Total Loss 0.1116 (0.1118)
2022-11-02 23:33:55,891:INFO: Batch: 29/31	Total Loss 0.1070 (0.1117)
2022-11-02 23:33:55,922:INFO: Batch: 30/31	Total Loss 0.0418 (0.1110)
2022-11-02 23:33:56,059:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_75.pth.tar
2022-11-02 23:33:56,059:INFO: 
===> EPOCH: 76 (P1)
2022-11-02 23:33:56,059:INFO: - Computing loss (training)
2022-11-02 23:33:56,714:INFO: Batch:  0/31	Total Loss 0.1059 (0.1059)
2022-11-02 23:33:56,768:INFO: Batch:  1/31	Total Loss 0.1144 (0.1103)
2022-11-02 23:33:56,825:INFO: Batch:  2/31	Total Loss 0.1100 (0.1102)
2022-11-02 23:33:56,872:INFO: Batch:  3/31	Total Loss 0.1033 (0.1087)
2022-11-02 23:33:56,920:INFO: Batch:  4/31	Total Loss 0.1173 (0.1103)
2022-11-02 23:33:56,975:INFO: Batch:  5/31	Total Loss 0.1239 (0.1126)
2022-11-02 23:33:57,024:INFO: Batch:  6/31	Total Loss 0.1129 (0.1126)
2022-11-02 23:33:57,073:INFO: Batch:  7/31	Total Loss 0.1210 (0.1137)
2022-11-02 23:33:57,120:INFO: Batch:  8/31	Total Loss 0.1121 (0.1135)
2022-11-02 23:33:57,169:INFO: Batch:  9/31	Total Loss 0.1119 (0.1133)
2022-11-02 23:33:57,217:INFO: Batch: 10/31	Total Loss 0.1246 (0.1144)
2022-11-02 23:33:57,267:INFO: Batch: 11/31	Total Loss 0.1118 (0.1142)
2022-11-02 23:33:57,317:INFO: Batch: 12/31	Total Loss 0.0965 (0.1128)
2022-11-02 23:33:57,367:INFO: Batch: 13/31	Total Loss 0.1128 (0.1128)
2022-11-02 23:33:57,420:INFO: Batch: 14/31	Total Loss 0.1096 (0.1125)
2022-11-02 23:33:57,470:INFO: Batch: 15/31	Total Loss 0.1105 (0.1124)
2022-11-02 23:33:57,520:INFO: Batch: 16/31	Total Loss 0.1182 (0.1128)
2022-11-02 23:33:57,571:INFO: Batch: 17/31	Total Loss 0.1022 (0.1121)
2022-11-02 23:33:57,621:INFO: Batch: 18/31	Total Loss 0.0979 (0.1114)
2022-11-02 23:33:57,673:INFO: Batch: 19/31	Total Loss 0.1221 (0.1119)
2022-11-02 23:33:57,723:INFO: Batch: 20/31	Total Loss 0.1020 (0.1114)
2022-11-02 23:33:57,772:INFO: Batch: 21/31	Total Loss 0.1108 (0.1114)
2022-11-02 23:33:57,822:INFO: Batch: 22/31	Total Loss 0.1178 (0.1116)
2022-11-02 23:33:57,875:INFO: Batch: 23/31	Total Loss 0.1200 (0.1120)
2022-11-02 23:33:57,926:INFO: Batch: 24/31	Total Loss 0.1121 (0.1120)
2022-11-02 23:33:57,975:INFO: Batch: 25/31	Total Loss 0.1042 (0.1117)
2022-11-02 23:33:58,023:INFO: Batch: 26/31	Total Loss 0.1061 (0.1114)
2022-11-02 23:33:58,072:INFO: Batch: 27/31	Total Loss 0.0984 (0.1110)
2022-11-02 23:33:58,124:INFO: Batch: 28/31	Total Loss 0.1066 (0.1109)
2022-11-02 23:33:58,173:INFO: Batch: 29/31	Total Loss 0.1141 (0.1110)
2022-11-02 23:33:58,204:INFO: Batch: 30/31	Total Loss 0.0450 (0.1103)
2022-11-02 23:33:58,357:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_76.pth.tar
2022-11-02 23:33:58,357:INFO: 
===> EPOCH: 77 (P1)
2022-11-02 23:33:58,358:INFO: - Computing loss (training)
2022-11-02 23:33:59,018:INFO: Batch:  0/31	Total Loss 0.1106 (0.1106)
2022-11-02 23:33:59,067:INFO: Batch:  1/31	Total Loss 0.1013 (0.1063)
2022-11-02 23:33:59,120:INFO: Batch:  2/31	Total Loss 0.1072 (0.1066)
2022-11-02 23:33:59,169:INFO: Batch:  3/31	Total Loss 0.1212 (0.1098)
2022-11-02 23:33:59,216:INFO: Batch:  4/31	Total Loss 0.1088 (0.1096)
2022-11-02 23:33:59,271:INFO: Batch:  5/31	Total Loss 0.1003 (0.1079)
2022-11-02 23:33:59,321:INFO: Batch:  6/31	Total Loss 0.1041 (0.1074)
2022-11-02 23:33:59,370:INFO: Batch:  7/31	Total Loss 0.1022 (0.1067)
2022-11-02 23:33:59,419:INFO: Batch:  8/31	Total Loss 0.1045 (0.1064)
2022-11-02 23:33:59,466:INFO: Batch:  9/31	Total Loss 0.1016 (0.1059)
2022-11-02 23:33:59,514:INFO: Batch: 10/31	Total Loss 0.1391 (0.1088)
2022-11-02 23:33:59,562:INFO: Batch: 11/31	Total Loss 0.1086 (0.1087)
2022-11-02 23:33:59,611:INFO: Batch: 12/31	Total Loss 0.1103 (0.1089)
2022-11-02 23:33:59,662:INFO: Batch: 13/31	Total Loss 0.1060 (0.1086)
2022-11-02 23:33:59,713:INFO: Batch: 14/31	Total Loss 0.0999 (0.1081)
2022-11-02 23:33:59,765:INFO: Batch: 15/31	Total Loss 0.0972 (0.1074)
2022-11-02 23:33:59,816:INFO: Batch: 16/31	Total Loss 0.1221 (0.1083)
2022-11-02 23:33:59,865:INFO: Batch: 17/31	Total Loss 0.0999 (0.1078)
2022-11-02 23:33:59,915:INFO: Batch: 18/31	Total Loss 0.1030 (0.1076)
2022-11-02 23:33:59,964:INFO: Batch: 19/31	Total Loss 0.1010 (0.1072)
2022-11-02 23:34:00,016:INFO: Batch: 20/31	Total Loss 0.1027 (0.1070)
2022-11-02 23:34:00,066:INFO: Batch: 21/31	Total Loss 0.1073 (0.1070)
2022-11-02 23:34:00,115:INFO: Batch: 22/31	Total Loss 0.1052 (0.1069)
2022-11-02 23:34:00,164:INFO: Batch: 23/31	Total Loss 0.1101 (0.1070)
2022-11-02 23:34:00,213:INFO: Batch: 24/31	Total Loss 0.1058 (0.1070)
2022-11-02 23:34:00,266:INFO: Batch: 25/31	Total Loss 0.1010 (0.1068)
2022-11-02 23:34:00,316:INFO: Batch: 26/31	Total Loss 0.1070 (0.1068)
2022-11-02 23:34:00,365:INFO: Batch: 27/31	Total Loss 0.0962 (0.1064)
2022-11-02 23:34:00,415:INFO: Batch: 28/31	Total Loss 0.1037 (0.1063)
2022-11-02 23:34:00,464:INFO: Batch: 29/31	Total Loss 0.1064 (0.1063)
2022-11-02 23:34:00,496:INFO: Batch: 30/31	Total Loss 0.0427 (0.1058)
2022-11-02 23:34:00,652:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_77.pth.tar
2022-11-02 23:34:00,652:INFO: 
===> EPOCH: 78 (P1)
2022-11-02 23:34:00,653:INFO: - Computing loss (training)
2022-11-02 23:34:01,324:INFO: Batch:  0/31	Total Loss 0.0986 (0.0986)
2022-11-02 23:34:01,375:INFO: Batch:  1/31	Total Loss 0.1030 (0.1007)
2022-11-02 23:34:01,434:INFO: Batch:  2/31	Total Loss 0.1063 (0.1025)
2022-11-02 23:34:01,482:INFO: Batch:  3/31	Total Loss 0.1012 (0.1022)
2022-11-02 23:34:01,535:INFO: Batch:  4/31	Total Loss 0.1088 (0.1036)
2022-11-02 23:34:01,588:INFO: Batch:  5/31	Total Loss 0.1034 (0.1036)
2022-11-02 23:34:01,638:INFO: Batch:  6/31	Total Loss 0.1007 (0.1031)
2022-11-02 23:34:01,685:INFO: Batch:  7/31	Total Loss 0.1069 (0.1036)
2022-11-02 23:34:01,734:INFO: Batch:  8/31	Total Loss 0.1112 (0.1045)
2022-11-02 23:34:01,784:INFO: Batch:  9/31	Total Loss 0.1094 (0.1050)
2022-11-02 23:34:01,834:INFO: Batch: 10/31	Total Loss 0.1066 (0.1051)
2022-11-02 23:34:01,884:INFO: Batch: 11/31	Total Loss 0.1041 (0.1050)
2022-11-02 23:34:01,935:INFO: Batch: 12/31	Total Loss 0.1085 (0.1052)
2022-11-02 23:34:01,987:INFO: Batch: 13/31	Total Loss 0.1029 (0.1051)
2022-11-02 23:34:02,040:INFO: Batch: 14/31	Total Loss 0.0994 (0.1047)
2022-11-02 23:34:02,092:INFO: Batch: 15/31	Total Loss 0.0931 (0.1039)
2022-11-02 23:34:02,143:INFO: Batch: 16/31	Total Loss 0.1064 (0.1040)
2022-11-02 23:34:02,195:INFO: Batch: 17/31	Total Loss 0.0972 (0.1037)
2022-11-02 23:34:02,250:INFO: Batch: 18/31	Total Loss 0.1023 (0.1036)
2022-11-02 23:34:02,301:INFO: Batch: 19/31	Total Loss 0.1021 (0.1035)
2022-11-02 23:34:02,353:INFO: Batch: 20/31	Total Loss 0.1195 (0.1042)
2022-11-02 23:34:02,405:INFO: Batch: 21/31	Total Loss 0.1033 (0.1042)
2022-11-02 23:34:02,458:INFO: Batch: 22/31	Total Loss 0.1113 (0.1045)
2022-11-02 23:34:02,508:INFO: Batch: 23/31	Total Loss 0.1039 (0.1044)
2022-11-02 23:34:02,558:INFO: Batch: 24/31	Total Loss 0.1035 (0.1044)
2022-11-02 23:34:02,607:INFO: Batch: 25/31	Total Loss 0.0992 (0.1042)
2022-11-02 23:34:02,660:INFO: Batch: 26/31	Total Loss 0.1021 (0.1041)
2022-11-02 23:34:02,710:INFO: Batch: 27/31	Total Loss 0.1150 (0.1045)
2022-11-02 23:34:02,760:INFO: Batch: 28/31	Total Loss 0.1003 (0.1043)
2022-11-02 23:34:02,811:INFO: Batch: 29/31	Total Loss 0.0989 (0.1042)
2022-11-02 23:34:02,841:INFO: Batch: 30/31	Total Loss 0.0424 (0.1034)
2022-11-02 23:34:02,991:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_78.pth.tar
2022-11-02 23:34:02,991:INFO: 
===> EPOCH: 79 (P1)
2022-11-02 23:34:02,992:INFO: - Computing loss (training)
2022-11-02 23:34:03,705:INFO: Batch:  0/31	Total Loss 0.1060 (0.1060)
2022-11-02 23:34:03,755:INFO: Batch:  1/31	Total Loss 0.1106 (0.1082)
2022-11-02 23:34:03,807:INFO: Batch:  2/31	Total Loss 0.0992 (0.1051)
2022-11-02 23:34:03,860:INFO: Batch:  3/31	Total Loss 0.0930 (0.1020)
2022-11-02 23:34:03,910:INFO: Batch:  4/31	Total Loss 0.1151 (0.1044)
2022-11-02 23:34:03,962:INFO: Batch:  5/31	Total Loss 0.1224 (0.1075)
2022-11-02 23:34:04,012:INFO: Batch:  6/31	Total Loss 0.1088 (0.1077)
2022-11-02 23:34:04,058:INFO: Batch:  7/31	Total Loss 0.1032 (0.1072)
2022-11-02 23:34:04,104:INFO: Batch:  8/31	Total Loss 0.1316 (0.1100)
2022-11-02 23:34:04,153:INFO: Batch:  9/31	Total Loss 0.1304 (0.1120)
2022-11-02 23:34:04,201:INFO: Batch: 10/31	Total Loss 0.1104 (0.1119)
2022-11-02 23:34:04,250:INFO: Batch: 11/31	Total Loss 0.1149 (0.1121)
2022-11-02 23:34:04,300:INFO: Batch: 12/31	Total Loss 0.1035 (0.1115)
2022-11-02 23:34:04,350:INFO: Batch: 13/31	Total Loss 0.1151 (0.1117)
2022-11-02 23:34:04,402:INFO: Batch: 14/31	Total Loss 0.0945 (0.1105)
2022-11-02 23:34:04,454:INFO: Batch: 15/31	Total Loss 0.0950 (0.1094)
2022-11-02 23:34:04,504:INFO: Batch: 16/31	Total Loss 0.1004 (0.1088)
2022-11-02 23:34:04,553:INFO: Batch: 17/31	Total Loss 0.0980 (0.1082)
2022-11-02 23:34:04,604:INFO: Batch: 18/31	Total Loss 0.1047 (0.1080)
2022-11-02 23:34:04,658:INFO: Batch: 19/31	Total Loss 0.0960 (0.1074)
2022-11-02 23:34:04,708:INFO: Batch: 20/31	Total Loss 0.0950 (0.1068)
2022-11-02 23:34:04,757:INFO: Batch: 21/31	Total Loss 0.1065 (0.1068)
2022-11-02 23:34:04,807:INFO: Batch: 22/31	Total Loss 0.1036 (0.1066)
2022-11-02 23:34:04,859:INFO: Batch: 23/31	Total Loss 0.0939 (0.1061)
2022-11-02 23:34:04,911:INFO: Batch: 24/31	Total Loss 0.0936 (0.1056)
2022-11-02 23:34:04,960:INFO: Batch: 25/31	Total Loss 0.0987 (0.1053)
2022-11-02 23:34:05,010:INFO: Batch: 26/31	Total Loss 0.1088 (0.1055)
2022-11-02 23:34:05,061:INFO: Batch: 27/31	Total Loss 0.0983 (0.1052)
2022-11-02 23:34:05,111:INFO: Batch: 28/31	Total Loss 0.0995 (0.1050)
2022-11-02 23:34:05,160:INFO: Batch: 29/31	Total Loss 0.0935 (0.1046)
2022-11-02 23:34:05,191:INFO: Batch: 30/31	Total Loss 0.0359 (0.1039)
2022-11-02 23:34:05,344:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_79.pth.tar
2022-11-02 23:34:05,344:INFO: 
===> EPOCH: 80 (P1)
2022-11-02 23:34:05,344:INFO: - Computing loss (training)
2022-11-02 23:34:06,038:INFO: Batch:  0/31	Total Loss 0.0952 (0.0952)
2022-11-02 23:34:06,093:INFO: Batch:  1/31	Total Loss 0.0994 (0.0972)
2022-11-02 23:34:06,150:INFO: Batch:  2/31	Total Loss 0.1002 (0.0981)
2022-11-02 23:34:06,198:INFO: Batch:  3/31	Total Loss 0.1000 (0.0986)
2022-11-02 23:34:06,250:INFO: Batch:  4/31	Total Loss 0.0937 (0.0976)
2022-11-02 23:34:06,302:INFO: Batch:  5/31	Total Loss 0.0972 (0.0976)
2022-11-02 23:34:06,352:INFO: Batch:  6/31	Total Loss 0.1011 (0.0980)
2022-11-02 23:34:06,401:INFO: Batch:  7/31	Total Loss 0.0922 (0.0973)
2022-11-02 23:34:06,454:INFO: Batch:  8/31	Total Loss 0.0901 (0.0966)
2022-11-02 23:34:06,504:INFO: Batch:  9/31	Total Loss 0.0934 (0.0963)
2022-11-02 23:34:06,555:INFO: Batch: 10/31	Total Loss 0.1035 (0.0970)
2022-11-02 23:34:06,605:INFO: Batch: 11/31	Total Loss 0.0984 (0.0971)
2022-11-02 23:34:06,657:INFO: Batch: 12/31	Total Loss 0.0971 (0.0971)
2022-11-02 23:34:06,712:INFO: Batch: 13/31	Total Loss 0.1030 (0.0975)
2022-11-02 23:34:06,764:INFO: Batch: 14/31	Total Loss 0.1011 (0.0977)
2022-11-02 23:34:06,816:INFO: Batch: 15/31	Total Loss 0.0918 (0.0974)
2022-11-02 23:34:06,867:INFO: Batch: 16/31	Total Loss 0.1013 (0.0976)
2022-11-02 23:34:06,920:INFO: Batch: 17/31	Total Loss 0.0978 (0.0976)
2022-11-02 23:34:06,973:INFO: Batch: 18/31	Total Loss 0.0891 (0.0971)
2022-11-02 23:34:07,025:INFO: Batch: 19/31	Total Loss 0.0973 (0.0971)
2022-11-02 23:34:07,076:INFO: Batch: 20/31	Total Loss 0.1006 (0.0973)
2022-11-02 23:34:07,131:INFO: Batch: 21/31	Total Loss 0.1207 (0.0983)
2022-11-02 23:34:07,182:INFO: Batch: 22/31	Total Loss 0.0997 (0.0983)
2022-11-02 23:34:07,233:INFO: Batch: 23/31	Total Loss 0.1026 (0.0985)
2022-11-02 23:34:07,285:INFO: Batch: 24/31	Total Loss 0.0992 (0.0985)
2022-11-02 23:34:07,339:INFO: Batch: 25/31	Total Loss 0.1043 (0.0987)
2022-11-02 23:34:07,390:INFO: Batch: 26/31	Total Loss 0.0966 (0.0986)
2022-11-02 23:34:07,442:INFO: Batch: 27/31	Total Loss 0.0967 (0.0986)
2022-11-02 23:34:07,495:INFO: Batch: 28/31	Total Loss 0.1011 (0.0987)
2022-11-02 23:34:07,548:INFO: Batch: 29/31	Total Loss 0.0931 (0.0985)
2022-11-02 23:34:07,580:INFO: Batch: 30/31	Total Loss 0.0368 (0.0979)
2022-11-02 23:34:07,738:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_80.pth.tar
2022-11-02 23:34:07,738:INFO: 
===> EPOCH: 81 (P1)
2022-11-02 23:34:07,738:INFO: - Computing loss (training)
2022-11-02 23:34:08,447:INFO: Batch:  0/31	Total Loss 0.1003 (0.1003)
2022-11-02 23:34:08,497:INFO: Batch:  1/31	Total Loss 0.0979 (0.0992)
2022-11-02 23:34:08,555:INFO: Batch:  2/31	Total Loss 0.0923 (0.0968)
2022-11-02 23:34:08,604:INFO: Batch:  3/31	Total Loss 0.0939 (0.0961)
2022-11-02 23:34:08,654:INFO: Batch:  4/31	Total Loss 0.0915 (0.0952)
2022-11-02 23:34:08,706:INFO: Batch:  5/31	Total Loss 0.0919 (0.0947)
2022-11-02 23:34:08,755:INFO: Batch:  6/31	Total Loss 0.0947 (0.0947)
2022-11-02 23:34:08,802:INFO: Batch:  7/31	Total Loss 0.0890 (0.0939)
2022-11-02 23:34:08,850:INFO: Batch:  8/31	Total Loss 0.1005 (0.0947)
2022-11-02 23:34:08,898:INFO: Batch:  9/31	Total Loss 0.0934 (0.0946)
2022-11-02 23:34:08,948:INFO: Batch: 10/31	Total Loss 0.1108 (0.0961)
2022-11-02 23:34:08,996:INFO: Batch: 11/31	Total Loss 0.1028 (0.0966)
2022-11-02 23:34:09,044:INFO: Batch: 12/31	Total Loss 0.1008 (0.0970)
2022-11-02 23:34:09,094:INFO: Batch: 13/31	Total Loss 0.1019 (0.0973)
2022-11-02 23:34:09,147:INFO: Batch: 14/31	Total Loss 0.0920 (0.0969)
2022-11-02 23:34:09,197:INFO: Batch: 15/31	Total Loss 0.0988 (0.0970)
2022-11-02 23:34:09,248:INFO: Batch: 16/31	Total Loss 0.1095 (0.0977)
2022-11-02 23:34:09,298:INFO: Batch: 17/31	Total Loss 0.1130 (0.0985)
2022-11-02 23:34:09,348:INFO: Batch: 18/31	Total Loss 0.0951 (0.0983)
2022-11-02 23:34:09,398:INFO: Batch: 19/31	Total Loss 0.1079 (0.0987)
2022-11-02 23:34:09,449:INFO: Batch: 20/31	Total Loss 0.1088 (0.0992)
2022-11-02 23:34:09,499:INFO: Batch: 21/31	Total Loss 0.1050 (0.0994)
2022-11-02 23:34:09,549:INFO: Batch: 22/31	Total Loss 0.1012 (0.0995)
2022-11-02 23:34:09,601:INFO: Batch: 23/31	Total Loss 0.0848 (0.0989)
2022-11-02 23:34:09,651:INFO: Batch: 24/31	Total Loss 0.1008 (0.0990)
2022-11-02 23:34:09,701:INFO: Batch: 25/31	Total Loss 0.1052 (0.0992)
2022-11-02 23:34:09,750:INFO: Batch: 26/31	Total Loss 0.0972 (0.0991)
2022-11-02 23:34:09,799:INFO: Batch: 27/31	Total Loss 0.0970 (0.0991)
2022-11-02 23:34:09,851:INFO: Batch: 28/31	Total Loss 0.0859 (0.0986)
2022-11-02 23:34:09,902:INFO: Batch: 29/31	Total Loss 0.1009 (0.0987)
2022-11-02 23:34:09,932:INFO: Batch: 30/31	Total Loss 0.0360 (0.0980)
2022-11-02 23:34:10,082:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_81.pth.tar
2022-11-02 23:34:10,082:INFO: 
===> EPOCH: 82 (P1)
2022-11-02 23:34:10,083:INFO: - Computing loss (training)
2022-11-02 23:34:10,753:INFO: Batch:  0/31	Total Loss 0.0944 (0.0944)
2022-11-02 23:34:10,812:INFO: Batch:  1/31	Total Loss 0.0897 (0.0921)
2022-11-02 23:34:10,868:INFO: Batch:  2/31	Total Loss 0.0945 (0.0929)
2022-11-02 23:34:10,917:INFO: Batch:  3/31	Total Loss 0.0997 (0.0945)
2022-11-02 23:34:10,969:INFO: Batch:  4/31	Total Loss 0.0994 (0.0955)
2022-11-02 23:34:11,022:INFO: Batch:  5/31	Total Loss 0.0943 (0.0953)
2022-11-02 23:34:11,070:INFO: Batch:  6/31	Total Loss 0.1007 (0.0961)
2022-11-02 23:34:11,120:INFO: Batch:  7/31	Total Loss 0.0903 (0.0953)
2022-11-02 23:34:11,168:INFO: Batch:  8/31	Total Loss 0.0934 (0.0951)
2022-11-02 23:34:11,217:INFO: Batch:  9/31	Total Loss 0.0960 (0.0952)
2022-11-02 23:34:11,264:INFO: Batch: 10/31	Total Loss 0.0988 (0.0955)
2022-11-02 23:34:11,312:INFO: Batch: 11/31	Total Loss 0.0947 (0.0955)
2022-11-02 23:34:11,362:INFO: Batch: 12/31	Total Loss 0.0892 (0.0949)
2022-11-02 23:34:11,413:INFO: Batch: 13/31	Total Loss 0.0957 (0.0950)
2022-11-02 23:34:11,466:INFO: Batch: 14/31	Total Loss 0.1017 (0.0954)
2022-11-02 23:34:11,517:INFO: Batch: 15/31	Total Loss 0.0889 (0.0950)
2022-11-02 23:34:11,567:INFO: Batch: 16/31	Total Loss 0.0918 (0.0948)
2022-11-02 23:34:11,618:INFO: Batch: 17/31	Total Loss 0.0871 (0.0944)
2022-11-02 23:34:11,668:INFO: Batch: 18/31	Total Loss 0.0923 (0.0943)
2022-11-02 23:34:11,721:INFO: Batch: 19/31	Total Loss 0.0921 (0.0942)
2022-11-02 23:34:11,771:INFO: Batch: 20/31	Total Loss 0.0951 (0.0943)
2022-11-02 23:34:11,819:INFO: Batch: 21/31	Total Loss 0.0964 (0.0944)
2022-11-02 23:34:11,868:INFO: Batch: 22/31	Total Loss 0.0962 (0.0945)
2022-11-02 23:34:11,920:INFO: Batch: 23/31	Total Loss 0.0864 (0.0941)
2022-11-02 23:34:11,972:INFO: Batch: 24/31	Total Loss 0.0945 (0.0942)
2022-11-02 23:34:12,022:INFO: Batch: 25/31	Total Loss 0.0964 (0.0942)
2022-11-02 23:34:12,070:INFO: Batch: 26/31	Total Loss 0.1034 (0.0945)
2022-11-02 23:34:12,120:INFO: Batch: 27/31	Total Loss 0.0990 (0.0947)
2022-11-02 23:34:12,171:INFO: Batch: 28/31	Total Loss 0.0911 (0.0946)
2022-11-02 23:34:12,221:INFO: Batch: 29/31	Total Loss 0.0968 (0.0947)
2022-11-02 23:34:12,252:INFO: Batch: 30/31	Total Loss 0.0334 (0.0942)
2022-11-02 23:34:12,400:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_82.pth.tar
2022-11-02 23:34:12,400:INFO: 
===> EPOCH: 83 (P1)
2022-11-02 23:34:12,401:INFO: - Computing loss (training)
2022-11-02 23:34:13,091:INFO: Batch:  0/31	Total Loss 0.1016 (0.1016)
2022-11-02 23:34:13,144:INFO: Batch:  1/31	Total Loss 0.0885 (0.0954)
2022-11-02 23:34:13,206:INFO: Batch:  2/31	Total Loss 0.0935 (0.0947)
2022-11-02 23:34:13,257:INFO: Batch:  3/31	Total Loss 0.0845 (0.0921)
2022-11-02 23:34:13,308:INFO: Batch:  4/31	Total Loss 0.1027 (0.0939)
2022-11-02 23:34:13,360:INFO: Batch:  5/31	Total Loss 0.1113 (0.0964)
2022-11-02 23:34:13,410:INFO: Batch:  6/31	Total Loss 0.1134 (0.0988)
2022-11-02 23:34:13,457:INFO: Batch:  7/31	Total Loss 0.0999 (0.0989)
2022-11-02 23:34:13,509:INFO: Batch:  8/31	Total Loss 0.0913 (0.0981)
2022-11-02 23:34:13,559:INFO: Batch:  9/31	Total Loss 0.0912 (0.0974)
2022-11-02 23:34:13,608:INFO: Batch: 10/31	Total Loss 0.0892 (0.0967)
2022-11-02 23:34:13,657:INFO: Batch: 11/31	Total Loss 0.0885 (0.0960)
2022-11-02 23:34:13,706:INFO: Batch: 12/31	Total Loss 0.0948 (0.0959)
2022-11-02 23:34:13,761:INFO: Batch: 13/31	Total Loss 0.0908 (0.0955)
2022-11-02 23:34:13,813:INFO: Batch: 14/31	Total Loss 0.1120 (0.0965)
2022-11-02 23:34:13,865:INFO: Batch: 15/31	Total Loss 0.1000 (0.0967)
2022-11-02 23:34:13,917:INFO: Batch: 16/31	Total Loss 0.1203 (0.0982)
2022-11-02 23:34:13,970:INFO: Batch: 17/31	Total Loss 0.0930 (0.0980)
2022-11-02 23:34:14,024:INFO: Batch: 18/31	Total Loss 0.1085 (0.0985)
2022-11-02 23:34:14,075:INFO: Batch: 19/31	Total Loss 0.0989 (0.0985)
2022-11-02 23:34:14,125:INFO: Batch: 20/31	Total Loss 0.0975 (0.0985)
2022-11-02 23:34:14,177:INFO: Batch: 21/31	Total Loss 0.0869 (0.0979)
2022-11-02 23:34:14,231:INFO: Batch: 22/31	Total Loss 0.0940 (0.0977)
2022-11-02 23:34:14,281:INFO: Batch: 23/31	Total Loss 0.0925 (0.0975)
2022-11-02 23:34:14,332:INFO: Batch: 24/31	Total Loss 0.0921 (0.0973)
2022-11-02 23:34:14,385:INFO: Batch: 25/31	Total Loss 0.1038 (0.0976)
2022-11-02 23:34:14,439:INFO: Batch: 26/31	Total Loss 0.0959 (0.0975)
2022-11-02 23:34:14,490:INFO: Batch: 27/31	Total Loss 0.0924 (0.0973)
2022-11-02 23:34:14,542:INFO: Batch: 28/31	Total Loss 0.0890 (0.0970)
2022-11-02 23:34:14,593:INFO: Batch: 29/31	Total Loss 0.0937 (0.0969)
2022-11-02 23:34:14,628:INFO: Batch: 30/31	Total Loss 0.0331 (0.0962)
2022-11-02 23:34:14,782:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_83.pth.tar
2022-11-02 23:34:14,782:INFO: 
===> EPOCH: 84 (P1)
2022-11-02 23:34:14,782:INFO: - Computing loss (training)
2022-11-02 23:34:15,451:INFO: Batch:  0/31	Total Loss 0.0893 (0.0893)
2022-11-02 23:34:15,500:INFO: Batch:  1/31	Total Loss 0.1134 (0.1015)
2022-11-02 23:34:15,557:INFO: Batch:  2/31	Total Loss 0.0897 (0.0976)
2022-11-02 23:34:15,605:INFO: Batch:  3/31	Total Loss 0.0951 (0.0970)
2022-11-02 23:34:15,655:INFO: Batch:  4/31	Total Loss 0.1016 (0.0979)
2022-11-02 23:34:15,708:INFO: Batch:  5/31	Total Loss 0.1094 (0.1000)
2022-11-02 23:34:15,756:INFO: Batch:  6/31	Total Loss 0.0932 (0.0991)
2022-11-02 23:34:15,804:INFO: Batch:  7/31	Total Loss 0.0881 (0.0978)
2022-11-02 23:34:15,851:INFO: Batch:  8/31	Total Loss 0.0928 (0.0972)
2022-11-02 23:34:15,900:INFO: Batch:  9/31	Total Loss 0.1076 (0.0983)
2022-11-02 23:34:15,948:INFO: Batch: 10/31	Total Loss 0.1075 (0.0992)
2022-11-02 23:34:15,998:INFO: Batch: 11/31	Total Loss 0.0944 (0.0988)
2022-11-02 23:34:16,047:INFO: Batch: 12/31	Total Loss 0.0869 (0.0979)
2022-11-02 23:34:16,095:INFO: Batch: 13/31	Total Loss 0.0923 (0.0975)
2022-11-02 23:34:16,147:INFO: Batch: 14/31	Total Loss 0.0971 (0.0975)
2022-11-02 23:34:16,198:INFO: Batch: 15/31	Total Loss 0.1042 (0.0979)
2022-11-02 23:34:16,247:INFO: Batch: 16/31	Total Loss 0.0911 (0.0975)
2022-11-02 23:34:16,297:INFO: Batch: 17/31	Total Loss 0.0860 (0.0969)
2022-11-02 23:34:16,347:INFO: Batch: 18/31	Total Loss 0.0932 (0.0966)
2022-11-02 23:34:16,399:INFO: Batch: 19/31	Total Loss 0.0986 (0.0967)
2022-11-02 23:34:16,449:INFO: Batch: 20/31	Total Loss 0.1086 (0.0973)
2022-11-02 23:34:16,499:INFO: Batch: 21/31	Total Loss 0.1049 (0.0976)
2022-11-02 23:34:16,549:INFO: Batch: 22/31	Total Loss 0.0871 (0.0972)
2022-11-02 23:34:16,603:INFO: Batch: 23/31	Total Loss 0.0886 (0.0968)
2022-11-02 23:34:16,652:INFO: Batch: 24/31	Total Loss 0.0995 (0.0969)
2022-11-02 23:34:16,701:INFO: Batch: 25/31	Total Loss 0.1018 (0.0971)
2022-11-02 23:34:16,750:INFO: Batch: 26/31	Total Loss 0.0947 (0.0971)
2022-11-02 23:34:16,798:INFO: Batch: 27/31	Total Loss 0.0783 (0.0964)
2022-11-02 23:34:16,850:INFO: Batch: 28/31	Total Loss 0.0837 (0.0960)
2022-11-02 23:34:16,900:INFO: Batch: 29/31	Total Loss 0.1044 (0.0963)
2022-11-02 23:34:16,930:INFO: Batch: 30/31	Total Loss 0.0362 (0.0958)
2022-11-02 23:34:17,085:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_84.pth.tar
2022-11-02 23:34:17,085:INFO: 
===> EPOCH: 85 (P1)
2022-11-02 23:34:17,086:INFO: - Computing loss (training)
2022-11-02 23:34:17,781:INFO: Batch:  0/31	Total Loss 0.0964 (0.0964)
2022-11-02 23:34:17,832:INFO: Batch:  1/31	Total Loss 0.0816 (0.0899)
2022-11-02 23:34:17,888:INFO: Batch:  2/31	Total Loss 0.0874 (0.0891)
2022-11-02 23:34:17,942:INFO: Batch:  3/31	Total Loss 0.0856 (0.0882)
2022-11-02 23:34:17,991:INFO: Batch:  4/31	Total Loss 0.0832 (0.0872)
2022-11-02 23:34:18,043:INFO: Batch:  5/31	Total Loss 0.0885 (0.0875)
2022-11-02 23:34:18,091:INFO: Batch:  6/31	Total Loss 0.0891 (0.0877)
2022-11-02 23:34:18,138:INFO: Batch:  7/31	Total Loss 0.0954 (0.0886)
2022-11-02 23:34:18,190:INFO: Batch:  8/31	Total Loss 0.0904 (0.0888)
2022-11-02 23:34:18,241:INFO: Batch:  9/31	Total Loss 0.0917 (0.0891)
2022-11-02 23:34:18,290:INFO: Batch: 10/31	Total Loss 0.0950 (0.0897)
2022-11-02 23:34:18,338:INFO: Batch: 11/31	Total Loss 0.0877 (0.0895)
2022-11-02 23:34:18,388:INFO: Batch: 12/31	Total Loss 0.0845 (0.0892)
2022-11-02 23:34:18,438:INFO: Batch: 13/31	Total Loss 0.0853 (0.0889)
2022-11-02 23:34:18,491:INFO: Batch: 14/31	Total Loss 0.0824 (0.0884)
2022-11-02 23:34:18,542:INFO: Batch: 15/31	Total Loss 0.0884 (0.0884)
2022-11-02 23:34:18,591:INFO: Batch: 16/31	Total Loss 0.0864 (0.0883)
2022-11-02 23:34:18,641:INFO: Batch: 17/31	Total Loss 0.0861 (0.0882)
2022-11-02 23:34:18,690:INFO: Batch: 18/31	Total Loss 0.0894 (0.0882)
2022-11-02 23:34:18,742:INFO: Batch: 19/31	Total Loss 0.0931 (0.0884)
2022-11-02 23:34:18,793:INFO: Batch: 20/31	Total Loss 0.0900 (0.0885)
2022-11-02 23:34:18,842:INFO: Batch: 21/31	Total Loss 0.0812 (0.0882)
2022-11-02 23:34:18,892:INFO: Batch: 22/31	Total Loss 0.0913 (0.0883)
2022-11-02 23:34:18,942:INFO: Batch: 23/31	Total Loss 0.0799 (0.0880)
2022-11-02 23:34:18,993:INFO: Batch: 24/31	Total Loss 0.0934 (0.0882)
2022-11-02 23:34:19,044:INFO: Batch: 25/31	Total Loss 0.0781 (0.0877)
2022-11-02 23:34:19,095:INFO: Batch: 26/31	Total Loss 0.0861 (0.0877)
2022-11-02 23:34:19,144:INFO: Batch: 27/31	Total Loss 0.0826 (0.0875)
2022-11-02 23:34:19,197:INFO: Batch: 28/31	Total Loss 0.0881 (0.0875)
2022-11-02 23:34:19,252:INFO: Batch: 29/31	Total Loss 0.0779 (0.0872)
2022-11-02 23:34:19,288:INFO: Batch: 30/31	Total Loss 0.0329 (0.0867)
2022-11-02 23:34:19,439:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_85.pth.tar
2022-11-02 23:34:19,439:INFO: 
===> EPOCH: 86 (P1)
2022-11-02 23:34:19,439:INFO: - Computing loss (training)
2022-11-02 23:34:20,119:INFO: Batch:  0/31	Total Loss 0.0954 (0.0954)
2022-11-02 23:34:20,172:INFO: Batch:  1/31	Total Loss 0.0863 (0.0904)
2022-11-02 23:34:20,223:INFO: Batch:  2/31	Total Loss 0.0789 (0.0868)
2022-11-02 23:34:20,273:INFO: Batch:  3/31	Total Loss 0.0849 (0.0863)
2022-11-02 23:34:20,324:INFO: Batch:  4/31	Total Loss 0.0847 (0.0860)
2022-11-02 23:34:20,377:INFO: Batch:  5/31	Total Loss 0.0900 (0.0867)
2022-11-02 23:34:20,425:INFO: Batch:  6/31	Total Loss 0.0858 (0.0866)
2022-11-02 23:34:20,474:INFO: Batch:  7/31	Total Loss 0.0920 (0.0872)
2022-11-02 23:34:20,521:INFO: Batch:  8/31	Total Loss 0.0932 (0.0879)
2022-11-02 23:34:20,571:INFO: Batch:  9/31	Total Loss 0.0886 (0.0880)
2022-11-02 23:34:20,619:INFO: Batch: 10/31	Total Loss 0.0769 (0.0868)
2022-11-02 23:34:20,668:INFO: Batch: 11/31	Total Loss 0.0820 (0.0864)
2022-11-02 23:34:20,718:INFO: Batch: 12/31	Total Loss 0.0809 (0.0860)
2022-11-02 23:34:20,769:INFO: Batch: 13/31	Total Loss 0.0831 (0.0858)
2022-11-02 23:34:20,822:INFO: Batch: 14/31	Total Loss 0.0838 (0.0856)
2022-11-02 23:34:20,873:INFO: Batch: 15/31	Total Loss 0.0797 (0.0853)
2022-11-02 23:34:20,925:INFO: Batch: 16/31	Total Loss 0.0826 (0.0851)
2022-11-02 23:34:20,975:INFO: Batch: 17/31	Total Loss 0.0859 (0.0852)
2022-11-02 23:34:21,026:INFO: Batch: 18/31	Total Loss 0.0856 (0.0852)
2022-11-02 23:34:21,084:INFO: Batch: 19/31	Total Loss 0.0868 (0.0853)
2022-11-02 23:34:21,134:INFO: Batch: 20/31	Total Loss 0.0846 (0.0853)
2022-11-02 23:34:21,183:INFO: Batch: 21/31	Total Loss 0.0899 (0.0855)
2022-11-02 23:34:21,234:INFO: Batch: 22/31	Total Loss 0.0898 (0.0857)
2022-11-02 23:34:21,285:INFO: Batch: 23/31	Total Loss 0.0993 (0.0863)
2022-11-02 23:34:21,335:INFO: Batch: 24/31	Total Loss 0.0808 (0.0861)
2022-11-02 23:34:21,385:INFO: Batch: 25/31	Total Loss 0.0782 (0.0857)
2022-11-02 23:34:21,436:INFO: Batch: 26/31	Total Loss 0.0846 (0.0857)
2022-11-02 23:34:21,489:INFO: Batch: 27/31	Total Loss 0.0878 (0.0858)
2022-11-02 23:34:21,539:INFO: Batch: 28/31	Total Loss 0.0861 (0.0858)
2022-11-02 23:34:21,588:INFO: Batch: 29/31	Total Loss 0.0807 (0.0856)
2022-11-02 23:34:21,618:INFO: Batch: 30/31	Total Loss 0.0285 (0.0851)
2022-11-02 23:34:21,772:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_86.pth.tar
2022-11-02 23:34:21,772:INFO: 
===> EPOCH: 87 (P1)
2022-11-02 23:34:21,772:INFO: - Computing loss (training)
2022-11-02 23:34:22,440:INFO: Batch:  0/31	Total Loss 0.0840 (0.0840)
2022-11-02 23:34:22,490:INFO: Batch:  1/31	Total Loss 0.0859 (0.0849)
2022-11-02 23:34:22,546:INFO: Batch:  2/31	Total Loss 0.0901 (0.0865)
2022-11-02 23:34:22,598:INFO: Batch:  3/31	Total Loss 0.0783 (0.0845)
2022-11-02 23:34:22,646:INFO: Batch:  4/31	Total Loss 0.0928 (0.0861)
2022-11-02 23:34:22,699:INFO: Batch:  5/31	Total Loss 0.0843 (0.0858)
2022-11-02 23:34:22,750:INFO: Batch:  6/31	Total Loss 0.1009 (0.0880)
2022-11-02 23:34:22,797:INFO: Batch:  7/31	Total Loss 0.0879 (0.0880)
2022-11-02 23:34:22,843:INFO: Batch:  8/31	Total Loss 0.0829 (0.0874)
2022-11-02 23:34:22,894:INFO: Batch:  9/31	Total Loss 0.0802 (0.0866)
2022-11-02 23:34:22,941:INFO: Batch: 10/31	Total Loss 0.0872 (0.0866)
2022-11-02 23:34:22,989:INFO: Batch: 11/31	Total Loss 0.0869 (0.0867)
2022-11-02 23:34:23,038:INFO: Batch: 12/31	Total Loss 0.0845 (0.0865)
2022-11-02 23:34:23,087:INFO: Batch: 13/31	Total Loss 0.0769 (0.0858)
2022-11-02 23:34:23,141:INFO: Batch: 14/31	Total Loss 0.0932 (0.0864)
2022-11-02 23:34:23,192:INFO: Batch: 15/31	Total Loss 0.0971 (0.0871)
2022-11-02 23:34:23,243:INFO: Batch: 16/31	Total Loss 0.0887 (0.0872)
2022-11-02 23:34:23,292:INFO: Batch: 17/31	Total Loss 0.0821 (0.0869)
2022-11-02 23:34:23,342:INFO: Batch: 18/31	Total Loss 0.0999 (0.0876)
2022-11-02 23:34:23,395:INFO: Batch: 19/31	Total Loss 0.0858 (0.0875)
2022-11-02 23:34:23,446:INFO: Batch: 20/31	Total Loss 0.0752 (0.0869)
2022-11-02 23:34:23,495:INFO: Batch: 21/31	Total Loss 0.0891 (0.0870)
2022-11-02 23:34:23,543:INFO: Batch: 22/31	Total Loss 0.0864 (0.0870)
2022-11-02 23:34:23,591:INFO: Batch: 23/31	Total Loss 0.0882 (0.0870)
2022-11-02 23:34:23,644:INFO: Batch: 24/31	Total Loss 0.0778 (0.0867)
2022-11-02 23:34:23,694:INFO: Batch: 25/31	Total Loss 0.0948 (0.0870)
2022-11-02 23:34:23,744:INFO: Batch: 26/31	Total Loss 0.0765 (0.0866)
2022-11-02 23:34:23,793:INFO: Batch: 27/31	Total Loss 0.0765 (0.0862)
2022-11-02 23:34:23,842:INFO: Batch: 28/31	Total Loss 0.0772 (0.0858)
2022-11-02 23:34:23,895:INFO: Batch: 29/31	Total Loss 0.0821 (0.0857)
2022-11-02 23:34:23,926:INFO: Batch: 30/31	Total Loss 0.0290 (0.0851)
2022-11-02 23:34:24,076:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_87.pth.tar
2022-11-02 23:34:24,076:INFO: 
===> EPOCH: 88 (P1)
2022-11-02 23:34:24,077:INFO: - Computing loss (training)
2022-11-02 23:34:24,748:INFO: Batch:  0/31	Total Loss 0.0795 (0.0795)
2022-11-02 23:34:24,800:INFO: Batch:  1/31	Total Loss 0.0820 (0.0808)
2022-11-02 23:34:24,855:INFO: Batch:  2/31	Total Loss 0.0791 (0.0802)
2022-11-02 23:34:24,903:INFO: Batch:  3/31	Total Loss 0.0920 (0.0833)
2022-11-02 23:34:24,955:INFO: Batch:  4/31	Total Loss 0.0739 (0.0815)
2022-11-02 23:34:25,005:INFO: Batch:  5/31	Total Loss 0.0837 (0.0818)
2022-11-02 23:34:25,054:INFO: Batch:  6/31	Total Loss 0.0738 (0.0808)
2022-11-02 23:34:25,101:INFO: Batch:  7/31	Total Loss 0.0753 (0.0802)
2022-11-02 23:34:25,149:INFO: Batch:  8/31	Total Loss 0.0757 (0.0797)
2022-11-02 23:34:25,198:INFO: Batch:  9/31	Total Loss 0.0802 (0.0798)
2022-11-02 23:34:25,248:INFO: Batch: 10/31	Total Loss 0.0857 (0.0803)
2022-11-02 23:34:25,296:INFO: Batch: 11/31	Total Loss 0.0777 (0.0800)
2022-11-02 23:34:25,346:INFO: Batch: 12/31	Total Loss 0.0727 (0.0794)
2022-11-02 23:34:25,395:INFO: Batch: 13/31	Total Loss 0.0785 (0.0794)
2022-11-02 23:34:25,446:INFO: Batch: 14/31	Total Loss 0.0888 (0.0799)
2022-11-02 23:34:25,498:INFO: Batch: 15/31	Total Loss 0.0787 (0.0798)
2022-11-02 23:34:25,548:INFO: Batch: 16/31	Total Loss 0.0771 (0.0796)
2022-11-02 23:34:25,598:INFO: Batch: 17/31	Total Loss 0.0918 (0.0803)
2022-11-02 23:34:25,647:INFO: Batch: 18/31	Total Loss 0.0840 (0.0805)
2022-11-02 23:34:25,698:INFO: Batch: 19/31	Total Loss 0.0916 (0.0810)
2022-11-02 23:34:25,748:INFO: Batch: 20/31	Total Loss 0.0782 (0.0809)
2022-11-02 23:34:25,798:INFO: Batch: 21/31	Total Loss 0.0714 (0.0804)
2022-11-02 23:34:25,847:INFO: Batch: 22/31	Total Loss 0.0736 (0.0802)
2022-11-02 23:34:25,896:INFO: Batch: 23/31	Total Loss 0.0851 (0.0804)
2022-11-02 23:34:25,948:INFO: Batch: 24/31	Total Loss 0.0728 (0.0801)
2022-11-02 23:34:25,997:INFO: Batch: 25/31	Total Loss 0.0738 (0.0798)
2022-11-02 23:34:26,047:INFO: Batch: 26/31	Total Loss 0.0721 (0.0796)
2022-11-02 23:34:26,096:INFO: Batch: 27/31	Total Loss 0.0847 (0.0798)
2022-11-02 23:34:26,145:INFO: Batch: 28/31	Total Loss 0.0847 (0.0799)
2022-11-02 23:34:26,196:INFO: Batch: 29/31	Total Loss 0.0753 (0.0798)
2022-11-02 23:34:26,228:INFO: Batch: 30/31	Total Loss 0.0291 (0.0792)
2022-11-02 23:34:26,372:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_88.pth.tar
2022-11-02 23:34:26,372:INFO: 
===> EPOCH: 89 (P1)
2022-11-02 23:34:26,372:INFO: - Computing loss (training)
2022-11-02 23:34:27,105:INFO: Batch:  0/31	Total Loss 0.0817 (0.0817)
2022-11-02 23:34:27,155:INFO: Batch:  1/31	Total Loss 0.0834 (0.0826)
2022-11-02 23:34:27,209:INFO: Batch:  2/31	Total Loss 0.0788 (0.0812)
2022-11-02 23:34:27,261:INFO: Batch:  3/31	Total Loss 0.0869 (0.0828)
2022-11-02 23:34:27,309:INFO: Batch:  4/31	Total Loss 0.0802 (0.0823)
2022-11-02 23:34:27,360:INFO: Batch:  5/31	Total Loss 0.0779 (0.0815)
2022-11-02 23:34:27,407:INFO: Batch:  6/31	Total Loss 0.0786 (0.0812)
2022-11-02 23:34:27,454:INFO: Batch:  7/31	Total Loss 0.0750 (0.0804)
2022-11-02 23:34:27,501:INFO: Batch:  8/31	Total Loss 0.0731 (0.0795)
2022-11-02 23:34:27,551:INFO: Batch:  9/31	Total Loss 0.0789 (0.0794)
2022-11-02 23:34:27,599:INFO: Batch: 10/31	Total Loss 0.0819 (0.0796)
2022-11-02 23:34:27,646:INFO: Batch: 11/31	Total Loss 0.0787 (0.0795)
2022-11-02 23:34:27,696:INFO: Batch: 12/31	Total Loss 0.0855 (0.0800)
2022-11-02 23:34:27,747:INFO: Batch: 13/31	Total Loss 0.0783 (0.0799)
2022-11-02 23:34:27,798:INFO: Batch: 14/31	Total Loss 0.0828 (0.0801)
2022-11-02 23:34:27,847:INFO: Batch: 15/31	Total Loss 0.0809 (0.0801)
2022-11-02 23:34:27,969:INFO: Batch: 16/31	Total Loss 0.0722 (0.0797)
2022-11-02 23:34:28,019:INFO: Batch: 17/31	Total Loss 0.0843 (0.0800)
2022-11-02 23:34:28,070:INFO: Batch: 18/31	Total Loss 0.0871 (0.0804)
2022-11-02 23:34:28,119:INFO: Batch: 19/31	Total Loss 0.0750 (0.0801)
2022-11-02 23:34:28,167:INFO: Batch: 20/31	Total Loss 0.0819 (0.0802)
2022-11-02 23:34:28,216:INFO: Batch: 21/31	Total Loss 0.0850 (0.0804)
2022-11-02 23:34:28,267:INFO: Batch: 22/31	Total Loss 0.0802 (0.0804)
2022-11-02 23:34:28,318:INFO: Batch: 23/31	Total Loss 0.0865 (0.0806)
2022-11-02 23:34:28,366:INFO: Batch: 24/31	Total Loss 0.0697 (0.0802)
2022-11-02 23:34:28,414:INFO: Batch: 25/31	Total Loss 0.0743 (0.0800)
2022-11-02 23:34:28,462:INFO: Batch: 26/31	Total Loss 0.0769 (0.0799)
2022-11-02 23:34:28,512:INFO: Batch: 27/31	Total Loss 0.0780 (0.0798)
2022-11-02 23:34:28,562:INFO: Batch: 28/31	Total Loss 0.0813 (0.0799)
2022-11-02 23:34:28,610:INFO: Batch: 29/31	Total Loss 0.0820 (0.0799)
2022-11-02 23:34:28,640:INFO: Batch: 30/31	Total Loss 0.0311 (0.0794)
2022-11-02 23:34:28,789:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_89.pth.tar
2022-11-02 23:34:28,789:INFO: 
===> EPOCH: 90 (P1)
2022-11-02 23:34:28,789:INFO: - Computing loss (training)
2022-11-02 23:34:29,465:INFO: Batch:  0/31	Total Loss 0.0820 (0.0820)
2022-11-02 23:34:29,515:INFO: Batch:  1/31	Total Loss 0.0881 (0.0849)
2022-11-02 23:34:29,566:INFO: Batch:  2/31	Total Loss 0.0850 (0.0849)
2022-11-02 23:34:29,615:INFO: Batch:  3/31	Total Loss 0.0868 (0.0854)
2022-11-02 23:34:29,666:INFO: Batch:  4/31	Total Loss 0.0821 (0.0846)
2022-11-02 23:34:29,720:INFO: Batch:  5/31	Total Loss 0.0805 (0.0839)
2022-11-02 23:34:29,769:INFO: Batch:  6/31	Total Loss 0.0872 (0.0844)
2022-11-02 23:34:29,817:INFO: Batch:  7/31	Total Loss 0.0830 (0.0842)
2022-11-02 23:34:29,864:INFO: Batch:  8/31	Total Loss 0.0884 (0.0847)
2022-11-02 23:34:29,911:INFO: Batch:  9/31	Total Loss 0.0899 (0.0852)
2022-11-02 23:34:29,961:INFO: Batch: 10/31	Total Loss 0.0860 (0.0853)
2022-11-02 23:34:30,011:INFO: Batch: 11/31	Total Loss 0.0719 (0.0840)
2022-11-02 23:34:30,060:INFO: Batch: 12/31	Total Loss 0.0982 (0.0851)
2022-11-02 23:34:30,110:INFO: Batch: 13/31	Total Loss 0.0939 (0.0857)
2022-11-02 23:34:30,159:INFO: Batch: 14/31	Total Loss 0.0815 (0.0854)
2022-11-02 23:34:30,211:INFO: Batch: 15/31	Total Loss 0.0751 (0.0847)
2022-11-02 23:34:30,262:INFO: Batch: 16/31	Total Loss 0.0761 (0.0842)
2022-11-02 23:34:30,311:INFO: Batch: 17/31	Total Loss 0.0787 (0.0840)
2022-11-02 23:34:30,362:INFO: Batch: 18/31	Total Loss 0.0769 (0.0836)
2022-11-02 23:34:30,412:INFO: Batch: 19/31	Total Loss 0.0807 (0.0835)
2022-11-02 23:34:30,463:INFO: Batch: 20/31	Total Loss 0.0763 (0.0832)
2022-11-02 23:34:30,512:INFO: Batch: 21/31	Total Loss 0.0706 (0.0826)
2022-11-02 23:34:30,562:INFO: Batch: 22/31	Total Loss 0.0703 (0.0821)
2022-11-02 23:34:30,612:INFO: Batch: 23/31	Total Loss 0.0732 (0.0817)
2022-11-02 23:34:30,662:INFO: Batch: 24/31	Total Loss 0.0746 (0.0814)
2022-11-02 23:34:30,712:INFO: Batch: 25/31	Total Loss 0.0775 (0.0813)
2022-11-02 23:34:30,761:INFO: Batch: 26/31	Total Loss 0.0776 (0.0811)
2022-11-02 23:34:30,812:INFO: Batch: 27/31	Total Loss 0.0790 (0.0810)
2022-11-02 23:34:30,860:INFO: Batch: 28/31	Total Loss 0.0815 (0.0811)
2022-11-02 23:34:30,911:INFO: Batch: 29/31	Total Loss 0.0710 (0.0807)
2022-11-02 23:34:30,942:INFO: Batch: 30/31	Total Loss 0.0260 (0.0802)
2022-11-02 23:34:31,102:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_90.pth.tar
2022-11-02 23:34:31,102:INFO: 
===> EPOCH: 91 (P1)
2022-11-02 23:34:31,103:INFO: - Computing loss (training)
2022-11-02 23:34:31,776:INFO: Batch:  0/31	Total Loss 0.1060 (0.1060)
2022-11-02 23:34:31,829:INFO: Batch:  1/31	Total Loss 0.0843 (0.0943)
2022-11-02 23:34:31,883:INFO: Batch:  2/31	Total Loss 0.0776 (0.0883)
2022-11-02 23:34:31,932:INFO: Batch:  3/31	Total Loss 0.0703 (0.0843)
2022-11-02 23:34:31,981:INFO: Batch:  4/31	Total Loss 0.0782 (0.0831)
2022-11-02 23:34:32,034:INFO: Batch:  5/31	Total Loss 0.0820 (0.0829)
2022-11-02 23:34:32,082:INFO: Batch:  6/31	Total Loss 0.0773 (0.0821)
2022-11-02 23:34:32,128:INFO: Batch:  7/31	Total Loss 0.0765 (0.0815)
2022-11-02 23:34:32,177:INFO: Batch:  8/31	Total Loss 0.0779 (0.0811)
2022-11-02 23:34:32,225:INFO: Batch:  9/31	Total Loss 0.0711 (0.0802)
2022-11-02 23:34:32,272:INFO: Batch: 10/31	Total Loss 0.0759 (0.0798)
2022-11-02 23:34:32,320:INFO: Batch: 11/31	Total Loss 0.0656 (0.0785)
2022-11-02 23:34:32,371:INFO: Batch: 12/31	Total Loss 0.0767 (0.0784)
2022-11-02 23:34:32,420:INFO: Batch: 13/31	Total Loss 0.0812 (0.0786)
2022-11-02 23:34:32,473:INFO: Batch: 14/31	Total Loss 0.0841 (0.0789)
2022-11-02 23:34:32,524:INFO: Batch: 15/31	Total Loss 0.0741 (0.0786)
2022-11-02 23:34:32,575:INFO: Batch: 16/31	Total Loss 0.0788 (0.0786)
2022-11-02 23:34:32,625:INFO: Batch: 17/31	Total Loss 0.0782 (0.0786)
2022-11-02 23:34:32,676:INFO: Batch: 18/31	Total Loss 0.0730 (0.0783)
2022-11-02 23:34:32,729:INFO: Batch: 19/31	Total Loss 0.0751 (0.0781)
2022-11-02 23:34:32,778:INFO: Batch: 20/31	Total Loss 0.0778 (0.0781)
2022-11-02 23:34:32,829:INFO: Batch: 21/31	Total Loss 0.0696 (0.0777)
2022-11-02 23:34:32,880:INFO: Batch: 22/31	Total Loss 0.0803 (0.0778)
2022-11-02 23:34:32,936:INFO: Batch: 23/31	Total Loss 0.0720 (0.0776)
2022-11-02 23:34:32,992:INFO: Batch: 24/31	Total Loss 0.0741 (0.0774)
2022-11-02 23:34:33,041:INFO: Batch: 25/31	Total Loss 0.0905 (0.0779)
2022-11-02 23:34:33,091:INFO: Batch: 26/31	Total Loss 0.0768 (0.0779)
2022-11-02 23:34:33,145:INFO: Batch: 27/31	Total Loss 0.0758 (0.0778)
2022-11-02 23:34:33,196:INFO: Batch: 28/31	Total Loss 0.0695 (0.0775)
2022-11-02 23:34:33,247:INFO: Batch: 29/31	Total Loss 0.0745 (0.0774)
2022-11-02 23:34:33,278:INFO: Batch: 30/31	Total Loss 0.0271 (0.0769)
2022-11-02 23:34:33,449:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_91.pth.tar
2022-11-02 23:34:33,449:INFO: 
===> EPOCH: 92 (P1)
2022-11-02 23:34:33,450:INFO: - Computing loss (training)
2022-11-02 23:34:34,131:INFO: Batch:  0/31	Total Loss 0.0731 (0.0731)
2022-11-02 23:34:34,179:INFO: Batch:  1/31	Total Loss 0.0805 (0.0765)
2022-11-02 23:34:34,233:INFO: Batch:  2/31	Total Loss 0.0718 (0.0749)
2022-11-02 23:34:34,288:INFO: Batch:  3/31	Total Loss 0.0804 (0.0763)
2022-11-02 23:34:34,335:INFO: Batch:  4/31	Total Loss 0.0731 (0.0756)
2022-11-02 23:34:34,388:INFO: Batch:  5/31	Total Loss 0.0702 (0.0748)
2022-11-02 23:34:34,436:INFO: Batch:  6/31	Total Loss 0.0726 (0.0745)
2022-11-02 23:34:34,483:INFO: Batch:  7/31	Total Loss 0.0772 (0.0748)
2022-11-02 23:34:34,530:INFO: Batch:  8/31	Total Loss 0.0740 (0.0747)
2022-11-02 23:34:34,579:INFO: Batch:  9/31	Total Loss 0.0838 (0.0756)
2022-11-02 23:34:34,628:INFO: Batch: 10/31	Total Loss 0.0703 (0.0752)
2022-11-02 23:34:34,676:INFO: Batch: 11/31	Total Loss 0.0719 (0.0749)
2022-11-02 23:34:34,726:INFO: Batch: 12/31	Total Loss 0.0912 (0.0760)
2022-11-02 23:34:34,776:INFO: Batch: 13/31	Total Loss 0.0821 (0.0764)
2022-11-02 23:34:34,828:INFO: Batch: 14/31	Total Loss 0.0758 (0.0764)
2022-11-02 23:34:34,879:INFO: Batch: 15/31	Total Loss 0.0763 (0.0764)
2022-11-02 23:34:34,928:INFO: Batch: 16/31	Total Loss 0.1039 (0.0781)
2022-11-02 23:34:34,978:INFO: Batch: 17/31	Total Loss 0.0771 (0.0781)
2022-11-02 23:34:35,029:INFO: Batch: 18/31	Total Loss 0.0729 (0.0778)
2022-11-02 23:34:35,081:INFO: Batch: 19/31	Total Loss 0.0652 (0.0771)
2022-11-02 23:34:35,131:INFO: Batch: 20/31	Total Loss 0.0801 (0.0773)
2022-11-02 23:34:35,181:INFO: Batch: 21/31	Total Loss 0.0582 (0.0764)
2022-11-02 23:34:35,231:INFO: Batch: 22/31	Total Loss 0.0873 (0.0769)
2022-11-02 23:34:35,280:INFO: Batch: 23/31	Total Loss 0.0852 (0.0772)
2022-11-02 23:34:35,331:INFO: Batch: 24/31	Total Loss 0.0773 (0.0772)
2022-11-02 23:34:35,382:INFO: Batch: 25/31	Total Loss 0.0714 (0.0770)
2022-11-02 23:34:35,431:INFO: Batch: 26/31	Total Loss 0.0746 (0.0769)
2022-11-02 23:34:35,481:INFO: Batch: 27/31	Total Loss 0.0830 (0.0771)
2022-11-02 23:34:35,534:INFO: Batch: 28/31	Total Loss 0.0724 (0.0770)
2022-11-02 23:34:35,585:INFO: Batch: 29/31	Total Loss 0.0788 (0.0770)
2022-11-02 23:34:35,617:INFO: Batch: 30/31	Total Loss 0.0265 (0.0764)
2022-11-02 23:34:35,770:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_92.pth.tar
2022-11-02 23:34:35,770:INFO: 
===> EPOCH: 93 (P1)
2022-11-02 23:34:35,770:INFO: - Computing loss (training)
2022-11-02 23:34:36,457:INFO: Batch:  0/31	Total Loss 0.0749 (0.0749)
2022-11-02 23:34:36,507:INFO: Batch:  1/31	Total Loss 0.0788 (0.0767)
2022-11-02 23:34:36,564:INFO: Batch:  2/31	Total Loss 0.0779 (0.0771)
2022-11-02 23:34:36,611:INFO: Batch:  3/31	Total Loss 0.0739 (0.0762)
2022-11-02 23:34:36,658:INFO: Batch:  4/31	Total Loss 0.0724 (0.0754)
2022-11-02 23:34:36,710:INFO: Batch:  5/31	Total Loss 0.0652 (0.0738)
2022-11-02 23:34:36,758:INFO: Batch:  6/31	Total Loss 0.0714 (0.0735)
2022-11-02 23:34:36,807:INFO: Batch:  7/31	Total Loss 0.0667 (0.0727)
2022-11-02 23:34:36,855:INFO: Batch:  8/31	Total Loss 0.0885 (0.0745)
2022-11-02 23:34:36,901:INFO: Batch:  9/31	Total Loss 0.0735 (0.0744)
2022-11-02 23:34:36,951:INFO: Batch: 10/31	Total Loss 0.0773 (0.0746)
2022-11-02 23:34:36,999:INFO: Batch: 11/31	Total Loss 0.0849 (0.0754)
2022-11-02 23:34:37,049:INFO: Batch: 12/31	Total Loss 0.0789 (0.0757)
2022-11-02 23:34:37,099:INFO: Batch: 13/31	Total Loss 0.0843 (0.0763)
2022-11-02 23:34:37,149:INFO: Batch: 14/31	Total Loss 0.0745 (0.0762)
2022-11-02 23:34:37,201:INFO: Batch: 15/31	Total Loss 0.1003 (0.0777)
2022-11-02 23:34:37,252:INFO: Batch: 16/31	Total Loss 0.0947 (0.0786)
2022-11-02 23:34:37,301:INFO: Batch: 17/31	Total Loss 0.0619 (0.0777)
2022-11-02 23:34:37,351:INFO: Batch: 18/31	Total Loss 0.0768 (0.0776)
2022-11-02 23:34:37,403:INFO: Batch: 19/31	Total Loss 0.0804 (0.0778)
2022-11-02 23:34:37,454:INFO: Batch: 20/31	Total Loss 0.0837 (0.0781)
2022-11-02 23:34:37,504:INFO: Batch: 21/31	Total Loss 0.0659 (0.0775)
2022-11-02 23:34:37,554:INFO: Batch: 22/31	Total Loss 0.0730 (0.0773)
2022-11-02 23:34:37,603:INFO: Batch: 23/31	Total Loss 0.0724 (0.0771)
2022-11-02 23:34:37,655:INFO: Batch: 24/31	Total Loss 0.0863 (0.0775)
2022-11-02 23:34:37,705:INFO: Batch: 25/31	Total Loss 0.0650 (0.0771)
2022-11-02 23:34:37,754:INFO: Batch: 26/31	Total Loss 0.0683 (0.0767)
2022-11-02 23:34:37,804:INFO: Batch: 27/31	Total Loss 0.0697 (0.0764)
2022-11-02 23:34:37,852:INFO: Batch: 28/31	Total Loss 0.0774 (0.0765)
2022-11-02 23:34:37,905:INFO: Batch: 29/31	Total Loss 0.0802 (0.0766)
2022-11-02 23:34:37,936:INFO: Batch: 30/31	Total Loss 0.0241 (0.0761)
2022-11-02 23:34:38,082:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_93.pth.tar
2022-11-02 23:34:38,082:INFO: 
===> EPOCH: 94 (P1)
2022-11-02 23:34:38,082:INFO: - Computing loss (training)
2022-11-02 23:34:38,783:INFO: Batch:  0/31	Total Loss 0.0698 (0.0698)
2022-11-02 23:34:38,833:INFO: Batch:  1/31	Total Loss 0.0735 (0.0715)
2022-11-02 23:34:38,887:INFO: Batch:  2/31	Total Loss 0.0677 (0.0703)
2022-11-02 23:34:38,938:INFO: Batch:  3/31	Total Loss 0.0668 (0.0694)
2022-11-02 23:34:38,985:INFO: Batch:  4/31	Total Loss 0.0722 (0.0699)
2022-11-02 23:34:39,038:INFO: Batch:  5/31	Total Loss 0.0638 (0.0690)
2022-11-02 23:34:39,087:INFO: Batch:  6/31	Total Loss 0.0753 (0.0699)
2022-11-02 23:34:39,133:INFO: Batch:  7/31	Total Loss 0.0774 (0.0706)
2022-11-02 23:34:39,179:INFO: Batch:  8/31	Total Loss 0.0683 (0.0704)
2022-11-02 23:34:39,230:INFO: Batch:  9/31	Total Loss 0.0770 (0.0710)
2022-11-02 23:34:39,280:INFO: Batch: 10/31	Total Loss 0.0708 (0.0710)
2022-11-02 23:34:39,327:INFO: Batch: 11/31	Total Loss 0.0727 (0.0711)
2022-11-02 23:34:39,377:INFO: Batch: 12/31	Total Loss 0.0717 (0.0712)
2022-11-02 23:34:39,428:INFO: Batch: 13/31	Total Loss 0.0677 (0.0709)
2022-11-02 23:34:39,482:INFO: Batch: 14/31	Total Loss 0.0751 (0.0712)
2022-11-02 23:34:39,533:INFO: Batch: 15/31	Total Loss 0.0698 (0.0711)
2022-11-02 23:34:39,584:INFO: Batch: 16/31	Total Loss 0.0939 (0.0725)
2022-11-02 23:34:39,635:INFO: Batch: 17/31	Total Loss 0.0686 (0.0723)
2022-11-02 23:34:39,686:INFO: Batch: 18/31	Total Loss 0.0655 (0.0719)
2022-11-02 23:34:39,739:INFO: Batch: 19/31	Total Loss 0.0781 (0.0723)
2022-11-02 23:34:39,789:INFO: Batch: 20/31	Total Loss 0.0707 (0.0722)
2022-11-02 23:34:39,840:INFO: Batch: 21/31	Total Loss 0.0680 (0.0720)
2022-11-02 23:34:39,891:INFO: Batch: 22/31	Total Loss 0.0670 (0.0718)
2022-11-02 23:34:39,944:INFO: Batch: 23/31	Total Loss 0.0827 (0.0722)
2022-11-02 23:34:39,995:INFO: Batch: 24/31	Total Loss 0.0785 (0.0725)
2022-11-02 23:34:40,046:INFO: Batch: 25/31	Total Loss 0.0666 (0.0722)
2022-11-02 23:34:40,097:INFO: Batch: 26/31	Total Loss 0.0642 (0.0719)
2022-11-02 23:34:40,152:INFO: Batch: 27/31	Total Loss 0.0717 (0.0719)
2022-11-02 23:34:40,202:INFO: Batch: 28/31	Total Loss 0.0673 (0.0718)
2022-11-02 23:34:40,252:INFO: Batch: 29/31	Total Loss 0.0678 (0.0716)
2022-11-02 23:34:40,284:INFO: Batch: 30/31	Total Loss 0.0280 (0.0713)
2022-11-02 23:34:40,444:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_94.pth.tar
2022-11-02 23:34:40,444:INFO: 
===> EPOCH: 95 (P1)
2022-11-02 23:34:40,444:INFO: - Computing loss (training)
2022-11-02 23:34:41,140:INFO: Batch:  0/31	Total Loss 0.0749 (0.0749)
2022-11-02 23:34:41,190:INFO: Batch:  1/31	Total Loss 0.0840 (0.0794)
2022-11-02 23:34:41,244:INFO: Batch:  2/31	Total Loss 0.0699 (0.0762)
2022-11-02 23:34:41,296:INFO: Batch:  3/31	Total Loss 0.0713 (0.0749)
2022-11-02 23:34:41,343:INFO: Batch:  4/31	Total Loss 0.0581 (0.0717)
2022-11-02 23:34:41,399:INFO: Batch:  5/31	Total Loss 0.0705 (0.0715)
2022-11-02 23:34:41,447:INFO: Batch:  6/31	Total Loss 0.0704 (0.0713)
2022-11-02 23:34:41,497:INFO: Batch:  7/31	Total Loss 0.0642 (0.0704)
2022-11-02 23:34:41,545:INFO: Batch:  8/31	Total Loss 0.0685 (0.0701)
2022-11-02 23:34:41,595:INFO: Batch:  9/31	Total Loss 0.0846 (0.0715)
2022-11-02 23:34:41,642:INFO: Batch: 10/31	Total Loss 0.0695 (0.0713)
2022-11-02 23:34:41,691:INFO: Batch: 11/31	Total Loss 0.0670 (0.0710)
2022-11-02 23:34:41,742:INFO: Batch: 12/31	Total Loss 0.0657 (0.0706)
2022-11-02 23:34:41,794:INFO: Batch: 13/31	Total Loss 0.0745 (0.0708)
2022-11-02 23:34:41,845:INFO: Batch: 14/31	Total Loss 0.0653 (0.0704)
2022-11-02 23:34:41,895:INFO: Batch: 15/31	Total Loss 0.0685 (0.0703)
2022-11-02 23:34:41,945:INFO: Batch: 16/31	Total Loss 0.0690 (0.0702)
2022-11-02 23:34:41,996:INFO: Batch: 17/31	Total Loss 0.0807 (0.0708)
2022-11-02 23:34:42,048:INFO: Batch: 18/31	Total Loss 0.0706 (0.0708)
2022-11-02 23:34:42,099:INFO: Batch: 19/31	Total Loss 0.0677 (0.0706)
2022-11-02 23:34:42,149:INFO: Batch: 20/31	Total Loss 0.0687 (0.0705)
2022-11-02 23:34:42,198:INFO: Batch: 21/31	Total Loss 0.0668 (0.0704)
2022-11-02 23:34:42,249:INFO: Batch: 22/31	Total Loss 0.0668 (0.0702)
2022-11-02 23:34:42,299:INFO: Batch: 23/31	Total Loss 0.0694 (0.0702)
2022-11-02 23:34:42,348:INFO: Batch: 24/31	Total Loss 0.0650 (0.0700)
2022-11-02 23:34:42,398:INFO: Batch: 25/31	Total Loss 0.0665 (0.0698)
2022-11-02 23:34:42,450:INFO: Batch: 26/31	Total Loss 0.0788 (0.0702)
2022-11-02 23:34:42,500:INFO: Batch: 27/31	Total Loss 0.0694 (0.0702)
2022-11-02 23:34:42,549:INFO: Batch: 28/31	Total Loss 0.0616 (0.0699)
2022-11-02 23:34:42,598:INFO: Batch: 29/31	Total Loss 0.0700 (0.0699)
2022-11-02 23:34:42,629:INFO: Batch: 30/31	Total Loss 0.0236 (0.0695)
2022-11-02 23:34:42,789:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_95.pth.tar
2022-11-02 23:34:42,789:INFO: 
===> EPOCH: 96 (P1)
2022-11-02 23:34:42,789:INFO: - Computing loss (training)
2022-11-02 23:34:43,471:INFO: Batch:  0/31	Total Loss 0.0757 (0.0757)
2022-11-02 23:34:43,520:INFO: Batch:  1/31	Total Loss 0.0676 (0.0716)
2022-11-02 23:34:43,572:INFO: Batch:  2/31	Total Loss 0.0690 (0.0708)
2022-11-02 23:34:43,620:INFO: Batch:  3/31	Total Loss 0.0677 (0.0700)
2022-11-02 23:34:43,669:INFO: Batch:  4/31	Total Loss 0.0720 (0.0704)
2022-11-02 23:34:43,726:INFO: Batch:  5/31	Total Loss 0.0628 (0.0691)
2022-11-02 23:34:43,776:INFO: Batch:  6/31	Total Loss 0.0709 (0.0694)
2022-11-02 23:34:43,825:INFO: Batch:  7/31	Total Loss 0.0675 (0.0691)
2022-11-02 23:34:43,872:INFO: Batch:  8/31	Total Loss 0.0588 (0.0681)
2022-11-02 23:34:43,919:INFO: Batch:  9/31	Total Loss 0.0670 (0.0680)
2022-11-02 23:34:43,968:INFO: Batch: 10/31	Total Loss 0.0655 (0.0677)
2022-11-02 23:34:44,020:INFO: Batch: 11/31	Total Loss 0.0639 (0.0674)
2022-11-02 23:34:44,069:INFO: Batch: 12/31	Total Loss 0.0769 (0.0681)
2022-11-02 23:34:44,120:INFO: Batch: 13/31	Total Loss 0.0691 (0.0682)
2022-11-02 23:34:44,169:INFO: Batch: 14/31	Total Loss 0.0638 (0.0679)
2022-11-02 23:34:44,220:INFO: Batch: 15/31	Total Loss 0.0699 (0.0680)
2022-11-02 23:34:44,271:INFO: Batch: 16/31	Total Loss 0.0647 (0.0678)
2022-11-02 23:34:44,320:INFO: Batch: 17/31	Total Loss 0.0719 (0.0681)
2022-11-02 23:34:44,370:INFO: Batch: 18/31	Total Loss 0.0661 (0.0680)
2022-11-02 23:34:44,420:INFO: Batch: 19/31	Total Loss 0.0730 (0.0682)
2022-11-02 23:34:44,471:INFO: Batch: 20/31	Total Loss 0.0617 (0.0679)
2022-11-02 23:34:44,520:INFO: Batch: 21/31	Total Loss 0.0670 (0.0679)
2022-11-02 23:34:44,569:INFO: Batch: 22/31	Total Loss 0.0640 (0.0677)
2022-11-02 23:34:44,619:INFO: Batch: 23/31	Total Loss 0.0609 (0.0674)
2022-11-02 23:34:44,668:INFO: Batch: 24/31	Total Loss 0.0704 (0.0676)
2022-11-02 23:34:44,719:INFO: Batch: 25/31	Total Loss 0.0773 (0.0679)
2022-11-02 23:34:44,768:INFO: Batch: 26/31	Total Loss 0.0669 (0.0679)
2022-11-02 23:34:44,818:INFO: Batch: 27/31	Total Loss 0.0612 (0.0677)
2022-11-02 23:34:44,867:INFO: Batch: 28/31	Total Loss 0.0586 (0.0674)
2022-11-02 23:34:44,916:INFO: Batch: 29/31	Total Loss 0.0697 (0.0675)
2022-11-02 23:34:44,948:INFO: Batch: 30/31	Total Loss 0.0335 (0.0671)
2022-11-02 23:34:45,105:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_96.pth.tar
2022-11-02 23:34:45,106:INFO: 
===> EPOCH: 97 (P1)
2022-11-02 23:34:45,106:INFO: - Computing loss (training)
2022-11-02 23:34:45,825:INFO: Batch:  0/31	Total Loss 0.0642 (0.0642)
2022-11-02 23:34:45,875:INFO: Batch:  1/31	Total Loss 0.0633 (0.0637)
2022-11-02 23:34:45,931:INFO: Batch:  2/31	Total Loss 0.0659 (0.0644)
2022-11-02 23:34:45,982:INFO: Batch:  3/31	Total Loss 0.0697 (0.0659)
2022-11-02 23:34:46,028:INFO: Batch:  4/31	Total Loss 0.0645 (0.0656)
2022-11-02 23:34:46,081:INFO: Batch:  5/31	Total Loss 0.0711 (0.0665)
2022-11-02 23:34:46,129:INFO: Batch:  6/31	Total Loss 0.0667 (0.0665)
2022-11-02 23:34:46,178:INFO: Batch:  7/31	Total Loss 0.0630 (0.0661)
2022-11-02 23:34:46,225:INFO: Batch:  8/31	Total Loss 0.0641 (0.0658)
2022-11-02 23:34:46,274:INFO: Batch:  9/31	Total Loss 0.0683 (0.0661)
2022-11-02 23:34:46,322:INFO: Batch: 10/31	Total Loss 0.0631 (0.0658)
2022-11-02 23:34:46,370:INFO: Batch: 11/31	Total Loss 0.0760 (0.0666)
2022-11-02 23:34:46,418:INFO: Batch: 12/31	Total Loss 0.0650 (0.0665)
2022-11-02 23:34:46,468:INFO: Batch: 13/31	Total Loss 0.0639 (0.0663)
2022-11-02 23:34:46,520:INFO: Batch: 14/31	Total Loss 0.0750 (0.0669)
2022-11-02 23:34:46,571:INFO: Batch: 15/31	Total Loss 0.0612 (0.0665)
2022-11-02 23:34:46,620:INFO: Batch: 16/31	Total Loss 0.0639 (0.0664)
2022-11-02 23:34:46,671:INFO: Batch: 17/31	Total Loss 0.0638 (0.0662)
2022-11-02 23:34:46,719:INFO: Batch: 18/31	Total Loss 0.0615 (0.0660)
2022-11-02 23:34:46,772:INFO: Batch: 19/31	Total Loss 0.0667 (0.0660)
2022-11-02 23:34:46,825:INFO: Batch: 20/31	Total Loss 0.0681 (0.0661)
2022-11-02 23:34:46,874:INFO: Batch: 21/31	Total Loss 0.0596 (0.0658)
2022-11-02 23:34:46,922:INFO: Batch: 22/31	Total Loss 0.0848 (0.0666)
2022-11-02 23:34:46,971:INFO: Batch: 23/31	Total Loss 0.0645 (0.0665)
2022-11-02 23:34:47,023:INFO: Batch: 24/31	Total Loss 0.0623 (0.0664)
2022-11-02 23:34:47,073:INFO: Batch: 25/31	Total Loss 0.0623 (0.0662)
2022-11-02 23:34:47,123:INFO: Batch: 26/31	Total Loss 0.0639 (0.0661)
2022-11-02 23:34:47,172:INFO: Batch: 27/31	Total Loss 0.0610 (0.0659)
2022-11-02 23:34:47,222:INFO: Batch: 28/31	Total Loss 0.0629 (0.0658)
2022-11-02 23:34:47,274:INFO: Batch: 29/31	Total Loss 0.0672 (0.0659)
2022-11-02 23:34:47,305:INFO: Batch: 30/31	Total Loss 0.0252 (0.0655)
2022-11-02 23:34:47,459:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_97.pth.tar
2022-11-02 23:34:47,459:INFO: 
===> EPOCH: 98 (P1)
2022-11-02 23:34:47,459:INFO: - Computing loss (training)
2022-11-02 23:34:48,157:INFO: Batch:  0/31	Total Loss 0.0603 (0.0603)
2022-11-02 23:34:48,204:INFO: Batch:  1/31	Total Loss 0.0597 (0.0600)
2022-11-02 23:34:48,257:INFO: Batch:  2/31	Total Loss 0.0621 (0.0608)
2022-11-02 23:34:48,310:INFO: Batch:  3/31	Total Loss 0.0578 (0.0601)
2022-11-02 23:34:48,358:INFO: Batch:  4/31	Total Loss 0.0599 (0.0600)
2022-11-02 23:34:48,409:INFO: Batch:  5/31	Total Loss 0.0667 (0.0611)
2022-11-02 23:34:48,461:INFO: Batch:  6/31	Total Loss 0.0639 (0.0615)
2022-11-02 23:34:48,508:INFO: Batch:  7/31	Total Loss 0.0616 (0.0615)
2022-11-02 23:34:48,557:INFO: Batch:  8/31	Total Loss 0.0637 (0.0618)
2022-11-02 23:34:48,608:INFO: Batch:  9/31	Total Loss 0.0672 (0.0624)
2022-11-02 23:34:48,657:INFO: Batch: 10/31	Total Loss 0.0651 (0.0627)
2022-11-02 23:34:48,705:INFO: Batch: 11/31	Total Loss 0.0721 (0.0635)
2022-11-02 23:34:48,753:INFO: Batch: 12/31	Total Loss 0.0707 (0.0639)
2022-11-02 23:34:48,803:INFO: Batch: 13/31	Total Loss 0.0598 (0.0637)
2022-11-02 23:34:48,856:INFO: Batch: 14/31	Total Loss 0.0626 (0.0636)
2022-11-02 23:34:48,908:INFO: Batch: 15/31	Total Loss 0.0643 (0.0636)
2022-11-02 23:34:48,958:INFO: Batch: 16/31	Total Loss 0.0586 (0.0633)
2022-11-02 23:34:49,008:INFO: Batch: 17/31	Total Loss 0.0716 (0.0637)
2022-11-02 23:34:49,058:INFO: Batch: 18/31	Total Loss 0.0615 (0.0636)
2022-11-02 23:34:49,110:INFO: Batch: 19/31	Total Loss 0.0529 (0.0631)
2022-11-02 23:34:49,160:INFO: Batch: 20/31	Total Loss 0.0677 (0.0633)
2022-11-02 23:34:49,209:INFO: Batch: 21/31	Total Loss 0.0637 (0.0634)
2022-11-02 23:34:49,258:INFO: Batch: 22/31	Total Loss 0.0635 (0.0634)
2022-11-02 23:34:49,311:INFO: Batch: 23/31	Total Loss 0.0548 (0.0630)
2022-11-02 23:34:49,362:INFO: Batch: 24/31	Total Loss 0.0659 (0.0631)
2022-11-02 23:34:49,412:INFO: Batch: 25/31	Total Loss 0.0676 (0.0633)
2022-11-02 23:34:49,462:INFO: Batch: 26/31	Total Loss 0.0594 (0.0632)
2022-11-02 23:34:49,512:INFO: Batch: 27/31	Total Loss 0.0610 (0.0631)
2022-11-02 23:34:49,562:INFO: Batch: 28/31	Total Loss 0.0599 (0.0630)
2022-11-02 23:34:49,612:INFO: Batch: 29/31	Total Loss 0.0696 (0.0632)
2022-11-02 23:34:49,644:INFO: Batch: 30/31	Total Loss 0.0261 (0.0628)
2022-11-02 23:34:49,805:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_98.pth.tar
2022-11-02 23:34:49,805:INFO: 
===> EPOCH: 99 (P1)
2022-11-02 23:34:49,805:INFO: - Computing loss (training)
2022-11-02 23:34:50,475:INFO: Batch:  0/31	Total Loss 0.0603 (0.0603)
2022-11-02 23:34:50,527:INFO: Batch:  1/31	Total Loss 0.0595 (0.0599)
2022-11-02 23:34:50,581:INFO: Batch:  2/31	Total Loss 0.0671 (0.0622)
2022-11-02 23:34:50,631:INFO: Batch:  3/31	Total Loss 0.0657 (0.0631)
2022-11-02 23:34:50,681:INFO: Batch:  4/31	Total Loss 0.0688 (0.0643)
2022-11-02 23:34:50,732:INFO: Batch:  5/31	Total Loss 0.0560 (0.0628)
2022-11-02 23:34:50,781:INFO: Batch:  6/31	Total Loss 0.0592 (0.0623)
2022-11-02 23:34:50,828:INFO: Batch:  7/31	Total Loss 0.0626 (0.0623)
2022-11-02 23:34:50,876:INFO: Batch:  8/31	Total Loss 0.0657 (0.0627)
2022-11-02 23:34:50,924:INFO: Batch:  9/31	Total Loss 0.0646 (0.0629)
2022-11-02 23:34:50,975:INFO: Batch: 10/31	Total Loss 0.0627 (0.0629)
2022-11-02 23:34:51,021:INFO: Batch: 11/31	Total Loss 0.0643 (0.0630)
2022-11-02 23:34:51,070:INFO: Batch: 12/31	Total Loss 0.0600 (0.0627)
2022-11-02 23:34:51,120:INFO: Batch: 13/31	Total Loss 0.0629 (0.0627)
2022-11-02 23:34:51,172:INFO: Batch: 14/31	Total Loss 0.0549 (0.0623)
2022-11-02 23:34:51,224:INFO: Batch: 15/31	Total Loss 0.0583 (0.0620)
2022-11-02 23:34:51,273:INFO: Batch: 16/31	Total Loss 0.0544 (0.0615)
2022-11-02 23:34:51,323:INFO: Batch: 17/31	Total Loss 0.0687 (0.0619)
2022-11-02 23:34:51,373:INFO: Batch: 18/31	Total Loss 0.0644 (0.0621)
2022-11-02 23:34:51,424:INFO: Batch: 19/31	Total Loss 0.0629 (0.0621)
2022-11-02 23:34:51,475:INFO: Batch: 20/31	Total Loss 0.0708 (0.0625)
2022-11-02 23:34:51,525:INFO: Batch: 21/31	Total Loss 0.0626 (0.0625)
2022-11-02 23:34:51,574:INFO: Batch: 22/31	Total Loss 0.0710 (0.0629)
2022-11-02 23:34:51,623:INFO: Batch: 23/31	Total Loss 0.0713 (0.0632)
2022-11-02 23:34:51,675:INFO: Batch: 24/31	Total Loss 0.0702 (0.0635)
2022-11-02 23:34:51,724:INFO: Batch: 25/31	Total Loss 0.0633 (0.0635)
2022-11-02 23:34:51,773:INFO: Batch: 26/31	Total Loss 0.0663 (0.0636)
2022-11-02 23:34:51,822:INFO: Batch: 27/31	Total Loss 0.0683 (0.0637)
2022-11-02 23:34:51,871:INFO: Batch: 28/31	Total Loss 0.0651 (0.0638)
2022-11-02 23:34:51,922:INFO: Batch: 29/31	Total Loss 0.0600 (0.0637)
2022-11-02 23:34:51,953:INFO: Batch: 30/31	Total Loss 0.0228 (0.0633)
2022-11-02 23:34:52,110:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_99.pth.tar
2022-11-02 23:34:52,110:INFO: 
===> EPOCH: 100 (P1)
2022-11-02 23:34:52,110:INFO: - Computing loss (training)
2022-11-02 23:34:52,800:INFO: Batch:  0/31	Total Loss 0.0640 (0.0640)
2022-11-02 23:34:52,852:INFO: Batch:  1/31	Total Loss 0.0618 (0.0629)
2022-11-02 23:34:52,906:INFO: Batch:  2/31	Total Loss 0.0605 (0.0621)
2022-11-02 23:34:52,952:INFO: Batch:  3/31	Total Loss 0.0665 (0.0630)
2022-11-02 23:34:52,999:INFO: Batch:  4/31	Total Loss 0.0667 (0.0638)
2022-11-02 23:34:53,052:INFO: Batch:  5/31	Total Loss 0.0650 (0.0640)
2022-11-02 23:34:53,102:INFO: Batch:  6/31	Total Loss 0.0626 (0.0638)
2022-11-02 23:34:53,149:INFO: Batch:  7/31	Total Loss 0.0646 (0.0639)
2022-11-02 23:34:53,196:INFO: Batch:  8/31	Total Loss 0.0573 (0.0632)
2022-11-02 23:34:53,246:INFO: Batch:  9/31	Total Loss 0.0610 (0.0630)
2022-11-02 23:34:53,295:INFO: Batch: 10/31	Total Loss 0.0643 (0.0631)
2022-11-02 23:34:53,345:INFO: Batch: 11/31	Total Loss 0.0761 (0.0642)
2022-11-02 23:34:53,395:INFO: Batch: 12/31	Total Loss 0.0643 (0.0642)
2022-11-02 23:34:53,445:INFO: Batch: 13/31	Total Loss 0.0559 (0.0637)
2022-11-02 23:34:53,498:INFO: Batch: 14/31	Total Loss 0.0684 (0.0640)
2022-11-02 23:34:53,548:INFO: Batch: 15/31	Total Loss 0.0671 (0.0642)
2022-11-02 23:34:53,596:INFO: Batch: 16/31	Total Loss 0.0583 (0.0638)
2022-11-02 23:34:53,646:INFO: Batch: 17/31	Total Loss 0.0623 (0.0637)
2022-11-02 23:34:53,696:INFO: Batch: 18/31	Total Loss 0.0568 (0.0633)
2022-11-02 23:34:53,747:INFO: Batch: 19/31	Total Loss 0.0699 (0.0636)
2022-11-02 23:34:53,796:INFO: Batch: 20/31	Total Loss 0.0661 (0.0638)
2022-11-02 23:34:53,845:INFO: Batch: 21/31	Total Loss 0.0644 (0.0638)
2022-11-02 23:34:53,894:INFO: Batch: 22/31	Total Loss 0.0567 (0.0635)
2022-11-02 23:34:53,942:INFO: Batch: 23/31	Total Loss 0.0676 (0.0636)
2022-11-02 23:34:53,994:INFO: Batch: 24/31	Total Loss 0.0625 (0.0636)
2022-11-02 23:34:54,044:INFO: Batch: 25/31	Total Loss 0.0565 (0.0633)
2022-11-02 23:34:54,092:INFO: Batch: 26/31	Total Loss 0.0526 (0.0630)
2022-11-02 23:34:54,142:INFO: Batch: 27/31	Total Loss 0.0709 (0.0632)
2022-11-02 23:34:54,191:INFO: Batch: 28/31	Total Loss 0.0640 (0.0632)
2022-11-02 23:34:54,241:INFO: Batch: 29/31	Total Loss 0.0568 (0.0630)
2022-11-02 23:34:54,273:INFO: Batch: 30/31	Total Loss 0.0264 (0.0627)
2022-11-02 23:34:54,427:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_100.pth.tar
2022-11-02 23:34:54,427:INFO: 
===> EPOCH: 101 (P1)
2022-11-02 23:34:54,427:INFO: - Computing loss (training)
2022-11-02 23:34:55,127:INFO: Batch:  0/31	Total Loss 0.0714 (0.0714)
2022-11-02 23:34:55,179:INFO: Batch:  1/31	Total Loss 0.0657 (0.0689)
2022-11-02 23:34:55,238:INFO: Batch:  2/31	Total Loss 0.0612 (0.0661)
2022-11-02 23:34:55,293:INFO: Batch:  3/31	Total Loss 0.0561 (0.0635)
2022-11-02 23:34:55,344:INFO: Batch:  4/31	Total Loss 0.0534 (0.0614)
2022-11-02 23:34:55,399:INFO: Batch:  5/31	Total Loss 0.0773 (0.0640)
2022-11-02 23:34:55,447:INFO: Batch:  6/31	Total Loss 0.0559 (0.0630)
2022-11-02 23:34:55,495:INFO: Batch:  7/31	Total Loss 0.0620 (0.0628)
2022-11-02 23:34:55,545:INFO: Batch:  8/31	Total Loss 0.0672 (0.0633)
2022-11-02 23:34:55,594:INFO: Batch:  9/31	Total Loss 0.0562 (0.0627)
2022-11-02 23:34:55,642:INFO: Batch: 10/31	Total Loss 0.0568 (0.0621)
2022-11-02 23:34:55,692:INFO: Batch: 11/31	Total Loss 0.0644 (0.0622)
2022-11-02 23:34:55,741:INFO: Batch: 12/31	Total Loss 0.0603 (0.0621)
2022-11-02 23:34:55,792:INFO: Batch: 13/31	Total Loss 0.0593 (0.0619)
2022-11-02 23:34:55,848:INFO: Batch: 14/31	Total Loss 0.0549 (0.0614)
2022-11-02 23:34:55,901:INFO: Batch: 15/31	Total Loss 0.0562 (0.0611)
2022-11-02 23:34:55,953:INFO: Batch: 16/31	Total Loss 0.0560 (0.0608)
2022-11-02 23:34:56,007:INFO: Batch: 17/31	Total Loss 0.0577 (0.0606)
2022-11-02 23:34:56,058:INFO: Batch: 18/31	Total Loss 0.0582 (0.0605)
2022-11-02 23:34:56,112:INFO: Batch: 19/31	Total Loss 0.0563 (0.0603)
2022-11-02 23:34:56,162:INFO: Batch: 20/31	Total Loss 0.0562 (0.0601)
2022-11-02 23:34:56,212:INFO: Batch: 21/31	Total Loss 0.0695 (0.0605)
2022-11-02 23:34:56,262:INFO: Batch: 22/31	Total Loss 0.0553 (0.0603)
2022-11-02 23:34:56,314:INFO: Batch: 23/31	Total Loss 0.0582 (0.0602)
2022-11-02 23:34:56,365:INFO: Batch: 24/31	Total Loss 0.0640 (0.0604)
2022-11-02 23:34:56,415:INFO: Batch: 25/31	Total Loss 0.0575 (0.0603)
2022-11-02 23:34:56,464:INFO: Batch: 26/31	Total Loss 0.0598 (0.0602)
2022-11-02 23:34:56,518:INFO: Batch: 27/31	Total Loss 0.0561 (0.0601)
2022-11-02 23:34:56,570:INFO: Batch: 28/31	Total Loss 0.0633 (0.0602)
2022-11-02 23:34:56,620:INFO: Batch: 29/31	Total Loss 0.0560 (0.0600)
2022-11-02 23:34:56,652:INFO: Batch: 30/31	Total Loss 0.0216 (0.0597)
2022-11-02 23:34:56,804:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_101.pth.tar
2022-11-02 23:34:56,805:INFO: 
===> EPOCH: 102 (P1)
2022-11-02 23:34:56,805:INFO: - Computing loss (training)
2022-11-02 23:34:57,491:INFO: Batch:  0/31	Total Loss 0.0548 (0.0548)
2022-11-02 23:34:57,545:INFO: Batch:  1/31	Total Loss 0.0565 (0.0557)
2022-11-02 23:34:57,611:INFO: Batch:  2/31	Total Loss 0.0588 (0.0567)
2022-11-02 23:34:57,669:INFO: Batch:  3/31	Total Loss 0.0538 (0.0560)
2022-11-02 23:34:57,725:INFO: Batch:  4/31	Total Loss 0.0549 (0.0558)
2022-11-02 23:34:57,777:INFO: Batch:  5/31	Total Loss 0.0615 (0.0568)
2022-11-02 23:34:57,827:INFO: Batch:  6/31	Total Loss 0.0561 (0.0567)
2022-11-02 23:34:57,875:INFO: Batch:  7/31	Total Loss 0.0567 (0.0567)
2022-11-02 23:34:57,943:INFO: Batch:  8/31	Total Loss 0.0638 (0.0575)
2022-11-02 23:34:58,039:INFO: Batch:  9/31	Total Loss 0.0560 (0.0574)
2022-11-02 23:34:58,156:INFO: Batch: 10/31	Total Loss 0.0691 (0.0585)
2022-11-02 23:34:58,267:INFO: Batch: 11/31	Total Loss 0.0640 (0.0589)
2022-11-02 23:34:58,367:INFO: Batch: 12/31	Total Loss 0.0594 (0.0590)
2022-11-02 23:34:58,427:INFO: Batch: 13/31	Total Loss 0.0539 (0.0586)
2022-11-02 23:34:58,483:INFO: Batch: 14/31	Total Loss 0.0700 (0.0593)
2022-11-02 23:34:58,544:INFO: Batch: 15/31	Total Loss 0.0636 (0.0596)
2022-11-02 23:34:58,597:INFO: Batch: 16/31	Total Loss 0.0622 (0.0597)
2022-11-02 23:34:58,649:INFO: Batch: 17/31	Total Loss 0.0505 (0.0592)
2022-11-02 23:34:58,700:INFO: Batch: 18/31	Total Loss 0.0706 (0.0598)
2022-11-02 23:34:58,750:INFO: Batch: 19/31	Total Loss 0.0652 (0.0601)
2022-11-02 23:34:58,800:INFO: Batch: 20/31	Total Loss 0.0599 (0.0601)
2022-11-02 23:34:58,851:INFO: Batch: 21/31	Total Loss 0.0594 (0.0601)
2022-11-02 23:34:58,901:INFO: Batch: 22/31	Total Loss 0.0610 (0.0601)
2022-11-02 23:34:58,952:INFO: Batch: 23/31	Total Loss 0.0566 (0.0600)
2022-11-02 23:34:59,003:INFO: Batch: 24/31	Total Loss 0.0654 (0.0601)
2022-11-02 23:34:59,055:INFO: Batch: 25/31	Total Loss 0.0564 (0.0600)
2022-11-02 23:34:59,115:INFO: Batch: 26/31	Total Loss 0.0579 (0.0599)
2022-11-02 23:34:59,174:INFO: Batch: 27/31	Total Loss 0.0665 (0.0602)
2022-11-02 23:34:59,228:INFO: Batch: 28/31	Total Loss 0.0571 (0.0601)
2022-11-02 23:34:59,282:INFO: Batch: 29/31	Total Loss 0.0596 (0.0600)
2022-11-02 23:34:59,315:INFO: Batch: 30/31	Total Loss 0.0194 (0.0596)
2022-11-02 23:34:59,492:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_102.pth.tar
2022-11-02 23:34:59,492:INFO: 
===> EPOCH: 103 (P1)
2022-11-02 23:34:59,492:INFO: - Computing loss (training)
2022-11-02 23:35:00,403:INFO: Batch:  0/31	Total Loss 0.0565 (0.0565)
2022-11-02 23:35:00,478:INFO: Batch:  1/31	Total Loss 0.0718 (0.0640)
2022-11-02 23:35:00,562:INFO: Batch:  2/31	Total Loss 0.0609 (0.0629)
2022-11-02 23:35:00,636:INFO: Batch:  3/31	Total Loss 0.0526 (0.0606)
2022-11-02 23:35:00,691:INFO: Batch:  4/31	Total Loss 0.0613 (0.0608)
2022-11-02 23:35:00,746:INFO: Batch:  5/31	Total Loss 0.0688 (0.0621)
2022-11-02 23:35:00,801:INFO: Batch:  6/31	Total Loss 0.0560 (0.0613)
2022-11-02 23:35:00,848:INFO: Batch:  7/31	Total Loss 0.0573 (0.0607)
2022-11-02 23:35:00,897:INFO: Batch:  8/31	Total Loss 0.0540 (0.0600)
2022-11-02 23:35:00,945:INFO: Batch:  9/31	Total Loss 0.0524 (0.0592)
2022-11-02 23:35:00,992:INFO: Batch: 10/31	Total Loss 0.0611 (0.0594)
2022-11-02 23:35:01,040:INFO: Batch: 11/31	Total Loss 0.0511 (0.0587)
2022-11-02 23:35:01,093:INFO: Batch: 12/31	Total Loss 0.0494 (0.0581)
2022-11-02 23:35:01,159:INFO: Batch: 13/31	Total Loss 0.0585 (0.0581)
2022-11-02 23:35:01,210:INFO: Batch: 14/31	Total Loss 0.0575 (0.0581)
2022-11-02 23:35:01,259:INFO: Batch: 15/31	Total Loss 0.0559 (0.0580)
2022-11-02 23:35:01,311:INFO: Batch: 16/31	Total Loss 0.0690 (0.0585)
2022-11-02 23:35:01,365:INFO: Batch: 17/31	Total Loss 0.0539 (0.0583)
2022-11-02 23:35:01,417:INFO: Batch: 18/31	Total Loss 0.0593 (0.0583)
2022-11-02 23:35:01,467:INFO: Batch: 19/31	Total Loss 0.0580 (0.0583)
2022-11-02 23:35:01,518:INFO: Batch: 20/31	Total Loss 0.0542 (0.0581)
2022-11-02 23:35:01,569:INFO: Batch: 21/31	Total Loss 0.0600 (0.0582)
2022-11-02 23:35:01,621:INFO: Batch: 22/31	Total Loss 0.0516 (0.0579)
2022-11-02 23:35:01,671:INFO: Batch: 23/31	Total Loss 0.0567 (0.0579)
2022-11-02 23:35:01,722:INFO: Batch: 24/31	Total Loss 0.0534 (0.0577)
2022-11-02 23:35:01,774:INFO: Batch: 25/31	Total Loss 0.0594 (0.0577)
2022-11-02 23:35:01,824:INFO: Batch: 26/31	Total Loss 0.0523 (0.0575)
2022-11-02 23:35:01,874:INFO: Batch: 27/31	Total Loss 0.0568 (0.0575)
2022-11-02 23:35:01,925:INFO: Batch: 28/31	Total Loss 0.0526 (0.0573)
2022-11-02 23:35:01,979:INFO: Batch: 29/31	Total Loss 0.0545 (0.0572)
2022-11-02 23:35:02,010:INFO: Batch: 30/31	Total Loss 0.0198 (0.0569)
2022-11-02 23:35:02,173:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_103.pth.tar
2022-11-02 23:35:02,173:INFO: 
===> EPOCH: 104 (P1)
2022-11-02 23:35:02,173:INFO: - Computing loss (training)
2022-11-02 23:35:02,901:INFO: Batch:  0/31	Total Loss 0.0563 (0.0563)
2022-11-02 23:35:02,957:INFO: Batch:  1/31	Total Loss 0.0557 (0.0560)
2022-11-02 23:35:03,013:INFO: Batch:  2/31	Total Loss 0.0544 (0.0554)
2022-11-02 23:35:03,065:INFO: Batch:  3/31	Total Loss 0.0585 (0.0562)
2022-11-02 23:35:03,169:INFO: Batch:  4/31	Total Loss 0.0566 (0.0562)
2022-11-02 23:35:03,228:INFO: Batch:  5/31	Total Loss 0.0634 (0.0573)
2022-11-02 23:35:03,278:INFO: Batch:  6/31	Total Loss 0.0594 (0.0576)
2022-11-02 23:35:03,329:INFO: Batch:  7/31	Total Loss 0.0539 (0.0571)
2022-11-02 23:35:03,380:INFO: Batch:  8/31	Total Loss 0.0533 (0.0567)
2022-11-02 23:35:03,438:INFO: Batch:  9/31	Total Loss 0.0546 (0.0564)
2022-11-02 23:35:03,505:INFO: Batch: 10/31	Total Loss 0.0580 (0.0566)
2022-11-02 23:35:03,577:INFO: Batch: 11/31	Total Loss 0.0628 (0.0571)
2022-11-02 23:35:03,633:INFO: Batch: 12/31	Total Loss 0.0489 (0.0564)
2022-11-02 23:35:03,686:INFO: Batch: 13/31	Total Loss 0.0499 (0.0560)
2022-11-02 23:35:03,737:INFO: Batch: 14/31	Total Loss 0.0557 (0.0560)
2022-11-02 23:35:03,788:INFO: Batch: 15/31	Total Loss 0.0492 (0.0556)
2022-11-02 23:35:03,839:INFO: Batch: 16/31	Total Loss 0.0553 (0.0556)
2022-11-02 23:35:03,890:INFO: Batch: 17/31	Total Loss 0.0656 (0.0561)
2022-11-02 23:35:03,939:INFO: Batch: 18/31	Total Loss 0.0597 (0.0563)
2022-11-02 23:35:03,989:INFO: Batch: 19/31	Total Loss 0.0536 (0.0562)
2022-11-02 23:35:04,038:INFO: Batch: 20/31	Total Loss 0.0541 (0.0561)
2022-11-02 23:35:04,087:INFO: Batch: 21/31	Total Loss 0.0560 (0.0561)
2022-11-02 23:35:04,136:INFO: Batch: 22/31	Total Loss 0.0538 (0.0560)
2022-11-02 23:35:04,185:INFO: Batch: 23/31	Total Loss 0.0527 (0.0558)
2022-11-02 23:35:04,234:INFO: Batch: 24/31	Total Loss 0.0549 (0.0558)
2022-11-02 23:35:04,284:INFO: Batch: 25/31	Total Loss 0.0592 (0.0560)
2022-11-02 23:35:04,334:INFO: Batch: 26/31	Total Loss 0.0604 (0.0561)
2022-11-02 23:35:04,383:INFO: Batch: 27/31	Total Loss 0.0578 (0.0562)
2022-11-02 23:35:04,433:INFO: Batch: 28/31	Total Loss 0.0520 (0.0560)
2022-11-02 23:35:04,482:INFO: Batch: 29/31	Total Loss 0.0546 (0.0560)
2022-11-02 23:35:04,512:INFO: Batch: 30/31	Total Loss 0.0220 (0.0557)
2022-11-02 23:35:04,662:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_104.pth.tar
2022-11-02 23:35:04,663:INFO: 
===> EPOCH: 105 (P1)
2022-11-02 23:35:04,663:INFO: - Computing loss (training)
2022-11-02 23:35:05,388:INFO: Batch:  0/31	Total Loss 0.0545 (0.0545)
2022-11-02 23:35:05,446:INFO: Batch:  1/31	Total Loss 0.0591 (0.0569)
2022-11-02 23:35:05,501:INFO: Batch:  2/31	Total Loss 0.0519 (0.0551)
2022-11-02 23:35:05,552:INFO: Batch:  3/31	Total Loss 0.0583 (0.0559)
2022-11-02 23:35:05,658:INFO: Batch:  4/31	Total Loss 0.0510 (0.0549)
2022-11-02 23:35:05,784:INFO: Batch:  5/31	Total Loss 0.0550 (0.0550)
2022-11-02 23:35:05,889:INFO: Batch:  6/31	Total Loss 0.0514 (0.0544)
2022-11-02 23:35:05,953:INFO: Batch:  7/31	Total Loss 0.0528 (0.0542)
2022-11-02 23:35:06,036:INFO: Batch:  8/31	Total Loss 0.0562 (0.0545)
2022-11-02 23:35:06,090:INFO: Batch:  9/31	Total Loss 0.0521 (0.0542)
2022-11-02 23:35:06,150:INFO: Batch: 10/31	Total Loss 0.0507 (0.0539)
2022-11-02 23:35:06,208:INFO: Batch: 11/31	Total Loss 0.0503 (0.0536)
2022-11-02 23:35:06,263:INFO: Batch: 12/31	Total Loss 0.0543 (0.0537)
2022-11-02 23:35:06,333:INFO: Batch: 13/31	Total Loss 0.0531 (0.0536)
2022-11-02 23:35:06,386:INFO: Batch: 14/31	Total Loss 0.0525 (0.0535)
2022-11-02 23:35:06,439:INFO: Batch: 15/31	Total Loss 0.0533 (0.0535)
2022-11-02 23:35:06,491:INFO: Batch: 16/31	Total Loss 0.0523 (0.0535)
2022-11-02 23:35:06,541:INFO: Batch: 17/31	Total Loss 0.0516 (0.0533)
2022-11-02 23:35:06,591:INFO: Batch: 18/31	Total Loss 0.0512 (0.0532)
2022-11-02 23:35:06,644:INFO: Batch: 19/31	Total Loss 0.0537 (0.0533)
2022-11-02 23:35:06,695:INFO: Batch: 20/31	Total Loss 0.0513 (0.0532)
2022-11-02 23:35:06,746:INFO: Batch: 21/31	Total Loss 0.0534 (0.0532)
2022-11-02 23:35:06,795:INFO: Batch: 22/31	Total Loss 0.0535 (0.0532)
2022-11-02 23:35:06,848:INFO: Batch: 23/31	Total Loss 0.0582 (0.0535)
2022-11-02 23:35:06,898:INFO: Batch: 24/31	Total Loss 0.0502 (0.0533)
2022-11-02 23:35:07,005:INFO: Batch: 25/31	Total Loss 0.0530 (0.0533)
2022-11-02 23:35:07,066:INFO: Batch: 26/31	Total Loss 0.0504 (0.0532)
2022-11-02 23:35:07,116:INFO: Batch: 27/31	Total Loss 0.0530 (0.0532)
2022-11-02 23:35:07,166:INFO: Batch: 28/31	Total Loss 0.0526 (0.0532)
2022-11-02 23:35:07,216:INFO: Batch: 29/31	Total Loss 0.0530 (0.0532)
2022-11-02 23:35:07,248:INFO: Batch: 30/31	Total Loss 0.0207 (0.0528)
2022-11-02 23:35:07,422:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_105.pth.tar
2022-11-02 23:35:07,422:INFO: 
===> EPOCH: 106 (P1)
2022-11-02 23:35:07,422:INFO: - Computing loss (training)
2022-11-02 23:35:08,096:INFO: Batch:  0/31	Total Loss 0.0498 (0.0498)
2022-11-02 23:35:08,147:INFO: Batch:  1/31	Total Loss 0.0533 (0.0515)
2022-11-02 23:35:08,200:INFO: Batch:  2/31	Total Loss 0.0509 (0.0512)
2022-11-02 23:35:08,249:INFO: Batch:  3/31	Total Loss 0.0555 (0.0523)
2022-11-02 23:35:08,300:INFO: Batch:  4/31	Total Loss 0.0576 (0.0533)
2022-11-02 23:35:08,349:INFO: Batch:  5/31	Total Loss 0.0482 (0.0523)
2022-11-02 23:35:08,398:INFO: Batch:  6/31	Total Loss 0.0517 (0.0523)
2022-11-02 23:35:08,449:INFO: Batch:  7/31	Total Loss 0.0611 (0.0534)
2022-11-02 23:35:08,497:INFO: Batch:  8/31	Total Loss 0.0616 (0.0544)
2022-11-02 23:35:08,543:INFO: Batch:  9/31	Total Loss 0.0517 (0.0541)
2022-11-02 23:35:08,591:INFO: Batch: 10/31	Total Loss 0.0546 (0.0541)
2022-11-02 23:35:08,638:INFO: Batch: 11/31	Total Loss 0.0540 (0.0541)
2022-11-02 23:35:08,687:INFO: Batch: 12/31	Total Loss 0.0516 (0.0539)
2022-11-02 23:35:08,737:INFO: Batch: 13/31	Total Loss 0.0498 (0.0536)
2022-11-02 23:35:08,787:INFO: Batch: 14/31	Total Loss 0.0508 (0.0534)
2022-11-02 23:35:08,836:INFO: Batch: 15/31	Total Loss 0.0535 (0.0534)
2022-11-02 23:35:08,885:INFO: Batch: 16/31	Total Loss 0.0498 (0.0532)
2022-11-02 23:35:08,934:INFO: Batch: 17/31	Total Loss 0.0528 (0.0532)
2022-11-02 23:35:08,984:INFO: Batch: 18/31	Total Loss 0.0528 (0.0532)
2022-11-02 23:35:09,033:INFO: Batch: 19/31	Total Loss 0.0489 (0.0530)
2022-11-02 23:35:09,082:INFO: Batch: 20/31	Total Loss 0.0498 (0.0528)
2022-11-02 23:35:09,131:INFO: Batch: 21/31	Total Loss 0.0541 (0.0529)
2022-11-02 23:35:09,180:INFO: Batch: 22/31	Total Loss 0.0577 (0.0531)
2022-11-02 23:35:09,228:INFO: Batch: 23/31	Total Loss 0.0588 (0.0533)
2022-11-02 23:35:09,276:INFO: Batch: 24/31	Total Loss 0.0534 (0.0533)
2022-11-02 23:35:09,325:INFO: Batch: 25/31	Total Loss 0.0607 (0.0536)
2022-11-02 23:35:09,375:INFO: Batch: 26/31	Total Loss 0.0534 (0.0536)
2022-11-02 23:35:09,425:INFO: Batch: 27/31	Total Loss 0.0534 (0.0536)
2022-11-02 23:35:09,475:INFO: Batch: 28/31	Total Loss 0.0594 (0.0538)
2022-11-02 23:35:09,525:INFO: Batch: 29/31	Total Loss 0.0516 (0.0537)
2022-11-02 23:35:09,555:INFO: Batch: 30/31	Total Loss 0.0193 (0.0534)
2022-11-02 23:35:09,700:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_106.pth.tar
2022-11-02 23:35:09,700:INFO: 
===> EPOCH: 107 (P1)
2022-11-02 23:35:09,701:INFO: - Computing loss (training)
2022-11-02 23:35:10,353:INFO: Batch:  0/31	Total Loss 0.0486 (0.0486)
2022-11-02 23:35:10,404:INFO: Batch:  1/31	Total Loss 0.0530 (0.0506)
2022-11-02 23:35:10,460:INFO: Batch:  2/31	Total Loss 0.0534 (0.0515)
2022-11-02 23:35:10,509:INFO: Batch:  3/31	Total Loss 0.0503 (0.0512)
2022-11-02 23:35:10,557:INFO: Batch:  4/31	Total Loss 0.0537 (0.0517)
2022-11-02 23:35:10,611:INFO: Batch:  5/31	Total Loss 0.0522 (0.0518)
2022-11-02 23:35:10,658:INFO: Batch:  6/31	Total Loss 0.0537 (0.0521)
2022-11-02 23:35:10,705:INFO: Batch:  7/31	Total Loss 0.0499 (0.0518)
2022-11-02 23:35:10,753:INFO: Batch:  8/31	Total Loss 0.0575 (0.0525)
2022-11-02 23:35:10,800:INFO: Batch:  9/31	Total Loss 0.0487 (0.0522)
2022-11-02 23:35:10,847:INFO: Batch: 10/31	Total Loss 0.0512 (0.0521)
2022-11-02 23:35:10,895:INFO: Batch: 11/31	Total Loss 0.0481 (0.0518)
2022-11-02 23:35:10,944:INFO: Batch: 12/31	Total Loss 0.0592 (0.0523)
2022-11-02 23:35:10,994:INFO: Batch: 13/31	Total Loss 0.0485 (0.0521)
2022-11-02 23:35:11,045:INFO: Batch: 14/31	Total Loss 0.0519 (0.0520)
2022-11-02 23:35:11,097:INFO: Batch: 15/31	Total Loss 0.0446 (0.0515)
2022-11-02 23:35:11,147:INFO: Batch: 16/31	Total Loss 0.0512 (0.0515)
2022-11-02 23:35:11,198:INFO: Batch: 17/31	Total Loss 0.0484 (0.0514)
2022-11-02 23:35:11,250:INFO: Batch: 18/31	Total Loss 0.0507 (0.0513)
2022-11-02 23:35:11,299:INFO: Batch: 19/31	Total Loss 0.0528 (0.0514)
2022-11-02 23:35:11,348:INFO: Batch: 20/31	Total Loss 0.0470 (0.0512)
2022-11-02 23:35:11,400:INFO: Batch: 21/31	Total Loss 0.0492 (0.0511)
2022-11-02 23:35:11,451:INFO: Batch: 22/31	Total Loss 0.0506 (0.0511)
2022-11-02 23:35:11,501:INFO: Batch: 23/31	Total Loss 0.0469 (0.0509)
2022-11-02 23:35:11,549:INFO: Batch: 24/31	Total Loss 0.0502 (0.0509)
2022-11-02 23:35:11,598:INFO: Batch: 25/31	Total Loss 0.0588 (0.0512)
2022-11-02 23:35:11,647:INFO: Batch: 26/31	Total Loss 0.0510 (0.0512)
2022-11-02 23:35:11,696:INFO: Batch: 27/31	Total Loss 0.0613 (0.0516)
2022-11-02 23:35:11,746:INFO: Batch: 28/31	Total Loss 0.0509 (0.0515)
2022-11-02 23:35:11,795:INFO: Batch: 29/31	Total Loss 0.0500 (0.0515)
2022-11-02 23:35:11,825:INFO: Batch: 30/31	Total Loss 0.0184 (0.0512)
2022-11-02 23:35:11,988:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_107.pth.tar
2022-11-02 23:35:11,988:INFO: 
===> EPOCH: 108 (P1)
2022-11-02 23:35:11,988:INFO: - Computing loss (training)
2022-11-02 23:35:12,719:INFO: Batch:  0/31	Total Loss 0.0555 (0.0555)
2022-11-02 23:35:12,770:INFO: Batch:  1/31	Total Loss 0.0569 (0.0563)
2022-11-02 23:35:12,824:INFO: Batch:  2/31	Total Loss 0.0481 (0.0533)
2022-11-02 23:35:12,871:INFO: Batch:  3/31	Total Loss 0.0557 (0.0540)
2022-11-02 23:35:12,921:INFO: Batch:  4/31	Total Loss 0.0516 (0.0535)
2022-11-02 23:35:12,970:INFO: Batch:  5/31	Total Loss 0.0477 (0.0523)
2022-11-02 23:35:13,020:INFO: Batch:  6/31	Total Loss 0.0569 (0.0530)
2022-11-02 23:35:13,068:INFO: Batch:  7/31	Total Loss 0.0537 (0.0531)
2022-11-02 23:35:13,115:INFO: Batch:  8/31	Total Loss 0.0522 (0.0530)
2022-11-02 23:35:13,163:INFO: Batch:  9/31	Total Loss 0.0530 (0.0530)
2022-11-02 23:35:13,211:INFO: Batch: 10/31	Total Loss 0.0535 (0.0530)
2022-11-02 23:35:13,259:INFO: Batch: 11/31	Total Loss 0.0524 (0.0530)
2022-11-02 23:35:13,311:INFO: Batch: 12/31	Total Loss 0.0522 (0.0529)
2022-11-02 23:35:13,367:INFO: Batch: 13/31	Total Loss 0.0546 (0.0531)
2022-11-02 23:35:13,421:INFO: Batch: 14/31	Total Loss 0.0505 (0.0529)
2022-11-02 23:35:13,472:INFO: Batch: 15/31	Total Loss 0.0482 (0.0526)
2022-11-02 23:35:13,523:INFO: Batch: 16/31	Total Loss 0.0507 (0.0525)
2022-11-02 23:35:13,574:INFO: Batch: 17/31	Total Loss 0.0513 (0.0524)
2022-11-02 23:35:13,625:INFO: Batch: 18/31	Total Loss 0.0470 (0.0521)
2022-11-02 23:35:13,674:INFO: Batch: 19/31	Total Loss 0.0460 (0.0519)
2022-11-02 23:35:13,724:INFO: Batch: 20/31	Total Loss 0.0507 (0.0518)
2022-11-02 23:35:13,775:INFO: Batch: 21/31	Total Loss 0.0517 (0.0518)
2022-11-02 23:35:13,829:INFO: Batch: 22/31	Total Loss 0.0570 (0.0520)
2022-11-02 23:35:13,880:INFO: Batch: 23/31	Total Loss 0.0545 (0.0521)
2022-11-02 23:35:13,932:INFO: Batch: 24/31	Total Loss 0.0542 (0.0522)
2022-11-02 23:35:13,983:INFO: Batch: 25/31	Total Loss 0.0519 (0.0522)
2022-11-02 23:35:14,036:INFO: Batch: 26/31	Total Loss 0.0481 (0.0521)
2022-11-02 23:35:14,088:INFO: Batch: 27/31	Total Loss 0.0601 (0.0524)
2022-11-02 23:35:14,141:INFO: Batch: 28/31	Total Loss 0.0510 (0.0523)
2022-11-02 23:35:14,192:INFO: Batch: 29/31	Total Loss 0.0583 (0.0525)
2022-11-02 23:35:14,224:INFO: Batch: 30/31	Total Loss 0.0179 (0.0522)
2022-11-02 23:35:14,388:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_108.pth.tar
2022-11-02 23:35:14,388:INFO: 
===> EPOCH: 109 (P1)
2022-11-02 23:35:14,389:INFO: - Computing loss (training)
2022-11-02 23:35:15,052:INFO: Batch:  0/31	Total Loss 0.0636 (0.0636)
2022-11-02 23:35:15,108:INFO: Batch:  1/31	Total Loss 0.0697 (0.0667)
2022-11-02 23:35:15,162:INFO: Batch:  2/31	Total Loss 0.0474 (0.0605)
2022-11-02 23:35:15,212:INFO: Batch:  3/31	Total Loss 0.0514 (0.0582)
2022-11-02 23:35:15,261:INFO: Batch:  4/31	Total Loss 0.0673 (0.0601)
2022-11-02 23:35:15,312:INFO: Batch:  5/31	Total Loss 0.0594 (0.0600)
2022-11-02 23:35:15,360:INFO: Batch:  6/31	Total Loss 0.0589 (0.0598)
2022-11-02 23:35:15,407:INFO: Batch:  7/31	Total Loss 0.0565 (0.0594)
2022-11-02 23:35:15,454:INFO: Batch:  8/31	Total Loss 0.0621 (0.0597)
2022-11-02 23:35:15,502:INFO: Batch:  9/31	Total Loss 0.0674 (0.0604)
2022-11-02 23:35:15,549:INFO: Batch: 10/31	Total Loss 0.0630 (0.0607)
2022-11-02 23:35:15,597:INFO: Batch: 11/31	Total Loss 0.0495 (0.0597)
2022-11-02 23:35:15,650:INFO: Batch: 12/31	Total Loss 0.0514 (0.0590)
2022-11-02 23:35:15,700:INFO: Batch: 13/31	Total Loss 0.0473 (0.0581)
2022-11-02 23:35:15,754:INFO: Batch: 14/31	Total Loss 0.0531 (0.0578)
2022-11-02 23:35:15,804:INFO: Batch: 15/31	Total Loss 0.0494 (0.0572)
2022-11-02 23:35:15,858:INFO: Batch: 16/31	Total Loss 0.0532 (0.0570)
2022-11-02 23:35:15,911:INFO: Batch: 17/31	Total Loss 0.0486 (0.0565)
2022-11-02 23:35:15,964:INFO: Batch: 18/31	Total Loss 0.0528 (0.0563)
2022-11-02 23:35:16,016:INFO: Batch: 19/31	Total Loss 0.0490 (0.0559)
2022-11-02 23:35:16,067:INFO: Batch: 20/31	Total Loss 0.0460 (0.0554)
2022-11-02 23:35:16,117:INFO: Batch: 21/31	Total Loss 0.0461 (0.0549)
2022-11-02 23:35:16,167:INFO: Batch: 22/31	Total Loss 0.0461 (0.0546)
2022-11-02 23:35:16,218:INFO: Batch: 23/31	Total Loss 0.0453 (0.0541)
2022-11-02 23:35:16,268:INFO: Batch: 24/31	Total Loss 0.0519 (0.0541)
2022-11-02 23:35:16,317:INFO: Batch: 25/31	Total Loss 0.0495 (0.0539)
2022-11-02 23:35:16,367:INFO: Batch: 26/31	Total Loss 0.0514 (0.0538)
2022-11-02 23:35:16,418:INFO: Batch: 27/31	Total Loss 0.0482 (0.0536)
2022-11-02 23:35:16,470:INFO: Batch: 28/31	Total Loss 0.0482 (0.0534)
2022-11-02 23:35:16,521:INFO: Batch: 29/31	Total Loss 0.0506 (0.0533)
2022-11-02 23:35:16,553:INFO: Batch: 30/31	Total Loss 0.0215 (0.0531)
2022-11-02 23:35:16,719:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_109.pth.tar
2022-11-02 23:35:16,719:INFO: 
===> EPOCH: 110 (P1)
2022-11-02 23:35:16,719:INFO: - Computing loss (training)
2022-11-02 23:35:17,422:INFO: Batch:  0/31	Total Loss 0.0557 (0.0557)
2022-11-02 23:35:17,472:INFO: Batch:  1/31	Total Loss 0.0503 (0.0529)
2022-11-02 23:35:17,528:INFO: Batch:  2/31	Total Loss 0.0517 (0.0525)
2022-11-02 23:35:17,581:INFO: Batch:  3/31	Total Loss 0.0496 (0.0519)
2022-11-02 23:35:17,632:INFO: Batch:  4/31	Total Loss 0.0488 (0.0513)
2022-11-02 23:35:17,684:INFO: Batch:  5/31	Total Loss 0.0549 (0.0519)
2022-11-02 23:35:17,733:INFO: Batch:  6/31	Total Loss 0.0501 (0.0516)
2022-11-02 23:35:17,780:INFO: Batch:  7/31	Total Loss 0.0465 (0.0510)
2022-11-02 23:35:17,830:INFO: Batch:  8/31	Total Loss 0.0449 (0.0503)
2022-11-02 23:35:17,878:INFO: Batch:  9/31	Total Loss 0.0630 (0.0514)
2022-11-02 23:35:17,925:INFO: Batch: 10/31	Total Loss 0.0497 (0.0513)
2022-11-02 23:35:17,974:INFO: Batch: 11/31	Total Loss 0.0490 (0.0511)
2022-11-02 23:35:18,024:INFO: Batch: 12/31	Total Loss 0.0500 (0.0510)
2022-11-02 23:35:18,074:INFO: Batch: 13/31	Total Loss 0.0481 (0.0508)
2022-11-02 23:35:18,125:INFO: Batch: 14/31	Total Loss 0.0491 (0.0507)
2022-11-02 23:35:18,190:INFO: Batch: 15/31	Total Loss 0.0553 (0.0509)
2022-11-02 23:35:18,256:INFO: Batch: 16/31	Total Loss 0.0495 (0.0508)
2022-11-02 23:35:18,321:INFO: Batch: 17/31	Total Loss 0.0512 (0.0509)
2022-11-02 23:35:18,382:INFO: Batch: 18/31	Total Loss 0.0521 (0.0509)
2022-11-02 23:35:18,454:INFO: Batch: 19/31	Total Loss 0.0480 (0.0508)
2022-11-02 23:35:18,515:INFO: Batch: 20/31	Total Loss 0.0469 (0.0506)
2022-11-02 23:35:18,573:INFO: Batch: 21/31	Total Loss 0.0493 (0.0505)
2022-11-02 23:35:18,628:INFO: Batch: 22/31	Total Loss 0.0486 (0.0505)
2022-11-02 23:35:18,685:INFO: Batch: 23/31	Total Loss 0.0600 (0.0508)
2022-11-02 23:35:18,740:INFO: Batch: 24/31	Total Loss 0.0491 (0.0507)
2022-11-02 23:35:18,797:INFO: Batch: 25/31	Total Loss 0.0483 (0.0506)
2022-11-02 23:35:18,853:INFO: Batch: 26/31	Total Loss 0.0435 (0.0504)
2022-11-02 23:35:18,909:INFO: Batch: 27/31	Total Loss 0.0489 (0.0503)
2022-11-02 23:35:18,965:INFO: Batch: 28/31	Total Loss 0.0491 (0.0503)
2022-11-02 23:35:19,018:INFO: Batch: 29/31	Total Loss 0.0517 (0.0503)
2022-11-02 23:35:19,052:INFO: Batch: 30/31	Total Loss 0.0182 (0.0500)
2022-11-02 23:35:19,209:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_110.pth.tar
2022-11-02 23:35:19,209:INFO: 
===> EPOCH: 111 (P1)
2022-11-02 23:35:19,210:INFO: - Computing loss (training)
2022-11-02 23:35:19,898:INFO: Batch:  0/31	Total Loss 0.0502 (0.0502)
2022-11-02 23:35:19,951:INFO: Batch:  1/31	Total Loss 0.0506 (0.0504)
2022-11-02 23:35:20,008:INFO: Batch:  2/31	Total Loss 0.0481 (0.0496)
2022-11-02 23:35:20,062:INFO: Batch:  3/31	Total Loss 0.0441 (0.0483)
2022-11-02 23:35:20,112:INFO: Batch:  4/31	Total Loss 0.0648 (0.0514)
2022-11-02 23:35:20,163:INFO: Batch:  5/31	Total Loss 0.0468 (0.0506)
2022-11-02 23:35:20,213:INFO: Batch:  6/31	Total Loss 0.0456 (0.0499)
2022-11-02 23:35:20,262:INFO: Batch:  7/31	Total Loss 0.0573 (0.0507)
2022-11-02 23:35:20,310:INFO: Batch:  8/31	Total Loss 0.0465 (0.0502)
2022-11-02 23:35:20,360:INFO: Batch:  9/31	Total Loss 0.0526 (0.0505)
2022-11-02 23:35:20,408:INFO: Batch: 10/31	Total Loss 0.0486 (0.0503)
2022-11-02 23:35:20,457:INFO: Batch: 11/31	Total Loss 0.0516 (0.0504)
2022-11-02 23:35:20,508:INFO: Batch: 12/31	Total Loss 0.0487 (0.0503)
2022-11-02 23:35:20,560:INFO: Batch: 13/31	Total Loss 0.0507 (0.0503)
2022-11-02 23:35:20,613:INFO: Batch: 14/31	Total Loss 0.0546 (0.0506)
2022-11-02 23:35:20,664:INFO: Batch: 15/31	Total Loss 0.0534 (0.0508)
2022-11-02 23:35:20,715:INFO: Batch: 16/31	Total Loss 0.0526 (0.0509)
2022-11-02 23:35:20,766:INFO: Batch: 17/31	Total Loss 0.0580 (0.0512)
2022-11-02 23:35:20,819:INFO: Batch: 18/31	Total Loss 0.0533 (0.0514)
2022-11-02 23:35:20,870:INFO: Batch: 19/31	Total Loss 0.0535 (0.0515)
2022-11-02 23:35:20,920:INFO: Batch: 20/31	Total Loss 0.0594 (0.0518)
2022-11-02 23:35:20,973:INFO: Batch: 21/31	Total Loss 0.0512 (0.0518)
2022-11-02 23:35:21,027:INFO: Batch: 22/31	Total Loss 0.0642 (0.0523)
2022-11-02 23:35:21,081:INFO: Batch: 23/31	Total Loss 0.0533 (0.0523)
2022-11-02 23:35:21,135:INFO: Batch: 24/31	Total Loss 0.0476 (0.0521)
2022-11-02 23:35:21,188:INFO: Batch: 25/31	Total Loss 0.0465 (0.0519)
2022-11-02 23:35:21,242:INFO: Batch: 26/31	Total Loss 0.0509 (0.0519)
2022-11-02 23:35:21,297:INFO: Batch: 27/31	Total Loss 0.0500 (0.0518)
2022-11-02 23:35:21,351:INFO: Batch: 28/31	Total Loss 0.0533 (0.0519)
2022-11-02 23:35:21,405:INFO: Batch: 29/31	Total Loss 0.0482 (0.0518)
2022-11-02 23:35:21,440:INFO: Batch: 30/31	Total Loss 0.0209 (0.0515)
2022-11-02 23:35:21,603:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_111.pth.tar
2022-11-02 23:35:21,603:INFO: 
===> EPOCH: 112 (P1)
2022-11-02 23:35:21,603:INFO: - Computing loss (training)
2022-11-02 23:35:22,297:INFO: Batch:  0/31	Total Loss 0.0448 (0.0448)
2022-11-02 23:35:22,351:INFO: Batch:  1/31	Total Loss 0.0501 (0.0473)
2022-11-02 23:35:22,414:INFO: Batch:  2/31	Total Loss 0.0456 (0.0467)
2022-11-02 23:35:22,467:INFO: Batch:  3/31	Total Loss 0.0498 (0.0475)
2022-11-02 23:35:22,522:INFO: Batch:  4/31	Total Loss 0.0490 (0.0478)
2022-11-02 23:35:22,575:INFO: Batch:  5/31	Total Loss 0.0582 (0.0494)
2022-11-02 23:35:22,627:INFO: Batch:  6/31	Total Loss 0.0484 (0.0492)
2022-11-02 23:35:22,678:INFO: Batch:  7/31	Total Loss 0.0443 (0.0487)
2022-11-02 23:35:22,729:INFO: Batch:  8/31	Total Loss 0.0459 (0.0484)
2022-11-02 23:35:22,777:INFO: Batch:  9/31	Total Loss 0.0452 (0.0480)
2022-11-02 23:35:22,827:INFO: Batch: 10/31	Total Loss 0.0516 (0.0484)
2022-11-02 23:35:22,875:INFO: Batch: 11/31	Total Loss 0.0481 (0.0484)
2022-11-02 23:35:22,926:INFO: Batch: 12/31	Total Loss 0.0499 (0.0485)
2022-11-02 23:35:22,979:INFO: Batch: 13/31	Total Loss 0.0573 (0.0492)
2022-11-02 23:35:23,029:INFO: Batch: 14/31	Total Loss 0.0483 (0.0491)
2022-11-02 23:35:23,080:INFO: Batch: 15/31	Total Loss 0.0478 (0.0490)
2022-11-02 23:35:23,130:INFO: Batch: 16/31	Total Loss 0.0455 (0.0488)
2022-11-02 23:35:23,181:INFO: Batch: 17/31	Total Loss 0.0552 (0.0492)
2022-11-02 23:35:23,232:INFO: Batch: 18/31	Total Loss 0.0558 (0.0495)
2022-11-02 23:35:23,283:INFO: Batch: 19/31	Total Loss 0.0557 (0.0499)
2022-11-02 23:35:23,333:INFO: Batch: 20/31	Total Loss 0.0514 (0.0500)
2022-11-02 23:35:23,382:INFO: Batch: 21/31	Total Loss 0.0541 (0.0502)
2022-11-02 23:35:23,432:INFO: Batch: 22/31	Total Loss 0.0602 (0.0506)
2022-11-02 23:35:23,483:INFO: Batch: 23/31	Total Loss 0.0472 (0.0505)
2022-11-02 23:35:23,533:INFO: Batch: 24/31	Total Loss 0.0484 (0.0504)
2022-11-02 23:35:23,583:INFO: Batch: 25/31	Total Loss 0.0505 (0.0504)
2022-11-02 23:35:23,633:INFO: Batch: 26/31	Total Loss 0.0489 (0.0503)
2022-11-02 23:35:23,682:INFO: Batch: 27/31	Total Loss 0.0429 (0.0501)
2022-11-02 23:35:23,732:INFO: Batch: 28/31	Total Loss 0.0520 (0.0501)
2022-11-02 23:35:23,782:INFO: Batch: 29/31	Total Loss 0.0539 (0.0502)
2022-11-02 23:35:23,813:INFO: Batch: 30/31	Total Loss 0.0168 (0.0499)
2022-11-02 23:35:23,965:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_112.pth.tar
2022-11-02 23:35:23,966:INFO: 
===> EPOCH: 113 (P1)
2022-11-02 23:35:23,966:INFO: - Computing loss (training)
2022-11-02 23:35:24,623:INFO: Batch:  0/31	Total Loss 0.0474 (0.0474)
2022-11-02 23:35:24,684:INFO: Batch:  1/31	Total Loss 0.0524 (0.0498)
2022-11-02 23:35:24,744:INFO: Batch:  2/31	Total Loss 0.0494 (0.0496)
2022-11-02 23:35:24,796:INFO: Batch:  3/31	Total Loss 0.0439 (0.0483)
2022-11-02 23:35:24,852:INFO: Batch:  4/31	Total Loss 0.0465 (0.0479)
2022-11-02 23:35:24,906:INFO: Batch:  5/31	Total Loss 0.0568 (0.0493)
2022-11-02 23:35:24,957:INFO: Batch:  6/31	Total Loss 0.0429 (0.0484)
2022-11-02 23:35:25,007:INFO: Batch:  7/31	Total Loss 0.0464 (0.0482)
2022-11-02 23:35:25,059:INFO: Batch:  8/31	Total Loss 0.0500 (0.0484)
2022-11-02 23:35:25,110:INFO: Batch:  9/31	Total Loss 0.0556 (0.0491)
2022-11-02 23:35:25,162:INFO: Batch: 10/31	Total Loss 0.0496 (0.0492)
2022-11-02 23:35:25,213:INFO: Batch: 11/31	Total Loss 0.0513 (0.0493)
2022-11-02 23:35:25,266:INFO: Batch: 12/31	Total Loss 0.0477 (0.0492)
2022-11-02 23:35:25,320:INFO: Batch: 13/31	Total Loss 0.0519 (0.0494)
2022-11-02 23:35:25,374:INFO: Batch: 14/31	Total Loss 0.0483 (0.0493)
2022-11-02 23:35:25,426:INFO: Batch: 15/31	Total Loss 0.0493 (0.0493)
2022-11-02 23:35:25,477:INFO: Batch: 16/31	Total Loss 0.0485 (0.0493)
2022-11-02 23:35:25,527:INFO: Batch: 17/31	Total Loss 0.0493 (0.0493)
2022-11-02 23:35:25,576:INFO: Batch: 18/31	Total Loss 0.0447 (0.0490)
2022-11-02 23:35:25,626:INFO: Batch: 19/31	Total Loss 0.0484 (0.0490)
2022-11-02 23:35:25,676:INFO: Batch: 20/31	Total Loss 0.0471 (0.0489)
2022-11-02 23:35:25,735:INFO: Batch: 21/31	Total Loss 0.0422 (0.0486)
2022-11-02 23:35:25,786:INFO: Batch: 22/31	Total Loss 0.0438 (0.0484)
2022-11-02 23:35:25,837:INFO: Batch: 23/31	Total Loss 0.0481 (0.0484)
2022-11-02 23:35:25,887:INFO: Batch: 24/31	Total Loss 0.0492 (0.0484)
2022-11-02 23:35:25,939:INFO: Batch: 25/31	Total Loss 0.0448 (0.0483)
2022-11-02 23:35:26,068:INFO: Batch: 26/31	Total Loss 0.0425 (0.0481)
2022-11-02 23:35:26,121:INFO: Batch: 27/31	Total Loss 0.0430 (0.0479)
2022-11-02 23:35:26,173:INFO: Batch: 28/31	Total Loss 0.0399 (0.0476)
2022-11-02 23:35:26,224:INFO: Batch: 29/31	Total Loss 0.0437 (0.0475)
2022-11-02 23:35:26,256:INFO: Batch: 30/31	Total Loss 0.0158 (0.0471)
2022-11-02 23:35:26,401:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_113.pth.tar
2022-11-02 23:35:26,401:INFO: 
===> EPOCH: 114 (P1)
2022-11-02 23:35:26,402:INFO: - Computing loss (training)
2022-11-02 23:35:27,056:INFO: Batch:  0/31	Total Loss 0.0490 (0.0490)
2022-11-02 23:35:27,110:INFO: Batch:  1/31	Total Loss 0.0436 (0.0462)
2022-11-02 23:35:27,163:INFO: Batch:  2/31	Total Loss 0.0466 (0.0464)
2022-11-02 23:35:27,214:INFO: Batch:  3/31	Total Loss 0.0517 (0.0478)
2022-11-02 23:35:27,262:INFO: Batch:  4/31	Total Loss 0.0447 (0.0472)
2022-11-02 23:35:27,313:INFO: Batch:  5/31	Total Loss 0.0456 (0.0469)
2022-11-02 23:35:27,362:INFO: Batch:  6/31	Total Loss 0.0414 (0.0461)
2022-11-02 23:35:27,409:INFO: Batch:  7/31	Total Loss 0.0421 (0.0456)
2022-11-02 23:35:27,456:INFO: Batch:  8/31	Total Loss 0.0446 (0.0455)
2022-11-02 23:35:27,503:INFO: Batch:  9/31	Total Loss 0.0426 (0.0452)
2022-11-02 23:35:27,551:INFO: Batch: 10/31	Total Loss 0.0399 (0.0447)
2022-11-02 23:35:27,599:INFO: Batch: 11/31	Total Loss 0.0531 (0.0453)
2022-11-02 23:35:27,654:INFO: Batch: 12/31	Total Loss 0.0451 (0.0453)
2022-11-02 23:35:27,707:INFO: Batch: 13/31	Total Loss 0.0463 (0.0453)
2022-11-02 23:35:27,757:INFO: Batch: 14/31	Total Loss 0.0440 (0.0452)
2022-11-02 23:35:27,808:INFO: Batch: 15/31	Total Loss 0.0454 (0.0452)
2022-11-02 23:35:27,859:INFO: Batch: 16/31	Total Loss 0.0481 (0.0454)
2022-11-02 23:35:27,911:INFO: Batch: 17/31	Total Loss 0.0444 (0.0454)
2022-11-02 23:35:27,964:INFO: Batch: 18/31	Total Loss 0.0492 (0.0456)
2022-11-02 23:35:28,015:INFO: Batch: 19/31	Total Loss 0.0487 (0.0457)
2022-11-02 23:35:28,065:INFO: Batch: 20/31	Total Loss 0.0492 (0.0459)
2022-11-02 23:35:28,117:INFO: Batch: 21/31	Total Loss 0.0487 (0.0460)
2022-11-02 23:35:28,167:INFO: Batch: 22/31	Total Loss 0.0475 (0.0461)
2022-11-02 23:35:28,221:INFO: Batch: 23/31	Total Loss 0.0451 (0.0460)
2022-11-02 23:35:28,270:INFO: Batch: 24/31	Total Loss 0.0466 (0.0461)
2022-11-02 23:35:28,320:INFO: Batch: 25/31	Total Loss 0.0400 (0.0458)
2022-11-02 23:35:28,371:INFO: Batch: 26/31	Total Loss 0.0451 (0.0458)
2022-11-02 23:35:28,422:INFO: Batch: 27/31	Total Loss 0.0432 (0.0457)
2022-11-02 23:35:28,474:INFO: Batch: 28/31	Total Loss 0.0419 (0.0456)
2022-11-02 23:35:28,526:INFO: Batch: 29/31	Total Loss 0.0404 (0.0454)
2022-11-02 23:35:28,558:INFO: Batch: 30/31	Total Loss 0.0166 (0.0451)
2022-11-02 23:35:28,726:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_114.pth.tar
2022-11-02 23:35:28,726:INFO: 
===> EPOCH: 115 (P1)
2022-11-02 23:35:28,726:INFO: - Computing loss (training)
2022-11-02 23:35:29,434:INFO: Batch:  0/31	Total Loss 0.0473 (0.0473)
2022-11-02 23:35:29,488:INFO: Batch:  1/31	Total Loss 0.0465 (0.0469)
2022-11-02 23:35:29,540:INFO: Batch:  2/31	Total Loss 0.0439 (0.0459)
2022-11-02 23:35:29,590:INFO: Batch:  3/31	Total Loss 0.0441 (0.0455)
2022-11-02 23:35:29,639:INFO: Batch:  4/31	Total Loss 0.0567 (0.0477)
2022-11-02 23:35:29,688:INFO: Batch:  5/31	Total Loss 0.0443 (0.0471)
2022-11-02 23:35:29,736:INFO: Batch:  6/31	Total Loss 0.0458 (0.0470)
2022-11-02 23:35:29,788:INFO: Batch:  7/31	Total Loss 0.0461 (0.0468)
2022-11-02 23:35:29,836:INFO: Batch:  8/31	Total Loss 0.0463 (0.0468)
2022-11-02 23:35:29,885:INFO: Batch:  9/31	Total Loss 0.0512 (0.0473)
2022-11-02 23:35:29,936:INFO: Batch: 10/31	Total Loss 0.0471 (0.0473)
2022-11-02 23:35:29,983:INFO: Batch: 11/31	Total Loss 0.0466 (0.0472)
2022-11-02 23:35:30,035:INFO: Batch: 12/31	Total Loss 0.0434 (0.0469)
2022-11-02 23:35:30,085:INFO: Batch: 13/31	Total Loss 0.0456 (0.0468)
2022-11-02 23:35:30,136:INFO: Batch: 14/31	Total Loss 0.0436 (0.0466)
2022-11-02 23:35:30,186:INFO: Batch: 15/31	Total Loss 0.0558 (0.0472)
2022-11-02 23:35:30,236:INFO: Batch: 16/31	Total Loss 0.0429 (0.0469)
2022-11-02 23:35:30,288:INFO: Batch: 17/31	Total Loss 0.0492 (0.0471)
2022-11-02 23:35:30,341:INFO: Batch: 18/31	Total Loss 0.0445 (0.0469)
2022-11-02 23:35:30,395:INFO: Batch: 19/31	Total Loss 0.0478 (0.0470)
2022-11-02 23:35:30,449:INFO: Batch: 20/31	Total Loss 0.0402 (0.0466)
2022-11-02 23:35:30,502:INFO: Batch: 21/31	Total Loss 0.0485 (0.0467)
2022-11-02 23:35:30,557:INFO: Batch: 22/31	Total Loss 0.0449 (0.0467)
2022-11-02 23:35:30,611:INFO: Batch: 23/31	Total Loss 0.0454 (0.0466)
2022-11-02 23:35:30,665:INFO: Batch: 24/31	Total Loss 0.0457 (0.0466)
2022-11-02 23:35:30,716:INFO: Batch: 25/31	Total Loss 0.0465 (0.0466)
2022-11-02 23:35:30,768:INFO: Batch: 26/31	Total Loss 0.0413 (0.0464)
2022-11-02 23:35:30,818:INFO: Batch: 27/31	Total Loss 0.0404 (0.0461)
2022-11-02 23:35:30,869:INFO: Batch: 28/31	Total Loss 0.0479 (0.0462)
2022-11-02 23:35:30,920:INFO: Batch: 29/31	Total Loss 0.0482 (0.0463)
2022-11-02 23:35:30,951:INFO: Batch: 30/31	Total Loss 0.0169 (0.0460)
2022-11-02 23:35:31,109:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_115.pth.tar
2022-11-02 23:35:31,109:INFO: 
===> EPOCH: 116 (P1)
2022-11-02 23:35:31,109:INFO: - Computing loss (training)
2022-11-02 23:35:31,781:INFO: Batch:  0/31	Total Loss 0.0400 (0.0400)
2022-11-02 23:35:31,832:INFO: Batch:  1/31	Total Loss 0.0417 (0.0409)
2022-11-02 23:35:31,889:INFO: Batch:  2/31	Total Loss 0.0511 (0.0440)
2022-11-02 23:35:31,940:INFO: Batch:  3/31	Total Loss 0.0397 (0.0429)
2022-11-02 23:35:31,989:INFO: Batch:  4/31	Total Loss 0.0428 (0.0429)
2022-11-02 23:35:32,045:INFO: Batch:  5/31	Total Loss 0.0439 (0.0431)
2022-11-02 23:35:32,094:INFO: Batch:  6/31	Total Loss 0.0399 (0.0426)
2022-11-02 23:35:32,149:INFO: Batch:  7/31	Total Loss 0.0444 (0.0428)
2022-11-02 23:35:32,213:INFO: Batch:  8/31	Total Loss 0.0447 (0.0430)
2022-11-02 23:35:32,266:INFO: Batch:  9/31	Total Loss 0.0490 (0.0436)
2022-11-02 23:35:32,318:INFO: Batch: 10/31	Total Loss 0.0702 (0.0458)
2022-11-02 23:35:32,368:INFO: Batch: 11/31	Total Loss 0.0492 (0.0461)
2022-11-02 23:35:32,422:INFO: Batch: 12/31	Total Loss 0.0508 (0.0464)
2022-11-02 23:35:32,478:INFO: Batch: 13/31	Total Loss 0.0548 (0.0470)
2022-11-02 23:35:32,530:INFO: Batch: 14/31	Total Loss 0.0428 (0.0468)
2022-11-02 23:35:32,582:INFO: Batch: 15/31	Total Loss 0.0535 (0.0472)
2022-11-02 23:35:32,634:INFO: Batch: 16/31	Total Loss 0.0501 (0.0474)
2022-11-02 23:35:32,685:INFO: Batch: 17/31	Total Loss 0.0469 (0.0473)
2022-11-02 23:35:32,737:INFO: Batch: 18/31	Total Loss 0.0400 (0.0469)
2022-11-02 23:35:32,787:INFO: Batch: 19/31	Total Loss 0.0432 (0.0468)
2022-11-02 23:35:32,836:INFO: Batch: 20/31	Total Loss 0.0463 (0.0467)
2022-11-02 23:35:32,886:INFO: Batch: 21/31	Total Loss 0.0490 (0.0468)
2022-11-02 23:35:32,936:INFO: Batch: 22/31	Total Loss 0.0480 (0.0469)
2022-11-02 23:35:32,986:INFO: Batch: 23/31	Total Loss 0.0420 (0.0467)
2022-11-02 23:35:33,037:INFO: Batch: 24/31	Total Loss 0.0412 (0.0465)
2022-11-02 23:35:33,088:INFO: Batch: 25/31	Total Loss 0.0440 (0.0464)
2022-11-02 23:35:33,139:INFO: Batch: 26/31	Total Loss 0.0393 (0.0461)
2022-11-02 23:35:33,192:INFO: Batch: 27/31	Total Loss 0.0433 (0.0460)
2022-11-02 23:35:33,244:INFO: Batch: 28/31	Total Loss 0.0399 (0.0458)
2022-11-02 23:35:33,297:INFO: Batch: 29/31	Total Loss 0.0408 (0.0456)
2022-11-02 23:35:33,329:INFO: Batch: 30/31	Total Loss 0.0153 (0.0453)
2022-11-02 23:35:33,498:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_116.pth.tar
2022-11-02 23:35:33,498:INFO: 
===> EPOCH: 117 (P1)
2022-11-02 23:35:33,498:INFO: - Computing loss (training)
2022-11-02 23:35:34,179:INFO: Batch:  0/31	Total Loss 0.0400 (0.0400)
2022-11-02 23:35:34,237:INFO: Batch:  1/31	Total Loss 0.0437 (0.0419)
2022-11-02 23:35:34,291:INFO: Batch:  2/31	Total Loss 0.0381 (0.0406)
2022-11-02 23:35:34,340:INFO: Batch:  3/31	Total Loss 0.0440 (0.0413)
2022-11-02 23:35:34,390:INFO: Batch:  4/31	Total Loss 0.0454 (0.0422)
2022-11-02 23:35:34,442:INFO: Batch:  5/31	Total Loss 0.0406 (0.0419)
2022-11-02 23:35:34,490:INFO: Batch:  6/31	Total Loss 0.0422 (0.0420)
2022-11-02 23:35:34,539:INFO: Batch:  7/31	Total Loss 0.0407 (0.0418)
2022-11-02 23:35:34,586:INFO: Batch:  8/31	Total Loss 0.0390 (0.0415)
2022-11-02 23:35:34,634:INFO: Batch:  9/31	Total Loss 0.0470 (0.0420)
2022-11-02 23:35:34,683:INFO: Batch: 10/31	Total Loss 0.0542 (0.0431)
2022-11-02 23:35:34,731:INFO: Batch: 11/31	Total Loss 0.0412 (0.0429)
2022-11-02 23:35:34,780:INFO: Batch: 12/31	Total Loss 0.0396 (0.0427)
2022-11-02 23:35:34,833:INFO: Batch: 13/31	Total Loss 0.0461 (0.0429)
2022-11-02 23:35:34,889:INFO: Batch: 14/31	Total Loss 0.0422 (0.0429)
2022-11-02 23:35:34,947:INFO: Batch: 15/31	Total Loss 0.0387 (0.0426)
2022-11-02 23:35:35,001:INFO: Batch: 16/31	Total Loss 0.0412 (0.0425)
2022-11-02 23:35:35,054:INFO: Batch: 17/31	Total Loss 0.0500 (0.0429)
2022-11-02 23:35:35,104:INFO: Batch: 18/31	Total Loss 0.0420 (0.0429)
2022-11-02 23:35:35,153:INFO: Batch: 19/31	Total Loss 0.0421 (0.0428)
2022-11-02 23:35:35,203:INFO: Batch: 20/31	Total Loss 0.0447 (0.0429)
2022-11-02 23:35:35,253:INFO: Batch: 21/31	Total Loss 0.0375 (0.0427)
2022-11-02 23:35:35,304:INFO: Batch: 22/31	Total Loss 0.0403 (0.0426)
2022-11-02 23:35:35,356:INFO: Batch: 23/31	Total Loss 0.0418 (0.0425)
2022-11-02 23:35:35,406:INFO: Batch: 24/31	Total Loss 0.0425 (0.0425)
2022-11-02 23:35:35,456:INFO: Batch: 25/31	Total Loss 0.0580 (0.0431)
2022-11-02 23:35:35,505:INFO: Batch: 26/31	Total Loss 0.0437 (0.0431)
2022-11-02 23:35:35,555:INFO: Batch: 27/31	Total Loss 0.0417 (0.0431)
2022-11-02 23:35:35,605:INFO: Batch: 28/31	Total Loss 0.0481 (0.0433)
2022-11-02 23:35:35,656:INFO: Batch: 29/31	Total Loss 0.0437 (0.0433)
2022-11-02 23:35:35,686:INFO: Batch: 30/31	Total Loss 0.0148 (0.0430)
2022-11-02 23:35:35,833:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_117.pth.tar
2022-11-02 23:35:35,833:INFO: 
===> EPOCH: 118 (P1)
2022-11-02 23:35:35,834:INFO: - Computing loss (training)
2022-11-02 23:35:36,550:INFO: Batch:  0/31	Total Loss 0.0399 (0.0399)
2022-11-02 23:35:36,599:INFO: Batch:  1/31	Total Loss 0.0446 (0.0423)
2022-11-02 23:35:36,654:INFO: Batch:  2/31	Total Loss 0.0495 (0.0447)
2022-11-02 23:35:36,706:INFO: Batch:  3/31	Total Loss 0.0408 (0.0437)
2022-11-02 23:35:36,758:INFO: Batch:  4/31	Total Loss 0.0404 (0.0430)
2022-11-02 23:35:36,808:INFO: Batch:  5/31	Total Loss 0.0424 (0.0429)
2022-11-02 23:35:36,855:INFO: Batch:  6/31	Total Loss 0.0450 (0.0432)
2022-11-02 23:35:36,901:INFO: Batch:  7/31	Total Loss 0.0411 (0.0429)
2022-11-02 23:35:36,947:INFO: Batch:  8/31	Total Loss 0.0379 (0.0424)
2022-11-02 23:35:36,997:INFO: Batch:  9/31	Total Loss 0.0392 (0.0421)
2022-11-02 23:35:37,047:INFO: Batch: 10/31	Total Loss 0.0427 (0.0421)
2022-11-02 23:35:37,095:INFO: Batch: 11/31	Total Loss 0.0411 (0.0420)
2022-11-02 23:35:37,145:INFO: Batch: 12/31	Total Loss 0.0404 (0.0419)
2022-11-02 23:35:37,196:INFO: Batch: 13/31	Total Loss 0.0395 (0.0417)
2022-11-02 23:35:37,247:INFO: Batch: 14/31	Total Loss 0.0409 (0.0417)
2022-11-02 23:35:37,297:INFO: Batch: 15/31	Total Loss 0.0412 (0.0416)
2022-11-02 23:35:37,352:INFO: Batch: 16/31	Total Loss 0.0375 (0.0414)
2022-11-02 23:35:37,403:INFO: Batch: 17/31	Total Loss 0.0433 (0.0415)
2022-11-02 23:35:37,456:INFO: Batch: 18/31	Total Loss 0.0365 (0.0412)
2022-11-02 23:35:37,507:INFO: Batch: 19/31	Total Loss 0.0416 (0.0412)
2022-11-02 23:35:37,557:INFO: Batch: 20/31	Total Loss 0.0378 (0.0411)
2022-11-02 23:35:37,606:INFO: Batch: 21/31	Total Loss 0.0423 (0.0411)
2022-11-02 23:35:37,656:INFO: Batch: 22/31	Total Loss 0.0412 (0.0411)
2022-11-02 23:35:37,706:INFO: Batch: 23/31	Total Loss 0.0444 (0.0412)
2022-11-02 23:35:37,756:INFO: Batch: 24/31	Total Loss 0.0437 (0.0414)
2022-11-02 23:35:37,807:INFO: Batch: 25/31	Total Loss 0.0416 (0.0414)
2022-11-02 23:35:37,857:INFO: Batch: 26/31	Total Loss 0.0414 (0.0414)
2022-11-02 23:35:37,908:INFO: Batch: 27/31	Total Loss 0.0407 (0.0413)
2022-11-02 23:35:37,958:INFO: Batch: 28/31	Total Loss 0.0403 (0.0413)
2022-11-02 23:35:38,008:INFO: Batch: 29/31	Total Loss 0.0451 (0.0414)
2022-11-02 23:35:38,039:INFO: Batch: 30/31	Total Loss 0.0148 (0.0412)
2022-11-02 23:35:38,201:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_118.pth.tar
2022-11-02 23:35:38,201:INFO: 
===> EPOCH: 119 (P1)
2022-11-02 23:35:38,201:INFO: - Computing loss (training)
2022-11-02 23:35:38,856:INFO: Batch:  0/31	Total Loss 0.0444 (0.0444)
2022-11-02 23:35:38,910:INFO: Batch:  1/31	Total Loss 0.0410 (0.0427)
2022-11-02 23:35:38,966:INFO: Batch:  2/31	Total Loss 0.0398 (0.0417)
2022-11-02 23:35:39,020:INFO: Batch:  3/31	Total Loss 0.0432 (0.0421)
2022-11-02 23:35:39,070:INFO: Batch:  4/31	Total Loss 0.0417 (0.0420)
2022-11-02 23:35:39,123:INFO: Batch:  5/31	Total Loss 0.0388 (0.0414)
2022-11-02 23:35:39,173:INFO: Batch:  6/31	Total Loss 0.0395 (0.0412)
2022-11-02 23:35:39,222:INFO: Batch:  7/31	Total Loss 0.0403 (0.0411)
2022-11-02 23:35:39,272:INFO: Batch:  8/31	Total Loss 0.0398 (0.0409)
2022-11-02 23:35:39,323:INFO: Batch:  9/31	Total Loss 0.0366 (0.0405)
2022-11-02 23:35:39,372:INFO: Batch: 10/31	Total Loss 0.0386 (0.0403)
2022-11-02 23:35:39,423:INFO: Batch: 11/31	Total Loss 0.0476 (0.0408)
2022-11-02 23:35:39,474:INFO: Batch: 12/31	Total Loss 0.0414 (0.0409)
2022-11-02 23:35:39,526:INFO: Batch: 13/31	Total Loss 0.0469 (0.0413)
2022-11-02 23:35:39,579:INFO: Batch: 14/31	Total Loss 0.0431 (0.0414)
2022-11-02 23:35:39,632:INFO: Batch: 15/31	Total Loss 0.0397 (0.0413)
2022-11-02 23:35:39,685:INFO: Batch: 16/31	Total Loss 0.0443 (0.0415)
2022-11-02 23:35:39,738:INFO: Batch: 17/31	Total Loss 0.0365 (0.0412)
2022-11-02 23:35:39,795:INFO: Batch: 18/31	Total Loss 0.0401 (0.0412)
2022-11-02 23:35:39,848:INFO: Batch: 19/31	Total Loss 0.0396 (0.0411)
2022-11-02 23:35:39,901:INFO: Batch: 20/31	Total Loss 0.0435 (0.0412)
2022-11-02 23:35:39,953:INFO: Batch: 21/31	Total Loss 0.0402 (0.0411)
2022-11-02 23:35:40,008:INFO: Batch: 22/31	Total Loss 0.0408 (0.0411)
2022-11-02 23:35:40,061:INFO: Batch: 23/31	Total Loss 0.0397 (0.0411)
2022-11-02 23:35:40,113:INFO: Batch: 24/31	Total Loss 0.0487 (0.0414)
2022-11-02 23:35:40,164:INFO: Batch: 25/31	Total Loss 0.0463 (0.0416)
2022-11-02 23:35:40,215:INFO: Batch: 26/31	Total Loss 0.0419 (0.0416)
2022-11-02 23:35:40,266:INFO: Batch: 27/31	Total Loss 0.0381 (0.0415)
2022-11-02 23:35:40,316:INFO: Batch: 28/31	Total Loss 0.0389 (0.0414)
2022-11-02 23:35:40,367:INFO: Batch: 29/31	Total Loss 0.0400 (0.0413)
2022-11-02 23:35:40,399:INFO: Batch: 30/31	Total Loss 0.0182 (0.0411)
2022-11-02 23:35:40,552:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_119.pth.tar
2022-11-02 23:35:40,552:INFO: 
===> EPOCH: 120 (P1)
2022-11-02 23:35:40,553:INFO: - Computing loss (training)
2022-11-02 23:35:41,295:INFO: Batch:  0/31	Total Loss 0.0414 (0.0414)
2022-11-02 23:35:41,342:INFO: Batch:  1/31	Total Loss 0.0375 (0.0396)
2022-11-02 23:35:41,400:INFO: Batch:  2/31	Total Loss 0.0434 (0.0409)
2022-11-02 23:35:41,447:INFO: Batch:  3/31	Total Loss 0.0423 (0.0413)
2022-11-02 23:35:41,496:INFO: Batch:  4/31	Total Loss 0.0389 (0.0408)
2022-11-02 23:35:41,547:INFO: Batch:  5/31	Total Loss 0.0392 (0.0405)
2022-11-02 23:35:41,594:INFO: Batch:  6/31	Total Loss 0.0474 (0.0413)
2022-11-02 23:35:41,641:INFO: Batch:  7/31	Total Loss 0.0413 (0.0413)
2022-11-02 23:35:41,688:INFO: Batch:  8/31	Total Loss 0.0410 (0.0413)
2022-11-02 23:35:41,734:INFO: Batch:  9/31	Total Loss 0.0387 (0.0410)
2022-11-02 23:35:41,780:INFO: Batch: 10/31	Total Loss 0.0425 (0.0411)
2022-11-02 23:35:41,828:INFO: Batch: 11/31	Total Loss 0.0402 (0.0411)
2022-11-02 23:35:41,877:INFO: Batch: 12/31	Total Loss 0.0494 (0.0416)
2022-11-02 23:35:41,926:INFO: Batch: 13/31	Total Loss 0.0372 (0.0413)
2022-11-02 23:35:41,976:INFO: Batch: 14/31	Total Loss 0.0369 (0.0410)
2022-11-02 23:35:42,025:INFO: Batch: 15/31	Total Loss 0.0397 (0.0409)
2022-11-02 23:35:42,074:INFO: Batch: 16/31	Total Loss 0.0393 (0.0408)
2022-11-02 23:35:42,124:INFO: Batch: 17/31	Total Loss 0.0390 (0.0407)
2022-11-02 23:35:42,172:INFO: Batch: 18/31	Total Loss 0.0365 (0.0405)
2022-11-02 23:35:42,223:INFO: Batch: 19/31	Total Loss 0.0371 (0.0403)
2022-11-02 23:35:42,272:INFO: Batch: 20/31	Total Loss 0.0364 (0.0401)
2022-11-02 23:35:42,323:INFO: Batch: 21/31	Total Loss 0.0378 (0.0400)
2022-11-02 23:35:42,373:INFO: Batch: 22/31	Total Loss 0.0409 (0.0401)
2022-11-02 23:35:42,423:INFO: Batch: 23/31	Total Loss 0.0474 (0.0404)
2022-11-02 23:35:42,472:INFO: Batch: 24/31	Total Loss 0.0452 (0.0406)
2022-11-02 23:35:42,522:INFO: Batch: 25/31	Total Loss 0.0472 (0.0408)
2022-11-02 23:35:42,573:INFO: Batch: 26/31	Total Loss 0.0443 (0.0410)
2022-11-02 23:35:42,622:INFO: Batch: 27/31	Total Loss 0.0357 (0.0408)
2022-11-02 23:35:42,672:INFO: Batch: 28/31	Total Loss 0.0404 (0.0408)
2022-11-02 23:35:42,720:INFO: Batch: 29/31	Total Loss 0.0432 (0.0409)
2022-11-02 23:35:42,751:INFO: Batch: 30/31	Total Loss 0.0127 (0.0406)
2022-11-02 23:35:42,892:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_120.pth.tar
2022-11-02 23:35:42,892:INFO: 
===> EPOCH: 121 (P1)
2022-11-02 23:35:42,893:INFO: - Computing loss (training)
2022-11-02 23:35:43,593:INFO: Batch:  0/31	Total Loss 0.0389 (0.0389)
2022-11-02 23:35:43,644:INFO: Batch:  1/31	Total Loss 0.0398 (0.0394)
2022-11-02 23:35:43,699:INFO: Batch:  2/31	Total Loss 0.0390 (0.0393)
2022-11-02 23:35:43,748:INFO: Batch:  3/31	Total Loss 0.0390 (0.0392)
2022-11-02 23:35:43,800:INFO: Batch:  4/31	Total Loss 0.0441 (0.0401)
2022-11-02 23:35:43,855:INFO: Batch:  5/31	Total Loss 0.0404 (0.0401)
2022-11-02 23:35:43,910:INFO: Batch:  6/31	Total Loss 0.0386 (0.0399)
2022-11-02 23:35:43,958:INFO: Batch:  7/31	Total Loss 0.0433 (0.0403)
2022-11-02 23:35:44,006:INFO: Batch:  8/31	Total Loss 0.0493 (0.0414)
2022-11-02 23:35:44,055:INFO: Batch:  9/31	Total Loss 0.0395 (0.0412)
2022-11-02 23:35:44,103:INFO: Batch: 10/31	Total Loss 0.0454 (0.0416)
2022-11-02 23:35:44,151:INFO: Batch: 11/31	Total Loss 0.0404 (0.0415)
2022-11-02 23:35:44,202:INFO: Batch: 12/31	Total Loss 0.0402 (0.0414)
2022-11-02 23:35:44,253:INFO: Batch: 13/31	Total Loss 0.0407 (0.0414)
2022-11-02 23:35:44,305:INFO: Batch: 14/31	Total Loss 0.0443 (0.0416)
2022-11-02 23:35:44,357:INFO: Batch: 15/31	Total Loss 0.0448 (0.0418)
2022-11-02 23:35:44,408:INFO: Batch: 16/31	Total Loss 0.0379 (0.0415)
2022-11-02 23:35:44,460:INFO: Batch: 17/31	Total Loss 0.0434 (0.0416)
2022-11-02 23:35:44,513:INFO: Batch: 18/31	Total Loss 0.0397 (0.0415)
2022-11-02 23:35:44,565:INFO: Batch: 19/31	Total Loss 0.0433 (0.0416)
2022-11-02 23:35:44,619:INFO: Batch: 20/31	Total Loss 0.0394 (0.0415)
2022-11-02 23:35:44,670:INFO: Batch: 21/31	Total Loss 0.0446 (0.0417)
2022-11-02 23:35:44,722:INFO: Batch: 22/31	Total Loss 0.0480 (0.0419)
2022-11-02 23:35:44,772:INFO: Batch: 23/31	Total Loss 0.0381 (0.0418)
2022-11-02 23:35:44,823:INFO: Batch: 24/31	Total Loss 0.0405 (0.0417)
2022-11-02 23:35:44,873:INFO: Batch: 25/31	Total Loss 0.0391 (0.0416)
2022-11-02 23:35:44,924:INFO: Batch: 26/31	Total Loss 0.0381 (0.0415)
2022-11-02 23:35:44,975:INFO: Batch: 27/31	Total Loss 0.0381 (0.0414)
2022-11-02 23:35:45,026:INFO: Batch: 28/31	Total Loss 0.0401 (0.0413)
2022-11-02 23:35:45,075:INFO: Batch: 29/31	Total Loss 0.0372 (0.0412)
2022-11-02 23:35:45,107:INFO: Batch: 30/31	Total Loss 0.0152 (0.0409)
2022-11-02 23:35:45,269:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_121.pth.tar
2022-11-02 23:35:45,269:INFO: 
===> EPOCH: 122 (P1)
2022-11-02 23:35:45,269:INFO: - Computing loss (training)
2022-11-02 23:35:45,941:INFO: Batch:  0/31	Total Loss 0.0479 (0.0479)
2022-11-02 23:35:45,995:INFO: Batch:  1/31	Total Loss 0.0403 (0.0440)
2022-11-02 23:35:46,049:INFO: Batch:  2/31	Total Loss 0.0369 (0.0414)
2022-11-02 23:35:46,101:INFO: Batch:  3/31	Total Loss 0.0370 (0.0404)
2022-11-02 23:35:46,149:INFO: Batch:  4/31	Total Loss 0.0446 (0.0412)
2022-11-02 23:35:46,203:INFO: Batch:  5/31	Total Loss 0.0362 (0.0404)
2022-11-02 23:35:46,251:INFO: Batch:  6/31	Total Loss 0.0381 (0.0401)
2022-11-02 23:35:46,299:INFO: Batch:  7/31	Total Loss 0.0487 (0.0413)
2022-11-02 23:35:46,347:INFO: Batch:  8/31	Total Loss 0.0401 (0.0411)
2022-11-02 23:35:46,396:INFO: Batch:  9/31	Total Loss 0.0410 (0.0411)
2022-11-02 23:35:46,442:INFO: Batch: 10/31	Total Loss 0.0413 (0.0411)
2022-11-02 23:35:46,492:INFO: Batch: 11/31	Total Loss 0.0373 (0.0408)
2022-11-02 23:35:46,541:INFO: Batch: 12/31	Total Loss 0.0376 (0.0405)
2022-11-02 23:35:46,592:INFO: Batch: 13/31	Total Loss 0.0356 (0.0402)
2022-11-02 23:35:46,643:INFO: Batch: 14/31	Total Loss 0.0443 (0.0404)
2022-11-02 23:35:46,692:INFO: Batch: 15/31	Total Loss 0.0360 (0.0401)
2022-11-02 23:35:46,743:INFO: Batch: 16/31	Total Loss 0.0361 (0.0399)
2022-11-02 23:35:46,794:INFO: Batch: 17/31	Total Loss 0.0357 (0.0397)
2022-11-02 23:35:46,845:INFO: Batch: 18/31	Total Loss 0.0400 (0.0397)
2022-11-02 23:35:46,896:INFO: Batch: 19/31	Total Loss 0.0402 (0.0397)
2022-11-02 23:35:46,945:INFO: Batch: 20/31	Total Loss 0.0363 (0.0396)
2022-11-02 23:35:46,997:INFO: Batch: 21/31	Total Loss 0.0408 (0.0396)
2022-11-02 23:35:47,048:INFO: Batch: 22/31	Total Loss 0.0393 (0.0396)
2022-11-02 23:35:47,098:INFO: Batch: 23/31	Total Loss 0.0388 (0.0396)
2022-11-02 23:35:47,148:INFO: Batch: 24/31	Total Loss 0.0497 (0.0399)
2022-11-02 23:35:47,198:INFO: Batch: 25/31	Total Loss 0.0399 (0.0399)
2022-11-02 23:35:47,248:INFO: Batch: 26/31	Total Loss 0.0428 (0.0400)
2022-11-02 23:35:47,298:INFO: Batch: 27/31	Total Loss 0.0458 (0.0402)
2022-11-02 23:35:47,348:INFO: Batch: 28/31	Total Loss 0.0375 (0.0401)
2022-11-02 23:35:47,399:INFO: Batch: 29/31	Total Loss 0.0351 (0.0400)
2022-11-02 23:35:47,433:INFO: Batch: 30/31	Total Loss 0.0133 (0.0397)
2022-11-02 23:35:47,619:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_122.pth.tar
2022-11-02 23:35:47,619:INFO: 
===> EPOCH: 123 (P1)
2022-11-02 23:35:47,620:INFO: - Computing loss (training)
2022-11-02 23:35:48,521:INFO: Batch:  0/31	Total Loss 0.0414 (0.0414)
2022-11-02 23:35:48,587:INFO: Batch:  1/31	Total Loss 0.0439 (0.0426)
2022-11-02 23:35:48,646:INFO: Batch:  2/31	Total Loss 0.0370 (0.0407)
2022-11-02 23:35:48,697:INFO: Batch:  3/31	Total Loss 0.0390 (0.0402)
2022-11-02 23:35:48,746:INFO: Batch:  4/31	Total Loss 0.0362 (0.0395)
2022-11-02 23:35:48,800:INFO: Batch:  5/31	Total Loss 0.0475 (0.0408)
2022-11-02 23:35:48,854:INFO: Batch:  6/31	Total Loss 0.0358 (0.0401)
2022-11-02 23:35:48,915:INFO: Batch:  7/31	Total Loss 0.0407 (0.0402)
2022-11-02 23:35:48,966:INFO: Batch:  8/31	Total Loss 0.0365 (0.0397)
2022-11-02 23:35:49,015:INFO: Batch:  9/31	Total Loss 0.0414 (0.0399)
2022-11-02 23:35:49,064:INFO: Batch: 10/31	Total Loss 0.0386 (0.0398)
2022-11-02 23:35:49,112:INFO: Batch: 11/31	Total Loss 0.0371 (0.0395)
2022-11-02 23:35:49,162:INFO: Batch: 12/31	Total Loss 0.0370 (0.0394)
2022-11-02 23:35:49,215:INFO: Batch: 13/31	Total Loss 0.0360 (0.0391)
2022-11-02 23:35:49,266:INFO: Batch: 14/31	Total Loss 0.0348 (0.0388)
2022-11-02 23:35:49,318:INFO: Batch: 15/31	Total Loss 0.0404 (0.0389)
2022-11-02 23:35:49,369:INFO: Batch: 16/31	Total Loss 0.0309 (0.0384)
2022-11-02 23:35:49,420:INFO: Batch: 17/31	Total Loss 0.0423 (0.0386)
2022-11-02 23:35:49,472:INFO: Batch: 18/31	Total Loss 0.0416 (0.0388)
2022-11-02 23:35:49,521:INFO: Batch: 19/31	Total Loss 0.0349 (0.0386)
2022-11-02 23:35:49,571:INFO: Batch: 20/31	Total Loss 0.0426 (0.0388)
2022-11-02 23:35:49,620:INFO: Batch: 21/31	Total Loss 0.0339 (0.0386)
2022-11-02 23:35:49,670:INFO: Batch: 22/31	Total Loss 0.0355 (0.0384)
2022-11-02 23:35:49,719:INFO: Batch: 23/31	Total Loss 0.0443 (0.0387)
2022-11-02 23:35:49,768:INFO: Batch: 24/31	Total Loss 0.0390 (0.0387)
2022-11-02 23:35:49,817:INFO: Batch: 25/31	Total Loss 0.0534 (0.0392)
2022-11-02 23:35:49,866:INFO: Batch: 26/31	Total Loss 0.0407 (0.0393)
2022-11-02 23:35:49,915:INFO: Batch: 27/31	Total Loss 0.0420 (0.0394)
2022-11-02 23:35:49,965:INFO: Batch: 28/31	Total Loss 0.0382 (0.0393)
2022-11-02 23:35:50,015:INFO: Batch: 29/31	Total Loss 0.0349 (0.0392)
2022-11-02 23:35:50,045:INFO: Batch: 30/31	Total Loss 0.0150 (0.0390)
2022-11-02 23:35:50,193:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_123.pth.tar
2022-11-02 23:35:50,193:INFO: 
===> EPOCH: 124 (P1)
2022-11-02 23:35:50,194:INFO: - Computing loss (training)
2022-11-02 23:35:50,913:INFO: Batch:  0/31	Total Loss 0.0407 (0.0407)
2022-11-02 23:35:50,965:INFO: Batch:  1/31	Total Loss 0.0489 (0.0448)
2022-11-02 23:35:51,024:INFO: Batch:  2/31	Total Loss 0.0374 (0.0423)
2022-11-02 23:35:51,075:INFO: Batch:  3/31	Total Loss 0.0407 (0.0419)
2022-11-02 23:35:51,127:INFO: Batch:  4/31	Total Loss 0.0455 (0.0427)
2022-11-02 23:35:51,178:INFO: Batch:  5/31	Total Loss 0.0412 (0.0424)
2022-11-02 23:35:51,229:INFO: Batch:  6/31	Total Loss 0.0394 (0.0419)
2022-11-02 23:35:51,277:INFO: Batch:  7/31	Total Loss 0.0353 (0.0411)
2022-11-02 23:35:51,325:INFO: Batch:  8/31	Total Loss 0.0396 (0.0409)
2022-11-02 23:35:51,374:INFO: Batch:  9/31	Total Loss 0.0408 (0.0409)
2022-11-02 23:35:51,425:INFO: Batch: 10/31	Total Loss 0.0519 (0.0418)
2022-11-02 23:35:51,477:INFO: Batch: 11/31	Total Loss 0.0364 (0.0413)
2022-11-02 23:35:51,529:INFO: Batch: 12/31	Total Loss 0.0503 (0.0420)
2022-11-02 23:35:51,579:INFO: Batch: 13/31	Total Loss 0.0538 (0.0430)
2022-11-02 23:35:51,631:INFO: Batch: 14/31	Total Loss 0.0365 (0.0426)
2022-11-02 23:35:51,695:INFO: Batch: 15/31	Total Loss 0.0392 (0.0424)
2022-11-02 23:35:51,748:INFO: Batch: 16/31	Total Loss 0.0467 (0.0426)
2022-11-02 23:35:51,800:INFO: Batch: 17/31	Total Loss 0.0511 (0.0431)
2022-11-02 23:35:51,852:INFO: Batch: 18/31	Total Loss 0.0367 (0.0427)
2022-11-02 23:35:51,901:INFO: Batch: 19/31	Total Loss 0.0410 (0.0426)
2022-11-02 23:35:51,953:INFO: Batch: 20/31	Total Loss 0.0417 (0.0426)
2022-11-02 23:35:52,056:INFO: Batch: 21/31	Total Loss 0.0409 (0.0425)
2022-11-02 23:35:52,141:INFO: Batch: 22/31	Total Loss 0.0432 (0.0425)
2022-11-02 23:35:52,196:INFO: Batch: 23/31	Total Loss 0.0372 (0.0423)
2022-11-02 23:35:52,248:INFO: Batch: 24/31	Total Loss 0.0364 (0.0421)
2022-11-02 23:35:52,299:INFO: Batch: 25/31	Total Loss 0.0422 (0.0421)
2022-11-02 23:35:52,350:INFO: Batch: 26/31	Total Loss 0.0419 (0.0421)
2022-11-02 23:35:52,402:INFO: Batch: 27/31	Total Loss 0.0388 (0.0419)
2022-11-02 23:35:52,462:INFO: Batch: 28/31	Total Loss 0.0399 (0.0419)
2022-11-02 23:35:52,533:INFO: Batch: 29/31	Total Loss 0.0370 (0.0417)
2022-11-02 23:35:52,568:INFO: Batch: 30/31	Total Loss 0.0149 (0.0415)
2022-11-02 23:35:52,745:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_124.pth.tar
2022-11-02 23:35:52,745:INFO: 
===> EPOCH: 125 (P1)
2022-11-02 23:35:52,746:INFO: - Computing loss (training)
2022-11-02 23:35:53,666:INFO: Batch:  0/31	Total Loss 0.0442 (0.0442)
2022-11-02 23:35:53,781:INFO: Batch:  1/31	Total Loss 0.0349 (0.0400)
2022-11-02 23:35:53,866:INFO: Batch:  2/31	Total Loss 0.0353 (0.0385)
2022-11-02 23:35:53,953:INFO: Batch:  3/31	Total Loss 0.0423 (0.0395)
2022-11-02 23:35:54,030:INFO: Batch:  4/31	Total Loss 0.0389 (0.0393)
2022-11-02 23:35:54,097:INFO: Batch:  5/31	Total Loss 0.0443 (0.0401)
2022-11-02 23:35:54,166:INFO: Batch:  6/31	Total Loss 0.0396 (0.0400)
2022-11-02 23:35:54,230:INFO: Batch:  7/31	Total Loss 0.0415 (0.0402)
2022-11-02 23:35:54,284:INFO: Batch:  8/31	Total Loss 0.0378 (0.0400)
2022-11-02 23:35:54,333:INFO: Batch:  9/31	Total Loss 0.0357 (0.0396)
2022-11-02 23:35:54,395:INFO: Batch: 10/31	Total Loss 0.0334 (0.0390)
2022-11-02 23:35:54,522:INFO: Batch: 11/31	Total Loss 0.0490 (0.0398)
2022-11-02 23:35:54,638:INFO: Batch: 12/31	Total Loss 0.0433 (0.0401)
2022-11-02 23:35:54,730:INFO: Batch: 13/31	Total Loss 0.0355 (0.0398)
2022-11-02 23:35:54,798:INFO: Batch: 14/31	Total Loss 0.0366 (0.0396)
2022-11-02 23:35:54,852:INFO: Batch: 15/31	Total Loss 0.0450 (0.0399)
2022-11-02 23:35:54,906:INFO: Batch: 16/31	Total Loss 0.0401 (0.0399)
2022-11-02 23:35:54,958:INFO: Batch: 17/31	Total Loss 0.0349 (0.0396)
2022-11-02 23:35:55,010:INFO: Batch: 18/31	Total Loss 0.0416 (0.0397)
2022-11-02 23:35:55,076:INFO: Batch: 19/31	Total Loss 0.0781 (0.0417)
2022-11-02 23:35:55,135:INFO: Batch: 20/31	Total Loss 0.0381 (0.0415)
2022-11-02 23:35:55,192:INFO: Batch: 21/31	Total Loss 0.0595 (0.0424)
2022-11-02 23:35:55,248:INFO: Batch: 22/31	Total Loss 0.0543 (0.0429)
2022-11-02 23:35:55,304:INFO: Batch: 23/31	Total Loss 0.0365 (0.0426)
2022-11-02 23:35:55,357:INFO: Batch: 24/31	Total Loss 0.0410 (0.0426)
2022-11-02 23:35:55,409:INFO: Batch: 25/31	Total Loss 0.0359 (0.0423)
2022-11-02 23:35:55,460:INFO: Batch: 26/31	Total Loss 0.0474 (0.0425)
2022-11-02 23:35:55,514:INFO: Batch: 27/31	Total Loss 0.0541 (0.0429)
2022-11-02 23:35:55,569:INFO: Batch: 28/31	Total Loss 0.0376 (0.0427)
2022-11-02 23:35:55,622:INFO: Batch: 29/31	Total Loss 0.0372 (0.0425)
2022-11-02 23:35:55,654:INFO: Batch: 30/31	Total Loss 0.0212 (0.0423)
2022-11-02 23:35:55,808:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_125.pth.tar
2022-11-02 23:35:55,808:INFO: 
===> EPOCH: 126 (P1)
2022-11-02 23:35:55,808:INFO: - Computing loss (training)
2022-11-02 23:35:56,467:INFO: Batch:  0/31	Total Loss 0.0673 (0.0673)
2022-11-02 23:35:56,526:INFO: Batch:  1/31	Total Loss 0.0464 (0.0563)
2022-11-02 23:35:56,591:INFO: Batch:  2/31	Total Loss 0.0323 (0.0476)
2022-11-02 23:35:56,644:INFO: Batch:  3/31	Total Loss 0.0475 (0.0476)
2022-11-02 23:35:56,697:INFO: Batch:  4/31	Total Loss 0.0615 (0.0502)
2022-11-02 23:35:56,761:INFO: Batch:  5/31	Total Loss 0.0430 (0.0490)
2022-11-02 23:35:56,815:INFO: Batch:  6/31	Total Loss 0.0389 (0.0476)
2022-11-02 23:35:56,866:INFO: Batch:  7/31	Total Loss 0.0448 (0.0472)
2022-11-02 23:35:56,915:INFO: Batch:  8/31	Total Loss 0.0411 (0.0465)
2022-11-02 23:35:56,964:INFO: Batch:  9/31	Total Loss 0.0374 (0.0456)
2022-11-02 23:35:57,013:INFO: Batch: 10/31	Total Loss 0.0406 (0.0451)
2022-11-02 23:35:57,063:INFO: Batch: 11/31	Total Loss 0.0351 (0.0443)
2022-11-02 23:35:57,114:INFO: Batch: 12/31	Total Loss 0.0481 (0.0446)
2022-11-02 23:35:57,167:INFO: Batch: 13/31	Total Loss 0.0390 (0.0442)
2022-11-02 23:35:57,218:INFO: Batch: 14/31	Total Loss 0.0347 (0.0436)
2022-11-02 23:35:57,269:INFO: Batch: 15/31	Total Loss 0.0409 (0.0434)
2022-11-02 23:35:57,320:INFO: Batch: 16/31	Total Loss 0.0436 (0.0434)
2022-11-02 23:35:57,371:INFO: Batch: 17/31	Total Loss 0.0431 (0.0434)
2022-11-02 23:35:57,424:INFO: Batch: 18/31	Total Loss 0.0436 (0.0434)
2022-11-02 23:35:57,476:INFO: Batch: 19/31	Total Loss 0.0333 (0.0428)
2022-11-02 23:35:57,527:INFO: Batch: 20/31	Total Loss 0.0377 (0.0426)
2022-11-02 23:35:57,579:INFO: Batch: 21/31	Total Loss 0.0417 (0.0426)
2022-11-02 23:35:57,633:INFO: Batch: 22/31	Total Loss 0.0507 (0.0429)
2022-11-02 23:35:57,683:INFO: Batch: 23/31	Total Loss 0.0297 (0.0424)
2022-11-02 23:35:57,735:INFO: Batch: 24/31	Total Loss 0.0360 (0.0421)
2022-11-02 23:35:57,788:INFO: Batch: 25/31	Total Loss 0.0428 (0.0422)
2022-11-02 23:35:57,843:INFO: Batch: 26/31	Total Loss 0.0459 (0.0423)
2022-11-02 23:35:57,900:INFO: Batch: 27/31	Total Loss 0.0372 (0.0421)
2022-11-02 23:35:57,952:INFO: Batch: 28/31	Total Loss 0.0310 (0.0418)
2022-11-02 23:35:58,002:INFO: Batch: 29/31	Total Loss 0.0458 (0.0419)
2022-11-02 23:35:58,035:INFO: Batch: 30/31	Total Loss 0.0132 (0.0416)
2022-11-02 23:35:58,193:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_126.pth.tar
2022-11-02 23:35:58,194:INFO: 
===> EPOCH: 127 (P1)
2022-11-02 23:35:58,194:INFO: - Computing loss (training)
2022-11-02 23:35:58,885:INFO: Batch:  0/31	Total Loss 0.0370 (0.0370)
2022-11-02 23:35:58,940:INFO: Batch:  1/31	Total Loss 0.0351 (0.0360)
2022-11-02 23:35:58,996:INFO: Batch:  2/31	Total Loss 0.0380 (0.0366)
2022-11-02 23:35:59,044:INFO: Batch:  3/31	Total Loss 0.0350 (0.0362)
2022-11-02 23:35:59,096:INFO: Batch:  4/31	Total Loss 0.0362 (0.0362)
2022-11-02 23:35:59,152:INFO: Batch:  5/31	Total Loss 0.0323 (0.0356)
2022-11-02 23:35:59,200:INFO: Batch:  6/31	Total Loss 0.0349 (0.0355)
2022-11-02 23:35:59,248:INFO: Batch:  7/31	Total Loss 0.0353 (0.0354)
2022-11-02 23:35:59,297:INFO: Batch:  8/31	Total Loss 0.0375 (0.0357)
2022-11-02 23:35:59,347:INFO: Batch:  9/31	Total Loss 0.0291 (0.0351)
2022-11-02 23:35:59,395:INFO: Batch: 10/31	Total Loss 0.0323 (0.0348)
2022-11-02 23:35:59,447:INFO: Batch: 11/31	Total Loss 0.0393 (0.0352)
2022-11-02 23:35:59,498:INFO: Batch: 12/31	Total Loss 0.0345 (0.0351)
2022-11-02 23:35:59,549:INFO: Batch: 13/31	Total Loss 0.0364 (0.0352)
2022-11-02 23:35:59,601:INFO: Batch: 14/31	Total Loss 0.0403 (0.0355)
2022-11-02 23:35:59,653:INFO: Batch: 15/31	Total Loss 0.0325 (0.0353)
2022-11-02 23:35:59,705:INFO: Batch: 16/31	Total Loss 0.0334 (0.0352)
2022-11-02 23:35:59,756:INFO: Batch: 17/31	Total Loss 0.0453 (0.0358)
2022-11-02 23:35:59,809:INFO: Batch: 18/31	Total Loss 0.0381 (0.0359)
2022-11-02 23:35:59,861:INFO: Batch: 19/31	Total Loss 0.0340 (0.0358)
2022-11-02 23:35:59,910:INFO: Batch: 20/31	Total Loss 0.0352 (0.0358)
2022-11-02 23:35:59,960:INFO: Batch: 21/31	Total Loss 0.0370 (0.0359)
2022-11-02 23:36:00,017:INFO: Batch: 22/31	Total Loss 0.0383 (0.0360)
2022-11-02 23:36:00,068:INFO: Batch: 23/31	Total Loss 0.0332 (0.0358)
2022-11-02 23:36:00,117:INFO: Batch: 24/31	Total Loss 0.0302 (0.0356)
2022-11-02 23:36:00,167:INFO: Batch: 25/31	Total Loss 0.0355 (0.0356)
2022-11-02 23:36:00,220:INFO: Batch: 26/31	Total Loss 0.0364 (0.0356)
2022-11-02 23:36:00,270:INFO: Batch: 27/31	Total Loss 0.0323 (0.0355)
2022-11-02 23:36:00,321:INFO: Batch: 28/31	Total Loss 0.0350 (0.0355)
2022-11-02 23:36:00,372:INFO: Batch: 29/31	Total Loss 0.0352 (0.0355)
2022-11-02 23:36:00,404:INFO: Batch: 30/31	Total Loss 0.0120 (0.0352)
2022-11-02 23:36:00,559:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_127.pth.tar
2022-11-02 23:36:00,559:INFO: 
===> EPOCH: 128 (P1)
2022-11-02 23:36:00,559:INFO: - Computing loss (training)
2022-11-02 23:36:01,267:INFO: Batch:  0/31	Total Loss 0.0352 (0.0352)
2022-11-02 23:36:01,319:INFO: Batch:  1/31	Total Loss 0.0353 (0.0352)
2022-11-02 23:36:01,371:INFO: Batch:  2/31	Total Loss 0.0356 (0.0353)
2022-11-02 23:36:01,420:INFO: Batch:  3/31	Total Loss 0.0370 (0.0357)
2022-11-02 23:36:01,470:INFO: Batch:  4/31	Total Loss 0.0317 (0.0349)
2022-11-02 23:36:01,525:INFO: Batch:  5/31	Total Loss 0.0317 (0.0343)
2022-11-02 23:36:01,578:INFO: Batch:  6/31	Total Loss 0.0383 (0.0349)
2022-11-02 23:36:01,626:INFO: Batch:  7/31	Total Loss 0.0348 (0.0349)
2022-11-02 23:36:01,674:INFO: Batch:  8/31	Total Loss 0.0321 (0.0346)
2022-11-02 23:36:01,726:INFO: Batch:  9/31	Total Loss 0.0323 (0.0344)
2022-11-02 23:36:01,778:INFO: Batch: 10/31	Total Loss 0.0338 (0.0343)
2022-11-02 23:36:01,824:INFO: Batch: 11/31	Total Loss 0.0485 (0.0354)
2022-11-02 23:36:01,874:INFO: Batch: 12/31	Total Loss 0.0279 (0.0348)
2022-11-02 23:36:01,926:INFO: Batch: 13/31	Total Loss 0.0327 (0.0347)
2022-11-02 23:36:01,976:INFO: Batch: 14/31	Total Loss 0.0410 (0.0351)
2022-11-02 23:36:02,026:INFO: Batch: 15/31	Total Loss 0.0387 (0.0353)
2022-11-02 23:36:02,075:INFO: Batch: 16/31	Total Loss 0.0341 (0.0353)
2022-11-02 23:36:02,127:INFO: Batch: 17/31	Total Loss 0.0332 (0.0351)
2022-11-02 23:36:02,178:INFO: Batch: 18/31	Total Loss 0.0374 (0.0353)
2022-11-02 23:36:02,229:INFO: Batch: 19/31	Total Loss 0.0341 (0.0352)
2022-11-02 23:36:02,279:INFO: Batch: 20/31	Total Loss 0.0402 (0.0354)
2022-11-02 23:36:02,329:INFO: Batch: 21/31	Total Loss 0.0350 (0.0354)
2022-11-02 23:36:02,381:INFO: Batch: 22/31	Total Loss 0.0381 (0.0355)
2022-11-02 23:36:02,432:INFO: Batch: 23/31	Total Loss 0.0340 (0.0355)
2022-11-02 23:36:02,483:INFO: Batch: 24/31	Total Loss 0.0334 (0.0354)
2022-11-02 23:36:02,533:INFO: Batch: 25/31	Total Loss 0.0361 (0.0354)
2022-11-02 23:36:02,586:INFO: Batch: 26/31	Total Loss 0.0335 (0.0354)
2022-11-02 23:36:02,635:INFO: Batch: 27/31	Total Loss 0.0393 (0.0355)
2022-11-02 23:36:02,684:INFO: Batch: 28/31	Total Loss 0.0406 (0.0357)
2022-11-02 23:36:02,732:INFO: Batch: 29/31	Total Loss 0.0323 (0.0356)
2022-11-02 23:36:02,764:INFO: Batch: 30/31	Total Loss 0.0154 (0.0354)
2022-11-02 23:36:02,908:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_128.pth.tar
2022-11-02 23:36:02,908:INFO: 
===> EPOCH: 129 (P1)
2022-11-02 23:36:02,908:INFO: - Computing loss (training)
2022-11-02 23:36:03,599:INFO: Batch:  0/31	Total Loss 0.0520 (0.0520)
2022-11-02 23:36:03,650:INFO: Batch:  1/31	Total Loss 0.0372 (0.0453)
2022-11-02 23:36:03,703:INFO: Batch:  2/31	Total Loss 0.0326 (0.0416)
2022-11-02 23:36:03,753:INFO: Batch:  3/31	Total Loss 0.0357 (0.0400)
2022-11-02 23:36:03,802:INFO: Batch:  4/31	Total Loss 0.0417 (0.0403)
2022-11-02 23:36:03,855:INFO: Batch:  5/31	Total Loss 0.0392 (0.0402)
2022-11-02 23:36:03,902:INFO: Batch:  6/31	Total Loss 0.0312 (0.0389)
2022-11-02 23:36:03,949:INFO: Batch:  7/31	Total Loss 0.0324 (0.0382)
2022-11-02 23:36:03,997:INFO: Batch:  8/31	Total Loss 0.0359 (0.0380)
2022-11-02 23:36:04,046:INFO: Batch:  9/31	Total Loss 0.0382 (0.0380)
2022-11-02 23:36:04,094:INFO: Batch: 10/31	Total Loss 0.0385 (0.0380)
2022-11-02 23:36:04,142:INFO: Batch: 11/31	Total Loss 0.0400 (0.0382)
2022-11-02 23:36:04,192:INFO: Batch: 12/31	Total Loss 0.0456 (0.0387)
2022-11-02 23:36:04,243:INFO: Batch: 13/31	Total Loss 0.0300 (0.0381)
2022-11-02 23:36:04,295:INFO: Batch: 14/31	Total Loss 0.0343 (0.0378)
2022-11-02 23:36:04,345:INFO: Batch: 15/31	Total Loss 0.0402 (0.0380)
2022-11-02 23:36:04,394:INFO: Batch: 16/31	Total Loss 0.0345 (0.0378)
2022-11-02 23:36:04,444:INFO: Batch: 17/31	Total Loss 0.0404 (0.0379)
2022-11-02 23:36:04,494:INFO: Batch: 18/31	Total Loss 0.0303 (0.0376)
2022-11-02 23:36:04,546:INFO: Batch: 19/31	Total Loss 0.0391 (0.0376)
2022-11-02 23:36:04,598:INFO: Batch: 20/31	Total Loss 0.0377 (0.0376)
2022-11-02 23:36:04,647:INFO: Batch: 21/31	Total Loss 0.0295 (0.0373)
2022-11-02 23:36:04,697:INFO: Batch: 22/31	Total Loss 0.0384 (0.0374)
2022-11-02 23:36:04,746:INFO: Batch: 23/31	Total Loss 0.0358 (0.0373)
2022-11-02 23:36:04,796:INFO: Batch: 24/31	Total Loss 0.0363 (0.0372)
2022-11-02 23:36:04,846:INFO: Batch: 25/31	Total Loss 0.0406 (0.0374)
2022-11-02 23:36:04,895:INFO: Batch: 26/31	Total Loss 0.0347 (0.0373)
2022-11-02 23:36:04,945:INFO: Batch: 27/31	Total Loss 0.0304 (0.0371)
2022-11-02 23:36:04,997:INFO: Batch: 28/31	Total Loss 0.0319 (0.0369)
2022-11-02 23:36:05,046:INFO: Batch: 29/31	Total Loss 0.0343 (0.0368)
2022-11-02 23:36:05,077:INFO: Batch: 30/31	Total Loss 0.0144 (0.0365)
2022-11-02 23:36:05,229:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_129.pth.tar
2022-11-02 23:36:05,229:INFO: 
===> EPOCH: 130 (P1)
2022-11-02 23:36:05,229:INFO: - Computing loss (training)
2022-11-02 23:36:05,937:INFO: Batch:  0/31	Total Loss 0.0355 (0.0355)
2022-11-02 23:36:05,988:INFO: Batch:  1/31	Total Loss 0.0312 (0.0335)
2022-11-02 23:36:06,044:INFO: Batch:  2/31	Total Loss 0.0318 (0.0329)
2022-11-02 23:36:06,095:INFO: Batch:  3/31	Total Loss 0.0325 (0.0328)
2022-11-02 23:36:06,149:INFO: Batch:  4/31	Total Loss 0.0337 (0.0330)
2022-11-02 23:36:06,202:INFO: Batch:  5/31	Total Loss 0.0313 (0.0327)
2022-11-02 23:36:06,251:INFO: Batch:  6/31	Total Loss 0.0414 (0.0339)
2022-11-02 23:36:06,298:INFO: Batch:  7/31	Total Loss 0.0330 (0.0338)
2022-11-02 23:36:06,346:INFO: Batch:  8/31	Total Loss 0.0371 (0.0341)
2022-11-02 23:36:06,397:INFO: Batch:  9/31	Total Loss 0.0380 (0.0345)
2022-11-02 23:36:06,448:INFO: Batch: 10/31	Total Loss 0.0364 (0.0347)
2022-11-02 23:36:06,497:INFO: Batch: 11/31	Total Loss 0.0314 (0.0344)
2022-11-02 23:36:06,548:INFO: Batch: 12/31	Total Loss 0.0350 (0.0345)
2022-11-02 23:36:06,599:INFO: Batch: 13/31	Total Loss 0.0326 (0.0344)
2022-11-02 23:36:06,652:INFO: Batch: 14/31	Total Loss 0.0367 (0.0345)
2022-11-02 23:36:06,705:INFO: Batch: 15/31	Total Loss 0.0343 (0.0345)
2022-11-02 23:36:06,756:INFO: Batch: 16/31	Total Loss 0.0338 (0.0345)
2022-11-02 23:36:06,808:INFO: Batch: 17/31	Total Loss 0.0289 (0.0342)
2022-11-02 23:36:06,861:INFO: Batch: 18/31	Total Loss 0.0363 (0.0343)
2022-11-02 23:36:06,912:INFO: Batch: 19/31	Total Loss 0.0352 (0.0343)
2022-11-02 23:36:06,963:INFO: Batch: 20/31	Total Loss 0.0326 (0.0342)
2022-11-02 23:36:07,015:INFO: Batch: 21/31	Total Loss 0.0331 (0.0342)
2022-11-02 23:36:07,066:INFO: Batch: 22/31	Total Loss 0.0456 (0.0346)
2022-11-02 23:36:07,115:INFO: Batch: 23/31	Total Loss 0.0301 (0.0345)
2022-11-02 23:36:07,163:INFO: Batch: 24/31	Total Loss 0.0330 (0.0344)
2022-11-02 23:36:07,213:INFO: Batch: 25/31	Total Loss 0.0337 (0.0344)
2022-11-02 23:36:07,265:INFO: Batch: 26/31	Total Loss 0.0355 (0.0344)
2022-11-02 23:36:07,315:INFO: Batch: 27/31	Total Loss 0.0361 (0.0345)
2022-11-02 23:36:07,364:INFO: Batch: 28/31	Total Loss 0.0438 (0.0348)
2022-11-02 23:36:07,413:INFO: Batch: 29/31	Total Loss 0.0318 (0.0347)
2022-11-02 23:36:07,444:INFO: Batch: 30/31	Total Loss 0.0131 (0.0345)
2022-11-02 23:36:07,599:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_130.pth.tar
2022-11-02 23:36:07,599:INFO: 
===> EPOCH: 131 (P1)
2022-11-02 23:36:07,600:INFO: - Computing loss (training)
2022-11-02 23:36:08,254:INFO: Batch:  0/31	Total Loss 0.0306 (0.0306)
2022-11-02 23:36:08,306:INFO: Batch:  1/31	Total Loss 0.0310 (0.0308)
2022-11-02 23:36:08,359:INFO: Batch:  2/31	Total Loss 0.0312 (0.0309)
2022-11-02 23:36:08,408:INFO: Batch:  3/31	Total Loss 0.0407 (0.0332)
2022-11-02 23:36:08,459:INFO: Batch:  4/31	Total Loss 0.0327 (0.0331)
2022-11-02 23:36:08,515:INFO: Batch:  5/31	Total Loss 0.0315 (0.0328)
2022-11-02 23:36:08,563:INFO: Batch:  6/31	Total Loss 0.0345 (0.0331)
2022-11-02 23:36:08,611:INFO: Batch:  7/31	Total Loss 0.0336 (0.0331)
2022-11-02 23:36:08,659:INFO: Batch:  8/31	Total Loss 0.0338 (0.0332)
2022-11-02 23:36:08,708:INFO: Batch:  9/31	Total Loss 0.0458 (0.0345)
2022-11-02 23:36:08,755:INFO: Batch: 10/31	Total Loss 0.0317 (0.0343)
2022-11-02 23:36:08,804:INFO: Batch: 11/31	Total Loss 0.0355 (0.0344)
2022-11-02 23:36:08,854:INFO: Batch: 12/31	Total Loss 0.0404 (0.0348)
2022-11-02 23:36:08,905:INFO: Batch: 13/31	Total Loss 0.0299 (0.0344)
2022-11-02 23:36:08,957:INFO: Batch: 14/31	Total Loss 0.0374 (0.0346)
2022-11-02 23:36:09,008:INFO: Batch: 15/31	Total Loss 0.0398 (0.0349)
2022-11-02 23:36:09,058:INFO: Batch: 16/31	Total Loss 0.0311 (0.0347)
2022-11-02 23:36:09,109:INFO: Batch: 17/31	Total Loss 0.0291 (0.0344)
2022-11-02 23:36:09,159:INFO: Batch: 18/31	Total Loss 0.0339 (0.0344)
2022-11-02 23:36:09,211:INFO: Batch: 19/31	Total Loss 0.0310 (0.0342)
2022-11-02 23:36:09,262:INFO: Batch: 20/31	Total Loss 0.0317 (0.0341)
2022-11-02 23:36:09,312:INFO: Batch: 21/31	Total Loss 0.0304 (0.0339)
2022-11-02 23:36:09,361:INFO: Batch: 22/31	Total Loss 0.0321 (0.0338)
2022-11-02 23:36:09,414:INFO: Batch: 23/31	Total Loss 0.0319 (0.0337)
2022-11-02 23:36:09,464:INFO: Batch: 24/31	Total Loss 0.0308 (0.0336)
2022-11-02 23:36:09,514:INFO: Batch: 25/31	Total Loss 0.0322 (0.0336)
2022-11-02 23:36:09,564:INFO: Batch: 26/31	Total Loss 0.0330 (0.0336)
2022-11-02 23:36:09,617:INFO: Batch: 27/31	Total Loss 0.0318 (0.0335)
2022-11-02 23:36:09,667:INFO: Batch: 28/31	Total Loss 0.0323 (0.0334)
2022-11-02 23:36:09,716:INFO: Batch: 29/31	Total Loss 0.0388 (0.0336)
2022-11-02 23:36:09,749:INFO: Batch: 30/31	Total Loss 0.0128 (0.0334)
2022-11-02 23:36:09,914:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_131.pth.tar
2022-11-02 23:36:09,914:INFO: 
===> EPOCH: 132 (P1)
2022-11-02 23:36:09,914:INFO: - Computing loss (training)
2022-11-02 23:36:10,576:INFO: Batch:  0/31	Total Loss 0.0355 (0.0355)
2022-11-02 23:36:10,627:INFO: Batch:  1/31	Total Loss 0.0304 (0.0329)
2022-11-02 23:36:10,684:INFO: Batch:  2/31	Total Loss 0.0294 (0.0317)
2022-11-02 23:36:10,735:INFO: Batch:  3/31	Total Loss 0.0333 (0.0321)
2022-11-02 23:36:10,784:INFO: Batch:  4/31	Total Loss 0.0410 (0.0336)
2022-11-02 23:36:10,836:INFO: Batch:  5/31	Total Loss 0.0471 (0.0357)
2022-11-02 23:36:10,885:INFO: Batch:  6/31	Total Loss 0.0356 (0.0357)
2022-11-02 23:36:10,933:INFO: Batch:  7/31	Total Loss 0.0527 (0.0378)
2022-11-02 23:36:10,979:INFO: Batch:  8/31	Total Loss 0.0449 (0.0386)
2022-11-02 23:36:11,028:INFO: Batch:  9/31	Total Loss 0.0314 (0.0378)
2022-11-02 23:36:11,078:INFO: Batch: 10/31	Total Loss 0.0361 (0.0377)
2022-11-02 23:36:11,125:INFO: Batch: 11/31	Total Loss 0.0368 (0.0376)
2022-11-02 23:36:11,175:INFO: Batch: 12/31	Total Loss 0.0363 (0.0375)
2022-11-02 23:36:11,225:INFO: Batch: 13/31	Total Loss 0.0371 (0.0375)
2022-11-02 23:36:11,278:INFO: Batch: 14/31	Total Loss 0.0298 (0.0369)
2022-11-02 23:36:11,328:INFO: Batch: 15/31	Total Loss 0.0359 (0.0368)
2022-11-02 23:36:11,378:INFO: Batch: 16/31	Total Loss 0.0467 (0.0374)
2022-11-02 23:36:11,428:INFO: Batch: 17/31	Total Loss 0.0332 (0.0372)
2022-11-02 23:36:11,478:INFO: Batch: 18/31	Total Loss 0.0358 (0.0371)
2022-11-02 23:36:11,529:INFO: Batch: 19/31	Total Loss 0.0314 (0.0368)
2022-11-02 23:36:11,579:INFO: Batch: 20/31	Total Loss 0.0348 (0.0368)
2022-11-02 23:36:11,628:INFO: Batch: 21/31	Total Loss 0.0347 (0.0367)
2022-11-02 23:36:11,678:INFO: Batch: 22/31	Total Loss 0.0303 (0.0364)
2022-11-02 23:36:11,729:INFO: Batch: 23/31	Total Loss 0.0344 (0.0363)
2022-11-02 23:36:11,779:INFO: Batch: 24/31	Total Loss 0.0326 (0.0361)
2022-11-02 23:36:11,828:INFO: Batch: 25/31	Total Loss 0.0337 (0.0360)
2022-11-02 23:36:11,878:INFO: Batch: 26/31	Total Loss 0.0326 (0.0359)
2022-11-02 23:36:11,927:INFO: Batch: 27/31	Total Loss 0.0300 (0.0357)
2022-11-02 23:36:11,978:INFO: Batch: 28/31	Total Loss 0.0321 (0.0356)
2022-11-02 23:36:12,029:INFO: Batch: 29/31	Total Loss 0.0320 (0.0354)
2022-11-02 23:36:12,060:INFO: Batch: 30/31	Total Loss 0.0107 (0.0351)
2022-11-02 23:36:12,214:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_132.pth.tar
2022-11-02 23:36:12,214:INFO: 
===> EPOCH: 133 (P1)
2022-11-02 23:36:12,215:INFO: - Computing loss (training)
2022-11-02 23:36:12,892:INFO: Batch:  0/31	Total Loss 0.0297 (0.0297)
2022-11-02 23:36:12,945:INFO: Batch:  1/31	Total Loss 0.0307 (0.0302)
2022-11-02 23:36:12,997:INFO: Batch:  2/31	Total Loss 0.0318 (0.0307)
2022-11-02 23:36:13,048:INFO: Batch:  3/31	Total Loss 0.0343 (0.0315)
2022-11-02 23:36:13,099:INFO: Batch:  4/31	Total Loss 0.0285 (0.0309)
2022-11-02 23:36:13,152:INFO: Batch:  5/31	Total Loss 0.0293 (0.0307)
2022-11-02 23:36:13,201:INFO: Batch:  6/31	Total Loss 0.0348 (0.0313)
2022-11-02 23:36:13,247:INFO: Batch:  7/31	Total Loss 0.0301 (0.0311)
2022-11-02 23:36:13,295:INFO: Batch:  8/31	Total Loss 0.0312 (0.0312)
2022-11-02 23:36:13,345:INFO: Batch:  9/31	Total Loss 0.0287 (0.0309)
2022-11-02 23:36:13,396:INFO: Batch: 10/31	Total Loss 0.0332 (0.0311)
2022-11-02 23:36:13,444:INFO: Batch: 11/31	Total Loss 0.0311 (0.0311)
2022-11-02 23:36:13,496:INFO: Batch: 12/31	Total Loss 0.0280 (0.0309)
2022-11-02 23:36:13,546:INFO: Batch: 13/31	Total Loss 0.0350 (0.0311)
2022-11-02 23:36:13,599:INFO: Batch: 14/31	Total Loss 0.0379 (0.0316)
2022-11-02 23:36:13,650:INFO: Batch: 15/31	Total Loss 0.0318 (0.0316)
2022-11-02 23:36:13,699:INFO: Batch: 16/31	Total Loss 0.0277 (0.0314)
2022-11-02 23:36:13,749:INFO: Batch: 17/31	Total Loss 0.0286 (0.0312)
2022-11-02 23:36:13,799:INFO: Batch: 18/31	Total Loss 0.0338 (0.0313)
2022-11-02 23:36:13,851:INFO: Batch: 19/31	Total Loss 0.0303 (0.0313)
2022-11-02 23:36:13,901:INFO: Batch: 20/31	Total Loss 0.0399 (0.0317)
2022-11-02 23:36:13,951:INFO: Batch: 21/31	Total Loss 0.0298 (0.0316)
2022-11-02 23:36:14,000:INFO: Batch: 22/31	Total Loss 0.0374 (0.0319)
2022-11-02 23:36:14,049:INFO: Batch: 23/31	Total Loss 0.0370 (0.0321)
2022-11-02 23:36:14,103:INFO: Batch: 24/31	Total Loss 0.0315 (0.0321)
2022-11-02 23:36:14,154:INFO: Batch: 25/31	Total Loss 0.0306 (0.0320)
2022-11-02 23:36:14,203:INFO: Batch: 26/31	Total Loss 0.0354 (0.0321)
2022-11-02 23:36:14,252:INFO: Batch: 27/31	Total Loss 0.0382 (0.0323)
2022-11-02 23:36:14,301:INFO: Batch: 28/31	Total Loss 0.0348 (0.0324)
2022-11-02 23:36:14,354:INFO: Batch: 29/31	Total Loss 0.0326 (0.0324)
2022-11-02 23:36:14,385:INFO: Batch: 30/31	Total Loss 0.0112 (0.0323)
2022-11-02 23:36:14,530:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_133.pth.tar
2022-11-02 23:36:14,530:INFO: 
===> EPOCH: 134 (P1)
2022-11-02 23:36:14,530:INFO: - Computing loss (training)
2022-11-02 23:36:15,216:INFO: Batch:  0/31	Total Loss 0.0359 (0.0359)
2022-11-02 23:36:15,268:INFO: Batch:  1/31	Total Loss 0.0316 (0.0336)
2022-11-02 23:36:15,325:INFO: Batch:  2/31	Total Loss 0.0297 (0.0322)
2022-11-02 23:36:15,375:INFO: Batch:  3/31	Total Loss 0.0387 (0.0335)
2022-11-02 23:36:15,422:INFO: Batch:  4/31	Total Loss 0.0294 (0.0327)
2022-11-02 23:36:15,474:INFO: Batch:  5/31	Total Loss 0.0357 (0.0332)
2022-11-02 23:36:15,522:INFO: Batch:  6/31	Total Loss 0.0347 (0.0334)
2022-11-02 23:36:15,568:INFO: Batch:  7/31	Total Loss 0.0328 (0.0333)
2022-11-02 23:36:15,617:INFO: Batch:  8/31	Total Loss 0.0338 (0.0334)
2022-11-02 23:36:15,667:INFO: Batch:  9/31	Total Loss 0.0269 (0.0328)
2022-11-02 23:36:15,716:INFO: Batch: 10/31	Total Loss 0.0389 (0.0333)
2022-11-02 23:36:15,763:INFO: Batch: 11/31	Total Loss 0.0310 (0.0331)
2022-11-02 23:36:15,811:INFO: Batch: 12/31	Total Loss 0.0319 (0.0330)
2022-11-02 23:36:15,860:INFO: Batch: 13/31	Total Loss 0.0314 (0.0329)
2022-11-02 23:36:15,913:INFO: Batch: 14/31	Total Loss 0.0306 (0.0327)
2022-11-02 23:36:15,963:INFO: Batch: 15/31	Total Loss 0.0301 (0.0325)
2022-11-02 23:36:16,014:INFO: Batch: 16/31	Total Loss 0.0337 (0.0326)
2022-11-02 23:36:16,064:INFO: Batch: 17/31	Total Loss 0.0305 (0.0325)
2022-11-02 23:36:16,112:INFO: Batch: 18/31	Total Loss 0.0316 (0.0324)
2022-11-02 23:36:16,163:INFO: Batch: 19/31	Total Loss 0.0278 (0.0322)
2022-11-02 23:36:16,213:INFO: Batch: 20/31	Total Loss 0.0303 (0.0321)
2022-11-02 23:36:16,262:INFO: Batch: 21/31	Total Loss 0.0272 (0.0319)
2022-11-02 23:36:16,311:INFO: Batch: 22/31	Total Loss 0.0285 (0.0317)
2022-11-02 23:36:16,360:INFO: Batch: 23/31	Total Loss 0.0350 (0.0319)
2022-11-02 23:36:16,412:INFO: Batch: 24/31	Total Loss 0.0291 (0.0318)
2022-11-02 23:36:16,461:INFO: Batch: 25/31	Total Loss 0.0288 (0.0316)
2022-11-02 23:36:16,510:INFO: Batch: 26/31	Total Loss 0.0284 (0.0315)
2022-11-02 23:36:16,559:INFO: Batch: 27/31	Total Loss 0.0265 (0.0313)
2022-11-02 23:36:16,607:INFO: Batch: 28/31	Total Loss 0.0302 (0.0313)
2022-11-02 23:36:16,659:INFO: Batch: 29/31	Total Loss 0.0297 (0.0312)
2022-11-02 23:36:16,689:INFO: Batch: 30/31	Total Loss 0.0104 (0.0310)
2022-11-02 23:36:16,842:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_134.pth.tar
2022-11-02 23:36:16,842:INFO: 
===> EPOCH: 135 (P1)
2022-11-02 23:36:16,842:INFO: - Computing loss (training)
2022-11-02 23:36:17,523:INFO: Batch:  0/31	Total Loss 0.0349 (0.0349)
2022-11-02 23:36:17,574:INFO: Batch:  1/31	Total Loss 0.0288 (0.0320)
2022-11-02 23:36:17,632:INFO: Batch:  2/31	Total Loss 0.0328 (0.0322)
2022-11-02 23:36:17,680:INFO: Batch:  3/31	Total Loss 0.0316 (0.0321)
2022-11-02 23:36:17,727:INFO: Batch:  4/31	Total Loss 0.0336 (0.0324)
2022-11-02 23:36:17,781:INFO: Batch:  5/31	Total Loss 0.0322 (0.0323)
2022-11-02 23:36:17,831:INFO: Batch:  6/31	Total Loss 0.0296 (0.0319)
2022-11-02 23:36:17,878:INFO: Batch:  7/31	Total Loss 0.0289 (0.0315)
2022-11-02 23:36:17,928:INFO: Batch:  8/31	Total Loss 0.0299 (0.0314)
2022-11-02 23:36:17,979:INFO: Batch:  9/31	Total Loss 0.0256 (0.0307)
2022-11-02 23:36:18,028:INFO: Batch: 10/31	Total Loss 0.0285 (0.0305)
2022-11-02 23:36:18,075:INFO: Batch: 11/31	Total Loss 0.0303 (0.0305)
2022-11-02 23:36:18,125:INFO: Batch: 12/31	Total Loss 0.0272 (0.0303)
2022-11-02 23:36:18,175:INFO: Batch: 13/31	Total Loss 0.0306 (0.0303)
2022-11-02 23:36:18,229:INFO: Batch: 14/31	Total Loss 0.0309 (0.0303)
2022-11-02 23:36:18,280:INFO: Batch: 15/31	Total Loss 0.0317 (0.0304)
2022-11-02 23:36:18,332:INFO: Batch: 16/31	Total Loss 0.0322 (0.0305)
2022-11-02 23:36:18,383:INFO: Batch: 17/31	Total Loss 0.0296 (0.0305)
2022-11-02 23:36:18,434:INFO: Batch: 18/31	Total Loss 0.0277 (0.0303)
2022-11-02 23:36:18,486:INFO: Batch: 19/31	Total Loss 0.0371 (0.0307)
2022-11-02 23:36:18,536:INFO: Batch: 20/31	Total Loss 0.0354 (0.0309)
2022-11-02 23:36:18,588:INFO: Batch: 21/31	Total Loss 0.0310 (0.0309)
2022-11-02 23:36:18,637:INFO: Batch: 22/31	Total Loss 0.0377 (0.0312)
2022-11-02 23:36:18,689:INFO: Batch: 23/31	Total Loss 0.0284 (0.0311)
2022-11-02 23:36:18,739:INFO: Batch: 24/31	Total Loss 0.0318 (0.0311)
2022-11-02 23:36:18,789:INFO: Batch: 25/31	Total Loss 0.0313 (0.0311)
2022-11-02 23:36:18,838:INFO: Batch: 26/31	Total Loss 0.0294 (0.0310)
2022-11-02 23:36:18,891:INFO: Batch: 27/31	Total Loss 0.0316 (0.0311)
2022-11-02 23:36:18,941:INFO: Batch: 28/31	Total Loss 0.0265 (0.0309)
2022-11-02 23:36:18,991:INFO: Batch: 29/31	Total Loss 0.0275 (0.0308)
2022-11-02 23:36:19,021:INFO: Batch: 30/31	Total Loss 0.0131 (0.0306)
2022-11-02 23:36:19,177:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_135.pth.tar
2022-11-02 23:36:19,177:INFO: 
===> EPOCH: 136 (P1)
2022-11-02 23:36:19,177:INFO: - Computing loss (training)
2022-11-02 23:36:19,872:INFO: Batch:  0/31	Total Loss 0.0309 (0.0309)
2022-11-02 23:36:19,922:INFO: Batch:  1/31	Total Loss 0.0409 (0.0359)
2022-11-02 23:36:19,974:INFO: Batch:  2/31	Total Loss 0.0337 (0.0352)
2022-11-02 23:36:20,026:INFO: Batch:  3/31	Total Loss 0.0277 (0.0334)
2022-11-02 23:36:20,075:INFO: Batch:  4/31	Total Loss 0.0294 (0.0326)
2022-11-02 23:36:20,129:INFO: Batch:  5/31	Total Loss 0.0265 (0.0316)
2022-11-02 23:36:20,177:INFO: Batch:  6/31	Total Loss 0.0275 (0.0310)
2022-11-02 23:36:20,225:INFO: Batch:  7/31	Total Loss 0.0348 (0.0315)
2022-11-02 23:36:20,272:INFO: Batch:  8/31	Total Loss 0.0296 (0.0313)
2022-11-02 23:36:20,323:INFO: Batch:  9/31	Total Loss 0.0264 (0.0308)
2022-11-02 23:36:20,371:INFO: Batch: 10/31	Total Loss 0.0279 (0.0306)
2022-11-02 23:36:20,420:INFO: Batch: 11/31	Total Loss 0.0324 (0.0307)
2022-11-02 23:36:20,469:INFO: Batch: 12/31	Total Loss 0.0311 (0.0308)
2022-11-02 23:36:20,518:INFO: Batch: 13/31	Total Loss 0.0307 (0.0308)
2022-11-02 23:36:20,571:INFO: Batch: 14/31	Total Loss 0.0284 (0.0306)
2022-11-02 23:36:20,622:INFO: Batch: 15/31	Total Loss 0.0309 (0.0306)
2022-11-02 23:36:20,672:INFO: Batch: 16/31	Total Loss 0.0267 (0.0303)
2022-11-02 23:36:20,721:INFO: Batch: 17/31	Total Loss 0.0283 (0.0302)
2022-11-02 23:36:20,771:INFO: Batch: 18/31	Total Loss 0.0289 (0.0301)
2022-11-02 23:36:20,822:INFO: Batch: 19/31	Total Loss 0.0281 (0.0300)
2022-11-02 23:36:20,876:INFO: Batch: 20/31	Total Loss 0.0276 (0.0299)
2022-11-02 23:36:20,925:INFO: Batch: 21/31	Total Loss 0.0271 (0.0298)
2022-11-02 23:36:20,974:INFO: Batch: 22/31	Total Loss 0.0264 (0.0297)
2022-11-02 23:36:21,026:INFO: Batch: 23/31	Total Loss 0.0292 (0.0296)
2022-11-02 23:36:21,076:INFO: Batch: 24/31	Total Loss 0.0279 (0.0296)
2022-11-02 23:36:21,125:INFO: Batch: 25/31	Total Loss 0.0282 (0.0295)
2022-11-02 23:36:21,174:INFO: Batch: 26/31	Total Loss 0.0347 (0.0297)
2022-11-02 23:36:21,225:INFO: Batch: 27/31	Total Loss 0.0280 (0.0296)
2022-11-02 23:36:21,275:INFO: Batch: 28/31	Total Loss 0.0321 (0.0297)
2022-11-02 23:36:21,324:INFO: Batch: 29/31	Total Loss 0.0252 (0.0296)
2022-11-02 23:36:21,353:INFO: Batch: 30/31	Total Loss 0.0109 (0.0294)
2022-11-02 23:36:21,513:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_136.pth.tar
2022-11-02 23:36:21,513:INFO: 
===> EPOCH: 137 (P1)
2022-11-02 23:36:21,514:INFO: - Computing loss (training)
2022-11-02 23:36:22,198:INFO: Batch:  0/31	Total Loss 0.0261 (0.0261)
2022-11-02 23:36:22,247:INFO: Batch:  1/31	Total Loss 0.0276 (0.0269)
2022-11-02 23:36:22,374:INFO: Batch:  2/31	Total Loss 0.0288 (0.0276)
2022-11-02 23:36:22,431:INFO: Batch:  3/31	Total Loss 0.0279 (0.0277)
2022-11-02 23:36:22,480:INFO: Batch:  4/31	Total Loss 0.0262 (0.0274)
2022-11-02 23:36:22,530:INFO: Batch:  5/31	Total Loss 0.0273 (0.0274)
2022-11-02 23:36:22,578:INFO: Batch:  6/31	Total Loss 0.0261 (0.0272)
2022-11-02 23:36:22,624:INFO: Batch:  7/31	Total Loss 0.0284 (0.0273)
2022-11-02 23:36:22,672:INFO: Batch:  8/31	Total Loss 0.0310 (0.0277)
2022-11-02 23:36:22,723:INFO: Batch:  9/31	Total Loss 0.0284 (0.0278)
2022-11-02 23:36:22,770:INFO: Batch: 10/31	Total Loss 0.0299 (0.0280)
2022-11-02 23:36:22,817:INFO: Batch: 11/31	Total Loss 0.0306 (0.0282)
2022-11-02 23:36:22,866:INFO: Batch: 12/31	Total Loss 0.0305 (0.0284)
2022-11-02 23:36:22,918:INFO: Batch: 13/31	Total Loss 0.0281 (0.0284)
2022-11-02 23:36:22,968:INFO: Batch: 14/31	Total Loss 0.0304 (0.0285)
2022-11-02 23:36:23,018:INFO: Batch: 15/31	Total Loss 0.0325 (0.0288)
2022-11-02 23:36:23,068:INFO: Batch: 16/31	Total Loss 0.0333 (0.0290)
2022-11-02 23:36:23,117:INFO: Batch: 17/31	Total Loss 0.0306 (0.0291)
2022-11-02 23:36:23,169:INFO: Batch: 18/31	Total Loss 0.0333 (0.0293)
2022-11-02 23:36:23,220:INFO: Batch: 19/31	Total Loss 0.0275 (0.0293)
2022-11-02 23:36:23,269:INFO: Batch: 20/31	Total Loss 0.0261 (0.0291)
2022-11-02 23:36:23,318:INFO: Batch: 21/31	Total Loss 0.0276 (0.0290)
2022-11-02 23:36:23,367:INFO: Batch: 22/31	Total Loss 0.0390 (0.0295)
2022-11-02 23:36:23,417:INFO: Batch: 23/31	Total Loss 0.0291 (0.0295)
2022-11-02 23:36:23,467:INFO: Batch: 24/31	Total Loss 0.0295 (0.0295)
2022-11-02 23:36:23,516:INFO: Batch: 25/31	Total Loss 0.0288 (0.0294)
2022-11-02 23:36:23,565:INFO: Batch: 26/31	Total Loss 0.0316 (0.0295)
2022-11-02 23:36:23,614:INFO: Batch: 27/31	Total Loss 0.0303 (0.0295)
2022-11-02 23:36:23,665:INFO: Batch: 28/31	Total Loss 0.0249 (0.0294)
2022-11-02 23:36:23,715:INFO: Batch: 29/31	Total Loss 0.0293 (0.0294)
2022-11-02 23:36:23,745:INFO: Batch: 30/31	Total Loss 0.0104 (0.0292)
2022-11-02 23:36:23,901:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_137.pth.tar
2022-11-02 23:36:23,901:INFO: 
===> EPOCH: 138 (P1)
2022-11-02 23:36:23,901:INFO: - Computing loss (training)
2022-11-02 23:36:24,547:INFO: Batch:  0/31	Total Loss 0.0296 (0.0296)
2022-11-02 23:36:24,608:INFO: Batch:  1/31	Total Loss 0.0294 (0.0295)
2022-11-02 23:36:24,662:INFO: Batch:  2/31	Total Loss 0.0278 (0.0290)
2022-11-02 23:36:24,711:INFO: Batch:  3/31	Total Loss 0.0287 (0.0289)
2022-11-02 23:36:24,760:INFO: Batch:  4/31	Total Loss 0.0321 (0.0295)
2022-11-02 23:36:24,816:INFO: Batch:  5/31	Total Loss 0.0303 (0.0296)
2022-11-02 23:36:24,865:INFO: Batch:  6/31	Total Loss 0.0311 (0.0298)
2022-11-02 23:36:24,914:INFO: Batch:  7/31	Total Loss 0.0308 (0.0300)
2022-11-02 23:36:24,963:INFO: Batch:  8/31	Total Loss 0.0310 (0.0301)
2022-11-02 23:36:25,012:INFO: Batch:  9/31	Total Loss 0.0244 (0.0295)
2022-11-02 23:36:25,063:INFO: Batch: 10/31	Total Loss 0.0301 (0.0295)
2022-11-02 23:36:25,112:INFO: Batch: 11/31	Total Loss 0.0273 (0.0294)
2022-11-02 23:36:25,163:INFO: Batch: 12/31	Total Loss 0.0283 (0.0293)
2022-11-02 23:36:25,217:INFO: Batch: 13/31	Total Loss 0.0249 (0.0289)
2022-11-02 23:36:25,269:INFO: Batch: 14/31	Total Loss 0.0289 (0.0289)
2022-11-02 23:36:25,321:INFO: Batch: 15/31	Total Loss 0.0277 (0.0289)
2022-11-02 23:36:25,373:INFO: Batch: 16/31	Total Loss 0.0268 (0.0287)
2022-11-02 23:36:25,427:INFO: Batch: 17/31	Total Loss 0.0328 (0.0290)
2022-11-02 23:36:25,479:INFO: Batch: 18/31	Total Loss 0.0281 (0.0289)
2022-11-02 23:36:25,530:INFO: Batch: 19/31	Total Loss 0.0247 (0.0287)
2022-11-02 23:36:25,582:INFO: Batch: 20/31	Total Loss 0.0295 (0.0287)
2022-11-02 23:36:25,636:INFO: Batch: 21/31	Total Loss 0.0283 (0.0287)
2022-11-02 23:36:25,687:INFO: Batch: 22/31	Total Loss 0.0326 (0.0289)
2022-11-02 23:36:25,739:INFO: Batch: 23/31	Total Loss 0.0271 (0.0288)
2022-11-02 23:36:25,791:INFO: Batch: 24/31	Total Loss 0.0302 (0.0289)
2022-11-02 23:36:25,844:INFO: Batch: 25/31	Total Loss 0.0245 (0.0287)
2022-11-02 23:36:25,895:INFO: Batch: 26/31	Total Loss 0.0271 (0.0286)
2022-11-02 23:36:25,946:INFO: Batch: 27/31	Total Loss 0.0255 (0.0285)
2022-11-02 23:36:25,997:INFO: Batch: 28/31	Total Loss 0.0291 (0.0285)
2022-11-02 23:36:26,051:INFO: Batch: 29/31	Total Loss 0.0284 (0.0285)
2022-11-02 23:36:26,083:INFO: Batch: 30/31	Total Loss 0.0103 (0.0284)
2022-11-02 23:36:26,235:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_138.pth.tar
2022-11-02 23:36:26,235:INFO: 
===> EPOCH: 139 (P1)
2022-11-02 23:36:26,236:INFO: - Computing loss (training)
2022-11-02 23:36:26,903:INFO: Batch:  0/31	Total Loss 0.0329 (0.0329)
2022-11-02 23:36:26,963:INFO: Batch:  1/31	Total Loss 0.0271 (0.0299)
2022-11-02 23:36:27,015:INFO: Batch:  2/31	Total Loss 0.0310 (0.0302)
2022-11-02 23:36:27,066:INFO: Batch:  3/31	Total Loss 0.0300 (0.0302)
2022-11-02 23:36:27,115:INFO: Batch:  4/31	Total Loss 0.0275 (0.0297)
2022-11-02 23:36:27,167:INFO: Batch:  5/31	Total Loss 0.0292 (0.0296)
2022-11-02 23:36:27,215:INFO: Batch:  6/31	Total Loss 0.0270 (0.0292)
2022-11-02 23:36:27,262:INFO: Batch:  7/31	Total Loss 0.0273 (0.0289)
2022-11-02 23:36:27,310:INFO: Batch:  8/31	Total Loss 0.0277 (0.0288)
2022-11-02 23:36:27,361:INFO: Batch:  9/31	Total Loss 0.0269 (0.0286)
2022-11-02 23:36:27,408:INFO: Batch: 10/31	Total Loss 0.0273 (0.0285)
2022-11-02 23:36:27,456:INFO: Batch: 11/31	Total Loss 0.0264 (0.0283)
2022-11-02 23:36:27,506:INFO: Batch: 12/31	Total Loss 0.0289 (0.0284)
2022-11-02 23:36:27,555:INFO: Batch: 13/31	Total Loss 0.0265 (0.0282)
2022-11-02 23:36:27,607:INFO: Batch: 14/31	Total Loss 0.0277 (0.0282)
2022-11-02 23:36:27,659:INFO: Batch: 15/31	Total Loss 0.0259 (0.0280)
2022-11-02 23:36:27,708:INFO: Batch: 16/31	Total Loss 0.0267 (0.0280)
2022-11-02 23:36:27,758:INFO: Batch: 17/31	Total Loss 0.0275 (0.0279)
2022-11-02 23:36:27,808:INFO: Batch: 18/31	Total Loss 0.0252 (0.0278)
2022-11-02 23:36:27,859:INFO: Batch: 19/31	Total Loss 0.0267 (0.0277)
2022-11-02 23:36:27,909:INFO: Batch: 20/31	Total Loss 0.0269 (0.0277)
2022-11-02 23:36:27,959:INFO: Batch: 21/31	Total Loss 0.0338 (0.0279)
2022-11-02 23:36:28,009:INFO: Batch: 22/31	Total Loss 0.0276 (0.0279)
2022-11-02 23:36:28,059:INFO: Batch: 23/31	Total Loss 0.0277 (0.0279)
2022-11-02 23:36:28,111:INFO: Batch: 24/31	Total Loss 0.0314 (0.0281)
2022-11-02 23:36:28,160:INFO: Batch: 25/31	Total Loss 0.0266 (0.0280)
2022-11-02 23:36:28,209:INFO: Batch: 26/31	Total Loss 0.0318 (0.0281)
2022-11-02 23:36:28,259:INFO: Batch: 27/31	Total Loss 0.0288 (0.0282)
2022-11-02 23:36:28,310:INFO: Batch: 28/31	Total Loss 0.0261 (0.0281)
2022-11-02 23:36:28,360:INFO: Batch: 29/31	Total Loss 0.0279 (0.0281)
2022-11-02 23:36:28,390:INFO: Batch: 30/31	Total Loss 0.0122 (0.0279)
2022-11-02 23:36:28,545:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_139.pth.tar
2022-11-02 23:36:28,545:INFO: 
===> EPOCH: 140 (P1)
2022-11-02 23:36:28,545:INFO: - Computing loss (training)
2022-11-02 23:36:29,218:INFO: Batch:  0/31	Total Loss 0.0282 (0.0282)
2022-11-02 23:36:29,270:INFO: Batch:  1/31	Total Loss 0.0258 (0.0270)
2022-11-02 23:36:29,321:INFO: Batch:  2/31	Total Loss 0.0262 (0.0267)
2022-11-02 23:36:29,373:INFO: Batch:  3/31	Total Loss 0.0302 (0.0276)
2022-11-02 23:36:29,420:INFO: Batch:  4/31	Total Loss 0.0312 (0.0283)
2022-11-02 23:36:29,472:INFO: Batch:  5/31	Total Loss 0.0261 (0.0279)
2022-11-02 23:36:29,520:INFO: Batch:  6/31	Total Loss 0.0257 (0.0276)
2022-11-02 23:36:29,567:INFO: Batch:  7/31	Total Loss 0.0339 (0.0284)
2022-11-02 23:36:29,615:INFO: Batch:  8/31	Total Loss 0.0297 (0.0286)
2022-11-02 23:36:29,669:INFO: Batch:  9/31	Total Loss 0.0295 (0.0287)
2022-11-02 23:36:29,717:INFO: Batch: 10/31	Total Loss 0.0266 (0.0284)
2022-11-02 23:36:29,766:INFO: Batch: 11/31	Total Loss 0.0297 (0.0286)
2022-11-02 23:36:29,815:INFO: Batch: 12/31	Total Loss 0.0299 (0.0287)
2022-11-02 23:36:29,865:INFO: Batch: 13/31	Total Loss 0.0270 (0.0285)
2022-11-02 23:36:29,917:INFO: Batch: 14/31	Total Loss 0.0277 (0.0285)
2022-11-02 23:36:29,969:INFO: Batch: 15/31	Total Loss 0.0299 (0.0286)
2022-11-02 23:36:30,023:INFO: Batch: 16/31	Total Loss 0.0284 (0.0286)
2022-11-02 23:36:30,073:INFO: Batch: 17/31	Total Loss 0.0336 (0.0288)
2022-11-02 23:36:30,124:INFO: Batch: 18/31	Total Loss 0.0274 (0.0287)
2022-11-02 23:36:30,176:INFO: Batch: 19/31	Total Loss 0.0315 (0.0289)
2022-11-02 23:36:30,225:INFO: Batch: 20/31	Total Loss 0.0263 (0.0287)
2022-11-02 23:36:30,275:INFO: Batch: 21/31	Total Loss 0.0276 (0.0287)
2022-11-02 23:36:30,324:INFO: Batch: 22/31	Total Loss 0.0282 (0.0287)
2022-11-02 23:36:30,376:INFO: Batch: 23/31	Total Loss 0.0294 (0.0287)
2022-11-02 23:36:30,426:INFO: Batch: 24/31	Total Loss 0.0268 (0.0286)
2022-11-02 23:36:30,475:INFO: Batch: 25/31	Total Loss 0.0259 (0.0285)
2022-11-02 23:36:30,525:INFO: Batch: 26/31	Total Loss 0.0272 (0.0285)
2022-11-02 23:36:30,575:INFO: Batch: 27/31	Total Loss 0.0274 (0.0284)
2022-11-02 23:36:30,626:INFO: Batch: 28/31	Total Loss 0.0292 (0.0285)
2022-11-02 23:36:30,676:INFO: Batch: 29/31	Total Loss 0.0285 (0.0285)
2022-11-02 23:36:30,707:INFO: Batch: 30/31	Total Loss 0.0108 (0.0283)
2022-11-02 23:36:30,870:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_140.pth.tar
2022-11-02 23:36:30,870:INFO: 
===> EPOCH: 141 (P1)
2022-11-02 23:36:30,870:INFO: - Computing loss (training)
2022-11-02 23:36:31,582:INFO: Batch:  0/31	Total Loss 0.0366 (0.0366)
2022-11-02 23:36:31,632:INFO: Batch:  1/31	Total Loss 0.0305 (0.0335)
2022-11-02 23:36:31,690:INFO: Batch:  2/31	Total Loss 0.0254 (0.0309)
2022-11-02 23:36:31,739:INFO: Batch:  3/31	Total Loss 0.0279 (0.0302)
2022-11-02 23:36:31,789:INFO: Batch:  4/31	Total Loss 0.0278 (0.0297)
2022-11-02 23:36:31,841:INFO: Batch:  5/31	Total Loss 0.0301 (0.0297)
2022-11-02 23:36:31,889:INFO: Batch:  6/31	Total Loss 0.0252 (0.0290)
2022-11-02 23:36:31,936:INFO: Batch:  7/31	Total Loss 0.0282 (0.0289)
2022-11-02 23:36:31,984:INFO: Batch:  8/31	Total Loss 0.0274 (0.0287)
2022-11-02 23:36:32,034:INFO: Batch:  9/31	Total Loss 0.0296 (0.0288)
2022-11-02 23:36:32,083:INFO: Batch: 10/31	Total Loss 0.0276 (0.0287)
2022-11-02 23:36:32,131:INFO: Batch: 11/31	Total Loss 0.0258 (0.0284)
2022-11-02 23:36:32,181:INFO: Batch: 12/31	Total Loss 0.0251 (0.0282)
2022-11-02 23:36:32,230:INFO: Batch: 13/31	Total Loss 0.0279 (0.0282)
2022-11-02 23:36:32,284:INFO: Batch: 14/31	Total Loss 0.0267 (0.0281)
2022-11-02 23:36:32,336:INFO: Batch: 15/31	Total Loss 0.0266 (0.0280)
2022-11-02 23:36:32,385:INFO: Batch: 16/31	Total Loss 0.0271 (0.0279)
2022-11-02 23:36:32,435:INFO: Batch: 17/31	Total Loss 0.0330 (0.0282)
2022-11-02 23:36:32,484:INFO: Batch: 18/31	Total Loss 0.0255 (0.0280)
2022-11-02 23:36:32,538:INFO: Batch: 19/31	Total Loss 0.0252 (0.0279)
2022-11-02 23:36:32,589:INFO: Batch: 20/31	Total Loss 0.0281 (0.0279)
2022-11-02 23:36:32,639:INFO: Batch: 21/31	Total Loss 0.0255 (0.0278)
2022-11-02 23:36:32,687:INFO: Batch: 22/31	Total Loss 0.0266 (0.0277)
2022-11-02 23:36:32,735:INFO: Batch: 23/31	Total Loss 0.0242 (0.0276)
2022-11-02 23:36:32,789:INFO: Batch: 24/31	Total Loss 0.0262 (0.0275)
2022-11-02 23:36:32,839:INFO: Batch: 25/31	Total Loss 0.0249 (0.0274)
2022-11-02 23:36:32,888:INFO: Batch: 26/31	Total Loss 0.0259 (0.0274)
2022-11-02 23:36:32,937:INFO: Batch: 27/31	Total Loss 0.0282 (0.0274)
2022-11-02 23:36:32,987:INFO: Batch: 28/31	Total Loss 0.0236 (0.0273)
2022-11-02 23:36:33,039:INFO: Batch: 29/31	Total Loss 0.0268 (0.0273)
2022-11-02 23:36:33,070:INFO: Batch: 30/31	Total Loss 0.0104 (0.0271)
2022-11-02 23:36:33,219:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_141.pth.tar
2022-11-02 23:36:33,219:INFO: 
===> EPOCH: 142 (P1)
2022-11-02 23:36:33,220:INFO: - Computing loss (training)
2022-11-02 23:36:33,933:INFO: Batch:  0/31	Total Loss 0.0285 (0.0285)
2022-11-02 23:36:33,981:INFO: Batch:  1/31	Total Loss 0.0277 (0.0281)
2022-11-02 23:36:34,038:INFO: Batch:  2/31	Total Loss 0.0247 (0.0269)
2022-11-02 23:36:34,086:INFO: Batch:  3/31	Total Loss 0.0264 (0.0268)
2022-11-02 23:36:34,135:INFO: Batch:  4/31	Total Loss 0.0258 (0.0266)
2022-11-02 23:36:34,189:INFO: Batch:  5/31	Total Loss 0.0262 (0.0266)
2022-11-02 23:36:34,237:INFO: Batch:  6/31	Total Loss 0.0222 (0.0260)
2022-11-02 23:36:34,285:INFO: Batch:  7/31	Total Loss 0.0248 (0.0258)
2022-11-02 23:36:34,332:INFO: Batch:  8/31	Total Loss 0.0287 (0.0262)
2022-11-02 23:36:34,382:INFO: Batch:  9/31	Total Loss 0.0272 (0.0263)
2022-11-02 23:36:34,431:INFO: Batch: 10/31	Total Loss 0.0258 (0.0262)
2022-11-02 23:36:34,480:INFO: Batch: 11/31	Total Loss 0.0253 (0.0261)
2022-11-02 23:36:34,528:INFO: Batch: 12/31	Total Loss 0.0250 (0.0261)
2022-11-02 23:36:34,578:INFO: Batch: 13/31	Total Loss 0.0337 (0.0266)
2022-11-02 23:36:34,630:INFO: Batch: 14/31	Total Loss 0.0263 (0.0266)
2022-11-02 23:36:34,681:INFO: Batch: 15/31	Total Loss 0.0255 (0.0265)
2022-11-02 23:36:34,731:INFO: Batch: 16/31	Total Loss 0.0256 (0.0264)
2022-11-02 23:36:34,781:INFO: Batch: 17/31	Total Loss 0.0252 (0.0263)
2022-11-02 23:36:34,831:INFO: Batch: 18/31	Total Loss 0.0245 (0.0263)
2022-11-02 23:36:34,883:INFO: Batch: 19/31	Total Loss 0.0305 (0.0265)
2022-11-02 23:36:34,933:INFO: Batch: 20/31	Total Loss 0.0244 (0.0264)
2022-11-02 23:36:34,982:INFO: Batch: 21/31	Total Loss 0.0254 (0.0263)
2022-11-02 23:36:35,032:INFO: Batch: 22/31	Total Loss 0.0281 (0.0264)
2022-11-02 23:36:35,084:INFO: Batch: 23/31	Total Loss 0.0256 (0.0264)
2022-11-02 23:36:35,135:INFO: Batch: 24/31	Total Loss 0.0255 (0.0264)
2022-11-02 23:36:35,183:INFO: Batch: 25/31	Total Loss 0.0264 (0.0264)
2022-11-02 23:36:35,232:INFO: Batch: 26/31	Total Loss 0.0253 (0.0263)
2022-11-02 23:36:35,281:INFO: Batch: 27/31	Total Loss 0.0280 (0.0264)
2022-11-02 23:36:35,332:INFO: Batch: 28/31	Total Loss 0.0234 (0.0263)
2022-11-02 23:36:35,383:INFO: Batch: 29/31	Total Loss 0.0225 (0.0262)
2022-11-02 23:36:35,413:INFO: Batch: 30/31	Total Loss 0.0104 (0.0260)
2022-11-02 23:36:35,571:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_142.pth.tar
2022-11-02 23:36:35,571:INFO: 
===> EPOCH: 143 (P1)
2022-11-02 23:36:35,572:INFO: - Computing loss (training)
2022-11-02 23:36:36,255:INFO: Batch:  0/31	Total Loss 0.0231 (0.0231)
2022-11-02 23:36:36,309:INFO: Batch:  1/31	Total Loss 0.0368 (0.0296)
2022-11-02 23:36:36,363:INFO: Batch:  2/31	Total Loss 0.0357 (0.0314)
2022-11-02 23:36:36,414:INFO: Batch:  3/31	Total Loss 0.0281 (0.0306)
2022-11-02 23:36:36,462:INFO: Batch:  4/31	Total Loss 0.0311 (0.0307)
2022-11-02 23:36:36,516:INFO: Batch:  5/31	Total Loss 0.0308 (0.0307)
2022-11-02 23:36:36,563:INFO: Batch:  6/31	Total Loss 0.0300 (0.0306)
2022-11-02 23:36:36,609:INFO: Batch:  7/31	Total Loss 0.0332 (0.0309)
2022-11-02 23:36:36,656:INFO: Batch:  8/31	Total Loss 0.0271 (0.0305)
2022-11-02 23:36:36,705:INFO: Batch:  9/31	Total Loss 0.0283 (0.0302)
2022-11-02 23:36:36,752:INFO: Batch: 10/31	Total Loss 0.0284 (0.0301)
2022-11-02 23:36:36,800:INFO: Batch: 11/31	Total Loss 0.0329 (0.0303)
2022-11-02 23:36:36,849:INFO: Batch: 12/31	Total Loss 0.0324 (0.0305)
2022-11-02 23:36:36,898:INFO: Batch: 13/31	Total Loss 0.0338 (0.0307)
2022-11-02 23:36:36,949:INFO: Batch: 14/31	Total Loss 0.0279 (0.0305)
2022-11-02 23:36:36,999:INFO: Batch: 15/31	Total Loss 0.0344 (0.0308)
2022-11-02 23:36:37,049:INFO: Batch: 16/31	Total Loss 0.0325 (0.0309)
2022-11-02 23:36:37,099:INFO: Batch: 17/31	Total Loss 0.0278 (0.0307)
2022-11-02 23:36:37,148:INFO: Batch: 18/31	Total Loss 0.0274 (0.0305)
2022-11-02 23:36:37,199:INFO: Batch: 19/31	Total Loss 0.0280 (0.0304)
2022-11-02 23:36:37,248:INFO: Batch: 20/31	Total Loss 0.0267 (0.0302)
2022-11-02 23:36:37,297:INFO: Batch: 21/31	Total Loss 0.0291 (0.0302)
2022-11-02 23:36:37,347:INFO: Batch: 22/31	Total Loss 0.0292 (0.0301)
2022-11-02 23:36:37,395:INFO: Batch: 23/31	Total Loss 0.0280 (0.0300)
2022-11-02 23:36:37,445:INFO: Batch: 24/31	Total Loss 0.0289 (0.0300)
2022-11-02 23:36:37,495:INFO: Batch: 25/31	Total Loss 0.0384 (0.0303)
2022-11-02 23:36:37,543:INFO: Batch: 26/31	Total Loss 0.0379 (0.0306)
2022-11-02 23:36:37,591:INFO: Batch: 27/31	Total Loss 0.0251 (0.0304)
2022-11-02 23:36:37,640:INFO: Batch: 28/31	Total Loss 0.0268 (0.0303)
2022-11-02 23:36:37,690:INFO: Batch: 29/31	Total Loss 0.0419 (0.0306)
2022-11-02 23:36:37,722:INFO: Batch: 30/31	Total Loss 0.0112 (0.0305)
2022-11-02 23:36:37,871:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_143.pth.tar
2022-11-02 23:36:37,872:INFO: 
===> EPOCH: 144 (P1)
2022-11-02 23:36:37,872:INFO: - Computing loss (training)
2022-11-02 23:36:38,548:INFO: Batch:  0/31	Total Loss 0.0289 (0.0289)
2022-11-02 23:36:38,599:INFO: Batch:  1/31	Total Loss 0.0243 (0.0265)
2022-11-02 23:36:38,655:INFO: Batch:  2/31	Total Loss 0.0269 (0.0266)
2022-11-02 23:36:38,702:INFO: Batch:  3/31	Total Loss 0.0289 (0.0272)
2022-11-02 23:36:38,751:INFO: Batch:  4/31	Total Loss 0.0320 (0.0281)
2022-11-02 23:36:38,804:INFO: Batch:  5/31	Total Loss 0.0324 (0.0289)
2022-11-02 23:36:38,853:INFO: Batch:  6/31	Total Loss 0.0289 (0.0289)
2022-11-02 23:36:38,900:INFO: Batch:  7/31	Total Loss 0.0316 (0.0293)
2022-11-02 23:36:38,947:INFO: Batch:  8/31	Total Loss 0.0350 (0.0299)
2022-11-02 23:36:38,996:INFO: Batch:  9/31	Total Loss 0.0289 (0.0298)
2022-11-02 23:36:39,044:INFO: Batch: 10/31	Total Loss 0.0271 (0.0296)
2022-11-02 23:36:39,092:INFO: Batch: 11/31	Total Loss 0.0288 (0.0295)
2022-11-02 23:36:39,142:INFO: Batch: 12/31	Total Loss 0.0291 (0.0295)
2022-11-02 23:36:39,192:INFO: Batch: 13/31	Total Loss 0.0303 (0.0295)
2022-11-02 23:36:39,243:INFO: Batch: 14/31	Total Loss 0.0255 (0.0293)
2022-11-02 23:36:39,293:INFO: Batch: 15/31	Total Loss 0.0380 (0.0298)
2022-11-02 23:36:39,342:INFO: Batch: 16/31	Total Loss 0.0232 (0.0294)
2022-11-02 23:36:39,393:INFO: Batch: 17/31	Total Loss 0.0346 (0.0297)
2022-11-02 23:36:39,444:INFO: Batch: 18/31	Total Loss 0.0342 (0.0300)
2022-11-02 23:36:39,496:INFO: Batch: 19/31	Total Loss 0.0183 (0.0294)
2022-11-02 23:36:39,546:INFO: Batch: 20/31	Total Loss 0.0252 (0.0292)
2022-11-02 23:36:39,595:INFO: Batch: 21/31	Total Loss 0.0327 (0.0294)
2022-11-02 23:36:39,645:INFO: Batch: 22/31	Total Loss 0.0317 (0.0295)
2022-11-02 23:36:39,697:INFO: Batch: 23/31	Total Loss 0.0268 (0.0294)
2022-11-02 23:36:39,747:INFO: Batch: 24/31	Total Loss 0.0262 (0.0293)
2022-11-02 23:36:39,796:INFO: Batch: 25/31	Total Loss 0.0271 (0.0292)
2022-11-02 23:36:39,846:INFO: Batch: 26/31	Total Loss 0.0275 (0.0291)
2022-11-02 23:36:39,897:INFO: Batch: 27/31	Total Loss 0.0311 (0.0292)
2022-11-02 23:36:39,948:INFO: Batch: 28/31	Total Loss 0.0264 (0.0291)
2022-11-02 23:36:39,997:INFO: Batch: 29/31	Total Loss 0.0290 (0.0291)
2022-11-02 23:36:40,028:INFO: Batch: 30/31	Total Loss 0.0118 (0.0289)
2022-11-02 23:36:40,182:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_144.pth.tar
2022-11-02 23:36:40,182:INFO: 
===> EPOCH: 145 (P1)
2022-11-02 23:36:40,183:INFO: - Computing loss (training)
2022-11-02 23:36:40,815:INFO: Batch:  0/31	Total Loss 0.0251 (0.0251)
2022-11-02 23:36:40,863:INFO: Batch:  1/31	Total Loss 0.0290 (0.0268)
2022-11-02 23:36:40,913:INFO: Batch:  2/31	Total Loss 0.0226 (0.0254)
2022-11-02 23:36:40,965:INFO: Batch:  3/31	Total Loss 0.0250 (0.0253)
2022-11-02 23:36:41,019:INFO: Batch:  4/31	Total Loss 0.0242 (0.0251)
2022-11-02 23:36:41,071:INFO: Batch:  5/31	Total Loss 0.0263 (0.0253)
2022-11-02 23:36:41,119:INFO: Batch:  6/31	Total Loss 0.0222 (0.0248)
2022-11-02 23:36:41,167:INFO: Batch:  7/31	Total Loss 0.0221 (0.0245)
2022-11-02 23:36:41,216:INFO: Batch:  8/31	Total Loss 0.0249 (0.0245)
2022-11-02 23:36:41,266:INFO: Batch:  9/31	Total Loss 0.0202 (0.0242)
2022-11-02 23:36:41,316:INFO: Batch: 10/31	Total Loss 0.0258 (0.0243)
2022-11-02 23:36:41,364:INFO: Batch: 11/31	Total Loss 0.0299 (0.0247)
2022-11-02 23:36:41,413:INFO: Batch: 12/31	Total Loss 0.0273 (0.0249)
2022-11-02 23:36:41,463:INFO: Batch: 13/31	Total Loss 0.0239 (0.0248)
2022-11-02 23:36:41,516:INFO: Batch: 14/31	Total Loss 0.0257 (0.0249)
2022-11-02 23:36:41,567:INFO: Batch: 15/31	Total Loss 0.0233 (0.0248)
2022-11-02 23:36:41,618:INFO: Batch: 16/31	Total Loss 0.0295 (0.0251)
2022-11-02 23:36:41,668:INFO: Batch: 17/31	Total Loss 0.0268 (0.0252)
2022-11-02 23:36:41,719:INFO: Batch: 18/31	Total Loss 0.0287 (0.0254)
2022-11-02 23:36:41,771:INFO: Batch: 19/31	Total Loss 0.0288 (0.0256)
2022-11-02 23:36:41,822:INFO: Batch: 20/31	Total Loss 0.0275 (0.0257)
2022-11-02 23:36:41,871:INFO: Batch: 21/31	Total Loss 0.0433 (0.0264)
2022-11-02 23:36:41,921:INFO: Batch: 22/31	Total Loss 0.0258 (0.0263)
2022-11-02 23:36:41,974:INFO: Batch: 23/31	Total Loss 0.0277 (0.0264)
2022-11-02 23:36:42,024:INFO: Batch: 24/31	Total Loss 0.0226 (0.0262)
2022-11-02 23:36:42,074:INFO: Batch: 25/31	Total Loss 0.0267 (0.0263)
2022-11-02 23:36:42,124:INFO: Batch: 26/31	Total Loss 0.0276 (0.0263)
2022-11-02 23:36:42,176:INFO: Batch: 27/31	Total Loss 0.0234 (0.0262)
2022-11-02 23:36:42,227:INFO: Batch: 28/31	Total Loss 0.0216 (0.0260)
2022-11-02 23:36:42,276:INFO: Batch: 29/31	Total Loss 0.0288 (0.0261)
2022-11-02 23:36:42,306:INFO: Batch: 30/31	Total Loss 0.0086 (0.0260)
2022-11-02 23:36:42,460:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_145.pth.tar
2022-11-02 23:36:42,460:INFO: 
===> EPOCH: 146 (P1)
2022-11-02 23:36:42,460:INFO: - Computing loss (training)
2022-11-02 23:36:43,138:INFO: Batch:  0/31	Total Loss 0.0233 (0.0233)
2022-11-02 23:36:43,194:INFO: Batch:  1/31	Total Loss 0.0282 (0.0258)
2022-11-02 23:36:43,242:INFO: Batch:  2/31	Total Loss 0.0251 (0.0255)
2022-11-02 23:36:43,299:INFO: Batch:  3/31	Total Loss 0.0276 (0.0261)
2022-11-02 23:36:43,346:INFO: Batch:  4/31	Total Loss 0.0286 (0.0266)
2022-11-02 23:36:43,397:INFO: Batch:  5/31	Total Loss 0.0259 (0.0265)
2022-11-02 23:36:43,446:INFO: Batch:  6/31	Total Loss 0.0238 (0.0261)
2022-11-02 23:36:43,493:INFO: Batch:  7/31	Total Loss 0.0257 (0.0261)
2022-11-02 23:36:43,542:INFO: Batch:  8/31	Total Loss 0.0296 (0.0264)
2022-11-02 23:36:43,596:INFO: Batch:  9/31	Total Loss 0.0216 (0.0259)
2022-11-02 23:36:43,644:INFO: Batch: 10/31	Total Loss 0.0233 (0.0257)
2022-11-02 23:36:43,693:INFO: Batch: 11/31	Total Loss 0.0253 (0.0257)
2022-11-02 23:36:43,743:INFO: Batch: 12/31	Total Loss 0.0281 (0.0259)
2022-11-02 23:36:43,792:INFO: Batch: 13/31	Total Loss 0.0261 (0.0259)
2022-11-02 23:36:43,845:INFO: Batch: 14/31	Total Loss 0.0216 (0.0256)
2022-11-02 23:36:43,897:INFO: Batch: 15/31	Total Loss 0.0262 (0.0256)
2022-11-02 23:36:43,948:INFO: Batch: 16/31	Total Loss 0.0236 (0.0255)
2022-11-02 23:36:44,000:INFO: Batch: 17/31	Total Loss 0.0212 (0.0252)
2022-11-02 23:36:44,050:INFO: Batch: 18/31	Total Loss 0.0249 (0.0252)
2022-11-02 23:36:44,104:INFO: Batch: 19/31	Total Loss 0.0242 (0.0252)
2022-11-02 23:36:44,155:INFO: Batch: 20/31	Total Loss 0.0253 (0.0252)
2022-11-02 23:36:44,206:INFO: Batch: 21/31	Total Loss 0.0230 (0.0251)
2022-11-02 23:36:44,255:INFO: Batch: 22/31	Total Loss 0.0232 (0.0250)
2022-11-02 23:36:44,307:INFO: Batch: 23/31	Total Loss 0.0316 (0.0253)
2022-11-02 23:36:44,357:INFO: Batch: 24/31	Total Loss 0.0248 (0.0253)
2022-11-02 23:36:44,408:INFO: Batch: 25/31	Total Loss 0.0451 (0.0259)
2022-11-02 23:36:44,459:INFO: Batch: 26/31	Total Loss 0.0229 (0.0258)
2022-11-02 23:36:44,512:INFO: Batch: 27/31	Total Loss 0.0350 (0.0261)
2022-11-02 23:36:44,563:INFO: Batch: 28/31	Total Loss 0.0255 (0.0261)
2022-11-02 23:36:44,613:INFO: Batch: 29/31	Total Loss 0.0244 (0.0260)
2022-11-02 23:36:44,645:INFO: Batch: 30/31	Total Loss 0.0099 (0.0259)
2022-11-02 23:36:44,809:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_146.pth.tar
2022-11-02 23:36:44,809:INFO: 
===> EPOCH: 147 (P1)
2022-11-02 23:36:44,809:INFO: - Computing loss (training)
2022-11-02 23:36:45,471:INFO: Batch:  0/31	Total Loss 0.0476 (0.0476)
2022-11-02 23:36:45,521:INFO: Batch:  1/31	Total Loss 0.0407 (0.0440)
2022-11-02 23:36:45,580:INFO: Batch:  2/31	Total Loss 0.0290 (0.0393)
2022-11-02 23:36:45,630:INFO: Batch:  3/31	Total Loss 0.0445 (0.0406)
2022-11-02 23:36:45,680:INFO: Batch:  4/31	Total Loss 0.0434 (0.0412)
2022-11-02 23:36:45,732:INFO: Batch:  5/31	Total Loss 0.0244 (0.0384)
2022-11-02 23:36:45,779:INFO: Batch:  6/31	Total Loss 0.0267 (0.0368)
2022-11-02 23:36:45,826:INFO: Batch:  7/31	Total Loss 0.0371 (0.0368)
2022-11-02 23:36:45,874:INFO: Batch:  8/31	Total Loss 0.0370 (0.0368)
2022-11-02 23:36:45,923:INFO: Batch:  9/31	Total Loss 0.0314 (0.0362)
2022-11-02 23:36:45,973:INFO: Batch: 10/31	Total Loss 0.0260 (0.0353)
2022-11-02 23:36:46,021:INFO: Batch: 11/31	Total Loss 0.0449 (0.0361)
2022-11-02 23:36:46,070:INFO: Batch: 12/31	Total Loss 0.0312 (0.0357)
2022-11-02 23:36:46,121:INFO: Batch: 13/31	Total Loss 0.0293 (0.0352)
2022-11-02 23:36:46,173:INFO: Batch: 14/31	Total Loss 0.0229 (0.0344)
2022-11-02 23:36:46,224:INFO: Batch: 15/31	Total Loss 0.0273 (0.0340)
2022-11-02 23:36:46,273:INFO: Batch: 16/31	Total Loss 0.0394 (0.0343)
2022-11-02 23:36:46,323:INFO: Batch: 17/31	Total Loss 0.0282 (0.0339)
2022-11-02 23:36:46,373:INFO: Batch: 18/31	Total Loss 0.0306 (0.0337)
2022-11-02 23:36:46,425:INFO: Batch: 19/31	Total Loss 0.0268 (0.0334)
2022-11-02 23:36:46,476:INFO: Batch: 20/31	Total Loss 0.0388 (0.0337)
2022-11-02 23:36:46,526:INFO: Batch: 21/31	Total Loss 0.0348 (0.0337)
2022-11-02 23:36:46,576:INFO: Batch: 22/31	Total Loss 0.0243 (0.0333)
2022-11-02 23:36:46,626:INFO: Batch: 23/31	Total Loss 0.0339 (0.0333)
2022-11-02 23:36:46,677:INFO: Batch: 24/31	Total Loss 0.0354 (0.0334)
2022-11-02 23:36:46,727:INFO: Batch: 25/31	Total Loss 0.0407 (0.0337)
2022-11-02 23:36:46,777:INFO: Batch: 26/31	Total Loss 0.0252 (0.0333)
2022-11-02 23:36:46,832:INFO: Batch: 27/31	Total Loss 0.0324 (0.0333)
2022-11-02 23:36:46,881:INFO: Batch: 28/31	Total Loss 0.0438 (0.0337)
2022-11-02 23:36:46,933:INFO: Batch: 29/31	Total Loss 0.0320 (0.0336)
2022-11-02 23:36:46,964:INFO: Batch: 30/31	Total Loss 0.0096 (0.0334)
2022-11-02 23:36:47,120:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_147.pth.tar
2022-11-02 23:36:47,120:INFO: 
===> EPOCH: 148 (P1)
2022-11-02 23:36:47,120:INFO: - Computing loss (training)
2022-11-02 23:36:47,773:INFO: Batch:  0/31	Total Loss 0.0343 (0.0343)
2022-11-02 23:36:47,826:INFO: Batch:  1/31	Total Loss 0.0492 (0.0414)
2022-11-02 23:36:47,881:INFO: Batch:  2/31	Total Loss 0.0295 (0.0375)
2022-11-02 23:36:47,932:INFO: Batch:  3/31	Total Loss 0.0291 (0.0353)
2022-11-02 23:36:47,979:INFO: Batch:  4/31	Total Loss 0.0293 (0.0342)
2022-11-02 23:36:48,033:INFO: Batch:  5/31	Total Loss 0.0529 (0.0374)
2022-11-02 23:36:48,082:INFO: Batch:  6/31	Total Loss 0.0371 (0.0374)
2022-11-02 23:36:48,128:INFO: Batch:  7/31	Total Loss 0.0226 (0.0355)
2022-11-02 23:36:48,178:INFO: Batch:  8/31	Total Loss 0.0359 (0.0356)
2022-11-02 23:36:48,226:INFO: Batch:  9/31	Total Loss 0.0573 (0.0378)
2022-11-02 23:36:48,276:INFO: Batch: 10/31	Total Loss 0.0232 (0.0364)
2022-11-02 23:36:48,323:INFO: Batch: 11/31	Total Loss 0.0230 (0.0352)
2022-11-02 23:36:48,374:INFO: Batch: 12/31	Total Loss 0.0287 (0.0347)
2022-11-02 23:36:48,424:INFO: Batch: 13/31	Total Loss 0.0316 (0.0345)
2022-11-02 23:36:48,476:INFO: Batch: 14/31	Total Loss 0.0281 (0.0340)
2022-11-02 23:36:48,528:INFO: Batch: 15/31	Total Loss 0.0222 (0.0333)
2022-11-02 23:36:48,578:INFO: Batch: 16/31	Total Loss 0.0288 (0.0330)
2022-11-02 23:36:48,628:INFO: Batch: 17/31	Total Loss 0.0256 (0.0326)
2022-11-02 23:36:48,678:INFO: Batch: 18/31	Total Loss 0.0336 (0.0326)
2022-11-02 23:36:48,731:INFO: Batch: 19/31	Total Loss 0.0234 (0.0322)
2022-11-02 23:36:48,781:INFO: Batch: 20/31	Total Loss 0.0249 (0.0318)
2022-11-02 23:36:48,831:INFO: Batch: 21/31	Total Loss 0.0293 (0.0317)
2022-11-02 23:36:48,880:INFO: Batch: 22/31	Total Loss 0.0250 (0.0314)
2022-11-02 23:36:48,932:INFO: Batch: 23/31	Total Loss 0.0277 (0.0313)
2022-11-02 23:36:48,983:INFO: Batch: 24/31	Total Loss 0.0222 (0.0309)
2022-11-02 23:36:49,032:INFO: Batch: 25/31	Total Loss 0.0222 (0.0306)
2022-11-02 23:36:49,083:INFO: Batch: 26/31	Total Loss 0.0233 (0.0302)
2022-11-02 23:36:49,132:INFO: Batch: 27/31	Total Loss 0.0216 (0.0299)
2022-11-02 23:36:49,184:INFO: Batch: 28/31	Total Loss 0.0259 (0.0298)
2022-11-02 23:36:49,234:INFO: Batch: 29/31	Total Loss 0.0235 (0.0296)
2022-11-02 23:36:49,265:INFO: Batch: 30/31	Total Loss 0.0154 (0.0294)
2022-11-02 23:36:49,417:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_148.pth.tar
2022-11-02 23:36:49,417:INFO: 
===> EPOCH: 149 (P1)
2022-11-02 23:36:49,418:INFO: - Computing loss (training)
2022-11-02 23:36:50,105:INFO: Batch:  0/31	Total Loss 0.0246 (0.0246)
2022-11-02 23:36:50,154:INFO: Batch:  1/31	Total Loss 0.0255 (0.0249)
2022-11-02 23:36:50,210:INFO: Batch:  2/31	Total Loss 0.0229 (0.0243)
2022-11-02 23:36:50,258:INFO: Batch:  3/31	Total Loss 0.0234 (0.0241)
2022-11-02 23:36:50,306:INFO: Batch:  4/31	Total Loss 0.0240 (0.0240)
2022-11-02 23:36:50,358:INFO: Batch:  5/31	Total Loss 0.0253 (0.0242)
2022-11-02 23:36:50,405:INFO: Batch:  6/31	Total Loss 0.0237 (0.0242)
2022-11-02 23:36:50,451:INFO: Batch:  7/31	Total Loss 0.0322 (0.0251)
2022-11-02 23:36:50,498:INFO: Batch:  8/31	Total Loss 0.0250 (0.0251)
2022-11-02 23:36:50,548:INFO: Batch:  9/31	Total Loss 0.0238 (0.0250)
2022-11-02 23:36:50,598:INFO: Batch: 10/31	Total Loss 0.0226 (0.0247)
2022-11-02 23:36:50,646:INFO: Batch: 11/31	Total Loss 0.0276 (0.0250)
2022-11-02 23:36:50,695:INFO: Batch: 12/31	Total Loss 0.0216 (0.0247)
2022-11-02 23:36:50,744:INFO: Batch: 13/31	Total Loss 0.0256 (0.0248)
2022-11-02 23:36:50,796:INFO: Batch: 14/31	Total Loss 0.0242 (0.0248)
2022-11-02 23:36:50,848:INFO: Batch: 15/31	Total Loss 0.0280 (0.0250)
2022-11-02 23:36:50,897:INFO: Batch: 16/31	Total Loss 0.0241 (0.0249)
2022-11-02 23:36:50,947:INFO: Batch: 17/31	Total Loss 0.0235 (0.0248)
2022-11-02 23:36:50,997:INFO: Batch: 18/31	Total Loss 0.0224 (0.0247)
2022-11-02 23:36:51,049:INFO: Batch: 19/31	Total Loss 0.0263 (0.0248)
2022-11-02 23:36:51,099:INFO: Batch: 20/31	Total Loss 0.0198 (0.0245)
2022-11-02 23:36:51,151:INFO: Batch: 21/31	Total Loss 0.0219 (0.0244)
2022-11-02 23:36:51,200:INFO: Batch: 22/31	Total Loss 0.0190 (0.0242)
2022-11-02 23:36:51,249:INFO: Batch: 23/31	Total Loss 0.0310 (0.0244)
2022-11-02 23:36:51,300:INFO: Batch: 24/31	Total Loss 0.0248 (0.0244)
2022-11-02 23:36:51,350:INFO: Batch: 25/31	Total Loss 0.0253 (0.0245)
2022-11-02 23:36:51,401:INFO: Batch: 26/31	Total Loss 0.0269 (0.0246)
2022-11-02 23:36:51,450:INFO: Batch: 27/31	Total Loss 0.0312 (0.0248)
2022-11-02 23:36:51,501:INFO: Batch: 28/31	Total Loss 0.0258 (0.0249)
2022-11-02 23:36:51,551:INFO: Batch: 29/31	Total Loss 0.0270 (0.0249)
2022-11-02 23:36:51,581:INFO: Batch: 30/31	Total Loss 0.0108 (0.0248)
2022-11-02 23:36:51,750:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_149.pth.tar
2022-11-02 23:36:51,751:INFO: 
===> EPOCH: 150 (P1)
2022-11-02 23:36:51,751:INFO: - Computing loss (training)
2022-11-02 23:36:52,445:INFO: Batch:  0/31	Total Loss 0.0355 (0.0355)
2022-11-02 23:36:52,497:INFO: Batch:  1/31	Total Loss 0.0331 (0.0342)
2022-11-02 23:36:52,549:INFO: Batch:  2/31	Total Loss 0.0226 (0.0301)
2022-11-02 23:36:52,600:INFO: Batch:  3/31	Total Loss 0.0291 (0.0299)
2022-11-02 23:36:52,650:INFO: Batch:  4/31	Total Loss 0.0275 (0.0294)
2022-11-02 23:36:52,701:INFO: Batch:  5/31	Total Loss 0.0248 (0.0286)
2022-11-02 23:36:52,753:INFO: Batch:  6/31	Total Loss 0.0240 (0.0279)
2022-11-02 23:36:52,802:INFO: Batch:  7/31	Total Loss 0.0227 (0.0273)
2022-11-02 23:36:52,849:INFO: Batch:  8/31	Total Loss 0.0342 (0.0280)
2022-11-02 23:36:52,900:INFO: Batch:  9/31	Total Loss 0.0212 (0.0273)
2022-11-02 23:36:52,948:INFO: Batch: 10/31	Total Loss 0.0268 (0.0273)
2022-11-02 23:36:52,996:INFO: Batch: 11/31	Total Loss 0.0257 (0.0271)
2022-11-02 23:36:53,047:INFO: Batch: 12/31	Total Loss 0.0235 (0.0268)
2022-11-02 23:36:53,098:INFO: Batch: 13/31	Total Loss 0.0248 (0.0266)
2022-11-02 23:36:53,152:INFO: Batch: 14/31	Total Loss 0.0201 (0.0262)
2022-11-02 23:36:53,202:INFO: Batch: 15/31	Total Loss 0.0264 (0.0262)
2022-11-02 23:36:53,253:INFO: Batch: 16/31	Total Loss 0.0288 (0.0264)
2022-11-02 23:36:53,304:INFO: Batch: 17/31	Total Loss 0.0153 (0.0257)
2022-11-02 23:36:53,354:INFO: Batch: 18/31	Total Loss 0.0225 (0.0256)
2022-11-02 23:36:53,407:INFO: Batch: 19/31	Total Loss 0.0274 (0.0257)
2022-11-02 23:36:53,457:INFO: Batch: 20/31	Total Loss 0.0234 (0.0255)
2022-11-02 23:36:53,507:INFO: Batch: 21/31	Total Loss 0.0242 (0.0255)
2022-11-02 23:36:53,556:INFO: Batch: 22/31	Total Loss 0.0278 (0.0256)
2022-11-02 23:36:53,608:INFO: Batch: 23/31	Total Loss 0.0208 (0.0254)
2022-11-02 23:36:53,658:INFO: Batch: 24/31	Total Loss 0.0232 (0.0253)
2022-11-02 23:36:53,708:INFO: Batch: 25/31	Total Loss 0.0254 (0.0253)
2022-11-02 23:36:53,756:INFO: Batch: 26/31	Total Loss 0.0255 (0.0253)
2022-11-02 23:36:53,809:INFO: Batch: 27/31	Total Loss 0.0205 (0.0251)
2022-11-02 23:36:53,859:INFO: Batch: 28/31	Total Loss 0.0250 (0.0251)
2022-11-02 23:36:53,908:INFO: Batch: 29/31	Total Loss 0.0249 (0.0251)
2022-11-02 23:36:53,939:INFO: Batch: 30/31	Total Loss 0.0085 (0.0250)
2022-11-02 23:36:54,094:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P1/CRMF_epoch_150.pth.tar
2022-11-02 23:36:54,094:INFO: 
===> EPOCH: 151 (P2)
2022-11-02 23:36:54,094:INFO: - Computing loss (training)
2022-11-02 23:36:54,971:INFO: Batch:  0/31	Total Loss 73.8065 (73.8065)
2022-11-02 23:36:55,241:INFO: Batch:  1/31	Total Loss 47.1446 (59.8188)
2022-11-02 23:36:55,514:INFO: Batch:  2/31	Total Loss 31.9678 (50.3208)
2022-11-02 23:36:55,781:INFO: Batch:  3/31	Total Loss 27.0660 (44.5115)
2022-11-02 23:36:56,047:INFO: Batch:  4/31	Total Loss 23.5709 (40.2189)
2022-11-02 23:36:56,316:INFO: Batch:  5/31	Total Loss 21.4694 (36.7136)
2022-11-02 23:36:56,580:INFO: Batch:  6/31	Total Loss 22.8970 (35.0232)
2022-11-02 23:36:56,842:INFO: Batch:  7/31	Total Loss 19.5857 (33.1340)
2022-11-02 23:36:57,108:INFO: Batch:  8/31	Total Loss 18.9546 (31.6844)
2022-11-02 23:36:57,373:INFO: Batch:  9/31	Total Loss 16.5412 (30.1510)
2022-11-02 23:36:57,636:INFO: Batch: 10/31	Total Loss 16.1243 (28.9328)
2022-11-02 23:36:57,904:INFO: Batch: 11/31	Total Loss 14.0794 (27.8029)
2022-11-02 23:36:58,167:INFO: Batch: 12/31	Total Loss 11.0983 (26.5062)
2022-11-02 23:36:58,430:INFO: Batch: 13/31	Total Loss 12.5280 (25.5658)
2022-11-02 23:36:58,694:INFO: Batch: 14/31	Total Loss 10.9702 (24.5683)
2022-11-02 23:36:58,958:INFO: Batch: 15/31	Total Loss 10.9909 (23.7152)
2022-11-02 23:36:59,223:INFO: Batch: 16/31	Total Loss 8.6686 (22.7335)
2022-11-02 23:36:59,493:INFO: Batch: 17/31	Total Loss 9.4068 (21.9666)
2022-11-02 23:36:59,767:INFO: Batch: 18/31	Total Loss 9.6646 (21.4312)
2022-11-02 23:37:00,038:INFO: Batch: 19/31	Total Loss 9.5173 (20.8079)
2022-11-02 23:37:00,307:INFO: Batch: 20/31	Total Loss 9.6547 (20.2901)
2022-11-02 23:37:00,567:INFO: Batch: 21/31	Total Loss 8.5510 (19.6966)
2022-11-02 23:37:00,827:INFO: Batch: 22/31	Total Loss 8.4198 (19.2214)
2022-11-02 23:37:01,087:INFO: Batch: 23/31	Total Loss 11.4673 (18.9224)
2022-11-02 23:37:01,352:INFO: Batch: 24/31	Total Loss 7.8669 (18.4972)
2022-11-02 23:37:01,613:INFO: Batch: 25/31	Total Loss 7.6781 (18.0556)
2022-11-02 23:37:01,873:INFO: Batch: 26/31	Total Loss 7.1060 (17.6182)
2022-11-02 23:37:02,135:INFO: Batch: 27/31	Total Loss 6.9930 (17.2644)
2022-11-02 23:37:02,394:INFO: Batch: 28/31	Total Loss 7.2899 (16.9352)
2022-11-02 23:37:02,653:INFO: Batch: 29/31	Total Loss 8.0893 (16.6319)
2022-11-02 23:37:02,772:INFO: Batch: 30/31	Total Loss 2.5274 (16.4753)
2022-11-02 23:37:02,941:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_151.pth.tar
2022-11-02 23:37:02,941:INFO: 
===> EPOCH: 152 (P2)
2022-11-02 23:37:02,941:INFO: - Computing loss (training)
2022-11-02 23:37:03,827:INFO: Batch:  0/31	Total Loss 6.0314 (6.0314)
2022-11-02 23:37:04,093:INFO: Batch:  1/31	Total Loss 6.5214 (6.2638)
2022-11-02 23:37:04,358:INFO: Batch:  2/31	Total Loss 6.3282 (6.2850)
2022-11-02 23:37:04,618:INFO: Batch:  3/31	Total Loss 5.9369 (6.2034)
2022-11-02 23:37:04,876:INFO: Batch:  4/31	Total Loss 6.0758 (6.1774)
2022-11-02 23:37:05,143:INFO: Batch:  5/31	Total Loss 5.7631 (6.1080)
2022-11-02 23:37:05,404:INFO: Batch:  6/31	Total Loss 5.0680 (5.9616)
2022-11-02 23:37:05,664:INFO: Batch:  7/31	Total Loss 5.7444 (5.9348)
2022-11-02 23:37:05,925:INFO: Batch:  8/31	Total Loss 5.5054 (5.8847)
2022-11-02 23:37:06,187:INFO: Batch:  9/31	Total Loss 5.7755 (5.8733)
2022-11-02 23:37:06,448:INFO: Batch: 10/31	Total Loss 5.1194 (5.8035)
2022-11-02 23:37:06,711:INFO: Batch: 11/31	Total Loss 5.3106 (5.7581)
2022-11-02 23:37:06,978:INFO: Batch: 12/31	Total Loss 4.9822 (5.6981)
2022-11-02 23:37:07,245:INFO: Batch: 13/31	Total Loss 5.3618 (5.6753)
2022-11-02 23:37:07,510:INFO: Batch: 14/31	Total Loss 4.5930 (5.6036)
2022-11-02 23:37:07,776:INFO: Batch: 15/31	Total Loss 4.5971 (5.5429)
2022-11-02 23:37:08,041:INFO: Batch: 16/31	Total Loss 4.4612 (5.4751)
2022-11-02 23:37:08,307:INFO: Batch: 17/31	Total Loss 4.3195 (5.4063)
2022-11-02 23:37:08,574:INFO: Batch: 18/31	Total Loss 4.5371 (5.3618)
2022-11-02 23:37:08,839:INFO: Batch: 19/31	Total Loss 4.1322 (5.2947)
2022-11-02 23:37:09,105:INFO: Batch: 20/31	Total Loss 4.0672 (5.2338)
2022-11-02 23:37:09,369:INFO: Batch: 21/31	Total Loss 4.6522 (5.2099)
2022-11-02 23:37:09,634:INFO: Batch: 22/31	Total Loss 4.3471 (5.1690)
2022-11-02 23:37:09,903:INFO: Batch: 23/31	Total Loss 4.4911 (5.1452)
2022-11-02 23:37:10,166:INFO: Batch: 24/31	Total Loss 4.5213 (5.1177)
2022-11-02 23:37:10,429:INFO: Batch: 25/31	Total Loss 4.3454 (5.0864)
2022-11-02 23:37:10,689:INFO: Batch: 26/31	Total Loss 4.3647 (5.0576)
2022-11-02 23:37:10,952:INFO: Batch: 27/31	Total Loss 3.9785 (5.0236)
2022-11-02 23:37:11,215:INFO: Batch: 28/31	Total Loss 4.4545 (5.0032)
2022-11-02 23:37:11,475:INFO: Batch: 29/31	Total Loss 3.8258 (4.9621)
2022-11-02 23:37:11,595:INFO: Batch: 30/31	Total Loss 1.5921 (4.9258)
2022-11-02 23:37:11,750:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_152.pth.tar
2022-11-02 23:37:11,750:INFO: 
===> EPOCH: 153 (P2)
2022-11-02 23:37:11,750:INFO: - Computing loss (training)
2022-11-02 23:37:12,615:INFO: Batch:  0/31	Total Loss 3.6940 (3.6940)
2022-11-02 23:37:12,873:INFO: Batch:  1/31	Total Loss 3.8807 (3.7870)
2022-11-02 23:37:13,134:INFO: Batch:  2/31	Total Loss 3.7369 (3.7708)
2022-11-02 23:37:13,391:INFO: Batch:  3/31	Total Loss 4.3875 (3.9160)
2022-11-02 23:37:13,650:INFO: Batch:  4/31	Total Loss 3.4546 (3.8246)
2022-11-02 23:37:13,910:INFO: Batch:  5/31	Total Loss 3.9063 (3.8360)
2022-11-02 23:37:14,167:INFO: Batch:  6/31	Total Loss 3.8729 (3.8413)
2022-11-02 23:37:14,423:INFO: Batch:  7/31	Total Loss 3.6740 (3.8190)
2022-11-02 23:37:14,679:INFO: Batch:  8/31	Total Loss 3.7249 (3.8088)
2022-11-02 23:37:14,936:INFO: Batch:  9/31	Total Loss 3.5092 (3.7775)
2022-11-02 23:37:15,193:INFO: Batch: 10/31	Total Loss 3.9024 (3.7896)
2022-11-02 23:37:15,451:INFO: Batch: 11/31	Total Loss 3.5910 (3.7719)
2022-11-02 23:37:15,712:INFO: Batch: 12/31	Total Loss 3.7521 (3.7705)
2022-11-02 23:37:15,972:INFO: Batch: 13/31	Total Loss 3.5753 (3.7570)
2022-11-02 23:37:16,234:INFO: Batch: 14/31	Total Loss 3.5424 (3.7424)
2022-11-02 23:37:16,495:INFO: Batch: 15/31	Total Loss 3.2213 (3.7071)
2022-11-02 23:37:16,756:INFO: Batch: 16/31	Total Loss 3.3157 (3.6832)
2022-11-02 23:37:17,017:INFO: Batch: 17/31	Total Loss 3.2758 (3.6575)
2022-11-02 23:37:17,278:INFO: Batch: 18/31	Total Loss 3.3385 (3.6391)
2022-11-02 23:37:17,615:INFO: Batch: 19/31	Total Loss 3.6208 (3.6381)
2022-11-02 23:37:17,875:INFO: Batch: 20/31	Total Loss 3.0688 (3.6124)
2022-11-02 23:37:18,134:INFO: Batch: 21/31	Total Loss 3.3587 (3.6010)
2022-11-02 23:37:18,393:INFO: Batch: 22/31	Total Loss 3.0205 (3.5738)
2022-11-02 23:37:18,654:INFO: Batch: 23/31	Total Loss 3.1231 (3.5540)
2022-11-02 23:37:18,913:INFO: Batch: 24/31	Total Loss 2.9760 (3.5315)
2022-11-02 23:37:19,173:INFO: Batch: 25/31	Total Loss 2.6324 (3.4985)
2022-11-02 23:37:19,434:INFO: Batch: 26/31	Total Loss 3.2643 (3.4896)
2022-11-02 23:37:19,694:INFO: Batch: 27/31	Total Loss 3.0853 (3.4752)
2022-11-02 23:37:19,954:INFO: Batch: 28/31	Total Loss 3.1460 (3.4640)
2022-11-02 23:37:20,217:INFO: Batch: 29/31	Total Loss 3.4367 (3.4631)
2022-11-02 23:37:20,336:INFO: Batch: 30/31	Total Loss 1.2944 (3.4451)
2022-11-02 23:37:20,484:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_153.pth.tar
2022-11-02 23:37:20,484:INFO: 
===> EPOCH: 154 (P2)
2022-11-02 23:37:20,485:INFO: - Computing loss (training)
2022-11-02 23:37:21,354:INFO: Batch:  0/31	Total Loss 3.0344 (3.0344)
2022-11-02 23:37:21,616:INFO: Batch:  1/31	Total Loss 3.1473 (3.0889)
2022-11-02 23:37:21,874:INFO: Batch:  2/31	Total Loss 2.9244 (3.0340)
2022-11-02 23:37:22,132:INFO: Batch:  3/31	Total Loss 2.8826 (2.9971)
2022-11-02 23:37:22,392:INFO: Batch:  4/31	Total Loss 2.9454 (2.9850)
2022-11-02 23:37:22,657:INFO: Batch:  5/31	Total Loss 3.0003 (2.9873)
2022-11-02 23:37:22,917:INFO: Batch:  6/31	Total Loss 2.7470 (2.9534)
2022-11-02 23:37:23,174:INFO: Batch:  7/31	Total Loss 2.9426 (2.9521)
2022-11-02 23:37:23,430:INFO: Batch:  8/31	Total Loss 2.7970 (2.9344)
2022-11-02 23:37:23,687:INFO: Batch:  9/31	Total Loss 2.6332 (2.9009)
2022-11-02 23:37:23,944:INFO: Batch: 10/31	Total Loss 2.8056 (2.8924)
2022-11-02 23:37:24,204:INFO: Batch: 11/31	Total Loss 3.1537 (2.9128)
2022-11-02 23:37:24,467:INFO: Batch: 12/31	Total Loss 2.9172 (2.9131)
2022-11-02 23:37:24,728:INFO: Batch: 13/31	Total Loss 2.5456 (2.8874)
2022-11-02 23:37:24,990:INFO: Batch: 14/31	Total Loss 2.7661 (2.8795)
2022-11-02 23:37:25,252:INFO: Batch: 15/31	Total Loss 2.5039 (2.8570)
2022-11-02 23:37:25,513:INFO: Batch: 16/31	Total Loss 2.5795 (2.8394)
2022-11-02 23:37:25,775:INFO: Batch: 17/31	Total Loss 2.5161 (2.8196)
2022-11-02 23:37:26,038:INFO: Batch: 18/31	Total Loss 2.3851 (2.7958)
2022-11-02 23:37:26,299:INFO: Batch: 19/31	Total Loss 2.2006 (2.7622)
2022-11-02 23:37:26,561:INFO: Batch: 20/31	Total Loss 2.3763 (2.7429)
2022-11-02 23:37:26,823:INFO: Batch: 21/31	Total Loss 2.5707 (2.7346)
2022-11-02 23:37:27,083:INFO: Batch: 22/31	Total Loss 3.0061 (2.7444)
2022-11-02 23:37:27,344:INFO: Batch: 23/31	Total Loss 2.3314 (2.7248)
2022-11-02 23:37:27,605:INFO: Batch: 24/31	Total Loss 2.6202 (2.7203)
2022-11-02 23:37:27,865:INFO: Batch: 25/31	Total Loss 2.3979 (2.7075)
2022-11-02 23:37:28,126:INFO: Batch: 26/31	Total Loss 2.5515 (2.7017)
2022-11-02 23:37:28,385:INFO: Batch: 27/31	Total Loss 2.5578 (2.6965)
2022-11-02 23:37:28,646:INFO: Batch: 28/31	Total Loss 2.3945 (2.6861)
2022-11-02 23:37:28,910:INFO: Batch: 29/31	Total Loss 2.3133 (2.6743)
2022-11-02 23:37:29,030:INFO: Batch: 30/31	Total Loss 0.8969 (2.6573)
2022-11-02 23:37:29,191:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_154.pth.tar
2022-11-02 23:37:29,191:INFO: 
===> EPOCH: 155 (P2)
2022-11-02 23:37:29,191:INFO: - Computing loss (training)
2022-11-02 23:37:30,092:INFO: Batch:  0/31	Total Loss 2.3113 (2.3113)
2022-11-02 23:37:30,354:INFO: Batch:  1/31	Total Loss 2.1814 (2.2484)
2022-11-02 23:37:30,615:INFO: Batch:  2/31	Total Loss 2.4034 (2.3026)
2022-11-02 23:37:30,873:INFO: Batch:  3/31	Total Loss 2.1094 (2.2541)
2022-11-02 23:37:31,130:INFO: Batch:  4/31	Total Loss 2.2636 (2.2560)
2022-11-02 23:37:31,392:INFO: Batch:  5/31	Total Loss 2.1200 (2.2315)
2022-11-02 23:37:31,650:INFO: Batch:  6/31	Total Loss 2.6515 (2.2888)
2022-11-02 23:37:31,906:INFO: Batch:  7/31	Total Loss 2.4141 (2.3032)
2022-11-02 23:37:32,163:INFO: Batch:  8/31	Total Loss 2.0756 (2.2798)
2022-11-02 23:37:32,420:INFO: Batch:  9/31	Total Loss 2.1752 (2.2691)
2022-11-02 23:37:32,679:INFO: Batch: 10/31	Total Loss 2.5496 (2.2958)
2022-11-02 23:37:32,936:INFO: Batch: 11/31	Total Loss 2.3415 (2.2993)
2022-11-02 23:37:33,197:INFO: Batch: 12/31	Total Loss 1.9338 (2.2733)
2022-11-02 23:37:33,456:INFO: Batch: 13/31	Total Loss 1.9112 (2.2462)
2022-11-02 23:37:33,718:INFO: Batch: 14/31	Total Loss 2.0350 (2.2314)
2022-11-02 23:37:33,978:INFO: Batch: 15/31	Total Loss 2.1952 (2.2291)
2022-11-02 23:37:34,238:INFO: Batch: 16/31	Total Loss 2.2766 (2.2315)
2022-11-02 23:37:34,499:INFO: Batch: 17/31	Total Loss 2.0453 (2.2217)
2022-11-02 23:37:34,761:INFO: Batch: 18/31	Total Loss 2.1004 (2.2155)
2022-11-02 23:37:35,021:INFO: Batch: 19/31	Total Loss 2.0381 (2.2063)
2022-11-02 23:37:35,281:INFO: Batch: 20/31	Total Loss 1.7163 (2.1833)
2022-11-02 23:37:35,541:INFO: Batch: 21/31	Total Loss 1.9905 (2.1747)
2022-11-02 23:37:35,800:INFO: Batch: 22/31	Total Loss 1.9515 (2.1655)
2022-11-02 23:37:36,059:INFO: Batch: 23/31	Total Loss 1.9393 (2.1559)
2022-11-02 23:37:36,318:INFO: Batch: 24/31	Total Loss 1.8575 (2.1437)
2022-11-02 23:37:36,577:INFO: Batch: 25/31	Total Loss 2.1107 (2.1425)
2022-11-02 23:37:36,836:INFO: Batch: 26/31	Total Loss 2.0276 (2.1382)
2022-11-02 23:37:37,096:INFO: Batch: 27/31	Total Loss 1.9080 (2.1295)
2022-11-02 23:37:37,355:INFO: Batch: 28/31	Total Loss 2.0106 (2.1254)
2022-11-02 23:37:37,615:INFO: Batch: 29/31	Total Loss 1.9646 (2.1198)
2022-11-02 23:37:37,733:INFO: Batch: 30/31	Total Loss 0.7281 (2.1073)
2022-11-02 23:37:37,890:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_155.pth.tar
2022-11-02 23:37:37,890:INFO: 
===> EPOCH: 156 (P2)
2022-11-02 23:37:37,890:INFO: - Computing loss (training)
2022-11-02 23:37:38,769:INFO: Batch:  0/31	Total Loss 1.8075 (1.8075)
2022-11-02 23:37:39,031:INFO: Batch:  1/31	Total Loss 1.7990 (1.8031)
2022-11-02 23:37:39,285:INFO: Batch:  2/31	Total Loss 1.9513 (1.8494)
2022-11-02 23:37:39,546:INFO: Batch:  3/31	Total Loss 1.7646 (1.8261)
2022-11-02 23:37:39,803:INFO: Batch:  4/31	Total Loss 1.8417 (1.8291)
2022-11-02 23:37:40,060:INFO: Batch:  5/31	Total Loss 1.8802 (1.8372)
2022-11-02 23:37:40,315:INFO: Batch:  6/31	Total Loss 1.9075 (1.8463)
2022-11-02 23:37:40,570:INFO: Batch:  7/31	Total Loss 1.7847 (1.8383)
2022-11-02 23:37:40,824:INFO: Batch:  8/31	Total Loss 1.8928 (1.8444)
2022-11-02 23:37:41,081:INFO: Batch:  9/31	Total Loss 1.7694 (1.8364)
2022-11-02 23:37:41,337:INFO: Batch: 10/31	Total Loss 1.8385 (1.8365)
2022-11-02 23:37:41,592:INFO: Batch: 11/31	Total Loss 1.8551 (1.8380)
2022-11-02 23:37:41,856:INFO: Batch: 12/31	Total Loss 1.7227 (1.8273)
2022-11-02 23:37:42,121:INFO: Batch: 13/31	Total Loss 1.7078 (1.8188)
2022-11-02 23:37:42,381:INFO: Batch: 14/31	Total Loss 1.8248 (1.8192)
2022-11-02 23:37:42,640:INFO: Batch: 15/31	Total Loss 1.6671 (1.8098)
2022-11-02 23:37:42,905:INFO: Batch: 16/31	Total Loss 1.8452 (1.8118)
2022-11-02 23:37:43,169:INFO: Batch: 17/31	Total Loss 1.4365 (1.7905)
2022-11-02 23:37:43,429:INFO: Batch: 18/31	Total Loss 1.8151 (1.7917)
2022-11-02 23:37:43,688:INFO: Batch: 19/31	Total Loss 1.6810 (1.7863)
2022-11-02 23:37:43,947:INFO: Batch: 20/31	Total Loss 1.8296 (1.7882)
2022-11-02 23:37:44,206:INFO: Batch: 21/31	Total Loss 1.7095 (1.7846)
2022-11-02 23:37:44,464:INFO: Batch: 22/31	Total Loss 1.5485 (1.7744)
2022-11-02 23:37:44,721:INFO: Batch: 23/31	Total Loss 1.7239 (1.7723)
2022-11-02 23:37:44,983:INFO: Batch: 24/31	Total Loss 1.7058 (1.7699)
2022-11-02 23:37:45,247:INFO: Batch: 25/31	Total Loss 1.6099 (1.7634)
2022-11-02 23:37:45,509:INFO: Batch: 26/31	Total Loss 1.7247 (1.7621)
2022-11-02 23:37:45,772:INFO: Batch: 27/31	Total Loss 1.6541 (1.7582)
2022-11-02 23:37:46,036:INFO: Batch: 28/31	Total Loss 1.6619 (1.7548)
2022-11-02 23:37:46,297:INFO: Batch: 29/31	Total Loss 1.4040 (1.7430)
2022-11-02 23:37:46,417:INFO: Batch: 30/31	Total Loss 0.6606 (1.7318)
2022-11-02 23:37:46,586:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_156.pth.tar
2022-11-02 23:37:46,586:INFO: 
===> EPOCH: 157 (P2)
2022-11-02 23:37:46,586:INFO: - Computing loss (training)
2022-11-02 23:37:47,481:INFO: Batch:  0/31	Total Loss 1.6547 (1.6547)
2022-11-02 23:37:47,750:INFO: Batch:  1/31	Total Loss 1.4404 (1.5419)
2022-11-02 23:37:48,018:INFO: Batch:  2/31	Total Loss 1.5660 (1.5496)
2022-11-02 23:37:48,286:INFO: Batch:  3/31	Total Loss 1.6065 (1.5633)
2022-11-02 23:37:48,550:INFO: Batch:  4/31	Total Loss 1.3719 (1.5253)
2022-11-02 23:37:48,818:INFO: Batch:  5/31	Total Loss 1.5554 (1.5306)
2022-11-02 23:37:49,085:INFO: Batch:  6/31	Total Loss 1.3825 (1.5098)
2022-11-02 23:37:49,348:INFO: Batch:  7/31	Total Loss 1.3911 (1.4933)
2022-11-02 23:37:49,613:INFO: Batch:  8/31	Total Loss 1.8913 (1.5312)
2022-11-02 23:37:49,877:INFO: Batch:  9/31	Total Loss 1.4523 (1.5234)
2022-11-02 23:37:50,144:INFO: Batch: 10/31	Total Loss 1.5243 (1.5235)
2022-11-02 23:37:50,408:INFO: Batch: 11/31	Total Loss 1.5369 (1.5246)
2022-11-02 23:37:50,677:INFO: Batch: 12/31	Total Loss 1.4541 (1.5190)
2022-11-02 23:37:50,945:INFO: Batch: 13/31	Total Loss 1.3599 (1.5074)
2022-11-02 23:37:51,212:INFO: Batch: 14/31	Total Loss 1.5868 (1.5126)
2022-11-02 23:37:51,479:INFO: Batch: 15/31	Total Loss 1.3787 (1.5042)
2022-11-02 23:37:51,747:INFO: Batch: 16/31	Total Loss 1.4957 (1.5038)
2022-11-02 23:37:52,013:INFO: Batch: 17/31	Total Loss 1.3140 (1.4938)
2022-11-02 23:37:52,281:INFO: Batch: 18/31	Total Loss 1.4777 (1.4930)
2022-11-02 23:37:52,548:INFO: Batch: 19/31	Total Loss 1.3882 (1.4877)
2022-11-02 23:37:52,815:INFO: Batch: 20/31	Total Loss 1.4364 (1.4853)
2022-11-02 23:37:53,082:INFO: Batch: 21/31	Total Loss 1.4066 (1.4820)
2022-11-02 23:37:53,349:INFO: Batch: 22/31	Total Loss 1.4324 (1.4796)
2022-11-02 23:37:53,615:INFO: Batch: 23/31	Total Loss 1.4743 (1.4794)
2022-11-02 23:37:53,881:INFO: Batch: 24/31	Total Loss 1.4240 (1.4775)
2022-11-02 23:37:54,148:INFO: Batch: 25/31	Total Loss 1.4187 (1.4751)
2022-11-02 23:37:54,414:INFO: Batch: 26/31	Total Loss 1.5202 (1.4767)
2022-11-02 23:37:54,682:INFO: Batch: 27/31	Total Loss 1.3514 (1.4723)
2022-11-02 23:37:54,949:INFO: Batch: 28/31	Total Loss 1.2564 (1.4641)
2022-11-02 23:37:55,216:INFO: Batch: 29/31	Total Loss 1.4494 (1.4636)
2022-11-02 23:37:55,338:INFO: Batch: 30/31	Total Loss 0.6951 (1.4580)
2022-11-02 23:37:55,500:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_157.pth.tar
2022-11-02 23:37:55,500:INFO: 
===> EPOCH: 158 (P2)
2022-11-02 23:37:55,500:INFO: - Computing loss (training)
2022-11-02 23:37:56,375:INFO: Batch:  0/31	Total Loss 1.3055 (1.3055)
2022-11-02 23:37:56,635:INFO: Batch:  1/31	Total Loss 1.3834 (1.3432)
2022-11-02 23:37:56,897:INFO: Batch:  2/31	Total Loss 1.3447 (1.3436)
2022-11-02 23:37:57,157:INFO: Batch:  3/31	Total Loss 1.2815 (1.3285)
2022-11-02 23:37:57,411:INFO: Batch:  4/31	Total Loss 1.2834 (1.3197)
2022-11-02 23:37:57,672:INFO: Batch:  5/31	Total Loss 1.1304 (1.2855)
2022-11-02 23:37:57,929:INFO: Batch:  6/31	Total Loss 1.2653 (1.2826)
2022-11-02 23:37:58,185:INFO: Batch:  7/31	Total Loss 1.3352 (1.2895)
2022-11-02 23:37:58,440:INFO: Batch:  8/31	Total Loss 1.3291 (1.2935)
2022-11-02 23:37:58,696:INFO: Batch:  9/31	Total Loss 1.4335 (1.3075)
2022-11-02 23:37:58,953:INFO: Batch: 10/31	Total Loss 1.3637 (1.3124)
2022-11-02 23:37:59,212:INFO: Batch: 11/31	Total Loss 1.2569 (1.3074)
2022-11-02 23:37:59,474:INFO: Batch: 12/31	Total Loss 1.2952 (1.3065)
2022-11-02 23:37:59,735:INFO: Batch: 13/31	Total Loss 1.2380 (1.3018)
2022-11-02 23:37:59,995:INFO: Batch: 14/31	Total Loss 1.1492 (1.2907)
2022-11-02 23:38:00,257:INFO: Batch: 15/31	Total Loss 1.1120 (1.2790)
2022-11-02 23:38:00,517:INFO: Batch: 16/31	Total Loss 1.1505 (1.2704)
2022-11-02 23:38:00,778:INFO: Batch: 17/31	Total Loss 1.2557 (1.2695)
2022-11-02 23:38:01,038:INFO: Batch: 18/31	Total Loss 1.2743 (1.2698)
2022-11-02 23:38:01,303:INFO: Batch: 19/31	Total Loss 1.2586 (1.2692)
2022-11-02 23:38:01,563:INFO: Batch: 20/31	Total Loss 1.5036 (1.2796)
2022-11-02 23:38:01,822:INFO: Batch: 21/31	Total Loss 1.1366 (1.2733)
2022-11-02 23:38:02,083:INFO: Batch: 22/31	Total Loss 0.9993 (1.2613)
2022-11-02 23:38:02,342:INFO: Batch: 23/31	Total Loss 1.1607 (1.2573)
2022-11-02 23:38:02,602:INFO: Batch: 24/31	Total Loss 1.1532 (1.2532)
2022-11-02 23:38:02,862:INFO: Batch: 25/31	Total Loss 1.1224 (1.2481)
2022-11-02 23:38:03,121:INFO: Batch: 26/31	Total Loss 1.2533 (1.2483)
2022-11-02 23:38:03,380:INFO: Batch: 27/31	Total Loss 1.3164 (1.2505)
2022-11-02 23:38:03,641:INFO: Batch: 28/31	Total Loss 1.3285 (1.2532)
2022-11-02 23:38:03,899:INFO: Batch: 29/31	Total Loss 1.1209 (1.2491)
2022-11-02 23:38:04,018:INFO: Batch: 30/31	Total Loss 0.4745 (1.2411)
2022-11-02 23:38:04,183:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_158.pth.tar
2022-11-02 23:38:04,184:INFO: 
===> EPOCH: 159 (P2)
2022-11-02 23:38:04,184:INFO: - Computing loss (training)
2022-11-02 23:38:05,108:INFO: Batch:  0/31	Total Loss 1.2164 (1.2164)
2022-11-02 23:38:05,375:INFO: Batch:  1/31	Total Loss 1.0384 (1.1278)
2022-11-02 23:38:05,635:INFO: Batch:  2/31	Total Loss 1.1214 (1.1256)
2022-11-02 23:38:05,902:INFO: Batch:  3/31	Total Loss 1.1404 (1.1296)
2022-11-02 23:38:06,240:INFO: Batch:  4/31	Total Loss 1.1953 (1.1420)
2022-11-02 23:38:06,501:INFO: Batch:  5/31	Total Loss 1.1549 (1.1440)
2022-11-02 23:38:06,760:INFO: Batch:  6/31	Total Loss 1.1522 (1.1454)
2022-11-02 23:38:07,015:INFO: Batch:  7/31	Total Loss 1.0513 (1.1341)
2022-11-02 23:38:07,271:INFO: Batch:  8/31	Total Loss 1.1301 (1.1337)
2022-11-02 23:38:07,527:INFO: Batch:  9/31	Total Loss 1.1132 (1.1315)
2022-11-02 23:38:07,785:INFO: Batch: 10/31	Total Loss 1.0932 (1.1279)
2022-11-02 23:38:08,043:INFO: Batch: 11/31	Total Loss 1.2501 (1.1387)
2022-11-02 23:38:08,302:INFO: Batch: 12/31	Total Loss 1.0358 (1.1310)
2022-11-02 23:38:08,562:INFO: Batch: 13/31	Total Loss 1.0356 (1.1247)
2022-11-02 23:38:08,822:INFO: Batch: 14/31	Total Loss 1.1156 (1.1241)
2022-11-02 23:38:09,082:INFO: Batch: 15/31	Total Loss 1.0161 (1.1171)
2022-11-02 23:38:09,342:INFO: Batch: 16/31	Total Loss 1.0778 (1.1148)
2022-11-02 23:38:09,604:INFO: Batch: 17/31	Total Loss 0.9257 (1.1043)
2022-11-02 23:38:09,867:INFO: Batch: 18/31	Total Loss 1.0954 (1.1038)
2022-11-02 23:38:10,127:INFO: Batch: 19/31	Total Loss 0.9987 (1.0983)
2022-11-02 23:38:10,386:INFO: Batch: 20/31	Total Loss 0.9558 (1.0916)
2022-11-02 23:38:10,645:INFO: Batch: 21/31	Total Loss 1.2554 (1.0980)
2022-11-02 23:38:10,904:INFO: Batch: 22/31	Total Loss 1.0795 (1.0972)
2022-11-02 23:38:11,162:INFO: Batch: 23/31	Total Loss 1.1546 (1.0995)
2022-11-02 23:38:11,420:INFO: Batch: 24/31	Total Loss 0.9063 (1.0916)
2022-11-02 23:38:11,679:INFO: Batch: 25/31	Total Loss 0.9398 (1.0857)
2022-11-02 23:38:11,941:INFO: Batch: 26/31	Total Loss 0.9550 (1.0810)
2022-11-02 23:38:12,202:INFO: Batch: 27/31	Total Loss 0.9977 (1.0782)
2022-11-02 23:38:12,460:INFO: Batch: 28/31	Total Loss 0.9908 (1.0753)
2022-11-02 23:38:12,718:INFO: Batch: 29/31	Total Loss 0.9171 (1.0701)
2022-11-02 23:38:12,836:INFO: Batch: 30/31	Total Loss 0.3266 (1.0624)
2022-11-02 23:38:12,981:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_159.pth.tar
2022-11-02 23:38:12,981:INFO: 
===> EPOCH: 160 (P2)
2022-11-02 23:38:12,981:INFO: - Computing loss (training)
2022-11-02 23:38:13,855:INFO: Batch:  0/31	Total Loss 0.9830 (0.9830)
2022-11-02 23:38:14,118:INFO: Batch:  1/31	Total Loss 0.8474 (0.9180)
2022-11-02 23:38:14,378:INFO: Batch:  2/31	Total Loss 0.9819 (0.9385)
2022-11-02 23:38:14,636:INFO: Batch:  3/31	Total Loss 1.1498 (0.9890)
2022-11-02 23:38:14,898:INFO: Batch:  4/31	Total Loss 0.9307 (0.9770)
2022-11-02 23:38:15,158:INFO: Batch:  5/31	Total Loss 0.9040 (0.9648)
2022-11-02 23:38:15,415:INFO: Batch:  6/31	Total Loss 1.1214 (0.9836)
2022-11-02 23:38:15,670:INFO: Batch:  7/31	Total Loss 0.8524 (0.9660)
2022-11-02 23:38:15,924:INFO: Batch:  8/31	Total Loss 0.8915 (0.9574)
2022-11-02 23:38:16,182:INFO: Batch:  9/31	Total Loss 1.0746 (0.9708)
2022-11-02 23:38:16,437:INFO: Batch: 10/31	Total Loss 0.9358 (0.9678)
2022-11-02 23:38:16,695:INFO: Batch: 11/31	Total Loss 0.9289 (0.9645)
2022-11-02 23:38:16,955:INFO: Batch: 12/31	Total Loss 1.0182 (0.9686)
2022-11-02 23:38:17,218:INFO: Batch: 13/31	Total Loss 0.8977 (0.9636)
2022-11-02 23:38:17,479:INFO: Batch: 14/31	Total Loss 0.8664 (0.9563)
2022-11-02 23:38:17,740:INFO: Batch: 15/31	Total Loss 0.8626 (0.9504)
2022-11-02 23:38:18,000:INFO: Batch: 16/31	Total Loss 1.1240 (0.9607)
2022-11-02 23:38:18,260:INFO: Batch: 17/31	Total Loss 0.9221 (0.9584)
2022-11-02 23:38:18,520:INFO: Batch: 18/31	Total Loss 0.9866 (0.9598)
2022-11-02 23:38:18,780:INFO: Batch: 19/31	Total Loss 0.9141 (0.9579)
2022-11-02 23:38:19,039:INFO: Batch: 20/31	Total Loss 0.8154 (0.9501)
2022-11-02 23:38:19,298:INFO: Batch: 21/31	Total Loss 0.8371 (0.9444)
2022-11-02 23:38:19,560:INFO: Batch: 22/31	Total Loss 0.8339 (0.9398)
2022-11-02 23:38:19,819:INFO: Batch: 23/31	Total Loss 0.7888 (0.9334)
2022-11-02 23:38:20,078:INFO: Batch: 24/31	Total Loss 0.8701 (0.9312)
2022-11-02 23:38:20,336:INFO: Batch: 25/31	Total Loss 0.8964 (0.9298)
2022-11-02 23:38:20,594:INFO: Batch: 26/31	Total Loss 0.8483 (0.9269)
2022-11-02 23:38:20,854:INFO: Batch: 27/31	Total Loss 0.7944 (0.9218)
2022-11-02 23:38:21,115:INFO: Batch: 28/31	Total Loss 0.8385 (0.9190)
2022-11-02 23:38:21,373:INFO: Batch: 29/31	Total Loss 0.8766 (0.9177)
2022-11-02 23:38:21,492:INFO: Batch: 30/31	Total Loss 0.2986 (0.9117)
2022-11-02 23:38:21,653:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_160.pth.tar
2022-11-02 23:38:21,653:INFO: 
===> EPOCH: 161 (P2)
2022-11-02 23:38:21,654:INFO: - Computing loss (training)
2022-11-02 23:38:22,514:INFO: Batch:  0/31	Total Loss 0.7328 (0.7328)
2022-11-02 23:38:22,773:INFO: Batch:  1/31	Total Loss 0.7672 (0.7505)
2022-11-02 23:38:23,032:INFO: Batch:  2/31	Total Loss 0.8040 (0.7701)
2022-11-02 23:38:23,292:INFO: Batch:  3/31	Total Loss 0.8136 (0.7824)
2022-11-02 23:38:23,549:INFO: Batch:  4/31	Total Loss 0.8155 (0.7892)
2022-11-02 23:38:23,809:INFO: Batch:  5/31	Total Loss 0.8444 (0.7978)
2022-11-02 23:38:24,065:INFO: Batch:  6/31	Total Loss 0.7736 (0.7947)
2022-11-02 23:38:24,320:INFO: Batch:  7/31	Total Loss 0.7600 (0.7903)
2022-11-02 23:38:24,578:INFO: Batch:  8/31	Total Loss 0.8147 (0.7930)
2022-11-02 23:38:24,838:INFO: Batch:  9/31	Total Loss 0.9089 (0.8048)
2022-11-02 23:38:25,096:INFO: Batch: 10/31	Total Loss 0.8628 (0.8103)
2022-11-02 23:38:25,353:INFO: Batch: 11/31	Total Loss 0.8019 (0.8096)
2022-11-02 23:38:25,614:INFO: Batch: 12/31	Total Loss 0.8189 (0.8103)
2022-11-02 23:38:25,875:INFO: Batch: 13/31	Total Loss 0.8223 (0.8111)
2022-11-02 23:38:26,136:INFO: Batch: 14/31	Total Loss 0.7113 (0.8050)
2022-11-02 23:38:26,397:INFO: Batch: 15/31	Total Loss 0.7464 (0.8014)
2022-11-02 23:38:26,658:INFO: Batch: 16/31	Total Loss 0.9232 (0.8082)
2022-11-02 23:38:26,920:INFO: Batch: 17/31	Total Loss 0.7949 (0.8075)
2022-11-02 23:38:27,181:INFO: Batch: 18/31	Total Loss 0.7971 (0.8069)
2022-11-02 23:38:27,441:INFO: Batch: 19/31	Total Loss 0.7559 (0.8044)
2022-11-02 23:38:27,700:INFO: Batch: 20/31	Total Loss 0.8634 (0.8071)
2022-11-02 23:38:27,961:INFO: Batch: 21/31	Total Loss 0.7474 (0.8044)
2022-11-02 23:38:28,221:INFO: Batch: 22/31	Total Loss 0.7629 (0.8026)
2022-11-02 23:38:28,480:INFO: Batch: 23/31	Total Loss 0.8572 (0.8050)
2022-11-02 23:38:28,740:INFO: Batch: 24/31	Total Loss 0.8958 (0.8082)
2022-11-02 23:38:28,999:INFO: Batch: 25/31	Total Loss 0.7630 (0.8064)
2022-11-02 23:38:29,259:INFO: Batch: 26/31	Total Loss 0.7777 (0.8052)
2022-11-02 23:38:29,523:INFO: Batch: 27/31	Total Loss 0.8185 (0.8057)
2022-11-02 23:38:29,782:INFO: Batch: 28/31	Total Loss 0.8181 (0.8061)
2022-11-02 23:38:30,042:INFO: Batch: 29/31	Total Loss 0.7550 (0.8044)
2022-11-02 23:38:30,161:INFO: Batch: 30/31	Total Loss 0.2969 (0.7986)
2022-11-02 23:38:30,327:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_161.pth.tar
2022-11-02 23:38:30,327:INFO: 
===> EPOCH: 162 (P2)
2022-11-02 23:38:30,327:INFO: - Computing loss (training)
2022-11-02 23:38:31,214:INFO: Batch:  0/31	Total Loss 0.6810 (0.6810)
2022-11-02 23:38:31,472:INFO: Batch:  1/31	Total Loss 0.7479 (0.7146)
2022-11-02 23:38:31,732:INFO: Batch:  2/31	Total Loss 0.7005 (0.7102)
2022-11-02 23:38:31,991:INFO: Batch:  3/31	Total Loss 0.8641 (0.7444)
2022-11-02 23:38:32,250:INFO: Batch:  4/31	Total Loss 0.7476 (0.7450)
2022-11-02 23:38:32,508:INFO: Batch:  5/31	Total Loss 0.7858 (0.7514)
2022-11-02 23:38:32,767:INFO: Batch:  6/31	Total Loss 0.7897 (0.7564)
2022-11-02 23:38:33,025:INFO: Batch:  7/31	Total Loss 0.7933 (0.7608)
2022-11-02 23:38:33,282:INFO: Batch:  8/31	Total Loss 0.6587 (0.7494)
2022-11-02 23:38:33,538:INFO: Batch:  9/31	Total Loss 0.8076 (0.7549)
2022-11-02 23:38:33,798:INFO: Batch: 10/31	Total Loss 0.7998 (0.7586)
2022-11-02 23:38:34,056:INFO: Batch: 11/31	Total Loss 0.7360 (0.7564)
2022-11-02 23:38:34,315:INFO: Batch: 12/31	Total Loss 0.8530 (0.7634)
2022-11-02 23:38:34,575:INFO: Batch: 13/31	Total Loss 0.7740 (0.7642)
2022-11-02 23:38:34,835:INFO: Batch: 14/31	Total Loss 0.7131 (0.7608)
2022-11-02 23:38:35,096:INFO: Batch: 15/31	Total Loss 0.7715 (0.7615)
2022-11-02 23:38:35,357:INFO: Batch: 16/31	Total Loss 0.6885 (0.7569)
2022-11-02 23:38:35,618:INFO: Batch: 17/31	Total Loss 0.6781 (0.7531)
2022-11-02 23:38:35,878:INFO: Batch: 18/31	Total Loss 0.6893 (0.7494)
2022-11-02 23:38:36,140:INFO: Batch: 19/31	Total Loss 0.6136 (0.7420)
2022-11-02 23:38:36,400:INFO: Batch: 20/31	Total Loss 0.6602 (0.7378)
2022-11-02 23:38:36,659:INFO: Batch: 21/31	Total Loss 0.8101 (0.7409)
2022-11-02 23:38:36,922:INFO: Batch: 22/31	Total Loss 0.6893 (0.7385)
2022-11-02 23:38:37,187:INFO: Batch: 23/31	Total Loss 0.6399 (0.7343)
2022-11-02 23:38:37,451:INFO: Batch: 24/31	Total Loss 0.7611 (0.7353)
2022-11-02 23:38:37,715:INFO: Batch: 25/31	Total Loss 0.6706 (0.7329)
2022-11-02 23:38:37,979:INFO: Batch: 26/31	Total Loss 0.6231 (0.7285)
2022-11-02 23:38:38,243:INFO: Batch: 27/31	Total Loss 0.5766 (0.7233)
2022-11-02 23:38:38,507:INFO: Batch: 28/31	Total Loss 0.6231 (0.7199)
2022-11-02 23:38:38,772:INFO: Batch: 29/31	Total Loss 0.7561 (0.7211)
2022-11-02 23:38:38,893:INFO: Batch: 30/31	Total Loss 0.2735 (0.7161)
2022-11-02 23:38:39,049:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_162.pth.tar
2022-11-02 23:38:39,049:INFO: 
===> EPOCH: 163 (P2)
2022-11-02 23:38:39,049:INFO: - Computing loss (training)
2022-11-02 23:38:39,916:INFO: Batch:  0/31	Total Loss 0.6163 (0.6163)
2022-11-02 23:38:40,177:INFO: Batch:  1/31	Total Loss 0.6686 (0.6416)
2022-11-02 23:38:40,436:INFO: Batch:  2/31	Total Loss 0.6346 (0.6394)
2022-11-02 23:38:40,698:INFO: Batch:  3/31	Total Loss 0.5507 (0.6187)
2022-11-02 23:38:40,954:INFO: Batch:  4/31	Total Loss 0.5791 (0.6106)
2022-11-02 23:38:41,216:INFO: Batch:  5/31	Total Loss 0.6738 (0.6200)
2022-11-02 23:38:41,473:INFO: Batch:  6/31	Total Loss 0.8971 (0.6598)
2022-11-02 23:38:41,733:INFO: Batch:  7/31	Total Loss 0.5842 (0.6509)
2022-11-02 23:38:41,990:INFO: Batch:  8/31	Total Loss 0.7496 (0.6605)
2022-11-02 23:38:42,248:INFO: Batch:  9/31	Total Loss 0.6260 (0.6571)
2022-11-02 23:38:42,507:INFO: Batch: 10/31	Total Loss 0.5787 (0.6499)
2022-11-02 23:38:42,766:INFO: Batch: 11/31	Total Loss 0.5842 (0.6444)
2022-11-02 23:38:43,029:INFO: Batch: 12/31	Total Loss 0.6195 (0.6425)
2022-11-02 23:38:43,289:INFO: Batch: 13/31	Total Loss 0.5952 (0.6393)
2022-11-02 23:38:43,552:INFO: Batch: 14/31	Total Loss 0.6203 (0.6381)
2022-11-02 23:38:43,813:INFO: Batch: 15/31	Total Loss 0.6316 (0.6377)
2022-11-02 23:38:44,075:INFO: Batch: 16/31	Total Loss 0.5987 (0.6353)
2022-11-02 23:38:44,337:INFO: Batch: 17/31	Total Loss 0.5846 (0.6327)
2022-11-02 23:38:44,599:INFO: Batch: 18/31	Total Loss 0.5867 (0.6302)
2022-11-02 23:38:44,860:INFO: Batch: 19/31	Total Loss 0.6335 (0.6304)
2022-11-02 23:38:45,122:INFO: Batch: 20/31	Total Loss 0.5491 (0.6261)
2022-11-02 23:38:45,381:INFO: Batch: 21/31	Total Loss 0.6312 (0.6263)
2022-11-02 23:38:45,651:INFO: Batch: 22/31	Total Loss 0.5994 (0.6253)
2022-11-02 23:38:45,913:INFO: Batch: 23/31	Total Loss 0.5803 (0.6236)
2022-11-02 23:38:46,174:INFO: Batch: 24/31	Total Loss 0.6058 (0.6228)
2022-11-02 23:38:46,446:INFO: Batch: 25/31	Total Loss 0.6626 (0.6244)
2022-11-02 23:38:46,707:INFO: Batch: 26/31	Total Loss 0.5706 (0.6223)
2022-11-02 23:38:46,969:INFO: Batch: 27/31	Total Loss 0.5809 (0.6206)
2022-11-02 23:38:47,232:INFO: Batch: 28/31	Total Loss 0.5687 (0.6188)
2022-11-02 23:38:47,497:INFO: Batch: 29/31	Total Loss 0.5356 (0.6161)
2022-11-02 23:38:47,617:INFO: Batch: 30/31	Total Loss 0.2209 (0.6120)
2022-11-02 23:38:47,774:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_163.pth.tar
2022-11-02 23:38:47,774:INFO: 
===> EPOCH: 164 (P2)
2022-11-02 23:38:47,774:INFO: - Computing loss (training)
2022-11-02 23:38:48,625:INFO: Batch:  0/31	Total Loss 0.5413 (0.5413)
2022-11-02 23:38:48,889:INFO: Batch:  1/31	Total Loss 0.5998 (0.5710)
2022-11-02 23:38:49,149:INFO: Batch:  2/31	Total Loss 0.5500 (0.5640)
2022-11-02 23:38:49,412:INFO: Batch:  3/31	Total Loss 0.5281 (0.5556)
2022-11-02 23:38:49,673:INFO: Batch:  4/31	Total Loss 0.5347 (0.5512)
2022-11-02 23:38:49,937:INFO: Batch:  5/31	Total Loss 0.4627 (0.5362)
2022-11-02 23:38:50,194:INFO: Batch:  6/31	Total Loss 0.5395 (0.5367)
2022-11-02 23:38:50,449:INFO: Batch:  7/31	Total Loss 0.5272 (0.5355)
2022-11-02 23:38:50,706:INFO: Batch:  8/31	Total Loss 0.6563 (0.5490)
2022-11-02 23:38:50,964:INFO: Batch:  9/31	Total Loss 0.5137 (0.5455)
2022-11-02 23:38:51,222:INFO: Batch: 10/31	Total Loss 0.4844 (0.5397)
2022-11-02 23:38:51,482:INFO: Batch: 11/31	Total Loss 0.5644 (0.5418)
2022-11-02 23:38:51,744:INFO: Batch: 12/31	Total Loss 0.5466 (0.5421)
2022-11-02 23:38:52,007:INFO: Batch: 13/31	Total Loss 0.5195 (0.5404)
2022-11-02 23:38:52,270:INFO: Batch: 14/31	Total Loss 0.5390 (0.5403)
2022-11-02 23:38:52,532:INFO: Batch: 15/31	Total Loss 0.5840 (0.5431)
2022-11-02 23:38:52,794:INFO: Batch: 16/31	Total Loss 0.4876 (0.5399)
2022-11-02 23:38:53,056:INFO: Batch: 17/31	Total Loss 0.4799 (0.5366)
2022-11-02 23:38:53,318:INFO: Batch: 18/31	Total Loss 0.5243 (0.5360)
2022-11-02 23:38:53,580:INFO: Batch: 19/31	Total Loss 0.5537 (0.5369)
2022-11-02 23:38:53,842:INFO: Batch: 20/31	Total Loss 0.4752 (0.5339)
2022-11-02 23:38:54,103:INFO: Batch: 21/31	Total Loss 0.5051 (0.5327)
2022-11-02 23:38:54,365:INFO: Batch: 22/31	Total Loss 0.5049 (0.5315)
2022-11-02 23:38:54,626:INFO: Batch: 23/31	Total Loss 0.4654 (0.5288)
2022-11-02 23:38:54,887:INFO: Batch: 24/31	Total Loss 0.5063 (0.5279)
2022-11-02 23:38:55,147:INFO: Batch: 25/31	Total Loss 0.5122 (0.5273)
2022-11-02 23:38:55,408:INFO: Batch: 26/31	Total Loss 0.4873 (0.5259)
2022-11-02 23:38:55,670:INFO: Batch: 27/31	Total Loss 0.4729 (0.5239)
2022-11-02 23:38:55,932:INFO: Batch: 28/31	Total Loss 0.4671 (0.5220)
2022-11-02 23:38:56,192:INFO: Batch: 29/31	Total Loss 0.5385 (0.5225)
2022-11-02 23:38:56,312:INFO: Batch: 30/31	Total Loss 0.1927 (0.5191)
2022-11-02 23:38:56,464:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_164.pth.tar
2022-11-02 23:38:56,464:INFO: 
===> EPOCH: 165 (P2)
2022-11-02 23:38:56,465:INFO: - Computing loss (training)
2022-11-02 23:38:57,373:INFO: Batch:  0/31	Total Loss 0.6455 (0.6455)
2022-11-02 23:38:57,635:INFO: Batch:  1/31	Total Loss 0.4676 (0.5488)
2022-11-02 23:38:57,966:INFO: Batch:  2/31	Total Loss 0.5036 (0.5332)
2022-11-02 23:38:58,223:INFO: Batch:  3/31	Total Loss 0.4955 (0.5229)
2022-11-02 23:38:58,478:INFO: Batch:  4/31	Total Loss 0.4648 (0.5108)
2022-11-02 23:38:58,736:INFO: Batch:  5/31	Total Loss 0.4636 (0.5017)
2022-11-02 23:38:58,991:INFO: Batch:  6/31	Total Loss 0.4322 (0.4913)
2022-11-02 23:38:59,245:INFO: Batch:  7/31	Total Loss 0.5061 (0.4931)
2022-11-02 23:38:59,502:INFO: Batch:  8/31	Total Loss 0.5377 (0.4981)
2022-11-02 23:38:59,758:INFO: Batch:  9/31	Total Loss 0.4760 (0.4959)
2022-11-02 23:39:00,014:INFO: Batch: 10/31	Total Loss 0.4996 (0.4962)
2022-11-02 23:39:00,272:INFO: Batch: 11/31	Total Loss 0.4143 (0.4894)
2022-11-02 23:39:00,532:INFO: Batch: 12/31	Total Loss 0.4417 (0.4852)
2022-11-02 23:39:00,792:INFO: Batch: 13/31	Total Loss 0.4728 (0.4843)
2022-11-02 23:39:01,053:INFO: Batch: 14/31	Total Loss 0.4404 (0.4814)
2022-11-02 23:39:01,314:INFO: Batch: 15/31	Total Loss 0.4585 (0.4799)
2022-11-02 23:39:01,574:INFO: Batch: 16/31	Total Loss 0.4738 (0.4795)
2022-11-02 23:39:01,834:INFO: Batch: 17/31	Total Loss 0.4512 (0.4779)
2022-11-02 23:39:02,096:INFO: Batch: 18/31	Total Loss 0.4376 (0.4757)
2022-11-02 23:39:02,356:INFO: Batch: 19/31	Total Loss 0.4532 (0.4744)
2022-11-02 23:39:02,615:INFO: Batch: 20/31	Total Loss 0.4271 (0.4722)
2022-11-02 23:39:02,874:INFO: Batch: 21/31	Total Loss 0.4757 (0.4723)
2022-11-02 23:39:03,133:INFO: Batch: 22/31	Total Loss 0.4522 (0.4715)
2022-11-02 23:39:03,391:INFO: Batch: 23/31	Total Loss 0.4724 (0.4715)
2022-11-02 23:39:03,649:INFO: Batch: 24/31	Total Loss 0.4403 (0.4702)
2022-11-02 23:39:03,907:INFO: Batch: 25/31	Total Loss 0.4272 (0.4687)
2022-11-02 23:39:04,166:INFO: Batch: 26/31	Total Loss 0.4506 (0.4680)
2022-11-02 23:39:04,425:INFO: Batch: 27/31	Total Loss 0.4316 (0.4666)
2022-11-02 23:39:04,684:INFO: Batch: 28/31	Total Loss 0.4688 (0.4667)
2022-11-02 23:39:04,943:INFO: Batch: 29/31	Total Loss 0.4438 (0.4659)
2022-11-02 23:39:05,062:INFO: Batch: 30/31	Total Loss 0.1685 (0.4635)
2022-11-02 23:39:05,221:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_165.pth.tar
2022-11-02 23:39:05,221:INFO: 
===> EPOCH: 166 (P2)
2022-11-02 23:39:05,222:INFO: - Computing loss (training)
2022-11-02 23:39:06,085:INFO: Batch:  0/31	Total Loss 0.4222 (0.4222)
2022-11-02 23:39:06,346:INFO: Batch:  1/31	Total Loss 0.4203 (0.4213)
2022-11-02 23:39:06,603:INFO: Batch:  2/31	Total Loss 0.4378 (0.4270)
2022-11-02 23:39:06,865:INFO: Batch:  3/31	Total Loss 0.4058 (0.4216)
2022-11-02 23:39:07,125:INFO: Batch:  4/31	Total Loss 0.3933 (0.4161)
2022-11-02 23:39:07,385:INFO: Batch:  5/31	Total Loss 0.4319 (0.4192)
2022-11-02 23:39:07,642:INFO: Batch:  6/31	Total Loss 0.4120 (0.4181)
2022-11-02 23:39:07,899:INFO: Batch:  7/31	Total Loss 0.4138 (0.4176)
2022-11-02 23:39:08,156:INFO: Batch:  8/31	Total Loss 0.3655 (0.4117)
2022-11-02 23:39:08,412:INFO: Batch:  9/31	Total Loss 0.4056 (0.4111)
2022-11-02 23:39:08,670:INFO: Batch: 10/31	Total Loss 0.4089 (0.4109)
2022-11-02 23:39:08,930:INFO: Batch: 11/31	Total Loss 0.3804 (0.4080)
2022-11-02 23:39:09,191:INFO: Batch: 12/31	Total Loss 0.4071 (0.4079)
2022-11-02 23:39:09,453:INFO: Batch: 13/31	Total Loss 0.4491 (0.4107)
2022-11-02 23:39:09,715:INFO: Batch: 14/31	Total Loss 0.3960 (0.4097)
2022-11-02 23:39:09,976:INFO: Batch: 15/31	Total Loss 0.3673 (0.4073)
2022-11-02 23:39:10,236:INFO: Batch: 16/31	Total Loss 0.3781 (0.4057)
2022-11-02 23:39:10,496:INFO: Batch: 17/31	Total Loss 0.4245 (0.4067)
2022-11-02 23:39:10,756:INFO: Batch: 18/31	Total Loss 0.4264 (0.4075)
2022-11-02 23:39:11,018:INFO: Batch: 19/31	Total Loss 0.4117 (0.4077)
2022-11-02 23:39:11,276:INFO: Batch: 20/31	Total Loss 0.4087 (0.4078)
2022-11-02 23:39:11,534:INFO: Batch: 21/31	Total Loss 0.3827 (0.4066)
2022-11-02 23:39:11,793:INFO: Batch: 22/31	Total Loss 0.3973 (0.4061)
2022-11-02 23:39:12,052:INFO: Batch: 23/31	Total Loss 0.3557 (0.4042)
2022-11-02 23:39:12,311:INFO: Batch: 24/31	Total Loss 0.4062 (0.4043)
2022-11-02 23:39:12,570:INFO: Batch: 25/31	Total Loss 0.4037 (0.4043)
2022-11-02 23:39:12,830:INFO: Batch: 26/31	Total Loss 0.4055 (0.4043)
2022-11-02 23:39:13,091:INFO: Batch: 27/31	Total Loss 0.4243 (0.4051)
2022-11-02 23:39:13,351:INFO: Batch: 28/31	Total Loss 0.3863 (0.4045)
2022-11-02 23:39:13,613:INFO: Batch: 29/31	Total Loss 0.3866 (0.4038)
2022-11-02 23:39:13,732:INFO: Batch: 30/31	Total Loss 0.1764 (0.4015)
2022-11-02 23:39:13,893:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_166.pth.tar
2022-11-02 23:39:13,893:INFO: 
===> EPOCH: 167 (P2)
2022-11-02 23:39:13,893:INFO: - Computing loss (training)
2022-11-02 23:39:14,770:INFO: Batch:  0/31	Total Loss 0.4687 (0.4687)
2022-11-02 23:39:15,028:INFO: Batch:  1/31	Total Loss 0.3935 (0.4322)
2022-11-02 23:39:15,287:INFO: Batch:  2/31	Total Loss 0.4647 (0.4426)
2022-11-02 23:39:15,539:INFO: Batch:  3/31	Total Loss 0.3087 (0.4082)
2022-11-02 23:39:15,801:INFO: Batch:  4/31	Total Loss 0.3478 (0.3957)
2022-11-02 23:39:16,060:INFO: Batch:  5/31	Total Loss 0.3864 (0.3940)
2022-11-02 23:39:16,315:INFO: Batch:  6/31	Total Loss 0.3484 (0.3869)
2022-11-02 23:39:16,568:INFO: Batch:  7/31	Total Loss 0.4466 (0.3936)
2022-11-02 23:39:16,823:INFO: Batch:  8/31	Total Loss 0.3651 (0.3906)
2022-11-02 23:39:17,080:INFO: Batch:  9/31	Total Loss 0.3899 (0.3905)
2022-11-02 23:39:17,335:INFO: Batch: 10/31	Total Loss 0.3826 (0.3899)
2022-11-02 23:39:17,591:INFO: Batch: 11/31	Total Loss 0.3816 (0.3892)
2022-11-02 23:39:17,850:INFO: Batch: 12/31	Total Loss 0.3547 (0.3862)
2022-11-02 23:39:18,110:INFO: Batch: 13/31	Total Loss 0.3434 (0.3832)
2022-11-02 23:39:18,374:INFO: Batch: 14/31	Total Loss 0.3651 (0.3821)
2022-11-02 23:39:18,634:INFO: Batch: 15/31	Total Loss 0.3900 (0.3826)
2022-11-02 23:39:18,893:INFO: Batch: 16/31	Total Loss 0.3543 (0.3809)
2022-11-02 23:39:19,152:INFO: Batch: 17/31	Total Loss 0.3624 (0.3798)
2022-11-02 23:39:19,420:INFO: Batch: 18/31	Total Loss 0.3399 (0.3777)
2022-11-02 23:39:19,681:INFO: Batch: 19/31	Total Loss 0.3573 (0.3766)
2022-11-02 23:39:19,940:INFO: Batch: 20/31	Total Loss 0.4251 (0.3788)
2022-11-02 23:39:20,198:INFO: Batch: 21/31	Total Loss 0.4215 (0.3804)
2022-11-02 23:39:20,457:INFO: Batch: 22/31	Total Loss 0.3365 (0.3784)
2022-11-02 23:39:20,713:INFO: Batch: 23/31	Total Loss 0.3676 (0.3780)
2022-11-02 23:39:20,971:INFO: Batch: 24/31	Total Loss 0.3835 (0.3782)
2022-11-02 23:39:21,230:INFO: Batch: 25/31	Total Loss 0.3554 (0.3773)
2022-11-02 23:39:21,489:INFO: Batch: 26/31	Total Loss 0.3344 (0.3755)
2022-11-02 23:39:21,748:INFO: Batch: 27/31	Total Loss 0.4217 (0.3770)
2022-11-02 23:39:22,006:INFO: Batch: 28/31	Total Loss 0.3535 (0.3762)
2022-11-02 23:39:22,266:INFO: Batch: 29/31	Total Loss 0.3413 (0.3751)
2022-11-02 23:39:22,384:INFO: Batch: 30/31	Total Loss 0.1465 (0.3729)
2022-11-02 23:39:22,545:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_167.pth.tar
2022-11-02 23:39:22,545:INFO: 
===> EPOCH: 168 (P2)
2022-11-02 23:39:22,546:INFO: - Computing loss (training)
2022-11-02 23:39:23,440:INFO: Batch:  0/31	Total Loss 0.3332 (0.3332)
2022-11-02 23:39:23,700:INFO: Batch:  1/31	Total Loss 0.3719 (0.3520)
2022-11-02 23:39:23,962:INFO: Batch:  2/31	Total Loss 0.3389 (0.3475)
2022-11-02 23:39:24,220:INFO: Batch:  3/31	Total Loss 0.3565 (0.3496)
2022-11-02 23:39:24,478:INFO: Batch:  4/31	Total Loss 0.3277 (0.3451)
2022-11-02 23:39:24,738:INFO: Batch:  5/31	Total Loss 0.3194 (0.3407)
2022-11-02 23:39:24,994:INFO: Batch:  6/31	Total Loss 0.3035 (0.3348)
2022-11-02 23:39:25,247:INFO: Batch:  7/31	Total Loss 0.3407 (0.3356)
2022-11-02 23:39:25,502:INFO: Batch:  8/31	Total Loss 0.3518 (0.3375)
2022-11-02 23:39:25,758:INFO: Batch:  9/31	Total Loss 0.2886 (0.3331)
2022-11-02 23:39:26,019:INFO: Batch: 10/31	Total Loss 0.3239 (0.3323)
2022-11-02 23:39:26,275:INFO: Batch: 11/31	Total Loss 0.2773 (0.3277)
2022-11-02 23:39:26,534:INFO: Batch: 12/31	Total Loss 0.3209 (0.3272)
2022-11-02 23:39:26,794:INFO: Batch: 13/31	Total Loss 0.3676 (0.3297)
2022-11-02 23:39:27,054:INFO: Batch: 14/31	Total Loss 0.3099 (0.3283)
2022-11-02 23:39:27,314:INFO: Batch: 15/31	Total Loss 0.3382 (0.3289)
2022-11-02 23:39:27,575:INFO: Batch: 16/31	Total Loss 0.3100 (0.3278)
2022-11-02 23:39:27,835:INFO: Batch: 17/31	Total Loss 0.3393 (0.3284)
2022-11-02 23:39:28,096:INFO: Batch: 18/31	Total Loss 0.3396 (0.3290)
2022-11-02 23:39:28,355:INFO: Batch: 19/31	Total Loss 0.3165 (0.3284)
2022-11-02 23:39:28,615:INFO: Batch: 20/31	Total Loss 0.2995 (0.3270)
2022-11-02 23:39:28,873:INFO: Batch: 21/31	Total Loss 0.2851 (0.3251)
2022-11-02 23:39:29,134:INFO: Batch: 22/31	Total Loss 0.2947 (0.3237)
2022-11-02 23:39:29,392:INFO: Batch: 23/31	Total Loss 0.4317 (0.3281)
2022-11-02 23:39:29,655:INFO: Batch: 24/31	Total Loss 0.2673 (0.3257)
2022-11-02 23:39:29,913:INFO: Batch: 25/31	Total Loss 0.3011 (0.3248)
2022-11-02 23:39:30,170:INFO: Batch: 26/31	Total Loss 0.2947 (0.3238)
2022-11-02 23:39:30,428:INFO: Batch: 27/31	Total Loss 0.3411 (0.3244)
2022-11-02 23:39:30,686:INFO: Batch: 28/31	Total Loss 0.3215 (0.3243)
2022-11-02 23:39:30,943:INFO: Batch: 29/31	Total Loss 0.3003 (0.3235)
2022-11-02 23:39:31,062:INFO: Batch: 30/31	Total Loss 0.1104 (0.3214)
2022-11-02 23:39:31,224:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_168.pth.tar
2022-11-02 23:39:31,224:INFO: 
===> EPOCH: 169 (P2)
2022-11-02 23:39:31,224:INFO: - Computing loss (training)
2022-11-02 23:39:32,087:INFO: Batch:  0/31	Total Loss 0.2677 (0.2677)
2022-11-02 23:39:32,354:INFO: Batch:  1/31	Total Loss 0.3166 (0.2938)
2022-11-02 23:39:32,619:INFO: Batch:  2/31	Total Loss 0.3324 (0.3070)
2022-11-02 23:39:32,888:INFO: Batch:  3/31	Total Loss 0.3007 (0.3054)
2022-11-02 23:39:33,151:INFO: Batch:  4/31	Total Loss 0.3027 (0.3049)
2022-11-02 23:39:33,415:INFO: Batch:  5/31	Total Loss 0.2916 (0.3027)
2022-11-02 23:39:33,675:INFO: Batch:  6/31	Total Loss 0.3118 (0.3041)
2022-11-02 23:39:33,933:INFO: Batch:  7/31	Total Loss 0.3979 (0.3147)
2022-11-02 23:39:34,192:INFO: Batch:  8/31	Total Loss 0.2837 (0.3111)
2022-11-02 23:39:34,451:INFO: Batch:  9/31	Total Loss 0.2903 (0.3091)
2022-11-02 23:39:34,710:INFO: Batch: 10/31	Total Loss 0.2826 (0.3066)
2022-11-02 23:39:34,969:INFO: Batch: 11/31	Total Loss 0.2553 (0.3024)
2022-11-02 23:39:35,230:INFO: Batch: 12/31	Total Loss 0.3085 (0.3029)
2022-11-02 23:39:35,491:INFO: Batch: 13/31	Total Loss 0.2595 (0.2997)
2022-11-02 23:39:35,753:INFO: Batch: 14/31	Total Loss 0.2643 (0.2971)
2022-11-02 23:39:36,015:INFO: Batch: 15/31	Total Loss 0.2907 (0.2967)
2022-11-02 23:39:36,276:INFO: Batch: 16/31	Total Loss 0.3120 (0.2976)
2022-11-02 23:39:36,538:INFO: Batch: 17/31	Total Loss 0.3379 (0.2997)
2022-11-02 23:39:36,801:INFO: Batch: 18/31	Total Loss 0.2721 (0.2982)
2022-11-02 23:39:37,062:INFO: Batch: 19/31	Total Loss 0.2698 (0.2968)
2022-11-02 23:39:37,324:INFO: Batch: 20/31	Total Loss 0.2657 (0.2953)
2022-11-02 23:39:37,584:INFO: Batch: 21/31	Total Loss 0.2812 (0.2947)
2022-11-02 23:39:37,846:INFO: Batch: 22/31	Total Loss 0.2898 (0.2945)
2022-11-02 23:39:38,107:INFO: Batch: 23/31	Total Loss 0.2546 (0.2930)
2022-11-02 23:39:38,369:INFO: Batch: 24/31	Total Loss 0.2729 (0.2922)
2022-11-02 23:39:38,630:INFO: Batch: 25/31	Total Loss 0.2795 (0.2917)
2022-11-02 23:39:38,890:INFO: Batch: 26/31	Total Loss 0.3016 (0.2921)
2022-11-02 23:39:39,151:INFO: Batch: 27/31	Total Loss 0.2917 (0.2921)
2022-11-02 23:39:39,412:INFO: Batch: 28/31	Total Loss 0.3072 (0.2926)
2022-11-02 23:39:39,677:INFO: Batch: 29/31	Total Loss 0.2683 (0.2917)
2022-11-02 23:39:39,796:INFO: Batch: 30/31	Total Loss 0.1131 (0.2901)
2022-11-02 23:39:39,959:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_169.pth.tar
2022-11-02 23:39:39,959:INFO: 
===> EPOCH: 170 (P2)
2022-11-02 23:39:39,959:INFO: - Computing loss (training)
2022-11-02 23:39:40,821:INFO: Batch:  0/31	Total Loss 0.2849 (0.2849)
2022-11-02 23:39:41,088:INFO: Batch:  1/31	Total Loss 0.2616 (0.2732)
2022-11-02 23:39:41,352:INFO: Batch:  2/31	Total Loss 0.2799 (0.2752)
2022-11-02 23:39:41,617:INFO: Batch:  3/31	Total Loss 0.2873 (0.2778)
2022-11-02 23:39:41,878:INFO: Batch:  4/31	Total Loss 0.2628 (0.2748)
2022-11-02 23:39:42,141:INFO: Batch:  5/31	Total Loss 0.3121 (0.2814)
2022-11-02 23:39:42,400:INFO: Batch:  6/31	Total Loss 0.2669 (0.2793)
2022-11-02 23:39:42,735:INFO: Batch:  7/31	Total Loss 0.2899 (0.2806)
2022-11-02 23:39:42,994:INFO: Batch:  8/31	Total Loss 0.2593 (0.2784)
2022-11-02 23:39:43,254:INFO: Batch:  9/31	Total Loss 0.2600 (0.2766)
2022-11-02 23:39:43,513:INFO: Batch: 10/31	Total Loss 0.2670 (0.2758)
2022-11-02 23:39:43,778:INFO: Batch: 11/31	Total Loss 0.2688 (0.2752)
2022-11-02 23:39:44,050:INFO: Batch: 12/31	Total Loss 0.2578 (0.2737)
2022-11-02 23:39:44,317:INFO: Batch: 13/31	Total Loss 0.2775 (0.2740)
2022-11-02 23:39:44,584:INFO: Batch: 14/31	Total Loss 0.2960 (0.2756)
2022-11-02 23:39:44,851:INFO: Batch: 15/31	Total Loss 0.2593 (0.2745)
2022-11-02 23:39:45,118:INFO: Batch: 16/31	Total Loss 0.2900 (0.2754)
2022-11-02 23:39:45,388:INFO: Batch: 17/31	Total Loss 0.2526 (0.2741)
2022-11-02 23:39:45,656:INFO: Batch: 18/31	Total Loss 0.2500 (0.2729)
2022-11-02 23:39:45,927:INFO: Batch: 19/31	Total Loss 0.3510 (0.2764)
2022-11-02 23:39:46,191:INFO: Batch: 20/31	Total Loss 0.2577 (0.2756)
2022-11-02 23:39:46,459:INFO: Batch: 21/31	Total Loss 0.2620 (0.2749)
2022-11-02 23:39:46,744:INFO: Batch: 22/31	Total Loss 0.2394 (0.2733)
2022-11-02 23:39:47,060:INFO: Batch: 23/31	Total Loss 0.2557 (0.2725)
2022-11-02 23:39:47,574:INFO: Batch: 24/31	Total Loss 0.2644 (0.2722)
2022-11-02 23:39:47,913:INFO: Batch: 25/31	Total Loss 0.2646 (0.2719)
2022-11-02 23:39:48,176:INFO: Batch: 26/31	Total Loss 0.2553 (0.2713)
2022-11-02 23:39:48,442:INFO: Batch: 27/31	Total Loss 0.2290 (0.2696)
2022-11-02 23:39:48,764:INFO: Batch: 28/31	Total Loss 0.2401 (0.2687)
2022-11-02 23:39:49,084:INFO: Batch: 29/31	Total Loss 0.2808 (0.2691)
2022-11-02 23:39:49,213:INFO: Batch: 30/31	Total Loss 0.0980 (0.2673)
2022-11-02 23:39:49,366:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_170.pth.tar
2022-11-02 23:39:49,366:INFO: 
===> EPOCH: 171 (P2)
2022-11-02 23:39:49,367:INFO: - Computing loss (training)
2022-11-02 23:39:50,240:INFO: Batch:  0/31	Total Loss 0.2377 (0.2377)
2022-11-02 23:39:50,508:INFO: Batch:  1/31	Total Loss 0.2584 (0.2468)
2022-11-02 23:39:50,768:INFO: Batch:  2/31	Total Loss 0.2359 (0.2431)
2022-11-02 23:39:51,024:INFO: Batch:  3/31	Total Loss 0.2857 (0.2530)
2022-11-02 23:39:51,281:INFO: Batch:  4/31	Total Loss 0.2409 (0.2503)
2022-11-02 23:39:51,537:INFO: Batch:  5/31	Total Loss 0.2591 (0.2518)
2022-11-02 23:39:51,797:INFO: Batch:  6/31	Total Loss 0.2878 (0.2567)
2022-11-02 23:39:52,056:INFO: Batch:  7/31	Total Loss 0.2816 (0.2598)
2022-11-02 23:39:52,315:INFO: Batch:  8/31	Total Loss 0.2304 (0.2563)
2022-11-02 23:39:52,568:INFO: Batch:  9/31	Total Loss 0.2309 (0.2542)
2022-11-02 23:39:52,825:INFO: Batch: 10/31	Total Loss 0.2401 (0.2528)
2022-11-02 23:39:53,082:INFO: Batch: 11/31	Total Loss 0.2400 (0.2517)
2022-11-02 23:39:53,341:INFO: Batch: 12/31	Total Loss 0.2558 (0.2520)
2022-11-02 23:39:53,600:INFO: Batch: 13/31	Total Loss 0.2520 (0.2520)
2022-11-02 23:39:53,864:INFO: Batch: 14/31	Total Loss 0.2543 (0.2522)
2022-11-02 23:39:54,125:INFO: Batch: 15/31	Total Loss 0.2442 (0.2517)
2022-11-02 23:39:54,384:INFO: Batch: 16/31	Total Loss 0.2317 (0.2506)
2022-11-02 23:39:54,644:INFO: Batch: 17/31	Total Loss 0.2489 (0.2505)
2022-11-02 23:39:54,903:INFO: Batch: 18/31	Total Loss 0.4296 (0.2591)
2022-11-02 23:39:55,162:INFO: Batch: 19/31	Total Loss 0.2369 (0.2580)
2022-11-02 23:39:55,420:INFO: Batch: 20/31	Total Loss 0.2291 (0.2565)
2022-11-02 23:39:55,679:INFO: Batch: 21/31	Total Loss 0.2338 (0.2556)
2022-11-02 23:39:55,943:INFO: Batch: 22/31	Total Loss 0.2337 (0.2546)
2022-11-02 23:39:56,207:INFO: Batch: 23/31	Total Loss 0.2527 (0.2545)
2022-11-02 23:39:56,471:INFO: Batch: 24/31	Total Loss 0.2369 (0.2539)
2022-11-02 23:39:56,735:INFO: Batch: 25/31	Total Loss 0.2396 (0.2533)
2022-11-02 23:39:57,000:INFO: Batch: 26/31	Total Loss 0.2374 (0.2527)
2022-11-02 23:39:57,265:INFO: Batch: 27/31	Total Loss 0.2660 (0.2532)
2022-11-02 23:39:57,525:INFO: Batch: 28/31	Total Loss 0.2277 (0.2523)
2022-11-02 23:39:57,783:INFO: Batch: 29/31	Total Loss 0.2241 (0.2514)
2022-11-02 23:39:57,901:INFO: Batch: 30/31	Total Loss 0.0854 (0.2496)
2022-11-02 23:39:58,050:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_171.pth.tar
2022-11-02 23:39:58,050:INFO: 
===> EPOCH: 172 (P2)
2022-11-02 23:39:58,051:INFO: - Computing loss (training)
2022-11-02 23:39:58,946:INFO: Batch:  0/31	Total Loss 0.2467 (0.2467)
2022-11-02 23:39:59,204:INFO: Batch:  1/31	Total Loss 0.2196 (0.2326)
2022-11-02 23:39:59,464:INFO: Batch:  2/31	Total Loss 0.2464 (0.2370)
2022-11-02 23:39:59,715:INFO: Batch:  3/31	Total Loss 0.2302 (0.2354)
2022-11-02 23:39:59,968:INFO: Batch:  4/31	Total Loss 0.2355 (0.2355)
2022-11-02 23:40:00,231:INFO: Batch:  5/31	Total Loss 0.2404 (0.2362)
2022-11-02 23:40:00,489:INFO: Batch:  6/31	Total Loss 0.2228 (0.2343)
2022-11-02 23:40:00,746:INFO: Batch:  7/31	Total Loss 0.2482 (0.2359)
2022-11-02 23:40:01,004:INFO: Batch:  8/31	Total Loss 0.2455 (0.2370)
2022-11-02 23:40:01,264:INFO: Batch:  9/31	Total Loss 0.2328 (0.2365)
2022-11-02 23:40:01,526:INFO: Batch: 10/31	Total Loss 0.2499 (0.2376)
2022-11-02 23:40:01,787:INFO: Batch: 11/31	Total Loss 0.2161 (0.2360)
2022-11-02 23:40:02,045:INFO: Batch: 12/31	Total Loss 0.2189 (0.2347)
2022-11-02 23:40:02,304:INFO: Batch: 13/31	Total Loss 0.2168 (0.2334)
2022-11-02 23:40:02,562:INFO: Batch: 14/31	Total Loss 0.2029 (0.2312)
2022-11-02 23:40:02,820:INFO: Batch: 15/31	Total Loss 0.2306 (0.2312)
2022-11-02 23:40:03,088:INFO: Batch: 16/31	Total Loss 0.2242 (0.2308)
2022-11-02 23:40:03,366:INFO: Batch: 17/31	Total Loss 0.2290 (0.2307)
2022-11-02 23:40:03,646:INFO: Batch: 18/31	Total Loss 0.2163 (0.2299)
2022-11-02 23:40:03,918:INFO: Batch: 19/31	Total Loss 0.2132 (0.2290)
2022-11-02 23:40:04,175:INFO: Batch: 20/31	Total Loss 0.2398 (0.2295)
2022-11-02 23:40:04,437:INFO: Batch: 21/31	Total Loss 0.1904 (0.2277)
2022-11-02 23:40:04,709:INFO: Batch: 22/31	Total Loss 0.2682 (0.2294)
2022-11-02 23:40:04,984:INFO: Batch: 23/31	Total Loss 0.2129 (0.2287)
2022-11-02 23:40:05,257:INFO: Batch: 24/31	Total Loss 0.2067 (0.2279)
2022-11-02 23:40:05,525:INFO: Batch: 25/31	Total Loss 0.2303 (0.2280)
2022-11-02 23:40:05,800:INFO: Batch: 26/31	Total Loss 0.2177 (0.2276)
2022-11-02 23:40:06,068:INFO: Batch: 27/31	Total Loss 0.1863 (0.2261)
2022-11-02 23:40:06,334:INFO: Batch: 28/31	Total Loss 0.2116 (0.2256)
2022-11-02 23:40:06,598:INFO: Batch: 29/31	Total Loss 0.2218 (0.2255)
2022-11-02 23:40:06,722:INFO: Batch: 30/31	Total Loss 0.0924 (0.2242)
2022-11-02 23:40:06,873:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_172.pth.tar
2022-11-02 23:40:06,873:INFO: 
===> EPOCH: 173 (P2)
2022-11-02 23:40:06,873:INFO: - Computing loss (training)
2022-11-02 23:40:07,741:INFO: Batch:  0/31	Total Loss 0.2043 (0.2043)
2022-11-02 23:40:08,002:INFO: Batch:  1/31	Total Loss 0.2200 (0.2120)
2022-11-02 23:40:08,264:INFO: Batch:  2/31	Total Loss 0.2050 (0.2095)
2022-11-02 23:40:08,555:INFO: Batch:  3/31	Total Loss 0.2205 (0.2123)
2022-11-02 23:40:08,905:INFO: Batch:  4/31	Total Loss 0.2578 (0.2212)
2022-11-02 23:40:09,312:INFO: Batch:  5/31	Total Loss 0.2006 (0.2181)
2022-11-02 23:40:09,604:INFO: Batch:  6/31	Total Loss 0.2508 (0.2230)
2022-11-02 23:40:09,901:INFO: Batch:  7/31	Total Loss 0.2411 (0.2253)
2022-11-02 23:40:10,162:INFO: Batch:  8/31	Total Loss 0.2185 (0.2246)
2022-11-02 23:40:10,425:INFO: Batch:  9/31	Total Loss 0.2090 (0.2230)
2022-11-02 23:40:10,694:INFO: Batch: 10/31	Total Loss 0.2355 (0.2242)
2022-11-02 23:40:10,965:INFO: Batch: 11/31	Total Loss 0.1990 (0.2220)
2022-11-02 23:40:11,239:INFO: Batch: 12/31	Total Loss 0.2245 (0.2222)
2022-11-02 23:40:11,501:INFO: Batch: 13/31	Total Loss 0.2018 (0.2208)
2022-11-02 23:40:11,760:INFO: Batch: 14/31	Total Loss 0.2261 (0.2212)
2022-11-02 23:40:12,019:INFO: Batch: 15/31	Total Loss 0.1981 (0.2197)
2022-11-02 23:40:12,280:INFO: Batch: 16/31	Total Loss 0.1819 (0.2176)
2022-11-02 23:40:12,546:INFO: Batch: 17/31	Total Loss 0.2057 (0.2169)
2022-11-02 23:40:12,834:INFO: Batch: 18/31	Total Loss 0.1854 (0.2151)
2022-11-02 23:40:13,093:INFO: Batch: 19/31	Total Loss 0.2180 (0.2153)
2022-11-02 23:40:13,354:INFO: Batch: 20/31	Total Loss 0.1939 (0.2143)
2022-11-02 23:40:13,613:INFO: Batch: 21/31	Total Loss 0.1856 (0.2130)
2022-11-02 23:40:13,878:INFO: Batch: 22/31	Total Loss 0.2005 (0.2124)
2022-11-02 23:40:14,136:INFO: Batch: 23/31	Total Loss 0.2156 (0.2126)
2022-11-02 23:40:14,394:INFO: Batch: 24/31	Total Loss 0.1926 (0.2117)
2022-11-02 23:40:14,652:INFO: Batch: 25/31	Total Loss 0.2449 (0.2129)
2022-11-02 23:40:14,913:INFO: Batch: 26/31	Total Loss 0.2157 (0.2130)
2022-11-02 23:40:15,254:INFO: Batch: 27/31	Total Loss 0.1785 (0.2116)
2022-11-02 23:40:15,541:INFO: Batch: 28/31	Total Loss 0.2273 (0.2122)
2022-11-02 23:40:15,827:INFO: Batch: 29/31	Total Loss 0.2120 (0.2122)
2022-11-02 23:40:15,962:INFO: Batch: 30/31	Total Loss 0.0746 (0.2107)
2022-11-02 23:40:16,126:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_173.pth.tar
2022-11-02 23:40:16,126:INFO: 
===> EPOCH: 174 (P2)
2022-11-02 23:40:16,127:INFO: - Computing loss (training)
2022-11-02 23:40:17,061:INFO: Batch:  0/31	Total Loss 0.1738 (0.1738)
2022-11-02 23:40:17,328:INFO: Batch:  1/31	Total Loss 0.1941 (0.1841)
2022-11-02 23:40:17,589:INFO: Batch:  2/31	Total Loss 0.2712 (0.2133)
2022-11-02 23:40:17,857:INFO: Batch:  3/31	Total Loss 0.1936 (0.2088)
2022-11-02 23:40:18,174:INFO: Batch:  4/31	Total Loss 0.1942 (0.2057)
2022-11-02 23:40:18,529:INFO: Batch:  5/31	Total Loss 0.1867 (0.2022)
2022-11-02 23:40:19,075:INFO: Batch:  6/31	Total Loss 0.2123 (0.2037)
2022-11-02 23:40:19,402:INFO: Batch:  7/31	Total Loss 0.1892 (0.2017)
2022-11-02 23:40:19,691:INFO: Batch:  8/31	Total Loss 0.2085 (0.2024)
2022-11-02 23:40:19,999:INFO: Batch:  9/31	Total Loss 0.1943 (0.2016)
2022-11-02 23:40:20,306:INFO: Batch: 10/31	Total Loss 0.2173 (0.2031)
2022-11-02 23:40:20,585:INFO: Batch: 11/31	Total Loss 0.1859 (0.2016)
2022-11-02 23:40:20,862:INFO: Batch: 12/31	Total Loss 0.2002 (0.2015)
2022-11-02 23:40:21,133:INFO: Batch: 13/31	Total Loss 0.2185 (0.2027)
2022-11-02 23:40:21,401:INFO: Batch: 14/31	Total Loss 0.1926 (0.2020)
2022-11-02 23:40:21,670:INFO: Batch: 15/31	Total Loss 0.2163 (0.2029)
2022-11-02 23:40:21,943:INFO: Batch: 16/31	Total Loss 0.2090 (0.2032)
2022-11-02 23:40:22,216:INFO: Batch: 17/31	Total Loss 0.1969 (0.2029)
2022-11-02 23:40:22,495:INFO: Batch: 18/31	Total Loss 0.2002 (0.2027)
2022-11-02 23:40:22,779:INFO: Batch: 19/31	Total Loss 0.1900 (0.2020)
2022-11-02 23:40:23,082:INFO: Batch: 20/31	Total Loss 0.2003 (0.2019)
2022-11-02 23:40:23,357:INFO: Batch: 21/31	Total Loss 0.1959 (0.2016)
2022-11-02 23:40:23,621:INFO: Batch: 22/31	Total Loss 0.1995 (0.2015)
2022-11-02 23:40:23,895:INFO: Batch: 23/31	Total Loss 0.1778 (0.2005)
2022-11-02 23:40:24,200:INFO: Batch: 24/31	Total Loss 0.2027 (0.2006)
2022-11-02 23:40:24,469:INFO: Batch: 25/31	Total Loss 0.1748 (0.1996)
2022-11-02 23:40:24,741:INFO: Batch: 26/31	Total Loss 0.1782 (0.1989)
2022-11-02 23:40:25,021:INFO: Batch: 27/31	Total Loss 0.1819 (0.1983)
2022-11-02 23:40:25,315:INFO: Batch: 28/31	Total Loss 0.1724 (0.1974)
2022-11-02 23:40:25,602:INFO: Batch: 29/31	Total Loss 0.1790 (0.1967)
2022-11-02 23:40:25,728:INFO: Batch: 30/31	Total Loss 0.0777 (0.1952)
2022-11-02 23:40:25,909:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_174.pth.tar
2022-11-02 23:40:25,910:INFO: 
===> EPOCH: 175 (P2)
2022-11-02 23:40:25,910:INFO: - Computing loss (training)
2022-11-02 23:40:27,075:INFO: Batch:  0/31	Total Loss 0.1758 (0.1758)
2022-11-02 23:40:27,383:INFO: Batch:  1/31	Total Loss 0.1812 (0.1786)
2022-11-02 23:40:27,660:INFO: Batch:  2/31	Total Loss 0.1940 (0.1837)
2022-11-02 23:40:27,997:INFO: Batch:  3/31	Total Loss 0.1938 (0.1862)
2022-11-02 23:40:28,322:INFO: Batch:  4/31	Total Loss 0.1769 (0.1843)
2022-11-02 23:40:28,604:INFO: Batch:  5/31	Total Loss 0.2027 (0.1873)
2022-11-02 23:40:28,873:INFO: Batch:  6/31	Total Loss 0.1953 (0.1884)
2022-11-02 23:40:29,143:INFO: Batch:  7/31	Total Loss 0.1882 (0.1884)
2022-11-02 23:40:29,409:INFO: Batch:  8/31	Total Loss 0.1669 (0.1861)
2022-11-02 23:40:29,677:INFO: Batch:  9/31	Total Loss 0.1662 (0.1842)
2022-11-02 23:40:29,948:INFO: Batch: 10/31	Total Loss 0.2062 (0.1863)
2022-11-02 23:40:30,216:INFO: Batch: 11/31	Total Loss 0.2063 (0.1878)
2022-11-02 23:40:30,489:INFO: Batch: 12/31	Total Loss 0.1901 (0.1880)
2022-11-02 23:40:30,764:INFO: Batch: 13/31	Total Loss 0.1911 (0.1883)
2022-11-02 23:40:31,036:INFO: Batch: 14/31	Total Loss 0.2091 (0.1896)
2022-11-02 23:40:31,308:INFO: Batch: 15/31	Total Loss 0.1975 (0.1901)
2022-11-02 23:40:31,581:INFO: Batch: 16/31	Total Loss 0.1789 (0.1894)
2022-11-02 23:40:31,932:INFO: Batch: 17/31	Total Loss 0.1920 (0.1895)
2022-11-02 23:40:32,206:INFO: Batch: 18/31	Total Loss 0.2065 (0.1904)
2022-11-02 23:40:32,477:INFO: Batch: 19/31	Total Loss 0.1859 (0.1902)
2022-11-02 23:40:32,764:INFO: Batch: 20/31	Total Loss 0.2136 (0.1912)
2022-11-02 23:40:33,037:INFO: Batch: 21/31	Total Loss 0.1930 (0.1913)
2022-11-02 23:40:33,311:INFO: Batch: 22/31	Total Loss 0.1756 (0.1905)
2022-11-02 23:40:33,584:INFO: Batch: 23/31	Total Loss 0.1896 (0.1905)
2022-11-02 23:40:33,856:INFO: Batch: 24/31	Total Loss 0.1710 (0.1897)
2022-11-02 23:40:34,129:INFO: Batch: 25/31	Total Loss 0.2146 (0.1907)
2022-11-02 23:40:34,397:INFO: Batch: 26/31	Total Loss 0.1919 (0.1908)
2022-11-02 23:40:34,667:INFO: Batch: 27/31	Total Loss 0.1673 (0.1900)
2022-11-02 23:40:34,937:INFO: Batch: 28/31	Total Loss 0.2151 (0.1908)
2022-11-02 23:40:35,223:INFO: Batch: 29/31	Total Loss 0.1782 (0.1904)
2022-11-02 23:40:35,368:INFO: Batch: 30/31	Total Loss 0.0822 (0.1892)
2022-11-02 23:40:35,552:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_175.pth.tar
2022-11-02 23:40:35,553:INFO: 
===> EPOCH: 176 (P2)
2022-11-02 23:40:35,553:INFO: - Computing loss (training)
2022-11-02 23:40:36,476:INFO: Batch:  0/31	Total Loss 0.1690 (0.1690)
2022-11-02 23:40:36,742:INFO: Batch:  1/31	Total Loss 0.1633 (0.1661)
2022-11-02 23:40:37,013:INFO: Batch:  2/31	Total Loss 0.1712 (0.1678)
2022-11-02 23:40:37,280:INFO: Batch:  3/31	Total Loss 0.1692 (0.1681)
2022-11-02 23:40:37,538:INFO: Batch:  4/31	Total Loss 0.1673 (0.1680)
2022-11-02 23:40:37,798:INFO: Batch:  5/31	Total Loss 0.1634 (0.1673)
2022-11-02 23:40:38,056:INFO: Batch:  6/31	Total Loss 0.2358 (0.1770)
2022-11-02 23:40:38,310:INFO: Batch:  7/31	Total Loss 0.2160 (0.1817)
2022-11-02 23:40:38,565:INFO: Batch:  8/31	Total Loss 0.1462 (0.1775)
2022-11-02 23:40:38,819:INFO: Batch:  9/31	Total Loss 0.1782 (0.1776)
2022-11-02 23:40:39,074:INFO: Batch: 10/31	Total Loss 0.1925 (0.1789)
2022-11-02 23:40:39,330:INFO: Batch: 11/31	Total Loss 0.1728 (0.1783)
2022-11-02 23:40:39,591:INFO: Batch: 12/31	Total Loss 0.1820 (0.1786)
2022-11-02 23:40:39,851:INFO: Batch: 13/31	Total Loss 0.1772 (0.1785)
2022-11-02 23:40:40,111:INFO: Batch: 14/31	Total Loss 0.1740 (0.1782)
2022-11-02 23:40:40,371:INFO: Batch: 15/31	Total Loss 0.1793 (0.1783)
2022-11-02 23:40:40,629:INFO: Batch: 16/31	Total Loss 0.1679 (0.1777)
2022-11-02 23:40:40,889:INFO: Batch: 17/31	Total Loss 0.1490 (0.1761)
2022-11-02 23:40:41,149:INFO: Batch: 18/31	Total Loss 0.1914 (0.1768)
2022-11-02 23:40:41,407:INFO: Batch: 19/31	Total Loss 0.1755 (0.1767)
2022-11-02 23:40:41,665:INFO: Batch: 20/31	Total Loss 0.1982 (0.1778)
2022-11-02 23:40:41,923:INFO: Batch: 21/31	Total Loss 0.1606 (0.1771)
2022-11-02 23:40:42,181:INFO: Batch: 22/31	Total Loss 0.1782 (0.1772)
2022-11-02 23:40:42,439:INFO: Batch: 23/31	Total Loss 0.1985 (0.1781)
2022-11-02 23:40:42,698:INFO: Batch: 24/31	Total Loss 0.1598 (0.1774)
2022-11-02 23:40:42,956:INFO: Batch: 25/31	Total Loss 0.1711 (0.1771)
2022-11-02 23:40:43,213:INFO: Batch: 26/31	Total Loss 0.2082 (0.1784)
2022-11-02 23:40:43,471:INFO: Batch: 27/31	Total Loss 0.1809 (0.1785)
2022-11-02 23:40:43,729:INFO: Batch: 28/31	Total Loss 0.1461 (0.1773)
2022-11-02 23:40:43,986:INFO: Batch: 29/31	Total Loss 0.1965 (0.1779)
2022-11-02 23:40:44,105:INFO: Batch: 30/31	Total Loss 0.0646 (0.1770)
2022-11-02 23:40:44,267:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_176.pth.tar
2022-11-02 23:40:44,267:INFO: 
===> EPOCH: 177 (P2)
2022-11-02 23:40:44,267:INFO: - Computing loss (training)
2022-11-02 23:40:45,137:INFO: Batch:  0/31	Total Loss 0.1875 (0.1875)
2022-11-02 23:40:45,398:INFO: Batch:  1/31	Total Loss 0.2422 (0.2175)
2022-11-02 23:40:45,658:INFO: Batch:  2/31	Total Loss 0.1644 (0.2010)
2022-11-02 23:40:45,915:INFO: Batch:  3/31	Total Loss 0.1874 (0.1977)
2022-11-02 23:40:46,169:INFO: Batch:  4/31	Total Loss 0.1670 (0.1914)
2022-11-02 23:40:46,428:INFO: Batch:  5/31	Total Loss 0.1659 (0.1869)
2022-11-02 23:40:46,687:INFO: Batch:  6/31	Total Loss 0.1774 (0.1856)
2022-11-02 23:40:46,943:INFO: Batch:  7/31	Total Loss 0.1574 (0.1819)
2022-11-02 23:40:47,201:INFO: Batch:  8/31	Total Loss 0.1686 (0.1805)
2022-11-02 23:40:47,456:INFO: Batch:  9/31	Total Loss 0.1623 (0.1788)
2022-11-02 23:40:47,715:INFO: Batch: 10/31	Total Loss 0.1677 (0.1778)
2022-11-02 23:40:47,972:INFO: Batch: 11/31	Total Loss 0.1695 (0.1771)
2022-11-02 23:40:48,232:INFO: Batch: 12/31	Total Loss 0.1503 (0.1752)
2022-11-02 23:40:48,492:INFO: Batch: 13/31	Total Loss 0.1807 (0.1756)
2022-11-02 23:40:48,755:INFO: Batch: 14/31	Total Loss 0.1594 (0.1745)
2022-11-02 23:40:49,016:INFO: Batch: 15/31	Total Loss 0.1630 (0.1738)
2022-11-02 23:40:49,278:INFO: Batch: 16/31	Total Loss 0.1602 (0.1730)
2022-11-02 23:40:49,541:INFO: Batch: 17/31	Total Loss 0.1791 (0.1733)
2022-11-02 23:40:49,804:INFO: Batch: 18/31	Total Loss 0.1937 (0.1743)
2022-11-02 23:40:50,065:INFO: Batch: 19/31	Total Loss 0.1516 (0.1731)
2022-11-02 23:40:50,327:INFO: Batch: 20/31	Total Loss 0.1927 (0.1740)
2022-11-02 23:40:50,587:INFO: Batch: 21/31	Total Loss 0.1742 (0.1740)
2022-11-02 23:40:50,847:INFO: Batch: 22/31	Total Loss 0.2039 (0.1754)
2022-11-02 23:40:51,107:INFO: Batch: 23/31	Total Loss 0.1920 (0.1761)
2022-11-02 23:40:51,366:INFO: Batch: 24/31	Total Loss 0.1704 (0.1759)
2022-11-02 23:40:51,626:INFO: Batch: 25/31	Total Loss 0.1506 (0.1749)
2022-11-02 23:40:51,886:INFO: Batch: 26/31	Total Loss 0.1397 (0.1735)
2022-11-02 23:40:52,147:INFO: Batch: 27/31	Total Loss 0.1457 (0.1726)
2022-11-02 23:40:52,407:INFO: Batch: 28/31	Total Loss 0.1524 (0.1719)
2022-11-02 23:40:52,666:INFO: Batch: 29/31	Total Loss 0.1820 (0.1722)
2022-11-02 23:40:52,785:INFO: Batch: 30/31	Total Loss 0.0680 (0.1714)
2022-11-02 23:40:52,936:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_177.pth.tar
2022-11-02 23:40:52,936:INFO: 
===> EPOCH: 178 (P2)
2022-11-02 23:40:52,937:INFO: - Computing loss (training)
2022-11-02 23:40:53,809:INFO: Batch:  0/31	Total Loss 0.1558 (0.1558)
2022-11-02 23:40:54,068:INFO: Batch:  1/31	Total Loss 0.2157 (0.1830)
2022-11-02 23:40:54,323:INFO: Batch:  2/31	Total Loss 0.1905 (0.1855)
2022-11-02 23:40:54,578:INFO: Batch:  3/31	Total Loss 0.1901 (0.1865)
2022-11-02 23:40:54,832:INFO: Batch:  4/31	Total Loss 0.1748 (0.1841)
2022-11-02 23:40:55,093:INFO: Batch:  5/31	Total Loss 0.1502 (0.1785)
2022-11-02 23:40:55,346:INFO: Batch:  6/31	Total Loss 0.1817 (0.1790)
2022-11-02 23:40:55,601:INFO: Batch:  7/31	Total Loss 0.1701 (0.1778)
2022-11-02 23:40:55,854:INFO: Batch:  8/31	Total Loss 0.1725 (0.1772)
2022-11-02 23:40:56,108:INFO: Batch:  9/31	Total Loss 0.1738 (0.1769)
2022-11-02 23:40:56,361:INFO: Batch: 10/31	Total Loss 0.1540 (0.1747)
2022-11-02 23:40:56,617:INFO: Batch: 11/31	Total Loss 0.1658 (0.1740)
2022-11-02 23:40:56,875:INFO: Batch: 12/31	Total Loss 0.1569 (0.1725)
2022-11-02 23:40:57,134:INFO: Batch: 13/31	Total Loss 0.1538 (0.1711)
2022-11-02 23:40:57,395:INFO: Batch: 14/31	Total Loss 0.1439 (0.1695)
2022-11-02 23:40:57,657:INFO: Batch: 15/31	Total Loss 0.1533 (0.1685)
2022-11-02 23:40:57,918:INFO: Batch: 16/31	Total Loss 0.1624 (0.1681)
2022-11-02 23:40:58,180:INFO: Batch: 17/31	Total Loss 0.1556 (0.1674)
2022-11-02 23:40:58,442:INFO: Batch: 18/31	Total Loss 0.1654 (0.1673)
2022-11-02 23:40:58,704:INFO: Batch: 19/31	Total Loss 0.1644 (0.1672)
2022-11-02 23:40:58,965:INFO: Batch: 20/31	Total Loss 0.1624 (0.1669)
2022-11-02 23:40:59,226:INFO: Batch: 21/31	Total Loss 0.1477 (0.1660)
2022-11-02 23:40:59,487:INFO: Batch: 22/31	Total Loss 0.1490 (0.1653)
2022-11-02 23:40:59,748:INFO: Batch: 23/31	Total Loss 0.1600 (0.1651)
2022-11-02 23:41:00,005:INFO: Batch: 24/31	Total Loss 0.1635 (0.1651)
2022-11-02 23:41:00,262:INFO: Batch: 25/31	Total Loss 0.1647 (0.1651)
2022-11-02 23:41:00,518:INFO: Batch: 26/31	Total Loss 0.1588 (0.1648)
2022-11-02 23:41:00,776:INFO: Batch: 27/31	Total Loss 0.1617 (0.1647)
2022-11-02 23:41:01,032:INFO: Batch: 28/31	Total Loss 0.1594 (0.1645)
2022-11-02 23:41:01,293:INFO: Batch: 29/31	Total Loss 0.1900 (0.1654)
2022-11-02 23:41:01,411:INFO: Batch: 30/31	Total Loss 0.0663 (0.1644)
2022-11-02 23:41:01,559:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_178.pth.tar
2022-11-02 23:41:01,559:INFO: 
===> EPOCH: 179 (P2)
2022-11-02 23:41:01,560:INFO: - Computing loss (training)
2022-11-02 23:41:02,416:INFO: Batch:  0/31	Total Loss 0.1820 (0.1820)
2022-11-02 23:41:02,677:INFO: Batch:  1/31	Total Loss 0.1710 (0.1766)
2022-11-02 23:41:02,938:INFO: Batch:  2/31	Total Loss 0.1511 (0.1687)
2022-11-02 23:41:03,196:INFO: Batch:  3/31	Total Loss 0.1530 (0.1650)
2022-11-02 23:41:03,457:INFO: Batch:  4/31	Total Loss 0.1568 (0.1633)
2022-11-02 23:41:03,718:INFO: Batch:  5/31	Total Loss 0.1535 (0.1616)
2022-11-02 23:41:03,976:INFO: Batch:  6/31	Total Loss 0.1517 (0.1601)
2022-11-02 23:41:04,232:INFO: Batch:  7/31	Total Loss 0.1681 (0.1611)
2022-11-02 23:41:04,486:INFO: Batch:  8/31	Total Loss 0.1507 (0.1599)
2022-11-02 23:41:04,741:INFO: Batch:  9/31	Total Loss 0.1547 (0.1593)
2022-11-02 23:41:04,997:INFO: Batch: 10/31	Total Loss 0.1611 (0.1595)
2022-11-02 23:41:05,255:INFO: Batch: 11/31	Total Loss 0.1460 (0.1583)
2022-11-02 23:41:05,516:INFO: Batch: 12/31	Total Loss 0.1375 (0.1569)
2022-11-02 23:41:05,776:INFO: Batch: 13/31	Total Loss 0.1621 (0.1573)
2022-11-02 23:41:06,035:INFO: Batch: 14/31	Total Loss 0.1409 (0.1562)
2022-11-02 23:41:06,294:INFO: Batch: 15/31	Total Loss 0.2197 (0.1602)
2022-11-02 23:41:06,554:INFO: Batch: 16/31	Total Loss 0.1433 (0.1592)
2022-11-02 23:41:06,814:INFO: Batch: 17/31	Total Loss 0.1473 (0.1584)
2022-11-02 23:41:07,072:INFO: Batch: 18/31	Total Loss 0.1332 (0.1570)
2022-11-02 23:41:07,332:INFO: Batch: 19/31	Total Loss 0.1741 (0.1579)
2022-11-02 23:41:07,591:INFO: Batch: 20/31	Total Loss 0.1803 (0.1591)
2022-11-02 23:41:07,849:INFO: Batch: 21/31	Total Loss 0.1426 (0.1584)
2022-11-02 23:41:08,108:INFO: Batch: 22/31	Total Loss 0.1582 (0.1583)
2022-11-02 23:41:08,367:INFO: Batch: 23/31	Total Loss 0.1503 (0.1580)
2022-11-02 23:41:08,624:INFO: Batch: 24/31	Total Loss 0.1578 (0.1580)
2022-11-02 23:41:08,882:INFO: Batch: 25/31	Total Loss 0.1543 (0.1579)
2022-11-02 23:41:09,141:INFO: Batch: 26/31	Total Loss 0.1502 (0.1575)
2022-11-02 23:41:09,399:INFO: Batch: 27/31	Total Loss 0.1554 (0.1575)
2022-11-02 23:41:09,660:INFO: Batch: 28/31	Total Loss 0.2202 (0.1596)
2022-11-02 23:41:09,919:INFO: Batch: 29/31	Total Loss 0.2050 (0.1610)
2022-11-02 23:41:10,036:INFO: Batch: 30/31	Total Loss 0.0645 (0.1602)
2022-11-02 23:41:10,183:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_179.pth.tar
2022-11-02 23:41:10,183:INFO: 
===> EPOCH: 180 (P2)
2022-11-02 23:41:10,184:INFO: - Computing loss (training)
2022-11-02 23:41:11,058:INFO: Batch:  0/31	Total Loss 0.1237 (0.1237)
2022-11-02 23:41:11,320:INFO: Batch:  1/31	Total Loss 0.1579 (0.1419)
2022-11-02 23:41:11,581:INFO: Batch:  2/31	Total Loss 0.1447 (0.1428)
2022-11-02 23:41:11,844:INFO: Batch:  3/31	Total Loss 0.1553 (0.1460)
2022-11-02 23:41:12,099:INFO: Batch:  4/31	Total Loss 0.1499 (0.1468)
2022-11-02 23:41:12,358:INFO: Batch:  5/31	Total Loss 0.1264 (0.1432)
2022-11-02 23:41:12,614:INFO: Batch:  6/31	Total Loss 0.1489 (0.1439)
2022-11-02 23:41:12,871:INFO: Batch:  7/31	Total Loss 0.1478 (0.1444)
2022-11-02 23:41:13,127:INFO: Batch:  8/31	Total Loss 0.1457 (0.1445)
2022-11-02 23:41:13,386:INFO: Batch:  9/31	Total Loss 0.1367 (0.1438)
2022-11-02 23:41:13,644:INFO: Batch: 10/31	Total Loss 0.1424 (0.1436)
2022-11-02 23:41:13,902:INFO: Batch: 11/31	Total Loss 0.1575 (0.1448)
2022-11-02 23:41:14,165:INFO: Batch: 12/31	Total Loss 0.1347 (0.1440)
2022-11-02 23:41:14,425:INFO: Batch: 13/31	Total Loss 0.1423 (0.1439)
2022-11-02 23:41:14,687:INFO: Batch: 14/31	Total Loss 0.1570 (0.1448)
2022-11-02 23:41:14,948:INFO: Batch: 15/31	Total Loss 0.1715 (0.1465)
2022-11-02 23:41:15,210:INFO: Batch: 16/31	Total Loss 0.1314 (0.1455)
2022-11-02 23:41:15,471:INFO: Batch: 17/31	Total Loss 0.1419 (0.1453)
2022-11-02 23:41:15,810:INFO: Batch: 18/31	Total Loss 0.1414 (0.1451)
2022-11-02 23:41:16,070:INFO: Batch: 19/31	Total Loss 0.1569 (0.1457)
2022-11-02 23:41:16,331:INFO: Batch: 20/31	Total Loss 0.1532 (0.1460)
2022-11-02 23:41:16,590:INFO: Batch: 21/31	Total Loss 0.1788 (0.1475)
2022-11-02 23:41:16,851:INFO: Batch: 22/31	Total Loss 0.1589 (0.1479)
2022-11-02 23:41:17,111:INFO: Batch: 23/31	Total Loss 0.1491 (0.1480)
2022-11-02 23:41:17,372:INFO: Batch: 24/31	Total Loss 0.1406 (0.1477)
2022-11-02 23:41:17,632:INFO: Batch: 25/31	Total Loss 0.1547 (0.1479)
2022-11-02 23:41:17,892:INFO: Batch: 26/31	Total Loss 0.1383 (0.1476)
2022-11-02 23:41:18,152:INFO: Batch: 27/31	Total Loss 0.1731 (0.1484)
2022-11-02 23:41:18,412:INFO: Batch: 28/31	Total Loss 0.1339 (0.1480)
2022-11-02 23:41:18,673:INFO: Batch: 29/31	Total Loss 0.1633 (0.1485)
2022-11-02 23:41:18,793:INFO: Batch: 30/31	Total Loss 0.0559 (0.1476)
2022-11-02 23:41:18,951:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_180.pth.tar
2022-11-02 23:41:18,951:INFO: 
===> EPOCH: 181 (P2)
2022-11-02 23:41:18,951:INFO: - Computing loss (training)
2022-11-02 23:41:19,805:INFO: Batch:  0/31	Total Loss 0.1399 (0.1399)
2022-11-02 23:41:20,072:INFO: Batch:  1/31	Total Loss 0.1242 (0.1322)
2022-11-02 23:41:20,332:INFO: Batch:  2/31	Total Loss 0.1411 (0.1354)
2022-11-02 23:41:20,591:INFO: Batch:  3/31	Total Loss 0.1334 (0.1348)
2022-11-02 23:41:20,848:INFO: Batch:  4/31	Total Loss 0.1526 (0.1385)
2022-11-02 23:41:21,108:INFO: Batch:  5/31	Total Loss 0.1395 (0.1387)
2022-11-02 23:41:21,363:INFO: Batch:  6/31	Total Loss 0.1810 (0.1440)
2022-11-02 23:41:21,620:INFO: Batch:  7/31	Total Loss 0.1322 (0.1426)
2022-11-02 23:41:21,875:INFO: Batch:  8/31	Total Loss 0.1347 (0.1417)
2022-11-02 23:41:22,130:INFO: Batch:  9/31	Total Loss 0.1270 (0.1402)
2022-11-02 23:41:22,387:INFO: Batch: 10/31	Total Loss 0.1331 (0.1395)
2022-11-02 23:41:22,645:INFO: Batch: 11/31	Total Loss 0.1696 (0.1420)
2022-11-02 23:41:22,906:INFO: Batch: 12/31	Total Loss 0.1407 (0.1419)
2022-11-02 23:41:23,167:INFO: Batch: 13/31	Total Loss 0.1389 (0.1416)
2022-11-02 23:41:23,427:INFO: Batch: 14/31	Total Loss 0.1252 (0.1405)
2022-11-02 23:41:23,687:INFO: Batch: 15/31	Total Loss 0.1341 (0.1401)
2022-11-02 23:41:23,946:INFO: Batch: 16/31	Total Loss 0.1469 (0.1405)
2022-11-02 23:41:24,207:INFO: Batch: 17/31	Total Loss 0.1380 (0.1404)
2022-11-02 23:41:24,467:INFO: Batch: 18/31	Total Loss 0.1463 (0.1407)
2022-11-02 23:41:24,729:INFO: Batch: 19/31	Total Loss 0.1365 (0.1404)
2022-11-02 23:41:24,989:INFO: Batch: 20/31	Total Loss 0.1505 (0.1410)
2022-11-02 23:41:25,249:INFO: Batch: 21/31	Total Loss 0.1407 (0.1410)
2022-11-02 23:41:25,507:INFO: Batch: 22/31	Total Loss 0.1470 (0.1412)
2022-11-02 23:41:25,766:INFO: Batch: 23/31	Total Loss 0.1598 (0.1419)
2022-11-02 23:41:26,026:INFO: Batch: 24/31	Total Loss 0.1413 (0.1419)
2022-11-02 23:41:26,285:INFO: Batch: 25/31	Total Loss 0.2192 (0.1448)
2022-11-02 23:41:26,545:INFO: Batch: 26/31	Total Loss 0.1298 (0.1443)
2022-11-02 23:41:26,806:INFO: Batch: 27/31	Total Loss 0.1571 (0.1447)
2022-11-02 23:41:27,066:INFO: Batch: 28/31	Total Loss 0.1435 (0.1447)
2022-11-02 23:41:27,329:INFO: Batch: 29/31	Total Loss 0.1470 (0.1447)
2022-11-02 23:41:27,449:INFO: Batch: 30/31	Total Loss 0.0627 (0.1439)
2022-11-02 23:41:27,613:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_181.pth.tar
2022-11-02 23:41:27,613:INFO: 
===> EPOCH: 182 (P2)
2022-11-02 23:41:27,613:INFO: - Computing loss (training)
2022-11-02 23:41:28,480:INFO: Batch:  0/31	Total Loss 0.1168 (0.1168)
2022-11-02 23:41:28,739:INFO: Batch:  1/31	Total Loss 0.1229 (0.1197)
2022-11-02 23:41:28,998:INFO: Batch:  2/31	Total Loss 0.1468 (0.1280)
2022-11-02 23:41:29,256:INFO: Batch:  3/31	Total Loss 0.1164 (0.1253)
2022-11-02 23:41:29,512:INFO: Batch:  4/31	Total Loss 0.1662 (0.1339)
2022-11-02 23:41:29,774:INFO: Batch:  5/31	Total Loss 0.1683 (0.1399)
2022-11-02 23:41:30,033:INFO: Batch:  6/31	Total Loss 0.1275 (0.1380)
2022-11-02 23:41:30,296:INFO: Batch:  7/31	Total Loss 0.1190 (0.1354)
2022-11-02 23:41:30,551:INFO: Batch:  8/31	Total Loss 0.1328 (0.1352)
2022-11-02 23:41:30,809:INFO: Batch:  9/31	Total Loss 0.1467 (0.1364)
2022-11-02 23:41:31,067:INFO: Batch: 10/31	Total Loss 0.1398 (0.1367)
2022-11-02 23:41:31,324:INFO: Batch: 11/31	Total Loss 0.1719 (0.1395)
2022-11-02 23:41:31,584:INFO: Batch: 12/31	Total Loss 0.1339 (0.1391)
2022-11-02 23:41:31,844:INFO: Batch: 13/31	Total Loss 0.1258 (0.1382)
2022-11-02 23:41:32,106:INFO: Batch: 14/31	Total Loss 0.1304 (0.1376)
2022-11-02 23:41:32,366:INFO: Batch: 15/31	Total Loss 0.1466 (0.1382)
2022-11-02 23:41:32,627:INFO: Batch: 16/31	Total Loss 0.1777 (0.1405)
2022-11-02 23:41:32,888:INFO: Batch: 17/31	Total Loss 0.1449 (0.1408)
2022-11-02 23:41:33,150:INFO: Batch: 18/31	Total Loss 0.1423 (0.1409)
2022-11-02 23:41:33,408:INFO: Batch: 19/31	Total Loss 0.1320 (0.1404)
2022-11-02 23:41:33,668:INFO: Batch: 20/31	Total Loss 0.1370 (0.1402)
2022-11-02 23:41:33,927:INFO: Batch: 21/31	Total Loss 0.1326 (0.1399)
2022-11-02 23:41:34,188:INFO: Batch: 22/31	Total Loss 0.1612 (0.1408)
2022-11-02 23:41:34,448:INFO: Batch: 23/31	Total Loss 0.1458 (0.1410)
2022-11-02 23:41:34,708:INFO: Batch: 24/31	Total Loss 0.1452 (0.1412)
2022-11-02 23:41:34,967:INFO: Batch: 25/31	Total Loss 0.1412 (0.1412)
2022-11-02 23:41:35,226:INFO: Batch: 26/31	Total Loss 0.1516 (0.1415)
2022-11-02 23:41:35,488:INFO: Batch: 27/31	Total Loss 0.1200 (0.1408)
2022-11-02 23:41:35,749:INFO: Batch: 28/31	Total Loss 0.1429 (0.1409)
2022-11-02 23:41:36,007:INFO: Batch: 29/31	Total Loss 0.1480 (0.1411)
2022-11-02 23:41:36,127:INFO: Batch: 30/31	Total Loss 0.0593 (0.1402)
2022-11-02 23:41:36,282:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_182.pth.tar
2022-11-02 23:41:36,282:INFO: 
===> EPOCH: 183 (P2)
2022-11-02 23:41:36,282:INFO: - Computing loss (training)
2022-11-02 23:41:37,134:INFO: Batch:  0/31	Total Loss 0.1336 (0.1336)
2022-11-02 23:41:37,401:INFO: Batch:  1/31	Total Loss 0.1224 (0.1278)
2022-11-02 23:41:37,661:INFO: Batch:  2/31	Total Loss 0.1260 (0.1272)
2022-11-02 23:41:37,917:INFO: Batch:  3/31	Total Loss 0.1544 (0.1344)
2022-11-02 23:41:38,171:INFO: Batch:  4/31	Total Loss 0.1312 (0.1338)
2022-11-02 23:41:38,429:INFO: Batch:  5/31	Total Loss 0.1452 (0.1355)
2022-11-02 23:41:38,684:INFO: Batch:  6/31	Total Loss 0.1351 (0.1354)
2022-11-02 23:41:38,938:INFO: Batch:  7/31	Total Loss 0.1542 (0.1378)
2022-11-02 23:41:39,192:INFO: Batch:  8/31	Total Loss 0.1268 (0.1367)
2022-11-02 23:41:39,449:INFO: Batch:  9/31	Total Loss 0.1328 (0.1363)
2022-11-02 23:41:39,703:INFO: Batch: 10/31	Total Loss 0.1307 (0.1358)
2022-11-02 23:41:39,958:INFO: Batch: 11/31	Total Loss 0.1804 (0.1398)
2022-11-02 23:41:40,218:INFO: Batch: 12/31	Total Loss 0.1207 (0.1382)
2022-11-02 23:41:40,476:INFO: Batch: 13/31	Total Loss 0.1364 (0.1381)
2022-11-02 23:41:40,733:INFO: Batch: 14/31	Total Loss 0.1211 (0.1369)
2022-11-02 23:41:40,991:INFO: Batch: 15/31	Total Loss 0.1268 (0.1364)
2022-11-02 23:41:41,250:INFO: Batch: 16/31	Total Loss 0.1698 (0.1383)
2022-11-02 23:41:41,508:INFO: Batch: 17/31	Total Loss 0.1233 (0.1374)
2022-11-02 23:41:41,766:INFO: Batch: 18/31	Total Loss 0.1678 (0.1388)
2022-11-02 23:41:42,024:INFO: Batch: 19/31	Total Loss 0.1366 (0.1387)
2022-11-02 23:41:42,284:INFO: Batch: 20/31	Total Loss 0.1545 (0.1395)
2022-11-02 23:41:42,542:INFO: Batch: 21/31	Total Loss 0.1391 (0.1395)
2022-11-02 23:41:42,800:INFO: Batch: 22/31	Total Loss 0.1400 (0.1395)
2022-11-02 23:41:43,056:INFO: Batch: 23/31	Total Loss 0.1284 (0.1390)
2022-11-02 23:41:43,314:INFO: Batch: 24/31	Total Loss 0.1263 (0.1385)
2022-11-02 23:41:43,572:INFO: Batch: 25/31	Total Loss 0.1337 (0.1383)
2022-11-02 23:41:43,829:INFO: Batch: 26/31	Total Loss 0.1278 (0.1379)
2022-11-02 23:41:44,088:INFO: Batch: 27/31	Total Loss 0.1182 (0.1372)
2022-11-02 23:41:44,346:INFO: Batch: 28/31	Total Loss 0.1231 (0.1367)
2022-11-02 23:41:44,603:INFO: Batch: 29/31	Total Loss 0.1235 (0.1363)
2022-11-02 23:41:44,721:INFO: Batch: 30/31	Total Loss 0.0533 (0.1355)
2022-11-02 23:41:44,877:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_183.pth.tar
2022-11-02 23:41:44,877:INFO: 
===> EPOCH: 184 (P2)
2022-11-02 23:41:44,877:INFO: - Computing loss (training)
2022-11-02 23:41:45,741:INFO: Batch:  0/31	Total Loss 0.1164 (0.1164)
2022-11-02 23:41:46,000:INFO: Batch:  1/31	Total Loss 0.1204 (0.1183)
2022-11-02 23:41:46,263:INFO: Batch:  2/31	Total Loss 0.1659 (0.1318)
2022-11-02 23:41:46,520:INFO: Batch:  3/31	Total Loss 0.1404 (0.1339)
2022-11-02 23:41:46,777:INFO: Batch:  4/31	Total Loss 0.1390 (0.1349)
2022-11-02 23:41:47,038:INFO: Batch:  5/31	Total Loss 0.1164 (0.1319)
2022-11-02 23:41:47,295:INFO: Batch:  6/31	Total Loss 0.1387 (0.1329)
2022-11-02 23:41:47,553:INFO: Batch:  7/31	Total Loss 0.1400 (0.1339)
2022-11-02 23:41:47,815:INFO: Batch:  8/31	Total Loss 0.1325 (0.1337)
2022-11-02 23:41:48,075:INFO: Batch:  9/31	Total Loss 0.1187 (0.1322)
2022-11-02 23:41:48,334:INFO: Batch: 10/31	Total Loss 0.1310 (0.1321)
2022-11-02 23:41:48,592:INFO: Batch: 11/31	Total Loss 0.1495 (0.1335)
2022-11-02 23:41:48,854:INFO: Batch: 12/31	Total Loss 0.1346 (0.1336)
2022-11-02 23:41:49,116:INFO: Batch: 13/31	Total Loss 0.1485 (0.1346)
2022-11-02 23:41:49,377:INFO: Batch: 14/31	Total Loss 0.1344 (0.1346)
2022-11-02 23:41:49,643:INFO: Batch: 15/31	Total Loss 0.1522 (0.1356)
2022-11-02 23:41:49,907:INFO: Batch: 16/31	Total Loss 0.1354 (0.1356)
2022-11-02 23:41:50,171:INFO: Batch: 17/31	Total Loss 0.1241 (0.1350)
2022-11-02 23:41:50,435:INFO: Batch: 18/31	Total Loss 0.1241 (0.1344)
2022-11-02 23:41:50,697:INFO: Batch: 19/31	Total Loss 0.1537 (0.1354)
2022-11-02 23:41:50,958:INFO: Batch: 20/31	Total Loss 0.1366 (0.1355)
2022-11-02 23:41:51,219:INFO: Batch: 21/31	Total Loss 0.1242 (0.1350)
2022-11-02 23:41:51,484:INFO: Batch: 22/31	Total Loss 0.1493 (0.1357)
2022-11-02 23:41:51,746:INFO: Batch: 23/31	Total Loss 0.1332 (0.1356)
2022-11-02 23:41:52,008:INFO: Batch: 24/31	Total Loss 0.1205 (0.1349)
2022-11-02 23:41:52,271:INFO: Batch: 25/31	Total Loss 0.1151 (0.1341)
2022-11-02 23:41:52,539:INFO: Batch: 26/31	Total Loss 0.1285 (0.1339)
2022-11-02 23:41:52,801:INFO: Batch: 27/31	Total Loss 0.1289 (0.1338)
2022-11-02 23:41:53,062:INFO: Batch: 28/31	Total Loss 0.1352 (0.1338)
2022-11-02 23:41:53,323:INFO: Batch: 29/31	Total Loss 0.1746 (0.1352)
2022-11-02 23:41:53,442:INFO: Batch: 30/31	Total Loss 0.0604 (0.1344)
2022-11-02 23:41:53,600:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_184.pth.tar
2022-11-02 23:41:53,600:INFO: 
===> EPOCH: 185 (P2)
2022-11-02 23:41:53,601:INFO: - Computing loss (training)
2022-11-02 23:41:54,506:INFO: Batch:  0/31	Total Loss 0.1327 (0.1327)
2022-11-02 23:41:54,771:INFO: Batch:  1/31	Total Loss 0.1425 (0.1375)
2022-11-02 23:41:55,033:INFO: Batch:  2/31	Total Loss 0.1423 (0.1391)
2022-11-02 23:41:55,292:INFO: Batch:  3/31	Total Loss 0.1308 (0.1371)
2022-11-02 23:41:55,554:INFO: Batch:  4/31	Total Loss 0.1227 (0.1341)
2022-11-02 23:41:55,818:INFO: Batch:  5/31	Total Loss 0.1230 (0.1323)
2022-11-02 23:41:56,080:INFO: Batch:  6/31	Total Loss 0.1519 (0.1350)
2022-11-02 23:41:56,342:INFO: Batch:  7/31	Total Loss 0.1112 (0.1321)
2022-11-02 23:41:56,606:INFO: Batch:  8/31	Total Loss 0.1235 (0.1311)
2022-11-02 23:41:56,867:INFO: Batch:  9/31	Total Loss 0.1259 (0.1306)
2022-11-02 23:41:57,130:INFO: Batch: 10/31	Total Loss 0.1190 (0.1295)
2022-11-02 23:41:57,393:INFO: Batch: 11/31	Total Loss 0.1140 (0.1280)
2022-11-02 23:41:57,658:INFO: Batch: 12/31	Total Loss 0.1417 (0.1290)
2022-11-02 23:41:57,926:INFO: Batch: 13/31	Total Loss 0.1215 (0.1285)
2022-11-02 23:41:58,193:INFO: Batch: 14/31	Total Loss 0.1211 (0.1281)
2022-11-02 23:41:58,458:INFO: Batch: 15/31	Total Loss 0.1050 (0.1266)
2022-11-02 23:41:58,724:INFO: Batch: 16/31	Total Loss 0.1175 (0.1260)
2022-11-02 23:41:58,989:INFO: Batch: 17/31	Total Loss 0.1231 (0.1258)
2022-11-02 23:41:59,256:INFO: Batch: 18/31	Total Loss 0.1196 (0.1255)
2022-11-02 23:41:59,524:INFO: Batch: 19/31	Total Loss 0.1258 (0.1255)
2022-11-02 23:41:59,791:INFO: Batch: 20/31	Total Loss 0.1257 (0.1255)
2022-11-02 23:42:00,056:INFO: Batch: 21/31	Total Loss 0.1435 (0.1263)
2022-11-02 23:42:00,321:INFO: Batch: 22/31	Total Loss 0.0935 (0.1249)
2022-11-02 23:42:00,665:INFO: Batch: 23/31	Total Loss 0.1168 (0.1245)
2022-11-02 23:42:00,930:INFO: Batch: 24/31	Total Loss 0.1644 (0.1260)
2022-11-02 23:42:01,198:INFO: Batch: 25/31	Total Loss 0.1204 (0.1258)
2022-11-02 23:42:01,463:INFO: Batch: 26/31	Total Loss 0.1365 (0.1262)
2022-11-02 23:42:01,725:INFO: Batch: 27/31	Total Loss 0.1271 (0.1263)
2022-11-02 23:42:01,986:INFO: Batch: 28/31	Total Loss 0.1156 (0.1259)
2022-11-02 23:42:02,247:INFO: Batch: 29/31	Total Loss 0.1176 (0.1256)
2022-11-02 23:42:02,366:INFO: Batch: 30/31	Total Loss 0.0404 (0.1248)
2022-11-02 23:42:02,522:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_185.pth.tar
2022-11-02 23:42:02,522:INFO: 
===> EPOCH: 186 (P2)
2022-11-02 23:42:02,523:INFO: - Computing loss (training)
2022-11-02 23:42:03,400:INFO: Batch:  0/31	Total Loss 0.1552 (0.1552)
2022-11-02 23:42:03,666:INFO: Batch:  1/31	Total Loss 0.1211 (0.1369)
2022-11-02 23:42:03,930:INFO: Batch:  2/31	Total Loss 0.1303 (0.1345)
2022-11-02 23:42:04,200:INFO: Batch:  3/31	Total Loss 0.1303 (0.1335)
2022-11-02 23:42:04,463:INFO: Batch:  4/31	Total Loss 0.1271 (0.1322)
2022-11-02 23:42:04,734:INFO: Batch:  5/31	Total Loss 0.1295 (0.1318)
2022-11-02 23:42:04,989:INFO: Batch:  6/31	Total Loss 0.1390 (0.1328)
2022-11-02 23:42:05,243:INFO: Batch:  7/31	Total Loss 0.1315 (0.1327)
2022-11-02 23:42:05,505:INFO: Batch:  8/31	Total Loss 0.1140 (0.1305)
2022-11-02 23:42:05,770:INFO: Batch:  9/31	Total Loss 0.1028 (0.1276)
2022-11-02 23:42:06,032:INFO: Batch: 10/31	Total Loss 0.1097 (0.1260)
2022-11-02 23:42:06,299:INFO: Batch: 11/31	Total Loss 0.1301 (0.1263)
2022-11-02 23:42:06,567:INFO: Batch: 12/31	Total Loss 0.1153 (0.1255)
2022-11-02 23:42:06,834:INFO: Batch: 13/31	Total Loss 0.1494 (0.1270)
2022-11-02 23:42:07,102:INFO: Batch: 14/31	Total Loss 0.1323 (0.1274)
2022-11-02 23:42:07,371:INFO: Batch: 15/31	Total Loss 0.1304 (0.1276)
2022-11-02 23:42:07,638:INFO: Batch: 16/31	Total Loss 0.1209 (0.1272)
2022-11-02 23:42:07,906:INFO: Batch: 17/31	Total Loss 0.1247 (0.1271)
2022-11-02 23:42:08,174:INFO: Batch: 18/31	Total Loss 0.1190 (0.1266)
2022-11-02 23:42:08,442:INFO: Batch: 19/31	Total Loss 0.1231 (0.1264)
2022-11-02 23:42:08,711:INFO: Batch: 20/31	Total Loss 0.1272 (0.1264)
2022-11-02 23:42:08,979:INFO: Batch: 21/31	Total Loss 0.1486 (0.1274)
2022-11-02 23:42:09,247:INFO: Batch: 22/31	Total Loss 0.1206 (0.1271)
2022-11-02 23:42:09,517:INFO: Batch: 23/31	Total Loss 0.1189 (0.1268)
2022-11-02 23:42:09,787:INFO: Batch: 24/31	Total Loss 0.1689 (0.1284)
2022-11-02 23:42:10,056:INFO: Batch: 25/31	Total Loss 0.1160 (0.1279)
2022-11-02 23:42:10,323:INFO: Batch: 26/31	Total Loss 0.1257 (0.1278)
2022-11-02 23:42:10,589:INFO: Batch: 27/31	Total Loss 0.1174 (0.1275)
2022-11-02 23:42:10,861:INFO: Batch: 28/31	Total Loss 0.1200 (0.1272)
2022-11-02 23:42:11,128:INFO: Batch: 29/31	Total Loss 0.1243 (0.1271)
2022-11-02 23:42:11,251:INFO: Batch: 30/31	Total Loss 0.0528 (0.1264)
2022-11-02 23:42:11,407:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_186.pth.tar
2022-11-02 23:42:11,407:INFO: 
===> EPOCH: 187 (P2)
2022-11-02 23:42:11,407:INFO: - Computing loss (training)
2022-11-02 23:42:12,307:INFO: Batch:  0/31	Total Loss 0.1283 (0.1283)
2022-11-02 23:42:12,573:INFO: Batch:  1/31	Total Loss 0.1511 (0.1392)
2022-11-02 23:42:12,845:INFO: Batch:  2/31	Total Loss 0.1392 (0.1392)
2022-11-02 23:42:13,109:INFO: Batch:  3/31	Total Loss 0.1209 (0.1348)
2022-11-02 23:42:13,374:INFO: Batch:  4/31	Total Loss 0.1236 (0.1325)
2022-11-02 23:42:13,645:INFO: Batch:  5/31	Total Loss 0.1289 (0.1318)
2022-11-02 23:42:13,910:INFO: Batch:  6/31	Total Loss 0.1288 (0.1314)
2022-11-02 23:42:14,175:INFO: Batch:  7/31	Total Loss 0.1091 (0.1287)
2022-11-02 23:42:14,438:INFO: Batch:  8/31	Total Loss 0.1122 (0.1269)
2022-11-02 23:42:14,704:INFO: Batch:  9/31	Total Loss 0.1156 (0.1257)
2022-11-02 23:42:14,975:INFO: Batch: 10/31	Total Loss 0.1260 (0.1257)
2022-11-02 23:42:15,242:INFO: Batch: 11/31	Total Loss 0.1173 (0.1250)
2022-11-02 23:42:15,511:INFO: Batch: 12/31	Total Loss 0.1509 (0.1267)
2022-11-02 23:42:15,773:INFO: Batch: 13/31	Total Loss 0.1203 (0.1263)
2022-11-02 23:42:16,034:INFO: Batch: 14/31	Total Loss 0.1209 (0.1259)
2022-11-02 23:42:16,296:INFO: Batch: 15/31	Total Loss 0.1115 (0.1250)
2022-11-02 23:42:16,558:INFO: Batch: 16/31	Total Loss 0.1122 (0.1243)
2022-11-02 23:42:16,818:INFO: Batch: 17/31	Total Loss 0.1111 (0.1235)
2022-11-02 23:42:17,078:INFO: Batch: 18/31	Total Loss 0.1231 (0.1235)
2022-11-02 23:42:17,338:INFO: Batch: 19/31	Total Loss 0.1176 (0.1232)
2022-11-02 23:42:17,596:INFO: Batch: 20/31	Total Loss 0.1416 (0.1240)
2022-11-02 23:42:17,854:INFO: Batch: 21/31	Total Loss 0.1171 (0.1237)
2022-11-02 23:42:18,112:INFO: Batch: 22/31	Total Loss 0.1204 (0.1236)
2022-11-02 23:42:18,370:INFO: Batch: 23/31	Total Loss 0.1285 (0.1238)
2022-11-02 23:42:18,628:INFO: Batch: 24/31	Total Loss 0.1200 (0.1237)
2022-11-02 23:42:18,886:INFO: Batch: 25/31	Total Loss 0.1403 (0.1242)
2022-11-02 23:42:19,144:INFO: Batch: 26/31	Total Loss 0.1339 (0.1246)
2022-11-02 23:42:19,402:INFO: Batch: 27/31	Total Loss 0.1279 (0.1247)
2022-11-02 23:42:19,664:INFO: Batch: 28/31	Total Loss 0.1160 (0.1244)
2022-11-02 23:42:19,923:INFO: Batch: 29/31	Total Loss 0.1154 (0.1241)
2022-11-02 23:42:20,040:INFO: Batch: 30/31	Total Loss 0.0520 (0.1234)
2022-11-02 23:42:20,200:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_187.pth.tar
2022-11-02 23:42:20,200:INFO: 
===> EPOCH: 188 (P2)
2022-11-02 23:42:20,200:INFO: - Computing loss (training)
2022-11-02 23:42:21,085:INFO: Batch:  0/31	Total Loss 0.1163 (0.1163)
2022-11-02 23:42:21,347:INFO: Batch:  1/31	Total Loss 0.1006 (0.1085)
2022-11-02 23:42:21,605:INFO: Batch:  2/31	Total Loss 0.1035 (0.1069)
2022-11-02 23:42:21,863:INFO: Batch:  3/31	Total Loss 0.0969 (0.1044)
2022-11-02 23:42:22,119:INFO: Batch:  4/31	Total Loss 0.1015 (0.1038)
2022-11-02 23:42:22,379:INFO: Batch:  5/31	Total Loss 0.1010 (0.1033)
2022-11-02 23:42:22,635:INFO: Batch:  6/31	Total Loss 0.1207 (0.1059)
2022-11-02 23:42:22,894:INFO: Batch:  7/31	Total Loss 0.1755 (0.1149)
2022-11-02 23:42:23,152:INFO: Batch:  8/31	Total Loss 0.1373 (0.1176)
2022-11-02 23:42:23,407:INFO: Batch:  9/31	Total Loss 0.1151 (0.1174)
2022-11-02 23:42:23,661:INFO: Batch: 10/31	Total Loss 0.1175 (0.1174)
2022-11-02 23:42:23,918:INFO: Batch: 11/31	Total Loss 0.1271 (0.1182)
2022-11-02 23:42:24,177:INFO: Batch: 12/31	Total Loss 0.1220 (0.1185)
2022-11-02 23:42:24,437:INFO: Batch: 13/31	Total Loss 0.1218 (0.1188)
2022-11-02 23:42:24,697:INFO: Batch: 14/31	Total Loss 0.1126 (0.1183)
2022-11-02 23:42:24,958:INFO: Batch: 15/31	Total Loss 0.1107 (0.1178)
2022-11-02 23:42:25,220:INFO: Batch: 16/31	Total Loss 0.1002 (0.1169)
2022-11-02 23:42:25,478:INFO: Batch: 17/31	Total Loss 0.1069 (0.1163)
2022-11-02 23:42:25,738:INFO: Batch: 18/31	Total Loss 0.1177 (0.1164)
2022-11-02 23:42:25,996:INFO: Batch: 19/31	Total Loss 0.1220 (0.1167)
2022-11-02 23:42:26,254:INFO: Batch: 20/31	Total Loss 0.1283 (0.1171)
2022-11-02 23:42:26,512:INFO: Batch: 21/31	Total Loss 0.0933 (0.1160)
2022-11-02 23:42:26,770:INFO: Batch: 22/31	Total Loss 0.1047 (0.1154)
2022-11-02 23:42:27,027:INFO: Batch: 23/31	Total Loss 0.1113 (0.1153)
2022-11-02 23:42:27,286:INFO: Batch: 24/31	Total Loss 0.1138 (0.1152)
2022-11-02 23:42:27,544:INFO: Batch: 25/31	Total Loss 0.1076 (0.1149)
2022-11-02 23:42:27,803:INFO: Batch: 26/31	Total Loss 0.1113 (0.1148)
2022-11-02 23:42:28,061:INFO: Batch: 27/31	Total Loss 0.1089 (0.1146)
2022-11-02 23:42:28,320:INFO: Batch: 28/31	Total Loss 0.1136 (0.1145)
2022-11-02 23:42:28,578:INFO: Batch: 29/31	Total Loss 0.1248 (0.1149)
2022-11-02 23:42:28,697:INFO: Batch: 30/31	Total Loss 0.0423 (0.1142)
2022-11-02 23:42:28,858:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_188.pth.tar
2022-11-02 23:42:28,858:INFO: 
===> EPOCH: 189 (P2)
2022-11-02 23:42:28,858:INFO: - Computing loss (training)
2022-11-02 23:42:29,718:INFO: Batch:  0/31	Total Loss 0.1050 (0.1050)
2022-11-02 23:42:29,979:INFO: Batch:  1/31	Total Loss 0.1139 (0.1092)
2022-11-02 23:42:30,235:INFO: Batch:  2/31	Total Loss 0.1238 (0.1144)
2022-11-02 23:42:30,496:INFO: Batch:  3/31	Total Loss 0.1282 (0.1178)
2022-11-02 23:42:30,750:INFO: Batch:  4/31	Total Loss 0.1308 (0.1205)
2022-11-02 23:42:31,009:INFO: Batch:  5/31	Total Loss 0.1054 (0.1181)
2022-11-02 23:42:31,268:INFO: Batch:  6/31	Total Loss 0.1066 (0.1164)
2022-11-02 23:42:31,525:INFO: Batch:  7/31	Total Loss 0.1042 (0.1147)
2022-11-02 23:42:31,783:INFO: Batch:  8/31	Total Loss 0.1144 (0.1147)
2022-11-02 23:42:32,045:INFO: Batch:  9/31	Total Loss 0.1135 (0.1146)
2022-11-02 23:42:32,314:INFO: Batch: 10/31	Total Loss 0.1200 (0.1151)
2022-11-02 23:42:32,572:INFO: Batch: 11/31	Total Loss 0.1163 (0.1152)
2022-11-02 23:42:32,833:INFO: Batch: 12/31	Total Loss 0.1733 (0.1193)
2022-11-02 23:42:33,101:INFO: Batch: 13/31	Total Loss 0.1193 (0.1193)
2022-11-02 23:42:33,361:INFO: Batch: 14/31	Total Loss 0.1116 (0.1187)
2022-11-02 23:42:33,622:INFO: Batch: 15/31	Total Loss 0.1156 (0.1185)
2022-11-02 23:42:33,883:INFO: Batch: 16/31	Total Loss 0.1150 (0.1183)
2022-11-02 23:42:34,144:INFO: Batch: 17/31	Total Loss 0.1194 (0.1183)
2022-11-02 23:42:34,404:INFO: Batch: 18/31	Total Loss 0.1056 (0.1177)
2022-11-02 23:42:34,664:INFO: Batch: 19/31	Total Loss 0.1619 (0.1199)
2022-11-02 23:42:34,924:INFO: Batch: 20/31	Total Loss 0.1618 (0.1219)
2022-11-02 23:42:35,184:INFO: Batch: 21/31	Total Loss 0.1060 (0.1212)
2022-11-02 23:42:35,446:INFO: Batch: 22/31	Total Loss 0.1257 (0.1214)
2022-11-02 23:42:35,705:INFO: Batch: 23/31	Total Loss 0.1230 (0.1214)
2022-11-02 23:42:35,963:INFO: Batch: 24/31	Total Loss 0.1113 (0.1211)
2022-11-02 23:42:36,223:INFO: Batch: 25/31	Total Loss 0.1125 (0.1208)
2022-11-02 23:42:36,483:INFO: Batch: 26/31	Total Loss 0.1235 (0.1209)
2022-11-02 23:42:36,741:INFO: Batch: 27/31	Total Loss 0.1059 (0.1204)
2022-11-02 23:42:37,001:INFO: Batch: 28/31	Total Loss 0.1156 (0.1202)
2022-11-02 23:42:37,264:INFO: Batch: 29/31	Total Loss 0.1165 (0.1200)
2022-11-02 23:42:37,384:INFO: Batch: 30/31	Total Loss 0.0425 (0.1193)
2022-11-02 23:42:37,543:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_189.pth.tar
2022-11-02 23:42:37,543:INFO: 
===> EPOCH: 190 (P2)
2022-11-02 23:42:37,543:INFO: - Computing loss (training)
2022-11-02 23:42:38,430:INFO: Batch:  0/31	Total Loss 0.1085 (0.1085)
2022-11-02 23:42:38,695:INFO: Batch:  1/31	Total Loss 0.1000 (0.1043)
2022-11-02 23:42:38,961:INFO: Batch:  2/31	Total Loss 0.1026 (0.1038)
2022-11-02 23:42:39,223:INFO: Batch:  3/31	Total Loss 0.1494 (0.1155)
2022-11-02 23:42:39,490:INFO: Batch:  4/31	Total Loss 0.1344 (0.1193)
2022-11-02 23:42:39,758:INFO: Batch:  5/31	Total Loss 0.1104 (0.1177)
2022-11-02 23:42:40,023:INFO: Batch:  6/31	Total Loss 0.1093 (0.1165)
2022-11-02 23:42:40,284:INFO: Batch:  7/31	Total Loss 0.0978 (0.1141)
2022-11-02 23:42:40,547:INFO: Batch:  8/31	Total Loss 0.1419 (0.1171)
2022-11-02 23:42:40,810:INFO: Batch:  9/31	Total Loss 0.1147 (0.1169)
2022-11-02 23:42:41,074:INFO: Batch: 10/31	Total Loss 0.1113 (0.1164)
2022-11-02 23:42:41,339:INFO: Batch: 11/31	Total Loss 0.1189 (0.1166)
2022-11-02 23:42:41,608:INFO: Batch: 12/31	Total Loss 0.1034 (0.1155)
2022-11-02 23:42:41,875:INFO: Batch: 13/31	Total Loss 0.1262 (0.1162)
2022-11-02 23:42:42,143:INFO: Batch: 14/31	Total Loss 0.1061 (0.1156)
2022-11-02 23:42:42,411:INFO: Batch: 15/31	Total Loss 0.1249 (0.1161)
2022-11-02 23:42:42,670:INFO: Batch: 16/31	Total Loss 0.1210 (0.1164)
2022-11-02 23:42:42,929:INFO: Batch: 17/31	Total Loss 0.0993 (0.1153)
2022-11-02 23:42:43,190:INFO: Batch: 18/31	Total Loss 0.1119 (0.1151)
2022-11-02 23:42:43,447:INFO: Batch: 19/31	Total Loss 0.1086 (0.1148)
2022-11-02 23:42:43,704:INFO: Batch: 20/31	Total Loss 0.0994 (0.1140)
2022-11-02 23:42:43,962:INFO: Batch: 21/31	Total Loss 0.1070 (0.1137)
2022-11-02 23:42:44,221:INFO: Batch: 22/31	Total Loss 0.1155 (0.1138)
2022-11-02 23:42:44,479:INFO: Batch: 23/31	Total Loss 0.1012 (0.1132)
2022-11-02 23:42:44,736:INFO: Batch: 24/31	Total Loss 0.1435 (0.1144)
2022-11-02 23:42:44,993:INFO: Batch: 25/31	Total Loss 0.1042 (0.1140)
2022-11-02 23:42:45,252:INFO: Batch: 26/31	Total Loss 0.1108 (0.1139)
2022-11-02 23:42:45,510:INFO: Batch: 27/31	Total Loss 0.1184 (0.1141)
2022-11-02 23:42:45,769:INFO: Batch: 28/31	Total Loss 0.0948 (0.1134)
2022-11-02 23:42:46,027:INFO: Batch: 29/31	Total Loss 0.0988 (0.1129)
2022-11-02 23:42:46,145:INFO: Batch: 30/31	Total Loss 0.0411 (0.1122)
2022-11-02 23:42:46,298:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_190.pth.tar
2022-11-02 23:42:46,298:INFO: 
===> EPOCH: 191 (P2)
2022-11-02 23:42:46,299:INFO: - Computing loss (training)
2022-11-02 23:42:47,178:INFO: Batch:  0/31	Total Loss 0.1085 (0.1085)
2022-11-02 23:42:47,438:INFO: Batch:  1/31	Total Loss 0.1176 (0.1129)
2022-11-02 23:42:47,698:INFO: Batch:  2/31	Total Loss 0.1213 (0.1154)
2022-11-02 23:42:47,958:INFO: Batch:  3/31	Total Loss 0.1113 (0.1144)
2022-11-02 23:42:48,215:INFO: Batch:  4/31	Total Loss 0.1236 (0.1163)
2022-11-02 23:42:48,470:INFO: Batch:  5/31	Total Loss 0.1070 (0.1149)
2022-11-02 23:42:48,726:INFO: Batch:  6/31	Total Loss 0.1118 (0.1145)
2022-11-02 23:42:48,979:INFO: Batch:  7/31	Total Loss 0.1048 (0.1134)
2022-11-02 23:42:49,236:INFO: Batch:  8/31	Total Loss 0.0975 (0.1113)
2022-11-02 23:42:49,496:INFO: Batch:  9/31	Total Loss 0.1147 (0.1116)
2022-11-02 23:42:49,754:INFO: Batch: 10/31	Total Loss 0.1229 (0.1126)
2022-11-02 23:42:50,011:INFO: Batch: 11/31	Total Loss 0.1280 (0.1138)
2022-11-02 23:42:50,271:INFO: Batch: 12/31	Total Loss 0.1321 (0.1151)
2022-11-02 23:42:50,533:INFO: Batch: 13/31	Total Loss 0.1131 (0.1150)
2022-11-02 23:42:50,793:INFO: Batch: 14/31	Total Loss 0.1208 (0.1154)
2022-11-02 23:42:51,051:INFO: Batch: 15/31	Total Loss 0.1207 (0.1157)
2022-11-02 23:42:51,310:INFO: Batch: 16/31	Total Loss 0.1200 (0.1160)
2022-11-02 23:42:51,646:INFO: Batch: 17/31	Total Loss 0.1018 (0.1151)
2022-11-02 23:42:51,904:INFO: Batch: 18/31	Total Loss 0.0957 (0.1140)
2022-11-02 23:42:52,162:INFO: Batch: 19/31	Total Loss 0.1111 (0.1139)
2022-11-02 23:42:52,420:INFO: Batch: 20/31	Total Loss 0.1023 (0.1133)
2022-11-02 23:42:52,678:INFO: Batch: 21/31	Total Loss 0.1208 (0.1137)
2022-11-02 23:42:52,936:INFO: Batch: 22/31	Total Loss 0.1046 (0.1132)
2022-11-02 23:42:53,192:INFO: Batch: 23/31	Total Loss 0.1068 (0.1130)
2022-11-02 23:42:53,450:INFO: Batch: 24/31	Total Loss 0.0984 (0.1124)
2022-11-02 23:42:53,707:INFO: Batch: 25/31	Total Loss 0.1043 (0.1120)
2022-11-02 23:42:53,964:INFO: Batch: 26/31	Total Loss 0.1104 (0.1120)
2022-11-02 23:42:54,221:INFO: Batch: 27/31	Total Loss 0.1120 (0.1120)
2022-11-02 23:42:54,477:INFO: Batch: 28/31	Total Loss 0.1046 (0.1117)
2022-11-02 23:42:54,735:INFO: Batch: 29/31	Total Loss 0.0923 (0.1111)
2022-11-02 23:42:54,853:INFO: Batch: 30/31	Total Loss 0.0401 (0.1103)
2022-11-02 23:42:55,018:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_191.pth.tar
2022-11-02 23:42:55,018:INFO: 
===> EPOCH: 192 (P2)
2022-11-02 23:42:55,018:INFO: - Computing loss (training)
2022-11-02 23:42:55,908:INFO: Batch:  0/31	Total Loss 0.0979 (0.0979)
2022-11-02 23:42:56,172:INFO: Batch:  1/31	Total Loss 0.1049 (0.1015)
2022-11-02 23:42:56,435:INFO: Batch:  2/31	Total Loss 0.1122 (0.1049)
2022-11-02 23:42:56,697:INFO: Batch:  3/31	Total Loss 0.1062 (0.1053)
2022-11-02 23:42:56,954:INFO: Batch:  4/31	Total Loss 0.1096 (0.1062)
2022-11-02 23:42:57,215:INFO: Batch:  5/31	Total Loss 0.0859 (0.1027)
2022-11-02 23:42:57,472:INFO: Batch:  6/31	Total Loss 0.1018 (0.1026)
2022-11-02 23:42:57,728:INFO: Batch:  7/31	Total Loss 0.1032 (0.1026)
2022-11-02 23:42:57,986:INFO: Batch:  8/31	Total Loss 0.1281 (0.1053)
2022-11-02 23:42:58,245:INFO: Batch:  9/31	Total Loss 0.1071 (0.1055)
2022-11-02 23:42:58,504:INFO: Batch: 10/31	Total Loss 0.0985 (0.1048)
2022-11-02 23:42:58,763:INFO: Batch: 11/31	Total Loss 0.0881 (0.1035)
2022-11-02 23:42:59,024:INFO: Batch: 12/31	Total Loss 0.0985 (0.1030)
2022-11-02 23:42:59,288:INFO: Batch: 13/31	Total Loss 0.1119 (0.1037)
2022-11-02 23:42:59,553:INFO: Batch: 14/31	Total Loss 0.1107 (0.1042)
2022-11-02 23:42:59,818:INFO: Batch: 15/31	Total Loss 0.1124 (0.1047)
2022-11-02 23:43:00,081:INFO: Batch: 16/31	Total Loss 0.1028 (0.1046)
2022-11-02 23:43:00,343:INFO: Batch: 17/31	Total Loss 0.1048 (0.1046)
2022-11-02 23:43:00,607:INFO: Batch: 18/31	Total Loss 0.1191 (0.1055)
2022-11-02 23:43:00,868:INFO: Batch: 19/31	Total Loss 0.0935 (0.1049)
2022-11-02 23:43:01,131:INFO: Batch: 20/31	Total Loss 0.1020 (0.1047)
2022-11-02 23:43:01,394:INFO: Batch: 21/31	Total Loss 0.1233 (0.1056)
2022-11-02 23:43:01,656:INFO: Batch: 22/31	Total Loss 0.1025 (0.1054)
2022-11-02 23:43:01,919:INFO: Batch: 23/31	Total Loss 0.1001 (0.1052)
2022-11-02 23:43:02,183:INFO: Batch: 24/31	Total Loss 0.1043 (0.1052)
2022-11-02 23:43:02,443:INFO: Batch: 25/31	Total Loss 0.0999 (0.1050)
2022-11-02 23:43:02,704:INFO: Batch: 26/31	Total Loss 0.1062 (0.1050)
2022-11-02 23:43:02,964:INFO: Batch: 27/31	Total Loss 0.1089 (0.1052)
2022-11-02 23:43:03,224:INFO: Batch: 28/31	Total Loss 0.0987 (0.1050)
2022-11-02 23:43:03,484:INFO: Batch: 29/31	Total Loss 0.1143 (0.1053)
2022-11-02 23:43:03,603:INFO: Batch: 30/31	Total Loss 0.0405 (0.1047)
2022-11-02 23:43:03,762:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_192.pth.tar
2022-11-02 23:43:03,762:INFO: 
===> EPOCH: 193 (P2)
2022-11-02 23:43:03,762:INFO: - Computing loss (training)
2022-11-02 23:43:04,617:INFO: Batch:  0/31	Total Loss 0.0957 (0.0957)
2022-11-02 23:43:04,886:INFO: Batch:  1/31	Total Loss 0.0783 (0.0870)
2022-11-02 23:43:05,144:INFO: Batch:  2/31	Total Loss 0.1018 (0.0919)
2022-11-02 23:43:05,410:INFO: Batch:  3/31	Total Loss 0.0894 (0.0913)
2022-11-02 23:43:05,666:INFO: Batch:  4/31	Total Loss 0.1069 (0.0947)
2022-11-02 23:43:05,923:INFO: Batch:  5/31	Total Loss 0.1126 (0.0976)
2022-11-02 23:43:06,188:INFO: Batch:  6/31	Total Loss 0.1143 (0.1001)
2022-11-02 23:43:06,450:INFO: Batch:  7/31	Total Loss 0.1112 (0.1016)
2022-11-02 23:43:06,711:INFO: Batch:  8/31	Total Loss 0.1167 (0.1032)
2022-11-02 23:43:06,975:INFO: Batch:  9/31	Total Loss 0.0936 (0.1022)
2022-11-02 23:43:07,240:INFO: Batch: 10/31	Total Loss 0.0996 (0.1019)
2022-11-02 23:43:07,501:INFO: Batch: 11/31	Total Loss 0.1089 (0.1026)
2022-11-02 23:43:07,763:INFO: Batch: 12/31	Total Loss 0.0612 (0.0993)
2022-11-02 23:43:08,023:INFO: Batch: 13/31	Total Loss 0.1103 (0.1001)
2022-11-02 23:43:08,284:INFO: Batch: 14/31	Total Loss 0.1039 (0.1003)
2022-11-02 23:43:08,544:INFO: Batch: 15/31	Total Loss 0.1018 (0.1004)
2022-11-02 23:43:08,804:INFO: Batch: 16/31	Total Loss 0.1156 (0.1013)
2022-11-02 23:43:09,065:INFO: Batch: 17/31	Total Loss 0.1011 (0.1013)
2022-11-02 23:43:09,326:INFO: Batch: 18/31	Total Loss 0.0935 (0.1009)
2022-11-02 23:43:09,589:INFO: Batch: 19/31	Total Loss 0.1007 (0.1009)
2022-11-02 23:43:09,855:INFO: Batch: 20/31	Total Loss 0.1089 (0.1013)
2022-11-02 23:43:10,116:INFO: Batch: 21/31	Total Loss 0.0975 (0.1011)
2022-11-02 23:43:10,375:INFO: Batch: 22/31	Total Loss 0.0956 (0.1009)
2022-11-02 23:43:10,635:INFO: Batch: 23/31	Total Loss 0.0909 (0.1004)
2022-11-02 23:43:10,895:INFO: Batch: 24/31	Total Loss 0.0976 (0.1003)
2022-11-02 23:43:11,155:INFO: Batch: 25/31	Total Loss 0.0897 (0.0999)
2022-11-02 23:43:11,416:INFO: Batch: 26/31	Total Loss 0.1001 (0.0999)
2022-11-02 23:43:11,677:INFO: Batch: 27/31	Total Loss 0.1008 (0.0999)
2022-11-02 23:43:11,937:INFO: Batch: 28/31	Total Loss 0.0990 (0.0999)
2022-11-02 23:43:12,198:INFO: Batch: 29/31	Total Loss 0.1109 (0.1003)
2022-11-02 23:43:12,317:INFO: Batch: 30/31	Total Loss 0.0469 (0.0998)
2022-11-02 23:43:12,480:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_193.pth.tar
2022-11-02 23:43:12,480:INFO: 
===> EPOCH: 194 (P2)
2022-11-02 23:43:12,480:INFO: - Computing loss (training)
2022-11-02 23:43:13,332:INFO: Batch:  0/31	Total Loss 0.0939 (0.0939)
2022-11-02 23:43:13,599:INFO: Batch:  1/31	Total Loss 0.0909 (0.0925)
2022-11-02 23:43:13,856:INFO: Batch:  2/31	Total Loss 0.0938 (0.0929)
2022-11-02 23:43:14,117:INFO: Batch:  3/31	Total Loss 0.0929 (0.0929)
2022-11-02 23:43:14,374:INFO: Batch:  4/31	Total Loss 0.1016 (0.0945)
2022-11-02 23:43:14,632:INFO: Batch:  5/31	Total Loss 0.1107 (0.0971)
2022-11-02 23:43:14,888:INFO: Batch:  6/31	Total Loss 0.0943 (0.0967)
2022-11-02 23:43:15,145:INFO: Batch:  7/31	Total Loss 0.1582 (0.1044)
2022-11-02 23:43:15,400:INFO: Batch:  8/31	Total Loss 0.0876 (0.1024)
2022-11-02 23:43:15,656:INFO: Batch:  9/31	Total Loss 0.0854 (0.1008)
2022-11-02 23:43:15,915:INFO: Batch: 10/31	Total Loss 0.0995 (0.1007)
2022-11-02 23:43:16,173:INFO: Batch: 11/31	Total Loss 0.0915 (0.0999)
2022-11-02 23:43:16,431:INFO: Batch: 12/31	Total Loss 0.1055 (0.1003)
2022-11-02 23:43:16,690:INFO: Batch: 13/31	Total Loss 0.0961 (0.1000)
2022-11-02 23:43:16,949:INFO: Batch: 14/31	Total Loss 0.0908 (0.0994)
2022-11-02 23:43:17,210:INFO: Batch: 15/31	Total Loss 0.1143 (0.1004)
2022-11-02 23:43:17,470:INFO: Batch: 16/31	Total Loss 0.1236 (0.1016)
2022-11-02 23:43:17,731:INFO: Batch: 17/31	Total Loss 0.0914 (0.1011)
2022-11-02 23:43:17,991:INFO: Batch: 18/31	Total Loss 0.0927 (0.1006)
2022-11-02 23:43:18,251:INFO: Batch: 19/31	Total Loss 0.0925 (0.1003)
2022-11-02 23:43:18,509:INFO: Batch: 20/31	Total Loss 0.1017 (0.1003)
2022-11-02 23:43:18,769:INFO: Batch: 21/31	Total Loss 0.0991 (0.1003)
2022-11-02 23:43:19,028:INFO: Batch: 22/31	Total Loss 0.0872 (0.0997)
2022-11-02 23:43:19,285:INFO: Batch: 23/31	Total Loss 0.0931 (0.0994)
2022-11-02 23:43:19,548:INFO: Batch: 24/31	Total Loss 0.1119 (0.1000)
2022-11-02 23:43:19,809:INFO: Batch: 25/31	Total Loss 0.0949 (0.0998)
2022-11-02 23:43:20,069:INFO: Batch: 26/31	Total Loss 0.0978 (0.0997)
2022-11-02 23:43:20,330:INFO: Batch: 27/31	Total Loss 0.0965 (0.0996)
2022-11-02 23:43:20,591:INFO: Batch: 28/31	Total Loss 0.0916 (0.0993)
2022-11-02 23:43:20,852:INFO: Batch: 29/31	Total Loss 0.1020 (0.0994)
2022-11-02 23:43:20,970:INFO: Batch: 30/31	Total Loss 0.0340 (0.0987)
2022-11-02 23:43:21,118:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_194.pth.tar
2022-11-02 23:43:21,118:INFO: 
===> EPOCH: 195 (P2)
2022-11-02 23:43:21,119:INFO: - Computing loss (training)
2022-11-02 23:43:21,998:INFO: Batch:  0/31	Total Loss 0.1026 (0.1026)
2022-11-02 23:43:22,256:INFO: Batch:  1/31	Total Loss 0.1096 (0.1062)
2022-11-02 23:43:22,517:INFO: Batch:  2/31	Total Loss 0.0971 (0.1032)
2022-11-02 23:43:22,775:INFO: Batch:  3/31	Total Loss 0.0883 (0.0995)
2022-11-02 23:43:23,033:INFO: Batch:  4/31	Total Loss 0.1011 (0.0998)
2022-11-02 23:43:23,293:INFO: Batch:  5/31	Total Loss 0.1079 (0.1011)
2022-11-02 23:43:23,551:INFO: Batch:  6/31	Total Loss 0.0914 (0.0997)
2022-11-02 23:43:23,811:INFO: Batch:  7/31	Total Loss 0.0944 (0.0991)
2022-11-02 23:43:24,068:INFO: Batch:  8/31	Total Loss 0.1144 (0.1008)
2022-11-02 23:43:24,326:INFO: Batch:  9/31	Total Loss 0.1077 (0.1015)
2022-11-02 23:43:24,585:INFO: Batch: 10/31	Total Loss 0.0693 (0.0988)
2022-11-02 23:43:24,845:INFO: Batch: 11/31	Total Loss 0.0906 (0.0981)
2022-11-02 23:43:25,107:INFO: Batch: 12/31	Total Loss 0.1314 (0.1004)
2022-11-02 23:43:25,367:INFO: Batch: 13/31	Total Loss 0.0863 (0.0995)
2022-11-02 23:43:25,629:INFO: Batch: 14/31	Total Loss 0.0911 (0.0989)
2022-11-02 23:43:25,893:INFO: Batch: 15/31	Total Loss 0.0932 (0.0986)
2022-11-02 23:43:26,155:INFO: Batch: 16/31	Total Loss 0.1072 (0.0991)
2022-11-02 23:43:26,418:INFO: Batch: 17/31	Total Loss 0.1073 (0.0996)
2022-11-02 23:43:26,681:INFO: Batch: 18/31	Total Loss 0.1050 (0.0999)
2022-11-02 23:43:26,943:INFO: Batch: 19/31	Total Loss 0.1270 (0.1013)
2022-11-02 23:43:27,206:INFO: Batch: 20/31	Total Loss 0.0976 (0.1011)
2022-11-02 23:43:27,467:INFO: Batch: 21/31	Total Loss 0.1004 (0.1011)
2022-11-02 23:43:27,733:INFO: Batch: 22/31	Total Loss 0.0991 (0.1010)
2022-11-02 23:43:28,000:INFO: Batch: 23/31	Total Loss 0.1011 (0.1010)
2022-11-02 23:43:28,265:INFO: Batch: 24/31	Total Loss 0.0887 (0.1005)
2022-11-02 23:43:28,531:INFO: Batch: 25/31	Total Loss 0.0950 (0.1003)
2022-11-02 23:43:28,794:INFO: Batch: 26/31	Total Loss 0.0882 (0.0998)
2022-11-02 23:43:29,053:INFO: Batch: 27/31	Total Loss 0.0978 (0.0998)
2022-11-02 23:43:29,315:INFO: Batch: 28/31	Total Loss 0.0985 (0.0997)
2022-11-02 23:43:29,579:INFO: Batch: 29/31	Total Loss 0.1014 (0.0998)
2022-11-02 23:43:29,698:INFO: Batch: 30/31	Total Loss 0.0341 (0.0993)
2022-11-02 23:43:29,857:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_195.pth.tar
2022-11-02 23:43:29,857:INFO: 
===> EPOCH: 196 (P2)
2022-11-02 23:43:29,857:INFO: - Computing loss (training)
2022-11-02 23:43:30,742:INFO: Batch:  0/31	Total Loss 0.0942 (0.0942)
2022-11-02 23:43:31,005:INFO: Batch:  1/31	Total Loss 0.0892 (0.0918)
2022-11-02 23:43:31,265:INFO: Batch:  2/31	Total Loss 0.0711 (0.0842)
2022-11-02 23:43:31,531:INFO: Batch:  3/31	Total Loss 0.0901 (0.0856)
2022-11-02 23:43:31,789:INFO: Batch:  4/31	Total Loss 0.1184 (0.0918)
2022-11-02 23:43:32,053:INFO: Batch:  5/31	Total Loss 0.0853 (0.0908)
2022-11-02 23:43:32,314:INFO: Batch:  6/31	Total Loss 0.1244 (0.0959)
2022-11-02 23:43:32,576:INFO: Batch:  7/31	Total Loss 0.1026 (0.0967)
2022-11-02 23:43:32,836:INFO: Batch:  8/31	Total Loss 0.1004 (0.0972)
2022-11-02 23:43:33,096:INFO: Batch:  9/31	Total Loss 0.1279 (0.1001)
2022-11-02 23:43:33,357:INFO: Batch: 10/31	Total Loss 0.0922 (0.0993)
2022-11-02 23:43:33,618:INFO: Batch: 11/31	Total Loss 0.0870 (0.0982)
2022-11-02 23:43:33,882:INFO: Batch: 12/31	Total Loss 0.0962 (0.0981)
2022-11-02 23:43:34,147:INFO: Batch: 13/31	Total Loss 0.0922 (0.0976)
2022-11-02 23:43:34,409:INFO: Batch: 14/31	Total Loss 0.0962 (0.0975)
2022-11-02 23:43:34,673:INFO: Batch: 15/31	Total Loss 0.0949 (0.0974)
2022-11-02 23:43:34,937:INFO: Batch: 16/31	Total Loss 0.1185 (0.0985)
2022-11-02 23:43:35,200:INFO: Batch: 17/31	Total Loss 0.1186 (0.0997)
2022-11-02 23:43:35,467:INFO: Batch: 18/31	Total Loss 0.0807 (0.0986)
2022-11-02 23:43:35,730:INFO: Batch: 19/31	Total Loss 0.0872 (0.0980)
2022-11-02 23:43:35,992:INFO: Batch: 20/31	Total Loss 0.1176 (0.0990)
2022-11-02 23:43:36,256:INFO: Batch: 21/31	Total Loss 0.1075 (0.0994)
2022-11-02 23:43:36,518:INFO: Batch: 22/31	Total Loss 0.0957 (0.0993)
2022-11-02 23:43:36,779:INFO: Batch: 23/31	Total Loss 0.1025 (0.0994)
2022-11-02 23:43:37,041:INFO: Batch: 24/31	Total Loss 0.0868 (0.0989)
2022-11-02 23:43:37,304:INFO: Batch: 25/31	Total Loss 0.1056 (0.0992)
2022-11-02 23:43:37,566:INFO: Batch: 26/31	Total Loss 0.1111 (0.0996)
2022-11-02 23:43:37,829:INFO: Batch: 27/31	Total Loss 0.0889 (0.0992)
2022-11-02 23:43:38,090:INFO: Batch: 28/31	Total Loss 0.0972 (0.0992)
2022-11-02 23:43:38,351:INFO: Batch: 29/31	Total Loss 0.1120 (0.0996)
2022-11-02 23:43:38,469:INFO: Batch: 30/31	Total Loss 0.0364 (0.0989)
2022-11-02 23:43:38,626:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_196.pth.tar
2022-11-02 23:43:38,627:INFO: 
===> EPOCH: 197 (P2)
2022-11-02 23:43:38,627:INFO: - Computing loss (training)
2022-11-02 23:43:39,586:INFO: Batch:  0/31	Total Loss 0.0950 (0.0950)
2022-11-02 23:43:39,842:INFO: Batch:  1/31	Total Loss 0.1007 (0.0978)
2022-11-02 23:43:40,105:INFO: Batch:  2/31	Total Loss 0.1023 (0.0994)
2022-11-02 23:43:40,357:INFO: Batch:  3/31	Total Loss 0.0891 (0.0967)
2022-11-02 23:43:40,611:INFO: Batch:  4/31	Total Loss 0.0958 (0.0965)
2022-11-02 23:43:40,872:INFO: Batch:  5/31	Total Loss 0.0972 (0.0966)
2022-11-02 23:43:41,126:INFO: Batch:  6/31	Total Loss 0.0973 (0.0967)
2022-11-02 23:43:41,381:INFO: Batch:  7/31	Total Loss 0.0991 (0.0971)
2022-11-02 23:43:41,637:INFO: Batch:  8/31	Total Loss 0.0886 (0.0961)
2022-11-02 23:43:41,892:INFO: Batch:  9/31	Total Loss 0.1029 (0.0968)
2022-11-02 23:43:42,149:INFO: Batch: 10/31	Total Loss 0.0791 (0.0952)
2022-11-02 23:43:42,406:INFO: Batch: 11/31	Total Loss 0.0982 (0.0955)
2022-11-02 23:43:42,664:INFO: Batch: 12/31	Total Loss 0.1217 (0.0974)
2022-11-02 23:43:42,924:INFO: Batch: 13/31	Total Loss 0.0794 (0.0961)
2022-11-02 23:43:43,185:INFO: Batch: 14/31	Total Loss 0.0742 (0.0946)
2022-11-02 23:43:43,445:INFO: Batch: 15/31	Total Loss 0.0909 (0.0944)
2022-11-02 23:43:43,704:INFO: Batch: 16/31	Total Loss 0.0992 (0.0947)
2022-11-02 23:43:43,963:INFO: Batch: 17/31	Total Loss 0.0866 (0.0943)
2022-11-02 23:43:44,223:INFO: Batch: 18/31	Total Loss 0.0966 (0.0944)
2022-11-02 23:43:44,483:INFO: Batch: 19/31	Total Loss 0.0873 (0.0940)
2022-11-02 23:43:44,742:INFO: Batch: 20/31	Total Loss 0.1000 (0.0943)
2022-11-02 23:43:44,999:INFO: Batch: 21/31	Total Loss 0.0767 (0.0934)
2022-11-02 23:43:45,258:INFO: Batch: 22/31	Total Loss 0.0947 (0.0935)
2022-11-02 23:43:45,517:INFO: Batch: 23/31	Total Loss 0.0870 (0.0932)
2022-11-02 23:43:45,776:INFO: Batch: 24/31	Total Loss 0.0848 (0.0929)
2022-11-02 23:43:46,035:INFO: Batch: 25/31	Total Loss 0.0888 (0.0927)
2022-11-02 23:43:46,294:INFO: Batch: 26/31	Total Loss 0.0818 (0.0923)
2022-11-02 23:43:46,552:INFO: Batch: 27/31	Total Loss 0.0868 (0.0922)
2022-11-02 23:43:46,812:INFO: Batch: 28/31	Total Loss 0.0943 (0.0922)
2022-11-02 23:43:47,069:INFO: Batch: 29/31	Total Loss 0.1121 (0.0928)
2022-11-02 23:43:47,187:INFO: Batch: 30/31	Total Loss 0.0302 (0.0923)
2022-11-02 23:43:47,354:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_197.pth.tar
2022-11-02 23:43:47,354:INFO: 
===> EPOCH: 198 (P2)
2022-11-02 23:43:47,354:INFO: - Computing loss (training)
2022-11-02 23:43:48,240:INFO: Batch:  0/31	Total Loss 0.0875 (0.0875)
2022-11-02 23:43:48,500:INFO: Batch:  1/31	Total Loss 0.0845 (0.0860)
2022-11-02 23:43:48,763:INFO: Batch:  2/31	Total Loss 0.0988 (0.0904)
2022-11-02 23:43:49,020:INFO: Batch:  3/31	Total Loss 0.0909 (0.0905)
2022-11-02 23:43:49,282:INFO: Batch:  4/31	Total Loss 0.0975 (0.0918)
2022-11-02 23:43:49,545:INFO: Batch:  5/31	Total Loss 0.0707 (0.0883)
2022-11-02 23:43:49,809:INFO: Batch:  6/31	Total Loss 0.0991 (0.0898)
2022-11-02 23:43:50,069:INFO: Batch:  7/31	Total Loss 0.0978 (0.0909)
2022-11-02 23:43:50,329:INFO: Batch:  8/31	Total Loss 0.0928 (0.0911)
2022-11-02 23:43:50,586:INFO: Batch:  9/31	Total Loss 0.1015 (0.0922)
2022-11-02 23:43:50,848:INFO: Batch: 10/31	Total Loss 0.0915 (0.0922)
2022-11-02 23:43:51,104:INFO: Batch: 11/31	Total Loss 0.0870 (0.0917)
2022-11-02 23:43:51,364:INFO: Batch: 12/31	Total Loss 0.1087 (0.0930)
2022-11-02 23:43:51,627:INFO: Batch: 13/31	Total Loss 0.1036 (0.0938)
2022-11-02 23:43:51,887:INFO: Batch: 14/31	Total Loss 0.0868 (0.0934)
2022-11-02 23:43:52,146:INFO: Batch: 15/31	Total Loss 0.1101 (0.0943)
2022-11-02 23:43:52,406:INFO: Batch: 16/31	Total Loss 0.1070 (0.0951)
2022-11-02 23:43:52,667:INFO: Batch: 17/31	Total Loss 0.1003 (0.0954)
2022-11-02 23:43:52,927:INFO: Batch: 18/31	Total Loss 0.0863 (0.0949)
2022-11-02 23:43:53,187:INFO: Batch: 19/31	Total Loss 0.0781 (0.0941)
2022-11-02 23:43:53,448:INFO: Batch: 20/31	Total Loss 0.1011 (0.0945)
2022-11-02 23:43:53,708:INFO: Batch: 21/31	Total Loss 0.0975 (0.0946)
2022-11-02 23:43:53,968:INFO: Batch: 22/31	Total Loss 0.0941 (0.0946)
2022-11-02 23:43:54,229:INFO: Batch: 23/31	Total Loss 0.0900 (0.0944)
2022-11-02 23:43:54,489:INFO: Batch: 24/31	Total Loss 0.0884 (0.0941)
2022-11-02 23:43:54,750:INFO: Batch: 25/31	Total Loss 0.0840 (0.0937)
2022-11-02 23:43:55,010:INFO: Batch: 26/31	Total Loss 0.1379 (0.0953)
2022-11-02 23:43:55,271:INFO: Batch: 27/31	Total Loss 0.0960 (0.0953)
2022-11-02 23:43:55,530:INFO: Batch: 28/31	Total Loss 0.0907 (0.0951)
2022-11-02 23:43:55,791:INFO: Batch: 29/31	Total Loss 0.0893 (0.0949)
2022-11-02 23:43:55,909:INFO: Batch: 30/31	Total Loss 0.0306 (0.0944)
2022-11-02 23:43:56,066:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_198.pth.tar
2022-11-02 23:43:56,066:INFO: 
===> EPOCH: 199 (P2)
2022-11-02 23:43:56,066:INFO: - Computing loss (training)
2022-11-02 23:43:56,937:INFO: Batch:  0/31	Total Loss 0.0947 (0.0947)
2022-11-02 23:43:57,200:INFO: Batch:  1/31	Total Loss 0.1091 (0.1020)
2022-11-02 23:43:57,462:INFO: Batch:  2/31	Total Loss 0.0891 (0.0977)
2022-11-02 23:43:57,720:INFO: Batch:  3/31	Total Loss 0.0796 (0.0930)
2022-11-02 23:43:57,974:INFO: Batch:  4/31	Total Loss 0.1133 (0.0969)
2022-11-02 23:43:58,234:INFO: Batch:  5/31	Total Loss 0.0809 (0.0943)
2022-11-02 23:43:58,490:INFO: Batch:  6/31	Total Loss 0.0975 (0.0948)
2022-11-02 23:43:58,749:INFO: Batch:  7/31	Total Loss 0.0917 (0.0944)
2022-11-02 23:43:59,005:INFO: Batch:  8/31	Total Loss 0.1032 (0.0952)
2022-11-02 23:43:59,261:INFO: Batch:  9/31	Total Loss 0.0810 (0.0940)
2022-11-02 23:43:59,519:INFO: Batch: 10/31	Total Loss 0.0868 (0.0934)
2022-11-02 23:43:59,779:INFO: Batch: 11/31	Total Loss 0.0829 (0.0925)
2022-11-02 23:44:00,040:INFO: Batch: 12/31	Total Loss 0.0811 (0.0916)
2022-11-02 23:44:00,301:INFO: Batch: 13/31	Total Loss 0.0956 (0.0919)
2022-11-02 23:44:00,562:INFO: Batch: 14/31	Total Loss 0.0845 (0.0914)
2022-11-02 23:44:00,827:INFO: Batch: 15/31	Total Loss 0.0865 (0.0911)
2022-11-02 23:44:01,088:INFO: Batch: 16/31	Total Loss 0.0845 (0.0907)
2022-11-02 23:44:01,352:INFO: Batch: 17/31	Total Loss 0.1158 (0.0921)
2022-11-02 23:44:01,613:INFO: Batch: 18/31	Total Loss 0.0996 (0.0925)
2022-11-02 23:44:01,874:INFO: Batch: 19/31	Total Loss 0.0890 (0.0924)
2022-11-02 23:44:02,135:INFO: Batch: 20/31	Total Loss 0.0844 (0.0920)
2022-11-02 23:44:02,395:INFO: Batch: 21/31	Total Loss 0.0715 (0.0911)
2022-11-02 23:44:02,654:INFO: Batch: 22/31	Total Loss 0.0692 (0.0902)
2022-11-02 23:44:02,914:INFO: Batch: 23/31	Total Loss 0.1045 (0.0907)
2022-11-02 23:44:03,174:INFO: Batch: 24/31	Total Loss 0.0822 (0.0904)
2022-11-02 23:44:03,434:INFO: Batch: 25/31	Total Loss 0.1079 (0.0910)
2022-11-02 23:44:03,694:INFO: Batch: 26/31	Total Loss 0.0784 (0.0905)
2022-11-02 23:44:03,955:INFO: Batch: 27/31	Total Loss 0.0874 (0.0904)
2022-11-02 23:44:04,215:INFO: Batch: 28/31	Total Loss 0.0872 (0.0902)
2022-11-02 23:44:04,475:INFO: Batch: 29/31	Total Loss 0.0948 (0.0904)
2022-11-02 23:44:04,593:INFO: Batch: 30/31	Total Loss 0.0321 (0.0897)
2022-11-02 23:44:04,744:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_199.pth.tar
2022-11-02 23:44:04,744:INFO: 
===> EPOCH: 200 (P2)
2022-11-02 23:44:04,744:INFO: - Computing loss (training)
2022-11-02 23:44:05,651:INFO: Batch:  0/31	Total Loss 0.0927 (0.0927)
2022-11-02 23:44:05,908:INFO: Batch:  1/31	Total Loss 0.1013 (0.0967)
2022-11-02 23:44:06,170:INFO: Batch:  2/31	Total Loss 0.0850 (0.0927)
2022-11-02 23:44:06,429:INFO: Batch:  3/31	Total Loss 0.0995 (0.0943)
2022-11-02 23:44:06,690:INFO: Batch:  4/31	Total Loss 0.0906 (0.0937)
2022-11-02 23:44:06,949:INFO: Batch:  5/31	Total Loss 0.0772 (0.0909)
2022-11-02 23:44:07,209:INFO: Batch:  6/31	Total Loss 0.0903 (0.0909)
2022-11-02 23:44:07,467:INFO: Batch:  7/31	Total Loss 0.0904 (0.0908)
2022-11-02 23:44:07,726:INFO: Batch:  8/31	Total Loss 0.0945 (0.0912)
2022-11-02 23:44:07,985:INFO: Batch:  9/31	Total Loss 0.0851 (0.0906)
2022-11-02 23:44:08,249:INFO: Batch: 10/31	Total Loss 0.0933 (0.0908)
2022-11-02 23:44:08,506:INFO: Batch: 11/31	Total Loss 0.0909 (0.0909)
2022-11-02 23:44:08,769:INFO: Batch: 12/31	Total Loss 0.0810 (0.0901)
2022-11-02 23:44:09,031:INFO: Batch: 13/31	Total Loss 0.0830 (0.0896)
2022-11-02 23:44:09,292:INFO: Batch: 14/31	Total Loss 0.0856 (0.0894)
2022-11-02 23:44:09,559:INFO: Batch: 15/31	Total Loss 0.0884 (0.0893)
2022-11-02 23:44:09,824:INFO: Batch: 16/31	Total Loss 0.0862 (0.0891)
2022-11-02 23:44:10,088:INFO: Batch: 17/31	Total Loss 0.0802 (0.0886)
2022-11-02 23:44:10,353:INFO: Batch: 18/31	Total Loss 0.0810 (0.0882)
2022-11-02 23:44:10,614:INFO: Batch: 19/31	Total Loss 0.0917 (0.0884)
2022-11-02 23:44:10,876:INFO: Batch: 20/31	Total Loss 0.1015 (0.0890)
2022-11-02 23:44:11,139:INFO: Batch: 21/31	Total Loss 0.1164 (0.0901)
2022-11-02 23:44:11,400:INFO: Batch: 22/31	Total Loss 0.0594 (0.0889)
2022-11-02 23:44:11,658:INFO: Batch: 23/31	Total Loss 0.0957 (0.0892)
2022-11-02 23:44:11,916:INFO: Batch: 24/31	Total Loss 0.0860 (0.0890)
2022-11-02 23:44:12,174:INFO: Batch: 25/31	Total Loss 0.0856 (0.0889)
2022-11-02 23:44:12,433:INFO: Batch: 26/31	Total Loss 0.0826 (0.0887)
2022-11-02 23:44:12,691:INFO: Batch: 27/31	Total Loss 0.0847 (0.0885)
2022-11-02 23:44:12,947:INFO: Batch: 28/31	Total Loss 0.0857 (0.0884)
2022-11-02 23:44:13,204:INFO: Batch: 29/31	Total Loss 0.0908 (0.0885)
2022-11-02 23:44:13,321:INFO: Batch: 30/31	Total Loss 0.0316 (0.0880)
2022-11-02 23:44:13,461:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_200.pth.tar
2022-11-02 23:44:13,461:INFO: 
===> EPOCH: 201 (P2)
2022-11-02 23:44:13,461:INFO: - Computing loss (training)
2022-11-02 23:44:14,356:INFO: Batch:  0/31	Total Loss 0.1049 (0.1049)
2022-11-02 23:44:14,618:INFO: Batch:  1/31	Total Loss 0.0869 (0.0958)
2022-11-02 23:44:14,878:INFO: Batch:  2/31	Total Loss 0.0800 (0.0910)
2022-11-02 23:44:15,136:INFO: Batch:  3/31	Total Loss 0.0900 (0.0907)
2022-11-02 23:44:15,398:INFO: Batch:  4/31	Total Loss 0.1016 (0.0928)
2022-11-02 23:44:15,665:INFO: Batch:  5/31	Total Loss 0.1118 (0.0961)
2022-11-02 23:44:15,928:INFO: Batch:  6/31	Total Loss 0.0908 (0.0953)
2022-11-02 23:44:16,191:INFO: Batch:  7/31	Total Loss 0.0961 (0.0954)
2022-11-02 23:44:16,455:INFO: Batch:  8/31	Total Loss 0.0847 (0.0942)
2022-11-02 23:44:16,720:INFO: Batch:  9/31	Total Loss 0.1121 (0.0962)
2022-11-02 23:44:16,984:INFO: Batch: 10/31	Total Loss 0.0816 (0.0950)
2022-11-02 23:44:17,250:INFO: Batch: 11/31	Total Loss 0.0766 (0.0935)
2022-11-02 23:44:17,517:INFO: Batch: 12/31	Total Loss 0.1021 (0.0941)
2022-11-02 23:44:17,787:INFO: Batch: 13/31	Total Loss 0.0589 (0.0916)
2022-11-02 23:44:18,054:INFO: Batch: 14/31	Total Loss 0.0955 (0.0919)
2022-11-02 23:44:18,329:INFO: Batch: 15/31	Total Loss 0.0936 (0.0920)
2022-11-02 23:44:18,597:INFO: Batch: 16/31	Total Loss 0.0851 (0.0916)
2022-11-02 23:44:18,869:INFO: Batch: 17/31	Total Loss 0.0892 (0.0914)
2022-11-02 23:44:19,137:INFO: Batch: 18/31	Total Loss 0.0965 (0.0917)
2022-11-02 23:44:19,412:INFO: Batch: 19/31	Total Loss 0.0881 (0.0915)
2022-11-02 23:44:19,683:INFO: Batch: 20/31	Total Loss 0.0831 (0.0911)
2022-11-02 23:44:19,950:INFO: Batch: 21/31	Total Loss 0.0822 (0.0906)
2022-11-02 23:44:20,218:INFO: Batch: 22/31	Total Loss 0.0829 (0.0903)
2022-11-02 23:44:20,488:INFO: Batch: 23/31	Total Loss 0.1006 (0.0907)
2022-11-02 23:44:20,755:INFO: Batch: 24/31	Total Loss 0.0807 (0.0904)
2022-11-02 23:44:21,023:INFO: Batch: 25/31	Total Loss 0.0809 (0.0900)
2022-11-02 23:44:21,291:INFO: Batch: 26/31	Total Loss 0.0801 (0.0896)
2022-11-02 23:44:21,559:INFO: Batch: 27/31	Total Loss 0.0885 (0.0895)
2022-11-02 23:44:21,827:INFO: Batch: 28/31	Total Loss 0.0803 (0.0893)
2022-11-02 23:44:22,177:INFO: Batch: 29/31	Total Loss 0.0804 (0.0889)
2022-11-02 23:44:22,300:INFO: Batch: 30/31	Total Loss 0.0290 (0.0884)
2022-11-02 23:44:22,449:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_201.pth.tar
2022-11-02 23:44:22,449:INFO: 
===> EPOCH: 202 (P2)
2022-11-02 23:44:22,449:INFO: - Computing loss (training)
2022-11-02 23:44:23,338:INFO: Batch:  0/31	Total Loss 0.0702 (0.0702)
2022-11-02 23:44:23,594:INFO: Batch:  1/31	Total Loss 0.0804 (0.0748)
2022-11-02 23:44:23,862:INFO: Batch:  2/31	Total Loss 0.0780 (0.0760)
2022-11-02 23:44:24,120:INFO: Batch:  3/31	Total Loss 0.0834 (0.0779)
2022-11-02 23:44:24,378:INFO: Batch:  4/31	Total Loss 0.0962 (0.0817)
2022-11-02 23:44:24,639:INFO: Batch:  5/31	Total Loss 0.0737 (0.0803)
2022-11-02 23:44:24,896:INFO: Batch:  6/31	Total Loss 0.0820 (0.0806)
2022-11-02 23:44:25,153:INFO: Batch:  7/31	Total Loss 0.0801 (0.0805)
2022-11-02 23:44:25,410:INFO: Batch:  8/31	Total Loss 0.0762 (0.0801)
2022-11-02 23:44:25,666:INFO: Batch:  9/31	Total Loss 0.0804 (0.0801)
2022-11-02 23:44:25,925:INFO: Batch: 10/31	Total Loss 0.0778 (0.0799)
2022-11-02 23:44:26,185:INFO: Batch: 11/31	Total Loss 0.1036 (0.0817)
2022-11-02 23:44:26,448:INFO: Batch: 12/31	Total Loss 0.0901 (0.0824)
2022-11-02 23:44:26,709:INFO: Batch: 13/31	Total Loss 0.0917 (0.0831)
2022-11-02 23:44:26,971:INFO: Batch: 14/31	Total Loss 0.0999 (0.0842)
2022-11-02 23:44:27,236:INFO: Batch: 15/31	Total Loss 0.0767 (0.0837)
2022-11-02 23:44:27,497:INFO: Batch: 16/31	Total Loss 0.0918 (0.0842)
2022-11-02 23:44:27,759:INFO: Batch: 17/31	Total Loss 0.1044 (0.0853)
2022-11-02 23:44:28,016:INFO: Batch: 18/31	Total Loss 0.0770 (0.0848)
2022-11-02 23:44:28,275:INFO: Batch: 19/31	Total Loss 0.0826 (0.0847)
2022-11-02 23:44:28,532:INFO: Batch: 20/31	Total Loss 0.0638 (0.0838)
2022-11-02 23:44:28,793:INFO: Batch: 21/31	Total Loss 0.0853 (0.0838)
2022-11-02 23:44:29,052:INFO: Batch: 22/31	Total Loss 0.0877 (0.0840)
2022-11-02 23:44:29,318:INFO: Batch: 23/31	Total Loss 0.1035 (0.0848)
2022-11-02 23:44:29,585:INFO: Batch: 24/31	Total Loss 0.0806 (0.0846)
2022-11-02 23:44:29,855:INFO: Batch: 25/31	Total Loss 0.1113 (0.0857)
2022-11-02 23:44:30,122:INFO: Batch: 26/31	Total Loss 0.0871 (0.0857)
2022-11-02 23:44:30,389:INFO: Batch: 27/31	Total Loss 0.0869 (0.0857)
2022-11-02 23:44:30,653:INFO: Batch: 28/31	Total Loss 0.0592 (0.0849)
2022-11-02 23:44:30,914:INFO: Batch: 29/31	Total Loss 0.0812 (0.0848)
2022-11-02 23:44:31,033:INFO: Batch: 30/31	Total Loss 0.0276 (0.0842)
2022-11-02 23:44:31,195:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_202.pth.tar
2022-11-02 23:44:31,195:INFO: 
===> EPOCH: 203 (P2)
2022-11-02 23:44:31,195:INFO: - Computing loss (training)
2022-11-02 23:44:32,081:INFO: Batch:  0/31	Total Loss 0.0930 (0.0930)
2022-11-02 23:44:32,342:INFO: Batch:  1/31	Total Loss 0.1345 (0.1148)
2022-11-02 23:44:32,605:INFO: Batch:  2/31	Total Loss 0.0652 (0.0968)
2022-11-02 23:44:32,860:INFO: Batch:  3/31	Total Loss 0.0795 (0.0922)
2022-11-02 23:44:33,118:INFO: Batch:  4/31	Total Loss 0.0841 (0.0906)
2022-11-02 23:44:33,375:INFO: Batch:  5/31	Total Loss 0.0813 (0.0889)
2022-11-02 23:44:33,634:INFO: Batch:  6/31	Total Loss 0.0922 (0.0894)
2022-11-02 23:44:33,889:INFO: Batch:  7/31	Total Loss 0.0612 (0.0860)
2022-11-02 23:44:34,144:INFO: Batch:  8/31	Total Loss 0.1030 (0.0877)
2022-11-02 23:44:34,397:INFO: Batch:  9/31	Total Loss 0.0902 (0.0880)
2022-11-02 23:44:34,655:INFO: Batch: 10/31	Total Loss 0.0938 (0.0885)
2022-11-02 23:44:34,911:INFO: Batch: 11/31	Total Loss 0.0754 (0.0873)
2022-11-02 23:44:35,171:INFO: Batch: 12/31	Total Loss 0.0813 (0.0869)
2022-11-02 23:44:35,433:INFO: Batch: 13/31	Total Loss 0.0748 (0.0860)
2022-11-02 23:44:35,694:INFO: Batch: 14/31	Total Loss 0.0851 (0.0859)
2022-11-02 23:44:35,953:INFO: Batch: 15/31	Total Loss 0.0971 (0.0867)
2022-11-02 23:44:36,213:INFO: Batch: 16/31	Total Loss 0.0819 (0.0864)
2022-11-02 23:44:36,471:INFO: Batch: 17/31	Total Loss 0.0852 (0.0863)
2022-11-02 23:44:36,729:INFO: Batch: 18/31	Total Loss 0.0840 (0.0862)
2022-11-02 23:44:36,987:INFO: Batch: 19/31	Total Loss 0.0785 (0.0858)
2022-11-02 23:44:37,245:INFO: Batch: 20/31	Total Loss 0.0820 (0.0856)
2022-11-02 23:44:37,503:INFO: Batch: 21/31	Total Loss 0.0768 (0.0853)
2022-11-02 23:44:37,760:INFO: Batch: 22/31	Total Loss 0.0755 (0.0848)
2022-11-02 23:44:38,018:INFO: Batch: 23/31	Total Loss 0.0792 (0.0846)
2022-11-02 23:44:38,275:INFO: Batch: 24/31	Total Loss 0.0718 (0.0841)
2022-11-02 23:44:38,535:INFO: Batch: 25/31	Total Loss 0.0689 (0.0835)
2022-11-02 23:44:38,794:INFO: Batch: 26/31	Total Loss 0.0997 (0.0841)
2022-11-02 23:44:39,052:INFO: Batch: 27/31	Total Loss 0.0812 (0.0840)
2022-11-02 23:44:39,310:INFO: Batch: 28/31	Total Loss 0.0776 (0.0838)
2022-11-02 23:44:39,571:INFO: Batch: 29/31	Total Loss 0.0889 (0.0840)
2022-11-02 23:44:39,688:INFO: Batch: 30/31	Total Loss 0.0264 (0.0834)
2022-11-02 23:44:39,837:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_203.pth.tar
2022-11-02 23:44:39,837:INFO: 
===> EPOCH: 204 (P2)
2022-11-02 23:44:39,838:INFO: - Computing loss (training)
2022-11-02 23:44:40,696:INFO: Batch:  0/31	Total Loss 0.1039 (0.1039)
2022-11-02 23:44:40,958:INFO: Batch:  1/31	Total Loss 0.0805 (0.0927)
2022-11-02 23:44:41,220:INFO: Batch:  2/31	Total Loss 0.0758 (0.0873)
2022-11-02 23:44:41,473:INFO: Batch:  3/31	Total Loss 0.0536 (0.0792)
2022-11-02 23:44:41,730:INFO: Batch:  4/31	Total Loss 0.0727 (0.0779)
2022-11-02 23:44:41,986:INFO: Batch:  5/31	Total Loss 0.0810 (0.0784)
2022-11-02 23:44:42,243:INFO: Batch:  6/31	Total Loss 0.0897 (0.0801)
2022-11-02 23:44:42,499:INFO: Batch:  7/31	Total Loss 0.0908 (0.0813)
2022-11-02 23:44:42,759:INFO: Batch:  8/31	Total Loss 0.0764 (0.0807)
2022-11-02 23:44:43,012:INFO: Batch:  9/31	Total Loss 0.0762 (0.0803)
2022-11-02 23:44:43,270:INFO: Batch: 10/31	Total Loss 0.0931 (0.0814)
2022-11-02 23:44:43,526:INFO: Batch: 11/31	Total Loss 0.0809 (0.0814)
2022-11-02 23:44:43,785:INFO: Batch: 12/31	Total Loss 0.0784 (0.0812)
2022-11-02 23:44:44,043:INFO: Batch: 13/31	Total Loss 0.0810 (0.0812)
2022-11-02 23:44:44,303:INFO: Batch: 14/31	Total Loss 0.0827 (0.0813)
2022-11-02 23:44:44,564:INFO: Batch: 15/31	Total Loss 0.0716 (0.0806)
2022-11-02 23:44:44,826:INFO: Batch: 16/31	Total Loss 0.0789 (0.0805)
2022-11-02 23:44:45,086:INFO: Batch: 17/31	Total Loss 0.1127 (0.0823)
2022-11-02 23:44:45,346:INFO: Batch: 18/31	Total Loss 0.0990 (0.0833)
2022-11-02 23:44:45,606:INFO: Batch: 19/31	Total Loss 0.0833 (0.0833)
2022-11-02 23:44:45,866:INFO: Batch: 20/31	Total Loss 0.0859 (0.0834)
2022-11-02 23:44:46,126:INFO: Batch: 21/31	Total Loss 0.0999 (0.0842)
2022-11-02 23:44:46,385:INFO: Batch: 22/31	Total Loss 0.0877 (0.0843)
2022-11-02 23:44:46,645:INFO: Batch: 23/31	Total Loss 0.0802 (0.0841)
2022-11-02 23:44:46,907:INFO: Batch: 24/31	Total Loss 0.0844 (0.0841)
2022-11-02 23:44:47,167:INFO: Batch: 25/31	Total Loss 0.0826 (0.0841)
2022-11-02 23:44:47,427:INFO: Batch: 26/31	Total Loss 0.0908 (0.0843)
2022-11-02 23:44:47,687:INFO: Batch: 27/31	Total Loss 0.0710 (0.0838)
2022-11-02 23:44:47,947:INFO: Batch: 28/31	Total Loss 0.0755 (0.0835)
2022-11-02 23:44:48,206:INFO: Batch: 29/31	Total Loss 0.0986 (0.0840)
2022-11-02 23:44:48,325:INFO: Batch: 30/31	Total Loss 0.0290 (0.0836)
2022-11-02 23:44:48,486:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_204.pth.tar
2022-11-02 23:44:48,486:INFO: 
===> EPOCH: 205 (P2)
2022-11-02 23:44:48,486:INFO: - Computing loss (training)
2022-11-02 23:44:49,374:INFO: Batch:  0/31	Total Loss 0.0803 (0.0803)
2022-11-02 23:44:49,635:INFO: Batch:  1/31	Total Loss 0.0884 (0.0848)
2022-11-02 23:44:49,892:INFO: Batch:  2/31	Total Loss 0.0760 (0.0819)
2022-11-02 23:44:50,148:INFO: Batch:  3/31	Total Loss 0.0880 (0.0834)
2022-11-02 23:44:50,406:INFO: Batch:  4/31	Total Loss 0.0913 (0.0852)
2022-11-02 23:44:50,664:INFO: Batch:  5/31	Total Loss 0.0735 (0.0832)
2022-11-02 23:44:50,924:INFO: Batch:  6/31	Total Loss 0.0916 (0.0844)
2022-11-02 23:44:51,178:INFO: Batch:  7/31	Total Loss 0.0769 (0.0837)
2022-11-02 23:44:51,433:INFO: Batch:  8/31	Total Loss 0.0786 (0.0831)
2022-11-02 23:44:51,688:INFO: Batch:  9/31	Total Loss 0.0657 (0.0815)
2022-11-02 23:44:51,946:INFO: Batch: 10/31	Total Loss 0.0753 (0.0809)
2022-11-02 23:44:52,204:INFO: Batch: 11/31	Total Loss 0.0929 (0.0817)
2022-11-02 23:44:52,463:INFO: Batch: 12/31	Total Loss 0.0868 (0.0821)
2022-11-02 23:44:52,724:INFO: Batch: 13/31	Total Loss 0.1000 (0.0835)
2022-11-02 23:44:52,983:INFO: Batch: 14/31	Total Loss 0.0762 (0.0830)
2022-11-02 23:44:53,242:INFO: Batch: 15/31	Total Loss 0.1070 (0.0844)
2022-11-02 23:44:53,504:INFO: Batch: 16/31	Total Loss 0.0893 (0.0847)
2022-11-02 23:44:53,765:INFO: Batch: 17/31	Total Loss 0.1053 (0.0858)
2022-11-02 23:44:54,026:INFO: Batch: 18/31	Total Loss 0.1027 (0.0867)
2022-11-02 23:44:54,286:INFO: Batch: 19/31	Total Loss 0.0953 (0.0871)
2022-11-02 23:44:54,543:INFO: Batch: 20/31	Total Loss 0.0718 (0.0865)
2022-11-02 23:44:54,801:INFO: Batch: 21/31	Total Loss 0.0816 (0.0862)
2022-11-02 23:44:55,059:INFO: Batch: 22/31	Total Loss 0.0903 (0.0864)
2022-11-02 23:44:55,317:INFO: Batch: 23/31	Total Loss 0.0716 (0.0857)
2022-11-02 23:44:55,575:INFO: Batch: 24/31	Total Loss 0.0884 (0.0858)
2022-11-02 23:44:55,833:INFO: Batch: 25/31	Total Loss 0.1001 (0.0863)
2022-11-02 23:44:56,091:INFO: Batch: 26/31	Total Loss 0.0719 (0.0858)
2022-11-02 23:44:56,349:INFO: Batch: 27/31	Total Loss 0.0848 (0.0858)
2022-11-02 23:44:56,608:INFO: Batch: 28/31	Total Loss 0.0767 (0.0855)
2022-11-02 23:44:56,867:INFO: Batch: 29/31	Total Loss 0.0799 (0.0853)
2022-11-02 23:44:56,984:INFO: Batch: 30/31	Total Loss 0.0435 (0.0849)
2022-11-02 23:44:57,140:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_205.pth.tar
2022-11-02 23:44:57,141:INFO: 
===> EPOCH: 206 (P2)
2022-11-02 23:44:57,141:INFO: - Computing loss (training)
2022-11-02 23:44:57,985:INFO: Batch:  0/31	Total Loss 0.0989 (0.0989)
2022-11-02 23:44:58,249:INFO: Batch:  1/31	Total Loss 0.0873 (0.0932)
2022-11-02 23:44:58,505:INFO: Batch:  2/31	Total Loss 0.0804 (0.0891)
2022-11-02 23:44:58,759:INFO: Batch:  3/31	Total Loss 0.0894 (0.0891)
2022-11-02 23:44:59,014:INFO: Batch:  4/31	Total Loss 0.0930 (0.0899)
2022-11-02 23:44:59,272:INFO: Batch:  5/31	Total Loss 0.0716 (0.0866)
2022-11-02 23:44:59,533:INFO: Batch:  6/31	Total Loss 0.0894 (0.0870)
2022-11-02 23:44:59,794:INFO: Batch:  7/31	Total Loss 0.0794 (0.0861)
2022-11-02 23:45:00,050:INFO: Batch:  8/31	Total Loss 0.0759 (0.0850)
2022-11-02 23:45:00,304:INFO: Batch:  9/31	Total Loss 0.1042 (0.0866)
2022-11-02 23:45:00,560:INFO: Batch: 10/31	Total Loss 0.0885 (0.0868)
2022-11-02 23:45:00,816:INFO: Batch: 11/31	Total Loss 0.0678 (0.0852)
2022-11-02 23:45:01,075:INFO: Batch: 12/31	Total Loss 0.0991 (0.0861)
2022-11-02 23:45:01,337:INFO: Batch: 13/31	Total Loss 0.0871 (0.0862)
2022-11-02 23:45:01,597:INFO: Batch: 14/31	Total Loss 0.0856 (0.0862)
2022-11-02 23:45:01,856:INFO: Batch: 15/31	Total Loss 0.0819 (0.0859)
2022-11-02 23:45:02,117:INFO: Batch: 16/31	Total Loss 0.0846 (0.0858)
2022-11-02 23:45:02,377:INFO: Batch: 17/31	Total Loss 0.0810 (0.0855)
2022-11-02 23:45:02,637:INFO: Batch: 18/31	Total Loss 0.1110 (0.0869)
2022-11-02 23:45:02,895:INFO: Batch: 19/31	Total Loss 0.0526 (0.0852)
2022-11-02 23:45:03,155:INFO: Batch: 20/31	Total Loss 0.0885 (0.0854)
2022-11-02 23:45:03,415:INFO: Batch: 21/31	Total Loss 0.0832 (0.0853)
2022-11-02 23:45:03,675:INFO: Batch: 22/31	Total Loss 0.0863 (0.0853)
2022-11-02 23:45:03,934:INFO: Batch: 23/31	Total Loss 0.0712 (0.0847)
2022-11-02 23:45:04,193:INFO: Batch: 24/31	Total Loss 0.0720 (0.0842)
2022-11-02 23:45:04,451:INFO: Batch: 25/31	Total Loss 0.0712 (0.0837)
2022-11-02 23:45:04,710:INFO: Batch: 26/31	Total Loss 0.1063 (0.0846)
2022-11-02 23:45:04,969:INFO: Batch: 27/31	Total Loss 0.0845 (0.0846)
2022-11-02 23:45:05,230:INFO: Batch: 28/31	Total Loss 0.0729 (0.0841)
2022-11-02 23:45:05,491:INFO: Batch: 29/31	Total Loss 0.0727 (0.0837)
2022-11-02 23:45:05,609:INFO: Batch: 30/31	Total Loss 0.0346 (0.0832)
2022-11-02 23:45:05,762:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_206.pth.tar
2022-11-02 23:45:05,762:INFO: 
===> EPOCH: 207 (P2)
2022-11-02 23:45:05,763:INFO: - Computing loss (training)
2022-11-02 23:45:06,611:INFO: Batch:  0/31	Total Loss 0.0768 (0.0768)
2022-11-02 23:45:06,869:INFO: Batch:  1/31	Total Loss 0.0701 (0.0733)
2022-11-02 23:45:07,127:INFO: Batch:  2/31	Total Loss 0.0756 (0.0741)
2022-11-02 23:45:07,386:INFO: Batch:  3/31	Total Loss 0.0689 (0.0727)
2022-11-02 23:45:07,643:INFO: Batch:  4/31	Total Loss 0.1130 (0.0801)
2022-11-02 23:45:07,900:INFO: Batch:  5/31	Total Loss 0.0702 (0.0786)
2022-11-02 23:45:08,155:INFO: Batch:  6/31	Total Loss 0.0719 (0.0776)
2022-11-02 23:45:08,410:INFO: Batch:  7/31	Total Loss 0.0796 (0.0778)
2022-11-02 23:45:08,665:INFO: Batch:  8/31	Total Loss 0.0718 (0.0771)
2022-11-02 23:45:08,920:INFO: Batch:  9/31	Total Loss 0.0913 (0.0786)
2022-11-02 23:45:09,174:INFO: Batch: 10/31	Total Loss 0.0865 (0.0793)
2022-11-02 23:45:09,431:INFO: Batch: 11/31	Total Loss 0.0845 (0.0797)
2022-11-02 23:45:09,692:INFO: Batch: 12/31	Total Loss 0.0719 (0.0791)
2022-11-02 23:45:09,950:INFO: Batch: 13/31	Total Loss 0.0728 (0.0787)
2022-11-02 23:45:10,210:INFO: Batch: 14/31	Total Loss 0.0676 (0.0779)
2022-11-02 23:45:10,467:INFO: Batch: 15/31	Total Loss 0.0886 (0.0786)
2022-11-02 23:45:10,726:INFO: Batch: 16/31	Total Loss 0.0809 (0.0788)
2022-11-02 23:45:10,988:INFO: Batch: 17/31	Total Loss 0.0701 (0.0783)
2022-11-02 23:45:11,248:INFO: Batch: 18/31	Total Loss 0.0745 (0.0781)
2022-11-02 23:45:11,505:INFO: Batch: 19/31	Total Loss 0.0872 (0.0785)
2022-11-02 23:45:11,762:INFO: Batch: 20/31	Total Loss 0.0620 (0.0776)
2022-11-02 23:45:12,019:INFO: Batch: 21/31	Total Loss 0.0762 (0.0776)
2022-11-02 23:45:12,277:INFO: Batch: 22/31	Total Loss 0.0767 (0.0775)
2022-11-02 23:45:12,611:INFO: Batch: 23/31	Total Loss 0.0774 (0.0775)
2022-11-02 23:45:12,868:INFO: Batch: 24/31	Total Loss 0.0775 (0.0775)
2022-11-02 23:45:13,127:INFO: Batch: 25/31	Total Loss 0.0816 (0.0777)
2022-11-02 23:45:13,384:INFO: Batch: 26/31	Total Loss 0.0721 (0.0775)
2022-11-02 23:45:13,643:INFO: Batch: 27/31	Total Loss 0.0566 (0.0767)
2022-11-02 23:45:13,901:INFO: Batch: 28/31	Total Loss 0.0641 (0.0762)
2022-11-02 23:45:14,158:INFO: Batch: 29/31	Total Loss 0.0740 (0.0761)
2022-11-02 23:45:14,276:INFO: Batch: 30/31	Total Loss 0.0253 (0.0756)
2022-11-02 23:45:14,437:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_207.pth.tar
2022-11-02 23:45:14,437:INFO: 
===> EPOCH: 208 (P2)
2022-11-02 23:45:14,437:INFO: - Computing loss (training)
2022-11-02 23:45:15,293:INFO: Batch:  0/31	Total Loss 0.0697 (0.0697)
2022-11-02 23:45:15,554:INFO: Batch:  1/31	Total Loss 0.0868 (0.0785)
2022-11-02 23:45:15,814:INFO: Batch:  2/31	Total Loss 0.1073 (0.0869)
2022-11-02 23:45:16,070:INFO: Batch:  3/31	Total Loss 0.0775 (0.0846)
2022-11-02 23:45:16,324:INFO: Batch:  4/31	Total Loss 0.0775 (0.0831)
2022-11-02 23:45:16,579:INFO: Batch:  5/31	Total Loss 0.0705 (0.0810)
2022-11-02 23:45:16,832:INFO: Batch:  6/31	Total Loss 0.0481 (0.0768)
2022-11-02 23:45:17,086:INFO: Batch:  7/31	Total Loss 0.0707 (0.0761)
2022-11-02 23:45:17,342:INFO: Batch:  8/31	Total Loss 0.0910 (0.0780)
2022-11-02 23:45:17,599:INFO: Batch:  9/31	Total Loss 0.0688 (0.0770)
2022-11-02 23:45:17,853:INFO: Batch: 10/31	Total Loss 0.0657 (0.0761)
2022-11-02 23:45:18,108:INFO: Batch: 11/31	Total Loss 0.0743 (0.0759)
2022-11-02 23:45:18,366:INFO: Batch: 12/31	Total Loss 0.0834 (0.0765)
2022-11-02 23:45:18,624:INFO: Batch: 13/31	Total Loss 0.0767 (0.0766)
2022-11-02 23:45:18,883:INFO: Batch: 14/31	Total Loss 0.0805 (0.0768)
2022-11-02 23:45:19,142:INFO: Batch: 15/31	Total Loss 0.0805 (0.0770)
2022-11-02 23:45:19,401:INFO: Batch: 16/31	Total Loss 0.0997 (0.0784)
2022-11-02 23:45:19,661:INFO: Batch: 17/31	Total Loss 0.0889 (0.0790)
2022-11-02 23:45:19,921:INFO: Batch: 18/31	Total Loss 0.0729 (0.0787)
2022-11-02 23:45:20,181:INFO: Batch: 19/31	Total Loss 0.0657 (0.0781)
2022-11-02 23:45:20,441:INFO: Batch: 20/31	Total Loss 0.0731 (0.0778)
2022-11-02 23:45:20,700:INFO: Batch: 21/31	Total Loss 0.0772 (0.0778)
2022-11-02 23:45:20,958:INFO: Batch: 22/31	Total Loss 0.0782 (0.0778)
2022-11-02 23:45:21,216:INFO: Batch: 23/31	Total Loss 0.0769 (0.0778)
2022-11-02 23:45:21,474:INFO: Batch: 24/31	Total Loss 0.0564 (0.0770)
2022-11-02 23:45:21,732:INFO: Batch: 25/31	Total Loss 0.0606 (0.0763)
2022-11-02 23:45:21,991:INFO: Batch: 26/31	Total Loss 0.0912 (0.0770)
2022-11-02 23:45:22,249:INFO: Batch: 27/31	Total Loss 0.1054 (0.0779)
2022-11-02 23:45:22,506:INFO: Batch: 28/31	Total Loss 0.0763 (0.0778)
2022-11-02 23:45:22,763:INFO: Batch: 29/31	Total Loss 0.0773 (0.0778)
2022-11-02 23:45:22,880:INFO: Batch: 30/31	Total Loss 0.0306 (0.0774)
2022-11-02 23:45:23,029:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_208.pth.tar
2022-11-02 23:45:23,030:INFO: 
===> EPOCH: 209 (P2)
2022-11-02 23:45:23,030:INFO: - Computing loss (training)
2022-11-02 23:45:23,921:INFO: Batch:  0/31	Total Loss 0.0747 (0.0747)
2022-11-02 23:45:24,181:INFO: Batch:  1/31	Total Loss 0.0973 (0.0856)
2022-11-02 23:45:24,446:INFO: Batch:  2/31	Total Loss 0.0820 (0.0845)
2022-11-02 23:45:24,712:INFO: Batch:  3/31	Total Loss 0.0705 (0.0807)
2022-11-02 23:45:24,971:INFO: Batch:  4/31	Total Loss 0.0678 (0.0779)
2022-11-02 23:45:25,231:INFO: Batch:  5/31	Total Loss 0.0814 (0.0785)
2022-11-02 23:45:25,488:INFO: Batch:  6/31	Total Loss 0.0809 (0.0788)
2022-11-02 23:45:25,744:INFO: Batch:  7/31	Total Loss 0.0721 (0.0781)
2022-11-02 23:45:26,002:INFO: Batch:  8/31	Total Loss 0.0687 (0.0770)
2022-11-02 23:45:26,264:INFO: Batch:  9/31	Total Loss 0.0750 (0.0768)
2022-11-02 23:45:26,523:INFO: Batch: 10/31	Total Loss 0.0681 (0.0760)
2022-11-02 23:45:26,785:INFO: Batch: 11/31	Total Loss 0.0917 (0.0773)
2022-11-02 23:45:27,048:INFO: Batch: 12/31	Total Loss 0.0719 (0.0769)
2022-11-02 23:45:27,311:INFO: Batch: 13/31	Total Loss 0.0981 (0.0786)
2022-11-02 23:45:27,574:INFO: Batch: 14/31	Total Loss 0.0650 (0.0777)
2022-11-02 23:45:27,837:INFO: Batch: 15/31	Total Loss 0.0754 (0.0775)
2022-11-02 23:45:28,101:INFO: Batch: 16/31	Total Loss 0.0722 (0.0772)
2022-11-02 23:45:28,362:INFO: Batch: 17/31	Total Loss 0.0706 (0.0769)
2022-11-02 23:45:28,626:INFO: Batch: 18/31	Total Loss 0.0953 (0.0777)
2022-11-02 23:45:28,889:INFO: Batch: 19/31	Total Loss 0.0693 (0.0773)
2022-11-02 23:45:29,153:INFO: Batch: 20/31	Total Loss 0.0705 (0.0769)
2022-11-02 23:45:29,415:INFO: Batch: 21/31	Total Loss 0.0552 (0.0760)
2022-11-02 23:45:29,680:INFO: Batch: 22/31	Total Loss 0.0655 (0.0755)
2022-11-02 23:45:29,941:INFO: Batch: 23/31	Total Loss 0.0735 (0.0755)
2022-11-02 23:45:30,203:INFO: Batch: 24/31	Total Loss 0.0708 (0.0753)
2022-11-02 23:45:30,464:INFO: Batch: 25/31	Total Loss 0.0697 (0.0751)
2022-11-02 23:45:30,724:INFO: Batch: 26/31	Total Loss 0.0630 (0.0747)
2022-11-02 23:45:30,985:INFO: Batch: 27/31	Total Loss 0.0701 (0.0745)
2022-11-02 23:45:31,245:INFO: Batch: 28/31	Total Loss 0.0681 (0.0743)
2022-11-02 23:45:31,506:INFO: Batch: 29/31	Total Loss 0.0655 (0.0740)
2022-11-02 23:45:31,625:INFO: Batch: 30/31	Total Loss 0.0254 (0.0735)
2022-11-02 23:45:31,771:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_209.pth.tar
2022-11-02 23:45:31,771:INFO: 
===> EPOCH: 210 (P2)
2022-11-02 23:45:31,772:INFO: - Computing loss (training)
2022-11-02 23:45:32,658:INFO: Batch:  0/31	Total Loss 0.0849 (0.0849)
2022-11-02 23:45:32,920:INFO: Batch:  1/31	Total Loss 0.0727 (0.0787)
2022-11-02 23:45:33,200:INFO: Batch:  2/31	Total Loss 0.0670 (0.0743)
2022-11-02 23:45:33,457:INFO: Batch:  3/31	Total Loss 0.0745 (0.0744)
2022-11-02 23:45:33,716:INFO: Batch:  4/31	Total Loss 0.1020 (0.0800)
2022-11-02 23:45:33,973:INFO: Batch:  5/31	Total Loss 0.0652 (0.0776)
2022-11-02 23:45:34,234:INFO: Batch:  6/31	Total Loss 0.0775 (0.0776)
2022-11-02 23:45:34,489:INFO: Batch:  7/31	Total Loss 0.0700 (0.0767)
2022-11-02 23:45:34,744:INFO: Batch:  8/31	Total Loss 0.0817 (0.0771)
2022-11-02 23:45:35,002:INFO: Batch:  9/31	Total Loss 0.0749 (0.0769)
2022-11-02 23:45:35,260:INFO: Batch: 10/31	Total Loss 0.0692 (0.0762)
2022-11-02 23:45:35,518:INFO: Batch: 11/31	Total Loss 0.0662 (0.0754)
2022-11-02 23:45:35,778:INFO: Batch: 12/31	Total Loss 0.0669 (0.0748)
2022-11-02 23:45:36,038:INFO: Batch: 13/31	Total Loss 0.0736 (0.0747)
2022-11-02 23:45:36,298:INFO: Batch: 14/31	Total Loss 0.0712 (0.0745)
2022-11-02 23:45:36,559:INFO: Batch: 15/31	Total Loss 0.0815 (0.0749)
2022-11-02 23:45:36,822:INFO: Batch: 16/31	Total Loss 0.0767 (0.0750)
2022-11-02 23:45:37,082:INFO: Batch: 17/31	Total Loss 0.0681 (0.0746)
2022-11-02 23:45:37,348:INFO: Batch: 18/31	Total Loss 0.0715 (0.0744)
2022-11-02 23:45:37,608:INFO: Batch: 19/31	Total Loss 0.0722 (0.0743)
2022-11-02 23:45:37,868:INFO: Batch: 20/31	Total Loss 0.0700 (0.0741)
2022-11-02 23:45:38,127:INFO: Batch: 21/31	Total Loss 0.0654 (0.0737)
2022-11-02 23:45:38,385:INFO: Batch: 22/31	Total Loss 0.0665 (0.0734)
2022-11-02 23:45:38,644:INFO: Batch: 23/31	Total Loss 0.0757 (0.0735)
2022-11-02 23:45:38,903:INFO: Batch: 24/31	Total Loss 0.0808 (0.0738)
2022-11-02 23:45:39,162:INFO: Batch: 25/31	Total Loss 0.0853 (0.0741)
2022-11-02 23:45:39,421:INFO: Batch: 26/31	Total Loss 0.0638 (0.0737)
2022-11-02 23:45:39,685:INFO: Batch: 27/31	Total Loss 0.0789 (0.0739)
2022-11-02 23:45:39,945:INFO: Batch: 28/31	Total Loss 0.0877 (0.0744)
2022-11-02 23:45:40,205:INFO: Batch: 29/31	Total Loss 0.0737 (0.0744)
2022-11-02 23:45:40,323:INFO: Batch: 30/31	Total Loss 0.0326 (0.0741)
2022-11-02 23:45:40,476:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_210.pth.tar
2022-11-02 23:45:40,476:INFO: 
===> EPOCH: 211 (P2)
2022-11-02 23:45:40,477:INFO: - Computing loss (training)
2022-11-02 23:45:41,359:INFO: Batch:  0/31	Total Loss 0.0736 (0.0736)
2022-11-02 23:45:41,623:INFO: Batch:  1/31	Total Loss 0.0666 (0.0701)
2022-11-02 23:45:41,880:INFO: Batch:  2/31	Total Loss 0.0730 (0.0712)
2022-11-02 23:45:42,140:INFO: Batch:  3/31	Total Loss 0.0823 (0.0739)
2022-11-02 23:45:42,398:INFO: Batch:  4/31	Total Loss 0.0672 (0.0724)
2022-11-02 23:45:42,657:INFO: Batch:  5/31	Total Loss 0.0659 (0.0715)
2022-11-02 23:45:42,913:INFO: Batch:  6/31	Total Loss 0.0704 (0.0713)
2022-11-02 23:45:43,173:INFO: Batch:  7/31	Total Loss 0.0847 (0.0729)
2022-11-02 23:45:43,431:INFO: Batch:  8/31	Total Loss 0.0842 (0.0743)
2022-11-02 23:45:43,687:INFO: Batch:  9/31	Total Loss 0.0635 (0.0732)
2022-11-02 23:45:43,946:INFO: Batch: 10/31	Total Loss 0.0777 (0.0736)
2022-11-02 23:45:44,204:INFO: Batch: 11/31	Total Loss 0.0809 (0.0741)
2022-11-02 23:45:44,465:INFO: Batch: 12/31	Total Loss 0.0669 (0.0736)
2022-11-02 23:45:44,725:INFO: Batch: 13/31	Total Loss 0.0858 (0.0743)
2022-11-02 23:45:44,985:INFO: Batch: 14/31	Total Loss 0.1039 (0.0764)
2022-11-02 23:45:45,246:INFO: Batch: 15/31	Total Loss 0.0783 (0.0765)
2022-11-02 23:45:45,508:INFO: Batch: 16/31	Total Loss 0.0599 (0.0755)
2022-11-02 23:45:45,769:INFO: Batch: 17/31	Total Loss 0.0659 (0.0749)
2022-11-02 23:45:46,029:INFO: Batch: 18/31	Total Loss 0.0641 (0.0744)
2022-11-02 23:45:46,289:INFO: Batch: 19/31	Total Loss 0.0661 (0.0740)
2022-11-02 23:45:46,549:INFO: Batch: 20/31	Total Loss 0.0854 (0.0745)
2022-11-02 23:45:46,809:INFO: Batch: 21/31	Total Loss 0.1040 (0.0757)
2022-11-02 23:45:47,070:INFO: Batch: 22/31	Total Loss 0.0790 (0.0759)
2022-11-02 23:45:47,331:INFO: Batch: 23/31	Total Loss 0.0642 (0.0753)
2022-11-02 23:45:47,591:INFO: Batch: 24/31	Total Loss 0.0721 (0.0752)
2022-11-02 23:45:47,852:INFO: Batch: 25/31	Total Loss 0.0864 (0.0756)
2022-11-02 23:45:48,112:INFO: Batch: 26/31	Total Loss 0.0852 (0.0760)
2022-11-02 23:45:48,371:INFO: Batch: 27/31	Total Loss 0.0628 (0.0755)
2022-11-02 23:45:48,631:INFO: Batch: 28/31	Total Loss 0.0651 (0.0751)
2022-11-02 23:45:48,892:INFO: Batch: 29/31	Total Loss 0.0754 (0.0751)
2022-11-02 23:45:49,010:INFO: Batch: 30/31	Total Loss 0.0220 (0.0746)
2022-11-02 23:45:49,168:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_211.pth.tar
2022-11-02 23:45:49,168:INFO: 
===> EPOCH: 212 (P2)
2022-11-02 23:45:49,168:INFO: - Computing loss (training)
2022-11-02 23:45:50,020:INFO: Batch:  0/31	Total Loss 0.0626 (0.0626)
2022-11-02 23:45:50,279:INFO: Batch:  1/31	Total Loss 0.0917 (0.0762)
2022-11-02 23:45:50,543:INFO: Batch:  2/31	Total Loss 0.0967 (0.0826)
2022-11-02 23:45:50,800:INFO: Batch:  3/31	Total Loss 0.0657 (0.0783)
2022-11-02 23:45:51,053:INFO: Batch:  4/31	Total Loss 0.0795 (0.0785)
2022-11-02 23:45:51,313:INFO: Batch:  5/31	Total Loss 0.0699 (0.0771)
2022-11-02 23:45:51,568:INFO: Batch:  6/31	Total Loss 0.0726 (0.0765)
2022-11-02 23:45:51,826:INFO: Batch:  7/31	Total Loss 0.0751 (0.0763)
2022-11-02 23:45:52,081:INFO: Batch:  8/31	Total Loss 0.0766 (0.0763)
2022-11-02 23:45:52,338:INFO: Batch:  9/31	Total Loss 0.0655 (0.0753)
2022-11-02 23:45:52,597:INFO: Batch: 10/31	Total Loss 0.0637 (0.0743)
2022-11-02 23:45:52,854:INFO: Batch: 11/31	Total Loss 0.0938 (0.0761)
2022-11-02 23:45:53,114:INFO: Batch: 12/31	Total Loss 0.0645 (0.0752)
2022-11-02 23:45:53,373:INFO: Batch: 13/31	Total Loss 0.0805 (0.0755)
2022-11-02 23:45:53,633:INFO: Batch: 14/31	Total Loss 0.0686 (0.0751)
2022-11-02 23:45:53,894:INFO: Batch: 15/31	Total Loss 0.0746 (0.0750)
2022-11-02 23:45:54,154:INFO: Batch: 16/31	Total Loss 0.0763 (0.0751)
2022-11-02 23:45:54,414:INFO: Batch: 17/31	Total Loss 0.0693 (0.0748)
2022-11-02 23:45:54,674:INFO: Batch: 18/31	Total Loss 0.0648 (0.0742)
2022-11-02 23:45:54,933:INFO: Batch: 19/31	Total Loss 0.0659 (0.0739)
2022-11-02 23:45:55,192:INFO: Batch: 20/31	Total Loss 0.0646 (0.0734)
2022-11-02 23:45:55,451:INFO: Batch: 21/31	Total Loss 0.0475 (0.0722)
2022-11-02 23:45:55,709:INFO: Batch: 22/31	Total Loss 0.1074 (0.0735)
2022-11-02 23:45:55,968:INFO: Batch: 23/31	Total Loss 0.0739 (0.0736)
2022-11-02 23:45:56,227:INFO: Batch: 24/31	Total Loss 0.0653 (0.0732)
2022-11-02 23:45:56,486:INFO: Batch: 25/31	Total Loss 0.0894 (0.0738)
2022-11-02 23:45:56,744:INFO: Batch: 26/31	Total Loss 0.0737 (0.0738)
2022-11-02 23:45:57,003:INFO: Batch: 27/31	Total Loss 0.0588 (0.0733)
2022-11-02 23:45:57,262:INFO: Batch: 28/31	Total Loss 0.0676 (0.0731)
2022-11-02 23:45:57,521:INFO: Batch: 29/31	Total Loss 0.0642 (0.0728)
2022-11-02 23:45:57,640:INFO: Batch: 30/31	Total Loss 0.0247 (0.0722)
2022-11-02 23:45:57,794:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_212.pth.tar
2022-11-02 23:45:57,794:INFO: 
===> EPOCH: 213 (P2)
2022-11-02 23:45:57,794:INFO: - Computing loss (training)
2022-11-02 23:45:58,676:INFO: Batch:  0/31	Total Loss 0.0688 (0.0688)
2022-11-02 23:45:58,939:INFO: Batch:  1/31	Total Loss 0.0751 (0.0719)
2022-11-02 23:45:59,198:INFO: Batch:  2/31	Total Loss 0.0681 (0.0706)
2022-11-02 23:45:59,455:INFO: Batch:  3/31	Total Loss 0.0624 (0.0685)
2022-11-02 23:45:59,718:INFO: Batch:  4/31	Total Loss 0.0849 (0.0718)
2022-11-02 23:45:59,977:INFO: Batch:  5/31	Total Loss 0.0678 (0.0712)
2022-11-02 23:46:00,236:INFO: Batch:  6/31	Total Loss 0.0593 (0.0694)
2022-11-02 23:46:00,490:INFO: Batch:  7/31	Total Loss 0.0684 (0.0693)
2022-11-02 23:46:00,749:INFO: Batch:  8/31	Total Loss 0.0726 (0.0696)
2022-11-02 23:46:01,005:INFO: Batch:  9/31	Total Loss 0.0821 (0.0709)
2022-11-02 23:46:01,269:INFO: Batch: 10/31	Total Loss 0.0635 (0.0702)
2022-11-02 23:46:01,526:INFO: Batch: 11/31	Total Loss 0.0806 (0.0710)
2022-11-02 23:46:01,789:INFO: Batch: 12/31	Total Loss 0.0622 (0.0703)
2022-11-02 23:46:02,050:INFO: Batch: 13/31	Total Loss 0.0638 (0.0699)
2022-11-02 23:46:02,313:INFO: Batch: 14/31	Total Loss 0.0708 (0.0700)
2022-11-02 23:46:02,575:INFO: Batch: 15/31	Total Loss 0.0600 (0.0693)
2022-11-02 23:46:02,835:INFO: Batch: 16/31	Total Loss 0.0670 (0.0691)
2022-11-02 23:46:03,093:INFO: Batch: 17/31	Total Loss 0.0756 (0.0695)
2022-11-02 23:46:03,354:INFO: Batch: 18/31	Total Loss 0.0675 (0.0694)
2022-11-02 23:46:03,614:INFO: Batch: 19/31	Total Loss 0.0671 (0.0692)
2022-11-02 23:46:03,874:INFO: Batch: 20/31	Total Loss 0.0670 (0.0691)
2022-11-02 23:46:04,134:INFO: Batch: 21/31	Total Loss 0.1068 (0.0707)
2022-11-02 23:46:04,391:INFO: Batch: 22/31	Total Loss 0.0698 (0.0706)
2022-11-02 23:46:04,650:INFO: Batch: 23/31	Total Loss 0.0696 (0.0706)
2022-11-02 23:46:04,910:INFO: Batch: 24/31	Total Loss 0.0635 (0.0703)
2022-11-02 23:46:05,170:INFO: Batch: 25/31	Total Loss 0.0675 (0.0702)
2022-11-02 23:46:05,432:INFO: Batch: 26/31	Total Loss 0.0687 (0.0701)
2022-11-02 23:46:05,693:INFO: Batch: 27/31	Total Loss 0.0804 (0.0705)
2022-11-02 23:46:05,953:INFO: Batch: 28/31	Total Loss 0.0720 (0.0705)
2022-11-02 23:46:06,214:INFO: Batch: 29/31	Total Loss 0.0556 (0.0700)
2022-11-02 23:46:06,332:INFO: Batch: 30/31	Total Loss 0.0258 (0.0697)
2022-11-02 23:46:06,492:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_213.pth.tar
2022-11-02 23:46:06,493:INFO: 
===> EPOCH: 214 (P2)
2022-11-02 23:46:06,493:INFO: - Computing loss (training)
2022-11-02 23:46:07,389:INFO: Batch:  0/31	Total Loss 0.0591 (0.0591)
2022-11-02 23:46:07,727:INFO: Batch:  1/31	Total Loss 0.1065 (0.0815)
2022-11-02 23:46:07,982:INFO: Batch:  2/31	Total Loss 0.0651 (0.0756)
2022-11-02 23:46:08,240:INFO: Batch:  3/31	Total Loss 0.0624 (0.0720)
2022-11-02 23:46:08,496:INFO: Batch:  4/31	Total Loss 0.0640 (0.0703)
2022-11-02 23:46:08,755:INFO: Batch:  5/31	Total Loss 0.0673 (0.0698)
2022-11-02 23:46:09,010:INFO: Batch:  6/31	Total Loss 0.0676 (0.0695)
2022-11-02 23:46:09,266:INFO: Batch:  7/31	Total Loss 0.0771 (0.0704)
2022-11-02 23:46:09,524:INFO: Batch:  8/31	Total Loss 0.0719 (0.0706)
2022-11-02 23:46:09,781:INFO: Batch:  9/31	Total Loss 0.0630 (0.0698)
2022-11-02 23:46:10,039:INFO: Batch: 10/31	Total Loss 0.0756 (0.0704)
2022-11-02 23:46:10,296:INFO: Batch: 11/31	Total Loss 0.0602 (0.0694)
2022-11-02 23:46:10,555:INFO: Batch: 12/31	Total Loss 0.0602 (0.0687)
2022-11-02 23:46:10,816:INFO: Batch: 13/31	Total Loss 0.0699 (0.0688)
2022-11-02 23:46:11,077:INFO: Batch: 14/31	Total Loss 0.0727 (0.0691)
2022-11-02 23:46:11,337:INFO: Batch: 15/31	Total Loss 0.0523 (0.0681)
2022-11-02 23:46:11,598:INFO: Batch: 16/31	Total Loss 0.0569 (0.0675)
2022-11-02 23:46:11,858:INFO: Batch: 17/31	Total Loss 0.0657 (0.0674)
2022-11-02 23:46:12,118:INFO: Batch: 18/31	Total Loss 0.0497 (0.0665)
2022-11-02 23:46:12,378:INFO: Batch: 19/31	Total Loss 0.0701 (0.0667)
2022-11-02 23:46:12,637:INFO: Batch: 20/31	Total Loss 0.0819 (0.0674)
2022-11-02 23:46:12,896:INFO: Batch: 21/31	Total Loss 0.0680 (0.0674)
2022-11-02 23:46:13,155:INFO: Batch: 22/31	Total Loss 0.0984 (0.0686)
2022-11-02 23:46:13,414:INFO: Batch: 23/31	Total Loss 0.0632 (0.0684)
2022-11-02 23:46:13,676:INFO: Batch: 24/31	Total Loss 0.0654 (0.0683)
2022-11-02 23:46:13,936:INFO: Batch: 25/31	Total Loss 0.0653 (0.0681)
2022-11-02 23:46:14,197:INFO: Batch: 26/31	Total Loss 0.0638 (0.0680)
2022-11-02 23:46:14,457:INFO: Batch: 27/31	Total Loss 0.0616 (0.0677)
2022-11-02 23:46:14,719:INFO: Batch: 28/31	Total Loss 0.0656 (0.0677)
2022-11-02 23:46:14,979:INFO: Batch: 29/31	Total Loss 0.0576 (0.0673)
2022-11-02 23:46:15,098:INFO: Batch: 30/31	Total Loss 0.0233 (0.0669)
2022-11-02 23:46:15,249:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_214.pth.tar
2022-11-02 23:46:15,249:INFO: 
===> EPOCH: 215 (P2)
2022-11-02 23:46:15,249:INFO: - Computing loss (training)
2022-11-02 23:46:16,121:INFO: Batch:  0/31	Total Loss 0.0509 (0.0509)
2022-11-02 23:46:16,381:INFO: Batch:  1/31	Total Loss 0.0587 (0.0546)
2022-11-02 23:46:16,639:INFO: Batch:  2/31	Total Loss 0.0707 (0.0597)
2022-11-02 23:46:16,896:INFO: Batch:  3/31	Total Loss 0.0613 (0.0601)
2022-11-02 23:46:17,148:INFO: Batch:  4/31	Total Loss 0.0699 (0.0622)
2022-11-02 23:46:17,403:INFO: Batch:  5/31	Total Loss 0.0679 (0.0632)
2022-11-02 23:46:17,657:INFO: Batch:  6/31	Total Loss 0.0686 (0.0640)
2022-11-02 23:46:17,908:INFO: Batch:  7/31	Total Loss 0.0670 (0.0643)
2022-11-02 23:46:18,161:INFO: Batch:  8/31	Total Loss 0.0647 (0.0643)
2022-11-02 23:46:18,414:INFO: Batch:  9/31	Total Loss 0.0631 (0.0642)
2022-11-02 23:46:18,668:INFO: Batch: 10/31	Total Loss 0.0615 (0.0639)
2022-11-02 23:46:18,925:INFO: Batch: 11/31	Total Loss 0.0603 (0.0637)
2022-11-02 23:46:19,188:INFO: Batch: 12/31	Total Loss 0.0572 (0.0632)
2022-11-02 23:46:19,453:INFO: Batch: 13/31	Total Loss 0.0792 (0.0643)
2022-11-02 23:46:19,714:INFO: Batch: 14/31	Total Loss 0.0770 (0.0652)
2022-11-02 23:46:19,975:INFO: Batch: 15/31	Total Loss 0.0612 (0.0650)
2022-11-02 23:46:20,234:INFO: Batch: 16/31	Total Loss 0.0647 (0.0649)
2022-11-02 23:46:20,496:INFO: Batch: 17/31	Total Loss 0.0757 (0.0655)
2022-11-02 23:46:20,754:INFO: Batch: 18/31	Total Loss 0.0623 (0.0653)
2022-11-02 23:46:21,017:INFO: Batch: 19/31	Total Loss 0.0693 (0.0655)
2022-11-02 23:46:21,278:INFO: Batch: 20/31	Total Loss 0.0675 (0.0656)
2022-11-02 23:46:21,537:INFO: Batch: 21/31	Total Loss 0.0769 (0.0661)
2022-11-02 23:46:21,795:INFO: Batch: 22/31	Total Loss 0.0684 (0.0662)
2022-11-02 23:46:22,053:INFO: Batch: 23/31	Total Loss 0.0532 (0.0657)
2022-11-02 23:46:22,311:INFO: Batch: 24/31	Total Loss 0.0738 (0.0660)
2022-11-02 23:46:22,569:INFO: Batch: 25/31	Total Loss 0.1003 (0.0672)
2022-11-02 23:46:22,827:INFO: Batch: 26/31	Total Loss 0.0746 (0.0675)
2022-11-02 23:46:23,086:INFO: Batch: 27/31	Total Loss 0.0681 (0.0675)
2022-11-02 23:46:23,349:INFO: Batch: 28/31	Total Loss 0.0694 (0.0676)
2022-11-02 23:46:23,609:INFO: Batch: 29/31	Total Loss 0.0616 (0.0674)
2022-11-02 23:46:23,728:INFO: Batch: 30/31	Total Loss 0.0265 (0.0670)
2022-11-02 23:46:23,879:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_215.pth.tar
2022-11-02 23:46:23,879:INFO: 
===> EPOCH: 216 (P2)
2022-11-02 23:46:23,879:INFO: - Computing loss (training)
2022-11-02 23:46:24,764:INFO: Batch:  0/31	Total Loss 0.0641 (0.0641)
2022-11-02 23:46:25,019:INFO: Batch:  1/31	Total Loss 0.0710 (0.0676)
2022-11-02 23:46:25,280:INFO: Batch:  2/31	Total Loss 0.0663 (0.0672)
2022-11-02 23:46:25,534:INFO: Batch:  3/31	Total Loss 0.0615 (0.0658)
2022-11-02 23:46:25,792:INFO: Batch:  4/31	Total Loss 0.0725 (0.0672)
2022-11-02 23:46:26,048:INFO: Batch:  5/31	Total Loss 0.0687 (0.0674)
2022-11-02 23:46:26,303:INFO: Batch:  6/31	Total Loss 0.0642 (0.0669)
2022-11-02 23:46:26,556:INFO: Batch:  7/31	Total Loss 0.0534 (0.0652)
2022-11-02 23:46:26,811:INFO: Batch:  8/31	Total Loss 0.1083 (0.0698)
2022-11-02 23:46:27,064:INFO: Batch:  9/31	Total Loss 0.0587 (0.0687)
2022-11-02 23:46:27,322:INFO: Batch: 10/31	Total Loss 0.0627 (0.0681)
2022-11-02 23:46:27,580:INFO: Batch: 11/31	Total Loss 0.0647 (0.0678)
2022-11-02 23:46:27,842:INFO: Batch: 12/31	Total Loss 0.0647 (0.0676)
2022-11-02 23:46:28,102:INFO: Batch: 13/31	Total Loss 0.0602 (0.0670)
2022-11-02 23:46:28,363:INFO: Batch: 14/31	Total Loss 0.0649 (0.0669)
2022-11-02 23:46:28,621:INFO: Batch: 15/31	Total Loss 0.0571 (0.0663)
2022-11-02 23:46:28,883:INFO: Batch: 16/31	Total Loss 0.0478 (0.0652)
2022-11-02 23:46:29,146:INFO: Batch: 17/31	Total Loss 0.0525 (0.0645)
2022-11-02 23:46:29,407:INFO: Batch: 18/31	Total Loss 0.0617 (0.0643)
2022-11-02 23:46:29,670:INFO: Batch: 19/31	Total Loss 0.0990 (0.0659)
2022-11-02 23:46:29,931:INFO: Batch: 20/31	Total Loss 0.0691 (0.0660)
2022-11-02 23:46:30,190:INFO: Batch: 21/31	Total Loss 0.0647 (0.0659)
2022-11-02 23:46:30,449:INFO: Batch: 22/31	Total Loss 0.0571 (0.0656)
2022-11-02 23:46:30,707:INFO: Batch: 23/31	Total Loss 0.0647 (0.0655)
2022-11-02 23:46:30,969:INFO: Batch: 24/31	Total Loss 0.0665 (0.0656)
2022-11-02 23:46:31,228:INFO: Batch: 25/31	Total Loss 0.0711 (0.0658)
2022-11-02 23:46:31,487:INFO: Batch: 26/31	Total Loss 0.0628 (0.0656)
2022-11-02 23:46:31,745:INFO: Batch: 27/31	Total Loss 0.0604 (0.0655)
2022-11-02 23:46:32,002:INFO: Batch: 28/31	Total Loss 0.0576 (0.0652)
2022-11-02 23:46:32,262:INFO: Batch: 29/31	Total Loss 0.0606 (0.0650)
2022-11-02 23:46:32,380:INFO: Batch: 30/31	Total Loss 0.0250 (0.0647)
2022-11-02 23:46:32,542:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_216.pth.tar
2022-11-02 23:46:32,542:INFO: 
===> EPOCH: 217 (P2)
2022-11-02 23:46:32,542:INFO: - Computing loss (training)
2022-11-02 23:46:33,463:INFO: Batch:  0/31	Total Loss 0.0567 (0.0567)
2022-11-02 23:46:33,718:INFO: Batch:  1/31	Total Loss 0.0795 (0.0687)
2022-11-02 23:46:33,978:INFO: Batch:  2/31	Total Loss 0.0611 (0.0661)
2022-11-02 23:46:34,234:INFO: Batch:  3/31	Total Loss 0.0638 (0.0655)
2022-11-02 23:46:34,489:INFO: Batch:  4/31	Total Loss 0.0631 (0.0651)
2022-11-02 23:46:34,743:INFO: Batch:  5/31	Total Loss 0.0609 (0.0643)
2022-11-02 23:46:35,000:INFO: Batch:  6/31	Total Loss 0.0583 (0.0634)
2022-11-02 23:46:35,253:INFO: Batch:  7/31	Total Loss 0.0625 (0.0633)
2022-11-02 23:46:35,511:INFO: Batch:  8/31	Total Loss 0.0696 (0.0640)
2022-11-02 23:46:35,767:INFO: Batch:  9/31	Total Loss 0.0705 (0.0647)
2022-11-02 23:46:36,024:INFO: Batch: 10/31	Total Loss 0.0626 (0.0645)
2022-11-02 23:46:36,278:INFO: Batch: 11/31	Total Loss 0.0949 (0.0670)
2022-11-02 23:46:36,537:INFO: Batch: 12/31	Total Loss 0.0575 (0.0662)
2022-11-02 23:46:36,796:INFO: Batch: 13/31	Total Loss 0.0591 (0.0657)
2022-11-02 23:46:37,054:INFO: Batch: 14/31	Total Loss 0.0653 (0.0657)
2022-11-02 23:46:37,316:INFO: Batch: 15/31	Total Loss 0.0692 (0.0659)
2022-11-02 23:46:37,577:INFO: Batch: 16/31	Total Loss 0.0589 (0.0655)
2022-11-02 23:46:37,835:INFO: Batch: 17/31	Total Loss 0.0648 (0.0655)
2022-11-02 23:46:38,093:INFO: Batch: 18/31	Total Loss 0.0543 (0.0649)
2022-11-02 23:46:38,352:INFO: Batch: 19/31	Total Loss 0.0622 (0.0648)
2022-11-02 23:46:38,610:INFO: Batch: 20/31	Total Loss 0.0509 (0.0641)
2022-11-02 23:46:38,869:INFO: Batch: 21/31	Total Loss 0.0591 (0.0639)
2022-11-02 23:46:39,127:INFO: Batch: 22/31	Total Loss 0.0675 (0.0640)
2022-11-02 23:46:39,385:INFO: Batch: 23/31	Total Loss 0.0722 (0.0644)
2022-11-02 23:46:39,647:INFO: Batch: 24/31	Total Loss 0.0596 (0.0642)
2022-11-02 23:46:39,907:INFO: Batch: 25/31	Total Loss 0.0659 (0.0643)
2022-11-02 23:46:40,165:INFO: Batch: 26/31	Total Loss 0.0584 (0.0640)
2022-11-02 23:46:40,422:INFO: Batch: 27/31	Total Loss 0.0605 (0.0639)
2022-11-02 23:46:40,681:INFO: Batch: 28/31	Total Loss 0.0589 (0.0637)
2022-11-02 23:46:40,938:INFO: Batch: 29/31	Total Loss 0.0693 (0.0639)
2022-11-02 23:46:41,056:INFO: Batch: 30/31	Total Loss 0.0248 (0.0635)
2022-11-02 23:46:41,218:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_217.pth.tar
2022-11-02 23:46:41,218:INFO: 
===> EPOCH: 218 (P2)
2022-11-02 23:46:41,219:INFO: - Computing loss (training)
2022-11-02 23:46:42,079:INFO: Batch:  0/31	Total Loss 0.0518 (0.0518)
2022-11-02 23:46:42,336:INFO: Batch:  1/31	Total Loss 0.0650 (0.0580)
2022-11-02 23:46:42,596:INFO: Batch:  2/31	Total Loss 0.0642 (0.0603)
2022-11-02 23:46:42,850:INFO: Batch:  3/31	Total Loss 0.0537 (0.0588)
2022-11-02 23:46:43,102:INFO: Batch:  4/31	Total Loss 0.0588 (0.0588)
2022-11-02 23:46:43,360:INFO: Batch:  5/31	Total Loss 0.0543 (0.0580)
2022-11-02 23:46:43,614:INFO: Batch:  6/31	Total Loss 0.0669 (0.0593)
2022-11-02 23:46:43,868:INFO: Batch:  7/31	Total Loss 0.0649 (0.0600)
2022-11-02 23:46:44,122:INFO: Batch:  8/31	Total Loss 0.0562 (0.0596)
2022-11-02 23:46:44,374:INFO: Batch:  9/31	Total Loss 0.0644 (0.0600)
2022-11-02 23:46:44,630:INFO: Batch: 10/31	Total Loss 0.0652 (0.0605)
2022-11-02 23:46:44,883:INFO: Batch: 11/31	Total Loss 0.0842 (0.0623)
2022-11-02 23:46:45,141:INFO: Batch: 12/31	Total Loss 0.0546 (0.0617)
2022-11-02 23:46:45,398:INFO: Batch: 13/31	Total Loss 0.0561 (0.0613)
2022-11-02 23:46:45,656:INFO: Batch: 14/31	Total Loss 0.0627 (0.0614)
2022-11-02 23:46:45,914:INFO: Batch: 15/31	Total Loss 0.0624 (0.0615)
2022-11-02 23:46:46,173:INFO: Batch: 16/31	Total Loss 0.0587 (0.0613)
2022-11-02 23:46:46,430:INFO: Batch: 17/31	Total Loss 0.0790 (0.0623)
2022-11-02 23:46:46,688:INFO: Batch: 18/31	Total Loss 0.0614 (0.0622)
2022-11-02 23:46:46,946:INFO: Batch: 19/31	Total Loss 0.0590 (0.0621)
2022-11-02 23:46:47,205:INFO: Batch: 20/31	Total Loss 0.0548 (0.0617)
2022-11-02 23:46:47,463:INFO: Batch: 21/31	Total Loss 0.0569 (0.0615)
2022-11-02 23:46:47,720:INFO: Batch: 22/31	Total Loss 0.0961 (0.0628)
2022-11-02 23:46:47,977:INFO: Batch: 23/31	Total Loss 0.0637 (0.0629)
2022-11-02 23:46:48,234:INFO: Batch: 24/31	Total Loss 0.0582 (0.0627)
2022-11-02 23:46:48,491:INFO: Batch: 25/31	Total Loss 0.0627 (0.0627)
2022-11-02 23:46:48,748:INFO: Batch: 26/31	Total Loss 0.0653 (0.0628)
2022-11-02 23:46:49,005:INFO: Batch: 27/31	Total Loss 0.0643 (0.0628)
2022-11-02 23:46:49,263:INFO: Batch: 28/31	Total Loss 0.0673 (0.0630)
2022-11-02 23:46:49,521:INFO: Batch: 29/31	Total Loss 0.0435 (0.0623)
2022-11-02 23:46:49,640:INFO: Batch: 30/31	Total Loss 0.0282 (0.0620)
2022-11-02 23:46:49,799:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_218.pth.tar
2022-11-02 23:46:49,799:INFO: 
===> EPOCH: 219 (P2)
2022-11-02 23:46:49,799:INFO: - Computing loss (training)
2022-11-02 23:46:50,675:INFO: Batch:  0/31	Total Loss 0.0546 (0.0546)
2022-11-02 23:46:50,937:INFO: Batch:  1/31	Total Loss 0.0593 (0.0572)
2022-11-02 23:46:51,198:INFO: Batch:  2/31	Total Loss 0.0541 (0.0562)
2022-11-02 23:46:51,542:INFO: Batch:  3/31	Total Loss 0.0858 (0.0635)
2022-11-02 23:46:51,808:INFO: Batch:  4/31	Total Loss 0.0710 (0.0648)
2022-11-02 23:46:52,068:INFO: Batch:  5/31	Total Loss 0.0601 (0.0640)
2022-11-02 23:46:52,330:INFO: Batch:  6/31	Total Loss 0.0539 (0.0625)
2022-11-02 23:46:52,586:INFO: Batch:  7/31	Total Loss 0.0804 (0.0647)
2022-11-02 23:46:52,846:INFO: Batch:  8/31	Total Loss 0.0702 (0.0653)
2022-11-02 23:46:53,107:INFO: Batch:  9/31	Total Loss 0.0475 (0.0635)
2022-11-02 23:46:53,369:INFO: Batch: 10/31	Total Loss 0.0559 (0.0628)
2022-11-02 23:46:53,629:INFO: Batch: 11/31	Total Loss 0.0578 (0.0624)
2022-11-02 23:46:53,894:INFO: Batch: 12/31	Total Loss 0.0607 (0.0623)
2022-11-02 23:46:54,160:INFO: Batch: 13/31	Total Loss 0.0739 (0.0631)
2022-11-02 23:46:54,425:INFO: Batch: 14/31	Total Loss 0.0510 (0.0623)
2022-11-02 23:46:54,690:INFO: Batch: 15/31	Total Loss 0.0573 (0.0620)
2022-11-02 23:46:54,955:INFO: Batch: 16/31	Total Loss 0.0617 (0.0620)
2022-11-02 23:46:55,219:INFO: Batch: 17/31	Total Loss 0.0562 (0.0617)
2022-11-02 23:46:55,485:INFO: Batch: 18/31	Total Loss 0.0741 (0.0623)
2022-11-02 23:46:55,752:INFO: Batch: 19/31	Total Loss 0.0757 (0.0629)
2022-11-02 23:46:56,016:INFO: Batch: 20/31	Total Loss 0.0612 (0.0628)
2022-11-02 23:46:56,282:INFO: Batch: 21/31	Total Loss 0.0933 (0.0642)
2022-11-02 23:46:56,544:INFO: Batch: 22/31	Total Loss 0.0685 (0.0643)
2022-11-02 23:46:56,806:INFO: Batch: 23/31	Total Loss 0.0679 (0.0645)
2022-11-02 23:46:57,068:INFO: Batch: 24/31	Total Loss 0.0510 (0.0640)
2022-11-02 23:46:57,330:INFO: Batch: 25/31	Total Loss 0.1030 (0.0653)
2022-11-02 23:46:57,591:INFO: Batch: 26/31	Total Loss 0.0582 (0.0651)
2022-11-02 23:46:57,853:INFO: Batch: 27/31	Total Loss 0.0670 (0.0651)
2022-11-02 23:46:58,114:INFO: Batch: 28/31	Total Loss 0.0490 (0.0646)
2022-11-02 23:46:58,375:INFO: Batch: 29/31	Total Loss 0.0672 (0.0647)
2022-11-02 23:46:58,494:INFO: Batch: 30/31	Total Loss 0.0205 (0.0643)
2022-11-02 23:46:58,650:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_219.pth.tar
2022-11-02 23:46:58,650:INFO: 
===> EPOCH: 220 (P2)
2022-11-02 23:46:58,650:INFO: - Computing loss (training)
2022-11-02 23:46:59,526:INFO: Batch:  0/31	Total Loss 0.0602 (0.0602)
2022-11-02 23:46:59,784:INFO: Batch:  1/31	Total Loss 0.0423 (0.0512)
2022-11-02 23:47:00,041:INFO: Batch:  2/31	Total Loss 0.0684 (0.0568)
2022-11-02 23:47:00,299:INFO: Batch:  3/31	Total Loss 0.0575 (0.0570)
2022-11-02 23:47:00,557:INFO: Batch:  4/31	Total Loss 0.0587 (0.0574)
2022-11-02 23:47:00,812:INFO: Batch:  5/31	Total Loss 0.0563 (0.0572)
2022-11-02 23:47:01,066:INFO: Batch:  6/31	Total Loss 0.0603 (0.0577)
2022-11-02 23:47:01,321:INFO: Batch:  7/31	Total Loss 0.0612 (0.0581)
2022-11-02 23:47:01,575:INFO: Batch:  8/31	Total Loss 0.0670 (0.0591)
2022-11-02 23:47:01,829:INFO: Batch:  9/31	Total Loss 0.0554 (0.0587)
2022-11-02 23:47:02,086:INFO: Batch: 10/31	Total Loss 0.0555 (0.0584)
2022-11-02 23:47:02,339:INFO: Batch: 11/31	Total Loss 0.0518 (0.0579)
2022-11-02 23:47:02,597:INFO: Batch: 12/31	Total Loss 0.0547 (0.0576)
2022-11-02 23:47:02,855:INFO: Batch: 13/31	Total Loss 0.0566 (0.0575)
2022-11-02 23:47:03,113:INFO: Batch: 14/31	Total Loss 0.0534 (0.0572)
2022-11-02 23:47:03,372:INFO: Batch: 15/31	Total Loss 0.0607 (0.0574)
2022-11-02 23:47:03,630:INFO: Batch: 16/31	Total Loss 0.0582 (0.0575)
2022-11-02 23:47:03,888:INFO: Batch: 17/31	Total Loss 0.0631 (0.0578)
2022-11-02 23:47:04,146:INFO: Batch: 18/31	Total Loss 0.0560 (0.0577)
2022-11-02 23:47:04,402:INFO: Batch: 19/31	Total Loss 0.0681 (0.0582)
2022-11-02 23:47:04,658:INFO: Batch: 20/31	Total Loss 0.0589 (0.0583)
2022-11-02 23:47:04,917:INFO: Batch: 21/31	Total Loss 0.0550 (0.0581)
2022-11-02 23:47:05,173:INFO: Batch: 22/31	Total Loss 0.0596 (0.0582)
2022-11-02 23:47:05,433:INFO: Batch: 23/31	Total Loss 0.0631 (0.0584)
2022-11-02 23:47:05,691:INFO: Batch: 24/31	Total Loss 0.0582 (0.0584)
2022-11-02 23:47:05,947:INFO: Batch: 25/31	Total Loss 0.0638 (0.0586)
2022-11-02 23:47:06,203:INFO: Batch: 26/31	Total Loss 0.0564 (0.0585)
2022-11-02 23:47:06,458:INFO: Batch: 27/31	Total Loss 0.0551 (0.0584)
2022-11-02 23:47:06,715:INFO: Batch: 28/31	Total Loss 0.0538 (0.0583)
2022-11-02 23:47:06,971:INFO: Batch: 29/31	Total Loss 0.0631 (0.0584)
2022-11-02 23:47:07,088:INFO: Batch: 30/31	Total Loss 0.0255 (0.0581)
2022-11-02 23:47:07,241:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_220.pth.tar
2022-11-02 23:47:07,241:INFO: 
===> EPOCH: 221 (P2)
2022-11-02 23:47:07,242:INFO: - Computing loss (training)
2022-11-02 23:47:08,105:INFO: Batch:  0/31	Total Loss 0.0636 (0.0636)
2022-11-02 23:47:08,364:INFO: Batch:  1/31	Total Loss 0.0655 (0.0645)
2022-11-02 23:47:08,618:INFO: Batch:  2/31	Total Loss 0.0600 (0.0631)
2022-11-02 23:47:08,877:INFO: Batch:  3/31	Total Loss 0.0545 (0.0610)
2022-11-02 23:47:09,133:INFO: Batch:  4/31	Total Loss 0.0824 (0.0656)
2022-11-02 23:47:09,394:INFO: Batch:  5/31	Total Loss 0.0599 (0.0647)
2022-11-02 23:47:09,651:INFO: Batch:  6/31	Total Loss 0.0470 (0.0622)
2022-11-02 23:47:09,910:INFO: Batch:  7/31	Total Loss 0.0447 (0.0601)
2022-11-02 23:47:10,167:INFO: Batch:  8/31	Total Loss 0.0551 (0.0595)
2022-11-02 23:47:10,423:INFO: Batch:  9/31	Total Loss 0.0880 (0.0618)
2022-11-02 23:47:10,681:INFO: Batch: 10/31	Total Loss 0.0553 (0.0612)
2022-11-02 23:47:10,947:INFO: Batch: 11/31	Total Loss 0.0551 (0.0607)
2022-11-02 23:47:11,209:INFO: Batch: 12/31	Total Loss 0.0631 (0.0608)
2022-11-02 23:47:11,470:INFO: Batch: 13/31	Total Loss 0.0568 (0.0606)
2022-11-02 23:47:11,731:INFO: Batch: 14/31	Total Loss 0.0592 (0.0605)
2022-11-02 23:47:11,990:INFO: Batch: 15/31	Total Loss 0.0687 (0.0610)
2022-11-02 23:47:12,250:INFO: Batch: 16/31	Total Loss 0.0537 (0.0606)
2022-11-02 23:47:12,511:INFO: Batch: 17/31	Total Loss 0.0556 (0.0603)
2022-11-02 23:47:12,771:INFO: Batch: 18/31	Total Loss 0.0626 (0.0604)
2022-11-02 23:47:13,030:INFO: Batch: 19/31	Total Loss 0.0628 (0.0606)
2022-11-02 23:47:13,289:INFO: Batch: 20/31	Total Loss 0.0482 (0.0599)
2022-11-02 23:47:13,548:INFO: Batch: 21/31	Total Loss 0.0547 (0.0597)
2022-11-02 23:47:13,809:INFO: Batch: 22/31	Total Loss 0.0517 (0.0593)
2022-11-02 23:47:14,071:INFO: Batch: 23/31	Total Loss 0.0654 (0.0595)
2022-11-02 23:47:14,329:INFO: Batch: 24/31	Total Loss 0.0520 (0.0592)
2022-11-02 23:47:14,587:INFO: Batch: 25/31	Total Loss 0.0573 (0.0592)
2022-11-02 23:47:14,846:INFO: Batch: 26/31	Total Loss 0.0660 (0.0594)
2022-11-02 23:47:15,107:INFO: Batch: 27/31	Total Loss 0.0716 (0.0598)
2022-11-02 23:47:15,367:INFO: Batch: 28/31	Total Loss 0.0426 (0.0593)
2022-11-02 23:47:15,626:INFO: Batch: 29/31	Total Loss 0.0533 (0.0591)
2022-11-02 23:47:15,744:INFO: Batch: 30/31	Total Loss 0.0199 (0.0588)
2022-11-02 23:47:15,907:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_221.pth.tar
2022-11-02 23:47:15,907:INFO: 
===> EPOCH: 222 (P2)
2022-11-02 23:47:15,907:INFO: - Computing loss (training)
2022-11-02 23:47:16,762:INFO: Batch:  0/31	Total Loss 0.0485 (0.0485)
2022-11-02 23:47:17,030:INFO: Batch:  1/31	Total Loss 0.0541 (0.0513)
2022-11-02 23:47:17,292:INFO: Batch:  2/31	Total Loss 0.0602 (0.0543)
2022-11-02 23:47:17,550:INFO: Batch:  3/31	Total Loss 0.0675 (0.0577)
2022-11-02 23:47:17,810:INFO: Batch:  4/31	Total Loss 0.0523 (0.0566)
2022-11-02 23:47:18,071:INFO: Batch:  5/31	Total Loss 0.0605 (0.0573)
2022-11-02 23:47:18,333:INFO: Batch:  6/31	Total Loss 0.0643 (0.0583)
2022-11-02 23:47:18,591:INFO: Batch:  7/31	Total Loss 0.0509 (0.0575)
2022-11-02 23:47:18,850:INFO: Batch:  8/31	Total Loss 0.0560 (0.0573)
2022-11-02 23:47:19,108:INFO: Batch:  9/31	Total Loss 0.0589 (0.0575)
2022-11-02 23:47:19,367:INFO: Batch: 10/31	Total Loss 0.0532 (0.0571)
2022-11-02 23:47:19,632:INFO: Batch: 11/31	Total Loss 0.0592 (0.0573)
2022-11-02 23:47:19,893:INFO: Batch: 12/31	Total Loss 0.0506 (0.0568)
2022-11-02 23:47:20,154:INFO: Batch: 13/31	Total Loss 0.0581 (0.0569)
2022-11-02 23:47:20,417:INFO: Batch: 14/31	Total Loss 0.0543 (0.0567)
2022-11-02 23:47:20,678:INFO: Batch: 15/31	Total Loss 0.0650 (0.0572)
2022-11-02 23:47:20,938:INFO: Batch: 16/31	Total Loss 0.0526 (0.0570)
2022-11-02 23:47:21,197:INFO: Batch: 17/31	Total Loss 0.0570 (0.0570)
2022-11-02 23:47:21,457:INFO: Batch: 18/31	Total Loss 0.0660 (0.0575)
2022-11-02 23:47:21,719:INFO: Batch: 19/31	Total Loss 0.0864 (0.0588)
2022-11-02 23:47:21,978:INFO: Batch: 20/31	Total Loss 0.0459 (0.0582)
2022-11-02 23:47:22,237:INFO: Batch: 21/31	Total Loss 0.0697 (0.0587)
2022-11-02 23:47:22,498:INFO: Batch: 22/31	Total Loss 0.0574 (0.0586)
2022-11-02 23:47:22,757:INFO: Batch: 23/31	Total Loss 0.0682 (0.0590)
2022-11-02 23:47:23,014:INFO: Batch: 24/31	Total Loss 0.0574 (0.0590)
2022-11-02 23:47:23,274:INFO: Batch: 25/31	Total Loss 0.0575 (0.0589)
2022-11-02 23:47:23,533:INFO: Batch: 26/31	Total Loss 0.0647 (0.0591)
2022-11-02 23:47:23,792:INFO: Batch: 27/31	Total Loss 0.0525 (0.0589)
2022-11-02 23:47:24,050:INFO: Batch: 28/31	Total Loss 0.0532 (0.0587)
2022-11-02 23:47:24,309:INFO: Batch: 29/31	Total Loss 0.0638 (0.0589)
2022-11-02 23:47:24,427:INFO: Batch: 30/31	Total Loss 0.0175 (0.0585)
2022-11-02 23:47:24,590:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_222.pth.tar
2022-11-02 23:47:24,590:INFO: 
===> EPOCH: 223 (P2)
2022-11-02 23:47:24,590:INFO: - Computing loss (training)
2022-11-02 23:47:25,466:INFO: Batch:  0/31	Total Loss 0.0692 (0.0692)
2022-11-02 23:47:25,730:INFO: Batch:  1/31	Total Loss 0.0435 (0.0559)
2022-11-02 23:47:25,986:INFO: Batch:  2/31	Total Loss 0.0566 (0.0561)
2022-11-02 23:47:26,244:INFO: Batch:  3/31	Total Loss 0.0506 (0.0547)
2022-11-02 23:47:26,500:INFO: Batch:  4/31	Total Loss 0.0576 (0.0553)
2022-11-02 23:47:26,756:INFO: Batch:  5/31	Total Loss 0.0697 (0.0577)
2022-11-02 23:47:27,009:INFO: Batch:  6/31	Total Loss 0.0574 (0.0577)
2022-11-02 23:47:27,262:INFO: Batch:  7/31	Total Loss 0.0596 (0.0580)
2022-11-02 23:47:27,515:INFO: Batch:  8/31	Total Loss 0.0385 (0.0557)
2022-11-02 23:47:27,770:INFO: Batch:  9/31	Total Loss 0.0556 (0.0557)
2022-11-02 23:47:28,026:INFO: Batch: 10/31	Total Loss 0.0416 (0.0544)
2022-11-02 23:47:28,280:INFO: Batch: 11/31	Total Loss 0.0541 (0.0544)
2022-11-02 23:47:28,539:INFO: Batch: 12/31	Total Loss 0.0521 (0.0542)
2022-11-02 23:47:28,796:INFO: Batch: 13/31	Total Loss 0.0553 (0.0543)
2022-11-02 23:47:29,053:INFO: Batch: 14/31	Total Loss 0.0519 (0.0541)
2022-11-02 23:47:29,311:INFO: Batch: 15/31	Total Loss 0.0663 (0.0549)
2022-11-02 23:47:29,573:INFO: Batch: 16/31	Total Loss 0.0623 (0.0553)
2022-11-02 23:47:29,833:INFO: Batch: 17/31	Total Loss 0.0685 (0.0561)
2022-11-02 23:47:30,092:INFO: Batch: 18/31	Total Loss 0.0468 (0.0557)
2022-11-02 23:47:30,351:INFO: Batch: 19/31	Total Loss 0.0508 (0.0555)
2022-11-02 23:47:30,608:INFO: Batch: 20/31	Total Loss 0.0590 (0.0556)
2022-11-02 23:47:30,867:INFO: Batch: 21/31	Total Loss 0.0548 (0.0556)
2022-11-02 23:47:31,124:INFO: Batch: 22/31	Total Loss 0.0549 (0.0556)
2022-11-02 23:47:31,381:INFO: Batch: 23/31	Total Loss 0.0596 (0.0557)
2022-11-02 23:47:31,637:INFO: Batch: 24/31	Total Loss 0.0431 (0.0552)
2022-11-02 23:47:31,894:INFO: Batch: 25/31	Total Loss 0.0667 (0.0557)
2022-11-02 23:47:32,151:INFO: Batch: 26/31	Total Loss 0.0487 (0.0555)
2022-11-02 23:47:32,407:INFO: Batch: 27/31	Total Loss 0.0476 (0.0552)
2022-11-02 23:47:32,666:INFO: Batch: 28/31	Total Loss 0.0398 (0.0547)
2022-11-02 23:47:32,922:INFO: Batch: 29/31	Total Loss 0.0545 (0.0547)
2022-11-02 23:47:33,039:INFO: Batch: 30/31	Total Loss 0.0198 (0.0544)
2022-11-02 23:47:33,191:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_223.pth.tar
2022-11-02 23:47:33,191:INFO: 
===> EPOCH: 224 (P2)
2022-11-02 23:47:33,191:INFO: - Computing loss (training)
2022-11-02 23:47:34,071:INFO: Batch:  0/31	Total Loss 0.0558 (0.0558)
2022-11-02 23:47:34,332:INFO: Batch:  1/31	Total Loss 0.0593 (0.0575)
2022-11-02 23:47:34,597:INFO: Batch:  2/31	Total Loss 0.0529 (0.0559)
2022-11-02 23:47:34,856:INFO: Batch:  3/31	Total Loss 0.0528 (0.0551)
2022-11-02 23:47:35,113:INFO: Batch:  4/31	Total Loss 0.0614 (0.0564)
2022-11-02 23:47:35,378:INFO: Batch:  5/31	Total Loss 0.0579 (0.0567)
2022-11-02 23:47:35,636:INFO: Batch:  6/31	Total Loss 0.0583 (0.0569)
2022-11-02 23:47:35,892:INFO: Batch:  7/31	Total Loss 0.0483 (0.0559)
2022-11-02 23:47:36,150:INFO: Batch:  8/31	Total Loss 0.0564 (0.0560)
2022-11-02 23:47:36,406:INFO: Batch:  9/31	Total Loss 0.0465 (0.0551)
2022-11-02 23:47:36,663:INFO: Batch: 10/31	Total Loss 0.0743 (0.0567)
2022-11-02 23:47:36,922:INFO: Batch: 11/31	Total Loss 0.0506 (0.0562)
2022-11-02 23:47:37,179:INFO: Batch: 12/31	Total Loss 0.0523 (0.0559)
2022-11-02 23:47:37,442:INFO: Batch: 13/31	Total Loss 0.0486 (0.0553)
2022-11-02 23:47:37,701:INFO: Batch: 14/31	Total Loss 0.0478 (0.0548)
2022-11-02 23:47:37,959:INFO: Batch: 15/31	Total Loss 0.0511 (0.0545)
2022-11-02 23:47:38,218:INFO: Batch: 16/31	Total Loss 0.0645 (0.0551)
2022-11-02 23:47:38,476:INFO: Batch: 17/31	Total Loss 0.0603 (0.0554)
2022-11-02 23:47:38,736:INFO: Batch: 18/31	Total Loss 0.0505 (0.0552)
2022-11-02 23:47:38,993:INFO: Batch: 19/31	Total Loss 0.0615 (0.0555)
2022-11-02 23:47:39,250:INFO: Batch: 20/31	Total Loss 0.0466 (0.0550)
2022-11-02 23:47:39,507:INFO: Batch: 21/31	Total Loss 0.0495 (0.0548)
2022-11-02 23:47:39,763:INFO: Batch: 22/31	Total Loss 0.0652 (0.0552)
2022-11-02 23:47:40,020:INFO: Batch: 23/31	Total Loss 0.0603 (0.0554)
2022-11-02 23:47:40,278:INFO: Batch: 24/31	Total Loss 0.0473 (0.0551)
2022-11-02 23:47:40,535:INFO: Batch: 25/31	Total Loss 0.0645 (0.0555)
2022-11-02 23:47:40,792:INFO: Batch: 26/31	Total Loss 0.0597 (0.0556)
2022-11-02 23:47:41,048:INFO: Batch: 27/31	Total Loss 0.0528 (0.0555)
2022-11-02 23:47:41,306:INFO: Batch: 28/31	Total Loss 0.0502 (0.0553)
2022-11-02 23:47:41,564:INFO: Batch: 29/31	Total Loss 0.0717 (0.0559)
2022-11-02 23:47:41,682:INFO: Batch: 30/31	Total Loss 0.0239 (0.0556)
2022-11-02 23:47:41,835:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_224.pth.tar
2022-11-02 23:47:41,836:INFO: 
===> EPOCH: 225 (P2)
2022-11-02 23:47:41,836:INFO: - Computing loss (training)
2022-11-02 23:47:42,711:INFO: Batch:  0/31	Total Loss 0.0550 (0.0550)
2022-11-02 23:47:43,057:INFO: Batch:  1/31	Total Loss 0.0420 (0.0485)
2022-11-02 23:47:43,324:INFO: Batch:  2/31	Total Loss 0.0822 (0.0588)
2022-11-02 23:47:43,587:INFO: Batch:  3/31	Total Loss 0.0514 (0.0570)
2022-11-02 23:47:43,858:INFO: Batch:  4/31	Total Loss 0.0539 (0.0564)
2022-11-02 23:47:44,119:INFO: Batch:  5/31	Total Loss 0.0624 (0.0574)
2022-11-02 23:47:44,374:INFO: Batch:  6/31	Total Loss 0.0657 (0.0587)
2022-11-02 23:47:44,629:INFO: Batch:  7/31	Total Loss 0.0638 (0.0594)
2022-11-02 23:47:44,886:INFO: Batch:  8/31	Total Loss 0.0531 (0.0588)
2022-11-02 23:47:45,141:INFO: Batch:  9/31	Total Loss 0.0620 (0.0591)
2022-11-02 23:47:45,396:INFO: Batch: 10/31	Total Loss 0.0550 (0.0587)
2022-11-02 23:47:45,653:INFO: Batch: 11/31	Total Loss 0.0626 (0.0590)
2022-11-02 23:47:45,913:INFO: Batch: 12/31	Total Loss 0.0790 (0.0607)
2022-11-02 23:47:46,173:INFO: Batch: 13/31	Total Loss 0.0643 (0.0610)
2022-11-02 23:47:46,436:INFO: Batch: 14/31	Total Loss 0.0638 (0.0612)
2022-11-02 23:47:46,698:INFO: Batch: 15/31	Total Loss 0.0560 (0.0609)
2022-11-02 23:47:46,957:INFO: Batch: 16/31	Total Loss 0.0525 (0.0604)
2022-11-02 23:47:47,221:INFO: Batch: 17/31	Total Loss 0.0558 (0.0602)
2022-11-02 23:47:47,481:INFO: Batch: 18/31	Total Loss 0.0560 (0.0599)
2022-11-02 23:47:47,742:INFO: Batch: 19/31	Total Loss 0.0490 (0.0594)
2022-11-02 23:47:48,000:INFO: Batch: 20/31	Total Loss 0.0524 (0.0590)
2022-11-02 23:47:48,259:INFO: Batch: 21/31	Total Loss 0.0554 (0.0589)
2022-11-02 23:47:48,518:INFO: Batch: 22/31	Total Loss 0.0589 (0.0589)
2022-11-02 23:47:48,777:INFO: Batch: 23/31	Total Loss 0.0528 (0.0586)
2022-11-02 23:47:49,037:INFO: Batch: 24/31	Total Loss 0.0572 (0.0585)
2022-11-02 23:47:49,295:INFO: Batch: 25/31	Total Loss 0.0491 (0.0581)
2022-11-02 23:47:49,558:INFO: Batch: 26/31	Total Loss 0.0516 (0.0579)
2022-11-02 23:47:49,819:INFO: Batch: 27/31	Total Loss 0.0610 (0.0580)
2022-11-02 23:47:50,078:INFO: Batch: 28/31	Total Loss 0.0445 (0.0576)
2022-11-02 23:47:50,338:INFO: Batch: 29/31	Total Loss 0.0551 (0.0575)
2022-11-02 23:47:50,456:INFO: Batch: 30/31	Total Loss 0.0202 (0.0572)
2022-11-02 23:47:50,612:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_225.pth.tar
2022-11-02 23:47:50,612:INFO: 
===> EPOCH: 226 (P2)
2022-11-02 23:47:50,612:INFO: - Computing loss (training)
2022-11-02 23:47:51,481:INFO: Batch:  0/31	Total Loss 0.0544 (0.0544)
2022-11-02 23:47:51,739:INFO: Batch:  1/31	Total Loss 0.0583 (0.0565)
2022-11-02 23:47:52,001:INFO: Batch:  2/31	Total Loss 0.0558 (0.0562)
2022-11-02 23:47:52,257:INFO: Batch:  3/31	Total Loss 0.0577 (0.0566)
2022-11-02 23:47:52,514:INFO: Batch:  4/31	Total Loss 0.0548 (0.0562)
2022-11-02 23:47:52,772:INFO: Batch:  5/31	Total Loss 0.0504 (0.0553)
2022-11-02 23:47:53,029:INFO: Batch:  6/31	Total Loss 0.0530 (0.0550)
2022-11-02 23:47:53,284:INFO: Batch:  7/31	Total Loss 0.0514 (0.0545)
2022-11-02 23:47:53,537:INFO: Batch:  8/31	Total Loss 0.0490 (0.0539)
2022-11-02 23:47:53,792:INFO: Batch:  9/31	Total Loss 0.0583 (0.0544)
2022-11-02 23:47:54,048:INFO: Batch: 10/31	Total Loss 0.0539 (0.0543)
2022-11-02 23:47:54,304:INFO: Batch: 11/31	Total Loss 0.0523 (0.0541)
2022-11-02 23:47:54,562:INFO: Batch: 12/31	Total Loss 0.0639 (0.0549)
2022-11-02 23:47:54,818:INFO: Batch: 13/31	Total Loss 0.0487 (0.0545)
2022-11-02 23:47:55,075:INFO: Batch: 14/31	Total Loss 0.0689 (0.0555)
2022-11-02 23:47:55,334:INFO: Batch: 15/31	Total Loss 0.0505 (0.0552)
2022-11-02 23:47:55,593:INFO: Batch: 16/31	Total Loss 0.0533 (0.0551)
2022-11-02 23:47:55,855:INFO: Batch: 17/31	Total Loss 0.0630 (0.0556)
2022-11-02 23:47:56,118:INFO: Batch: 18/31	Total Loss 0.0578 (0.0557)
2022-11-02 23:47:56,378:INFO: Batch: 19/31	Total Loss 0.0502 (0.0554)
2022-11-02 23:47:56,636:INFO: Batch: 20/31	Total Loss 0.0479 (0.0550)
2022-11-02 23:47:56,895:INFO: Batch: 21/31	Total Loss 0.0474 (0.0547)
2022-11-02 23:47:57,184:INFO: Batch: 22/31	Total Loss 0.0556 (0.0547)
2022-11-02 23:47:57,512:INFO: Batch: 23/31	Total Loss 0.0393 (0.0540)
2022-11-02 23:47:57,840:INFO: Batch: 24/31	Total Loss 0.0530 (0.0540)
2022-11-02 23:47:58,136:INFO: Batch: 25/31	Total Loss 0.0527 (0.0539)
2022-11-02 23:47:58,396:INFO: Batch: 26/31	Total Loss 0.0408 (0.0535)
2022-11-02 23:47:58,655:INFO: Batch: 27/31	Total Loss 0.0490 (0.0533)
2022-11-02 23:47:58,913:INFO: Batch: 28/31	Total Loss 0.0519 (0.0533)
2022-11-02 23:47:59,173:INFO: Batch: 29/31	Total Loss 0.0653 (0.0537)
2022-11-02 23:47:59,291:INFO: Batch: 30/31	Total Loss 0.0238 (0.0534)
2022-11-02 23:47:59,452:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_226.pth.tar
2022-11-02 23:47:59,452:INFO: 
===> EPOCH: 227 (P2)
2022-11-02 23:47:59,453:INFO: - Computing loss (training)
2022-11-02 23:48:00,351:INFO: Batch:  0/31	Total Loss 0.0597 (0.0597)
2022-11-02 23:48:00,613:INFO: Batch:  1/31	Total Loss 0.0498 (0.0545)
2022-11-02 23:48:00,876:INFO: Batch:  2/31	Total Loss 0.0444 (0.0519)
2022-11-02 23:48:01,138:INFO: Batch:  3/31	Total Loss 0.0546 (0.0526)
2022-11-02 23:48:01,399:INFO: Batch:  4/31	Total Loss 0.0516 (0.0524)
2022-11-02 23:48:01,666:INFO: Batch:  5/31	Total Loss 0.0584 (0.0533)
2022-11-02 23:48:01,927:INFO: Batch:  6/31	Total Loss 0.0506 (0.0529)
2022-11-02 23:48:02,187:INFO: Batch:  7/31	Total Loss 0.0785 (0.0557)
2022-11-02 23:48:02,447:INFO: Batch:  8/31	Total Loss 0.0462 (0.0545)
2022-11-02 23:48:02,709:INFO: Batch:  9/31	Total Loss 0.0604 (0.0552)
2022-11-02 23:48:02,967:INFO: Batch: 10/31	Total Loss 0.0567 (0.0553)
2022-11-02 23:48:03,227:INFO: Batch: 11/31	Total Loss 0.0549 (0.0553)
2022-11-02 23:48:03,490:INFO: Batch: 12/31	Total Loss 0.0576 (0.0555)
2022-11-02 23:48:03,753:INFO: Batch: 13/31	Total Loss 0.0504 (0.0551)
2022-11-02 23:48:04,015:INFO: Batch: 14/31	Total Loss 0.0477 (0.0546)
2022-11-02 23:48:04,278:INFO: Batch: 15/31	Total Loss 0.0528 (0.0545)
2022-11-02 23:48:04,540:INFO: Batch: 16/31	Total Loss 0.0509 (0.0543)
2022-11-02 23:48:04,809:INFO: Batch: 17/31	Total Loss 0.0603 (0.0546)
2022-11-02 23:48:05,068:INFO: Batch: 18/31	Total Loss 0.0526 (0.0545)
2022-11-02 23:48:05,329:INFO: Batch: 19/31	Total Loss 0.0519 (0.0544)
2022-11-02 23:48:05,588:INFO: Batch: 20/31	Total Loss 0.0417 (0.0538)
2022-11-02 23:48:05,849:INFO: Batch: 21/31	Total Loss 0.0460 (0.0534)
2022-11-02 23:48:06,107:INFO: Batch: 22/31	Total Loss 0.0642 (0.0539)
2022-11-02 23:48:06,366:INFO: Batch: 23/31	Total Loss 0.0578 (0.0540)
2022-11-02 23:48:06,625:INFO: Batch: 24/31	Total Loss 0.0387 (0.0534)
2022-11-02 23:48:06,884:INFO: Batch: 25/31	Total Loss 0.0479 (0.0532)
2022-11-02 23:48:07,143:INFO: Batch: 26/31	Total Loss 0.0545 (0.0532)
2022-11-02 23:48:07,402:INFO: Batch: 27/31	Total Loss 0.0514 (0.0532)
2022-11-02 23:48:07,661:INFO: Batch: 28/31	Total Loss 0.0614 (0.0535)
2022-11-02 23:48:07,920:INFO: Batch: 29/31	Total Loss 0.0529 (0.0535)
2022-11-02 23:48:08,038:INFO: Batch: 30/31	Total Loss 0.0161 (0.0531)
2022-11-02 23:48:08,191:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_227.pth.tar
2022-11-02 23:48:08,192:INFO: 
===> EPOCH: 228 (P2)
2022-11-02 23:48:08,192:INFO: - Computing loss (training)
2022-11-02 23:48:09,082:INFO: Batch:  0/31	Total Loss 0.0501 (0.0501)
2022-11-02 23:48:09,344:INFO: Batch:  1/31	Total Loss 0.0514 (0.0507)
2022-11-02 23:48:09,606:INFO: Batch:  2/31	Total Loss 0.0580 (0.0532)
2022-11-02 23:48:09,864:INFO: Batch:  3/31	Total Loss 0.0483 (0.0520)
2022-11-02 23:48:10,118:INFO: Batch:  4/31	Total Loss 0.0551 (0.0526)
2022-11-02 23:48:10,376:INFO: Batch:  5/31	Total Loss 0.0427 (0.0509)
2022-11-02 23:48:10,633:INFO: Batch:  6/31	Total Loss 0.0395 (0.0493)
2022-11-02 23:48:10,888:INFO: Batch:  7/31	Total Loss 0.0590 (0.0505)
2022-11-02 23:48:11,143:INFO: Batch:  8/31	Total Loss 0.0525 (0.0507)
2022-11-02 23:48:11,398:INFO: Batch:  9/31	Total Loss 0.0552 (0.0512)
2022-11-02 23:48:11,652:INFO: Batch: 10/31	Total Loss 0.0408 (0.0503)
2022-11-02 23:48:11,910:INFO: Batch: 11/31	Total Loss 0.0504 (0.0503)
2022-11-02 23:48:12,168:INFO: Batch: 12/31	Total Loss 0.0534 (0.0505)
2022-11-02 23:48:12,428:INFO: Batch: 13/31	Total Loss 0.0445 (0.0501)
2022-11-02 23:48:12,690:INFO: Batch: 14/31	Total Loss 0.0671 (0.0512)
2022-11-02 23:48:12,950:INFO: Batch: 15/31	Total Loss 0.0538 (0.0513)
2022-11-02 23:48:13,210:INFO: Batch: 16/31	Total Loss 0.0461 (0.0510)
2022-11-02 23:48:13,468:INFO: Batch: 17/31	Total Loss 0.0503 (0.0509)
2022-11-02 23:48:13,730:INFO: Batch: 18/31	Total Loss 0.0470 (0.0507)
2022-11-02 23:48:13,989:INFO: Batch: 19/31	Total Loss 0.0585 (0.0511)
2022-11-02 23:48:14,249:INFO: Batch: 20/31	Total Loss 0.0518 (0.0512)
2022-11-02 23:48:14,506:INFO: Batch: 21/31	Total Loss 0.0558 (0.0514)
2022-11-02 23:48:14,765:INFO: Batch: 22/31	Total Loss 0.0522 (0.0514)
2022-11-02 23:48:15,025:INFO: Batch: 23/31	Total Loss 0.0469 (0.0512)
2022-11-02 23:48:15,283:INFO: Batch: 24/31	Total Loss 0.0725 (0.0521)
2022-11-02 23:48:15,541:INFO: Batch: 25/31	Total Loss 0.0564 (0.0523)
2022-11-02 23:48:15,801:INFO: Batch: 26/31	Total Loss 0.0593 (0.0526)
2022-11-02 23:48:16,060:INFO: Batch: 27/31	Total Loss 0.0500 (0.0525)
2022-11-02 23:48:16,318:INFO: Batch: 28/31	Total Loss 0.0655 (0.0528)
2022-11-02 23:48:16,577:INFO: Batch: 29/31	Total Loss 0.0525 (0.0528)
2022-11-02 23:48:16,695:INFO: Batch: 30/31	Total Loss 0.0193 (0.0525)
2022-11-02 23:48:16,854:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_228.pth.tar
2022-11-02 23:48:16,855:INFO: 
===> EPOCH: 229 (P2)
2022-11-02 23:48:16,855:INFO: - Computing loss (training)
2022-11-02 23:48:17,724:INFO: Batch:  0/31	Total Loss 0.0555 (0.0555)
2022-11-02 23:48:17,981:INFO: Batch:  1/31	Total Loss 0.0555 (0.0555)
2022-11-02 23:48:18,243:INFO: Batch:  2/31	Total Loss 0.0489 (0.0532)
2022-11-02 23:48:18,495:INFO: Batch:  3/31	Total Loss 0.0507 (0.0526)
2022-11-02 23:48:18,750:INFO: Batch:  4/31	Total Loss 0.0501 (0.0521)
2022-11-02 23:48:19,008:INFO: Batch:  5/31	Total Loss 0.0493 (0.0516)
2022-11-02 23:48:19,263:INFO: Batch:  6/31	Total Loss 0.0565 (0.0524)
2022-11-02 23:48:19,517:INFO: Batch:  7/31	Total Loss 0.0460 (0.0516)
2022-11-02 23:48:19,773:INFO: Batch:  8/31	Total Loss 0.0563 (0.0522)
2022-11-02 23:48:20,029:INFO: Batch:  9/31	Total Loss 0.0404 (0.0510)
2022-11-02 23:48:20,286:INFO: Batch: 10/31	Total Loss 0.0489 (0.0508)
2022-11-02 23:48:20,542:INFO: Batch: 11/31	Total Loss 0.0587 (0.0514)
2022-11-02 23:48:20,803:INFO: Batch: 12/31	Total Loss 0.0480 (0.0511)
2022-11-02 23:48:21,064:INFO: Batch: 13/31	Total Loss 0.0556 (0.0515)
2022-11-02 23:48:21,325:INFO: Batch: 14/31	Total Loss 0.0521 (0.0515)
2022-11-02 23:48:21,584:INFO: Batch: 15/31	Total Loss 0.0538 (0.0516)
2022-11-02 23:48:21,844:INFO: Batch: 16/31	Total Loss 0.0526 (0.0517)
2022-11-02 23:48:22,104:INFO: Batch: 17/31	Total Loss 0.0493 (0.0516)
2022-11-02 23:48:22,363:INFO: Batch: 18/31	Total Loss 0.0420 (0.0510)
2022-11-02 23:48:22,621:INFO: Batch: 19/31	Total Loss 0.0429 (0.0506)
2022-11-02 23:48:22,880:INFO: Batch: 20/31	Total Loss 0.0473 (0.0505)
2022-11-02 23:48:23,139:INFO: Batch: 21/31	Total Loss 0.0544 (0.0507)
2022-11-02 23:48:23,396:INFO: Batch: 22/31	Total Loss 0.0735 (0.0516)
2022-11-02 23:48:23,656:INFO: Batch: 23/31	Total Loss 0.0488 (0.0515)
2022-11-02 23:48:23,913:INFO: Batch: 24/31	Total Loss 0.0503 (0.0514)
2022-11-02 23:48:24,172:INFO: Batch: 25/31	Total Loss 0.0505 (0.0514)
2022-11-02 23:48:24,430:INFO: Batch: 26/31	Total Loss 0.0594 (0.0517)
2022-11-02 23:48:24,688:INFO: Batch: 27/31	Total Loss 0.0577 (0.0519)
2022-11-02 23:48:24,946:INFO: Batch: 28/31	Total Loss 0.0568 (0.0521)
2022-11-02 23:48:25,204:INFO: Batch: 29/31	Total Loss 0.0596 (0.0523)
2022-11-02 23:48:25,322:INFO: Batch: 30/31	Total Loss 0.0194 (0.0520)
2022-11-02 23:48:25,475:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_229.pth.tar
2022-11-02 23:48:25,475:INFO: 
===> EPOCH: 230 (P2)
2022-11-02 23:48:25,475:INFO: - Computing loss (training)
2022-11-02 23:48:26,334:INFO: Batch:  0/31	Total Loss 0.0507 (0.0507)
2022-11-02 23:48:26,602:INFO: Batch:  1/31	Total Loss 0.0507 (0.0507)
2022-11-02 23:48:26,857:INFO: Batch:  2/31	Total Loss 0.0415 (0.0472)
2022-11-02 23:48:27,112:INFO: Batch:  3/31	Total Loss 0.0488 (0.0476)
2022-11-02 23:48:27,366:INFO: Batch:  4/31	Total Loss 0.0421 (0.0465)
2022-11-02 23:48:27,623:INFO: Batch:  5/31	Total Loss 0.0467 (0.0466)
2022-11-02 23:48:27,879:INFO: Batch:  6/31	Total Loss 0.0504 (0.0471)
2022-11-02 23:48:28,134:INFO: Batch:  7/31	Total Loss 0.0601 (0.0490)
2022-11-02 23:48:28,388:INFO: Batch:  8/31	Total Loss 0.0484 (0.0489)
2022-11-02 23:48:28,643:INFO: Batch:  9/31	Total Loss 0.0528 (0.0492)
2022-11-02 23:48:28,898:INFO: Batch: 10/31	Total Loss 0.0483 (0.0492)
2022-11-02 23:48:29,157:INFO: Batch: 11/31	Total Loss 0.0484 (0.0491)
2022-11-02 23:48:29,416:INFO: Batch: 12/31	Total Loss 0.0524 (0.0494)
2022-11-02 23:48:29,678:INFO: Batch: 13/31	Total Loss 0.0459 (0.0491)
2022-11-02 23:48:29,939:INFO: Batch: 14/31	Total Loss 0.0588 (0.0498)
2022-11-02 23:48:30,201:INFO: Batch: 15/31	Total Loss 0.0712 (0.0512)
2022-11-02 23:48:30,463:INFO: Batch: 16/31	Total Loss 0.0562 (0.0514)
2022-11-02 23:48:30,725:INFO: Batch: 17/31	Total Loss 0.0448 (0.0511)
2022-11-02 23:48:30,986:INFO: Batch: 18/31	Total Loss 0.0454 (0.0508)
2022-11-02 23:48:31,322:INFO: Batch: 19/31	Total Loss 0.0602 (0.0512)
2022-11-02 23:48:31,580:INFO: Batch: 20/31	Total Loss 0.0752 (0.0523)
2022-11-02 23:48:31,838:INFO: Batch: 21/31	Total Loss 0.0494 (0.0522)
2022-11-02 23:48:32,097:INFO: Batch: 22/31	Total Loss 0.0471 (0.0520)
2022-11-02 23:48:32,356:INFO: Batch: 23/31	Total Loss 0.0464 (0.0517)
2022-11-02 23:48:32,615:INFO: Batch: 24/31	Total Loss 0.0485 (0.0516)
2022-11-02 23:48:32,876:INFO: Batch: 25/31	Total Loss 0.0464 (0.0514)
2022-11-02 23:48:33,134:INFO: Batch: 26/31	Total Loss 0.0431 (0.0511)
2022-11-02 23:48:33,396:INFO: Batch: 27/31	Total Loss 0.0452 (0.0509)
2022-11-02 23:48:33,655:INFO: Batch: 28/31	Total Loss 0.0478 (0.0508)
2022-11-02 23:48:33,914:INFO: Batch: 29/31	Total Loss 0.0526 (0.0508)
2022-11-02 23:48:34,032:INFO: Batch: 30/31	Total Loss 0.0172 (0.0505)
2022-11-02 23:48:34,192:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_230.pth.tar
2022-11-02 23:48:34,192:INFO: 
===> EPOCH: 231 (P2)
2022-11-02 23:48:34,192:INFO: - Computing loss (training)
2022-11-02 23:48:35,074:INFO: Batch:  0/31	Total Loss 0.0527 (0.0527)
2022-11-02 23:48:35,333:INFO: Batch:  1/31	Total Loss 0.0456 (0.0494)
2022-11-02 23:48:35,599:INFO: Batch:  2/31	Total Loss 0.0519 (0.0502)
2022-11-02 23:48:35,852:INFO: Batch:  3/31	Total Loss 0.0477 (0.0496)
2022-11-02 23:48:36,105:INFO: Batch:  4/31	Total Loss 0.0561 (0.0509)
2022-11-02 23:48:36,362:INFO: Batch:  5/31	Total Loss 0.0473 (0.0503)
2022-11-02 23:48:36,616:INFO: Batch:  6/31	Total Loss 0.0512 (0.0504)
2022-11-02 23:48:36,871:INFO: Batch:  7/31	Total Loss 0.0496 (0.0503)
2022-11-02 23:48:37,129:INFO: Batch:  8/31	Total Loss 0.0412 (0.0494)
2022-11-02 23:48:37,385:INFO: Batch:  9/31	Total Loss 0.0484 (0.0493)
2022-11-02 23:48:37,638:INFO: Batch: 10/31	Total Loss 0.0494 (0.0493)
2022-11-02 23:48:37,894:INFO: Batch: 11/31	Total Loss 0.0421 (0.0487)
2022-11-02 23:48:38,152:INFO: Batch: 12/31	Total Loss 0.0461 (0.0485)
2022-11-02 23:48:38,411:INFO: Batch: 13/31	Total Loss 0.0519 (0.0487)
2022-11-02 23:48:38,672:INFO: Batch: 14/31	Total Loss 0.0457 (0.0485)
2022-11-02 23:48:38,932:INFO: Batch: 15/31	Total Loss 0.0491 (0.0485)
2022-11-02 23:48:39,191:INFO: Batch: 16/31	Total Loss 0.0452 (0.0483)
2022-11-02 23:48:39,450:INFO: Batch: 17/31	Total Loss 0.0507 (0.0485)
2022-11-02 23:48:39,712:INFO: Batch: 18/31	Total Loss 0.0556 (0.0489)
2022-11-02 23:48:39,970:INFO: Batch: 19/31	Total Loss 0.0456 (0.0487)
2022-11-02 23:48:40,228:INFO: Batch: 20/31	Total Loss 0.0530 (0.0489)
2022-11-02 23:48:40,485:INFO: Batch: 21/31	Total Loss 0.0860 (0.0505)
2022-11-02 23:48:40,743:INFO: Batch: 22/31	Total Loss 0.0806 (0.0516)
2022-11-02 23:48:41,001:INFO: Batch: 23/31	Total Loss 0.0611 (0.0520)
2022-11-02 23:48:41,260:INFO: Batch: 24/31	Total Loss 0.0539 (0.0521)
2022-11-02 23:48:41,518:INFO: Batch: 25/31	Total Loss 0.0592 (0.0524)
2022-11-02 23:48:41,777:INFO: Batch: 26/31	Total Loss 0.0514 (0.0524)
2022-11-02 23:48:42,035:INFO: Batch: 27/31	Total Loss 0.0493 (0.0523)
2022-11-02 23:48:42,293:INFO: Batch: 28/31	Total Loss 0.0449 (0.0520)
2022-11-02 23:48:42,552:INFO: Batch: 29/31	Total Loss 0.0415 (0.0516)
2022-11-02 23:48:42,670:INFO: Batch: 30/31	Total Loss 0.0164 (0.0512)
2022-11-02 23:48:42,817:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_231.pth.tar
2022-11-02 23:48:42,817:INFO: 
===> EPOCH: 232 (P2)
2022-11-02 23:48:42,818:INFO: - Computing loss (training)
2022-11-02 23:48:43,704:INFO: Batch:  0/31	Total Loss 0.0563 (0.0563)
2022-11-02 23:48:43,970:INFO: Batch:  1/31	Total Loss 0.0500 (0.0532)
2022-11-02 23:48:44,233:INFO: Batch:  2/31	Total Loss 0.0458 (0.0507)
2022-11-02 23:48:44,496:INFO: Batch:  3/31	Total Loss 0.0618 (0.0538)
2022-11-02 23:48:44,753:INFO: Batch:  4/31	Total Loss 0.0472 (0.0523)
2022-11-02 23:48:45,014:INFO: Batch:  5/31	Total Loss 0.0447 (0.0510)
2022-11-02 23:48:45,273:INFO: Batch:  6/31	Total Loss 0.0486 (0.0507)
2022-11-02 23:48:45,530:INFO: Batch:  7/31	Total Loss 0.0467 (0.0502)
2022-11-02 23:48:45,789:INFO: Batch:  8/31	Total Loss 0.0514 (0.0503)
2022-11-02 23:48:46,051:INFO: Batch:  9/31	Total Loss 0.0495 (0.0503)
2022-11-02 23:48:46,310:INFO: Batch: 10/31	Total Loss 0.0456 (0.0499)
2022-11-02 23:48:46,570:INFO: Batch: 11/31	Total Loss 0.0472 (0.0496)
2022-11-02 23:48:46,833:INFO: Batch: 12/31	Total Loss 0.0413 (0.0490)
2022-11-02 23:48:47,097:INFO: Batch: 13/31	Total Loss 0.0560 (0.0495)
2022-11-02 23:48:47,360:INFO: Batch: 14/31	Total Loss 0.0543 (0.0498)
2022-11-02 23:48:47,624:INFO: Batch: 15/31	Total Loss 0.0443 (0.0495)
2022-11-02 23:48:47,888:INFO: Batch: 16/31	Total Loss 0.0480 (0.0494)
2022-11-02 23:48:48,151:INFO: Batch: 17/31	Total Loss 0.0488 (0.0494)
2022-11-02 23:48:48,408:INFO: Batch: 18/31	Total Loss 0.0503 (0.0494)
2022-11-02 23:48:48,665:INFO: Batch: 19/31	Total Loss 0.0391 (0.0489)
2022-11-02 23:48:48,922:INFO: Batch: 20/31	Total Loss 0.0553 (0.0492)
2022-11-02 23:48:49,178:INFO: Batch: 21/31	Total Loss 0.0505 (0.0492)
2022-11-02 23:48:49,435:INFO: Batch: 22/31	Total Loss 0.0726 (0.0504)
2022-11-02 23:48:49,695:INFO: Batch: 23/31	Total Loss 0.0475 (0.0503)
2022-11-02 23:48:49,951:INFO: Batch: 24/31	Total Loss 0.0480 (0.0502)
2022-11-02 23:48:50,209:INFO: Batch: 25/31	Total Loss 0.0451 (0.0500)
2022-11-02 23:48:50,467:INFO: Batch: 26/31	Total Loss 0.0468 (0.0498)
2022-11-02 23:48:50,726:INFO: Batch: 27/31	Total Loss 0.0457 (0.0497)
2022-11-02 23:48:50,983:INFO: Batch: 28/31	Total Loss 0.0660 (0.0502)
2022-11-02 23:48:51,241:INFO: Batch: 29/31	Total Loss 0.0443 (0.0500)
2022-11-02 23:48:51,359:INFO: Batch: 30/31	Total Loss 0.0200 (0.0497)
2022-11-02 23:48:51,507:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_232.pth.tar
2022-11-02 23:48:51,507:INFO: 
===> EPOCH: 233 (P2)
2022-11-02 23:48:51,507:INFO: - Computing loss (training)
2022-11-02 23:48:52,367:INFO: Batch:  0/31	Total Loss 0.0417 (0.0417)
2022-11-02 23:48:52,624:INFO: Batch:  1/31	Total Loss 0.0426 (0.0421)
2022-11-02 23:48:52,883:INFO: Batch:  2/31	Total Loss 0.0473 (0.0438)
2022-11-02 23:48:53,137:INFO: Batch:  3/31	Total Loss 0.0504 (0.0455)
2022-11-02 23:48:53,396:INFO: Batch:  4/31	Total Loss 0.0457 (0.0455)
2022-11-02 23:48:53,652:INFO: Batch:  5/31	Total Loss 0.0514 (0.0465)
2022-11-02 23:48:53,908:INFO: Batch:  6/31	Total Loss 0.0427 (0.0459)
2022-11-02 23:48:54,163:INFO: Batch:  7/31	Total Loss 0.0369 (0.0448)
2022-11-02 23:48:54,419:INFO: Batch:  8/31	Total Loss 0.0541 (0.0459)
2022-11-02 23:48:54,673:INFO: Batch:  9/31	Total Loss 0.0481 (0.0461)
2022-11-02 23:48:54,930:INFO: Batch: 10/31	Total Loss 0.0425 (0.0458)
2022-11-02 23:48:55,186:INFO: Batch: 11/31	Total Loss 0.0477 (0.0459)
2022-11-02 23:48:55,444:INFO: Batch: 12/31	Total Loss 0.0514 (0.0463)
2022-11-02 23:48:55,703:INFO: Batch: 13/31	Total Loss 0.0461 (0.0463)
2022-11-02 23:48:55,962:INFO: Batch: 14/31	Total Loss 0.0420 (0.0460)
2022-11-02 23:48:56,221:INFO: Batch: 15/31	Total Loss 0.0446 (0.0459)
2022-11-02 23:48:56,480:INFO: Batch: 16/31	Total Loss 0.0474 (0.0460)
2022-11-02 23:48:56,740:INFO: Batch: 17/31	Total Loss 0.0585 (0.0467)
2022-11-02 23:48:56,999:INFO: Batch: 18/31	Total Loss 0.0514 (0.0469)
2022-11-02 23:48:57,257:INFO: Batch: 19/31	Total Loss 0.0479 (0.0469)
2022-11-02 23:48:57,516:INFO: Batch: 20/31	Total Loss 0.0485 (0.0470)
2022-11-02 23:48:57,774:INFO: Batch: 21/31	Total Loss 0.0450 (0.0469)
2022-11-02 23:48:58,032:INFO: Batch: 22/31	Total Loss 0.0515 (0.0471)
2022-11-02 23:48:58,291:INFO: Batch: 23/31	Total Loss 0.0443 (0.0470)
2022-11-02 23:48:58,549:INFO: Batch: 24/31	Total Loss 0.0468 (0.0470)
2022-11-02 23:48:58,808:INFO: Batch: 25/31	Total Loss 0.0542 (0.0472)
2022-11-02 23:48:59,066:INFO: Batch: 26/31	Total Loss 0.0518 (0.0474)
2022-11-02 23:48:59,324:INFO: Batch: 27/31	Total Loss 0.0476 (0.0474)
2022-11-02 23:48:59,586:INFO: Batch: 28/31	Total Loss 0.0502 (0.0475)
2022-11-02 23:48:59,844:INFO: Batch: 29/31	Total Loss 0.0464 (0.0475)
2022-11-02 23:48:59,962:INFO: Batch: 30/31	Total Loss 0.0344 (0.0473)
2022-11-02 23:49:00,122:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_233.pth.tar
2022-11-02 23:49:00,122:INFO: 
===> EPOCH: 234 (P2)
2022-11-02 23:49:00,123:INFO: - Computing loss (training)
2022-11-02 23:49:00,978:INFO: Batch:  0/31	Total Loss 0.0594 (0.0594)
2022-11-02 23:49:01,236:INFO: Batch:  1/31	Total Loss 0.0406 (0.0503)
2022-11-02 23:49:01,488:INFO: Batch:  2/31	Total Loss 0.0456 (0.0488)
2022-11-02 23:49:01,744:INFO: Batch:  3/31	Total Loss 0.0485 (0.0488)
2022-11-02 23:49:02,002:INFO: Batch:  4/31	Total Loss 0.0408 (0.0471)
2022-11-02 23:49:02,258:INFO: Batch:  5/31	Total Loss 0.0427 (0.0463)
2022-11-02 23:49:02,512:INFO: Batch:  6/31	Total Loss 0.0513 (0.0470)
2022-11-02 23:49:02,766:INFO: Batch:  7/31	Total Loss 0.0482 (0.0472)
2022-11-02 23:49:03,018:INFO: Batch:  8/31	Total Loss 0.0480 (0.0473)
2022-11-02 23:49:03,272:INFO: Batch:  9/31	Total Loss 0.0492 (0.0475)
2022-11-02 23:49:03,527:INFO: Batch: 10/31	Total Loss 0.0454 (0.0473)
2022-11-02 23:49:03,782:INFO: Batch: 11/31	Total Loss 0.0490 (0.0474)
2022-11-02 23:49:04,041:INFO: Batch: 12/31	Total Loss 0.0422 (0.0470)
2022-11-02 23:49:04,299:INFO: Batch: 13/31	Total Loss 0.0469 (0.0470)
2022-11-02 23:49:04,557:INFO: Batch: 14/31	Total Loss 0.0461 (0.0469)
2022-11-02 23:49:04,815:INFO: Batch: 15/31	Total Loss 0.0612 (0.0478)
2022-11-02 23:49:05,072:INFO: Batch: 16/31	Total Loss 0.0502 (0.0480)
2022-11-02 23:49:05,333:INFO: Batch: 17/31	Total Loss 0.0398 (0.0475)
2022-11-02 23:49:05,591:INFO: Batch: 18/31	Total Loss 0.0417 (0.0473)
2022-11-02 23:49:05,850:INFO: Batch: 19/31	Total Loss 0.0357 (0.0467)
2022-11-02 23:49:06,107:INFO: Batch: 20/31	Total Loss 0.0459 (0.0467)
2022-11-02 23:49:06,365:INFO: Batch: 21/31	Total Loss 0.0413 (0.0465)
2022-11-02 23:49:06,622:INFO: Batch: 22/31	Total Loss 0.0493 (0.0466)
2022-11-02 23:49:06,880:INFO: Batch: 23/31	Total Loss 0.0360 (0.0461)
2022-11-02 23:49:07,137:INFO: Batch: 24/31	Total Loss 0.0425 (0.0460)
2022-11-02 23:49:07,397:INFO: Batch: 25/31	Total Loss 0.0500 (0.0462)
2022-11-02 23:49:07,655:INFO: Batch: 26/31	Total Loss 0.0434 (0.0461)
2022-11-02 23:49:07,913:INFO: Batch: 27/31	Total Loss 0.0428 (0.0459)
2022-11-02 23:49:08,172:INFO: Batch: 28/31	Total Loss 0.0418 (0.0458)
2022-11-02 23:49:08,429:INFO: Batch: 29/31	Total Loss 0.0521 (0.0460)
2022-11-02 23:49:08,546:INFO: Batch: 30/31	Total Loss 0.0157 (0.0458)
2022-11-02 23:49:08,700:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_234.pth.tar
2022-11-02 23:49:08,700:INFO: 
===> EPOCH: 235 (P2)
2022-11-02 23:49:08,701:INFO: - Computing loss (training)
2022-11-02 23:49:09,544:INFO: Batch:  0/31	Total Loss 0.0414 (0.0414)
2022-11-02 23:49:09,814:INFO: Batch:  1/31	Total Loss 0.0476 (0.0447)
2022-11-02 23:49:10,073:INFO: Batch:  2/31	Total Loss 0.0385 (0.0426)
2022-11-02 23:49:10,326:INFO: Batch:  3/31	Total Loss 0.0442 (0.0429)
2022-11-02 23:49:10,580:INFO: Batch:  4/31	Total Loss 0.0410 (0.0425)
2022-11-02 23:49:10,841:INFO: Batch:  5/31	Total Loss 0.0446 (0.0428)
2022-11-02 23:49:11,096:INFO: Batch:  6/31	Total Loss 0.0471 (0.0434)
2022-11-02 23:49:11,353:INFO: Batch:  7/31	Total Loss 0.0408 (0.0431)
2022-11-02 23:49:11,609:INFO: Batch:  8/31	Total Loss 0.0412 (0.0429)
2022-11-02 23:49:11,861:INFO: Batch:  9/31	Total Loss 0.0424 (0.0428)
2022-11-02 23:49:12,116:INFO: Batch: 10/31	Total Loss 0.0409 (0.0426)
2022-11-02 23:49:12,374:INFO: Batch: 11/31	Total Loss 0.0451 (0.0428)
2022-11-02 23:49:12,631:INFO: Batch: 12/31	Total Loss 0.0406 (0.0427)
2022-11-02 23:49:12,890:INFO: Batch: 13/31	Total Loss 0.0493 (0.0432)
2022-11-02 23:49:13,148:INFO: Batch: 14/31	Total Loss 0.0516 (0.0437)
2022-11-02 23:49:13,405:INFO: Batch: 15/31	Total Loss 0.0494 (0.0441)
2022-11-02 23:49:13,672:INFO: Batch: 16/31	Total Loss 0.0493 (0.0444)
2022-11-02 23:49:13,942:INFO: Batch: 17/31	Total Loss 0.0416 (0.0442)
2022-11-02 23:49:14,211:INFO: Batch: 18/31	Total Loss 0.0427 (0.0442)
2022-11-02 23:49:14,467:INFO: Batch: 19/31	Total Loss 0.0467 (0.0443)
2022-11-02 23:49:14,727:INFO: Batch: 20/31	Total Loss 0.0472 (0.0444)
2022-11-02 23:49:14,985:INFO: Batch: 21/31	Total Loss 0.0401 (0.0442)
2022-11-02 23:49:15,242:INFO: Batch: 22/31	Total Loss 0.0450 (0.0442)
2022-11-02 23:49:15,499:INFO: Batch: 23/31	Total Loss 0.0428 (0.0442)
2022-11-02 23:49:15,757:INFO: Batch: 24/31	Total Loss 0.0398 (0.0440)
2022-11-02 23:49:16,015:INFO: Batch: 25/31	Total Loss 0.0478 (0.0441)
2022-11-02 23:49:16,271:INFO: Batch: 26/31	Total Loss 0.0505 (0.0443)
2022-11-02 23:49:16,527:INFO: Batch: 27/31	Total Loss 0.0385 (0.0442)
2022-11-02 23:49:16,784:INFO: Batch: 28/31	Total Loss 0.0450 (0.0442)
2022-11-02 23:49:17,040:INFO: Batch: 29/31	Total Loss 0.0535 (0.0445)
2022-11-02 23:49:17,157:INFO: Batch: 30/31	Total Loss 0.0163 (0.0442)
2022-11-02 23:49:17,303:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_235.pth.tar
2022-11-02 23:49:17,303:INFO: 
===> EPOCH: 236 (P2)
2022-11-02 23:49:17,303:INFO: - Computing loss (training)
2022-11-02 23:49:18,196:INFO: Batch:  0/31	Total Loss 0.0504 (0.0504)
2022-11-02 23:49:18,458:INFO: Batch:  1/31	Total Loss 0.0544 (0.0523)
2022-11-02 23:49:18,711:INFO: Batch:  2/31	Total Loss 0.0454 (0.0499)
2022-11-02 23:49:18,966:INFO: Batch:  3/31	Total Loss 0.0308 (0.0452)
2022-11-02 23:49:19,225:INFO: Batch:  4/31	Total Loss 0.0357 (0.0433)
2022-11-02 23:49:19,488:INFO: Batch:  5/31	Total Loss 0.0554 (0.0452)
2022-11-02 23:49:19,744:INFO: Batch:  6/31	Total Loss 0.0429 (0.0449)
2022-11-02 23:49:20,001:INFO: Batch:  7/31	Total Loss 0.0412 (0.0444)
2022-11-02 23:49:20,256:INFO: Batch:  8/31	Total Loss 0.0660 (0.0467)
2022-11-02 23:49:20,514:INFO: Batch:  9/31	Total Loss 0.0412 (0.0462)
2022-11-02 23:49:20,771:INFO: Batch: 10/31	Total Loss 0.0444 (0.0460)
2022-11-02 23:49:21,027:INFO: Batch: 11/31	Total Loss 0.0462 (0.0460)
2022-11-02 23:49:21,286:INFO: Batch: 12/31	Total Loss 0.0367 (0.0452)
2022-11-02 23:49:21,545:INFO: Batch: 13/31	Total Loss 0.0487 (0.0455)
2022-11-02 23:49:21,804:INFO: Batch: 14/31	Total Loss 0.0431 (0.0454)
2022-11-02 23:49:22,064:INFO: Batch: 15/31	Total Loss 0.0413 (0.0451)
2022-11-02 23:49:22,399:INFO: Batch: 16/31	Total Loss 0.0449 (0.0451)
2022-11-02 23:49:22,657:INFO: Batch: 17/31	Total Loss 0.0407 (0.0448)
2022-11-02 23:49:22,915:INFO: Batch: 18/31	Total Loss 0.0402 (0.0446)
2022-11-02 23:49:23,173:INFO: Batch: 19/31	Total Loss 0.0406 (0.0444)
2022-11-02 23:49:23,433:INFO: Batch: 20/31	Total Loss 0.0436 (0.0444)
2022-11-02 23:49:23,690:INFO: Batch: 21/31	Total Loss 0.0419 (0.0443)
2022-11-02 23:49:23,949:INFO: Batch: 22/31	Total Loss 0.0396 (0.0441)
2022-11-02 23:49:24,207:INFO: Batch: 23/31	Total Loss 0.0442 (0.0441)
2022-11-02 23:49:24,465:INFO: Batch: 24/31	Total Loss 0.0429 (0.0440)
2022-11-02 23:49:24,722:INFO: Batch: 25/31	Total Loss 0.0403 (0.0439)
2022-11-02 23:49:24,979:INFO: Batch: 26/31	Total Loss 0.0486 (0.0441)
2022-11-02 23:49:25,236:INFO: Batch: 27/31	Total Loss 0.0458 (0.0441)
2022-11-02 23:49:25,493:INFO: Batch: 28/31	Total Loss 0.0614 (0.0447)
2022-11-02 23:49:25,751:INFO: Batch: 29/31	Total Loss 0.0429 (0.0446)
2022-11-02 23:49:25,869:INFO: Batch: 30/31	Total Loss 0.0152 (0.0442)
2022-11-02 23:49:26,036:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_236.pth.tar
2022-11-02 23:49:26,036:INFO: 
===> EPOCH: 237 (P2)
2022-11-02 23:49:26,036:INFO: - Computing loss (training)
2022-11-02 23:49:26,920:INFO: Batch:  0/31	Total Loss 0.0479 (0.0479)
2022-11-02 23:49:27,181:INFO: Batch:  1/31	Total Loss 0.0467 (0.0473)
2022-11-02 23:49:27,443:INFO: Batch:  2/31	Total Loss 0.0502 (0.0483)
2022-11-02 23:49:27,703:INFO: Batch:  3/31	Total Loss 0.0336 (0.0445)
2022-11-02 23:49:27,961:INFO: Batch:  4/31	Total Loss 0.0476 (0.0451)
2022-11-02 23:49:28,221:INFO: Batch:  5/31	Total Loss 0.0431 (0.0448)
2022-11-02 23:49:28,475:INFO: Batch:  6/31	Total Loss 0.0490 (0.0454)
2022-11-02 23:49:28,734:INFO: Batch:  7/31	Total Loss 0.0568 (0.0469)
2022-11-02 23:49:28,991:INFO: Batch:  8/31	Total Loss 0.0474 (0.0470)
2022-11-02 23:49:29,247:INFO: Batch:  9/31	Total Loss 0.0467 (0.0470)
2022-11-02 23:49:29,503:INFO: Batch: 10/31	Total Loss 0.0468 (0.0469)
2022-11-02 23:49:29,767:INFO: Batch: 11/31	Total Loss 0.0375 (0.0462)
2022-11-02 23:49:30,029:INFO: Batch: 12/31	Total Loss 0.0412 (0.0459)
2022-11-02 23:49:30,290:INFO: Batch: 13/31	Total Loss 0.0476 (0.0460)
2022-11-02 23:49:30,549:INFO: Batch: 14/31	Total Loss 0.0322 (0.0451)
2022-11-02 23:49:30,810:INFO: Batch: 15/31	Total Loss 0.0407 (0.0449)
2022-11-02 23:49:31,072:INFO: Batch: 16/31	Total Loss 0.0478 (0.0451)
2022-11-02 23:49:31,333:INFO: Batch: 17/31	Total Loss 0.0425 (0.0449)
2022-11-02 23:49:31,592:INFO: Batch: 18/31	Total Loss 0.0389 (0.0446)
2022-11-02 23:49:31,852:INFO: Batch: 19/31	Total Loss 0.0363 (0.0442)
2022-11-02 23:49:32,113:INFO: Batch: 20/31	Total Loss 0.0465 (0.0443)
2022-11-02 23:49:32,373:INFO: Batch: 21/31	Total Loss 0.0327 (0.0437)
2022-11-02 23:49:32,635:INFO: Batch: 22/31	Total Loss 0.0447 (0.0438)
2022-11-02 23:49:32,894:INFO: Batch: 23/31	Total Loss 0.0427 (0.0437)
2022-11-02 23:49:33,155:INFO: Batch: 24/31	Total Loss 0.0449 (0.0438)
2022-11-02 23:49:33,414:INFO: Batch: 25/31	Total Loss 0.0478 (0.0439)
2022-11-02 23:49:33,674:INFO: Batch: 26/31	Total Loss 0.0401 (0.0438)
2022-11-02 23:49:33,936:INFO: Batch: 27/31	Total Loss 0.0394 (0.0436)
2022-11-02 23:49:34,198:INFO: Batch: 28/31	Total Loss 0.0371 (0.0434)
2022-11-02 23:49:34,456:INFO: Batch: 29/31	Total Loss 0.0514 (0.0436)
2022-11-02 23:49:34,576:INFO: Batch: 30/31	Total Loss 0.0211 (0.0434)
2022-11-02 23:49:34,729:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_237.pth.tar
2022-11-02 23:49:34,729:INFO: 
===> EPOCH: 238 (P2)
2022-11-02 23:49:34,729:INFO: - Computing loss (training)
2022-11-02 23:49:35,673:INFO: Batch:  0/31	Total Loss 0.0377 (0.0377)
2022-11-02 23:49:35,936:INFO: Batch:  1/31	Total Loss 0.0543 (0.0454)
2022-11-02 23:49:36,198:INFO: Batch:  2/31	Total Loss 0.0553 (0.0489)
2022-11-02 23:49:36,458:INFO: Batch:  3/31	Total Loss 0.0432 (0.0475)
2022-11-02 23:49:36,712:INFO: Batch:  4/31	Total Loss 0.0383 (0.0457)
2022-11-02 23:49:36,968:INFO: Batch:  5/31	Total Loss 0.0403 (0.0448)
2022-11-02 23:49:37,224:INFO: Batch:  6/31	Total Loss 0.0482 (0.0453)
2022-11-02 23:49:37,477:INFO: Batch:  7/31	Total Loss 0.0424 (0.0450)
2022-11-02 23:49:37,732:INFO: Batch:  8/31	Total Loss 0.0433 (0.0448)
2022-11-02 23:49:37,987:INFO: Batch:  9/31	Total Loss 0.0399 (0.0443)
2022-11-02 23:49:38,244:INFO: Batch: 10/31	Total Loss 0.0436 (0.0443)
2022-11-02 23:49:38,499:INFO: Batch: 11/31	Total Loss 0.0434 (0.0442)
2022-11-02 23:49:38,758:INFO: Batch: 12/31	Total Loss 0.0319 (0.0433)
2022-11-02 23:49:39,018:INFO: Batch: 13/31	Total Loss 0.0398 (0.0430)
2022-11-02 23:49:39,277:INFO: Batch: 14/31	Total Loss 0.0626 (0.0444)
2022-11-02 23:49:39,538:INFO: Batch: 15/31	Total Loss 0.0399 (0.0441)
2022-11-02 23:49:39,797:INFO: Batch: 16/31	Total Loss 0.0457 (0.0442)
2022-11-02 23:49:40,056:INFO: Batch: 17/31	Total Loss 0.0411 (0.0440)
2022-11-02 23:49:40,315:INFO: Batch: 18/31	Total Loss 0.0378 (0.0437)
2022-11-02 23:49:40,574:INFO: Batch: 19/31	Total Loss 0.0463 (0.0439)
2022-11-02 23:49:40,833:INFO: Batch: 20/31	Total Loss 0.0376 (0.0436)
2022-11-02 23:49:41,090:INFO: Batch: 21/31	Total Loss 0.0413 (0.0435)
2022-11-02 23:49:41,348:INFO: Batch: 22/31	Total Loss 0.0446 (0.0435)
2022-11-02 23:49:41,607:INFO: Batch: 23/31	Total Loss 0.0544 (0.0440)
2022-11-02 23:49:41,865:INFO: Batch: 24/31	Total Loss 0.0385 (0.0438)
2022-11-02 23:49:42,123:INFO: Batch: 25/31	Total Loss 0.0416 (0.0437)
2022-11-02 23:49:42,382:INFO: Batch: 26/31	Total Loss 0.0412 (0.0436)
2022-11-02 23:49:42,639:INFO: Batch: 27/31	Total Loss 0.0419 (0.0435)
2022-11-02 23:49:42,897:INFO: Batch: 28/31	Total Loss 0.0445 (0.0436)
2022-11-02 23:49:43,155:INFO: Batch: 29/31	Total Loss 0.0429 (0.0436)
2022-11-02 23:49:43,272:INFO: Batch: 30/31	Total Loss 0.0149 (0.0433)
2022-11-02 23:49:43,427:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_238.pth.tar
2022-11-02 23:49:43,427:INFO: 
===> EPOCH: 239 (P2)
2022-11-02 23:49:43,427:INFO: - Computing loss (training)
2022-11-02 23:49:44,332:INFO: Batch:  0/31	Total Loss 0.0273 (0.0273)
2022-11-02 23:49:44,593:INFO: Batch:  1/31	Total Loss 0.0404 (0.0343)
2022-11-02 23:49:44,850:INFO: Batch:  2/31	Total Loss 0.0444 (0.0375)
2022-11-02 23:49:45,104:INFO: Batch:  3/31	Total Loss 0.0536 (0.0413)
2022-11-02 23:49:45,362:INFO: Batch:  4/31	Total Loss 0.0504 (0.0429)
2022-11-02 23:49:45,620:INFO: Batch:  5/31	Total Loss 0.0411 (0.0426)
2022-11-02 23:49:45,877:INFO: Batch:  6/31	Total Loss 0.0594 (0.0449)
2022-11-02 23:49:46,132:INFO: Batch:  7/31	Total Loss 0.0702 (0.0481)
2022-11-02 23:49:46,386:INFO: Batch:  8/31	Total Loss 0.0468 (0.0479)
2022-11-02 23:49:46,640:INFO: Batch:  9/31	Total Loss 0.0408 (0.0472)
2022-11-02 23:49:46,897:INFO: Batch: 10/31	Total Loss 0.0363 (0.0462)
2022-11-02 23:49:47,154:INFO: Batch: 11/31	Total Loss 0.0548 (0.0469)
2022-11-02 23:49:47,415:INFO: Batch: 12/31	Total Loss 0.0416 (0.0465)
2022-11-02 23:49:47,673:INFO: Batch: 13/31	Total Loss 0.0757 (0.0484)
2022-11-02 23:49:47,932:INFO: Batch: 14/31	Total Loss 0.0399 (0.0478)
2022-11-02 23:49:48,192:INFO: Batch: 15/31	Total Loss 0.0366 (0.0471)
2022-11-02 23:49:48,450:INFO: Batch: 16/31	Total Loss 0.0566 (0.0477)
2022-11-02 23:49:48,708:INFO: Batch: 17/31	Total Loss 0.0444 (0.0475)
2022-11-02 23:49:48,967:INFO: Batch: 18/31	Total Loss 0.0659 (0.0484)
2022-11-02 23:49:49,225:INFO: Batch: 19/31	Total Loss 0.0424 (0.0481)
2022-11-02 23:49:49,483:INFO: Batch: 20/31	Total Loss 0.0398 (0.0477)
2022-11-02 23:49:49,742:INFO: Batch: 21/31	Total Loss 0.0449 (0.0476)
2022-11-02 23:49:50,000:INFO: Batch: 22/31	Total Loss 0.0472 (0.0476)
2022-11-02 23:49:50,259:INFO: Batch: 23/31	Total Loss 0.0497 (0.0477)
2022-11-02 23:49:50,518:INFO: Batch: 24/31	Total Loss 0.0439 (0.0475)
2022-11-02 23:49:50,776:INFO: Batch: 25/31	Total Loss 0.0434 (0.0474)
2022-11-02 23:49:51,033:INFO: Batch: 26/31	Total Loss 0.0377 (0.0470)
2022-11-02 23:49:51,291:INFO: Batch: 27/31	Total Loss 0.0377 (0.0466)
2022-11-02 23:49:51,548:INFO: Batch: 28/31	Total Loss 0.0405 (0.0464)
2022-11-02 23:49:51,806:INFO: Batch: 29/31	Total Loss 0.0476 (0.0465)
2022-11-02 23:49:51,924:INFO: Batch: 30/31	Total Loss 0.0114 (0.0461)
2022-11-02 23:49:52,079:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_239.pth.tar
2022-11-02 23:49:52,079:INFO: 
===> EPOCH: 240 (P2)
2022-11-02 23:49:52,080:INFO: - Computing loss (training)
2022-11-02 23:49:52,971:INFO: Batch:  0/31	Total Loss 0.0461 (0.0461)
2022-11-02 23:49:53,225:INFO: Batch:  1/31	Total Loss 0.0413 (0.0437)
2022-11-02 23:49:53,480:INFO: Batch:  2/31	Total Loss 0.0444 (0.0439)
2022-11-02 23:49:53,732:INFO: Batch:  3/31	Total Loss 0.0425 (0.0436)
2022-11-02 23:49:53,984:INFO: Batch:  4/31	Total Loss 0.0375 (0.0425)
2022-11-02 23:49:54,242:INFO: Batch:  5/31	Total Loss 0.0421 (0.0424)
2022-11-02 23:49:54,494:INFO: Batch:  6/31	Total Loss 0.0583 (0.0448)
2022-11-02 23:49:54,749:INFO: Batch:  7/31	Total Loss 0.0393 (0.0441)
2022-11-02 23:49:55,002:INFO: Batch:  8/31	Total Loss 0.0404 (0.0437)
2022-11-02 23:49:55,257:INFO: Batch:  9/31	Total Loss 0.0378 (0.0431)
2022-11-02 23:49:55,510:INFO: Batch: 10/31	Total Loss 0.0490 (0.0436)
2022-11-02 23:49:55,768:INFO: Batch: 11/31	Total Loss 0.0416 (0.0434)
2022-11-02 23:49:56,025:INFO: Batch: 12/31	Total Loss 0.0341 (0.0427)
2022-11-02 23:49:56,284:INFO: Batch: 13/31	Total Loss 0.0404 (0.0425)
2022-11-02 23:49:56,543:INFO: Batch: 14/31	Total Loss 0.0464 (0.0428)
2022-11-02 23:49:56,803:INFO: Batch: 15/31	Total Loss 0.0451 (0.0429)
2022-11-02 23:49:57,061:INFO: Batch: 16/31	Total Loss 0.0299 (0.0422)
2022-11-02 23:49:57,319:INFO: Batch: 17/31	Total Loss 0.0427 (0.0423)
2022-11-02 23:49:57,577:INFO: Batch: 18/31	Total Loss 0.0444 (0.0424)
2022-11-02 23:49:57,836:INFO: Batch: 19/31	Total Loss 0.0428 (0.0424)
2022-11-02 23:49:58,092:INFO: Batch: 20/31	Total Loss 0.0417 (0.0424)
2022-11-02 23:49:58,350:INFO: Batch: 21/31	Total Loss 0.0379 (0.0421)
2022-11-02 23:49:58,606:INFO: Batch: 22/31	Total Loss 0.0539 (0.0427)
2022-11-02 23:49:58,864:INFO: Batch: 23/31	Total Loss 0.0434 (0.0427)
2022-11-02 23:49:59,121:INFO: Batch: 24/31	Total Loss 0.0400 (0.0426)
2022-11-02 23:49:59,379:INFO: Batch: 25/31	Total Loss 0.0383 (0.0424)
2022-11-02 23:49:59,637:INFO: Batch: 26/31	Total Loss 0.0356 (0.0422)
2022-11-02 23:49:59,895:INFO: Batch: 27/31	Total Loss 0.0379 (0.0420)
2022-11-02 23:50:00,154:INFO: Batch: 28/31	Total Loss 0.0418 (0.0420)
2022-11-02 23:50:00,411:INFO: Batch: 29/31	Total Loss 0.0393 (0.0419)
2022-11-02 23:50:00,528:INFO: Batch: 30/31	Total Loss 0.0160 (0.0417)
2022-11-02 23:50:00,681:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_240.pth.tar
2022-11-02 23:50:00,681:INFO: 
===> EPOCH: 241 (P2)
2022-11-02 23:50:00,681:INFO: - Computing loss (training)
2022-11-02 23:50:01,532:INFO: Batch:  0/31	Total Loss 0.0399 (0.0399)
2022-11-02 23:50:01,792:INFO: Batch:  1/31	Total Loss 0.0332 (0.0366)
2022-11-02 23:50:02,049:INFO: Batch:  2/31	Total Loss 0.0422 (0.0383)
2022-11-02 23:50:02,306:INFO: Batch:  3/31	Total Loss 0.0389 (0.0384)
2022-11-02 23:50:02,560:INFO: Batch:  4/31	Total Loss 0.0322 (0.0371)
2022-11-02 23:50:02,822:INFO: Batch:  5/31	Total Loss 0.0408 (0.0377)
2022-11-02 23:50:03,075:INFO: Batch:  6/31	Total Loss 0.0439 (0.0387)
2022-11-02 23:50:03,328:INFO: Batch:  7/31	Total Loss 0.0448 (0.0395)
2022-11-02 23:50:03,582:INFO: Batch:  8/31	Total Loss 0.0458 (0.0402)
2022-11-02 23:50:03,838:INFO: Batch:  9/31	Total Loss 0.0404 (0.0402)
2022-11-02 23:50:04,091:INFO: Batch: 10/31	Total Loss 0.0367 (0.0399)
2022-11-02 23:50:04,347:INFO: Batch: 11/31	Total Loss 0.0566 (0.0414)
2022-11-02 23:50:04,604:INFO: Batch: 12/31	Total Loss 0.0534 (0.0423)
2022-11-02 23:50:04,865:INFO: Batch: 13/31	Total Loss 0.0499 (0.0428)
2022-11-02 23:50:05,122:INFO: Batch: 14/31	Total Loss 0.0390 (0.0426)
2022-11-02 23:50:05,383:INFO: Batch: 15/31	Total Loss 0.0368 (0.0422)
2022-11-02 23:50:05,642:INFO: Batch: 16/31	Total Loss 0.0387 (0.0420)
2022-11-02 23:50:05,901:INFO: Batch: 17/31	Total Loss 0.0426 (0.0420)
2022-11-02 23:50:06,160:INFO: Batch: 18/31	Total Loss 0.0467 (0.0423)
2022-11-02 23:50:06,418:INFO: Batch: 19/31	Total Loss 0.0479 (0.0425)
2022-11-02 23:50:06,675:INFO: Batch: 20/31	Total Loss 0.0361 (0.0422)
2022-11-02 23:50:06,936:INFO: Batch: 21/31	Total Loss 0.0368 (0.0420)
2022-11-02 23:50:07,194:INFO: Batch: 22/31	Total Loss 0.0397 (0.0419)
2022-11-02 23:50:07,530:INFO: Batch: 23/31	Total Loss 0.0481 (0.0422)
2022-11-02 23:50:07,787:INFO: Batch: 24/31	Total Loss 0.0406 (0.0421)
2022-11-02 23:50:08,045:INFO: Batch: 25/31	Total Loss 0.0312 (0.0417)
2022-11-02 23:50:08,304:INFO: Batch: 26/31	Total Loss 0.0438 (0.0418)
2022-11-02 23:50:08,560:INFO: Batch: 27/31	Total Loss 0.0396 (0.0417)
2022-11-02 23:50:08,819:INFO: Batch: 28/31	Total Loss 0.0454 (0.0418)
2022-11-02 23:50:09,077:INFO: Batch: 29/31	Total Loss 0.0374 (0.0417)
2022-11-02 23:50:09,195:INFO: Batch: 30/31	Total Loss 0.0178 (0.0414)
2022-11-02 23:50:09,345:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_241.pth.tar
2022-11-02 23:50:09,345:INFO: 
===> EPOCH: 242 (P2)
2022-11-02 23:50:09,346:INFO: - Computing loss (training)
2022-11-02 23:50:10,219:INFO: Batch:  0/31	Total Loss 0.0377 (0.0377)
2022-11-02 23:50:10,479:INFO: Batch:  1/31	Total Loss 0.0382 (0.0379)
2022-11-02 23:50:10,738:INFO: Batch:  2/31	Total Loss 0.0404 (0.0388)
2022-11-02 23:50:10,995:INFO: Batch:  3/31	Total Loss 0.0395 (0.0390)
2022-11-02 23:50:11,256:INFO: Batch:  4/31	Total Loss 0.0468 (0.0406)
2022-11-02 23:50:11,512:INFO: Batch:  5/31	Total Loss 0.0371 (0.0400)
2022-11-02 23:50:11,771:INFO: Batch:  6/31	Total Loss 0.0359 (0.0394)
2022-11-02 23:50:12,026:INFO: Batch:  7/31	Total Loss 0.0610 (0.0424)
2022-11-02 23:50:12,284:INFO: Batch:  8/31	Total Loss 0.0357 (0.0417)
2022-11-02 23:50:12,541:INFO: Batch:  9/31	Total Loss 0.0406 (0.0416)
2022-11-02 23:50:12,799:INFO: Batch: 10/31	Total Loss 0.0243 (0.0399)
2022-11-02 23:50:13,056:INFO: Batch: 11/31	Total Loss 0.0334 (0.0394)
2022-11-02 23:50:13,317:INFO: Batch: 12/31	Total Loss 0.0369 (0.0392)
2022-11-02 23:50:13,575:INFO: Batch: 13/31	Total Loss 0.0444 (0.0396)
2022-11-02 23:50:13,838:INFO: Batch: 14/31	Total Loss 0.0400 (0.0396)
2022-11-02 23:50:14,097:INFO: Batch: 15/31	Total Loss 0.0386 (0.0395)
2022-11-02 23:50:14,359:INFO: Batch: 16/31	Total Loss 0.0375 (0.0394)
2022-11-02 23:50:14,618:INFO: Batch: 17/31	Total Loss 0.0375 (0.0393)
2022-11-02 23:50:14,879:INFO: Batch: 18/31	Total Loss 0.0411 (0.0394)
2022-11-02 23:50:15,138:INFO: Batch: 19/31	Total Loss 0.0480 (0.0398)
2022-11-02 23:50:15,398:INFO: Batch: 20/31	Total Loss 0.0415 (0.0399)
2022-11-02 23:50:15,657:INFO: Batch: 21/31	Total Loss 0.0390 (0.0399)
2022-11-02 23:50:15,917:INFO: Batch: 22/31	Total Loss 0.0445 (0.0401)
2022-11-02 23:50:16,176:INFO: Batch: 23/31	Total Loss 0.0365 (0.0399)
2022-11-02 23:50:16,434:INFO: Batch: 24/31	Total Loss 0.0336 (0.0397)
2022-11-02 23:50:16,692:INFO: Batch: 25/31	Total Loss 0.0439 (0.0398)
2022-11-02 23:50:16,953:INFO: Batch: 26/31	Total Loss 0.0499 (0.0402)
2022-11-02 23:50:17,213:INFO: Batch: 27/31	Total Loss 0.0420 (0.0403)
2022-11-02 23:50:17,474:INFO: Batch: 28/31	Total Loss 0.0387 (0.0402)
2022-11-02 23:50:17,734:INFO: Batch: 29/31	Total Loss 0.0413 (0.0403)
2022-11-02 23:50:17,853:INFO: Batch: 30/31	Total Loss 0.0174 (0.0400)
2022-11-02 23:50:18,007:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_242.pth.tar
2022-11-02 23:50:18,007:INFO: 
===> EPOCH: 243 (P2)
2022-11-02 23:50:18,007:INFO: - Computing loss (training)
2022-11-02 23:50:18,886:INFO: Batch:  0/31	Total Loss 0.0525 (0.0525)
2022-11-02 23:50:19,148:INFO: Batch:  1/31	Total Loss 0.0419 (0.0473)
2022-11-02 23:50:19,408:INFO: Batch:  2/31	Total Loss 0.0355 (0.0438)
2022-11-02 23:50:19,665:INFO: Batch:  3/31	Total Loss 0.0417 (0.0432)
2022-11-02 23:50:19,920:INFO: Batch:  4/31	Total Loss 0.0372 (0.0420)
2022-11-02 23:50:20,180:INFO: Batch:  5/31	Total Loss 0.0441 (0.0424)
2022-11-02 23:50:20,440:INFO: Batch:  6/31	Total Loss 0.0428 (0.0425)
2022-11-02 23:50:20,694:INFO: Batch:  7/31	Total Loss 0.0488 (0.0432)
2022-11-02 23:50:20,948:INFO: Batch:  8/31	Total Loss 0.0422 (0.0431)
2022-11-02 23:50:21,203:INFO: Batch:  9/31	Total Loss 0.0396 (0.0427)
2022-11-02 23:50:21,459:INFO: Batch: 10/31	Total Loss 0.0378 (0.0423)
2022-11-02 23:50:21,713:INFO: Batch: 11/31	Total Loss 0.0467 (0.0427)
2022-11-02 23:50:21,971:INFO: Batch: 12/31	Total Loss 0.0447 (0.0428)
2022-11-02 23:50:22,229:INFO: Batch: 13/31	Total Loss 0.0343 (0.0422)
2022-11-02 23:50:22,487:INFO: Batch: 14/31	Total Loss 0.0389 (0.0419)
2022-11-02 23:50:22,744:INFO: Batch: 15/31	Total Loss 0.0406 (0.0418)
2022-11-02 23:50:23,001:INFO: Batch: 16/31	Total Loss 0.0452 (0.0420)
2022-11-02 23:50:23,260:INFO: Batch: 17/31	Total Loss 0.0574 (0.0428)
2022-11-02 23:50:23,522:INFO: Batch: 18/31	Total Loss 0.0359 (0.0424)
2022-11-02 23:50:23,789:INFO: Batch: 19/31	Total Loss 0.0411 (0.0424)
2022-11-02 23:50:24,045:INFO: Batch: 20/31	Total Loss 0.0526 (0.0428)
2022-11-02 23:50:24,303:INFO: Batch: 21/31	Total Loss 0.0645 (0.0439)
2022-11-02 23:50:24,559:INFO: Batch: 22/31	Total Loss 0.0421 (0.0438)
2022-11-02 23:50:24,816:INFO: Batch: 23/31	Total Loss 0.0422 (0.0437)
2022-11-02 23:50:25,073:INFO: Batch: 24/31	Total Loss 0.0421 (0.0436)
2022-11-02 23:50:25,331:INFO: Batch: 25/31	Total Loss 0.0413 (0.0435)
2022-11-02 23:50:25,588:INFO: Batch: 26/31	Total Loss 0.0570 (0.0439)
2022-11-02 23:50:25,845:INFO: Batch: 27/31	Total Loss 0.0372 (0.0437)
2022-11-02 23:50:26,102:INFO: Batch: 28/31	Total Loss 0.0406 (0.0436)
2022-11-02 23:50:26,360:INFO: Batch: 29/31	Total Loss 0.0408 (0.0435)
2022-11-02 23:50:26,477:INFO: Batch: 30/31	Total Loss 0.0154 (0.0433)
2022-11-02 23:50:26,639:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_243.pth.tar
2022-11-02 23:50:26,639:INFO: 
===> EPOCH: 244 (P2)
2022-11-02 23:50:26,640:INFO: - Computing loss (training)
2022-11-02 23:50:27,500:INFO: Batch:  0/31	Total Loss 0.0383 (0.0383)
2022-11-02 23:50:27,757:INFO: Batch:  1/31	Total Loss 0.0382 (0.0383)
2022-11-02 23:50:28,018:INFO: Batch:  2/31	Total Loss 0.0349 (0.0371)
2022-11-02 23:50:28,278:INFO: Batch:  3/31	Total Loss 0.0525 (0.0409)
2022-11-02 23:50:28,538:INFO: Batch:  4/31	Total Loss 0.0417 (0.0411)
2022-11-02 23:50:28,799:INFO: Batch:  5/31	Total Loss 0.0365 (0.0402)
2022-11-02 23:50:29,057:INFO: Batch:  6/31	Total Loss 0.0452 (0.0408)
2022-11-02 23:50:29,318:INFO: Batch:  7/31	Total Loss 0.0401 (0.0408)
2022-11-02 23:50:29,577:INFO: Batch:  8/31	Total Loss 0.0492 (0.0417)
2022-11-02 23:50:29,837:INFO: Batch:  9/31	Total Loss 0.0385 (0.0414)
2022-11-02 23:50:30,097:INFO: Batch: 10/31	Total Loss 0.0372 (0.0410)
2022-11-02 23:50:30,357:INFO: Batch: 11/31	Total Loss 0.0437 (0.0412)
2022-11-02 23:50:30,620:INFO: Batch: 12/31	Total Loss 0.0386 (0.0410)
2022-11-02 23:50:30,883:INFO: Batch: 13/31	Total Loss 0.0369 (0.0406)
2022-11-02 23:50:31,145:INFO: Batch: 14/31	Total Loss 0.0495 (0.0412)
2022-11-02 23:50:31,409:INFO: Batch: 15/31	Total Loss 0.0388 (0.0410)
2022-11-02 23:50:31,672:INFO: Batch: 16/31	Total Loss 0.0379 (0.0408)
2022-11-02 23:50:31,933:INFO: Batch: 17/31	Total Loss 0.0450 (0.0411)
2022-11-02 23:50:32,198:INFO: Batch: 18/31	Total Loss 0.0392 (0.0410)
2022-11-02 23:50:32,460:INFO: Batch: 19/31	Total Loss 0.0321 (0.0405)
2022-11-02 23:50:32,724:INFO: Batch: 20/31	Total Loss 0.0381 (0.0404)
2022-11-02 23:50:32,985:INFO: Batch: 21/31	Total Loss 0.0425 (0.0405)
2022-11-02 23:50:33,246:INFO: Batch: 22/31	Total Loss 0.0450 (0.0406)
2022-11-02 23:50:33,507:INFO: Batch: 23/31	Total Loss 0.0488 (0.0410)
2022-11-02 23:50:33,770:INFO: Batch: 24/31	Total Loss 0.0379 (0.0409)
2022-11-02 23:50:34,031:INFO: Batch: 25/31	Total Loss 0.0606 (0.0417)
2022-11-02 23:50:34,292:INFO: Batch: 26/31	Total Loss 0.0407 (0.0416)
2022-11-02 23:50:34,553:INFO: Batch: 27/31	Total Loss 0.0354 (0.0414)
2022-11-02 23:50:34,815:INFO: Batch: 28/31	Total Loss 0.0490 (0.0417)
2022-11-02 23:50:35,075:INFO: Batch: 29/31	Total Loss 0.0362 (0.0415)
2022-11-02 23:50:35,193:INFO: Batch: 30/31	Total Loss 0.0144 (0.0412)
2022-11-02 23:50:35,353:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_244.pth.tar
2022-11-02 23:50:35,353:INFO: 
===> EPOCH: 245 (P2)
2022-11-02 23:50:35,354:INFO: - Computing loss (training)
2022-11-02 23:50:36,229:INFO: Batch:  0/31	Total Loss 0.0392 (0.0392)
2022-11-02 23:50:36,488:INFO: Batch:  1/31	Total Loss 0.0413 (0.0402)
2022-11-02 23:50:36,747:INFO: Batch:  2/31	Total Loss 0.0406 (0.0403)
2022-11-02 23:50:37,002:INFO: Batch:  3/31	Total Loss 0.0419 (0.0407)
2022-11-02 23:50:37,260:INFO: Batch:  4/31	Total Loss 0.0387 (0.0403)
2022-11-02 23:50:37,518:INFO: Batch:  5/31	Total Loss 0.0343 (0.0394)
2022-11-02 23:50:37,774:INFO: Batch:  6/31	Total Loss 0.0398 (0.0395)
2022-11-02 23:50:38,029:INFO: Batch:  7/31	Total Loss 0.0345 (0.0388)
2022-11-02 23:50:38,285:INFO: Batch:  8/31	Total Loss 0.0374 (0.0387)
2022-11-02 23:50:38,541:INFO: Batch:  9/31	Total Loss 0.0390 (0.0387)
2022-11-02 23:50:38,799:INFO: Batch: 10/31	Total Loss 0.0357 (0.0384)
2022-11-02 23:50:39,053:INFO: Batch: 11/31	Total Loss 0.0427 (0.0388)
2022-11-02 23:50:39,310:INFO: Batch: 12/31	Total Loss 0.0426 (0.0390)
2022-11-02 23:50:39,569:INFO: Batch: 13/31	Total Loss 0.0381 (0.0389)
2022-11-02 23:50:39,828:INFO: Batch: 14/31	Total Loss 0.0407 (0.0391)
2022-11-02 23:50:40,084:INFO: Batch: 15/31	Total Loss 0.0480 (0.0396)
2022-11-02 23:50:40,341:INFO: Batch: 16/31	Total Loss 0.0397 (0.0396)
2022-11-02 23:50:40,598:INFO: Batch: 17/31	Total Loss 0.0397 (0.0396)
2022-11-02 23:50:40,856:INFO: Batch: 18/31	Total Loss 0.0318 (0.0392)
2022-11-02 23:50:41,113:INFO: Batch: 19/31	Total Loss 0.0372 (0.0391)
2022-11-02 23:50:41,370:INFO: Batch: 20/31	Total Loss 0.0448 (0.0394)
2022-11-02 23:50:41,627:INFO: Batch: 21/31	Total Loss 0.0442 (0.0396)
2022-11-02 23:50:41,885:INFO: Batch: 22/31	Total Loss 0.0384 (0.0395)
2022-11-02 23:50:42,142:INFO: Batch: 23/31	Total Loss 0.0298 (0.0392)
2022-11-02 23:50:42,400:INFO: Batch: 24/31	Total Loss 0.0379 (0.0391)
2022-11-02 23:50:42,658:INFO: Batch: 25/31	Total Loss 0.0371 (0.0390)
2022-11-02 23:50:42,915:INFO: Batch: 26/31	Total Loss 0.0393 (0.0390)
2022-11-02 23:50:43,173:INFO: Batch: 27/31	Total Loss 0.0375 (0.0390)
2022-11-02 23:50:43,430:INFO: Batch: 28/31	Total Loss 0.0484 (0.0394)
2022-11-02 23:50:43,688:INFO: Batch: 29/31	Total Loss 0.0342 (0.0392)
2022-11-02 23:50:43,805:INFO: Batch: 30/31	Total Loss 0.0175 (0.0390)
2022-11-02 23:50:43,962:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_245.pth.tar
2022-11-02 23:50:43,963:INFO: 
===> EPOCH: 246 (P2)
2022-11-02 23:50:43,963:INFO: - Computing loss (training)
2022-11-02 23:50:44,815:INFO: Batch:  0/31	Total Loss 0.0349 (0.0349)
2022-11-02 23:50:45,078:INFO: Batch:  1/31	Total Loss 0.0448 (0.0396)
2022-11-02 23:50:45,340:INFO: Batch:  2/31	Total Loss 0.0388 (0.0393)
2022-11-02 23:50:45,596:INFO: Batch:  3/31	Total Loss 0.0392 (0.0393)
2022-11-02 23:50:45,855:INFO: Batch:  4/31	Total Loss 0.0379 (0.0390)
2022-11-02 23:50:46,117:INFO: Batch:  5/31	Total Loss 0.0414 (0.0394)
2022-11-02 23:50:46,377:INFO: Batch:  6/31	Total Loss 0.0362 (0.0390)
2022-11-02 23:50:46,633:INFO: Batch:  7/31	Total Loss 0.0404 (0.0392)
2022-11-02 23:50:46,889:INFO: Batch:  8/31	Total Loss 0.0368 (0.0389)
2022-11-02 23:50:47,146:INFO: Batch:  9/31	Total Loss 0.0337 (0.0383)
2022-11-02 23:50:47,404:INFO: Batch: 10/31	Total Loss 0.0419 (0.0387)
2022-11-02 23:50:47,663:INFO: Batch: 11/31	Total Loss 0.0406 (0.0388)
2022-11-02 23:50:47,924:INFO: Batch: 12/31	Total Loss 0.0331 (0.0384)
2022-11-02 23:50:48,187:INFO: Batch: 13/31	Total Loss 0.0364 (0.0383)
2022-11-02 23:50:48,444:INFO: Batch: 14/31	Total Loss 0.0275 (0.0376)
2022-11-02 23:50:48,701:INFO: Batch: 15/31	Total Loss 0.0440 (0.0380)
2022-11-02 23:50:48,959:INFO: Batch: 16/31	Total Loss 0.0367 (0.0379)
2022-11-02 23:50:49,218:INFO: Batch: 17/31	Total Loss 0.0380 (0.0379)
2022-11-02 23:50:49,474:INFO: Batch: 18/31	Total Loss 0.0486 (0.0385)
2022-11-02 23:50:49,735:INFO: Batch: 19/31	Total Loss 0.0401 (0.0386)
2022-11-02 23:50:50,002:INFO: Batch: 20/31	Total Loss 0.0351 (0.0384)
2022-11-02 23:50:50,262:INFO: Batch: 21/31	Total Loss 0.0402 (0.0385)
2022-11-02 23:50:50,522:INFO: Batch: 22/31	Total Loss 0.0362 (0.0384)
2022-11-02 23:50:50,780:INFO: Batch: 23/31	Total Loss 0.0382 (0.0384)
2022-11-02 23:50:51,117:INFO: Batch: 24/31	Total Loss 0.0422 (0.0385)
2022-11-02 23:50:51,375:INFO: Batch: 25/31	Total Loss 0.0386 (0.0385)
2022-11-02 23:50:51,632:INFO: Batch: 26/31	Total Loss 0.0368 (0.0385)
2022-11-02 23:50:51,888:INFO: Batch: 27/31	Total Loss 0.0419 (0.0386)
2022-11-02 23:50:52,153:INFO: Batch: 28/31	Total Loss 0.0359 (0.0385)
2022-11-02 23:50:52,427:INFO: Batch: 29/31	Total Loss 0.0334 (0.0383)
2022-11-02 23:50:52,552:INFO: Batch: 30/31	Total Loss 0.0135 (0.0381)
2022-11-02 23:50:52,718:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_246.pth.tar
2022-11-02 23:50:52,718:INFO: 
===> EPOCH: 247 (P2)
2022-11-02 23:50:52,718:INFO: - Computing loss (training)
2022-11-02 23:50:53,627:INFO: Batch:  0/31	Total Loss 0.0394 (0.0394)
2022-11-02 23:50:53,893:INFO: Batch:  1/31	Total Loss 0.0369 (0.0382)
2022-11-02 23:50:54,167:INFO: Batch:  2/31	Total Loss 0.0387 (0.0384)
2022-11-02 23:50:54,442:INFO: Batch:  3/31	Total Loss 0.0338 (0.0372)
2022-11-02 23:50:54,718:INFO: Batch:  4/31	Total Loss 0.0430 (0.0383)
2022-11-02 23:50:55,039:INFO: Batch:  5/31	Total Loss 0.0361 (0.0379)
2022-11-02 23:50:55,469:INFO: Batch:  6/31	Total Loss 0.0404 (0.0383)
2022-11-02 23:50:55,763:INFO: Batch:  7/31	Total Loss 0.0352 (0.0378)
2022-11-02 23:50:56,031:INFO: Batch:  8/31	Total Loss 0.0395 (0.0380)
2022-11-02 23:50:56,300:INFO: Batch:  9/31	Total Loss 0.0413 (0.0383)
2022-11-02 23:50:56,616:INFO: Batch: 10/31	Total Loss 0.0360 (0.0381)
2022-11-02 23:50:56,926:INFO: Batch: 11/31	Total Loss 0.0403 (0.0383)
2022-11-02 23:50:57,242:INFO: Batch: 12/31	Total Loss 0.0372 (0.0382)
2022-11-02 23:50:57,514:INFO: Batch: 13/31	Total Loss 0.0363 (0.0381)
2022-11-02 23:50:57,782:INFO: Batch: 14/31	Total Loss 0.0345 (0.0378)
2022-11-02 23:50:58,068:INFO: Batch: 15/31	Total Loss 0.0351 (0.0376)
2022-11-02 23:50:58,362:INFO: Batch: 16/31	Total Loss 0.0314 (0.0373)
2022-11-02 23:50:58,646:INFO: Batch: 17/31	Total Loss 0.0389 (0.0374)
2022-11-02 23:50:58,947:INFO: Batch: 18/31	Total Loss 0.0330 (0.0371)
2022-11-02 23:50:59,281:INFO: Batch: 19/31	Total Loss 0.0338 (0.0370)
2022-11-02 23:50:59,740:INFO: Batch: 20/31	Total Loss 0.0363 (0.0369)
2022-11-02 23:51:00,023:INFO: Batch: 21/31	Total Loss 0.0495 (0.0375)
2022-11-02 23:51:00,287:INFO: Batch: 22/31	Total Loss 0.0332 (0.0373)
2022-11-02 23:51:00,546:INFO: Batch: 23/31	Total Loss 0.0355 (0.0372)
2022-11-02 23:51:00,813:INFO: Batch: 24/31	Total Loss 0.0394 (0.0373)
2022-11-02 23:51:01,078:INFO: Batch: 25/31	Total Loss 0.0361 (0.0372)
2022-11-02 23:51:01,341:INFO: Batch: 26/31	Total Loss 0.0352 (0.0372)
2022-11-02 23:51:01,601:INFO: Batch: 27/31	Total Loss 0.0389 (0.0372)
2022-11-02 23:51:01,861:INFO: Batch: 28/31	Total Loss 0.0400 (0.0373)
2022-11-02 23:51:02,127:INFO: Batch: 29/31	Total Loss 0.0332 (0.0372)
2022-11-02 23:51:02,247:INFO: Batch: 30/31	Total Loss 0.0126 (0.0370)
2022-11-02 23:51:02,403:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_247.pth.tar
2022-11-02 23:51:02,403:INFO: 
===> EPOCH: 248 (P2)
2022-11-02 23:51:02,404:INFO: - Computing loss (training)
2022-11-02 23:51:03,260:INFO: Batch:  0/31	Total Loss 0.0376 (0.0376)
2022-11-02 23:51:03,524:INFO: Batch:  1/31	Total Loss 0.0391 (0.0383)
2022-11-02 23:51:03,788:INFO: Batch:  2/31	Total Loss 0.0349 (0.0371)
2022-11-02 23:51:04,061:INFO: Batch:  3/31	Total Loss 0.0343 (0.0365)
2022-11-02 23:51:04,329:INFO: Batch:  4/31	Total Loss 0.0443 (0.0382)
2022-11-02 23:51:04,593:INFO: Batch:  5/31	Total Loss 0.0378 (0.0381)
2022-11-02 23:51:04,855:INFO: Batch:  6/31	Total Loss 0.0340 (0.0375)
2022-11-02 23:51:05,116:INFO: Batch:  7/31	Total Loss 0.0392 (0.0377)
2022-11-02 23:51:05,369:INFO: Batch:  8/31	Total Loss 0.0423 (0.0382)
2022-11-02 23:51:05,631:INFO: Batch:  9/31	Total Loss 0.0381 (0.0382)
2022-11-02 23:51:05,893:INFO: Batch: 10/31	Total Loss 0.0360 (0.0380)
2022-11-02 23:51:06,152:INFO: Batch: 11/31	Total Loss 0.0467 (0.0387)
2022-11-02 23:51:06,426:INFO: Batch: 12/31	Total Loss 0.0416 (0.0389)
2022-11-02 23:51:06,700:INFO: Batch: 13/31	Total Loss 0.0377 (0.0389)
2022-11-02 23:51:06,968:INFO: Batch: 14/31	Total Loss 0.0358 (0.0387)
2022-11-02 23:51:07,236:INFO: Batch: 15/31	Total Loss 0.0378 (0.0386)
2022-11-02 23:51:07,505:INFO: Batch: 16/31	Total Loss 0.0372 (0.0385)
2022-11-02 23:51:07,774:INFO: Batch: 17/31	Total Loss 0.0326 (0.0382)
2022-11-02 23:51:08,036:INFO: Batch: 18/31	Total Loss 0.0324 (0.0379)
2022-11-02 23:51:08,302:INFO: Batch: 19/31	Total Loss 0.0341 (0.0377)
2022-11-02 23:51:08,564:INFO: Batch: 20/31	Total Loss 0.0297 (0.0373)
2022-11-02 23:51:08,827:INFO: Batch: 21/31	Total Loss 0.0528 (0.0379)
2022-11-02 23:51:09,086:INFO: Batch: 22/31	Total Loss 0.0485 (0.0384)
2022-11-02 23:51:09,346:INFO: Batch: 23/31	Total Loss 0.0362 (0.0383)
2022-11-02 23:51:09,609:INFO: Batch: 24/31	Total Loss 0.0316 (0.0380)
2022-11-02 23:51:09,869:INFO: Batch: 25/31	Total Loss 0.0410 (0.0381)
2022-11-02 23:51:10,129:INFO: Batch: 26/31	Total Loss 0.0582 (0.0388)
2022-11-02 23:51:10,389:INFO: Batch: 27/31	Total Loss 0.0406 (0.0389)
2022-11-02 23:51:10,649:INFO: Batch: 28/31	Total Loss 0.0348 (0.0387)
2022-11-02 23:51:10,909:INFO: Batch: 29/31	Total Loss 0.0350 (0.0386)
2022-11-02 23:51:11,027:INFO: Batch: 30/31	Total Loss 0.0121 (0.0383)
2022-11-02 23:51:11,196:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_248.pth.tar
2022-11-02 23:51:11,196:INFO: 
===> EPOCH: 249 (P2)
2022-11-02 23:51:11,197:INFO: - Computing loss (training)
2022-11-02 23:51:12,067:INFO: Batch:  0/31	Total Loss 0.0467 (0.0467)
2022-11-02 23:51:12,325:INFO: Batch:  1/31	Total Loss 0.0489 (0.0477)
2022-11-02 23:51:12,582:INFO: Batch:  2/31	Total Loss 0.0396 (0.0449)
2022-11-02 23:51:12,843:INFO: Batch:  3/31	Total Loss 0.0317 (0.0415)
2022-11-02 23:51:13,096:INFO: Batch:  4/31	Total Loss 0.0527 (0.0437)
2022-11-02 23:51:13,356:INFO: Batch:  5/31	Total Loss 0.0419 (0.0434)
2022-11-02 23:51:13,614:INFO: Batch:  6/31	Total Loss 0.0545 (0.0450)
2022-11-02 23:51:13,871:INFO: Batch:  7/31	Total Loss 0.0432 (0.0448)
2022-11-02 23:51:14,128:INFO: Batch:  8/31	Total Loss 0.0363 (0.0437)
2022-11-02 23:51:14,383:INFO: Batch:  9/31	Total Loss 0.0333 (0.0426)
2022-11-02 23:51:14,640:INFO: Batch: 10/31	Total Loss 0.0534 (0.0435)
2022-11-02 23:51:14,900:INFO: Batch: 11/31	Total Loss 0.0389 (0.0431)
2022-11-02 23:51:15,160:INFO: Batch: 12/31	Total Loss 0.0419 (0.0430)
2022-11-02 23:51:15,420:INFO: Batch: 13/31	Total Loss 0.0309 (0.0421)
2022-11-02 23:51:15,681:INFO: Batch: 14/31	Total Loss 0.0410 (0.0421)
2022-11-02 23:51:15,941:INFO: Batch: 15/31	Total Loss 0.0331 (0.0415)
2022-11-02 23:51:16,201:INFO: Batch: 16/31	Total Loss 0.0336 (0.0411)
2022-11-02 23:51:16,462:INFO: Batch: 17/31	Total Loss 0.0404 (0.0410)
2022-11-02 23:51:16,721:INFO: Batch: 18/31	Total Loss 0.0347 (0.0407)
2022-11-02 23:51:16,982:INFO: Batch: 19/31	Total Loss 0.0351 (0.0404)
2022-11-02 23:51:17,242:INFO: Batch: 20/31	Total Loss 0.0343 (0.0401)
2022-11-02 23:51:17,502:INFO: Batch: 21/31	Total Loss 0.0390 (0.0400)
2022-11-02 23:51:17,761:INFO: Batch: 22/31	Total Loss 0.0510 (0.0405)
2022-11-02 23:51:18,020:INFO: Batch: 23/31	Total Loss 0.0328 (0.0401)
2022-11-02 23:51:18,280:INFO: Batch: 24/31	Total Loss 0.0350 (0.0399)
2022-11-02 23:51:18,538:INFO: Batch: 25/31	Total Loss 0.0418 (0.0400)
2022-11-02 23:51:18,800:INFO: Batch: 26/31	Total Loss 0.0352 (0.0398)
2022-11-02 23:51:19,059:INFO: Batch: 27/31	Total Loss 0.0366 (0.0397)
2022-11-02 23:51:19,316:INFO: Batch: 28/31	Total Loss 0.0301 (0.0394)
2022-11-02 23:51:19,577:INFO: Batch: 29/31	Total Loss 0.0344 (0.0393)
2022-11-02 23:51:19,697:INFO: Batch: 30/31	Total Loss 0.0155 (0.0391)
2022-11-02 23:51:19,865:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_249.pth.tar
2022-11-02 23:51:19,865:INFO: 
===> EPOCH: 250 (P2)
2022-11-02 23:51:19,866:INFO: - Computing loss (training)
2022-11-02 23:51:20,749:INFO: Batch:  0/31	Total Loss 0.0358 (0.0358)
2022-11-02 23:51:21,010:INFO: Batch:  1/31	Total Loss 0.0360 (0.0359)
2022-11-02 23:51:21,270:INFO: Batch:  2/31	Total Loss 0.0346 (0.0355)
2022-11-02 23:51:21,529:INFO: Batch:  3/31	Total Loss 0.0373 (0.0359)
2022-11-02 23:51:21,783:INFO: Batch:  4/31	Total Loss 0.0345 (0.0356)
2022-11-02 23:51:22,041:INFO: Batch:  5/31	Total Loss 0.0263 (0.0341)
2022-11-02 23:51:22,297:INFO: Batch:  6/31	Total Loss 0.0361 (0.0344)
2022-11-02 23:51:22,552:INFO: Batch:  7/31	Total Loss 0.0303 (0.0339)
2022-11-02 23:51:22,807:INFO: Batch:  8/31	Total Loss 0.0369 (0.0342)
2022-11-02 23:51:23,063:INFO: Batch:  9/31	Total Loss 0.0412 (0.0350)
2022-11-02 23:51:23,320:INFO: Batch: 10/31	Total Loss 0.0288 (0.0344)
2022-11-02 23:51:23,577:INFO: Batch: 11/31	Total Loss 0.0373 (0.0347)
2022-11-02 23:51:23,837:INFO: Batch: 12/31	Total Loss 0.0390 (0.0350)
2022-11-02 23:51:24,098:INFO: Batch: 13/31	Total Loss 0.0481 (0.0359)
2022-11-02 23:51:24,360:INFO: Batch: 14/31	Total Loss 0.0469 (0.0366)
2022-11-02 23:51:24,621:INFO: Batch: 15/31	Total Loss 0.0391 (0.0368)
2022-11-02 23:51:24,881:INFO: Batch: 16/31	Total Loss 0.0341 (0.0366)
2022-11-02 23:51:25,141:INFO: Batch: 17/31	Total Loss 0.0416 (0.0369)
2022-11-02 23:51:25,402:INFO: Batch: 18/31	Total Loss 0.0374 (0.0369)
2022-11-02 23:51:25,662:INFO: Batch: 19/31	Total Loss 0.0425 (0.0372)
2022-11-02 23:51:25,922:INFO: Batch: 20/31	Total Loss 0.0348 (0.0371)
2022-11-02 23:51:26,182:INFO: Batch: 21/31	Total Loss 0.0334 (0.0369)
2022-11-02 23:51:26,441:INFO: Batch: 22/31	Total Loss 0.0308 (0.0367)
2022-11-02 23:51:26,701:INFO: Batch: 23/31	Total Loss 0.0311 (0.0364)
2022-11-02 23:51:26,961:INFO: Batch: 24/31	Total Loss 0.0393 (0.0366)
2022-11-02 23:51:27,220:INFO: Batch: 25/31	Total Loss 0.0326 (0.0364)
2022-11-02 23:51:27,478:INFO: Batch: 26/31	Total Loss 0.0326 (0.0363)
2022-11-02 23:51:27,738:INFO: Batch: 27/31	Total Loss 0.0419 (0.0365)
2022-11-02 23:51:27,996:INFO: Batch: 28/31	Total Loss 0.0374 (0.0365)
2022-11-02 23:51:28,255:INFO: Batch: 29/31	Total Loss 0.0327 (0.0364)
2022-11-02 23:51:28,372:INFO: Batch: 30/31	Total Loss 0.0125 (0.0362)
2022-11-02 23:51:28,514:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P2/CRMF_epoch_250.pth.tar
2022-11-02 23:51:28,514:INFO: 
===> EPOCH: 251 (P3)
2022-11-02 23:51:28,514:INFO: - Computing loss (training)
2022-11-02 23:51:29,594:INFO: Batch:  0/31	Total Loss 21.8320 (21.8320)
2022-11-02 23:51:30,068:INFO: Batch:  1/31	Total Loss 23.8072 (22.7526)
2022-11-02 23:51:30,535:INFO: Batch:  2/31	Total Loss 21.4043 (22.2635)
2022-11-02 23:51:31,001:INFO: Batch:  3/31	Total Loss 21.2016 (22.0092)
2022-11-02 23:51:31,467:INFO: Batch:  4/31	Total Loss 20.3220 (21.6516)
2022-11-02 23:51:31,931:INFO: Batch:  5/31	Total Loss 21.1830 (21.5689)
2022-11-02 23:51:32,395:INFO: Batch:  6/31	Total Loss 18.4151 (21.1255)
2022-11-02 23:51:32,858:INFO: Batch:  7/31	Total Loss 20.9421 (21.1033)
2022-11-02 23:51:33,323:INFO: Batch:  8/31	Total Loss 19.1628 (20.8622)
2022-11-02 23:51:33,786:INFO: Batch:  9/31	Total Loss 20.8536 (20.8613)
2022-11-02 23:51:34,253:INFO: Batch: 10/31	Total Loss 18.2246 (20.6251)
2022-11-02 23:51:34,718:INFO: Batch: 11/31	Total Loss 19.7803 (20.5518)
2022-11-02 23:51:35,185:INFO: Batch: 12/31	Total Loss 19.5287 (20.4731)
2022-11-02 23:51:35,653:INFO: Batch: 13/31	Total Loss 20.0928 (20.4452)
2022-11-02 23:51:36,121:INFO: Batch: 14/31	Total Loss 21.3417 (20.4992)
2022-11-02 23:51:36,664:INFO: Batch: 15/31	Total Loss 19.9712 (20.4683)
2022-11-02 23:51:37,141:INFO: Batch: 16/31	Total Loss 19.5894 (20.4192)
2022-11-02 23:51:37,633:INFO: Batch: 17/31	Total Loss 17.9492 (20.2776)
2022-11-02 23:51:38,105:INFO: Batch: 18/31	Total Loss 19.8798 (20.2569)
2022-11-02 23:51:38,586:INFO: Batch: 19/31	Total Loss 16.4483 (20.0394)
2022-11-02 23:51:39,056:INFO: Batch: 20/31	Total Loss 17.1277 (19.8846)
2022-11-02 23:51:39,532:INFO: Batch: 21/31	Total Loss 21.2757 (19.9457)
2022-11-02 23:51:40,008:INFO: Batch: 22/31	Total Loss 20.9701 (19.9907)
2022-11-02 23:51:40,482:INFO: Batch: 23/31	Total Loss 20.3433 (20.0061)
2022-11-02 23:51:40,957:INFO: Batch: 24/31	Total Loss 18.1446 (19.9317)
2022-11-02 23:51:41,432:INFO: Batch: 25/31	Total Loss 18.6644 (19.8808)
2022-11-02 23:51:41,913:INFO: Batch: 26/31	Total Loss 19.2193 (19.8536)
2022-11-02 23:51:42,408:INFO: Batch: 27/31	Total Loss 19.8639 (19.8540)
2022-11-02 23:51:42,883:INFO: Batch: 28/31	Total Loss 19.4630 (19.8391)
2022-11-02 23:51:43,350:INFO: Batch: 29/31	Total Loss 19.5941 (19.8309)
2022-11-02 23:51:43,754:INFO: Batch: 30/31	Total Loss 8.0590 (19.7141)
2022-11-02 23:51:43,921:INFO: - Computing ADE (validation o)
2022-11-02 23:51:44,611:INFO: 		 ADE on eth                       dataset:	 2.8480587005615234
2022-11-02 23:51:44,611:INFO: Average validation o:	ADE  2.8481	FDE  4.8321
2022-11-02 23:51:44,612:INFO: - Computing ADE (validation)
2022-11-02 23:51:44,907:INFO: 		 ADE on hotel                     dataset:	 0.900741696357727
2022-11-02 23:51:45,199:INFO: 		 ADE on univ                      dataset:	 1.4935541152954102
2022-11-02 23:51:45,499:INFO: 		 ADE on zara1                     dataset:	 2.5225932598114014
2022-11-02 23:51:45,918:INFO: 		 ADE on zara2                     dataset:	 1.3922549486160278
2022-11-02 23:51:45,918:INFO: Average validation:	ADE  1.4838	FDE  2.7055
2022-11-02 23:51:45,919:INFO: - Computing ADE (training)
2022-11-02 23:51:46,403:INFO: 		 ADE on hotel                     dataset:	 1.2684887647628784
2022-11-02 23:51:47,124:INFO: 		 ADE on univ                      dataset:	 1.375004768371582
2022-11-02 23:51:47,675:INFO: 		 ADE on zara1                     dataset:	 2.4718363285064697
2022-11-02 23:51:48,469:INFO: 		 ADE on zara2                     dataset:	 1.67184317111969
2022-11-02 23:51:48,469:INFO: Average training:	ADE  1.5024	FDE  2.7440
2022-11-02 23:51:48,478:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_251.pth.tar
2022-11-02 23:51:48,478:INFO: 
===> EPOCH: 252 (P3)
2022-11-02 23:51:48,479:INFO: - Computing loss (training)
2022-11-02 23:51:49,840:INFO: Batch:  0/31	Total Loss 18.5341 (18.5341)
2022-11-02 23:51:50,350:INFO: Batch:  1/31	Total Loss 19.2761 (18.9262)
2022-11-02 23:51:50,881:INFO: Batch:  2/31	Total Loss 18.2883 (18.7305)
2022-11-02 23:51:51,383:INFO: Batch:  3/31	Total Loss 20.6350 (19.1791)
2022-11-02 23:51:51,876:INFO: Batch:  4/31	Total Loss 20.2406 (19.3772)
2022-11-02 23:51:52,382:INFO: Batch:  5/31	Total Loss 19.9564 (19.4769)
2022-11-02 23:51:52,866:INFO: Batch:  6/31	Total Loss 18.3186 (19.3307)
2022-11-02 23:51:53,354:INFO: Batch:  7/31	Total Loss 19.3985 (19.3403)
2022-11-02 23:51:53,835:INFO: Batch:  8/31	Total Loss 20.0814 (19.4210)
2022-11-02 23:51:54,308:INFO: Batch:  9/31	Total Loss 18.9879 (19.3782)
2022-11-02 23:51:54,780:INFO: Batch: 10/31	Total Loss 17.6270 (19.2231)
2022-11-02 23:51:55,251:INFO: Batch: 11/31	Total Loss 19.1628 (19.2176)
2022-11-02 23:51:55,726:INFO: Batch: 12/31	Total Loss 18.7295 (19.1747)
2022-11-02 23:51:56,201:INFO: Batch: 13/31	Total Loss 19.8166 (19.2256)
2022-11-02 23:51:56,678:INFO: Batch: 14/31	Total Loss 20.2966 (19.2949)
2022-11-02 23:51:57,160:INFO: Batch: 15/31	Total Loss 19.7656 (19.3239)
2022-11-02 23:51:57,643:INFO: Batch: 16/31	Total Loss 18.9175 (19.2996)
2022-11-02 23:51:58,122:INFO: Batch: 17/31	Total Loss 18.3291 (19.2457)
2022-11-02 23:51:58,600:INFO: Batch: 18/31	Total Loss 19.5945 (19.2632)
2022-11-02 23:51:59,078:INFO: Batch: 19/31	Total Loss 18.0833 (19.2032)
2022-11-02 23:51:59,558:INFO: Batch: 20/31	Total Loss 20.0987 (19.2402)
2022-11-02 23:52:00,037:INFO: Batch: 21/31	Total Loss 18.9831 (19.2296)
2022-11-02 23:52:00,515:INFO: Batch: 22/31	Total Loss 17.5380 (19.1514)
2022-11-02 23:52:01,005:INFO: Batch: 23/31	Total Loss 18.8342 (19.1378)
2022-11-02 23:52:01,486:INFO: Batch: 24/31	Total Loss 18.3953 (19.1066)
2022-11-02 23:52:01,965:INFO: Batch: 25/31	Total Loss 18.4572 (19.0832)
2022-11-02 23:52:02,444:INFO: Batch: 26/31	Total Loss 16.5857 (18.9772)
2022-11-02 23:52:02,925:INFO: Batch: 27/31	Total Loss 20.0287 (19.0152)
2022-11-02 23:52:03,403:INFO: Batch: 28/31	Total Loss 21.5116 (19.0948)
2022-11-02 23:52:03,881:INFO: Batch: 29/31	Total Loss 19.0952 (19.0948)
2022-11-02 23:52:04,274:INFO: Batch: 30/31	Total Loss 7.6812 (18.9900)
2022-11-02 23:52:04,423:INFO: - Computing ADE (validation o)
2022-11-02 23:52:05,027:INFO: 		 ADE on eth                       dataset:	 2.8238890171051025
2022-11-02 23:52:05,027:INFO: Average validation o:	ADE  2.8239	FDE  4.8049
2022-11-02 23:52:05,028:INFO: - Computing ADE (validation)
2022-11-02 23:52:05,318:INFO: 		 ADE on hotel                     dataset:	 0.89234459400177
2022-11-02 23:52:05,622:INFO: 		 ADE on univ                      dataset:	 1.4770615100860596
2022-11-02 23:52:05,871:INFO: 		 ADE on zara1                     dataset:	 2.505171298980713
2022-11-02 23:52:06,227:INFO: 		 ADE on zara2                     dataset:	 1.3802095651626587
2022-11-02 23:52:06,228:INFO: Average validation:	ADE  1.4693	FDE  2.6865
2022-11-02 23:52:06,228:INFO: - Computing ADE (training)
2022-11-02 23:52:06,696:INFO: 		 ADE on hotel                     dataset:	 1.2560895681381226
2022-11-02 23:52:07,372:INFO: 		 ADE on univ                      dataset:	 1.3638200759887695
2022-11-02 23:52:07,918:INFO: 		 ADE on zara1                     dataset:	 2.456289529800415
2022-11-02 23:52:08,670:INFO: 		 ADE on zara2                     dataset:	 1.6579703092575073
2022-11-02 23:52:08,670:INFO: Average training:	ADE  1.4904	FDE  2.7292
2022-11-02 23:52:08,679:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_252.pth.tar
2022-11-02 23:52:08,679:INFO: 
===> EPOCH: 253 (P3)
2022-11-02 23:52:08,679:INFO: - Computing loss (training)
2022-11-02 23:52:09,776:INFO: Batch:  0/31	Total Loss 17.6418 (17.6418)
2022-11-02 23:52:10,251:INFO: Batch:  1/31	Total Loss 18.3252 (17.9650)
2022-11-02 23:52:10,733:INFO: Batch:  2/31	Total Loss 18.9620 (18.2535)
2022-11-02 23:52:11,208:INFO: Batch:  3/31	Total Loss 19.1159 (18.4798)
2022-11-02 23:52:11,680:INFO: Batch:  4/31	Total Loss 19.8960 (18.7400)
2022-11-02 23:52:12,158:INFO: Batch:  5/31	Total Loss 19.8204 (18.9275)
2022-11-02 23:52:12,630:INFO: Batch:  6/31	Total Loss 18.2788 (18.8355)
2022-11-02 23:52:13,102:INFO: Batch:  7/31	Total Loss 20.8407 (19.0686)
2022-11-02 23:52:13,578:INFO: Batch:  8/31	Total Loss 19.8864 (19.1546)
2022-11-02 23:52:14,055:INFO: Batch:  9/31	Total Loss 18.9842 (19.1383)
2022-11-02 23:52:14,529:INFO: Batch: 10/31	Total Loss 20.3080 (19.2431)
2022-11-02 23:52:15,003:INFO: Batch: 11/31	Total Loss 19.2052 (19.2401)
2022-11-02 23:52:15,476:INFO: Batch: 12/31	Total Loss 17.5157 (19.1058)
2022-11-02 23:52:15,947:INFO: Batch: 13/31	Total Loss 19.7605 (19.1529)
2022-11-02 23:52:16,419:INFO: Batch: 14/31	Total Loss 18.9862 (19.1414)
2022-11-02 23:52:16,894:INFO: Batch: 15/31	Total Loss 17.6789 (19.0528)
2022-11-02 23:52:17,368:INFO: Batch: 16/31	Total Loss 19.7834 (19.0960)
2022-11-02 23:52:17,843:INFO: Batch: 17/31	Total Loss 16.0989 (18.9303)
2022-11-02 23:52:18,315:INFO: Batch: 18/31	Total Loss 19.1130 (18.9410)
2022-11-02 23:52:18,787:INFO: Batch: 19/31	Total Loss 18.4232 (18.9121)
2022-11-02 23:52:19,258:INFO: Batch: 20/31	Total Loss 20.8060 (18.9904)
2022-11-02 23:52:19,732:INFO: Batch: 21/31	Total Loss 18.5728 (18.9704)
2022-11-02 23:52:20,204:INFO: Batch: 22/31	Total Loss 20.5061 (19.0348)
2022-11-02 23:52:20,676:INFO: Batch: 23/31	Total Loss 18.4259 (19.0106)
2022-11-02 23:52:21,149:INFO: Batch: 24/31	Total Loss 20.9027 (19.0830)
2022-11-02 23:52:21,623:INFO: Batch: 25/31	Total Loss 18.3200 (19.0502)
2022-11-02 23:52:22,098:INFO: Batch: 26/31	Total Loss 18.4097 (19.0273)
2022-11-02 23:52:22,568:INFO: Batch: 27/31	Total Loss 20.9635 (19.0878)
2022-11-02 23:52:23,039:INFO: Batch: 28/31	Total Loss 16.1296 (18.9745)
2022-11-02 23:52:23,509:INFO: Batch: 29/31	Total Loss 18.3512 (18.9551)
2022-11-02 23:52:23,896:INFO: Batch: 30/31	Total Loss 7.3725 (18.8305)
2022-11-02 23:52:24,045:INFO: - Computing ADE (validation o)
2022-11-02 23:52:24,681:INFO: 		 ADE on eth                       dataset:	 2.7963247299194336
2022-11-02 23:52:24,681:INFO: Average validation o:	ADE  2.7963	FDE  4.7729
2022-11-02 23:52:24,682:INFO: - Computing ADE (validation)
2022-11-02 23:52:24,943:INFO: 		 ADE on hotel                     dataset:	 0.9034309983253479
2022-11-02 23:52:25,234:INFO: 		 ADE on univ                      dataset:	 1.4633982181549072
2022-11-02 23:52:25,499:INFO: 		 ADE on zara1                     dataset:	 2.4673969745635986
2022-11-02 23:52:25,859:INFO: 		 ADE on zara2                     dataset:	 1.3741374015808105
2022-11-02 23:52:25,859:INFO: Average validation:	ADE  1.4584	FDE  2.6718
2022-11-02 23:52:25,860:INFO: - Computing ADE (training)
2022-11-02 23:52:26,314:INFO: 		 ADE on hotel                     dataset:	 1.2598917484283447
2022-11-02 23:52:27,015:INFO: 		 ADE on univ                      dataset:	 1.3521519899368286
2022-11-02 23:52:27,565:INFO: 		 ADE on zara1                     dataset:	 2.427570343017578
2022-11-02 23:52:28,358:INFO: 		 ADE on zara2                     dataset:	 1.6492613554000854
2022-11-02 23:52:28,358:INFO: Average training:	ADE  1.4786	FDE  2.7143
2022-11-02 23:52:28,367:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_253.pth.tar
2022-11-02 23:52:28,367:INFO: 
===> EPOCH: 254 (P3)
2022-11-02 23:52:28,368:INFO: - Computing loss (training)
2022-11-02 23:52:29,458:INFO: Batch:  0/31	Total Loss 18.3256 (18.3256)
2022-11-02 23:52:30,011:INFO: Batch:  1/31	Total Loss 19.3046 (18.8339)
2022-11-02 23:52:30,487:INFO: Batch:  2/31	Total Loss 16.9680 (18.2299)
2022-11-02 23:52:30,959:INFO: Batch:  3/31	Total Loss 18.0961 (18.1947)
2022-11-02 23:52:31,429:INFO: Batch:  4/31	Total Loss 17.1846 (17.9844)
2022-11-02 23:52:31,901:INFO: Batch:  5/31	Total Loss 18.3777 (18.0469)
2022-11-02 23:52:32,371:INFO: Batch:  6/31	Total Loss 19.1466 (18.1966)
2022-11-02 23:52:32,845:INFO: Batch:  7/31	Total Loss 18.9023 (18.2846)
2022-11-02 23:52:33,321:INFO: Batch:  8/31	Total Loss 18.3980 (18.2978)
2022-11-02 23:52:33,794:INFO: Batch:  9/31	Total Loss 18.3693 (18.3049)
2022-11-02 23:52:34,270:INFO: Batch: 10/31	Total Loss 19.5319 (18.4090)
2022-11-02 23:52:34,743:INFO: Batch: 11/31	Total Loss 19.6476 (18.5109)
2022-11-02 23:52:35,220:INFO: Batch: 12/31	Total Loss 17.7342 (18.4517)
2022-11-02 23:52:35,698:INFO: Batch: 13/31	Total Loss 17.9578 (18.4143)
2022-11-02 23:52:36,173:INFO: Batch: 14/31	Total Loss 17.9994 (18.3869)
2022-11-02 23:52:36,646:INFO: Batch: 15/31	Total Loss 18.9382 (18.4207)
2022-11-02 23:52:37,122:INFO: Batch: 16/31	Total Loss 20.7468 (18.5544)
2022-11-02 23:52:37,593:INFO: Batch: 17/31	Total Loss 17.0377 (18.4667)
2022-11-02 23:52:38,065:INFO: Batch: 18/31	Total Loss 18.8805 (18.4888)
2022-11-02 23:52:38,537:INFO: Batch: 19/31	Total Loss 19.5083 (18.5376)
2022-11-02 23:52:39,010:INFO: Batch: 20/31	Total Loss 18.4328 (18.5327)
2022-11-02 23:52:39,484:INFO: Batch: 21/31	Total Loss 21.3330 (18.6536)
2022-11-02 23:52:39,961:INFO: Batch: 22/31	Total Loss 20.8735 (18.7350)
2022-11-02 23:52:40,435:INFO: Batch: 23/31	Total Loss 19.0394 (18.7480)
2022-11-02 23:52:40,907:INFO: Batch: 24/31	Total Loss 18.8490 (18.7520)
2022-11-02 23:52:41,381:INFO: Batch: 25/31	Total Loss 20.1068 (18.8025)
2022-11-02 23:52:41,855:INFO: Batch: 26/31	Total Loss 18.3430 (18.7870)
2022-11-02 23:52:42,331:INFO: Batch: 27/31	Total Loss 20.0829 (18.8331)
2022-11-02 23:52:42,805:INFO: Batch: 28/31	Total Loss 19.2986 (18.8495)
2022-11-02 23:52:43,278:INFO: Batch: 29/31	Total Loss 16.8912 (18.7829)
2022-11-02 23:52:43,667:INFO: Batch: 30/31	Total Loss 7.4627 (18.6623)
2022-11-02 23:52:43,819:INFO: - Computing ADE (validation o)
2022-11-02 23:52:44,419:INFO: 		 ADE on eth                       dataset:	 2.7511518001556396
2022-11-02 23:52:44,419:INFO: Average validation o:	ADE  2.7512	FDE  4.7255
2022-11-02 23:52:44,420:INFO: - Computing ADE (validation)
2022-11-02 23:52:44,699:INFO: 		 ADE on hotel                     dataset:	 0.9572844505310059
2022-11-02 23:52:44,995:INFO: 		 ADE on univ                      dataset:	 1.4459673166275024
2022-11-02 23:52:45,248:INFO: 		 ADE on zara1                     dataset:	 2.369554042816162
2022-11-02 23:52:45,582:INFO: 		 ADE on zara2                     dataset:	 1.3724548816680908
2022-11-02 23:52:45,582:INFO: Average validation:	ADE  1.4459	FDE  2.6521
2022-11-02 23:52:45,583:INFO: - Computing ADE (training)
2022-11-02 23:52:46,034:INFO: 		 ADE on hotel                     dataset:	 1.2946850061416626
2022-11-02 23:52:46,726:INFO: 		 ADE on univ                      dataset:	 1.3377939462661743
2022-11-02 23:52:47,276:INFO: 		 ADE on zara1                     dataset:	 2.3655736446380615
2022-11-02 23:52:48,046:INFO: 		 ADE on zara2                     dataset:	 1.6480165719985962
2022-11-02 23:52:48,046:INFO: Average training:	ADE  1.4652	FDE  2.6950
2022-11-02 23:52:48,055:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_254.pth.tar
2022-11-02 23:52:48,055:INFO: 
===> EPOCH: 255 (P3)
2022-11-02 23:52:48,055:INFO: - Computing loss (training)
2022-11-02 23:52:49,184:INFO: Batch:  0/31	Total Loss 19.4775 (19.4775)
2022-11-02 23:52:49,658:INFO: Batch:  1/31	Total Loss 18.1433 (18.8803)
2022-11-02 23:52:50,127:INFO: Batch:  2/31	Total Loss 18.2402 (18.6435)
2022-11-02 23:52:50,595:INFO: Batch:  3/31	Total Loss 18.4577 (18.5941)
2022-11-02 23:52:51,061:INFO: Batch:  4/31	Total Loss 19.9311 (18.8302)
2022-11-02 23:52:51,530:INFO: Batch:  5/31	Total Loss 22.1939 (19.3010)
2022-11-02 23:52:51,996:INFO: Batch:  6/31	Total Loss 17.7773 (19.0693)
2022-11-02 23:52:52,464:INFO: Batch:  7/31	Total Loss 20.1424 (19.1936)
2022-11-02 23:52:52,931:INFO: Batch:  8/31	Total Loss 18.1072 (19.0650)
2022-11-02 23:52:53,395:INFO: Batch:  9/31	Total Loss 15.4396 (18.6713)
2022-11-02 23:52:53,860:INFO: Batch: 10/31	Total Loss 17.8734 (18.5979)
2022-11-02 23:52:54,327:INFO: Batch: 11/31	Total Loss 16.9551 (18.4604)
2022-11-02 23:52:54,794:INFO: Batch: 12/31	Total Loss 18.6007 (18.4705)
2022-11-02 23:52:55,263:INFO: Batch: 13/31	Total Loss 17.1169 (18.3747)
2022-11-02 23:52:55,732:INFO: Batch: 14/31	Total Loss 18.4164 (18.3774)
2022-11-02 23:52:56,209:INFO: Batch: 15/31	Total Loss 18.0754 (18.3585)
2022-11-02 23:52:56,693:INFO: Batch: 16/31	Total Loss 18.1031 (18.3419)
2022-11-02 23:52:57,174:INFO: Batch: 17/31	Total Loss 17.5629 (18.2978)
2022-11-02 23:52:57,658:INFO: Batch: 18/31	Total Loss 16.8537 (18.2203)
2022-11-02 23:52:58,147:INFO: Batch: 19/31	Total Loss 19.2571 (18.2693)
2022-11-02 23:52:58,630:INFO: Batch: 20/31	Total Loss 18.7640 (18.2932)
2022-11-02 23:52:59,106:INFO: Batch: 21/31	Total Loss 17.4398 (18.2525)
2022-11-02 23:52:59,584:INFO: Batch: 22/31	Total Loss 20.3758 (18.3433)
2022-11-02 23:53:00,060:INFO: Batch: 23/31	Total Loss 18.5068 (18.3503)
2022-11-02 23:53:00,534:INFO: Batch: 24/31	Total Loss 20.4080 (18.4260)
2022-11-02 23:53:01,011:INFO: Batch: 25/31	Total Loss 16.9783 (18.3678)
2022-11-02 23:53:01,486:INFO: Batch: 26/31	Total Loss 18.7252 (18.3815)
2022-11-02 23:53:01,965:INFO: Batch: 27/31	Total Loss 19.5637 (18.4224)
2022-11-02 23:53:02,444:INFO: Batch: 28/31	Total Loss 17.5379 (18.3937)
2022-11-02 23:53:02,917:INFO: Batch: 29/31	Total Loss 18.3792 (18.3933)
2022-11-02 23:53:03,307:INFO: Batch: 30/31	Total Loss 5.9904 (18.2649)
2022-11-02 23:53:03,460:INFO: - Computing ADE (validation o)
2022-11-02 23:53:04,030:INFO: 		 ADE on eth                       dataset:	 2.481288194656372
2022-11-02 23:53:04,031:INFO: Average validation o:	ADE  2.4813	FDE  4.2187
2022-11-02 23:53:04,031:INFO: - Computing ADE (validation)
2022-11-02 23:53:04,293:INFO: 		 ADE on hotel                     dataset:	 1.0264310836791992
2022-11-02 23:53:04,586:INFO: 		 ADE on univ                      dataset:	 1.3895231485366821
2022-11-02 23:53:04,836:INFO: 		 ADE on zara1                     dataset:	 2.218928575515747
2022-11-02 23:53:05,211:INFO: 		 ADE on zara2                     dataset:	 1.337775707244873
2022-11-02 23:53:05,211:INFO: Average validation:	ADE  1.3989	FDE  2.5639
2022-11-02 23:53:05,212:INFO: - Computing ADE (training)
2022-11-02 23:53:05,671:INFO: 		 ADE on hotel                     dataset:	 1.3143823146820068
2022-11-02 23:53:06,356:INFO: 		 ADE on univ                      dataset:	 1.2888504266738892
2022-11-02 23:53:06,899:INFO: 		 ADE on zara1                     dataset:	 2.173222064971924
2022-11-02 23:53:07,642:INFO: 		 ADE on zara2                     dataset:	 1.5644482374191284
2022-11-02 23:53:07,642:INFO: Average training:	ADE  1.4018	FDE  2.5756
2022-11-02 23:53:07,650:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_255.pth.tar
2022-11-02 23:53:07,651:INFO: 
===> EPOCH: 256 (P3)
2022-11-02 23:53:07,651:INFO: - Computing loss (training)
2022-11-02 23:53:08,769:INFO: Batch:  0/31	Total Loss 19.5324 (19.5324)
2022-11-02 23:53:09,260:INFO: Batch:  1/31	Total Loss 19.3192 (19.4274)
2022-11-02 23:53:09,752:INFO: Batch:  2/31	Total Loss 16.0518 (18.2351)
2022-11-02 23:53:10,242:INFO: Batch:  3/31	Total Loss 16.2997 (17.7028)
2022-11-02 23:53:10,722:INFO: Batch:  4/31	Total Loss 17.5158 (17.6643)
2022-11-02 23:53:11,198:INFO: Batch:  5/31	Total Loss 16.7065 (17.5069)
2022-11-02 23:53:11,679:INFO: Batch:  6/31	Total Loss 18.0953 (17.5942)
2022-11-02 23:53:12,157:INFO: Batch:  7/31	Total Loss 17.2826 (17.5585)
2022-11-02 23:53:12,634:INFO: Batch:  8/31	Total Loss 16.3808 (17.4198)
2022-11-02 23:53:13,111:INFO: Batch:  9/31	Total Loss 17.6728 (17.4463)
2022-11-02 23:53:13,584:INFO: Batch: 10/31	Total Loss 15.0539 (17.1968)
2022-11-02 23:53:14,064:INFO: Batch: 11/31	Total Loss 17.7153 (17.2392)
2022-11-02 23:53:14,546:INFO: Batch: 12/31	Total Loss 17.0231 (17.2238)
2022-11-02 23:53:15,029:INFO: Batch: 13/31	Total Loss 17.9920 (17.2771)
2022-11-02 23:53:15,499:INFO: Batch: 14/31	Total Loss 19.2875 (17.4172)
2022-11-02 23:53:15,975:INFO: Batch: 15/31	Total Loss 18.6159 (17.4888)
2022-11-02 23:53:16,458:INFO: Batch: 16/31	Total Loss 15.2439 (17.3535)
2022-11-02 23:53:16,946:INFO: Batch: 17/31	Total Loss 18.2532 (17.4047)
2022-11-02 23:53:17,432:INFO: Batch: 18/31	Total Loss 16.8333 (17.3718)
2022-11-02 23:53:17,914:INFO: Batch: 19/31	Total Loss 17.3782 (17.3721)
2022-11-02 23:53:18,395:INFO: Batch: 20/31	Total Loss 16.7425 (17.3441)
2022-11-02 23:53:18,876:INFO: Batch: 21/31	Total Loss 16.4826 (17.3069)
2022-11-02 23:53:19,424:INFO: Batch: 22/31	Total Loss 16.9661 (17.2916)
2022-11-02 23:53:19,975:INFO: Batch: 23/31	Total Loss 14.6065 (17.1791)
2022-11-02 23:53:20,501:INFO: Batch: 24/31	Total Loss 18.3974 (17.2238)
2022-11-02 23:53:20,992:INFO: Batch: 25/31	Total Loss 15.8854 (17.1711)
2022-11-02 23:53:21,473:INFO: Batch: 26/31	Total Loss 16.6833 (17.1512)
2022-11-02 23:53:22,096:INFO: Batch: 27/31	Total Loss 14.6326 (17.0564)
2022-11-02 23:53:22,635:INFO: Batch: 28/31	Total Loss 17.3613 (17.0665)
2022-11-02 23:53:23,124:INFO: Batch: 29/31	Total Loss 15.9051 (17.0261)
2022-11-02 23:53:23,530:INFO: Batch: 30/31	Total Loss 7.4287 (16.9328)
2022-11-02 23:53:23,704:INFO: - Computing ADE (validation o)
2022-11-02 23:53:24,307:INFO: 		 ADE on eth                       dataset:	 2.1412782669067383
2022-11-02 23:53:24,307:INFO: Average validation o:	ADE  2.1413	FDE  3.5922
2022-11-02 23:53:24,308:INFO: - Computing ADE (validation)
2022-11-02 23:53:24,661:INFO: 		 ADE on hotel                     dataset:	 1.1808435916900635
2022-11-02 23:53:24,961:INFO: 		 ADE on univ                      dataset:	 1.2941780090332031
2022-11-02 23:53:25,230:INFO: 		 ADE on zara1                     dataset:	 1.7566910982131958
2022-11-02 23:53:25,592:INFO: 		 ADE on zara2                     dataset:	 1.2543197870254517
2022-11-02 23:53:25,592:INFO: Average validation:	ADE  1.3002	FDE  2.4765
2022-11-02 23:53:25,593:INFO: - Computing ADE (training)
2022-11-02 23:53:26,064:INFO: 		 ADE on hotel                     dataset:	 1.397484540939331
2022-11-02 23:53:26,755:INFO: 		 ADE on univ                      dataset:	 1.2101404666900635
2022-11-02 23:53:27,329:INFO: 		 ADE on zara1                     dataset:	 1.8032288551330566
2022-11-02 23:53:28,176:INFO: 		 ADE on zara2                     dataset:	 1.4376276731491089
2022-11-02 23:53:28,185:INFO: Average training:	ADE  1.2989	FDE  2.4762
2022-11-02 23:53:28,195:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_256.pth.tar
2022-11-02 23:53:28,195:INFO: 
===> EPOCH: 257 (P3)
2022-11-02 23:53:28,195:INFO: - Computing loss (training)
2022-11-02 23:53:29,331:INFO: Batch:  0/31	Total Loss 18.2535 (18.2535)
2022-11-02 23:53:29,810:INFO: Batch:  1/31	Total Loss 15.4754 (16.8611)
2022-11-02 23:53:30,287:INFO: Batch:  2/31	Total Loss 17.4225 (17.0323)
2022-11-02 23:53:30,778:INFO: Batch:  3/31	Total Loss 17.0654 (17.0408)
2022-11-02 23:53:31,259:INFO: Batch:  4/31	Total Loss 16.6508 (16.9661)
2022-11-02 23:53:31,743:INFO: Batch:  5/31	Total Loss 15.4263 (16.7147)
2022-11-02 23:53:32,218:INFO: Batch:  6/31	Total Loss 15.1843 (16.5028)
2022-11-02 23:53:32,710:INFO: Batch:  7/31	Total Loss 15.0084 (16.3182)
2022-11-02 23:53:33,207:INFO: Batch:  8/31	Total Loss 13.8448 (16.0384)
2022-11-02 23:53:33,696:INFO: Batch:  9/31	Total Loss 17.5233 (16.1836)
2022-11-02 23:53:34,193:INFO: Batch: 10/31	Total Loss 16.2535 (16.1900)
2022-11-02 23:53:34,693:INFO: Batch: 11/31	Total Loss 17.0534 (16.2573)
2022-11-02 23:53:35,195:INFO: Batch: 12/31	Total Loss 15.1781 (16.1645)
2022-11-02 23:53:35,697:INFO: Batch: 13/31	Total Loss 13.1475 (15.9600)
2022-11-02 23:53:36,198:INFO: Batch: 14/31	Total Loss 14.9100 (15.8880)
2022-11-02 23:53:36,727:INFO: Batch: 15/31	Total Loss 13.4920 (15.7480)
2022-11-02 23:53:37,224:INFO: Batch: 16/31	Total Loss 14.0703 (15.6484)
2022-11-02 23:53:37,730:INFO: Batch: 17/31	Total Loss 13.8595 (15.5363)
2022-11-02 23:53:38,222:INFO: Batch: 18/31	Total Loss 15.6291 (15.5411)
2022-11-02 23:53:38,717:INFO: Batch: 19/31	Total Loss 14.1096 (15.4707)
2022-11-02 23:53:39,241:INFO: Batch: 20/31	Total Loss 12.7907 (15.3359)
2022-11-02 23:53:39,744:INFO: Batch: 21/31	Total Loss 15.1355 (15.3276)
2022-11-02 23:53:40,309:INFO: Batch: 22/31	Total Loss 13.2088 (15.2424)
2022-11-02 23:53:40,905:INFO: Batch: 23/31	Total Loss 15.8333 (15.2662)
2022-11-02 23:53:41,465:INFO: Batch: 24/31	Total Loss 14.4886 (15.2323)
2022-11-02 23:53:42,020:INFO: Batch: 25/31	Total Loss 13.3490 (15.1599)
2022-11-02 23:53:42,537:INFO: Batch: 26/31	Total Loss 11.8643 (15.0427)
2022-11-02 23:53:43,081:INFO: Batch: 27/31	Total Loss 12.3963 (14.9552)
2022-11-02 23:53:43,606:INFO: Batch: 28/31	Total Loss 14.0539 (14.9263)
2022-11-02 23:53:44,092:INFO: Batch: 29/31	Total Loss 14.9674 (14.9276)
2022-11-02 23:53:44,502:INFO: Batch: 30/31	Total Loss 5.3961 (14.8440)
2022-11-02 23:53:44,660:INFO: - Computing ADE (validation o)
2022-11-02 23:53:45,266:INFO: 		 ADE on eth                       dataset:	 1.82677161693573
2022-11-02 23:53:45,266:INFO: Average validation o:	ADE  1.8268	FDE  2.9561
2022-11-02 23:53:45,267:INFO: - Computing ADE (validation)
2022-11-02 23:53:45,562:INFO: 		 ADE on hotel                     dataset:	 0.9420675039291382
2022-11-02 23:53:45,855:INFO: 		 ADE on univ                      dataset:	 1.066331386566162
2022-11-02 23:53:46,106:INFO: 		 ADE on zara1                     dataset:	 1.6186597347259521
2022-11-02 23:53:46,476:INFO: 		 ADE on zara2                     dataset:	 1.0090569257736206
2022-11-02 23:53:46,476:INFO: Average validation:	ADE  1.0706	FDE  1.9038
2022-11-02 23:53:46,477:INFO: - Computing ADE (training)
2022-11-02 23:53:46,930:INFO: 		 ADE on hotel                     dataset:	 1.186793565750122
2022-11-02 23:53:47,703:INFO: 		 ADE on univ                      dataset:	 1.0170297622680664
2022-11-02 23:53:48,236:INFO: 		 ADE on zara1                     dataset:	 1.57376229763031
2022-11-02 23:53:49,000:INFO: 		 ADE on zara2                     dataset:	 1.1656849384307861
2022-11-02 23:53:49,000:INFO: Average training:	ADE  1.0870	FDE  1.9508
2022-11-02 23:53:49,008:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_257.pth.tar
2022-11-02 23:53:49,009:INFO: 
===> EPOCH: 258 (P3)
2022-11-02 23:53:49,009:INFO: - Computing loss (training)
2022-11-02 23:53:50,112:INFO: Batch:  0/31	Total Loss 12.6530 (12.6530)
2022-11-02 23:53:50,595:INFO: Batch:  1/31	Total Loss 13.9352 (13.2511)
2022-11-02 23:53:51,117:INFO: Batch:  2/31	Total Loss 14.7093 (13.7372)
2022-11-02 23:53:51,606:INFO: Batch:  3/31	Total Loss 11.9410 (13.2891)
2022-11-02 23:53:52,098:INFO: Batch:  4/31	Total Loss 14.0140 (13.4179)
2022-11-02 23:53:52,628:INFO: Batch:  5/31	Total Loss 14.3423 (13.5698)
2022-11-02 23:53:53,154:INFO: Batch:  6/31	Total Loss 12.7175 (13.4628)
2022-11-02 23:53:53,638:INFO: Batch:  7/31	Total Loss 12.7593 (13.3757)
2022-11-02 23:53:54,134:INFO: Batch:  8/31	Total Loss 12.2982 (13.2599)
2022-11-02 23:53:54,651:INFO: Batch:  9/31	Total Loss 13.8520 (13.3171)
2022-11-02 23:53:55,164:INFO: Batch: 10/31	Total Loss 14.3247 (13.4034)
2022-11-02 23:53:55,675:INFO: Batch: 11/31	Total Loss 12.4565 (13.3132)
2022-11-02 23:53:56,189:INFO: Batch: 12/31	Total Loss 13.5941 (13.3385)
2022-11-02 23:53:56,709:INFO: Batch: 13/31	Total Loss 14.2852 (13.4091)
2022-11-02 23:53:57,328:INFO: Batch: 14/31	Total Loss 12.9434 (13.3804)
2022-11-02 23:53:58,059:INFO: Batch: 15/31	Total Loss 14.9945 (13.4762)
2022-11-02 23:53:58,562:INFO: Batch: 16/31	Total Loss 14.8004 (13.5588)
2022-11-02 23:53:59,045:INFO: Batch: 17/31	Total Loss 13.0298 (13.5292)
2022-11-02 23:53:59,523:INFO: Batch: 18/31	Total Loss 12.8396 (13.4932)
2022-11-02 23:54:00,011:INFO: Batch: 19/31	Total Loss 13.6760 (13.5028)
2022-11-02 23:54:00,495:INFO: Batch: 20/31	Total Loss 13.7954 (13.5154)
2022-11-02 23:54:00,973:INFO: Batch: 21/31	Total Loss 12.9268 (13.4873)
2022-11-02 23:54:01,451:INFO: Batch: 22/31	Total Loss 13.9972 (13.5097)
2022-11-02 23:54:01,928:INFO: Batch: 23/31	Total Loss 13.3395 (13.5026)
2022-11-02 23:54:02,402:INFO: Batch: 24/31	Total Loss 12.8283 (13.4759)
2022-11-02 23:54:02,882:INFO: Batch: 25/31	Total Loss 12.1675 (13.4192)
2022-11-02 23:54:03,377:INFO: Batch: 26/31	Total Loss 15.8261 (13.5218)
2022-11-02 23:54:03,856:INFO: Batch: 27/31	Total Loss 14.0053 (13.5377)
2022-11-02 23:54:04,352:INFO: Batch: 28/31	Total Loss 12.3264 (13.4975)
2022-11-02 23:54:04,860:INFO: Batch: 29/31	Total Loss 12.7052 (13.4706)
2022-11-02 23:54:05,284:INFO: Batch: 30/31	Total Loss 5.2689 (13.3834)
2022-11-02 23:54:05,481:INFO: - Computing ADE (validation o)
2022-11-02 23:54:06,096:INFO: 		 ADE on eth                       dataset:	 1.6033867597579956
2022-11-02 23:54:06,096:INFO: Average validation o:	ADE  1.6034	FDE  2.5496
2022-11-02 23:54:06,097:INFO: - Computing ADE (validation)
2022-11-02 23:54:06,419:INFO: 		 ADE on hotel                     dataset:	 1.0010396242141724
2022-11-02 23:54:06,769:INFO: 		 ADE on univ                      dataset:	 1.0285367965698242
2022-11-02 23:54:07,078:INFO: 		 ADE on zara1                     dataset:	 1.4360253810882568
2022-11-02 23:54:07,441:INFO: 		 ADE on zara2                     dataset:	 0.9230806231498718
2022-11-02 23:54:07,442:INFO: Average validation:	ADE  1.0120	FDE  1.8089
2022-11-02 23:54:07,443:INFO: - Computing ADE (training)
2022-11-02 23:54:07,982:INFO: 		 ADE on hotel                     dataset:	 1.2637813091278076
2022-11-02 23:54:08,675:INFO: 		 ADE on univ                      dataset:	 0.9833171367645264
2022-11-02 23:54:09,268:INFO: 		 ADE on zara1                     dataset:	 1.361149549484253
2022-11-02 23:54:10,066:INFO: 		 ADE on zara2                     dataset:	 1.0414165258407593
2022-11-02 23:54:10,066:INFO: Average training:	ADE  1.0263	FDE  1.8508
2022-11-02 23:54:10,075:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_258.pth.tar
2022-11-02 23:54:10,075:INFO: 
===> EPOCH: 259 (P3)
2022-11-02 23:54:10,075:INFO: - Computing loss (training)
2022-11-02 23:54:11,214:INFO: Batch:  0/31	Total Loss 11.2090 (11.2090)
2022-11-02 23:54:11,714:INFO: Batch:  1/31	Total Loss 14.5387 (12.7837)
2022-11-02 23:54:12,240:INFO: Batch:  2/31	Total Loss 12.9839 (12.8443)
2022-11-02 23:54:12,740:INFO: Batch:  3/31	Total Loss 13.4509 (12.9978)
2022-11-02 23:54:13,234:INFO: Batch:  4/31	Total Loss 13.0881 (13.0156)
2022-11-02 23:54:13,755:INFO: Batch:  5/31	Total Loss 13.1891 (13.0418)
2022-11-02 23:54:14,263:INFO: Batch:  6/31	Total Loss 12.0560 (12.8999)
2022-11-02 23:54:14,771:INFO: Batch:  7/31	Total Loss 13.0423 (12.9158)
2022-11-02 23:54:15,279:INFO: Batch:  8/31	Total Loss 14.3504 (13.0692)
2022-11-02 23:54:15,799:INFO: Batch:  9/31	Total Loss 11.8083 (12.9439)
2022-11-02 23:54:16,339:INFO: Batch: 10/31	Total Loss 13.9038 (13.0118)
2022-11-02 23:54:16,832:INFO: Batch: 11/31	Total Loss 13.7372 (13.0694)
2022-11-02 23:54:17,340:INFO: Batch: 12/31	Total Loss 13.3401 (13.0890)
2022-11-02 23:54:17,847:INFO: Batch: 13/31	Total Loss 11.8346 (12.9940)
2022-11-02 23:54:18,337:INFO: Batch: 14/31	Total Loss 14.0577 (13.0666)
2022-11-02 23:54:18,900:INFO: Batch: 15/31	Total Loss 12.6673 (13.0427)
2022-11-02 23:54:19,762:INFO: Batch: 16/31	Total Loss 13.5978 (13.0697)
2022-11-02 23:54:20,279:INFO: Batch: 17/31	Total Loss 12.4402 (13.0322)
2022-11-02 23:54:20,768:INFO: Batch: 18/31	Total Loss 12.0861 (12.9856)
2022-11-02 23:54:21,257:INFO: Batch: 19/31	Total Loss 12.8022 (12.9771)
2022-11-02 23:54:21,819:INFO: Batch: 20/31	Total Loss 13.3169 (12.9906)
2022-11-02 23:54:22,301:INFO: Batch: 21/31	Total Loss 15.5791 (13.1158)
2022-11-02 23:54:22,785:INFO: Batch: 22/31	Total Loss 13.8607 (13.1459)
2022-11-02 23:54:23,270:INFO: Batch: 23/31	Total Loss 11.6067 (13.0760)
2022-11-02 23:54:23,752:INFO: Batch: 24/31	Total Loss 12.1898 (13.0426)
2022-11-02 23:54:24,236:INFO: Batch: 25/31	Total Loss 12.0883 (13.0032)
2022-11-02 23:54:24,718:INFO: Batch: 26/31	Total Loss 12.3401 (12.9770)
2022-11-02 23:54:25,199:INFO: Batch: 27/31	Total Loss 13.8886 (13.0126)
2022-11-02 23:54:25,676:INFO: Batch: 28/31	Total Loss 11.8900 (12.9746)
2022-11-02 23:54:26,152:INFO: Batch: 29/31	Total Loss 12.9387 (12.9733)
2022-11-02 23:54:26,544:INFO: Batch: 30/31	Total Loss 3.7712 (12.8824)
2022-11-02 23:54:26,707:INFO: - Computing ADE (validation o)
2022-11-02 23:54:27,293:INFO: 		 ADE on eth                       dataset:	 1.5060341358184814
2022-11-02 23:54:27,293:INFO: Average validation o:	ADE  1.5060	FDE  2.2741
2022-11-02 23:54:27,294:INFO: - Computing ADE (validation)
2022-11-02 23:54:27,555:INFO: 		 ADE on hotel                     dataset:	 1.002837061882019
2022-11-02 23:54:27,850:INFO: 		 ADE on univ                      dataset:	 0.9939866662025452
2022-11-02 23:54:28,104:INFO: 		 ADE on zara1                     dataset:	 1.2816513776779175
2022-11-02 23:54:28,462:INFO: 		 ADE on zara2                     dataset:	 0.8452445268630981
2022-11-02 23:54:28,462:INFO: Average validation:	ADE  0.9566	FDE  1.6541
2022-11-02 23:54:28,471:INFO: - Computing ADE (training)
2022-11-02 23:54:28,929:INFO: 		 ADE on hotel                     dataset:	 1.2724875211715698
2022-11-02 23:54:29,671:INFO: 		 ADE on univ                      dataset:	 0.9387299418449402
2022-11-02 23:54:30,215:INFO: 		 ADE on zara1                     dataset:	 1.2602357864379883
2022-11-02 23:54:30,976:INFO: 		 ADE on zara2                     dataset:	 0.9619829058647156
2022-11-02 23:54:30,977:INFO: Average training:	ADE  0.9724	FDE  1.7000
2022-11-02 23:54:30,985:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_259.pth.tar
2022-11-02 23:54:30,985:INFO: 
===> EPOCH: 260 (P3)
2022-11-02 23:54:30,986:INFO: - Computing loss (training)
2022-11-02 23:54:32,054:INFO: Batch:  0/31	Total Loss 12.8166 (12.8166)
2022-11-02 23:54:32,541:INFO: Batch:  1/31	Total Loss 11.9504 (12.3840)
2022-11-02 23:54:33,022:INFO: Batch:  2/31	Total Loss 13.4646 (12.7921)
2022-11-02 23:54:33,496:INFO: Batch:  3/31	Total Loss 12.6213 (12.7481)
2022-11-02 23:54:33,976:INFO: Batch:  4/31	Total Loss 12.3994 (12.6782)
2022-11-02 23:54:34,450:INFO: Batch:  5/31	Total Loss 13.4875 (12.8070)
2022-11-02 23:54:34,925:INFO: Batch:  6/31	Total Loss 10.7473 (12.4755)
2022-11-02 23:54:35,400:INFO: Batch:  7/31	Total Loss 14.1551 (12.6816)
2022-11-02 23:54:35,879:INFO: Batch:  8/31	Total Loss 12.5038 (12.6604)
2022-11-02 23:54:36,371:INFO: Batch:  9/31	Total Loss 13.7913 (12.7624)
2022-11-02 23:54:36,879:INFO: Batch: 10/31	Total Loss 14.3619 (12.9071)
2022-11-02 23:54:37,377:INFO: Batch: 11/31	Total Loss 13.3349 (12.9444)
2022-11-02 23:54:37,890:INFO: Batch: 12/31	Total Loss 11.8104 (12.8628)
2022-11-02 23:54:38,380:INFO: Batch: 13/31	Total Loss 11.4269 (12.7581)
2022-11-02 23:54:38,865:INFO: Batch: 14/31	Total Loss 12.5260 (12.7421)
2022-11-02 23:54:39,367:INFO: Batch: 15/31	Total Loss 13.1553 (12.7705)
2022-11-02 23:54:39,872:INFO: Batch: 16/31	Total Loss 11.8510 (12.7138)
2022-11-02 23:54:40,379:INFO: Batch: 17/31	Total Loss 11.9812 (12.6716)
2022-11-02 23:54:40,885:INFO: Batch: 18/31	Total Loss 12.0586 (12.6419)
2022-11-02 23:54:41,376:INFO: Batch: 19/31	Total Loss 12.3631 (12.6277)
2022-11-02 23:54:41,868:INFO: Batch: 20/31	Total Loss 13.2565 (12.6572)
2022-11-02 23:54:42,360:INFO: Batch: 21/31	Total Loss 12.3150 (12.6419)
2022-11-02 23:54:42,868:INFO: Batch: 22/31	Total Loss 11.9754 (12.6143)
2022-11-02 23:54:43,394:INFO: Batch: 23/31	Total Loss 12.9068 (12.6277)
2022-11-02 23:54:43,892:INFO: Batch: 24/31	Total Loss 12.6362 (12.6281)
2022-11-02 23:54:44,413:INFO: Batch: 25/31	Total Loss 13.5766 (12.6615)
2022-11-02 23:54:44,905:INFO: Batch: 26/31	Total Loss 13.6369 (12.6983)
2022-11-02 23:54:45,390:INFO: Batch: 27/31	Total Loss 13.2836 (12.7214)
2022-11-02 23:54:45,881:INFO: Batch: 28/31	Total Loss 12.4962 (12.7131)
2022-11-02 23:54:46,377:INFO: Batch: 29/31	Total Loss 12.8617 (12.7181)
2022-11-02 23:54:46,779:INFO: Batch: 30/31	Total Loss 4.7421 (12.6446)
2022-11-02 23:54:46,938:INFO: - Computing ADE (validation o)
2022-11-02 23:54:47,537:INFO: 		 ADE on eth                       dataset:	 1.4353294372558594
2022-11-02 23:54:47,538:INFO: Average validation o:	ADE  1.4353	FDE  2.2070
2022-11-02 23:54:47,538:INFO: - Computing ADE (validation)
2022-11-02 23:54:47,835:INFO: 		 ADE on hotel                     dataset:	 1.0063875913619995
2022-11-02 23:54:48,225:INFO: 		 ADE on univ                      dataset:	 0.9805794954299927
2022-11-02 23:54:48,492:INFO: 		 ADE on zara1                     dataset:	 1.2352722883224487
2022-11-02 23:54:48,892:INFO: 		 ADE on zara2                     dataset:	 0.8125893473625183
2022-11-02 23:54:48,892:INFO: Average validation:	ADE  0.9352	FDE  1.6199
2022-11-02 23:54:48,893:INFO: - Computing ADE (training)
2022-11-02 23:54:49,409:INFO: 		 ADE on hotel                     dataset:	 1.2874664068222046
2022-11-02 23:54:50,119:INFO: 		 ADE on univ                      dataset:	 0.929275631904602
2022-11-02 23:54:50,756:INFO: 		 ADE on zara1                     dataset:	 1.1912500858306885
2022-11-02 23:54:51,608:INFO: 		 ADE on zara2                     dataset:	 0.9101231694221497
2022-11-02 23:54:51,608:INFO: Average training:	ADE  0.9512	FDE  1.6623
2022-11-02 23:54:51,618:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_260.pth.tar
2022-11-02 23:54:51,618:INFO: 
===> EPOCH: 261 (P3)
2022-11-02 23:54:51,619:INFO: - Computing loss (training)
2022-11-02 23:54:52,770:INFO: Batch:  0/31	Total Loss 11.5482 (11.5482)
2022-11-02 23:54:53,268:INFO: Batch:  1/31	Total Loss 13.3191 (12.3624)
2022-11-02 23:54:53,794:INFO: Batch:  2/31	Total Loss 12.2166 (12.3123)
2022-11-02 23:54:54,314:INFO: Batch:  3/31	Total Loss 11.1768 (12.0194)
2022-11-02 23:54:54,802:INFO: Batch:  4/31	Total Loss 12.3272 (12.0751)
2022-11-02 23:54:55,313:INFO: Batch:  5/31	Total Loss 11.7555 (12.0209)
2022-11-02 23:54:55,829:INFO: Batch:  6/31	Total Loss 12.3772 (12.0684)
2022-11-02 23:54:56,310:INFO: Batch:  7/31	Total Loss 12.1701 (12.0816)
2022-11-02 23:54:56,803:INFO: Batch:  8/31	Total Loss 11.2158 (11.9817)
2022-11-02 23:54:57,318:INFO: Batch:  9/31	Total Loss 12.7241 (12.0517)
2022-11-02 23:54:57,822:INFO: Batch: 10/31	Total Loss 12.4911 (12.0952)
2022-11-02 23:54:58,333:INFO: Batch: 11/31	Total Loss 12.8084 (12.1510)
2022-11-02 23:54:58,821:INFO: Batch: 12/31	Total Loss 11.2636 (12.0777)
2022-11-02 23:54:59,317:INFO: Batch: 13/31	Total Loss 11.7472 (12.0516)
2022-11-02 23:54:59,803:INFO: Batch: 14/31	Total Loss 12.0630 (12.0523)
2022-11-02 23:55:00,285:INFO: Batch: 15/31	Total Loss 13.4830 (12.1438)
2022-11-02 23:55:00,773:INFO: Batch: 16/31	Total Loss 11.9157 (12.1300)
2022-11-02 23:55:01,273:INFO: Batch: 17/31	Total Loss 12.6822 (12.1603)
2022-11-02 23:55:01,761:INFO: Batch: 18/31	Total Loss 12.1012 (12.1573)
2022-11-02 23:55:02,240:INFO: Batch: 19/31	Total Loss 11.6715 (12.1316)
2022-11-02 23:55:02,736:INFO: Batch: 20/31	Total Loss 11.8247 (12.1179)
2022-11-02 23:55:03,211:INFO: Batch: 21/31	Total Loss 12.2728 (12.1247)
2022-11-02 23:55:03,694:INFO: Batch: 22/31	Total Loss 11.7842 (12.1104)
2022-11-02 23:55:04,180:INFO: Batch: 23/31	Total Loss 11.3326 (12.0777)
2022-11-02 23:55:04,655:INFO: Batch: 24/31	Total Loss 11.0988 (12.0332)
2022-11-02 23:55:05,126:INFO: Batch: 25/31	Total Loss 12.2582 (12.0419)
2022-11-02 23:55:05,631:INFO: Batch: 26/31	Total Loss 11.0284 (12.0026)
2022-11-02 23:55:06,117:INFO: Batch: 27/31	Total Loss 12.5673 (12.0238)
2022-11-02 23:55:06,600:INFO: Batch: 28/31	Total Loss 11.9439 (12.0214)
2022-11-02 23:55:07,074:INFO: Batch: 29/31	Total Loss 11.8397 (12.0155)
2022-11-02 23:55:07,481:INFO: Batch: 30/31	Total Loss 4.7300 (11.9513)
2022-11-02 23:55:07,656:INFO: - Computing ADE (validation o)
2022-11-02 23:55:08,258:INFO: 		 ADE on eth                       dataset:	 1.3635283708572388
2022-11-02 23:55:08,258:INFO: Average validation o:	ADE  1.3635	FDE  2.0381
2022-11-02 23:55:08,259:INFO: - Computing ADE (validation)
2022-11-02 23:55:08,515:INFO: 		 ADE on hotel                     dataset:	 1.0029555559158325
2022-11-02 23:55:08,826:INFO: 		 ADE on univ                      dataset:	 0.9680852293968201
2022-11-02 23:55:09,074:INFO: 		 ADE on zara1                     dataset:	 1.1521214246749878
2022-11-02 23:55:09,432:INFO: 		 ADE on zara2                     dataset:	 0.7644476294517517
2022-11-02 23:55:09,432:INFO: Average validation:	ADE  0.9060	FDE  1.5422
2022-11-02 23:55:09,433:INFO: - Computing ADE (training)
2022-11-02 23:55:09,942:INFO: 		 ADE on hotel                     dataset:	 1.2954355478286743
2022-11-02 23:55:10,644:INFO: 		 ADE on univ                      dataset:	 0.9084449410438538
2022-11-02 23:55:11,190:INFO: 		 ADE on zara1                     dataset:	 1.1159005165100098
2022-11-02 23:55:11,985:INFO: 		 ADE on zara2                     dataset:	 0.854558527469635
2022-11-02 23:55:11,985:INFO: Average training:	ADE  0.9206	FDE  1.5836
2022-11-02 23:55:11,994:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_261.pth.tar
2022-11-02 23:55:11,995:INFO: 
===> EPOCH: 262 (P3)
2022-11-02 23:55:11,995:INFO: - Computing loss (training)
2022-11-02 23:55:13,123:INFO: Batch:  0/31	Total Loss 11.8836 (11.8836)
2022-11-02 23:55:13,648:INFO: Batch:  1/31	Total Loss 13.3856 (12.6003)
2022-11-02 23:55:14,150:INFO: Batch:  2/31	Total Loss 12.4442 (12.5451)
2022-11-02 23:55:14,645:INFO: Batch:  3/31	Total Loss 11.4048 (12.2274)
2022-11-02 23:55:15,136:INFO: Batch:  4/31	Total Loss 12.5379 (12.2934)
2022-11-02 23:55:15,660:INFO: Batch:  5/31	Total Loss 9.9013 (11.8497)
2022-11-02 23:55:16,188:INFO: Batch:  6/31	Total Loss 10.6518 (11.6656)
2022-11-02 23:55:16,685:INFO: Batch:  7/31	Total Loss 12.3331 (11.7494)
2022-11-02 23:55:17,180:INFO: Batch:  8/31	Total Loss 11.0407 (11.6689)
2022-11-02 23:55:17,754:INFO: Batch:  9/31	Total Loss 11.9506 (11.6959)
2022-11-02 23:55:18,264:INFO: Batch: 10/31	Total Loss 12.6552 (11.7821)
2022-11-02 23:55:18,769:INFO: Batch: 11/31	Total Loss 11.9588 (11.7963)
2022-11-02 23:55:19,312:INFO: Batch: 12/31	Total Loss 12.3884 (11.8418)
2022-11-02 23:55:19,839:INFO: Batch: 13/31	Total Loss 11.6285 (11.8262)
2022-11-02 23:55:20,333:INFO: Batch: 14/31	Total Loss 10.6789 (11.7397)
2022-11-02 23:55:20,863:INFO: Batch: 15/31	Total Loss 12.5040 (11.7866)
2022-11-02 23:55:21,372:INFO: Batch: 16/31	Total Loss 12.2347 (11.8148)
2022-11-02 23:55:21,892:INFO: Batch: 17/31	Total Loss 12.5258 (11.8546)
2022-11-02 23:55:22,457:INFO: Batch: 18/31	Total Loss 11.6972 (11.8450)
2022-11-02 23:55:23,006:INFO: Batch: 19/31	Total Loss 10.4722 (11.7767)
2022-11-02 23:55:23,563:INFO: Batch: 20/31	Total Loss 12.1704 (11.7970)
2022-11-02 23:55:24,133:INFO: Batch: 21/31	Total Loss 11.1102 (11.7649)
2022-11-02 23:55:24,659:INFO: Batch: 22/31	Total Loss 13.9446 (11.8655)
2022-11-02 23:55:25,202:INFO: Batch: 23/31	Total Loss 13.2449 (11.9200)
2022-11-02 23:55:25,714:INFO: Batch: 24/31	Total Loss 12.4977 (11.9413)
2022-11-02 23:55:26,227:INFO: Batch: 25/31	Total Loss 11.1302 (11.9105)
2022-11-02 23:55:26,776:INFO: Batch: 26/31	Total Loss 12.6605 (11.9391)
2022-11-02 23:55:27,291:INFO: Batch: 27/31	Total Loss 12.3746 (11.9543)
2022-11-02 23:55:27,783:INFO: Batch: 28/31	Total Loss 11.6056 (11.9435)
2022-11-02 23:55:28,309:INFO: Batch: 29/31	Total Loss 11.5437 (11.9304)
2022-11-02 23:55:28,739:INFO: Batch: 30/31	Total Loss 4.9939 (11.8644)
2022-11-02 23:55:28,903:INFO: - Computing ADE (validation o)
2022-11-02 23:55:29,514:INFO: 		 ADE on eth                       dataset:	 1.324039101600647
2022-11-02 23:55:29,515:INFO: Average validation o:	ADE  1.3240	FDE  1.9748
2022-11-02 23:55:29,515:INFO: - Computing ADE (validation)
2022-11-02 23:55:29,794:INFO: 		 ADE on hotel                     dataset:	 1.0026519298553467
2022-11-02 23:55:30,115:INFO: 		 ADE on univ                      dataset:	 0.9444626569747925
2022-11-02 23:55:30,404:INFO: 		 ADE on zara1                     dataset:	 1.0541201829910278
2022-11-02 23:55:30,827:INFO: 		 ADE on zara2                     dataset:	 0.7334375977516174
2022-11-02 23:55:30,827:INFO: Average validation:	ADE  0.8766	FDE  1.4766
2022-11-02 23:55:30,828:INFO: - Computing ADE (training)
2022-11-02 23:55:31,484:INFO: 		 ADE on hotel                     dataset:	 1.2864196300506592
2022-11-02 23:55:32,208:INFO: 		 ADE on univ                      dataset:	 0.8884636759757996
2022-11-02 23:55:32,766:INFO: 		 ADE on zara1                     dataset:	 1.0629243850708008
2022-11-02 23:55:33,580:INFO: 		 ADE on zara2                     dataset:	 0.8216556310653687
2022-11-02 23:55:33,581:INFO: Average training:	ADE  0.8961	FDE  1.5294
2022-11-02 23:55:33,590:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_262.pth.tar
2022-11-02 23:55:33,590:INFO: 
===> EPOCH: 263 (P3)
2022-11-02 23:55:33,590:INFO: - Computing loss (training)
2022-11-02 23:55:34,731:INFO: Batch:  0/31	Total Loss 11.4894 (11.4894)
2022-11-02 23:55:35,204:INFO: Batch:  1/31	Total Loss 12.0364 (11.7479)
2022-11-02 23:55:35,680:INFO: Batch:  2/31	Total Loss 12.6153 (12.0235)
2022-11-02 23:55:36,189:INFO: Batch:  3/31	Total Loss 11.4861 (11.8920)
2022-11-02 23:55:36,831:INFO: Batch:  4/31	Total Loss 11.7228 (11.8558)
2022-11-02 23:55:37,321:INFO: Batch:  5/31	Total Loss 10.5569 (11.6293)
2022-11-02 23:55:37,796:INFO: Batch:  6/31	Total Loss 11.5581 (11.6188)
2022-11-02 23:55:38,302:INFO: Batch:  7/31	Total Loss 11.9803 (11.6646)
2022-11-02 23:55:38,785:INFO: Batch:  8/31	Total Loss 11.0379 (11.5971)
2022-11-02 23:55:39,280:INFO: Batch:  9/31	Total Loss 12.0112 (11.6336)
2022-11-02 23:55:39,810:INFO: Batch: 10/31	Total Loss 11.1530 (11.5856)
2022-11-02 23:55:40,290:INFO: Batch: 11/31	Total Loss 11.8625 (11.6084)
2022-11-02 23:55:40,850:INFO: Batch: 12/31	Total Loss 10.7115 (11.5391)
2022-11-02 23:55:41,420:INFO: Batch: 13/31	Total Loss 11.5350 (11.5388)
2022-11-02 23:55:41,980:INFO: Batch: 14/31	Total Loss 11.8623 (11.5615)
2022-11-02 23:55:42,496:INFO: Batch: 15/31	Total Loss 11.6668 (11.5676)
2022-11-02 23:55:42,997:INFO: Batch: 16/31	Total Loss 12.0573 (11.5938)
2022-11-02 23:55:43,519:INFO: Batch: 17/31	Total Loss 13.1916 (11.6705)
2022-11-02 23:55:44,025:INFO: Batch: 18/31	Total Loss 12.7431 (11.7340)
2022-11-02 23:55:44,507:INFO: Batch: 19/31	Total Loss 12.1525 (11.7525)
2022-11-02 23:55:45,041:INFO: Batch: 20/31	Total Loss 11.8136 (11.7554)
2022-11-02 23:55:45,562:INFO: Batch: 21/31	Total Loss 12.8116 (11.7987)
2022-11-02 23:55:46,137:INFO: Batch: 22/31	Total Loss 12.7028 (11.8429)
2022-11-02 23:55:46,853:INFO: Batch: 23/31	Total Loss 12.1915 (11.8589)
2022-11-02 23:55:47,341:INFO: Batch: 24/31	Total Loss 12.0565 (11.8655)
2022-11-02 23:55:47,814:INFO: Batch: 25/31	Total Loss 13.6077 (11.9354)
2022-11-02 23:55:48,296:INFO: Batch: 26/31	Total Loss 11.0411 (11.8987)
2022-11-02 23:55:48,774:INFO: Batch: 27/31	Total Loss 12.2147 (11.9101)
2022-11-02 23:55:49,248:INFO: Batch: 28/31	Total Loss 12.9088 (11.9449)
2022-11-02 23:55:49,721:INFO: Batch: 29/31	Total Loss 10.2433 (11.8812)
2022-11-02 23:55:50,111:INFO: Batch: 30/31	Total Loss 5.3572 (11.8132)
2022-11-02 23:55:50,276:INFO: - Computing ADE (validation o)
2022-11-02 23:55:50,845:INFO: 		 ADE on eth                       dataset:	 1.3421812057495117
2022-11-02 23:55:50,846:INFO: Average validation o:	ADE  1.3422	FDE  2.1926
2022-11-02 23:55:50,846:INFO: - Computing ADE (validation)
2022-11-02 23:55:51,131:INFO: 		 ADE on hotel                     dataset:	 1.0999599695205688
2022-11-02 23:55:51,427:INFO: 		 ADE on univ                      dataset:	 1.006948471069336
2022-11-02 23:55:51,678:INFO: 		 ADE on zara1                     dataset:	 1.1548069715499878
2022-11-02 23:55:52,024:INFO: 		 ADE on zara2                     dataset:	 0.8109193444252014
2022-11-02 23:55:52,025:INFO: Average validation:	ADE  0.9487	FDE  1.7453
2022-11-02 23:55:52,025:INFO: - Computing ADE (training)
2022-11-02 23:55:52,484:INFO: 		 ADE on hotel                     dataset:	 1.376347303390503
2022-11-02 23:55:53,197:INFO: 		 ADE on univ                      dataset:	 0.9596157670021057
2022-11-02 23:55:53,727:INFO: 		 ADE on zara1                     dataset:	 1.0746638774871826
2022-11-02 23:55:54,480:INFO: 		 ADE on zara2                     dataset:	 0.8729521632194519
2022-11-02 23:55:54,480:INFO: Average training:	ADE  0.9600	FDE  1.7736
2022-11-02 23:55:54,489:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_263.pth.tar
2022-11-02 23:55:54,490:INFO: 
===> EPOCH: 264 (P3)
2022-11-02 23:55:54,490:INFO: - Computing loss (training)
2022-11-02 23:55:55,583:INFO: Batch:  0/31	Total Loss 11.0477 (11.0477)
2022-11-02 23:55:56,063:INFO: Batch:  1/31	Total Loss 12.7808 (11.8574)
2022-11-02 23:55:56,541:INFO: Batch:  2/31	Total Loss 11.5443 (11.7502)
2022-11-02 23:55:57,014:INFO: Batch:  3/31	Total Loss 10.7771 (11.5207)
2022-11-02 23:55:57,488:INFO: Batch:  4/31	Total Loss 12.1431 (11.6493)
2022-11-02 23:55:57,965:INFO: Batch:  5/31	Total Loss 11.5577 (11.6339)
2022-11-02 23:55:58,444:INFO: Batch:  6/31	Total Loss 11.2614 (11.5845)
2022-11-02 23:55:58,918:INFO: Batch:  7/31	Total Loss 12.4869 (11.7121)
2022-11-02 23:55:59,390:INFO: Batch:  8/31	Total Loss 10.0358 (11.5070)
2022-11-02 23:55:59,866:INFO: Batch:  9/31	Total Loss 13.1374 (11.6631)
2022-11-02 23:56:00,341:INFO: Batch: 10/31	Total Loss 11.7310 (11.6699)
2022-11-02 23:56:00,816:INFO: Batch: 11/31	Total Loss 10.7392 (11.5856)
2022-11-02 23:56:01,303:INFO: Batch: 12/31	Total Loss 10.2934 (11.4959)
2022-11-02 23:56:01,780:INFO: Batch: 13/31	Total Loss 12.0969 (11.5373)
2022-11-02 23:56:02,259:INFO: Batch: 14/31	Total Loss 11.4209 (11.5297)
2022-11-02 23:56:02,740:INFO: Batch: 15/31	Total Loss 12.2424 (11.5732)
2022-11-02 23:56:03,222:INFO: Batch: 16/31	Total Loss 11.9683 (11.5975)
2022-11-02 23:56:03,703:INFO: Batch: 17/31	Total Loss 12.4254 (11.6452)
2022-11-02 23:56:04,183:INFO: Batch: 18/31	Total Loss 10.8830 (11.6030)
2022-11-02 23:56:04,664:INFO: Batch: 19/31	Total Loss 12.1043 (11.6301)
2022-11-02 23:56:05,145:INFO: Batch: 20/31	Total Loss 11.6179 (11.6295)
2022-11-02 23:56:05,625:INFO: Batch: 21/31	Total Loss 10.6532 (11.5817)
2022-11-02 23:56:06,108:INFO: Batch: 22/31	Total Loss 11.1342 (11.5610)
2022-11-02 23:56:06,591:INFO: Batch: 23/31	Total Loss 13.5902 (11.6420)
2022-11-02 23:56:07,070:INFO: Batch: 24/31	Total Loss 10.8320 (11.6072)
2022-11-02 23:56:07,549:INFO: Batch: 25/31	Total Loss 11.9122 (11.6189)
2022-11-02 23:56:08,030:INFO: Batch: 26/31	Total Loss 11.9318 (11.6304)
2022-11-02 23:56:08,511:INFO: Batch: 27/31	Total Loss 10.9281 (11.6048)
2022-11-02 23:56:08,992:INFO: Batch: 28/31	Total Loss 11.9010 (11.6148)
2022-11-02 23:56:09,473:INFO: Batch: 29/31	Total Loss 11.0831 (11.5967)
2022-11-02 23:56:09,870:INFO: Batch: 30/31	Total Loss 4.8795 (11.5282)
2022-11-02 23:56:10,007:INFO: - Computing ADE (validation o)
2022-11-02 23:56:10,614:INFO: 		 ADE on eth                       dataset:	 1.2667820453643799
2022-11-02 23:56:10,614:INFO: Average validation o:	ADE  1.2668	FDE  1.9444
2022-11-02 23:56:10,615:INFO: - Computing ADE (validation)
2022-11-02 23:56:10,900:INFO: 		 ADE on hotel                     dataset:	 0.9920334219932556
2022-11-02 23:56:11,213:INFO: 		 ADE on univ                      dataset:	 0.9227485656738281
2022-11-02 23:56:11,458:INFO: 		 ADE on zara1                     dataset:	 0.9657390713691711
2022-11-02 23:56:11,820:INFO: 		 ADE on zara2                     dataset:	 0.6815456748008728
2022-11-02 23:56:11,820:INFO: Average validation:	ADE  0.8406	FDE  1.4169
2022-11-02 23:56:11,821:INFO: - Computing ADE (training)
2022-11-02 23:56:12,260:INFO: 		 ADE on hotel                     dataset:	 1.2794643640518188
2022-11-02 23:56:12,942:INFO: 		 ADE on univ                      dataset:	 0.8653006553649902
2022-11-02 23:56:13,481:INFO: 		 ADE on zara1                     dataset:	 0.9716705083847046
2022-11-02 23:56:14,217:INFO: 		 ADE on zara2                     dataset:	 0.7550691366195679
2022-11-02 23:56:14,218:INFO: Average training:	ADE  0.8602	FDE  1.4689
2022-11-02 23:56:14,227:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_264.pth.tar
2022-11-02 23:56:14,227:INFO: 
===> EPOCH: 265 (P3)
2022-11-02 23:56:14,227:INFO: - Computing loss (training)
2022-11-02 23:56:15,380:INFO: Batch:  0/31	Total Loss 11.3895 (11.3895)
2022-11-02 23:56:15,853:INFO: Batch:  1/31	Total Loss 10.6703 (11.0199)
2022-11-02 23:56:16,325:INFO: Batch:  2/31	Total Loss 12.1712 (11.3582)
2022-11-02 23:56:16,799:INFO: Batch:  3/31	Total Loss 12.5170 (11.6626)
2022-11-02 23:56:17,267:INFO: Batch:  4/31	Total Loss 11.8118 (11.6937)
2022-11-02 23:56:17,736:INFO: Batch:  5/31	Total Loss 11.1189 (11.6003)
2022-11-02 23:56:18,204:INFO: Batch:  6/31	Total Loss 10.8388 (11.4820)
2022-11-02 23:56:18,674:INFO: Batch:  7/31	Total Loss 11.4762 (11.4812)
2022-11-02 23:56:19,141:INFO: Batch:  8/31	Total Loss 10.7538 (11.3920)
2022-11-02 23:56:19,619:INFO: Batch:  9/31	Total Loss 11.1344 (11.3693)
2022-11-02 23:56:20,094:INFO: Batch: 10/31	Total Loss 11.5189 (11.3833)
2022-11-02 23:56:20,565:INFO: Batch: 11/31	Total Loss 11.1985 (11.3685)
2022-11-02 23:56:21,044:INFO: Batch: 12/31	Total Loss 11.2603 (11.3608)
2022-11-02 23:56:21,522:INFO: Batch: 13/31	Total Loss 9.5944 (11.2412)
2022-11-02 23:56:21,997:INFO: Batch: 14/31	Total Loss 11.5168 (11.2610)
2022-11-02 23:56:22,473:INFO: Batch: 15/31	Total Loss 11.6426 (11.2841)
2022-11-02 23:56:22,949:INFO: Batch: 16/31	Total Loss 11.7060 (11.3082)
2022-11-02 23:56:23,420:INFO: Batch: 17/31	Total Loss 11.4376 (11.3158)
2022-11-02 23:56:23,892:INFO: Batch: 18/31	Total Loss 12.7644 (11.3801)
2022-11-02 23:56:24,364:INFO: Batch: 19/31	Total Loss 11.2050 (11.3711)
2022-11-02 23:56:24,835:INFO: Batch: 20/31	Total Loss 12.7150 (11.4386)
2022-11-02 23:56:25,308:INFO: Batch: 21/31	Total Loss 11.2601 (11.4304)
2022-11-02 23:56:25,781:INFO: Batch: 22/31	Total Loss 11.9471 (11.4536)
2022-11-02 23:56:26,254:INFO: Batch: 23/31	Total Loss 10.5199 (11.4158)
2022-11-02 23:56:26,725:INFO: Batch: 24/31	Total Loss 11.0514 (11.4020)
2022-11-02 23:56:27,197:INFO: Batch: 25/31	Total Loss 10.0423 (11.3500)
2022-11-02 23:56:27,670:INFO: Batch: 26/31	Total Loss 10.6761 (11.3284)
2022-11-02 23:56:28,141:INFO: Batch: 27/31	Total Loss 9.7949 (11.2692)
2022-11-02 23:56:28,615:INFO: Batch: 28/31	Total Loss 11.0331 (11.2609)
2022-11-02 23:56:29,085:INFO: Batch: 29/31	Total Loss 12.0145 (11.2876)
2022-11-02 23:56:29,473:INFO: Batch: 30/31	Total Loss 4.5611 (11.2144)
2022-11-02 23:56:29,633:INFO: - Computing ADE (validation o)
2022-11-02 23:56:30,236:INFO: 		 ADE on eth                       dataset:	 1.2985235452651978
2022-11-02 23:56:30,237:INFO: Average validation o:	ADE  1.2985	FDE  1.9314
2022-11-02 23:56:30,237:INFO: - Computing ADE (validation)
2022-11-02 23:56:30,503:INFO: 		 ADE on hotel                     dataset:	 0.9902155995368958
2022-11-02 23:56:30,800:INFO: 		 ADE on univ                      dataset:	 0.9374983310699463
2022-11-02 23:56:31,059:INFO: 		 ADE on zara1                     dataset:	 1.0082041025161743
2022-11-02 23:56:31,401:INFO: 		 ADE on zara2                     dataset:	 0.7009833455085754
2022-11-02 23:56:31,401:INFO: Average validation:	ADE  0.8577	FDE  1.4421
2022-11-02 23:56:31,402:INFO: - Computing ADE (training)
2022-11-02 23:56:31,846:INFO: 		 ADE on hotel                     dataset:	 1.2763968706130981
2022-11-02 23:56:32,590:INFO: 		 ADE on univ                      dataset:	 0.8725278973579407
2022-11-02 23:56:33,156:INFO: 		 ADE on zara1                     dataset:	 1.0154286623001099
2022-11-02 23:56:33,900:INFO: 		 ADE on zara2                     dataset:	 0.776908814907074
2022-11-02 23:56:33,900:INFO: Average training:	ADE  0.8725	FDE  1.4812
2022-11-02 23:56:33,909:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_265.pth.tar
2022-11-02 23:56:33,909:INFO: 
===> EPOCH: 266 (P3)
2022-11-02 23:56:33,909:INFO: - Computing loss (training)
2022-11-02 23:56:35,004:INFO: Batch:  0/31	Total Loss 11.9315 (11.9315)
2022-11-02 23:56:35,471:INFO: Batch:  1/31	Total Loss 10.7468 (11.2915)
2022-11-02 23:56:35,950:INFO: Batch:  2/31	Total Loss 10.3562 (10.9468)
2022-11-02 23:56:36,419:INFO: Batch:  3/31	Total Loss 10.9505 (10.9478)
2022-11-02 23:56:36,892:INFO: Batch:  4/31	Total Loss 12.2524 (11.2123)
2022-11-02 23:56:37,366:INFO: Batch:  5/31	Total Loss 10.4662 (11.0889)
2022-11-02 23:56:37,837:INFO: Batch:  6/31	Total Loss 10.6606 (11.0329)
2022-11-02 23:56:38,307:INFO: Batch:  7/31	Total Loss 10.3600 (10.9528)
2022-11-02 23:56:38,777:INFO: Batch:  8/31	Total Loss 11.9469 (11.0613)
2022-11-02 23:56:39,248:INFO: Batch:  9/31	Total Loss 11.3135 (11.0851)
2022-11-02 23:56:39,721:INFO: Batch: 10/31	Total Loss 10.7434 (11.0495)
2022-11-02 23:56:40,193:INFO: Batch: 11/31	Total Loss 11.9881 (11.1273)
2022-11-02 23:56:40,668:INFO: Batch: 12/31	Total Loss 12.5536 (11.2349)
2022-11-02 23:56:41,143:INFO: Batch: 13/31	Total Loss 9.8479 (11.1371)
2022-11-02 23:56:41,616:INFO: Batch: 14/31	Total Loss 11.5524 (11.1637)
2022-11-02 23:56:42,089:INFO: Batch: 15/31	Total Loss 11.3556 (11.1759)
2022-11-02 23:56:42,566:INFO: Batch: 16/31	Total Loss 11.1576 (11.1748)
2022-11-02 23:56:43,041:INFO: Batch: 17/31	Total Loss 10.8751 (11.1584)
2022-11-02 23:56:43,516:INFO: Batch: 18/31	Total Loss 10.2875 (11.1086)
2022-11-02 23:56:43,990:INFO: Batch: 19/31	Total Loss 10.5567 (11.0784)
2022-11-02 23:56:44,464:INFO: Batch: 20/31	Total Loss 10.7028 (11.0608)
2022-11-02 23:56:44,937:INFO: Batch: 21/31	Total Loss 11.9346 (11.0944)
2022-11-02 23:56:45,411:INFO: Batch: 22/31	Total Loss 11.1888 (11.0984)
2022-11-02 23:56:45,885:INFO: Batch: 23/31	Total Loss 10.0329 (11.0505)
2022-11-02 23:56:46,363:INFO: Batch: 24/31	Total Loss 10.0499 (11.0056)
2022-11-02 23:56:46,837:INFO: Batch: 25/31	Total Loss 10.6625 (10.9919)
2022-11-02 23:56:47,311:INFO: Batch: 26/31	Total Loss 11.2504 (11.0007)
2022-11-02 23:56:47,784:INFO: Batch: 27/31	Total Loss 11.7089 (11.0270)
2022-11-02 23:56:48,259:INFO: Batch: 28/31	Total Loss 10.5604 (11.0104)
2022-11-02 23:56:48,732:INFO: Batch: 29/31	Total Loss 10.9341 (11.0080)
2022-11-02 23:56:49,123:INFO: Batch: 30/31	Total Loss 3.7569 (10.9373)
2022-11-02 23:56:49,281:INFO: - Computing ADE (validation o)
2022-11-02 23:56:49,930:INFO: 		 ADE on eth                       dataset:	 1.267242670059204
2022-11-02 23:56:49,931:INFO: Average validation o:	ADE  1.2672	FDE  1.8833
2022-11-02 23:56:49,931:INFO: - Computing ADE (validation)
2022-11-02 23:56:50,230:INFO: 		 ADE on hotel                     dataset:	 0.9836791157722473
2022-11-02 23:56:50,534:INFO: 		 ADE on univ                      dataset:	 0.9199941754341125
2022-11-02 23:56:50,811:INFO: 		 ADE on zara1                     dataset:	 0.9285238981246948
2022-11-02 23:56:51,177:INFO: 		 ADE on zara2                     dataset:	 0.6769115328788757
2022-11-02 23:56:51,177:INFO: Average validation:	ADE  0.8348	FDE  1.3970
2022-11-02 23:56:51,178:INFO: - Computing ADE (training)
2022-11-02 23:56:51,639:INFO: 		 ADE on hotel                     dataset:	 1.2684465646743774
2022-11-02 23:56:52,343:INFO: 		 ADE on univ                      dataset:	 0.8576256036758423
2022-11-02 23:56:52,880:INFO: 		 ADE on zara1                     dataset:	 0.9739537239074707
2022-11-02 23:56:53,648:INFO: 		 ADE on zara2                     dataset:	 0.7528681755065918
2022-11-02 23:56:53,649:INFO: Average training:	ADE  0.8542	FDE  1.4449
2022-11-02 23:56:53,658:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_266.pth.tar
2022-11-02 23:56:53,658:INFO: 
===> EPOCH: 267 (P3)
2022-11-02 23:56:53,658:INFO: - Computing loss (training)
2022-11-02 23:56:54,770:INFO: Batch:  0/31	Total Loss 11.9414 (11.9414)
2022-11-02 23:56:55,251:INFO: Batch:  1/31	Total Loss 10.4236 (11.1485)
2022-11-02 23:56:55,734:INFO: Batch:  2/31	Total Loss 10.9155 (11.0642)
2022-11-02 23:56:56,207:INFO: Batch:  3/31	Total Loss 11.4927 (11.1806)
2022-11-02 23:56:56,684:INFO: Batch:  4/31	Total Loss 9.9759 (10.9315)
2022-11-02 23:56:57,166:INFO: Batch:  5/31	Total Loss 11.0394 (10.9503)
2022-11-02 23:56:57,644:INFO: Batch:  6/31	Total Loss 10.0349 (10.8287)
2022-11-02 23:56:58,122:INFO: Batch:  7/31	Total Loss 11.4100 (10.9042)
2022-11-02 23:56:58,599:INFO: Batch:  8/31	Total Loss 11.5230 (10.9689)
2022-11-02 23:56:59,074:INFO: Batch:  9/31	Total Loss 10.6836 (10.9397)
2022-11-02 23:56:59,550:INFO: Batch: 10/31	Total Loss 10.9772 (10.9429)
2022-11-02 23:57:00,028:INFO: Batch: 11/31	Total Loss 10.2090 (10.8794)
2022-11-02 23:57:00,508:INFO: Batch: 12/31	Total Loss 12.3204 (10.9735)
2022-11-02 23:57:00,987:INFO: Batch: 13/31	Total Loss 10.0163 (10.9106)
2022-11-02 23:57:01,469:INFO: Batch: 14/31	Total Loss 11.4903 (10.9461)
2022-11-02 23:57:01,950:INFO: Batch: 15/31	Total Loss 11.0433 (10.9524)
2022-11-02 23:57:02,429:INFO: Batch: 16/31	Total Loss 11.3857 (10.9758)
2022-11-02 23:57:02,909:INFO: Batch: 17/31	Total Loss 9.3496 (10.8914)
2022-11-02 23:57:03,388:INFO: Batch: 18/31	Total Loss 9.0420 (10.8014)
2022-11-02 23:57:03,867:INFO: Batch: 19/31	Total Loss 11.3088 (10.8251)
2022-11-02 23:57:04,346:INFO: Batch: 20/31	Total Loss 10.7142 (10.8197)
2022-11-02 23:57:04,823:INFO: Batch: 21/31	Total Loss 11.2197 (10.8372)
2022-11-02 23:57:05,382:INFO: Batch: 22/31	Total Loss 10.3944 (10.8184)
2022-11-02 23:57:05,860:INFO: Batch: 23/31	Total Loss 10.5095 (10.8040)
2022-11-02 23:57:06,339:INFO: Batch: 24/31	Total Loss 10.6834 (10.7993)
2022-11-02 23:57:06,819:INFO: Batch: 25/31	Total Loss 11.0086 (10.8075)
2022-11-02 23:57:07,299:INFO: Batch: 26/31	Total Loss 10.8436 (10.8088)
2022-11-02 23:57:07,778:INFO: Batch: 27/31	Total Loss 11.9165 (10.8419)
2022-11-02 23:57:08,259:INFO: Batch: 28/31	Total Loss 10.4049 (10.8269)
2022-11-02 23:57:08,737:INFO: Batch: 29/31	Total Loss 10.9634 (10.8316)
2022-11-02 23:57:09,130:INFO: Batch: 30/31	Total Loss 5.2627 (10.7816)
2022-11-02 23:57:09,284:INFO: - Computing ADE (validation o)
2022-11-02 23:57:09,894:INFO: 		 ADE on eth                       dataset:	 1.2624635696411133
2022-11-02 23:57:09,894:INFO: Average validation o:	ADE  1.2625	FDE  1.8812
2022-11-02 23:57:09,895:INFO: - Computing ADE (validation)
2022-11-02 23:57:10,171:INFO: 		 ADE on hotel                     dataset:	 0.9819682240486145
2022-11-02 23:57:10,478:INFO: 		 ADE on univ                      dataset:	 0.9099323153495789
2022-11-02 23:57:10,736:INFO: 		 ADE on zara1                     dataset:	 0.8948453664779663
2022-11-02 23:57:11,092:INFO: 		 ADE on zara2                     dataset:	 0.6629828810691833
2022-11-02 23:57:11,092:INFO: Average validation:	ADE  0.8224	FDE  1.3741
2022-11-02 23:57:11,093:INFO: - Computing ADE (training)
2022-11-02 23:57:11,563:INFO: 		 ADE on hotel                     dataset:	 1.258091688156128
2022-11-02 23:57:12,248:INFO: 		 ADE on univ                      dataset:	 0.8495621681213379
2022-11-02 23:57:12,807:INFO: 		 ADE on zara1                     dataset:	 0.9526761770248413
2022-11-02 23:57:13,598:INFO: 		 ADE on zara2                     dataset:	 0.738613486289978
2022-11-02 23:57:13,598:INFO: Average training:	ADE  0.8440	FDE  1.4271
2022-11-02 23:57:13,607:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_267.pth.tar
2022-11-02 23:57:13,607:INFO: 
===> EPOCH: 268 (P3)
2022-11-02 23:57:13,607:INFO: - Computing loss (training)
2022-11-02 23:57:14,697:INFO: Batch:  0/31	Total Loss 11.1273 (11.1273)
2022-11-02 23:57:15,172:INFO: Batch:  1/31	Total Loss 11.5223 (11.3154)
2022-11-02 23:57:15,656:INFO: Batch:  2/31	Total Loss 9.8160 (10.8213)
2022-11-02 23:57:16,127:INFO: Batch:  3/31	Total Loss 10.2986 (10.6681)
2022-11-02 23:57:16,601:INFO: Batch:  4/31	Total Loss 12.0587 (10.9384)
2022-11-02 23:57:17,074:INFO: Batch:  5/31	Total Loss 10.4230 (10.8545)
2022-11-02 23:57:17,551:INFO: Batch:  6/31	Total Loss 10.3575 (10.7753)
2022-11-02 23:57:18,022:INFO: Batch:  7/31	Total Loss 11.4753 (10.8537)
2022-11-02 23:57:18,496:INFO: Batch:  8/31	Total Loss 10.1359 (10.7716)
2022-11-02 23:57:18,967:INFO: Batch:  9/31	Total Loss 10.2608 (10.7221)
2022-11-02 23:57:19,439:INFO: Batch: 10/31	Total Loss 11.7909 (10.8293)
2022-11-02 23:57:19,914:INFO: Batch: 11/31	Total Loss 10.1176 (10.7649)
2022-11-02 23:57:20,389:INFO: Batch: 12/31	Total Loss 9.0913 (10.6371)
2022-11-02 23:57:20,866:INFO: Batch: 13/31	Total Loss 10.0727 (10.5945)
2022-11-02 23:57:21,343:INFO: Batch: 14/31	Total Loss 9.9016 (10.5439)
2022-11-02 23:57:21,819:INFO: Batch: 15/31	Total Loss 12.5155 (10.6606)
2022-11-02 23:57:22,300:INFO: Batch: 16/31	Total Loss 10.3853 (10.6456)
2022-11-02 23:57:22,776:INFO: Batch: 17/31	Total Loss 10.4057 (10.6321)
2022-11-02 23:57:23,253:INFO: Batch: 18/31	Total Loss 11.4608 (10.6761)
2022-11-02 23:57:23,728:INFO: Batch: 19/31	Total Loss 11.0806 (10.6955)
2022-11-02 23:57:24,203:INFO: Batch: 20/31	Total Loss 11.0254 (10.7103)
2022-11-02 23:57:24,678:INFO: Batch: 21/31	Total Loss 10.7867 (10.7137)
2022-11-02 23:57:25,155:INFO: Batch: 22/31	Total Loss 10.1449 (10.6869)
2022-11-02 23:57:25,630:INFO: Batch: 23/31	Total Loss 11.9075 (10.7344)
2022-11-02 23:57:26,107:INFO: Batch: 24/31	Total Loss 12.6858 (10.8071)
2022-11-02 23:57:26,585:INFO: Batch: 25/31	Total Loss 11.2925 (10.8268)
2022-11-02 23:57:27,064:INFO: Batch: 26/31	Total Loss 11.2826 (10.8456)
2022-11-02 23:57:27,544:INFO: Batch: 27/31	Total Loss 10.3551 (10.8275)
2022-11-02 23:57:28,021:INFO: Batch: 28/31	Total Loss 10.8453 (10.8281)
2022-11-02 23:57:28,502:INFO: Batch: 29/31	Total Loss 11.9134 (10.8638)
2022-11-02 23:57:28,894:INFO: Batch: 30/31	Total Loss 4.2396 (10.7984)
2022-11-02 23:57:29,044:INFO: - Computing ADE (validation o)
2022-11-02 23:57:29,613:INFO: 		 ADE on eth                       dataset:	 1.2270569801330566
2022-11-02 23:57:29,613:INFO: Average validation o:	ADE  1.2271	FDE  1.9090
2022-11-02 23:57:29,613:INFO: - Computing ADE (validation)
2022-11-02 23:57:29,876:INFO: 		 ADE on hotel                     dataset:	 0.9944150447845459
2022-11-02 23:57:30,170:INFO: 		 ADE on univ                      dataset:	 0.9215160608291626
2022-11-02 23:57:30,427:INFO: 		 ADE on zara1                     dataset:	 0.9121941328048706
2022-11-02 23:57:30,792:INFO: 		 ADE on zara2                     dataset:	 0.6686596870422363
2022-11-02 23:57:30,793:INFO: Average validation:	ADE  0.8322	FDE  1.4351
2022-11-02 23:57:30,794:INFO: - Computing ADE (training)
2022-11-02 23:57:31,250:INFO: 		 ADE on hotel                     dataset:	 1.281005620956421
2022-11-02 23:57:31,942:INFO: 		 ADE on univ                      dataset:	 0.8617622256278992
2022-11-02 23:57:32,471:INFO: 		 ADE on zara1                     dataset:	 0.9151219129562378
2022-11-02 23:57:33,228:INFO: 		 ADE on zara2                     dataset:	 0.7264677882194519
2022-11-02 23:57:33,228:INFO: Average training:	ADE  0.8484	FDE  1.4747
2022-11-02 23:57:33,237:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_268.pth.tar
2022-11-02 23:57:33,237:INFO: 
===> EPOCH: 269 (P3)
2022-11-02 23:57:33,237:INFO: - Computing loss (training)
2022-11-02 23:57:34,381:INFO: Batch:  0/31	Total Loss 12.1368 (12.1368)
2022-11-02 23:57:34,853:INFO: Batch:  1/31	Total Loss 10.4504 (11.2836)
2022-11-02 23:57:35,327:INFO: Batch:  2/31	Total Loss 9.3212 (10.5894)
2022-11-02 23:57:35,797:INFO: Batch:  3/31	Total Loss 12.2782 (11.0317)
2022-11-02 23:57:36,267:INFO: Batch:  4/31	Total Loss 10.1957 (10.8593)
2022-11-02 23:57:36,736:INFO: Batch:  5/31	Total Loss 10.3362 (10.7758)
2022-11-02 23:57:37,208:INFO: Batch:  6/31	Total Loss 10.5514 (10.7457)
2022-11-02 23:57:37,678:INFO: Batch:  7/31	Total Loss 10.3431 (10.6930)
2022-11-02 23:57:38,150:INFO: Batch:  8/31	Total Loss 9.7610 (10.5827)
2022-11-02 23:57:38,620:INFO: Batch:  9/31	Total Loss 9.8597 (10.5059)
2022-11-02 23:57:39,091:INFO: Batch: 10/31	Total Loss 10.5947 (10.5139)
2022-11-02 23:57:39,562:INFO: Batch: 11/31	Total Loss 10.7125 (10.5318)
2022-11-02 23:57:40,037:INFO: Batch: 12/31	Total Loss 10.5618 (10.5339)
2022-11-02 23:57:40,510:INFO: Batch: 13/31	Total Loss 10.5306 (10.5337)
2022-11-02 23:57:40,983:INFO: Batch: 14/31	Total Loss 10.2835 (10.5171)
2022-11-02 23:57:41,457:INFO: Batch: 15/31	Total Loss 10.2652 (10.5015)
2022-11-02 23:57:41,930:INFO: Batch: 16/31	Total Loss 11.3059 (10.5508)
2022-11-02 23:57:42,404:INFO: Batch: 17/31	Total Loss 10.2282 (10.5355)
2022-11-02 23:57:42,878:INFO: Batch: 18/31	Total Loss 10.9980 (10.5605)
2022-11-02 23:57:43,351:INFO: Batch: 19/31	Total Loss 9.9680 (10.5311)
2022-11-02 23:57:43,824:INFO: Batch: 20/31	Total Loss 9.9095 (10.4967)
2022-11-02 23:57:44,296:INFO: Batch: 21/31	Total Loss 10.5318 (10.4982)
2022-11-02 23:57:44,768:INFO: Batch: 22/31	Total Loss 8.7126 (10.4206)
2022-11-02 23:57:45,242:INFO: Batch: 23/31	Total Loss 11.9222 (10.4907)
2022-11-02 23:57:45,715:INFO: Batch: 24/31	Total Loss 10.8723 (10.5067)
2022-11-02 23:57:46,186:INFO: Batch: 25/31	Total Loss 11.3233 (10.5371)
2022-11-02 23:57:46,659:INFO: Batch: 26/31	Total Loss 10.8223 (10.5480)
2022-11-02 23:57:47,129:INFO: Batch: 27/31	Total Loss 11.9267 (10.5970)
2022-11-02 23:57:47,602:INFO: Batch: 28/31	Total Loss 11.5118 (10.6280)
2022-11-02 23:57:48,074:INFO: Batch: 29/31	Total Loss 10.3842 (10.6206)
2022-11-02 23:57:48,463:INFO: Batch: 30/31	Total Loss 5.9727 (10.5825)
2022-11-02 23:57:48,618:INFO: - Computing ADE (validation o)
2022-11-02 23:57:49,229:INFO: 		 ADE on eth                       dataset:	 1.2624857425689697
2022-11-02 23:57:49,229:INFO: Average validation o:	ADE  1.2625	FDE  1.9029
2022-11-02 23:57:49,230:INFO: - Computing ADE (validation)
2022-11-02 23:57:49,488:INFO: 		 ADE on hotel                     dataset:	 1.0002378225326538
2022-11-02 23:57:49,789:INFO: 		 ADE on univ                      dataset:	 0.9103803038597107
2022-11-02 23:57:50,030:INFO: 		 ADE on zara1                     dataset:	 0.8364977836608887
2022-11-02 23:57:50,384:INFO: 		 ADE on zara2                     dataset:	 0.6645476222038269
2022-11-02 23:57:50,384:INFO: Average validation:	ADE  0.8208	FDE  1.4084
2022-11-02 23:57:50,385:INFO: - Computing ADE (training)
2022-11-02 23:57:50,824:INFO: 		 ADE on hotel                     dataset:	 1.2622579336166382
2022-11-02 23:57:51,508:INFO: 		 ADE on univ                      dataset:	 0.8472003936767578
2022-11-02 23:57:52,027:INFO: 		 ADE on zara1                     dataset:	 0.9340380430221558
2022-11-02 23:57:52,798:INFO: 		 ADE on zara2                     dataset:	 0.7400575280189514
2022-11-02 23:57:52,799:INFO: Average training:	ADE  0.8415	FDE  1.4574
2022-11-02 23:57:52,808:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_269.pth.tar
2022-11-02 23:57:52,808:INFO: 
===> EPOCH: 270 (P3)
2022-11-02 23:57:52,809:INFO: - Computing loss (training)
2022-11-02 23:57:53,898:INFO: Batch:  0/31	Total Loss 9.0209 (9.0209)
2022-11-02 23:57:54,380:INFO: Batch:  1/31	Total Loss 11.6821 (10.2934)
2022-11-02 23:57:54,857:INFO: Batch:  2/31	Total Loss 10.6230 (10.3926)
2022-11-02 23:57:55,341:INFO: Batch:  3/31	Total Loss 10.8903 (10.5213)
2022-11-02 23:57:55,817:INFO: Batch:  4/31	Total Loss 9.9653 (10.4134)
2022-11-02 23:57:56,298:INFO: Batch:  5/31	Total Loss 9.7654 (10.3031)
2022-11-02 23:57:56,776:INFO: Batch:  6/31	Total Loss 10.9145 (10.3902)
2022-11-02 23:57:57,246:INFO: Batch:  7/31	Total Loss 12.4329 (10.6201)
2022-11-02 23:57:57,716:INFO: Batch:  8/31	Total Loss 9.9294 (10.5421)
2022-11-02 23:57:58,269:INFO: Batch:  9/31	Total Loss 10.3692 (10.5260)
2022-11-02 23:57:58,740:INFO: Batch: 10/31	Total Loss 11.6740 (10.6389)
2022-11-02 23:57:59,213:INFO: Batch: 11/31	Total Loss 10.7545 (10.6480)
2022-11-02 23:57:59,692:INFO: Batch: 12/31	Total Loss 9.8781 (10.5925)
2022-11-02 23:58:00,170:INFO: Batch: 13/31	Total Loss 10.4512 (10.5824)
2022-11-02 23:58:00,646:INFO: Batch: 14/31	Total Loss 9.6149 (10.5102)
2022-11-02 23:58:01,120:INFO: Batch: 15/31	Total Loss 9.6495 (10.4517)
2022-11-02 23:58:01,598:INFO: Batch: 16/31	Total Loss 10.7344 (10.4687)
2022-11-02 23:58:02,072:INFO: Batch: 17/31	Total Loss 10.0973 (10.4510)
2022-11-02 23:58:02,547:INFO: Batch: 18/31	Total Loss 11.1657 (10.4884)
2022-11-02 23:58:03,021:INFO: Batch: 19/31	Total Loss 10.8876 (10.5086)
2022-11-02 23:58:03,496:INFO: Batch: 20/31	Total Loss 10.3895 (10.5029)
2022-11-02 23:58:03,969:INFO: Batch: 21/31	Total Loss 10.0813 (10.4822)
2022-11-02 23:58:04,442:INFO: Batch: 22/31	Total Loss 9.6863 (10.4497)
2022-11-02 23:58:04,924:INFO: Batch: 23/31	Total Loss 10.4066 (10.4479)
2022-11-02 23:58:05,404:INFO: Batch: 24/31	Total Loss 10.8456 (10.4640)
2022-11-02 23:58:05,881:INFO: Batch: 25/31	Total Loss 11.5846 (10.5085)
2022-11-02 23:58:06,360:INFO: Batch: 26/31	Total Loss 11.4889 (10.5428)
2022-11-02 23:58:06,841:INFO: Batch: 27/31	Total Loss 9.6772 (10.5103)
2022-11-02 23:58:07,321:INFO: Batch: 28/31	Total Loss 10.2769 (10.5019)
2022-11-02 23:58:07,800:INFO: Batch: 29/31	Total Loss 10.4758 (10.5010)
2022-11-02 23:58:08,193:INFO: Batch: 30/31	Total Loss 4.8816 (10.4506)
2022-11-02 23:58:08,350:INFO: - Computing ADE (validation o)
2022-11-02 23:58:08,956:INFO: 		 ADE on eth                       dataset:	 1.2292859554290771
2022-11-02 23:58:08,956:INFO: Average validation o:	ADE  1.2293	FDE  1.8169
2022-11-02 23:58:08,957:INFO: - Computing ADE (validation)
2022-11-02 23:58:09,228:INFO: 		 ADE on hotel                     dataset:	 0.9568808078765869
2022-11-02 23:58:09,523:INFO: 		 ADE on univ                      dataset:	 0.8922861218452454
2022-11-02 23:58:09,780:INFO: 		 ADE on zara1                     dataset:	 0.831070065498352
2022-11-02 23:58:10,132:INFO: 		 ADE on zara2                     dataset:	 0.6313019394874573
2022-11-02 23:58:10,132:INFO: Average validation:	ADE  0.7965	FDE  1.3388
2022-11-02 23:58:10,133:INFO: - Computing ADE (training)
2022-11-02 23:58:10,579:INFO: 		 ADE on hotel                     dataset:	 1.2285338640213013
2022-11-02 23:58:11,258:INFO: 		 ADE on univ                      dataset:	 0.8277651071548462
2022-11-02 23:58:11,823:INFO: 		 ADE on zara1                     dataset:	 0.9021836519241333
2022-11-02 23:58:12,615:INFO: 		 ADE on zara2                     dataset:	 0.6987442970275879
2022-11-02 23:58:12,615:INFO: Average training:	ADE  0.8165	FDE  1.3860
2022-11-02 23:58:12,623:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_270.pth.tar
2022-11-02 23:58:12,624:INFO: 
===> EPOCH: 271 (P3)
2022-11-02 23:58:12,624:INFO: - Computing loss (training)
2022-11-02 23:58:13,712:INFO: Batch:  0/31	Total Loss 10.4986 (10.4986)
2022-11-02 23:58:14,205:INFO: Batch:  1/31	Total Loss 10.1981 (10.3491)
2022-11-02 23:58:14,682:INFO: Batch:  2/31	Total Loss 9.3660 (10.0089)
2022-11-02 23:58:15,161:INFO: Batch:  3/31	Total Loss 9.4319 (9.8604)
2022-11-02 23:58:15,638:INFO: Batch:  4/31	Total Loss 10.9609 (10.0623)
2022-11-02 23:58:16,111:INFO: Batch:  5/31	Total Loss 10.0057 (10.0537)
2022-11-02 23:58:16,583:INFO: Batch:  6/31	Total Loss 9.4200 (9.9600)
2022-11-02 23:58:17,057:INFO: Batch:  7/31	Total Loss 9.9960 (9.9646)
2022-11-02 23:58:17,522:INFO: Batch:  8/31	Total Loss 9.7581 (9.9398)
2022-11-02 23:58:17,993:INFO: Batch:  9/31	Total Loss 11.0461 (10.0383)
2022-11-02 23:58:18,465:INFO: Batch: 10/31	Total Loss 9.1779 (9.9609)
2022-11-02 23:58:18,934:INFO: Batch: 11/31	Total Loss 10.7232 (10.0181)
2022-11-02 23:58:19,406:INFO: Batch: 12/31	Total Loss 10.1629 (10.0297)
2022-11-02 23:58:19,880:INFO: Batch: 13/31	Total Loss 10.0873 (10.0336)
2022-11-02 23:58:20,353:INFO: Batch: 14/31	Total Loss 10.3702 (10.0564)
2022-11-02 23:58:20,825:INFO: Batch: 15/31	Total Loss 12.3747 (10.2043)
2022-11-02 23:58:21,299:INFO: Batch: 16/31	Total Loss 11.5150 (10.2838)
2022-11-02 23:58:21,771:INFO: Batch: 17/31	Total Loss 10.1044 (10.2749)
2022-11-02 23:58:22,243:INFO: Batch: 18/31	Total Loss 9.9148 (10.2550)
2022-11-02 23:58:22,714:INFO: Batch: 19/31	Total Loss 10.4318 (10.2640)
2022-11-02 23:58:23,184:INFO: Batch: 20/31	Total Loss 10.1343 (10.2579)
2022-11-02 23:58:23,656:INFO: Batch: 21/31	Total Loss 10.8825 (10.2850)
2022-11-02 23:58:24,127:INFO: Batch: 22/31	Total Loss 9.9645 (10.2695)
2022-11-02 23:58:24,600:INFO: Batch: 23/31	Total Loss 10.2068 (10.2672)
2022-11-02 23:58:25,072:INFO: Batch: 24/31	Total Loss 10.1967 (10.2643)
2022-11-02 23:58:25,545:INFO: Batch: 25/31	Total Loss 10.4209 (10.2708)
2022-11-02 23:58:26,017:INFO: Batch: 26/31	Total Loss 9.6059 (10.2476)
2022-11-02 23:58:26,487:INFO: Batch: 27/31	Total Loss 9.9968 (10.2386)
2022-11-02 23:58:26,958:INFO: Batch: 28/31	Total Loss 9.6122 (10.2170)
2022-11-02 23:58:27,428:INFO: Batch: 29/31	Total Loss 10.3614 (10.2217)
2022-11-02 23:58:27,816:INFO: Batch: 30/31	Total Loss 4.2598 (10.1627)
2022-11-02 23:58:27,970:INFO: - Computing ADE (validation o)
2022-11-02 23:58:28,554:INFO: 		 ADE on eth                       dataset:	 1.2426624298095703
2022-11-02 23:58:28,555:INFO: Average validation o:	ADE  1.2427	FDE  1.8656
2022-11-02 23:58:28,555:INFO: - Computing ADE (validation)
2022-11-02 23:58:28,822:INFO: 		 ADE on hotel                     dataset:	 0.9436146020889282
2022-11-02 23:58:29,131:INFO: 		 ADE on univ                      dataset:	 0.8872395157814026
2022-11-02 23:58:29,389:INFO: 		 ADE on zara1                     dataset:	 0.8662300705909729
2022-11-02 23:58:29,746:INFO: 		 ADE on zara2                     dataset:	 0.6416614651679993
2022-11-02 23:58:29,746:INFO: Average validation:	ADE  0.7990	FDE  1.3470
2022-11-02 23:58:29,747:INFO: - Computing ADE (training)
2022-11-02 23:58:30,188:INFO: 		 ADE on hotel                     dataset:	 1.219162106513977
2022-11-02 23:58:30,877:INFO: 		 ADE on univ                      dataset:	 0.8306018710136414
2022-11-02 23:58:31,431:INFO: 		 ADE on zara1                     dataset:	 0.9195711016654968
2022-11-02 23:58:32,159:INFO: 		 ADE on zara2                     dataset:	 0.7097495198249817
2022-11-02 23:58:32,159:INFO: Average training:	ADE  0.8216	FDE  1.4001
2022-11-02 23:58:32,168:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_271.pth.tar
2022-11-02 23:58:32,168:INFO: 
===> EPOCH: 272 (P3)
2022-11-02 23:58:32,168:INFO: - Computing loss (training)
2022-11-02 23:58:33,295:INFO: Batch:  0/31	Total Loss 10.3595 (10.3595)
2022-11-02 23:58:33,768:INFO: Batch:  1/31	Total Loss 10.9467 (10.6691)
2022-11-02 23:58:34,248:INFO: Batch:  2/31	Total Loss 11.3741 (10.9041)
2022-11-02 23:58:34,723:INFO: Batch:  3/31	Total Loss 10.8528 (10.8924)
2022-11-02 23:58:35,201:INFO: Batch:  4/31	Total Loss 9.2834 (10.5569)
2022-11-02 23:58:35,676:INFO: Batch:  5/31	Total Loss 9.4489 (10.3446)
2022-11-02 23:58:36,149:INFO: Batch:  6/31	Total Loss 9.6886 (10.2476)
2022-11-02 23:58:36,623:INFO: Batch:  7/31	Total Loss 9.4423 (10.1419)
2022-11-02 23:58:37,096:INFO: Batch:  8/31	Total Loss 9.6876 (10.0937)
2022-11-02 23:58:37,570:INFO: Batch:  9/31	Total Loss 9.6625 (10.0555)
2022-11-02 23:58:38,045:INFO: Batch: 10/31	Total Loss 10.4665 (10.0951)
2022-11-02 23:58:38,518:INFO: Batch: 11/31	Total Loss 9.9829 (10.0860)
2022-11-02 23:58:38,995:INFO: Batch: 12/31	Total Loss 11.0475 (10.1528)
2022-11-02 23:58:39,474:INFO: Batch: 13/31	Total Loss 10.3613 (10.1689)
2022-11-02 23:58:39,956:INFO: Batch: 14/31	Total Loss 10.6204 (10.1978)
2022-11-02 23:58:40,434:INFO: Batch: 15/31	Total Loss 9.5028 (10.1513)
2022-11-02 23:58:40,914:INFO: Batch: 16/31	Total Loss 9.4887 (10.1119)
2022-11-02 23:58:41,397:INFO: Batch: 17/31	Total Loss 11.7210 (10.2045)
2022-11-02 23:58:41,879:INFO: Batch: 18/31	Total Loss 10.5492 (10.2218)
2022-11-02 23:58:42,361:INFO: Batch: 19/31	Total Loss 9.7673 (10.2005)
2022-11-02 23:58:42,840:INFO: Batch: 20/31	Total Loss 10.4151 (10.2099)
2022-11-02 23:58:43,324:INFO: Batch: 21/31	Total Loss 11.0194 (10.2435)
2022-11-02 23:58:43,803:INFO: Batch: 22/31	Total Loss 9.5338 (10.2113)
2022-11-02 23:58:44,283:INFO: Batch: 23/31	Total Loss 10.1825 (10.2101)
2022-11-02 23:58:44,762:INFO: Batch: 24/31	Total Loss 10.1702 (10.2084)
2022-11-02 23:58:45,241:INFO: Batch: 25/31	Total Loss 9.8932 (10.1945)
2022-11-02 23:58:45,722:INFO: Batch: 26/31	Total Loss 9.9199 (10.1854)
2022-11-02 23:58:46,201:INFO: Batch: 27/31	Total Loss 11.0102 (10.2163)
2022-11-02 23:58:46,680:INFO: Batch: 28/31	Total Loss 10.5294 (10.2272)
2022-11-02 23:58:47,159:INFO: Batch: 29/31	Total Loss 9.9324 (10.2164)
2022-11-02 23:58:47,552:INFO: Batch: 30/31	Total Loss 4.3682 (10.1560)
2022-11-02 23:58:47,707:INFO: - Computing ADE (validation o)
2022-11-02 23:58:48,304:INFO: 		 ADE on eth                       dataset:	 1.2670953273773193
2022-11-02 23:58:48,304:INFO: Average validation o:	ADE  1.2671	FDE  1.8950
2022-11-02 23:58:48,305:INFO: - Computing ADE (validation)
2022-11-02 23:58:48,570:INFO: 		 ADE on hotel                     dataset:	 0.9497689604759216
2022-11-02 23:58:48,863:INFO: 		 ADE on univ                      dataset:	 0.8909842371940613
2022-11-02 23:58:49,122:INFO: 		 ADE on zara1                     dataset:	 0.8267403841018677
2022-11-02 23:58:49,462:INFO: 		 ADE on zara2                     dataset:	 0.6462668180465698
2022-11-02 23:58:49,463:INFO: Average validation:	ADE  0.8007	FDE  1.3599
2022-11-02 23:58:49,463:INFO: - Computing ADE (training)
2022-11-02 23:58:49,919:INFO: 		 ADE on hotel                     dataset:	 1.2135778665542603
2022-11-02 23:58:50,589:INFO: 		 ADE on univ                      dataset:	 0.8272000551223755
2022-11-02 23:58:51,169:INFO: 		 ADE on zara1                     dataset:	 0.9278504252433777
2022-11-02 23:58:51,938:INFO: 		 ADE on zara2                     dataset:	 0.7224436402320862
2022-11-02 23:58:51,938:INFO: Average training:	ADE  0.8222	FDE  1.4070
2022-11-02 23:58:51,946:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_272.pth.tar
2022-11-02 23:58:51,947:INFO: 
===> EPOCH: 273 (P3)
2022-11-02 23:58:51,947:INFO: - Computing loss (training)
2022-11-02 23:58:53,111:INFO: Batch:  0/31	Total Loss 12.6569 (12.6569)
2022-11-02 23:58:53,589:INFO: Batch:  1/31	Total Loss 9.6981 (11.0663)
2022-11-02 23:58:54,077:INFO: Batch:  2/31	Total Loss 10.4741 (10.8745)
2022-11-02 23:58:54,557:INFO: Batch:  3/31	Total Loss 10.0964 (10.6813)
2022-11-02 23:58:55,038:INFO: Batch:  4/31	Total Loss 9.0966 (10.3688)
2022-11-02 23:58:55,525:INFO: Batch:  5/31	Total Loss 10.1250 (10.3310)
2022-11-02 23:58:56,009:INFO: Batch:  6/31	Total Loss 9.6648 (10.2250)
2022-11-02 23:58:56,491:INFO: Batch:  7/31	Total Loss 9.8933 (10.1823)
2022-11-02 23:58:56,972:INFO: Batch:  8/31	Total Loss 11.2215 (10.3016)
2022-11-02 23:58:57,452:INFO: Batch:  9/31	Total Loss 9.3174 (10.1874)
2022-11-02 23:58:57,933:INFO: Batch: 10/31	Total Loss 10.1017 (10.1793)
2022-11-02 23:58:58,421:INFO: Batch: 11/31	Total Loss 10.1308 (10.1750)
2022-11-02 23:58:58,906:INFO: Batch: 12/31	Total Loss 9.6895 (10.1367)
2022-11-02 23:58:59,392:INFO: Batch: 13/31	Total Loss 11.0427 (10.2069)
2022-11-02 23:58:59,882:INFO: Batch: 14/31	Total Loss 9.1986 (10.1334)
2022-11-02 23:59:00,370:INFO: Batch: 15/31	Total Loss 9.0420 (10.0655)
2022-11-02 23:59:00,854:INFO: Batch: 16/31	Total Loss 8.3287 (9.9573)
2022-11-02 23:59:01,351:INFO: Batch: 17/31	Total Loss 10.0142 (9.9604)
2022-11-02 23:59:01,828:INFO: Batch: 18/31	Total Loss 10.3113 (9.9793)
2022-11-02 23:59:02,303:INFO: Batch: 19/31	Total Loss 9.4140 (9.9490)
2022-11-02 23:59:02,776:INFO: Batch: 20/31	Total Loss 10.2024 (9.9619)
2022-11-02 23:59:03,249:INFO: Batch: 21/31	Total Loss 10.0625 (9.9669)
2022-11-02 23:59:03,725:INFO: Batch: 22/31	Total Loss 8.9450 (9.9209)
2022-11-02 23:59:04,198:INFO: Batch: 23/31	Total Loss 9.4826 (9.9043)
2022-11-02 23:59:04,672:INFO: Batch: 24/31	Total Loss 9.9807 (9.9073)
2022-11-02 23:59:05,146:INFO: Batch: 25/31	Total Loss 9.8539 (9.9052)
2022-11-02 23:59:05,621:INFO: Batch: 26/31	Total Loss 9.8479 (9.9031)
2022-11-02 23:59:06,096:INFO: Batch: 27/31	Total Loss 9.1294 (9.8768)
2022-11-02 23:59:06,568:INFO: Batch: 28/31	Total Loss 10.2889 (9.8906)
2022-11-02 23:59:07,042:INFO: Batch: 29/31	Total Loss 9.3574 (9.8739)
2022-11-02 23:59:07,432:INFO: Batch: 30/31	Total Loss 4.3713 (9.8155)
2022-11-02 23:59:07,586:INFO: - Computing ADE (validation o)
2022-11-02 23:59:08,203:INFO: 		 ADE on eth                       dataset:	 1.2289584875106812
2022-11-02 23:59:08,203:INFO: Average validation o:	ADE  1.2290	FDE  1.8605
2022-11-02 23:59:08,204:INFO: - Computing ADE (validation)
2022-11-02 23:59:08,469:INFO: 		 ADE on hotel                     dataset:	 0.9327074885368347
2022-11-02 23:59:08,764:INFO: 		 ADE on univ                      dataset:	 0.8822159171104431
2022-11-02 23:59:09,015:INFO: 		 ADE on zara1                     dataset:	 0.8381862640380859
2022-11-02 23:59:09,368:INFO: 		 ADE on zara2                     dataset:	 0.6291012763977051
2022-11-02 23:59:09,368:INFO: Average validation:	ADE  0.7896	FDE  1.3376
2022-11-02 23:59:09,369:INFO: - Computing ADE (training)
2022-11-02 23:59:09,818:INFO: 		 ADE on hotel                     dataset:	 1.1935393810272217
2022-11-02 23:59:10,494:INFO: 		 ADE on univ                      dataset:	 0.8182495832443237
2022-11-02 23:59:11,027:INFO: 		 ADE on zara1                     dataset:	 0.8984766602516174
2022-11-02 23:59:11,827:INFO: 		 ADE on zara2                     dataset:	 0.6937238574028015
2022-11-02 23:59:11,828:INFO: Average training:	ADE  0.8076	FDE  1.3810
2022-11-02 23:59:11,836:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_273.pth.tar
2022-11-02 23:59:11,836:INFO: 
===> EPOCH: 274 (P3)
2022-11-02 23:59:11,836:INFO: - Computing loss (training)
2022-11-02 23:59:12,915:INFO: Batch:  0/31	Total Loss 10.7809 (10.7809)
2022-11-02 23:59:13,382:INFO: Batch:  1/31	Total Loss 10.4115 (10.6032)
2022-11-02 23:59:13,856:INFO: Batch:  2/31	Total Loss 8.6039 (9.8831)
2022-11-02 23:59:14,325:INFO: Batch:  3/31	Total Loss 9.7978 (9.8608)
2022-11-02 23:59:14,793:INFO: Batch:  4/31	Total Loss 10.0817 (9.9053)
2022-11-02 23:59:15,262:INFO: Batch:  5/31	Total Loss 10.2343 (9.9636)
2022-11-02 23:59:15,731:INFO: Batch:  6/31	Total Loss 9.4328 (9.8819)
2022-11-02 23:59:16,197:INFO: Batch:  7/31	Total Loss 10.0357 (9.9007)
2022-11-02 23:59:16,662:INFO: Batch:  8/31	Total Loss 9.4993 (9.8562)
2022-11-02 23:59:17,128:INFO: Batch:  9/31	Total Loss 9.4134 (9.8124)
2022-11-02 23:59:17,595:INFO: Batch: 10/31	Total Loss 9.4320 (9.7752)
2022-11-02 23:59:18,061:INFO: Batch: 11/31	Total Loss 9.7201 (9.7708)
2022-11-02 23:59:18,536:INFO: Batch: 12/31	Total Loss 9.2533 (9.7285)
2022-11-02 23:59:19,005:INFO: Batch: 13/31	Total Loss 8.6077 (9.6459)
2022-11-02 23:59:19,481:INFO: Batch: 14/31	Total Loss 9.1669 (9.6185)
2022-11-02 23:59:19,954:INFO: Batch: 15/31	Total Loss 11.1160 (9.7070)
2022-11-02 23:59:20,427:INFO: Batch: 16/31	Total Loss 8.9566 (9.6665)
2022-11-02 23:59:20,896:INFO: Batch: 17/31	Total Loss 10.3382 (9.6985)
2022-11-02 23:59:21,368:INFO: Batch: 18/31	Total Loss 11.3311 (9.7814)
2022-11-02 23:59:21,842:INFO: Batch: 19/31	Total Loss 10.6049 (9.8238)
2022-11-02 23:59:22,313:INFO: Batch: 20/31	Total Loss 9.0852 (9.7862)
2022-11-02 23:59:22,781:INFO: Batch: 21/31	Total Loss 9.3432 (9.7670)
2022-11-02 23:59:23,250:INFO: Batch: 22/31	Total Loss 11.1328 (9.8281)
2022-11-02 23:59:23,719:INFO: Batch: 23/31	Total Loss 9.9256 (9.8319)
2022-11-02 23:59:24,188:INFO: Batch: 24/31	Total Loss 9.7633 (9.8295)
2022-11-02 23:59:24,658:INFO: Batch: 25/31	Total Loss 11.1252 (9.8837)
2022-11-02 23:59:25,127:INFO: Batch: 26/31	Total Loss 10.7201 (9.9120)
2022-11-02 23:59:25,596:INFO: Batch: 27/31	Total Loss 9.0685 (9.8784)
2022-11-02 23:59:26,065:INFO: Batch: 28/31	Total Loss 10.2648 (9.8905)
2022-11-02 23:59:26,535:INFO: Batch: 29/31	Total Loss 10.3360 (9.9063)
2022-11-02 23:59:26,920:INFO: Batch: 30/31	Total Loss 3.6527 (9.8375)
2022-11-02 23:59:27,070:INFO: - Computing ADE (validation o)
2022-11-02 23:59:27,694:INFO: 		 ADE on eth                       dataset:	 1.2386499643325806
2022-11-02 23:59:27,694:INFO: Average validation o:	ADE  1.2386	FDE  1.9446
2022-11-02 23:59:27,695:INFO: - Computing ADE (validation)
2022-11-02 23:59:27,971:INFO: 		 ADE on hotel                     dataset:	 0.9540731906890869
2022-11-02 23:59:28,266:INFO: 		 ADE on univ                      dataset:	 0.8956378102302551
2022-11-02 23:59:28,530:INFO: 		 ADE on zara1                     dataset:	 0.8909857869148254
2022-11-02 23:59:28,895:INFO: 		 ADE on zara2                     dataset:	 0.6642705798149109
2022-11-02 23:59:28,896:INFO: Average validation:	ADE  0.8137	FDE  1.4238
2022-11-02 23:59:28,896:INFO: - Computing ADE (training)
2022-11-02 23:59:29,362:INFO: 		 ADE on hotel                     dataset:	 1.2133584022521973
2022-11-02 23:59:30,034:INFO: 		 ADE on univ                      dataset:	 0.8406408429145813
2022-11-02 23:59:30,556:INFO: 		 ADE on zara1                     dataset:	 0.9111128449440002
2022-11-02 23:59:31,335:INFO: 		 ADE on zara2                     dataset:	 0.7181144952774048
2022-11-02 23:59:31,335:INFO: Average training:	ADE  0.8297	FDE  1.4633
2022-11-02 23:59:31,343:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_274.pth.tar
2022-11-02 23:59:31,343:INFO: 
===> EPOCH: 275 (P3)
2022-11-02 23:59:31,344:INFO: - Computing loss (training)
2022-11-02 23:59:32,468:INFO: Batch:  0/31	Total Loss 8.5674 (8.5674)
2022-11-02 23:59:32,947:INFO: Batch:  1/31	Total Loss 8.4867 (8.5231)
2022-11-02 23:59:33,433:INFO: Batch:  2/31	Total Loss 11.9255 (9.6514)
2022-11-02 23:59:33,913:INFO: Batch:  3/31	Total Loss 10.7099 (9.9444)
2022-11-02 23:59:34,390:INFO: Batch:  4/31	Total Loss 10.9011 (10.1009)
2022-11-02 23:59:34,873:INFO: Batch:  5/31	Total Loss 9.3279 (9.9767)
2022-11-02 23:59:35,354:INFO: Batch:  6/31	Total Loss 10.3058 (10.0210)
2022-11-02 23:59:35,832:INFO: Batch:  7/31	Total Loss 9.5223 (9.9529)
2022-11-02 23:59:36,311:INFO: Batch:  8/31	Total Loss 9.7141 (9.9256)
2022-11-02 23:59:36,788:INFO: Batch:  9/31	Total Loss 8.7222 (9.8080)
2022-11-02 23:59:37,269:INFO: Batch: 10/31	Total Loss 9.4612 (9.7734)
2022-11-02 23:59:37,748:INFO: Batch: 11/31	Total Loss 8.9261 (9.6982)
2022-11-02 23:59:38,231:INFO: Batch: 12/31	Total Loss 8.2359 (9.5900)
2022-11-02 23:59:38,714:INFO: Batch: 13/31	Total Loss 10.5032 (9.6549)
2022-11-02 23:59:39,198:INFO: Batch: 14/31	Total Loss 10.8490 (9.7344)
2022-11-02 23:59:39,686:INFO: Batch: 15/31	Total Loss 10.0390 (9.7548)
2022-11-02 23:59:40,168:INFO: Batch: 16/31	Total Loss 9.8936 (9.7628)
2022-11-02 23:59:40,651:INFO: Batch: 17/31	Total Loss 9.8843 (9.7706)
2022-11-02 23:59:41,129:INFO: Batch: 18/31	Total Loss 9.0503 (9.7320)
2022-11-02 23:59:41,605:INFO: Batch: 19/31	Total Loss 9.0909 (9.6961)
2022-11-02 23:59:42,081:INFO: Batch: 20/31	Total Loss 9.2876 (9.6762)
2022-11-02 23:59:42,558:INFO: Batch: 21/31	Total Loss 10.5723 (9.7128)
2022-11-02 23:59:43,035:INFO: Batch: 22/31	Total Loss 9.9852 (9.7237)
2022-11-02 23:59:43,513:INFO: Batch: 23/31	Total Loss 10.8040 (9.7641)
2022-11-02 23:59:43,989:INFO: Batch: 24/31	Total Loss 10.9199 (9.8129)
2022-11-02 23:59:44,539:INFO: Batch: 25/31	Total Loss 9.2561 (9.7902)
2022-11-02 23:59:45,014:INFO: Batch: 26/31	Total Loss 10.0746 (9.8005)
2022-11-02 23:59:45,490:INFO: Batch: 27/31	Total Loss 10.2643 (9.8181)
2022-11-02 23:59:45,966:INFO: Batch: 28/31	Total Loss 9.4013 (9.8042)
2022-11-02 23:59:46,441:INFO: Batch: 29/31	Total Loss 8.9093 (9.7773)
2022-11-02 23:59:46,831:INFO: Batch: 30/31	Total Loss 4.3724 (9.7176)
2022-11-02 23:59:46,988:INFO: - Computing ADE (validation o)
2022-11-02 23:59:47,605:INFO: 		 ADE on eth                       dataset:	 1.2129660844802856
2022-11-02 23:59:47,605:INFO: Average validation o:	ADE  1.2130	FDE  1.8311
2022-11-02 23:59:47,606:INFO: - Computing ADE (validation)
2022-11-02 23:59:47,899:INFO: 		 ADE on hotel                     dataset:	 0.9221067428588867
2022-11-02 23:59:48,208:INFO: 		 ADE on univ                      dataset:	 0.8633812069892883
2022-11-02 23:59:48,462:INFO: 		 ADE on zara1                     dataset:	 0.7909201979637146
2022-11-02 23:59:48,800:INFO: 		 ADE on zara2                     dataset:	 0.613386869430542
2022-11-02 23:59:48,800:INFO: Average validation:	ADE  0.7707	FDE  1.3123
2022-11-02 23:59:48,801:INFO: - Computing ADE (training)
2022-11-02 23:59:49,280:INFO: 		 ADE on hotel                     dataset:	 1.1672507524490356
2022-11-02 23:59:49,967:INFO: 		 ADE on univ                      dataset:	 0.8002999424934387
2022-11-02 23:59:50,530:INFO: 		 ADE on zara1                     dataset:	 0.8740083575248718
2022-11-02 23:59:51,299:INFO: 		 ADE on zara2                     dataset:	 0.6780362129211426
2022-11-02 23:59:51,299:INFO: Average training:	ADE  0.7895	FDE  1.3536
2022-11-02 23:59:51,307:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_275.pth.tar
2022-11-02 23:59:51,307:INFO: 
===> EPOCH: 276 (P3)
2022-11-02 23:59:51,308:INFO: - Computing loss (training)
2022-11-02 23:59:52,405:INFO: Batch:  0/31	Total Loss 9.3138 (9.3138)
2022-11-02 23:59:52,877:INFO: Batch:  1/31	Total Loss 10.0807 (9.6953)
2022-11-02 23:59:53,352:INFO: Batch:  2/31	Total Loss 9.9910 (9.7916)
2022-11-02 23:59:53,821:INFO: Batch:  3/31	Total Loss 9.1866 (9.6456)
2022-11-02 23:59:54,290:INFO: Batch:  4/31	Total Loss 9.1759 (9.5489)
2022-11-02 23:59:54,769:INFO: Batch:  5/31	Total Loss 9.0681 (9.4731)
2022-11-02 23:59:55,239:INFO: Batch:  6/31	Total Loss 9.5135 (9.4791)
2022-11-02 23:59:55,710:INFO: Batch:  7/31	Total Loss 8.8925 (9.4009)
2022-11-02 23:59:56,180:INFO: Batch:  8/31	Total Loss 10.3578 (9.5007)
2022-11-02 23:59:56,648:INFO: Batch:  9/31	Total Loss 8.6811 (9.4172)
2022-11-02 23:59:57,119:INFO: Batch: 10/31	Total Loss 9.6074 (9.4352)
2022-11-02 23:59:57,593:INFO: Batch: 11/31	Total Loss 9.1755 (9.4109)
2022-11-02 23:59:58,070:INFO: Batch: 12/31	Total Loss 8.5394 (9.3436)
2022-11-02 23:59:58,545:INFO: Batch: 13/31	Total Loss 8.2805 (9.2690)
2022-11-02 23:59:59,021:INFO: Batch: 14/31	Total Loss 10.5021 (9.3491)
2022-11-02 23:59:59,495:INFO: Batch: 15/31	Total Loss 9.0418 (9.3311)
2022-11-02 23:59:59,972:INFO: Batch: 16/31	Total Loss 9.2252 (9.3249)
2022-11-03 00:00:00,448:INFO: Batch: 17/31	Total Loss 10.2140 (9.3734)
2022-11-03 00:00:00,928:INFO: Batch: 18/31	Total Loss 9.6157 (9.3862)
2022-11-03 00:00:01,414:INFO: Batch: 19/31	Total Loss 10.2510 (9.4345)
2022-11-03 00:00:01,895:INFO: Batch: 20/31	Total Loss 10.1148 (9.4676)
2022-11-03 00:00:02,377:INFO: Batch: 21/31	Total Loss 9.6329 (9.4754)
2022-11-03 00:00:02,857:INFO: Batch: 22/31	Total Loss 8.9957 (9.4538)
2022-11-03 00:00:03,337:INFO: Batch: 23/31	Total Loss 9.6032 (9.4598)
2022-11-03 00:00:03,816:INFO: Batch: 24/31	Total Loss 10.3773 (9.4898)
2022-11-03 00:00:04,296:INFO: Batch: 25/31	Total Loss 10.1793 (9.5191)
2022-11-03 00:00:04,776:INFO: Batch: 26/31	Total Loss 8.4327 (9.4812)
2022-11-03 00:00:05,259:INFO: Batch: 27/31	Total Loss 7.9280 (9.4230)
2022-11-03 00:00:05,741:INFO: Batch: 28/31	Total Loss 9.5412 (9.4273)
2022-11-03 00:00:06,215:INFO: Batch: 29/31	Total Loss 9.4027 (9.4265)
2022-11-03 00:00:06,605:INFO: Batch: 30/31	Total Loss 4.4142 (9.3798)
2022-11-03 00:00:06,767:INFO: - Computing ADE (validation o)
2022-11-03 00:00:07,384:INFO: 		 ADE on eth                       dataset:	 1.2209618091583252
2022-11-03 00:00:07,384:INFO: Average validation o:	ADE  1.2210	FDE  1.8442
2022-11-03 00:00:07,385:INFO: - Computing ADE (validation)
2022-11-03 00:00:07,678:INFO: 		 ADE on hotel                     dataset:	 0.9038940668106079
2022-11-03 00:00:07,980:INFO: 		 ADE on univ                      dataset:	 0.856798529624939
2022-11-03 00:00:08,233:INFO: 		 ADE on zara1                     dataset:	 0.7993217706680298
2022-11-03 00:00:08,587:INFO: 		 ADE on zara2                     dataset:	 0.6167824864387512
2022-11-03 00:00:08,587:INFO: Average validation:	ADE  0.7680	FDE  1.3112
2022-11-03 00:00:08,588:INFO: - Computing ADE (training)
2022-11-03 00:00:09,026:INFO: 		 ADE on hotel                     dataset:	 1.1393331289291382
2022-11-03 00:00:09,739:INFO: 		 ADE on univ                      dataset:	 0.7961162328720093
2022-11-03 00:00:10,293:INFO: 		 ADE on zara1                     dataset:	 0.868552565574646
2022-11-03 00:00:11,069:INFO: 		 ADE on zara2                     dataset:	 0.6757755279541016
2022-11-03 00:00:11,070:INFO: Average training:	ADE  0.7850	FDE  1.3503
2022-11-03 00:00:11,079:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_276.pth.tar
2022-11-03 00:00:11,079:INFO: 
===> EPOCH: 277 (P3)
2022-11-03 00:00:11,079:INFO: - Computing loss (training)
2022-11-03 00:00:12,175:INFO: Batch:  0/31	Total Loss 10.7490 (10.7490)
2022-11-03 00:00:12,650:INFO: Batch:  1/31	Total Loss 10.0905 (10.4535)
2022-11-03 00:00:13,126:INFO: Batch:  2/31	Total Loss 8.8900 (9.9685)
2022-11-03 00:00:13,596:INFO: Batch:  3/31	Total Loss 9.0383 (9.7281)
2022-11-03 00:00:14,068:INFO: Batch:  4/31	Total Loss 9.4546 (9.6760)
2022-11-03 00:00:14,540:INFO: Batch:  5/31	Total Loss 9.4987 (9.6440)
2022-11-03 00:00:15,011:INFO: Batch:  6/31	Total Loss 9.3825 (9.6061)
2022-11-03 00:00:15,480:INFO: Batch:  7/31	Total Loss 9.4240 (9.5834)
2022-11-03 00:00:15,948:INFO: Batch:  8/31	Total Loss 9.2315 (9.5436)
2022-11-03 00:00:16,417:INFO: Batch:  9/31	Total Loss 9.1999 (9.5080)
2022-11-03 00:00:16,885:INFO: Batch: 10/31	Total Loss 10.0786 (9.5568)
2022-11-03 00:00:17,356:INFO: Batch: 11/31	Total Loss 10.2310 (9.6097)
2022-11-03 00:00:17,830:INFO: Batch: 12/31	Total Loss 8.3901 (9.5190)
2022-11-03 00:00:18,302:INFO: Batch: 13/31	Total Loss 9.5576 (9.5217)
2022-11-03 00:00:18,777:INFO: Batch: 14/31	Total Loss 9.1649 (9.4974)
2022-11-03 00:00:19,251:INFO: Batch: 15/31	Total Loss 9.7523 (9.5130)
2022-11-03 00:00:19,731:INFO: Batch: 16/31	Total Loss 9.8226 (9.5300)
2022-11-03 00:00:20,205:INFO: Batch: 17/31	Total Loss 9.6246 (9.5355)
2022-11-03 00:00:20,679:INFO: Batch: 18/31	Total Loss 10.9192 (9.6043)
2022-11-03 00:00:21,149:INFO: Batch: 19/31	Total Loss 9.1062 (9.5778)
2022-11-03 00:00:21,623:INFO: Batch: 20/31	Total Loss 9.9963 (9.5989)
2022-11-03 00:00:22,096:INFO: Batch: 21/31	Total Loss 8.4551 (9.5435)
2022-11-03 00:00:22,570:INFO: Batch: 22/31	Total Loss 10.3120 (9.5788)
2022-11-03 00:00:23,041:INFO: Batch: 23/31	Total Loss 9.1492 (9.5643)
2022-11-03 00:00:23,512:INFO: Batch: 24/31	Total Loss 9.8566 (9.5767)
2022-11-03 00:00:23,983:INFO: Batch: 25/31	Total Loss 8.2343 (9.5252)
2022-11-03 00:00:24,454:INFO: Batch: 26/31	Total Loss 8.5815 (9.4899)
2022-11-03 00:00:24,928:INFO: Batch: 27/31	Total Loss 8.2985 (9.4463)
2022-11-03 00:00:25,401:INFO: Batch: 28/31	Total Loss 8.7343 (9.4228)
2022-11-03 00:00:25,872:INFO: Batch: 29/31	Total Loss 10.3582 (9.4569)
2022-11-03 00:00:26,259:INFO: Batch: 30/31	Total Loss 3.4741 (9.3943)
2022-11-03 00:00:26,420:INFO: - Computing ADE (validation o)
2022-11-03 00:00:27,015:INFO: 		 ADE on eth                       dataset:	 1.2054890394210815
2022-11-03 00:00:27,015:INFO: Average validation o:	ADE  1.2055	FDE  1.8453
2022-11-03 00:00:27,016:INFO: - Computing ADE (validation)
2022-11-03 00:00:27,281:INFO: 		 ADE on hotel                     dataset:	 0.8873051404953003
2022-11-03 00:00:27,567:INFO: 		 ADE on univ                      dataset:	 0.8342163562774658
2022-11-03 00:00:27,824:INFO: 		 ADE on zara1                     dataset:	 0.7630204558372498
2022-11-03 00:00:28,184:INFO: 		 ADE on zara2                     dataset:	 0.6039457321166992
2022-11-03 00:00:28,184:INFO: Average validation:	ADE  0.7485	FDE  1.2882
2022-11-03 00:00:28,185:INFO: - Computing ADE (training)
2022-11-03 00:00:28,634:INFO: 		 ADE on hotel                     dataset:	 1.113883137702942
2022-11-03 00:00:29,316:INFO: 		 ADE on univ                      dataset:	 0.7834594249725342
2022-11-03 00:00:29,860:INFO: 		 ADE on zara1                     dataset:	 0.8388976454734802
2022-11-03 00:00:30,600:INFO: 		 ADE on zara2                     dataset:	 0.6566610932350159
2022-11-03 00:00:30,600:INFO: Average training:	ADE  0.7697	FDE  1.3370
2022-11-03 00:00:30,609:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_277.pth.tar
2022-11-03 00:00:30,609:INFO: 
===> EPOCH: 278 (P3)
2022-11-03 00:00:30,609:INFO: - Computing loss (training)
2022-11-03 00:00:31,720:INFO: Batch:  0/31	Total Loss 9.2930 (9.2930)
2022-11-03 00:00:32,198:INFO: Batch:  1/31	Total Loss 8.7231 (8.9981)
2022-11-03 00:00:32,678:INFO: Batch:  2/31	Total Loss 8.9078 (8.9667)
2022-11-03 00:00:33,152:INFO: Batch:  3/31	Total Loss 10.3568 (9.2819)
2022-11-03 00:00:33,632:INFO: Batch:  4/31	Total Loss 9.1247 (9.2507)
2022-11-03 00:00:34,110:INFO: Batch:  5/31	Total Loss 8.2066 (9.0626)
2022-11-03 00:00:34,589:INFO: Batch:  6/31	Total Loss 9.6499 (9.1543)
2022-11-03 00:00:35,067:INFO: Batch:  7/31	Total Loss 9.5035 (9.1995)
2022-11-03 00:00:35,539:INFO: Batch:  8/31	Total Loss 9.5086 (9.2320)
2022-11-03 00:00:36,015:INFO: Batch:  9/31	Total Loss 9.3958 (9.2482)
2022-11-03 00:00:36,493:INFO: Batch: 10/31	Total Loss 9.4820 (9.2681)
2022-11-03 00:00:36,970:INFO: Batch: 11/31	Total Loss 8.3654 (9.1853)
2022-11-03 00:00:37,452:INFO: Batch: 12/31	Total Loss 9.5557 (9.2170)
2022-11-03 00:00:37,934:INFO: Batch: 13/31	Total Loss 10.0137 (9.2763)
2022-11-03 00:00:38,415:INFO: Batch: 14/31	Total Loss 8.1079 (9.2002)
2022-11-03 00:00:38,898:INFO: Batch: 15/31	Total Loss 8.7177 (9.1688)
2022-11-03 00:00:39,380:INFO: Batch: 16/31	Total Loss 9.4206 (9.1853)
2022-11-03 00:00:39,942:INFO: Batch: 17/31	Total Loss 9.3888 (9.1962)
2022-11-03 00:00:40,422:INFO: Batch: 18/31	Total Loss 10.1138 (9.2391)
2022-11-03 00:00:40,902:INFO: Batch: 19/31	Total Loss 9.2997 (9.2420)
2022-11-03 00:00:41,381:INFO: Batch: 20/31	Total Loss 9.1407 (9.2375)
2022-11-03 00:00:41,861:INFO: Batch: 21/31	Total Loss 9.1424 (9.2335)
2022-11-03 00:00:42,341:INFO: Batch: 22/31	Total Loss 10.1788 (9.2706)
2022-11-03 00:00:42,821:INFO: Batch: 23/31	Total Loss 7.9479 (9.2180)
2022-11-03 00:00:43,303:INFO: Batch: 24/31	Total Loss 8.6406 (9.1947)
2022-11-03 00:00:43,782:INFO: Batch: 25/31	Total Loss 8.8574 (9.1812)
2022-11-03 00:00:44,262:INFO: Batch: 26/31	Total Loss 9.0160 (9.1748)
2022-11-03 00:00:44,740:INFO: Batch: 27/31	Total Loss 8.4290 (9.1475)
2022-11-03 00:00:45,222:INFO: Batch: 28/31	Total Loss 9.9052 (9.1719)
2022-11-03 00:00:45,703:INFO: Batch: 29/31	Total Loss 9.1731 (9.1719)
2022-11-03 00:00:46,097:INFO: Batch: 30/31	Total Loss 3.8998 (9.1278)
2022-11-03 00:00:46,251:INFO: - Computing ADE (validation o)
2022-11-03 00:00:46,903:INFO: 		 ADE on eth                       dataset:	 1.2256280183792114
2022-11-03 00:00:46,903:INFO: Average validation o:	ADE  1.2256	FDE  1.8707
2022-11-03 00:00:46,904:INFO: - Computing ADE (validation)
2022-11-03 00:00:47,160:INFO: 		 ADE on hotel                     dataset:	 0.8974393606185913
2022-11-03 00:00:47,451:INFO: 		 ADE on univ                      dataset:	 0.8406111598014832
2022-11-03 00:00:47,706:INFO: 		 ADE on zara1                     dataset:	 0.7391491532325745
2022-11-03 00:00:48,052:INFO: 		 ADE on zara2                     dataset:	 0.6168198585510254
2022-11-03 00:00:48,052:INFO: Average validation:	ADE  0.7557	FDE  1.3232
2022-11-03 00:00:48,053:INFO: - Computing ADE (training)
2022-11-03 00:00:48,563:INFO: 		 ADE on hotel                     dataset:	 1.110870599746704
2022-11-03 00:00:49,251:INFO: 		 ADE on univ                      dataset:	 0.7829481959342957
2022-11-03 00:00:49,787:INFO: 		 ADE on zara1                     dataset:	 0.8557555079460144
2022-11-03 00:00:50,548:INFO: 		 ADE on zara2                     dataset:	 0.6791412830352783
2022-11-03 00:00:50,548:INFO: Average training:	ADE  0.7749	FDE  1.3631
2022-11-03 00:00:50,557:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_278.pth.tar
2022-11-03 00:00:50,557:INFO: 
===> EPOCH: 279 (P3)
2022-11-03 00:00:50,557:INFO: - Computing loss (training)
2022-11-03 00:00:51,638:INFO: Batch:  0/31	Total Loss 9.6224 (9.6224)
2022-11-03 00:00:52,109:INFO: Batch:  1/31	Total Loss 9.3460 (9.4860)
2022-11-03 00:00:52,589:INFO: Batch:  2/31	Total Loss 9.9173 (9.6312)
2022-11-03 00:00:53,066:INFO: Batch:  3/31	Total Loss 9.8045 (9.6730)
2022-11-03 00:00:53,539:INFO: Batch:  4/31	Total Loss 9.1408 (9.5592)
2022-11-03 00:00:54,011:INFO: Batch:  5/31	Total Loss 8.7878 (9.4246)
2022-11-03 00:00:54,482:INFO: Batch:  6/31	Total Loss 8.5693 (9.3068)
2022-11-03 00:00:54,950:INFO: Batch:  7/31	Total Loss 9.1248 (9.2869)
2022-11-03 00:00:55,419:INFO: Batch:  8/31	Total Loss 9.1612 (9.2720)
2022-11-03 00:00:55,890:INFO: Batch:  9/31	Total Loss 10.7025 (9.4350)
2022-11-03 00:00:56,360:INFO: Batch: 10/31	Total Loss 9.3460 (9.4275)
2022-11-03 00:00:56,834:INFO: Batch: 11/31	Total Loss 8.3550 (9.3352)
2022-11-03 00:00:57,309:INFO: Batch: 12/31	Total Loss 8.8450 (9.2947)
2022-11-03 00:00:57,783:INFO: Batch: 13/31	Total Loss 9.0243 (9.2749)
2022-11-03 00:00:58,260:INFO: Batch: 14/31	Total Loss 11.8231 (9.4342)
2022-11-03 00:00:58,734:INFO: Batch: 15/31	Total Loss 8.9962 (9.4092)
2022-11-03 00:00:59,208:INFO: Batch: 16/31	Total Loss 8.3069 (9.3450)
2022-11-03 00:00:59,685:INFO: Batch: 17/31	Total Loss 8.9300 (9.3190)
2022-11-03 00:01:00,160:INFO: Batch: 18/31	Total Loss 7.5430 (9.2155)
2022-11-03 00:01:00,632:INFO: Batch: 19/31	Total Loss 9.9280 (9.2511)
2022-11-03 00:01:01,106:INFO: Batch: 20/31	Total Loss 9.3614 (9.2558)
2022-11-03 00:01:01,587:INFO: Batch: 21/31	Total Loss 9.1062 (9.2494)
2022-11-03 00:01:02,072:INFO: Batch: 22/31	Total Loss 10.0767 (9.2889)
2022-11-03 00:01:02,571:INFO: Batch: 23/31	Total Loss 10.1807 (9.3273)
2022-11-03 00:01:03,044:INFO: Batch: 24/31	Total Loss 8.8565 (9.3095)
2022-11-03 00:01:03,518:INFO: Batch: 25/31	Total Loss 8.5619 (9.2753)
2022-11-03 00:01:03,992:INFO: Batch: 26/31	Total Loss 8.2049 (9.2319)
2022-11-03 00:01:04,466:INFO: Batch: 27/31	Total Loss 9.3580 (9.2366)
2022-11-03 00:01:04,940:INFO: Batch: 28/31	Total Loss 9.5657 (9.2466)
2022-11-03 00:01:05,414:INFO: Batch: 29/31	Total Loss 8.7206 (9.2284)
2022-11-03 00:01:05,802:INFO: Batch: 30/31	Total Loss 3.5004 (9.1783)
2022-11-03 00:01:05,944:INFO: - Computing ADE (validation o)
2022-11-03 00:01:06,526:INFO: 		 ADE on eth                       dataset:	 1.2050827741622925
2022-11-03 00:01:06,527:INFO: Average validation o:	ADE  1.2051	FDE  1.8537
2022-11-03 00:01:06,528:INFO: - Computing ADE (validation)
2022-11-03 00:01:06,810:INFO: 		 ADE on hotel                     dataset:	 0.8473206162452698
2022-11-03 00:01:07,111:INFO: 		 ADE on univ                      dataset:	 0.816556990146637
2022-11-03 00:01:07,351:INFO: 		 ADE on zara1                     dataset:	 0.789310872554779
2022-11-03 00:01:07,697:INFO: 		 ADE on zara2                     dataset:	 0.6026500463485718
2022-11-03 00:01:07,697:INFO: Average validation:	ADE  0.7382	FDE  1.2633
2022-11-03 00:01:07,698:INFO: - Computing ADE (training)
2022-11-03 00:01:08,163:INFO: 		 ADE on hotel                     dataset:	 1.054551601409912
2022-11-03 00:01:08,855:INFO: 		 ADE on univ                      dataset:	 0.7655957937240601
2022-11-03 00:01:09,402:INFO: 		 ADE on zara1                     dataset:	 0.8467414975166321
2022-11-03 00:01:10,167:INFO: 		 ADE on zara2                     dataset:	 0.6588792204856873
2022-11-03 00:01:10,167:INFO: Average training:	ADE  0.7565	FDE  1.3055
2022-11-03 00:01:10,176:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_279.pth.tar
2022-11-03 00:01:10,177:INFO: 
===> EPOCH: 280 (P3)
2022-11-03 00:01:10,177:INFO: - Computing loss (training)
2022-11-03 00:01:11,290:INFO: Batch:  0/31	Total Loss 8.6111 (8.6111)
2022-11-03 00:01:11,759:INFO: Batch:  1/31	Total Loss 9.4811 (9.0689)
2022-11-03 00:01:12,232:INFO: Batch:  2/31	Total Loss 8.3625 (8.8065)
2022-11-03 00:01:12,702:INFO: Batch:  3/31	Total Loss 8.7828 (8.8010)
2022-11-03 00:01:13,176:INFO: Batch:  4/31	Total Loss 9.0863 (8.8583)
2022-11-03 00:01:13,649:INFO: Batch:  5/31	Total Loss 8.8601 (8.8586)
2022-11-03 00:01:14,123:INFO: Batch:  6/31	Total Loss 8.5339 (8.8153)
2022-11-03 00:01:14,595:INFO: Batch:  7/31	Total Loss 8.2002 (8.7436)
2022-11-03 00:01:15,065:INFO: Batch:  8/31	Total Loss 8.8656 (8.7587)
2022-11-03 00:01:15,534:INFO: Batch:  9/31	Total Loss 9.0646 (8.7891)
2022-11-03 00:01:16,005:INFO: Batch: 10/31	Total Loss 9.0546 (8.8145)
2022-11-03 00:01:16,476:INFO: Batch: 11/31	Total Loss 9.3507 (8.8624)
2022-11-03 00:01:16,951:INFO: Batch: 12/31	Total Loss 9.4400 (8.9098)
2022-11-03 00:01:17,425:INFO: Batch: 13/31	Total Loss 8.2334 (8.8623)
2022-11-03 00:01:17,901:INFO: Batch: 14/31	Total Loss 8.8555 (8.8618)
2022-11-03 00:01:18,376:INFO: Batch: 15/31	Total Loss 9.2483 (8.8836)
2022-11-03 00:01:18,852:INFO: Batch: 16/31	Total Loss 10.4079 (8.9774)
2022-11-03 00:01:19,329:INFO: Batch: 17/31	Total Loss 8.5169 (8.9523)
2022-11-03 00:01:19,806:INFO: Batch: 18/31	Total Loss 8.8408 (8.9467)
2022-11-03 00:01:20,279:INFO: Batch: 19/31	Total Loss 9.0254 (8.9504)
2022-11-03 00:01:20,754:INFO: Batch: 20/31	Total Loss 9.6083 (8.9807)
2022-11-03 00:01:21,249:INFO: Batch: 21/31	Total Loss 8.6093 (8.9642)
2022-11-03 00:01:21,724:INFO: Batch: 22/31	Total Loss 9.1517 (8.9722)
2022-11-03 00:01:22,199:INFO: Batch: 23/31	Total Loss 8.8179 (8.9652)
2022-11-03 00:01:22,675:INFO: Batch: 24/31	Total Loss 7.9228 (8.9272)
2022-11-03 00:01:23,153:INFO: Batch: 25/31	Total Loss 8.2156 (8.8960)
2022-11-03 00:01:23,627:INFO: Batch: 26/31	Total Loss 9.3857 (8.9147)
2022-11-03 00:01:24,102:INFO: Batch: 27/31	Total Loss 8.4830 (8.9002)
2022-11-03 00:01:24,575:INFO: Batch: 28/31	Total Loss 9.0727 (8.9062)
2022-11-03 00:01:25,050:INFO: Batch: 29/31	Total Loss 9.4352 (8.9239)
2022-11-03 00:01:25,439:INFO: Batch: 30/31	Total Loss 2.9362 (8.8572)
2022-11-03 00:01:25,585:INFO: - Computing ADE (validation o)
2022-11-03 00:01:26,179:INFO: 		 ADE on eth                       dataset:	 1.2385939359664917
2022-11-03 00:01:26,179:INFO: Average validation o:	ADE  1.2386	FDE  1.8968
2022-11-03 00:01:26,180:INFO: - Computing ADE (validation)
2022-11-03 00:01:26,451:INFO: 		 ADE on hotel                     dataset:	 0.8339819312095642
2022-11-03 00:01:26,747:INFO: 		 ADE on univ                      dataset:	 0.8182405829429626
2022-11-03 00:01:26,999:INFO: 		 ADE on zara1                     dataset:	 0.7591642141342163
2022-11-03 00:01:27,333:INFO: 		 ADE on zara2                     dataset:	 0.6194493174552917
2022-11-03 00:01:27,333:INFO: Average validation:	ADE  0.7428	FDE  1.2871
2022-11-03 00:01:27,334:INFO: - Computing ADE (training)
2022-11-03 00:01:27,795:INFO: 		 ADE on hotel                     dataset:	 1.0306766033172607
2022-11-03 00:01:28,487:INFO: 		 ADE on univ                      dataset:	 0.7615857124328613
2022-11-03 00:01:29,066:INFO: 		 ADE on zara1                     dataset:	 0.8688367605209351
2022-11-03 00:01:29,795:INFO: 		 ADE on zara2                     dataset:	 0.6863400936126709
2022-11-03 00:01:29,795:INFO: Average training:	ADE  0.7600	FDE  1.3224
2022-11-03 00:01:29,804:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_280.pth.tar
2022-11-03 00:01:29,804:INFO: 
===> EPOCH: 281 (P3)
2022-11-03 00:01:29,804:INFO: - Computing loss (training)
2022-11-03 00:01:30,892:INFO: Batch:  0/31	Total Loss 8.4552 (8.4552)
2022-11-03 00:01:31,371:INFO: Batch:  1/31	Total Loss 8.1334 (8.3022)
2022-11-03 00:01:31,848:INFO: Batch:  2/31	Total Loss 8.6393 (8.4114)
2022-11-03 00:01:32,395:INFO: Batch:  3/31	Total Loss 8.1225 (8.3361)
2022-11-03 00:01:32,867:INFO: Batch:  4/31	Total Loss 9.3289 (8.5478)
2022-11-03 00:01:33,346:INFO: Batch:  5/31	Total Loss 8.6645 (8.5668)
2022-11-03 00:01:33,820:INFO: Batch:  6/31	Total Loss 8.6774 (8.5825)
2022-11-03 00:01:34,290:INFO: Batch:  7/31	Total Loss 8.0289 (8.5163)
2022-11-03 00:01:34,765:INFO: Batch:  8/31	Total Loss 9.3808 (8.6106)
2022-11-03 00:01:35,237:INFO: Batch:  9/31	Total Loss 8.5593 (8.6062)
2022-11-03 00:01:35,708:INFO: Batch: 10/31	Total Loss 9.0823 (8.6491)
2022-11-03 00:01:36,180:INFO: Batch: 11/31	Total Loss 8.9489 (8.6750)
2022-11-03 00:01:36,657:INFO: Batch: 12/31	Total Loss 8.9519 (8.6977)
2022-11-03 00:01:37,132:INFO: Batch: 13/31	Total Loss 8.3755 (8.6751)
2022-11-03 00:01:37,608:INFO: Batch: 14/31	Total Loss 8.4345 (8.6580)
2022-11-03 00:01:38,085:INFO: Batch: 15/31	Total Loss 8.9980 (8.6813)
2022-11-03 00:01:38,559:INFO: Batch: 16/31	Total Loss 9.2449 (8.7163)
2022-11-03 00:01:39,034:INFO: Batch: 17/31	Total Loss 9.7194 (8.7649)
2022-11-03 00:01:39,510:INFO: Batch: 18/31	Total Loss 8.0712 (8.7277)
2022-11-03 00:01:39,985:INFO: Batch: 19/31	Total Loss 10.0532 (8.7872)
2022-11-03 00:01:40,461:INFO: Batch: 20/31	Total Loss 8.5156 (8.7738)
2022-11-03 00:01:40,935:INFO: Batch: 21/31	Total Loss 8.5564 (8.7635)
2022-11-03 00:01:41,411:INFO: Batch: 22/31	Total Loss 9.1971 (8.7825)
2022-11-03 00:01:41,886:INFO: Batch: 23/31	Total Loss 8.2960 (8.7645)
2022-11-03 00:01:42,361:INFO: Batch: 24/31	Total Loss 9.4106 (8.7898)
2022-11-03 00:01:42,835:INFO: Batch: 25/31	Total Loss 8.1614 (8.7656)
2022-11-03 00:01:43,312:INFO: Batch: 26/31	Total Loss 9.0280 (8.7755)
2022-11-03 00:01:43,788:INFO: Batch: 27/31	Total Loss 7.6192 (8.7338)
2022-11-03 00:01:44,262:INFO: Batch: 28/31	Total Loss 8.5054 (8.7259)
2022-11-03 00:01:44,736:INFO: Batch: 29/31	Total Loss 9.8622 (8.7655)
2022-11-03 00:01:45,127:INFO: Batch: 30/31	Total Loss 3.7776 (8.7184)
2022-11-03 00:01:45,281:INFO: - Computing ADE (validation o)
2022-11-03 00:01:45,858:INFO: 		 ADE on eth                       dataset:	 1.2202799320220947
2022-11-03 00:01:45,859:INFO: Average validation o:	ADE  1.2203	FDE  1.9531
2022-11-03 00:01:45,859:INFO: - Computing ADE (validation)
2022-11-03 00:01:46,126:INFO: 		 ADE on hotel                     dataset:	 0.8187393546104431
2022-11-03 00:01:46,431:INFO: 		 ADE on univ                      dataset:	 0.8013628125190735
2022-11-03 00:01:46,688:INFO: 		 ADE on zara1                     dataset:	 0.8459887504577637
2022-11-03 00:01:47,039:INFO: 		 ADE on zara2                     dataset:	 0.6319040656089783
2022-11-03 00:01:47,040:INFO: Average validation:	ADE  0.7428	FDE  1.3019
2022-11-03 00:01:47,040:INFO: - Computing ADE (training)
2022-11-03 00:01:47,491:INFO: 		 ADE on hotel                     dataset:	 1.0007870197296143
2022-11-03 00:01:48,201:INFO: 		 ADE on univ                      dataset:	 0.7643375992774963
2022-11-03 00:01:48,765:INFO: 		 ADE on zara1                     dataset:	 0.8637150526046753
2022-11-03 00:01:49,499:INFO: 		 ADE on zara2                     dataset:	 0.6842025518417358
2022-11-03 00:01:49,500:INFO: Average training:	ADE  0.7604	FDE  1.3478
2022-11-03 00:01:49,508:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_281.pth.tar
2022-11-03 00:01:49,508:INFO: 
===> EPOCH: 282 (P3)
2022-11-03 00:01:49,509:INFO: - Computing loss (training)
2022-11-03 00:01:50,603:INFO: Batch:  0/31	Total Loss 8.3116 (8.3116)
2022-11-03 00:01:51,088:INFO: Batch:  1/31	Total Loss 8.7302 (8.5331)
2022-11-03 00:01:51,574:INFO: Batch:  2/31	Total Loss 8.2538 (8.4324)
2022-11-03 00:01:52,052:INFO: Batch:  3/31	Total Loss 8.9154 (8.5403)
2022-11-03 00:01:52,533:INFO: Batch:  4/31	Total Loss 9.6490 (8.7751)
2022-11-03 00:01:53,017:INFO: Batch:  5/31	Total Loss 8.1078 (8.6601)
2022-11-03 00:01:53,503:INFO: Batch:  6/31	Total Loss 8.6837 (8.6634)
2022-11-03 00:01:53,979:INFO: Batch:  7/31	Total Loss 8.2707 (8.6133)
2022-11-03 00:01:54,457:INFO: Batch:  8/31	Total Loss 7.9575 (8.5416)
2022-11-03 00:01:54,932:INFO: Batch:  9/31	Total Loss 8.2014 (8.5068)
2022-11-03 00:01:55,412:INFO: Batch: 10/31	Total Loss 9.2252 (8.5717)
2022-11-03 00:01:55,889:INFO: Batch: 11/31	Total Loss 8.7646 (8.5877)
2022-11-03 00:01:56,371:INFO: Batch: 12/31	Total Loss 8.8288 (8.6058)
2022-11-03 00:01:56,855:INFO: Batch: 13/31	Total Loss 8.1414 (8.5737)
2022-11-03 00:01:57,338:INFO: Batch: 14/31	Total Loss 7.5540 (8.5035)
2022-11-03 00:01:57,818:INFO: Batch: 15/31	Total Loss 9.0298 (8.5364)
2022-11-03 00:01:58,303:INFO: Batch: 16/31	Total Loss 9.3364 (8.5878)
2022-11-03 00:01:58,783:INFO: Batch: 17/31	Total Loss 9.3136 (8.6250)
2022-11-03 00:01:59,254:INFO: Batch: 18/31	Total Loss 8.2726 (8.6072)
2022-11-03 00:01:59,729:INFO: Batch: 19/31	Total Loss 9.3239 (8.6439)
2022-11-03 00:02:00,199:INFO: Batch: 20/31	Total Loss 7.8284 (8.6036)
2022-11-03 00:02:00,670:INFO: Batch: 21/31	Total Loss 8.1213 (8.5841)
2022-11-03 00:02:01,141:INFO: Batch: 22/31	Total Loss 7.8969 (8.5524)
2022-11-03 00:02:01,614:INFO: Batch: 23/31	Total Loss 8.4392 (8.5479)
2022-11-03 00:02:02,085:INFO: Batch: 24/31	Total Loss 8.2985 (8.5382)
2022-11-03 00:02:02,555:INFO: Batch: 25/31	Total Loss 7.6477 (8.5017)
2022-11-03 00:02:03,026:INFO: Batch: 26/31	Total Loss 8.1544 (8.4882)
2022-11-03 00:02:03,498:INFO: Batch: 27/31	Total Loss 8.6311 (8.4933)
2022-11-03 00:02:03,969:INFO: Batch: 28/31	Total Loss 8.2325 (8.4833)
2022-11-03 00:02:04,439:INFO: Batch: 29/31	Total Loss 9.2803 (8.5100)
2022-11-03 00:02:04,826:INFO: Batch: 30/31	Total Loss 3.8779 (8.4741)
2022-11-03 00:02:04,972:INFO: - Computing ADE (validation o)
2022-11-03 00:02:05,539:INFO: 		 ADE on eth                       dataset:	 1.2028495073318481
2022-11-03 00:02:05,539:INFO: Average validation o:	ADE  1.2028	FDE  1.8931
2022-11-03 00:02:05,540:INFO: - Computing ADE (validation)
2022-11-03 00:02:05,815:INFO: 		 ADE on hotel                     dataset:	 0.7851954698562622
2022-11-03 00:02:06,115:INFO: 		 ADE on univ                      dataset:	 0.777451753616333
2022-11-03 00:02:06,382:INFO: 		 ADE on zara1                     dataset:	 0.720555305480957
2022-11-03 00:02:06,733:INFO: 		 ADE on zara2                     dataset:	 0.6061715483665466
2022-11-03 00:02:06,733:INFO: Average validation:	ADE  0.7117	FDE  1.2523
2022-11-03 00:02:06,733:INFO: - Computing ADE (training)
2022-11-03 00:02:07,215:INFO: 		 ADE on hotel                     dataset:	 0.940007209777832
2022-11-03 00:02:07,896:INFO: 		 ADE on univ                      dataset:	 0.7302799820899963
2022-11-03 00:02:08,451:INFO: 		 ADE on zara1                     dataset:	 0.8215433955192566
2022-11-03 00:02:09,258:INFO: 		 ADE on zara2                     dataset:	 0.6656347513198853
2022-11-03 00:02:09,258:INFO: Average training:	ADE  0.7283	FDE  1.2852
2022-11-03 00:02:09,267:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_282.pth.tar
2022-11-03 00:02:09,267:INFO: 
===> EPOCH: 283 (P3)
2022-11-03 00:02:09,268:INFO: - Computing loss (training)
2022-11-03 00:02:10,361:INFO: Batch:  0/31	Total Loss 9.3494 (9.3494)
2022-11-03 00:02:10,847:INFO: Batch:  1/31	Total Loss 8.6048 (8.9817)
2022-11-03 00:02:11,323:INFO: Batch:  2/31	Total Loss 8.7234 (8.9038)
2022-11-03 00:02:11,793:INFO: Batch:  3/31	Total Loss 8.5989 (8.8321)
2022-11-03 00:02:12,258:INFO: Batch:  4/31	Total Loss 8.3794 (8.7544)
2022-11-03 00:02:12,733:INFO: Batch:  5/31	Total Loss 9.5294 (8.8870)
2022-11-03 00:02:13,203:INFO: Batch:  6/31	Total Loss 8.5856 (8.8384)
2022-11-03 00:02:13,671:INFO: Batch:  7/31	Total Loss 7.5353 (8.6489)
2022-11-03 00:02:14,142:INFO: Batch:  8/31	Total Loss 9.9175 (8.8022)
2022-11-03 00:02:14,608:INFO: Batch:  9/31	Total Loss 9.2468 (8.8449)
2022-11-03 00:02:15,076:INFO: Batch: 10/31	Total Loss 7.0968 (8.6875)
2022-11-03 00:02:15,549:INFO: Batch: 11/31	Total Loss 7.9767 (8.6286)
2022-11-03 00:02:16,021:INFO: Batch: 12/31	Total Loss 9.6289 (8.7039)
2022-11-03 00:02:16,494:INFO: Batch: 13/31	Total Loss 8.5259 (8.6909)
2022-11-03 00:02:16,966:INFO: Batch: 14/31	Total Loss 7.6025 (8.6114)
2022-11-03 00:02:17,440:INFO: Batch: 15/31	Total Loss 8.8792 (8.6298)
2022-11-03 00:02:17,912:INFO: Batch: 16/31	Total Loss 8.4241 (8.6155)
2022-11-03 00:02:18,387:INFO: Batch: 17/31	Total Loss 8.5926 (8.6142)
2022-11-03 00:02:18,860:INFO: Batch: 18/31	Total Loss 8.1101 (8.5878)
2022-11-03 00:02:19,334:INFO: Batch: 19/31	Total Loss 8.1413 (8.5668)
2022-11-03 00:02:19,809:INFO: Batch: 20/31	Total Loss 7.8638 (8.5331)
2022-11-03 00:02:20,280:INFO: Batch: 21/31	Total Loss 9.2740 (8.5705)
2022-11-03 00:02:20,751:INFO: Batch: 22/31	Total Loss 9.8569 (8.6259)
2022-11-03 00:02:21,224:INFO: Batch: 23/31	Total Loss 8.7523 (8.6314)
2022-11-03 00:02:21,698:INFO: Batch: 24/31	Total Loss 7.5539 (8.5830)
2022-11-03 00:02:22,248:INFO: Batch: 25/31	Total Loss 7.7728 (8.5456)
2022-11-03 00:02:22,723:INFO: Batch: 26/31	Total Loss 9.3143 (8.5733)
2022-11-03 00:02:23,197:INFO: Batch: 27/31	Total Loss 8.0552 (8.5542)
2022-11-03 00:02:23,669:INFO: Batch: 28/31	Total Loss 8.6588 (8.5581)
2022-11-03 00:02:24,141:INFO: Batch: 29/31	Total Loss 8.1319 (8.5445)
2022-11-03 00:02:24,529:INFO: Batch: 30/31	Total Loss 3.1961 (8.4832)
2022-11-03 00:02:24,685:INFO: - Computing ADE (validation o)
2022-11-03 00:02:25,273:INFO: 		 ADE on eth                       dataset:	 1.245038628578186
2022-11-03 00:02:25,274:INFO: Average validation o:	ADE  1.2450	FDE  1.9221
2022-11-03 00:02:25,274:INFO: - Computing ADE (validation)
2022-11-03 00:02:25,536:INFO: 		 ADE on hotel                     dataset:	 0.7692956328392029
2022-11-03 00:02:25,843:INFO: 		 ADE on univ                      dataset:	 0.7772432565689087
2022-11-03 00:02:26,101:INFO: 		 ADE on zara1                     dataset:	 0.7326402068138123
2022-11-03 00:02:26,439:INFO: 		 ADE on zara2                     dataset:	 0.6346120238304138
2022-11-03 00:02:26,439:INFO: Average validation:	ADE  0.7219	FDE  1.2882
2022-11-03 00:02:26,440:INFO: - Computing ADE (training)
2022-11-03 00:02:26,883:INFO: 		 ADE on hotel                     dataset:	 0.9011169672012329
2022-11-03 00:02:27,623:INFO: 		 ADE on univ                      dataset:	 0.7267279624938965
2022-11-03 00:02:28,151:INFO: 		 ADE on zara1                     dataset:	 0.8560761213302612
2022-11-03 00:02:28,957:INFO: 		 ADE on zara2                     dataset:	 0.7021111249923706
2022-11-03 00:02:28,957:INFO: Average training:	ADE  0.7344	FDE  1.3084
2022-11-03 00:02:28,967:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_283.pth.tar
2022-11-03 00:02:28,967:INFO: 
===> EPOCH: 284 (P3)
2022-11-03 00:02:28,967:INFO: - Computing loss (training)
2022-11-03 00:02:30,070:INFO: Batch:  0/31	Total Loss 7.3179 (7.3179)
2022-11-03 00:02:30,543:INFO: Batch:  1/31	Total Loss 9.5322 (8.4385)
2022-11-03 00:02:31,020:INFO: Batch:  2/31	Total Loss 8.2489 (8.3790)
2022-11-03 00:02:31,491:INFO: Batch:  3/31	Total Loss 8.6312 (8.4330)
2022-11-03 00:02:31,965:INFO: Batch:  4/31	Total Loss 8.2934 (8.4063)
2022-11-03 00:02:32,437:INFO: Batch:  5/31	Total Loss 8.2640 (8.3825)
2022-11-03 00:02:32,910:INFO: Batch:  6/31	Total Loss 8.0777 (8.3409)
2022-11-03 00:02:33,382:INFO: Batch:  7/31	Total Loss 8.5897 (8.3717)
2022-11-03 00:02:33,852:INFO: Batch:  8/31	Total Loss 7.8307 (8.3147)
2022-11-03 00:02:34,320:INFO: Batch:  9/31	Total Loss 9.0501 (8.3824)
2022-11-03 00:02:34,789:INFO: Batch: 10/31	Total Loss 7.0955 (8.2820)
2022-11-03 00:02:35,262:INFO: Batch: 11/31	Total Loss 8.8438 (8.3295)
2022-11-03 00:02:35,736:INFO: Batch: 12/31	Total Loss 10.4854 (8.5003)
2022-11-03 00:02:36,208:INFO: Batch: 13/31	Total Loss 8.4204 (8.4951)
2022-11-03 00:02:36,680:INFO: Batch: 14/31	Total Loss 8.3566 (8.4847)
2022-11-03 00:02:37,153:INFO: Batch: 15/31	Total Loss 8.3078 (8.4734)
2022-11-03 00:02:37,627:INFO: Batch: 16/31	Total Loss 8.7818 (8.4902)
2022-11-03 00:02:38,101:INFO: Batch: 17/31	Total Loss 7.9691 (8.4578)
2022-11-03 00:02:38,575:INFO: Batch: 18/31	Total Loss 7.7811 (8.4239)
2022-11-03 00:02:39,049:INFO: Batch: 19/31	Total Loss 8.2585 (8.4155)
2022-11-03 00:02:39,522:INFO: Batch: 20/31	Total Loss 7.5185 (8.3727)
2022-11-03 00:02:39,996:INFO: Batch: 21/31	Total Loss 8.2656 (8.3685)
2022-11-03 00:02:40,468:INFO: Batch: 22/31	Total Loss 8.4233 (8.3707)
2022-11-03 00:02:40,940:INFO: Batch: 23/31	Total Loss 7.5536 (8.3339)
2022-11-03 00:02:41,413:INFO: Batch: 24/31	Total Loss 8.3181 (8.3333)
2022-11-03 00:02:41,887:INFO: Batch: 25/31	Total Loss 8.2657 (8.3307)
2022-11-03 00:02:42,359:INFO: Batch: 26/31	Total Loss 7.9820 (8.3190)
2022-11-03 00:02:42,832:INFO: Batch: 27/31	Total Loss 8.4421 (8.3231)
2022-11-03 00:02:43,307:INFO: Batch: 28/31	Total Loss 9.6436 (8.3680)
2022-11-03 00:02:43,781:INFO: Batch: 29/31	Total Loss 7.7738 (8.3449)
2022-11-03 00:02:44,170:INFO: Batch: 30/31	Total Loss 3.1910 (8.2924)
2022-11-03 00:02:44,324:INFO: - Computing ADE (validation o)
2022-11-03 00:02:44,920:INFO: 		 ADE on eth                       dataset:	 1.1939977407455444
2022-11-03 00:02:44,920:INFO: Average validation o:	ADE  1.1940	FDE  1.9245
2022-11-03 00:02:44,921:INFO: - Computing ADE (validation)
2022-11-03 00:02:45,189:INFO: 		 ADE on hotel                     dataset:	 0.7140763401985168
2022-11-03 00:02:45,470:INFO: 		 ADE on univ                      dataset:	 0.7632822394371033
2022-11-03 00:02:45,728:INFO: 		 ADE on zara1                     dataset:	 0.8240086436271667
2022-11-03 00:02:46,076:INFO: 		 ADE on zara2                     dataset:	 0.6248157024383545
2022-11-03 00:02:46,076:INFO: Average validation:	ADE  0.7133	FDE  1.2817
2022-11-03 00:02:46,077:INFO: - Computing ADE (training)
2022-11-03 00:02:46,530:INFO: 		 ADE on hotel                     dataset:	 0.842107892036438
2022-11-03 00:02:47,204:INFO: 		 ADE on univ                      dataset:	 0.7225667834281921
2022-11-03 00:02:47,742:INFO: 		 ADE on zara1                     dataset:	 0.8133286833763123
2022-11-03 00:02:48,536:INFO: 		 ADE on zara2                     dataset:	 0.665063738822937
2022-11-03 00:02:48,537:INFO: Average training:	ADE  0.7197	FDE  1.3048
2022-11-03 00:02:48,546:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_284.pth.tar
2022-11-03 00:02:48,546:INFO: 
===> EPOCH: 285 (P3)
2022-11-03 00:02:48,547:INFO: - Computing loss (training)
2022-11-03 00:02:49,641:INFO: Batch:  0/31	Total Loss 9.0543 (9.0543)
2022-11-03 00:02:50,123:INFO: Batch:  1/31	Total Loss 8.1855 (8.6180)
2022-11-03 00:02:50,604:INFO: Batch:  2/31	Total Loss 7.8894 (8.3776)
2022-11-03 00:02:51,081:INFO: Batch:  3/31	Total Loss 8.2895 (8.3571)
2022-11-03 00:02:51,557:INFO: Batch:  4/31	Total Loss 8.9641 (8.4634)
2022-11-03 00:02:52,034:INFO: Batch:  5/31	Total Loss 7.8273 (8.3619)
2022-11-03 00:02:52,505:INFO: Batch:  6/31	Total Loss 8.3033 (8.3531)
2022-11-03 00:02:52,976:INFO: Batch:  7/31	Total Loss 8.1886 (8.3345)
2022-11-03 00:02:53,447:INFO: Batch:  8/31	Total Loss 8.9031 (8.3988)
2022-11-03 00:02:53,917:INFO: Batch:  9/31	Total Loss 8.5793 (8.4177)
2022-11-03 00:02:54,389:INFO: Batch: 10/31	Total Loss 8.2623 (8.4033)
2022-11-03 00:02:54,861:INFO: Batch: 11/31	Total Loss 8.0476 (8.3743)
2022-11-03 00:02:55,336:INFO: Batch: 12/31	Total Loss 7.8741 (8.3353)
2022-11-03 00:02:55,811:INFO: Batch: 13/31	Total Loss 7.7646 (8.2934)
2022-11-03 00:02:56,285:INFO: Batch: 14/31	Total Loss 8.0693 (8.2769)
2022-11-03 00:02:56,759:INFO: Batch: 15/31	Total Loss 7.6652 (8.2358)
2022-11-03 00:02:57,246:INFO: Batch: 16/31	Total Loss 7.6098 (8.2005)
2022-11-03 00:02:57,721:INFO: Batch: 17/31	Total Loss 7.7605 (8.1719)
2022-11-03 00:02:58,197:INFO: Batch: 18/31	Total Loss 7.7739 (8.1512)
2022-11-03 00:02:58,671:INFO: Batch: 19/31	Total Loss 7.5530 (8.1215)
2022-11-03 00:02:59,147:INFO: Batch: 20/31	Total Loss 8.0591 (8.1187)
2022-11-03 00:02:59,622:INFO: Batch: 21/31	Total Loss 8.2231 (8.1232)
2022-11-03 00:03:00,098:INFO: Batch: 22/31	Total Loss 8.6082 (8.1436)
2022-11-03 00:03:00,572:INFO: Batch: 23/31	Total Loss 7.4161 (8.1130)
2022-11-03 00:03:01,047:INFO: Batch: 24/31	Total Loss 8.5819 (8.1300)
2022-11-03 00:03:01,522:INFO: Batch: 25/31	Total Loss 8.3482 (8.1377)
2022-11-03 00:03:01,994:INFO: Batch: 26/31	Total Loss 8.5102 (8.1521)
2022-11-03 00:03:02,467:INFO: Batch: 27/31	Total Loss 7.7506 (8.1386)
2022-11-03 00:03:02,941:INFO: Batch: 28/31	Total Loss 8.6893 (8.1581)
2022-11-03 00:03:03,414:INFO: Batch: 29/31	Total Loss 8.3443 (8.1637)
2022-11-03 00:03:03,802:INFO: Batch: 30/31	Total Loss 2.8178 (8.1103)
2022-11-03 00:03:03,958:INFO: - Computing ADE (validation o)
2022-11-03 00:03:04,558:INFO: 		 ADE on eth                       dataset:	 1.199678659439087
2022-11-03 00:03:04,559:INFO: Average validation o:	ADE  1.1997	FDE  1.8602
2022-11-03 00:03:04,559:INFO: - Computing ADE (validation)
2022-11-03 00:03:04,836:INFO: 		 ADE on hotel                     dataset:	 0.6298781633377075
2022-11-03 00:03:05,131:INFO: 		 ADE on univ                      dataset:	 0.7014607191085815
2022-11-03 00:03:05,378:INFO: 		 ADE on zara1                     dataset:	 0.7728089094161987
2022-11-03 00:03:05,730:INFO: 		 ADE on zara2                     dataset:	 0.5770944356918335
2022-11-03 00:03:05,731:INFO: Average validation:	ADE  0.6561	FDE  1.1100
2022-11-03 00:03:05,731:INFO: - Computing ADE (training)
2022-11-03 00:03:06,162:INFO: 		 ADE on hotel                     dataset:	 0.744200587272644
2022-11-03 00:03:06,851:INFO: 		 ADE on univ                      dataset:	 0.6690849661827087
2022-11-03 00:03:07,404:INFO: 		 ADE on zara1                     dataset:	 0.8180631995201111
2022-11-03 00:03:08,166:INFO: 		 ADE on zara2                     dataset:	 0.633581280708313
2022-11-03 00:03:08,167:INFO: Average training:	ADE  0.6733	FDE  1.1566
2022-11-03 00:03:08,175:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_285.pth.tar
2022-11-03 00:03:08,175:INFO: 
===> EPOCH: 286 (P3)
2022-11-03 00:03:08,175:INFO: - Computing loss (training)
2022-11-03 00:03:09,260:INFO: Batch:  0/31	Total Loss 7.3832 (7.3832)
2022-11-03 00:03:09,741:INFO: Batch:  1/31	Total Loss 7.3325 (7.3580)
2022-11-03 00:03:10,224:INFO: Batch:  2/31	Total Loss 7.9493 (7.5372)
2022-11-03 00:03:10,692:INFO: Batch:  3/31	Total Loss 8.5170 (7.7586)
2022-11-03 00:03:11,165:INFO: Batch:  4/31	Total Loss 8.0008 (7.8091)
2022-11-03 00:03:11,645:INFO: Batch:  5/31	Total Loss 7.2439 (7.7172)
2022-11-03 00:03:12,118:INFO: Batch:  6/31	Total Loss 7.6057 (7.7015)
2022-11-03 00:03:12,588:INFO: Batch:  7/31	Total Loss 6.9536 (7.5987)
2022-11-03 00:03:13,058:INFO: Batch:  8/31	Total Loss 8.9393 (7.7421)
2022-11-03 00:03:13,529:INFO: Batch:  9/31	Total Loss 8.5841 (7.8331)
2022-11-03 00:03:14,000:INFO: Batch: 10/31	Total Loss 7.8211 (7.8320)
2022-11-03 00:03:14,473:INFO: Batch: 11/31	Total Loss 7.6086 (7.8135)
2022-11-03 00:03:14,948:INFO: Batch: 12/31	Total Loss 7.5622 (7.7933)
2022-11-03 00:03:15,423:INFO: Batch: 13/31	Total Loss 7.4535 (7.7699)
2022-11-03 00:03:15,973:INFO: Batch: 14/31	Total Loss 7.4000 (7.7464)
2022-11-03 00:03:16,445:INFO: Batch: 15/31	Total Loss 8.6149 (7.8039)
2022-11-03 00:03:16,919:INFO: Batch: 16/31	Total Loss 8.5446 (7.8466)
2022-11-03 00:03:17,393:INFO: Batch: 17/31	Total Loss 8.4901 (7.8846)
2022-11-03 00:03:17,868:INFO: Batch: 18/31	Total Loss 8.1095 (7.8976)
2022-11-03 00:03:18,340:INFO: Batch: 19/31	Total Loss 7.7816 (7.8923)
2022-11-03 00:03:18,812:INFO: Batch: 20/31	Total Loss 7.9035 (7.8928)
2022-11-03 00:03:19,282:INFO: Batch: 21/31	Total Loss 7.7391 (7.8862)
2022-11-03 00:03:19,758:INFO: Batch: 22/31	Total Loss 8.4517 (7.9126)
2022-11-03 00:03:20,230:INFO: Batch: 23/31	Total Loss 7.8334 (7.9092)
2022-11-03 00:03:20,704:INFO: Batch: 24/31	Total Loss 7.3773 (7.8883)
2022-11-03 00:03:21,178:INFO: Batch: 25/31	Total Loss 7.2923 (7.8659)
2022-11-03 00:03:21,652:INFO: Batch: 26/31	Total Loss 7.6403 (7.8568)
2022-11-03 00:03:22,126:INFO: Batch: 27/31	Total Loss 9.0486 (7.8969)
2022-11-03 00:03:22,597:INFO: Batch: 28/31	Total Loss 8.2689 (7.9115)
2022-11-03 00:03:23,070:INFO: Batch: 29/31	Total Loss 7.8313 (7.9092)
2022-11-03 00:03:23,457:INFO: Batch: 30/31	Total Loss 2.7393 (7.8626)
2022-11-03 00:03:23,614:INFO: - Computing ADE (validation o)
2022-11-03 00:03:24,246:INFO: 		 ADE on eth                       dataset:	 1.2190327644348145
2022-11-03 00:03:24,246:INFO: Average validation o:	ADE  1.2190	FDE  1.8805
2022-11-03 00:03:24,247:INFO: - Computing ADE (validation)
2022-11-03 00:03:24,534:INFO: 		 ADE on hotel                     dataset:	 0.6095150709152222
2022-11-03 00:03:24,831:INFO: 		 ADE on univ                      dataset:	 0.6919240951538086
2022-11-03 00:03:25,080:INFO: 		 ADE on zara1                     dataset:	 0.781182587146759
2022-11-03 00:03:25,422:INFO: 		 ADE on zara2                     dataset:	 0.5915232300758362
2022-11-03 00:03:25,423:INFO: Average validation:	ADE  0.6558	FDE  1.1076
2022-11-03 00:03:25,423:INFO: - Computing ADE (training)
2022-11-03 00:03:25,858:INFO: 		 ADE on hotel                     dataset:	 0.7091763615608215
2022-11-03 00:03:26,574:INFO: 		 ADE on univ                      dataset:	 0.6665930151939392
2022-11-03 00:03:27,101:INFO: 		 ADE on zara1                     dataset:	 0.8459287285804749
2022-11-03 00:03:27,848:INFO: 		 ADE on zara2                     dataset:	 0.6558451652526855
2022-11-03 00:03:27,848:INFO: Average training:	ADE  0.6769	FDE  1.1633
2022-11-03 00:03:27,858:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_286.pth.tar
2022-11-03 00:03:27,858:INFO: 
===> EPOCH: 287 (P3)
2022-11-03 00:03:27,858:INFO: - Computing loss (training)
2022-11-03 00:03:28,965:INFO: Batch:  0/31	Total Loss 8.0192 (8.0192)
2022-11-03 00:03:29,441:INFO: Batch:  1/31	Total Loss 9.1674 (8.5588)
2022-11-03 00:03:29,920:INFO: Batch:  2/31	Total Loss 8.0276 (8.3829)
2022-11-03 00:03:30,406:INFO: Batch:  3/31	Total Loss 8.1853 (8.3330)
2022-11-03 00:03:30,888:INFO: Batch:  4/31	Total Loss 7.4875 (8.1581)
2022-11-03 00:03:31,364:INFO: Batch:  5/31	Total Loss 8.0047 (8.1332)
2022-11-03 00:03:31,841:INFO: Batch:  6/31	Total Loss 7.8513 (8.0936)
2022-11-03 00:03:32,316:INFO: Batch:  7/31	Total Loss 7.5558 (8.0273)
2022-11-03 00:03:32,794:INFO: Batch:  8/31	Total Loss 7.6609 (7.9863)
2022-11-03 00:03:33,270:INFO: Batch:  9/31	Total Loss 7.2352 (7.9139)
2022-11-03 00:03:33,748:INFO: Batch: 10/31	Total Loss 8.3197 (7.9457)
2022-11-03 00:03:34,223:INFO: Batch: 11/31	Total Loss 7.5142 (7.9101)
2022-11-03 00:03:34,700:INFO: Batch: 12/31	Total Loss 8.6623 (7.9696)
2022-11-03 00:03:35,179:INFO: Batch: 13/31	Total Loss 7.9977 (7.9717)
2022-11-03 00:03:35,656:INFO: Batch: 14/31	Total Loss 7.2695 (7.9240)
2022-11-03 00:03:36,131:INFO: Batch: 15/31	Total Loss 7.9109 (7.9233)
2022-11-03 00:03:36,604:INFO: Batch: 16/31	Total Loss 7.6946 (7.9096)
2022-11-03 00:03:37,079:INFO: Batch: 17/31	Total Loss 7.6718 (7.8957)
2022-11-03 00:03:37,554:INFO: Batch: 18/31	Total Loss 7.8486 (7.8933)
2022-11-03 00:03:38,030:INFO: Batch: 19/31	Total Loss 8.3930 (7.9174)
2022-11-03 00:03:38,505:INFO: Batch: 20/31	Total Loss 8.2125 (7.9320)
2022-11-03 00:03:38,978:INFO: Batch: 21/31	Total Loss 7.5749 (7.9145)
2022-11-03 00:03:39,453:INFO: Batch: 22/31	Total Loss 7.8021 (7.9097)
2022-11-03 00:03:39,930:INFO: Batch: 23/31	Total Loss 7.4512 (7.8905)
2022-11-03 00:03:40,408:INFO: Batch: 24/31	Total Loss 7.6624 (7.8819)
2022-11-03 00:03:40,882:INFO: Batch: 25/31	Total Loss 7.0298 (7.8476)
2022-11-03 00:03:41,356:INFO: Batch: 26/31	Total Loss 8.4878 (7.8716)
2022-11-03 00:03:41,830:INFO: Batch: 27/31	Total Loss 7.3662 (7.8555)
2022-11-03 00:03:42,302:INFO: Batch: 28/31	Total Loss 7.2842 (7.8339)
2022-11-03 00:03:42,777:INFO: Batch: 29/31	Total Loss 7.9105 (7.8364)
2022-11-03 00:03:43,168:INFO: Batch: 30/31	Total Loss 3.6464 (7.7945)
2022-11-03 00:03:43,319:INFO: - Computing ADE (validation o)
2022-11-03 00:03:43,900:INFO: 		 ADE on eth                       dataset:	 1.1869757175445557
2022-11-03 00:03:43,900:INFO: Average validation o:	ADE  1.1870	FDE  1.8057
2022-11-03 00:03:43,901:INFO: - Computing ADE (validation)
2022-11-03 00:03:44,175:INFO: 		 ADE on hotel                     dataset:	 0.5779603123664856
2022-11-03 00:03:44,471:INFO: 		 ADE on univ                      dataset:	 0.6872405409812927
2022-11-03 00:03:44,727:INFO: 		 ADE on zara1                     dataset:	 0.771862268447876
2022-11-03 00:03:45,080:INFO: 		 ADE on zara2                     dataset:	 0.564583420753479
2022-11-03 00:03:45,080:INFO: Average validation:	ADE  0.6412	FDE  1.0833
2022-11-03 00:03:45,081:INFO: - Computing ADE (training)
2022-11-03 00:03:45,548:INFO: 		 ADE on hotel                     dataset:	 0.689333975315094
2022-11-03 00:03:46,263:INFO: 		 ADE on univ                      dataset:	 0.6522772908210754
2022-11-03 00:03:46,789:INFO: 		 ADE on zara1                     dataset:	 0.8115934133529663
2022-11-03 00:03:47,534:INFO: 		 ADE on zara2                     dataset:	 0.6230872869491577
2022-11-03 00:03:47,535:INFO: Average training:	ADE  0.6575	FDE  1.1275
2022-11-03 00:03:47,544:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_287.pth.tar
2022-11-03 00:03:47,544:INFO: 
===> EPOCH: 288 (P3)
2022-11-03 00:03:47,544:INFO: - Computing loss (training)
2022-11-03 00:03:48,635:INFO: Batch:  0/31	Total Loss 7.2964 (7.2964)
2022-11-03 00:03:49,106:INFO: Batch:  1/31	Total Loss 7.1223 (7.2076)
2022-11-03 00:03:49,585:INFO: Batch:  2/31	Total Loss 7.6667 (7.3663)
2022-11-03 00:03:50,053:INFO: Batch:  3/31	Total Loss 8.5670 (7.6425)
2022-11-03 00:03:50,521:INFO: Batch:  4/31	Total Loss 8.1087 (7.7402)
2022-11-03 00:03:50,996:INFO: Batch:  5/31	Total Loss 7.8145 (7.7526)
2022-11-03 00:03:51,467:INFO: Batch:  6/31	Total Loss 7.1414 (7.6722)
2022-11-03 00:03:51,936:INFO: Batch:  7/31	Total Loss 8.9696 (7.8373)
2022-11-03 00:03:52,406:INFO: Batch:  8/31	Total Loss 7.8245 (7.8359)
2022-11-03 00:03:52,875:INFO: Batch:  9/31	Total Loss 7.9414 (7.8456)
2022-11-03 00:03:53,342:INFO: Batch: 10/31	Total Loss 7.8367 (7.8448)
2022-11-03 00:03:53,813:INFO: Batch: 11/31	Total Loss 8.4345 (7.8874)
2022-11-03 00:03:54,288:INFO: Batch: 12/31	Total Loss 7.7320 (7.8739)
2022-11-03 00:03:54,763:INFO: Batch: 13/31	Total Loss 7.5627 (7.8511)
2022-11-03 00:03:55,238:INFO: Batch: 14/31	Total Loss 7.9848 (7.8598)
2022-11-03 00:03:55,712:INFO: Batch: 15/31	Total Loss 8.0126 (7.8692)
2022-11-03 00:03:56,187:INFO: Batch: 16/31	Total Loss 8.3348 (7.8965)
2022-11-03 00:03:56,661:INFO: Batch: 17/31	Total Loss 7.5331 (7.8748)
2022-11-03 00:03:57,134:INFO: Batch: 18/31	Total Loss 7.9452 (7.8781)
2022-11-03 00:03:57,607:INFO: Batch: 19/31	Total Loss 7.1743 (7.8458)
2022-11-03 00:03:58,080:INFO: Batch: 20/31	Total Loss 8.3537 (7.8697)
2022-11-03 00:03:58,553:INFO: Batch: 21/31	Total Loss 7.5878 (7.8574)
2022-11-03 00:03:59,024:INFO: Batch: 22/31	Total Loss 8.5573 (7.8834)
2022-11-03 00:03:59,496:INFO: Batch: 23/31	Total Loss 7.9924 (7.8875)
2022-11-03 00:03:59,969:INFO: Batch: 24/31	Total Loss 7.2082 (7.8601)
2022-11-03 00:04:00,443:INFO: Batch: 25/31	Total Loss 7.2460 (7.8366)
2022-11-03 00:04:00,915:INFO: Batch: 26/31	Total Loss 7.8003 (7.8353)
2022-11-03 00:04:01,388:INFO: Batch: 27/31	Total Loss 7.6927 (7.8305)
2022-11-03 00:04:01,860:INFO: Batch: 28/31	Total Loss 7.2587 (7.8132)
2022-11-03 00:04:02,331:INFO: Batch: 29/31	Total Loss 8.1157 (7.8232)
2022-11-03 00:04:02,719:INFO: Batch: 30/31	Total Loss 3.3369 (7.7740)
2022-11-03 00:04:02,868:INFO: - Computing ADE (validation o)
2022-11-03 00:04:03,466:INFO: 		 ADE on eth                       dataset:	 1.1942270994186401
2022-11-03 00:04:03,466:INFO: Average validation o:	ADE  1.1942	FDE  1.7919
2022-11-03 00:04:03,467:INFO: - Computing ADE (validation)
2022-11-03 00:04:03,748:INFO: 		 ADE on hotel                     dataset:	 0.5674152374267578
2022-11-03 00:04:04,044:INFO: 		 ADE on univ                      dataset:	 0.681259036064148
2022-11-03 00:04:04,306:INFO: 		 ADE on zara1                     dataset:	 0.7462229132652283
2022-11-03 00:04:04,676:INFO: 		 ADE on zara2                     dataset:	 0.5590583682060242
2022-11-03 00:04:04,676:INFO: Average validation:	ADE  0.6340	FDE  1.0653
2022-11-03 00:04:04,677:INFO: - Computing ADE (training)
2022-11-03 00:04:05,146:INFO: 		 ADE on hotel                     dataset:	 0.6764793395996094
2022-11-03 00:04:05,824:INFO: 		 ADE on univ                      dataset:	 0.6449188590049744
2022-11-03 00:04:06,358:INFO: 		 ADE on zara1                     dataset:	 0.8180215358734131
2022-11-03 00:04:07,099:INFO: 		 ADE on zara2                     dataset:	 0.6226959228515625
2022-11-03 00:04:07,099:INFO: Average training:	ADE  0.6522	FDE  1.1134
2022-11-03 00:04:07,108:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_288.pth.tar
2022-11-03 00:04:07,108:INFO: 
===> EPOCH: 289 (P3)
2022-11-03 00:04:07,108:INFO: - Computing loss (training)
2022-11-03 00:04:08,191:INFO: Batch:  0/31	Total Loss 7.8307 (7.8307)
2022-11-03 00:04:08,662:INFO: Batch:  1/31	Total Loss 8.2697 (8.0571)
2022-11-03 00:04:09,142:INFO: Batch:  2/31	Total Loss 7.6338 (7.9235)
2022-11-03 00:04:09,614:INFO: Batch:  3/31	Total Loss 7.2216 (7.7554)
2022-11-03 00:04:10,084:INFO: Batch:  4/31	Total Loss 8.0011 (7.8011)
2022-11-03 00:04:10,554:INFO: Batch:  5/31	Total Loss 8.1398 (7.8524)
2022-11-03 00:04:11,100:INFO: Batch:  6/31	Total Loss 7.3805 (7.7821)
2022-11-03 00:04:11,571:INFO: Batch:  7/31	Total Loss 7.9906 (7.8049)
2022-11-03 00:04:12,039:INFO: Batch:  8/31	Total Loss 7.8379 (7.8087)
2022-11-03 00:04:12,508:INFO: Batch:  9/31	Total Loss 7.5348 (7.7804)
2022-11-03 00:04:12,979:INFO: Batch: 10/31	Total Loss 8.1280 (7.8103)
2022-11-03 00:04:13,450:INFO: Batch: 11/31	Total Loss 7.1009 (7.7503)
2022-11-03 00:04:13,925:INFO: Batch: 12/31	Total Loss 7.4410 (7.7254)
2022-11-03 00:04:14,400:INFO: Batch: 13/31	Total Loss 7.0445 (7.6744)
2022-11-03 00:04:14,874:INFO: Batch: 14/31	Total Loss 8.1118 (7.7039)
2022-11-03 00:04:15,348:INFO: Batch: 15/31	Total Loss 7.7978 (7.7104)
2022-11-03 00:04:15,821:INFO: Batch: 16/31	Total Loss 7.1398 (7.6792)
2022-11-03 00:04:16,295:INFO: Batch: 17/31	Total Loss 7.0413 (7.6441)
2022-11-03 00:04:16,768:INFO: Batch: 18/31	Total Loss 7.9876 (7.6615)
2022-11-03 00:04:17,246:INFO: Batch: 19/31	Total Loss 7.5943 (7.6578)
2022-11-03 00:04:17,718:INFO: Batch: 20/31	Total Loss 8.4153 (7.6910)
2022-11-03 00:04:18,198:INFO: Batch: 21/31	Total Loss 7.1781 (7.6685)
2022-11-03 00:04:18,671:INFO: Batch: 22/31	Total Loss 7.3136 (7.6541)
2022-11-03 00:04:19,143:INFO: Batch: 23/31	Total Loss 7.1137 (7.6323)
2022-11-03 00:04:19,617:INFO: Batch: 24/31	Total Loss 7.9796 (7.6484)
2022-11-03 00:04:20,089:INFO: Batch: 25/31	Total Loss 6.9871 (7.6251)
2022-11-03 00:04:20,559:INFO: Batch: 26/31	Total Loss 7.7758 (7.6312)
2022-11-03 00:04:21,030:INFO: Batch: 27/31	Total Loss 6.3358 (7.5759)
2022-11-03 00:04:21,501:INFO: Batch: 28/31	Total Loss 6.7950 (7.5472)
2022-11-03 00:04:21,976:INFO: Batch: 29/31	Total Loss 7.7520 (7.5539)
2022-11-03 00:04:22,364:INFO: Batch: 30/31	Total Loss 2.9324 (7.5102)
2022-11-03 00:04:22,509:INFO: - Computing ADE (validation o)
2022-11-03 00:04:23,097:INFO: 		 ADE on eth                       dataset:	 1.1793993711471558
2022-11-03 00:04:23,098:INFO: Average validation o:	ADE  1.1794	FDE  1.8050
2022-11-03 00:04:23,098:INFO: - Computing ADE (validation)
2022-11-03 00:04:23,399:INFO: 		 ADE on hotel                     dataset:	 0.5501522421836853
2022-11-03 00:04:23,696:INFO: 		 ADE on univ                      dataset:	 0.665381669998169
2022-11-03 00:04:23,949:INFO: 		 ADE on zara1                     dataset:	 0.7478142976760864
2022-11-03 00:04:24,320:INFO: 		 ADE on zara2                     dataset:	 0.5524277091026306
2022-11-03 00:04:24,320:INFO: Average validation:	ADE  0.6224	FDE  1.0476
2022-11-03 00:04:24,320:INFO: - Computing ADE (training)
2022-11-03 00:04:24,802:INFO: 		 ADE on hotel                     dataset:	 0.6508345007896423
2022-11-03 00:04:25,474:INFO: 		 ADE on univ                      dataset:	 0.6385804414749146
2022-11-03 00:04:26,056:INFO: 		 ADE on zara1                     dataset:	 0.7976384162902832
2022-11-03 00:04:26,792:INFO: 		 ADE on zara2                     dataset:	 0.6105197668075562
2022-11-03 00:04:26,792:INFO: Average training:	ADE  0.6433	FDE  1.1058
2022-11-03 00:04:26,801:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_289.pth.tar
2022-11-03 00:04:26,801:INFO: 
===> EPOCH: 290 (P3)
2022-11-03 00:04:26,801:INFO: - Computing loss (training)
2022-11-03 00:04:27,892:INFO: Batch:  0/31	Total Loss 6.8756 (6.8756)
2022-11-03 00:04:28,366:INFO: Batch:  1/31	Total Loss 7.4499 (7.1794)
2022-11-03 00:04:28,841:INFO: Batch:  2/31	Total Loss 7.1658 (7.1755)
2022-11-03 00:04:29,308:INFO: Batch:  3/31	Total Loss 8.2001 (7.4104)
2022-11-03 00:04:29,784:INFO: Batch:  4/31	Total Loss 7.8109 (7.4905)
2022-11-03 00:04:30,257:INFO: Batch:  5/31	Total Loss 7.7810 (7.5386)
2022-11-03 00:04:30,730:INFO: Batch:  6/31	Total Loss 7.1352 (7.4842)
2022-11-03 00:04:31,198:INFO: Batch:  7/31	Total Loss 7.1360 (7.4396)
2022-11-03 00:04:31,669:INFO: Batch:  8/31	Total Loss 7.1145 (7.4061)
2022-11-03 00:04:32,137:INFO: Batch:  9/31	Total Loss 6.9905 (7.3628)
2022-11-03 00:04:32,611:INFO: Batch: 10/31	Total Loss 7.8855 (7.4078)
2022-11-03 00:04:33,083:INFO: Batch: 11/31	Total Loss 7.7885 (7.4393)
2022-11-03 00:04:33,558:INFO: Batch: 12/31	Total Loss 7.1958 (7.4211)
2022-11-03 00:04:34,029:INFO: Batch: 13/31	Total Loss 7.0777 (7.3966)
2022-11-03 00:04:34,506:INFO: Batch: 14/31	Total Loss 6.5057 (7.3388)
2022-11-03 00:04:34,979:INFO: Batch: 15/31	Total Loss 7.4829 (7.3479)
2022-11-03 00:04:35,452:INFO: Batch: 16/31	Total Loss 7.3561 (7.3484)
2022-11-03 00:04:35,922:INFO: Batch: 17/31	Total Loss 7.3493 (7.3485)
2022-11-03 00:04:36,397:INFO: Batch: 18/31	Total Loss 8.4403 (7.4059)
2022-11-03 00:04:36,867:INFO: Batch: 19/31	Total Loss 7.9209 (7.4315)
2022-11-03 00:04:37,338:INFO: Batch: 20/31	Total Loss 8.6201 (7.4928)
2022-11-03 00:04:37,807:INFO: Batch: 21/31	Total Loss 7.2793 (7.4829)
2022-11-03 00:04:38,278:INFO: Batch: 22/31	Total Loss 8.1770 (7.5101)
2022-11-03 00:04:38,748:INFO: Batch: 23/31	Total Loss 7.5563 (7.5120)
2022-11-03 00:04:39,219:INFO: Batch: 24/31	Total Loss 7.8180 (7.5247)
2022-11-03 00:04:39,688:INFO: Batch: 25/31	Total Loss 7.5850 (7.5272)
2022-11-03 00:04:40,161:INFO: Batch: 26/31	Total Loss 8.1737 (7.5523)
2022-11-03 00:04:40,632:INFO: Batch: 27/31	Total Loss 7.1648 (7.5384)
2022-11-03 00:04:41,102:INFO: Batch: 28/31	Total Loss 7.4576 (7.5358)
2022-11-03 00:04:41,573:INFO: Batch: 29/31	Total Loss 7.3851 (7.5304)
2022-11-03 00:04:41,960:INFO: Batch: 30/31	Total Loss 2.8501 (7.4786)
2022-11-03 00:04:42,108:INFO: - Computing ADE (validation o)
2022-11-03 00:04:42,679:INFO: 		 ADE on eth                       dataset:	 1.1712446212768555
2022-11-03 00:04:42,679:INFO: Average validation o:	ADE  1.1712	FDE  1.7878
2022-11-03 00:04:42,680:INFO: - Computing ADE (validation)
2022-11-03 00:04:42,946:INFO: 		 ADE on hotel                     dataset:	 0.5608781576156616
2022-11-03 00:04:43,245:INFO: 		 ADE on univ                      dataset:	 0.6579517722129822
2022-11-03 00:04:43,498:INFO: 		 ADE on zara1                     dataset:	 0.6971116065979004
2022-11-03 00:04:43,837:INFO: 		 ADE on zara2                     dataset:	 0.5401266813278198
2022-11-03 00:04:43,837:INFO: Average validation:	ADE  0.6117	FDE  1.0333
2022-11-03 00:04:43,838:INFO: - Computing ADE (training)
2022-11-03 00:04:44,307:INFO: 		 ADE on hotel                     dataset:	 0.6503661870956421
2022-11-03 00:04:44,984:INFO: 		 ADE on univ                      dataset:	 0.6312483549118042
2022-11-03 00:04:45,582:INFO: 		 ADE on zara1                     dataset:	 0.7762909531593323
2022-11-03 00:04:46,356:INFO: 		 ADE on zara2                     dataset:	 0.5983366370201111
2022-11-03 00:04:46,357:INFO: Average training:	ADE  0.6343	FDE  1.0915
2022-11-03 00:04:46,366:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_290.pth.tar
2022-11-03 00:04:46,366:INFO: 
===> EPOCH: 291 (P3)
2022-11-03 00:04:46,366:INFO: - Computing loss (training)
2022-11-03 00:04:47,452:INFO: Batch:  0/31	Total Loss 7.6783 (7.6783)
2022-11-03 00:04:47,924:INFO: Batch:  1/31	Total Loss 9.6258 (8.6624)
2022-11-03 00:04:48,398:INFO: Batch:  2/31	Total Loss 6.6711 (8.0017)
2022-11-03 00:04:48,866:INFO: Batch:  3/31	Total Loss 7.7558 (7.9440)
2022-11-03 00:04:49,343:INFO: Batch:  4/31	Total Loss 7.3494 (7.8219)
2022-11-03 00:04:49,816:INFO: Batch:  5/31	Total Loss 6.8658 (7.6609)
2022-11-03 00:04:50,288:INFO: Batch:  6/31	Total Loss 7.6876 (7.6651)
2022-11-03 00:04:50,757:INFO: Batch:  7/31	Total Loss 6.1500 (7.4867)
2022-11-03 00:04:51,227:INFO: Batch:  8/31	Total Loss 7.4445 (7.4820)
2022-11-03 00:04:51,695:INFO: Batch:  9/31	Total Loss 7.8577 (7.5188)
2022-11-03 00:04:52,167:INFO: Batch: 10/31	Total Loss 7.7370 (7.5381)
2022-11-03 00:04:52,636:INFO: Batch: 11/31	Total Loss 7.3836 (7.5266)
2022-11-03 00:04:53,109:INFO: Batch: 12/31	Total Loss 6.8240 (7.4753)
2022-11-03 00:04:53,582:INFO: Batch: 13/31	Total Loss 7.3470 (7.4668)
2022-11-03 00:04:54,054:INFO: Batch: 14/31	Total Loss 7.8352 (7.4898)
2022-11-03 00:04:54,528:INFO: Batch: 15/31	Total Loss 8.1566 (7.5289)
2022-11-03 00:04:55,003:INFO: Batch: 16/31	Total Loss 7.4077 (7.5221)
2022-11-03 00:04:55,475:INFO: Batch: 17/31	Total Loss 7.2473 (7.5063)
2022-11-03 00:04:55,949:INFO: Batch: 18/31	Total Loss 7.1791 (7.4880)
2022-11-03 00:04:56,421:INFO: Batch: 19/31	Total Loss 7.4345 (7.4855)
2022-11-03 00:04:56,894:INFO: Batch: 20/31	Total Loss 8.3437 (7.5187)
2022-11-03 00:04:57,366:INFO: Batch: 21/31	Total Loss 7.1157 (7.5004)
2022-11-03 00:04:57,841:INFO: Batch: 22/31	Total Loss 6.7721 (7.4653)
2022-11-03 00:04:58,317:INFO: Batch: 23/31	Total Loss 7.1662 (7.4531)
2022-11-03 00:04:58,788:INFO: Batch: 24/31	Total Loss 7.8227 (7.4671)
2022-11-03 00:04:59,261:INFO: Batch: 25/31	Total Loss 7.1389 (7.4559)
2022-11-03 00:04:59,733:INFO: Batch: 26/31	Total Loss 8.0261 (7.4766)
2022-11-03 00:05:00,206:INFO: Batch: 27/31	Total Loss 6.9362 (7.4596)
2022-11-03 00:05:00,676:INFO: Batch: 28/31	Total Loss 7.4084 (7.4576)
2022-11-03 00:05:01,149:INFO: Batch: 29/31	Total Loss 8.4805 (7.4906)
2022-11-03 00:05:01,614:INFO: Batch: 30/31	Total Loss 3.7738 (7.4572)
2022-11-03 00:05:01,760:INFO: - Computing ADE (validation o)
2022-11-03 00:05:02,334:INFO: 		 ADE on eth                       dataset:	 1.2034958600997925
2022-11-03 00:05:02,334:INFO: Average validation o:	ADE  1.2035	FDE  1.8330
2022-11-03 00:05:02,335:INFO: - Computing ADE (validation)
2022-11-03 00:05:02,623:INFO: 		 ADE on hotel                     dataset:	 0.5624694228172302
2022-11-03 00:05:02,917:INFO: 		 ADE on univ                      dataset:	 0.6908340454101562
2022-11-03 00:05:03,179:INFO: 		 ADE on zara1                     dataset:	 0.7875785827636719
2022-11-03 00:05:03,532:INFO: 		 ADE on zara2                     dataset:	 0.5726233720779419
2022-11-03 00:05:03,533:INFO: Average validation:	ADE  0.6461	FDE  1.0974
2022-11-03 00:05:03,533:INFO: - Computing ADE (training)
2022-11-03 00:05:03,990:INFO: 		 ADE on hotel                     dataset:	 0.6624170541763306
2022-11-03 00:05:04,703:INFO: 		 ADE on univ                      dataset:	 0.6511202454566956
2022-11-03 00:05:05,242:INFO: 		 ADE on zara1                     dataset:	 0.8309612274169922
2022-11-03 00:05:05,975:INFO: 		 ADE on zara2                     dataset:	 0.6388908624649048
2022-11-03 00:05:05,975:INFO: Average training:	ADE  0.6604	FDE  1.1381
2022-11-03 00:05:05,984:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_291.pth.tar
2022-11-03 00:05:05,984:INFO: 
===> EPOCH: 292 (P3)
2022-11-03 00:05:05,984:INFO: - Computing loss (training)
2022-11-03 00:05:07,101:INFO: Batch:  0/31	Total Loss 7.3336 (7.3336)
2022-11-03 00:05:07,578:INFO: Batch:  1/31	Total Loss 7.8986 (7.6111)
2022-11-03 00:05:08,057:INFO: Batch:  2/31	Total Loss 7.7430 (7.6525)
2022-11-03 00:05:08,533:INFO: Batch:  3/31	Total Loss 8.1621 (7.7871)
2022-11-03 00:05:09,004:INFO: Batch:  4/31	Total Loss 6.5618 (7.5422)
2022-11-03 00:05:09,478:INFO: Batch:  5/31	Total Loss 6.3629 (7.3352)
2022-11-03 00:05:09,957:INFO: Batch:  6/31	Total Loss 7.9724 (7.4368)
2022-11-03 00:05:10,429:INFO: Batch:  7/31	Total Loss 7.3331 (7.4230)
2022-11-03 00:05:10,905:INFO: Batch:  8/31	Total Loss 6.8726 (7.3558)
2022-11-03 00:05:11,379:INFO: Batch:  9/31	Total Loss 7.2141 (7.3426)
2022-11-03 00:05:11,852:INFO: Batch: 10/31	Total Loss 7.5296 (7.3601)
2022-11-03 00:05:12,322:INFO: Batch: 11/31	Total Loss 7.5659 (7.3766)
2022-11-03 00:05:12,801:INFO: Batch: 12/31	Total Loss 7.0050 (7.3452)
2022-11-03 00:05:13,280:INFO: Batch: 13/31	Total Loss 7.8296 (7.3816)
2022-11-03 00:05:13,758:INFO: Batch: 14/31	Total Loss 6.7804 (7.3385)
2022-11-03 00:05:14,236:INFO: Batch: 15/31	Total Loss 8.2151 (7.3949)
2022-11-03 00:05:14,711:INFO: Batch: 16/31	Total Loss 7.0216 (7.3745)
2022-11-03 00:05:15,189:INFO: Batch: 17/31	Total Loss 6.4663 (7.3188)
2022-11-03 00:05:15,665:INFO: Batch: 18/31	Total Loss 8.4336 (7.3711)
2022-11-03 00:05:16,143:INFO: Batch: 19/31	Total Loss 7.1088 (7.3580)
2022-11-03 00:05:16,619:INFO: Batch: 20/31	Total Loss 7.7765 (7.3773)
2022-11-03 00:05:17,094:INFO: Batch: 21/31	Total Loss 7.8644 (7.3971)
2022-11-03 00:05:17,569:INFO: Batch: 22/31	Total Loss 9.0895 (7.4628)
2022-11-03 00:05:18,045:INFO: Batch: 23/31	Total Loss 8.0558 (7.4879)
2022-11-03 00:05:18,520:INFO: Batch: 24/31	Total Loss 7.9120 (7.5053)
2022-11-03 00:05:18,997:INFO: Batch: 25/31	Total Loss 7.8037 (7.5176)
2022-11-03 00:05:19,471:INFO: Batch: 26/31	Total Loss 7.2924 (7.5088)
2022-11-03 00:05:19,945:INFO: Batch: 27/31	Total Loss 7.7026 (7.5161)
2022-11-03 00:05:20,421:INFO: Batch: 28/31	Total Loss 7.0019 (7.4990)
2022-11-03 00:05:20,895:INFO: Batch: 29/31	Total Loss 7.2322 (7.4888)
2022-11-03 00:05:21,286:INFO: Batch: 30/31	Total Loss 3.5157 (7.4494)
2022-11-03 00:05:21,434:INFO: - Computing ADE (validation o)
2022-11-03 00:05:22,014:INFO: 		 ADE on eth                       dataset:	 1.2371970415115356
2022-11-03 00:05:22,014:INFO: Average validation o:	ADE  1.2372	FDE  1.9794
2022-11-03 00:05:22,015:INFO: - Computing ADE (validation)
2022-11-03 00:05:22,276:INFO: 		 ADE on hotel                     dataset:	 0.646899402141571
2022-11-03 00:05:22,587:INFO: 		 ADE on univ                      dataset:	 0.7112005352973938
2022-11-03 00:05:22,843:INFO: 		 ADE on zara1                     dataset:	 0.8491378426551819
2022-11-03 00:05:23,176:INFO: 		 ADE on zara2                     dataset:	 0.6537301540374756
2022-11-03 00:05:23,176:INFO: Average validation:	ADE  0.6946	FDE  1.2473
2022-11-03 00:05:23,177:INFO: - Computing ADE (training)
2022-11-03 00:05:23,614:INFO: 		 ADE on hotel                     dataset:	 0.7298976182937622
2022-11-03 00:05:24,307:INFO: 		 ADE on univ                      dataset:	 0.705344557762146
2022-11-03 00:05:24,826:INFO: 		 ADE on zara1                     dataset:	 0.8793447017669678
2022-11-03 00:05:25,594:INFO: 		 ADE on zara2                     dataset:	 0.7062098383903503
2022-11-03 00:05:25,594:INFO: Average training:	ADE  0.7172	FDE  1.3126
2022-11-03 00:05:25,603:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_292.pth.tar
2022-11-03 00:05:25,603:INFO: 
===> EPOCH: 293 (P3)
2022-11-03 00:05:25,603:INFO: - Computing loss (training)
2022-11-03 00:05:26,693:INFO: Batch:  0/31	Total Loss 8.9927 (8.9927)
2022-11-03 00:05:27,167:INFO: Batch:  1/31	Total Loss 7.7470 (8.2932)
2022-11-03 00:05:27,640:INFO: Batch:  2/31	Total Loss 7.9977 (8.1960)
2022-11-03 00:05:28,114:INFO: Batch:  3/31	Total Loss 8.1606 (8.1886)
2022-11-03 00:05:28,590:INFO: Batch:  4/31	Total Loss 6.7632 (7.9049)
2022-11-03 00:05:29,067:INFO: Batch:  5/31	Total Loss 7.8546 (7.8970)
2022-11-03 00:05:29,543:INFO: Batch:  6/31	Total Loss 7.8739 (7.8937)
2022-11-03 00:05:30,021:INFO: Batch:  7/31	Total Loss 7.5327 (7.8476)
2022-11-03 00:05:30,495:INFO: Batch:  8/31	Total Loss 7.9818 (7.8638)
2022-11-03 00:05:30,970:INFO: Batch:  9/31	Total Loss 6.9256 (7.7680)
2022-11-03 00:05:31,447:INFO: Batch: 10/31	Total Loss 7.1814 (7.7139)
2022-11-03 00:05:31,918:INFO: Batch: 11/31	Total Loss 7.8421 (7.7234)
2022-11-03 00:05:32,393:INFO: Batch: 12/31	Total Loss 7.6249 (7.7159)
2022-11-03 00:05:32,868:INFO: Batch: 13/31	Total Loss 8.5351 (7.7784)
2022-11-03 00:05:33,343:INFO: Batch: 14/31	Total Loss 7.2525 (7.7407)
2022-11-03 00:05:33,816:INFO: Batch: 15/31	Total Loss 6.7516 (7.6831)
2022-11-03 00:05:34,291:INFO: Batch: 16/31	Total Loss 7.0300 (7.6454)
2022-11-03 00:05:34,764:INFO: Batch: 17/31	Total Loss 7.5314 (7.6393)
2022-11-03 00:05:35,238:INFO: Batch: 18/31	Total Loss 7.0137 (7.6058)
2022-11-03 00:05:35,710:INFO: Batch: 19/31	Total Loss 6.7593 (7.5603)
2022-11-03 00:05:36,183:INFO: Batch: 20/31	Total Loss 6.9358 (7.5310)
2022-11-03 00:05:36,665:INFO: Batch: 21/31	Total Loss 8.8016 (7.5882)
2022-11-03 00:05:37,154:INFO: Batch: 22/31	Total Loss 9.1681 (7.6554)
2022-11-03 00:05:37,637:INFO: Batch: 23/31	Total Loss 6.6882 (7.6190)
2022-11-03 00:05:38,124:INFO: Batch: 24/31	Total Loss 6.9621 (7.5918)
2022-11-03 00:05:38,668:INFO: Batch: 25/31	Total Loss 7.4515 (7.5859)
2022-11-03 00:05:39,421:INFO: Batch: 26/31	Total Loss 6.9136 (7.5605)
2022-11-03 00:05:40,017:INFO: Batch: 27/31	Total Loss 6.5049 (7.5212)
2022-11-03 00:05:40,561:INFO: Batch: 28/31	Total Loss 7.4909 (7.5203)
2022-11-03 00:05:41,115:INFO: Batch: 29/31	Total Loss 6.8112 (7.4968)
2022-11-03 00:05:41,516:INFO: Batch: 30/31	Total Loss 2.5441 (7.4415)
2022-11-03 00:05:41,673:INFO: - Computing ADE (validation o)
2022-11-03 00:05:42,260:INFO: 		 ADE on eth                       dataset:	 1.1790883541107178
2022-11-03 00:05:42,260:INFO: Average validation o:	ADE  1.1791	FDE  1.8214
2022-11-03 00:05:42,261:INFO: - Computing ADE (validation)
2022-11-03 00:05:42,552:INFO: 		 ADE on hotel                     dataset:	 0.536823034286499
2022-11-03 00:05:42,870:INFO: 		 ADE on univ                      dataset:	 0.6603683233261108
2022-11-03 00:05:43,124:INFO: 		 ADE on zara1                     dataset:	 0.7293325066566467
2022-11-03 00:05:43,502:INFO: 		 ADE on zara2                     dataset:	 0.5383589863777161
2022-11-03 00:05:43,502:INFO: Average validation:	ADE  0.6129	FDE  1.0297
2022-11-03 00:05:43,503:INFO: - Computing ADE (training)
2022-11-03 00:05:43,973:INFO: 		 ADE on hotel                     dataset:	 0.6288276314735413
2022-11-03 00:05:44,736:INFO: 		 ADE on univ                      dataset:	 0.6289981603622437
2022-11-03 00:05:45,286:INFO: 		 ADE on zara1                     dataset:	 0.7874829769134521
2022-11-03 00:05:46,072:INFO: 		 ADE on zara2                     dataset:	 0.5983808636665344
2022-11-03 00:05:46,072:INFO: Average training:	ADE  0.6329	FDE  1.0844
2022-11-03 00:05:46,081:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_293.pth.tar
2022-11-03 00:05:46,081:INFO: 
===> EPOCH: 294 (P3)
2022-11-03 00:05:46,082:INFO: - Computing loss (training)
2022-11-03 00:05:47,194:INFO: Batch:  0/31	Total Loss 7.8975 (7.8975)
2022-11-03 00:05:47,694:INFO: Batch:  1/31	Total Loss 6.9923 (7.4523)
2022-11-03 00:05:48,245:INFO: Batch:  2/31	Total Loss 7.7914 (7.5572)
2022-11-03 00:05:48,747:INFO: Batch:  3/31	Total Loss 7.0694 (7.4262)
2022-11-03 00:05:49,253:INFO: Batch:  4/31	Total Loss 7.2585 (7.3913)
2022-11-03 00:05:49,755:INFO: Batch:  5/31	Total Loss 6.6109 (7.2599)
2022-11-03 00:05:50,243:INFO: Batch:  6/31	Total Loss 7.7291 (7.3289)
2022-11-03 00:05:50,715:INFO: Batch:  7/31	Total Loss 6.4162 (7.2153)
2022-11-03 00:05:51,204:INFO: Batch:  8/31	Total Loss 6.6854 (7.1559)
2022-11-03 00:05:51,719:INFO: Batch:  9/31	Total Loss 7.4848 (7.1908)
2022-11-03 00:05:52,212:INFO: Batch: 10/31	Total Loss 7.0602 (7.1786)
2022-11-03 00:05:52,695:INFO: Batch: 11/31	Total Loss 7.3724 (7.1967)
2022-11-03 00:05:53,192:INFO: Batch: 12/31	Total Loss 6.8059 (7.1671)
2022-11-03 00:05:53,725:INFO: Batch: 13/31	Total Loss 7.1395 (7.1652)
2022-11-03 00:05:54,250:INFO: Batch: 14/31	Total Loss 6.9024 (7.1485)
2022-11-03 00:05:54,752:INFO: Batch: 15/31	Total Loss 7.7470 (7.1862)
2022-11-03 00:05:55,292:INFO: Batch: 16/31	Total Loss 7.3011 (7.1925)
2022-11-03 00:05:55,831:INFO: Batch: 17/31	Total Loss 8.0939 (7.2444)
2022-11-03 00:05:56,392:INFO: Batch: 18/31	Total Loss 7.1318 (7.2386)
2022-11-03 00:05:56,910:INFO: Batch: 19/31	Total Loss 7.4873 (7.2517)
2022-11-03 00:05:57,440:INFO: Batch: 20/31	Total Loss 7.1641 (7.2475)
2022-11-03 00:05:58,038:INFO: Batch: 21/31	Total Loss 6.9588 (7.2336)
2022-11-03 00:05:58,561:INFO: Batch: 22/31	Total Loss 7.4232 (7.2423)
2022-11-03 00:05:59,070:INFO: Batch: 23/31	Total Loss 7.4849 (7.2526)
2022-11-03 00:05:59,611:INFO: Batch: 24/31	Total Loss 7.6053 (7.2669)
2022-11-03 00:06:00,134:INFO: Batch: 25/31	Total Loss 6.5010 (7.2389)
2022-11-03 00:06:00,668:INFO: Batch: 26/31	Total Loss 7.7662 (7.2578)
2022-11-03 00:06:01,164:INFO: Batch: 27/31	Total Loss 6.7636 (7.2411)
2022-11-03 00:06:01,694:INFO: Batch: 28/31	Total Loss 6.3635 (7.2083)
2022-11-03 00:06:02,231:INFO: Batch: 29/31	Total Loss 7.1070 (7.2050)
2022-11-03 00:06:02,639:INFO: Batch: 30/31	Total Loss 2.3593 (7.1506)
2022-11-03 00:06:02,801:INFO: - Computing ADE (validation o)
2022-11-03 00:06:03,417:INFO: 		 ADE on eth                       dataset:	 1.1572308540344238
2022-11-03 00:06:03,417:INFO: Average validation o:	ADE  1.1572	FDE  1.8103
2022-11-03 00:06:03,418:INFO: - Computing ADE (validation)
2022-11-03 00:06:03,698:INFO: 		 ADE on hotel                     dataset:	 0.5444362759590149
2022-11-03 00:06:04,055:INFO: 		 ADE on univ                      dataset:	 0.6620352268218994
2022-11-03 00:06:04,383:INFO: 		 ADE on zara1                     dataset:	 0.7395263910293579
2022-11-03 00:06:04,810:INFO: 		 ADE on zara2                     dataset:	 0.5400464534759521
2022-11-03 00:06:04,810:INFO: Average validation:	ADE  0.6154	FDE  1.0482
2022-11-03 00:06:04,811:INFO: - Computing ADE (training)
2022-11-03 00:06:05,482:INFO: 		 ADE on hotel                     dataset:	 0.6385970711708069
2022-11-03 00:06:06,182:INFO: 		 ADE on univ                      dataset:	 0.6332471966743469
2022-11-03 00:06:06,738:INFO: 		 ADE on zara1                     dataset:	 0.7702110409736633
2022-11-03 00:06:07,475:INFO: 		 ADE on zara2                     dataset:	 0.5941705703735352
2022-11-03 00:06:07,475:INFO: Average training:	ADE  0.6342	FDE  1.1033
2022-11-03 00:06:07,484:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_294.pth.tar
2022-11-03 00:06:07,484:INFO: 
===> EPOCH: 295 (P3)
2022-11-03 00:06:07,484:INFO: - Computing loss (training)
2022-11-03 00:06:08,598:INFO: Batch:  0/31	Total Loss 6.8304 (6.8304)
2022-11-03 00:06:09,091:INFO: Batch:  1/31	Total Loss 7.1998 (7.0147)
2022-11-03 00:06:09,597:INFO: Batch:  2/31	Total Loss 6.7152 (6.9168)
2022-11-03 00:06:10,102:INFO: Batch:  3/31	Total Loss 6.4882 (6.8078)
2022-11-03 00:06:10,655:INFO: Batch:  4/31	Total Loss 7.9991 (7.0609)
2022-11-03 00:06:11,224:INFO: Batch:  5/31	Total Loss 7.1645 (7.0792)
2022-11-03 00:06:11,767:INFO: Batch:  6/31	Total Loss 7.3450 (7.1172)
2022-11-03 00:06:12,314:INFO: Batch:  7/31	Total Loss 7.8793 (7.2042)
2022-11-03 00:06:12,848:INFO: Batch:  8/31	Total Loss 6.8878 (7.1660)
2022-11-03 00:06:13,329:INFO: Batch:  9/31	Total Loss 6.7691 (7.1290)
2022-11-03 00:06:13,819:INFO: Batch: 10/31	Total Loss 7.2282 (7.1382)
2022-11-03 00:06:14,321:INFO: Batch: 11/31	Total Loss 7.2382 (7.1466)
2022-11-03 00:06:14,816:INFO: Batch: 12/31	Total Loss 7.4587 (7.1723)
2022-11-03 00:06:15,304:INFO: Batch: 13/31	Total Loss 7.4322 (7.1914)
2022-11-03 00:06:15,806:INFO: Batch: 14/31	Total Loss 7.3944 (7.2046)
2022-11-03 00:06:16,305:INFO: Batch: 15/31	Total Loss 6.9040 (7.1846)
2022-11-03 00:06:16,800:INFO: Batch: 16/31	Total Loss 6.8751 (7.1671)
2022-11-03 00:06:17,285:INFO: Batch: 17/31	Total Loss 6.2726 (7.1183)
2022-11-03 00:06:17,770:INFO: Batch: 18/31	Total Loss 7.3289 (7.1293)
2022-11-03 00:06:18,285:INFO: Batch: 19/31	Total Loss 6.8381 (7.1140)
2022-11-03 00:06:18,777:INFO: Batch: 20/31	Total Loss 6.5159 (7.0852)
2022-11-03 00:06:19,266:INFO: Batch: 21/31	Total Loss 6.8974 (7.0775)
2022-11-03 00:06:19,750:INFO: Batch: 22/31	Total Loss 7.9800 (7.1146)
2022-11-03 00:06:20,236:INFO: Batch: 23/31	Total Loss 6.8635 (7.1041)
2022-11-03 00:06:20,724:INFO: Batch: 24/31	Total Loss 6.7443 (7.0889)
2022-11-03 00:06:21,218:INFO: Batch: 25/31	Total Loss 6.6724 (7.0725)
2022-11-03 00:06:21,709:INFO: Batch: 26/31	Total Loss 7.5580 (7.0904)
2022-11-03 00:06:22,215:INFO: Batch: 27/31	Total Loss 7.3806 (7.1014)
2022-11-03 00:06:22,728:INFO: Batch: 28/31	Total Loss 8.0192 (7.1316)
2022-11-03 00:06:23,219:INFO: Batch: 29/31	Total Loss 7.1932 (7.1337)
2022-11-03 00:06:23,632:INFO: Batch: 30/31	Total Loss 2.7181 (7.0908)
2022-11-03 00:06:23,782:INFO: - Computing ADE (validation o)
2022-11-03 00:06:24,372:INFO: 		 ADE on eth                       dataset:	 1.1668285131454468
2022-11-03 00:06:24,372:INFO: Average validation o:	ADE  1.1668	FDE  1.8147
2022-11-03 00:06:24,373:INFO: - Computing ADE (validation)
2022-11-03 00:06:24,634:INFO: 		 ADE on hotel                     dataset:	 0.5494056344032288
2022-11-03 00:06:24,919:INFO: 		 ADE on univ                      dataset:	 0.6636359691619873
2022-11-03 00:06:25,179:INFO: 		 ADE on zara1                     dataset:	 0.7308804988861084
2022-11-03 00:06:25,526:INFO: 		 ADE on zara2                     dataset:	 0.5364676713943481
2022-11-03 00:06:25,526:INFO: Average validation:	ADE  0.6146	FDE  1.0409
2022-11-03 00:06:25,527:INFO: - Computing ADE (training)
2022-11-03 00:06:25,969:INFO: 		 ADE on hotel                     dataset:	 0.648444414138794
2022-11-03 00:06:26,646:INFO: 		 ADE on univ                      dataset:	 0.6328977942466736
2022-11-03 00:06:27,224:INFO: 		 ADE on zara1                     dataset:	 0.7813668251037598
2022-11-03 00:06:27,984:INFO: 		 ADE on zara2                     dataset:	 0.5931773781776428
2022-11-03 00:06:27,985:INFO: Average training:	ADE  0.6347	FDE  1.0958
2022-11-03 00:06:27,993:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_295.pth.tar
2022-11-03 00:06:27,993:INFO: 
===> EPOCH: 296 (P3)
2022-11-03 00:06:27,994:INFO: - Computing loss (training)
2022-11-03 00:06:29,083:INFO: Batch:  0/31	Total Loss 7.2265 (7.2265)
2022-11-03 00:06:29,577:INFO: Batch:  1/31	Total Loss 7.8585 (7.5474)
2022-11-03 00:06:30,076:INFO: Batch:  2/31	Total Loss 8.0929 (7.7200)
2022-11-03 00:06:30,563:INFO: Batch:  3/31	Total Loss 6.5374 (7.3883)
2022-11-03 00:06:31,054:INFO: Batch:  4/31	Total Loss 6.3015 (7.1595)
2022-11-03 00:06:31,545:INFO: Batch:  5/31	Total Loss 5.9690 (6.9798)
2022-11-03 00:06:32,034:INFO: Batch:  6/31	Total Loss 7.3287 (7.0311)
2022-11-03 00:06:32,522:INFO: Batch:  7/31	Total Loss 7.6003 (7.0978)
2022-11-03 00:06:33,013:INFO: Batch:  8/31	Total Loss 7.4390 (7.1349)
2022-11-03 00:06:33,500:INFO: Batch:  9/31	Total Loss 7.0260 (7.1249)
2022-11-03 00:06:33,988:INFO: Batch: 10/31	Total Loss 6.3462 (7.0462)
2022-11-03 00:06:34,477:INFO: Batch: 11/31	Total Loss 6.8678 (7.0307)
2022-11-03 00:06:34,970:INFO: Batch: 12/31	Total Loss 6.4864 (6.9920)
2022-11-03 00:06:35,466:INFO: Batch: 13/31	Total Loss 6.4887 (6.9511)
2022-11-03 00:06:35,959:INFO: Batch: 14/31	Total Loss 6.7429 (6.9378)
2022-11-03 00:06:36,454:INFO: Batch: 15/31	Total Loss 6.5577 (6.9132)
2022-11-03 00:06:36,947:INFO: Batch: 16/31	Total Loss 7.2692 (6.9352)
2022-11-03 00:06:37,441:INFO: Batch: 17/31	Total Loss 6.6255 (6.9174)
2022-11-03 00:06:37,935:INFO: Batch: 18/31	Total Loss 7.2818 (6.9337)
2022-11-03 00:06:38,427:INFO: Batch: 19/31	Total Loss 6.9428 (6.9342)
2022-11-03 00:06:38,919:INFO: Batch: 20/31	Total Loss 6.2974 (6.9065)
2022-11-03 00:06:39,406:INFO: Batch: 21/31	Total Loss 7.2216 (6.9195)
2022-11-03 00:06:39,885:INFO: Batch: 22/31	Total Loss 7.0017 (6.9231)
2022-11-03 00:06:40,364:INFO: Batch: 23/31	Total Loss 6.8803 (6.9212)
2022-11-03 00:06:40,841:INFO: Batch: 24/31	Total Loss 7.4855 (6.9431)
2022-11-03 00:06:41,317:INFO: Batch: 25/31	Total Loss 7.3541 (6.9581)
2022-11-03 00:06:41,790:INFO: Batch: 26/31	Total Loss 5.7321 (6.9116)
2022-11-03 00:06:42,263:INFO: Batch: 27/31	Total Loss 6.7128 (6.9040)
2022-11-03 00:06:42,740:INFO: Batch: 28/31	Total Loss 6.6314 (6.8940)
2022-11-03 00:06:43,213:INFO: Batch: 29/31	Total Loss 6.3436 (6.8747)
2022-11-03 00:06:43,605:INFO: Batch: 30/31	Total Loss 2.3780 (6.8296)
2022-11-03 00:06:43,753:INFO: - Computing ADE (validation o)
2022-11-03 00:06:44,376:INFO: 		 ADE on eth                       dataset:	 1.1830075979232788
2022-11-03 00:06:44,376:INFO: Average validation o:	ADE  1.1830	FDE  1.8180
2022-11-03 00:06:44,377:INFO: - Computing ADE (validation)
2022-11-03 00:06:44,663:INFO: 		 ADE on hotel                     dataset:	 0.5550756454467773
2022-11-03 00:06:44,961:INFO: 		 ADE on univ                      dataset:	 0.6599079966545105
2022-11-03 00:06:45,239:INFO: 		 ADE on zara1                     dataset:	 0.7365006804466248
2022-11-03 00:06:45,583:INFO: 		 ADE on zara2                     dataset:	 0.5453364253044128
2022-11-03 00:06:45,583:INFO: Average validation:	ADE  0.6166	FDE  1.0365
2022-11-03 00:06:45,584:INFO: - Computing ADE (training)
2022-11-03 00:06:46,038:INFO: 		 ADE on hotel                     dataset:	 0.6437909007072449
2022-11-03 00:06:46,724:INFO: 		 ADE on univ                      dataset:	 0.6324487328529358
2022-11-03 00:06:47,275:INFO: 		 ADE on zara1                     dataset:	 0.7948445677757263
2022-11-03 00:06:48,012:INFO: 		 ADE on zara2                     dataset:	 0.6079627871513367
2022-11-03 00:06:48,012:INFO: Average training:	ADE  0.6381	FDE  1.0938
2022-11-03 00:06:48,021:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_296.pth.tar
2022-11-03 00:06:48,022:INFO: 
===> EPOCH: 297 (P3)
2022-11-03 00:06:48,022:INFO: - Computing loss (training)
2022-11-03 00:06:49,129:INFO: Batch:  0/31	Total Loss 7.3277 (7.3277)
2022-11-03 00:06:49,609:INFO: Batch:  1/31	Total Loss 7.4617 (7.3958)
2022-11-03 00:06:50,081:INFO: Batch:  2/31	Total Loss 6.5164 (7.0948)
2022-11-03 00:06:50,548:INFO: Batch:  3/31	Total Loss 7.0828 (7.0920)
2022-11-03 00:06:51,017:INFO: Batch:  4/31	Total Loss 6.6580 (7.0020)
2022-11-03 00:06:51,492:INFO: Batch:  5/31	Total Loss 7.6244 (7.1164)
2022-11-03 00:06:51,968:INFO: Batch:  6/31	Total Loss 8.2062 (7.2786)
2022-11-03 00:06:52,436:INFO: Batch:  7/31	Total Loss 6.5294 (7.1638)
2022-11-03 00:06:52,910:INFO: Batch:  8/31	Total Loss 6.7270 (7.1094)
2022-11-03 00:06:53,381:INFO: Batch:  9/31	Total Loss 7.3618 (7.1343)
2022-11-03 00:06:53,857:INFO: Batch: 10/31	Total Loss 7.0982 (7.1306)
2022-11-03 00:06:54,325:INFO: Batch: 11/31	Total Loss 7.1235 (7.1300)
2022-11-03 00:06:54,799:INFO: Batch: 12/31	Total Loss 7.2061 (7.1361)
2022-11-03 00:06:55,351:INFO: Batch: 13/31	Total Loss 6.5883 (7.0954)
2022-11-03 00:06:55,825:INFO: Batch: 14/31	Total Loss 6.9043 (7.0817)
2022-11-03 00:06:56,300:INFO: Batch: 15/31	Total Loss 6.7451 (7.0601)
2022-11-03 00:06:56,773:INFO: Batch: 16/31	Total Loss 6.9194 (7.0520)
2022-11-03 00:06:57,247:INFO: Batch: 17/31	Total Loss 6.0449 (6.9944)
2022-11-03 00:06:57,723:INFO: Batch: 18/31	Total Loss 7.2375 (7.0068)
2022-11-03 00:06:58,196:INFO: Batch: 19/31	Total Loss 7.0034 (7.0066)
2022-11-03 00:06:58,670:INFO: Batch: 20/31	Total Loss 6.7207 (6.9923)
2022-11-03 00:06:59,142:INFO: Batch: 21/31	Total Loss 6.2493 (6.9599)
2022-11-03 00:06:59,616:INFO: Batch: 22/31	Total Loss 6.4369 (6.9361)
2022-11-03 00:07:00,091:INFO: Batch: 23/31	Total Loss 6.5186 (6.9168)
2022-11-03 00:07:00,565:INFO: Batch: 24/31	Total Loss 6.2100 (6.8883)
2022-11-03 00:07:01,035:INFO: Batch: 25/31	Total Loss 6.7833 (6.8841)
2022-11-03 00:07:01,512:INFO: Batch: 26/31	Total Loss 6.6443 (6.8750)
2022-11-03 00:07:01,985:INFO: Batch: 27/31	Total Loss 6.8339 (6.8735)
2022-11-03 00:07:02,457:INFO: Batch: 28/31	Total Loss 7.0916 (6.8808)
2022-11-03 00:07:02,931:INFO: Batch: 29/31	Total Loss 6.2312 (6.8591)
2022-11-03 00:07:03,318:INFO: Batch: 30/31	Total Loss 2.7443 (6.8169)
2022-11-03 00:07:03,469:INFO: - Computing ADE (validation o)
2022-11-03 00:07:04,074:INFO: 		 ADE on eth                       dataset:	 1.1831603050231934
2022-11-03 00:07:04,074:INFO: Average validation o:	ADE  1.1832	FDE  1.8033
2022-11-03 00:07:04,074:INFO: - Computing ADE (validation)
2022-11-03 00:07:04,349:INFO: 		 ADE on hotel                     dataset:	 0.5514881014823914
2022-11-03 00:07:04,656:INFO: 		 ADE on univ                      dataset:	 0.6697434782981873
2022-11-03 00:07:04,910:INFO: 		 ADE on zara1                     dataset:	 0.756420373916626
2022-11-03 00:07:05,267:INFO: 		 ADE on zara2                     dataset:	 0.546874463558197
2022-11-03 00:07:05,267:INFO: Average validation:	ADE  0.6232	FDE  1.0450
2022-11-03 00:07:05,268:INFO: - Computing ADE (training)
2022-11-03 00:07:05,723:INFO: 		 ADE on hotel                     dataset:	 0.6490562558174133
2022-11-03 00:07:06,412:INFO: 		 ADE on univ                      dataset:	 0.6355306506156921
2022-11-03 00:07:06,962:INFO: 		 ADE on zara1                     dataset:	 0.8106427788734436
2022-11-03 00:07:07,724:INFO: 		 ADE on zara2                     dataset:	 0.6114867329597473
2022-11-03 00:07:07,724:INFO: Average training:	ADE  0.6422	FDE  1.0954
2022-11-03 00:07:07,733:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_297.pth.tar
2022-11-03 00:07:07,733:INFO: 
===> EPOCH: 298 (P3)
2022-11-03 00:07:07,733:INFO: - Computing loss (training)
2022-11-03 00:07:08,814:INFO: Batch:  0/31	Total Loss 6.8608 (6.8608)
2022-11-03 00:07:09,291:INFO: Batch:  1/31	Total Loss 6.6939 (6.7708)
2022-11-03 00:07:09,768:INFO: Batch:  2/31	Total Loss 6.8844 (6.8089)
2022-11-03 00:07:10,235:INFO: Batch:  3/31	Total Loss 6.7135 (6.7844)
2022-11-03 00:07:10,711:INFO: Batch:  4/31	Total Loss 6.0878 (6.6364)
2022-11-03 00:07:11,190:INFO: Batch:  5/31	Total Loss 7.8477 (6.8526)
2022-11-03 00:07:11,666:INFO: Batch:  6/31	Total Loss 7.3847 (6.9176)
2022-11-03 00:07:12,160:INFO: Batch:  7/31	Total Loss 6.6235 (6.8856)
2022-11-03 00:07:12,655:INFO: Batch:  8/31	Total Loss 7.5324 (6.9635)
2022-11-03 00:07:13,151:INFO: Batch:  9/31	Total Loss 7.5146 (7.0186)
2022-11-03 00:07:13,652:INFO: Batch: 10/31	Total Loss 6.4704 (6.9677)
2022-11-03 00:07:14,146:INFO: Batch: 11/31	Total Loss 7.3897 (7.0066)
2022-11-03 00:07:14,643:INFO: Batch: 12/31	Total Loss 6.8943 (6.9987)
2022-11-03 00:07:15,144:INFO: Batch: 13/31	Total Loss 6.6234 (6.9702)
2022-11-03 00:07:15,641:INFO: Batch: 14/31	Total Loss 6.0609 (6.9042)
2022-11-03 00:07:16,140:INFO: Batch: 15/31	Total Loss 6.3472 (6.8653)
2022-11-03 00:07:16,639:INFO: Batch: 16/31	Total Loss 6.6929 (6.8550)
2022-11-03 00:07:17,136:INFO: Batch: 17/31	Total Loss 6.2812 (6.8238)
2022-11-03 00:07:17,619:INFO: Batch: 18/31	Total Loss 6.7451 (6.8199)
2022-11-03 00:07:18,095:INFO: Batch: 19/31	Total Loss 6.6478 (6.8116)
2022-11-03 00:07:18,569:INFO: Batch: 20/31	Total Loss 6.9252 (6.8168)
2022-11-03 00:07:19,042:INFO: Batch: 21/31	Total Loss 7.1832 (6.8321)
2022-11-03 00:07:19,515:INFO: Batch: 22/31	Total Loss 6.5517 (6.8203)
2022-11-03 00:07:19,990:INFO: Batch: 23/31	Total Loss 7.1305 (6.8314)
2022-11-03 00:07:20,461:INFO: Batch: 24/31	Total Loss 6.9156 (6.8347)
2022-11-03 00:07:20,934:INFO: Batch: 25/31	Total Loss 6.6631 (6.8285)
2022-11-03 00:07:21,406:INFO: Batch: 26/31	Total Loss 7.0989 (6.8383)
2022-11-03 00:07:21,879:INFO: Batch: 27/31	Total Loss 7.4548 (6.8595)
2022-11-03 00:07:22,350:INFO: Batch: 28/31	Total Loss 6.6348 (6.8510)
2022-11-03 00:07:22,828:INFO: Batch: 29/31	Total Loss 5.7613 (6.8166)
2022-11-03 00:07:23,218:INFO: Batch: 30/31	Total Loss 2.6694 (6.7736)
2022-11-03 00:07:23,366:INFO: - Computing ADE (validation o)
2022-11-03 00:07:23,959:INFO: 		 ADE on eth                       dataset:	 1.1622706651687622
2022-11-03 00:07:23,959:INFO: Average validation o:	ADE  1.1623	FDE  1.8246
2022-11-03 00:07:23,959:INFO: - Computing ADE (validation)
2022-11-03 00:07:24,238:INFO: 		 ADE on hotel                     dataset:	 0.5355180501937866
2022-11-03 00:07:24,535:INFO: 		 ADE on univ                      dataset:	 0.6581125855445862
2022-11-03 00:07:24,787:INFO: 		 ADE on zara1                     dataset:	 0.7449645400047302
2022-11-03 00:07:25,139:INFO: 		 ADE on zara2                     dataset:	 0.5440988540649414
2022-11-03 00:07:25,139:INFO: Average validation:	ADE  0.6146	FDE  1.0482
2022-11-03 00:07:25,140:INFO: - Computing ADE (training)
2022-11-03 00:07:25,579:INFO: 		 ADE on hotel                     dataset:	 0.6232269406318665
2022-11-03 00:07:26,307:INFO: 		 ADE on univ                      dataset:	 0.6315152049064636
2022-11-03 00:07:26,836:INFO: 		 ADE on zara1                     dataset:	 0.7813082337379456
2022-11-03 00:07:27,580:INFO: 		 ADE on zara2                     dataset:	 0.5995320081710815
2022-11-03 00:07:27,580:INFO: Average training:	ADE  0.6344	FDE  1.1066
2022-11-03 00:07:27,589:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_298.pth.tar
2022-11-03 00:07:27,589:INFO: 
===> EPOCH: 299 (P3)
2022-11-03 00:07:27,589:INFO: - Computing loss (training)
2022-11-03 00:07:28,661:INFO: Batch:  0/31	Total Loss 6.5159 (6.5159)
2022-11-03 00:07:29,135:INFO: Batch:  1/31	Total Loss 8.3117 (7.4212)
2022-11-03 00:07:29,609:INFO: Batch:  2/31	Total Loss 6.6958 (7.1729)
2022-11-03 00:07:30,077:INFO: Batch:  3/31	Total Loss 6.4853 (6.9871)
2022-11-03 00:07:30,548:INFO: Batch:  4/31	Total Loss 6.9090 (6.9722)
2022-11-03 00:07:31,023:INFO: Batch:  5/31	Total Loss 7.3992 (7.0431)
2022-11-03 00:07:31,496:INFO: Batch:  6/31	Total Loss 6.1969 (6.9146)
2022-11-03 00:07:31,967:INFO: Batch:  7/31	Total Loss 6.5399 (6.8646)
2022-11-03 00:07:32,436:INFO: Batch:  8/31	Total Loss 6.9738 (6.8772)
2022-11-03 00:07:32,907:INFO: Batch:  9/31	Total Loss 6.9197 (6.8814)
2022-11-03 00:07:33,374:INFO: Batch: 10/31	Total Loss 6.2933 (6.8256)
2022-11-03 00:07:33,846:INFO: Batch: 11/31	Total Loss 6.1535 (6.7622)
2022-11-03 00:07:34,322:INFO: Batch: 12/31	Total Loss 6.8375 (6.7678)
2022-11-03 00:07:34,797:INFO: Batch: 13/31	Total Loss 6.8521 (6.7744)
2022-11-03 00:07:35,271:INFO: Batch: 14/31	Total Loss 6.8139 (6.7768)
2022-11-03 00:07:35,746:INFO: Batch: 15/31	Total Loss 7.6162 (6.8261)
2022-11-03 00:07:36,222:INFO: Batch: 16/31	Total Loss 7.0093 (6.8370)
2022-11-03 00:07:36,696:INFO: Batch: 17/31	Total Loss 6.2372 (6.8003)
2022-11-03 00:07:37,170:INFO: Batch: 18/31	Total Loss 6.5773 (6.7887)
2022-11-03 00:07:37,642:INFO: Batch: 19/31	Total Loss 6.4025 (6.7691)
2022-11-03 00:07:38,116:INFO: Batch: 20/31	Total Loss 6.1042 (6.7413)
2022-11-03 00:07:38,588:INFO: Batch: 21/31	Total Loss 6.5640 (6.7331)
2022-11-03 00:07:39,060:INFO: Batch: 22/31	Total Loss 6.9059 (6.7411)
2022-11-03 00:07:39,533:INFO: Batch: 23/31	Total Loss 6.7617 (6.7420)
2022-11-03 00:07:40,009:INFO: Batch: 24/31	Total Loss 6.8027 (6.7445)
2022-11-03 00:07:40,482:INFO: Batch: 25/31	Total Loss 6.9723 (6.7534)
2022-11-03 00:07:40,955:INFO: Batch: 26/31	Total Loss 6.6137 (6.7480)
2022-11-03 00:07:41,429:INFO: Batch: 27/31	Total Loss 7.2436 (6.7643)
2022-11-03 00:07:41,902:INFO: Batch: 28/31	Total Loss 6.8319 (6.7669)
2022-11-03 00:07:42,375:INFO: Batch: 29/31	Total Loss 6.2948 (6.7506)
2022-11-03 00:07:42,762:INFO: Batch: 30/31	Total Loss 2.5461 (6.7140)
2022-11-03 00:07:42,913:INFO: - Computing ADE (validation o)
2022-11-03 00:07:43,512:INFO: 		 ADE on eth                       dataset:	 1.1957669258117676
2022-11-03 00:07:43,512:INFO: Average validation o:	ADE  1.1958	FDE  1.8233
2022-11-03 00:07:43,513:INFO: - Computing ADE (validation)
2022-11-03 00:07:43,769:INFO: 		 ADE on hotel                     dataset:	 0.5653030276298523
2022-11-03 00:07:44,062:INFO: 		 ADE on univ                      dataset:	 0.6627268195152283
2022-11-03 00:07:44,307:INFO: 		 ADE on zara1                     dataset:	 0.7191201448440552
2022-11-03 00:07:44,643:INFO: 		 ADE on zara2                     dataset:	 0.5597968697547913
2022-11-03 00:07:44,643:INFO: Average validation:	ADE  0.6229	FDE  1.0585
2022-11-03 00:07:44,643:INFO: - Computing ADE (training)
2022-11-03 00:07:45,128:INFO: 		 ADE on hotel                     dataset:	 0.6548362374305725
2022-11-03 00:07:45,897:INFO: 		 ADE on univ                      dataset:	 0.6362151503562927
2022-11-03 00:07:46,467:INFO: 		 ADE on zara1                     dataset:	 0.8071754574775696
2022-11-03 00:07:47,227:INFO: 		 ADE on zara2                     dataset:	 0.625221312046051
2022-11-03 00:07:47,228:INFO: Average training:	ADE  0.6454	FDE  1.1158
2022-11-03 00:07:47,237:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_299.pth.tar
2022-11-03 00:07:47,237:INFO: 
===> EPOCH: 300 (P3)
2022-11-03 00:07:47,237:INFO: - Computing loss (training)
2022-11-03 00:07:48,339:INFO: Batch:  0/31	Total Loss 6.4991 (6.4991)
2022-11-03 00:07:48,815:INFO: Batch:  1/31	Total Loss 7.0468 (6.7884)
2022-11-03 00:07:49,288:INFO: Batch:  2/31	Total Loss 6.8646 (6.8154)
2022-11-03 00:07:49,856:INFO: Batch:  3/31	Total Loss 6.3562 (6.7041)
2022-11-03 00:07:50,327:INFO: Batch:  4/31	Total Loss 6.2403 (6.6026)
2022-11-03 00:07:50,805:INFO: Batch:  5/31	Total Loss 6.1681 (6.5280)
2022-11-03 00:07:51,276:INFO: Batch:  6/31	Total Loss 6.0337 (6.4544)
2022-11-03 00:07:51,751:INFO: Batch:  7/31	Total Loss 6.3485 (6.4426)
2022-11-03 00:07:52,221:INFO: Batch:  8/31	Total Loss 6.8812 (6.4956)
2022-11-03 00:07:52,692:INFO: Batch:  9/31	Total Loss 6.6348 (6.5103)
2022-11-03 00:07:53,165:INFO: Batch: 10/31	Total Loss 6.7115 (6.5297)
2022-11-03 00:07:53,635:INFO: Batch: 11/31	Total Loss 6.5977 (6.5356)
2022-11-03 00:07:54,111:INFO: Batch: 12/31	Total Loss 7.1251 (6.5797)
2022-11-03 00:07:54,586:INFO: Batch: 13/31	Total Loss 5.9784 (6.5335)
2022-11-03 00:07:55,060:INFO: Batch: 14/31	Total Loss 6.4209 (6.5260)
2022-11-03 00:07:55,549:INFO: Batch: 15/31	Total Loss 7.1598 (6.5661)
2022-11-03 00:07:56,040:INFO: Batch: 16/31	Total Loss 6.8798 (6.5828)
2022-11-03 00:07:56,531:INFO: Batch: 17/31	Total Loss 7.1177 (6.6105)
2022-11-03 00:07:57,018:INFO: Batch: 18/31	Total Loss 7.3553 (6.6462)
2022-11-03 00:07:57,491:INFO: Batch: 19/31	Total Loss 6.4754 (6.6392)
2022-11-03 00:07:57,963:INFO: Batch: 20/31	Total Loss 7.7735 (6.6897)
2022-11-03 00:07:58,440:INFO: Batch: 21/31	Total Loss 6.4299 (6.6762)
2022-11-03 00:07:58,912:INFO: Batch: 22/31	Total Loss 5.7142 (6.6359)
2022-11-03 00:07:59,385:INFO: Batch: 23/31	Total Loss 7.0148 (6.6508)
2022-11-03 00:07:59,857:INFO: Batch: 24/31	Total Loss 6.0771 (6.6286)
2022-11-03 00:08:00,331:INFO: Batch: 25/31	Total Loss 6.5085 (6.6241)
2022-11-03 00:08:00,814:INFO: Batch: 26/31	Total Loss 7.4041 (6.6542)
2022-11-03 00:08:01,291:INFO: Batch: 27/31	Total Loss 6.5664 (6.6512)
2022-11-03 00:08:01,764:INFO: Batch: 28/31	Total Loss 6.1330 (6.6324)
2022-11-03 00:08:02,236:INFO: Batch: 29/31	Total Loss 7.2860 (6.6531)
2022-11-03 00:08:02,624:INFO: Batch: 30/31	Total Loss 2.5591 (6.6135)
2022-11-03 00:08:02,779:INFO: - Computing ADE (validation o)
2022-11-03 00:08:03,352:INFO: 		 ADE on eth                       dataset:	 1.1950539350509644
2022-11-03 00:08:03,352:INFO: Average validation o:	ADE  1.1951	FDE  1.8356
2022-11-03 00:08:03,353:INFO: - Computing ADE (validation)
2022-11-03 00:08:03,623:INFO: 		 ADE on hotel                     dataset:	 0.532052218914032
2022-11-03 00:08:03,922:INFO: 		 ADE on univ                      dataset:	 0.6630947589874268
2022-11-03 00:08:04,185:INFO: 		 ADE on zara1                     dataset:	 0.7502866387367249
2022-11-03 00:08:04,549:INFO: 		 ADE on zara2                     dataset:	 0.5572361946105957
2022-11-03 00:08:04,549:INFO: Average validation:	ADE  0.6222	FDE  1.0478
2022-11-03 00:08:04,550:INFO: - Computing ADE (training)
2022-11-03 00:08:05,042:INFO: 		 ADE on hotel                     dataset:	 0.6163105368614197
2022-11-03 00:08:05,726:INFO: 		 ADE on univ                      dataset:	 0.6316892504692078
2022-11-03 00:08:06,269:INFO: 		 ADE on zara1                     dataset:	 0.8186373114585876
2022-11-03 00:08:07,052:INFO: 		 ADE on zara2                     dataset:	 0.6274407505989075
2022-11-03 00:08:07,052:INFO: Average training:	ADE  0.6424	FDE  1.1058
2022-11-03 00:08:07,069:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_300.pth.tar
2022-11-03 00:08:07,069:INFO: 
===> EPOCH: 301 (P3)
2022-11-03 00:08:07,069:INFO: - Computing loss (training)
2022-11-03 00:08:08,176:INFO: Batch:  0/31	Total Loss 7.2797 (7.2797)
2022-11-03 00:08:08,653:INFO: Batch:  1/31	Total Loss 7.2261 (7.2555)
2022-11-03 00:08:09,132:INFO: Batch:  2/31	Total Loss 7.1258 (7.2117)
2022-11-03 00:08:09,607:INFO: Batch:  3/31	Total Loss 6.0432 (6.8980)
2022-11-03 00:08:10,085:INFO: Batch:  4/31	Total Loss 6.1089 (6.7344)
2022-11-03 00:08:10,562:INFO: Batch:  5/31	Total Loss 7.0790 (6.7951)
2022-11-03 00:08:11,036:INFO: Batch:  6/31	Total Loss 7.5950 (6.8994)
2022-11-03 00:08:11,514:INFO: Batch:  7/31	Total Loss 6.4350 (6.8344)
2022-11-03 00:08:11,991:INFO: Batch:  8/31	Total Loss 5.8461 (6.7199)
2022-11-03 00:08:12,467:INFO: Batch:  9/31	Total Loss 6.8242 (6.7315)
2022-11-03 00:08:12,945:INFO: Batch: 10/31	Total Loss 6.9605 (6.7510)
2022-11-03 00:08:13,429:INFO: Batch: 11/31	Total Loss 5.8640 (6.6683)
2022-11-03 00:08:13,911:INFO: Batch: 12/31	Total Loss 6.8361 (6.6805)
2022-11-03 00:08:14,393:INFO: Batch: 13/31	Total Loss 7.1206 (6.7108)
2022-11-03 00:08:14,867:INFO: Batch: 14/31	Total Loss 6.2290 (6.6781)
2022-11-03 00:08:15,344:INFO: Batch: 15/31	Total Loss 7.4069 (6.7213)
2022-11-03 00:08:15,821:INFO: Batch: 16/31	Total Loss 6.8580 (6.7291)
2022-11-03 00:08:16,297:INFO: Batch: 17/31	Total Loss 6.5038 (6.7169)
2022-11-03 00:08:16,774:INFO: Batch: 18/31	Total Loss 6.0940 (6.6813)
2022-11-03 00:08:17,249:INFO: Batch: 19/31	Total Loss 6.6620 (6.6803)
2022-11-03 00:08:17,725:INFO: Batch: 20/31	Total Loss 6.3665 (6.6650)
2022-11-03 00:08:18,201:INFO: Batch: 21/31	Total Loss 6.7117 (6.6675)
2022-11-03 00:08:18,676:INFO: Batch: 22/31	Total Loss 6.7234 (6.6699)
2022-11-03 00:08:19,151:INFO: Batch: 23/31	Total Loss 5.8626 (6.6366)
2022-11-03 00:08:19,626:INFO: Batch: 24/31	Total Loss 6.7724 (6.6422)
2022-11-03 00:08:20,103:INFO: Batch: 25/31	Total Loss 6.8044 (6.6492)
2022-11-03 00:08:20,577:INFO: Batch: 26/31	Total Loss 7.3107 (6.6727)
2022-11-03 00:08:21,053:INFO: Batch: 27/31	Total Loss 6.7240 (6.6746)
2022-11-03 00:08:21,530:INFO: Batch: 28/31	Total Loss 6.5047 (6.6690)
2022-11-03 00:08:22,006:INFO: Batch: 29/31	Total Loss 6.0524 (6.6493)
2022-11-03 00:08:22,397:INFO: Batch: 30/31	Total Loss 2.3292 (6.6060)
2022-11-03 00:08:22,548:INFO: - Computing ADE (validation o)
2022-11-03 00:08:23,125:INFO: 		 ADE on eth                       dataset:	 1.1926943063735962
2022-11-03 00:08:23,125:INFO: Average validation o:	ADE  1.1927	FDE  1.8232
2022-11-03 00:08:23,126:INFO: - Computing ADE (validation)
2022-11-03 00:08:23,404:INFO: 		 ADE on hotel                     dataset:	 0.5460196733474731
2022-11-03 00:08:23,700:INFO: 		 ADE on univ                      dataset:	 0.6686147451400757
2022-11-03 00:08:23,942:INFO: 		 ADE on zara1                     dataset:	 0.7679651379585266
2022-11-03 00:08:24,296:INFO: 		 ADE on zara2                     dataset:	 0.5499082803726196
2022-11-03 00:08:24,296:INFO: Average validation:	ADE  0.6241	FDE  1.0477
2022-11-03 00:08:24,297:INFO: - Computing ADE (training)
2022-11-03 00:08:24,775:INFO: 		 ADE on hotel                     dataset:	 0.6427749991416931
2022-11-03 00:08:25,444:INFO: 		 ADE on univ                      dataset:	 0.6335905194282532
2022-11-03 00:08:25,976:INFO: 		 ADE on zara1                     dataset:	 0.814669668674469
2022-11-03 00:08:26,707:INFO: 		 ADE on zara2                     dataset:	 0.6151497960090637
2022-11-03 00:08:26,707:INFO: Average training:	ADE  0.6416	FDE  1.0955
2022-11-03 00:08:26,715:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_301.pth.tar
2022-11-03 00:08:26,716:INFO: 
===> EPOCH: 302 (P3)
2022-11-03 00:08:26,716:INFO: - Computing loss (training)
2022-11-03 00:08:27,821:INFO: Batch:  0/31	Total Loss 6.0758 (6.0758)
2022-11-03 00:08:28,306:INFO: Batch:  1/31	Total Loss 6.6344 (6.3624)
2022-11-03 00:08:28,787:INFO: Batch:  2/31	Total Loss 7.3208 (6.6659)
2022-11-03 00:08:29,265:INFO: Batch:  3/31	Total Loss 7.0310 (6.7492)
2022-11-03 00:08:29,746:INFO: Batch:  4/31	Total Loss 7.8225 (6.9586)
2022-11-03 00:08:30,221:INFO: Batch:  5/31	Total Loss 6.4619 (6.8752)
2022-11-03 00:08:30,695:INFO: Batch:  6/31	Total Loss 6.2668 (6.7840)
2022-11-03 00:08:31,176:INFO: Batch:  7/31	Total Loss 7.5243 (6.8676)
2022-11-03 00:08:31,652:INFO: Batch:  8/31	Total Loss 6.9835 (6.8799)
2022-11-03 00:08:32,128:INFO: Batch:  9/31	Total Loss 7.2203 (6.9105)
2022-11-03 00:08:32,603:INFO: Batch: 10/31	Total Loss 6.0262 (6.8269)
2022-11-03 00:08:33,078:INFO: Batch: 11/31	Total Loss 7.3291 (6.8652)
2022-11-03 00:08:33,552:INFO: Batch: 12/31	Total Loss 6.0632 (6.7984)
2022-11-03 00:08:34,026:INFO: Batch: 13/31	Total Loss 6.2591 (6.7534)
2022-11-03 00:08:34,499:INFO: Batch: 14/31	Total Loss 7.4894 (6.7984)
2022-11-03 00:08:34,975:INFO: Batch: 15/31	Total Loss 5.9228 (6.7377)
2022-11-03 00:08:35,453:INFO: Batch: 16/31	Total Loss 6.0757 (6.6979)
2022-11-03 00:08:35,932:INFO: Batch: 17/31	Total Loss 6.4675 (6.6843)
2022-11-03 00:08:36,413:INFO: Batch: 18/31	Total Loss 6.0123 (6.6499)
2022-11-03 00:08:36,892:INFO: Batch: 19/31	Total Loss 6.5185 (6.6432)
2022-11-03 00:08:37,371:INFO: Batch: 20/31	Total Loss 6.1267 (6.6180)
2022-11-03 00:08:37,850:INFO: Batch: 21/31	Total Loss 5.8717 (6.5830)
2022-11-03 00:08:38,330:INFO: Batch: 22/31	Total Loss 6.4090 (6.5754)
2022-11-03 00:08:38,808:INFO: Batch: 23/31	Total Loss 5.9374 (6.5493)
2022-11-03 00:08:39,285:INFO: Batch: 24/31	Total Loss 6.5465 (6.5491)
2022-11-03 00:08:39,763:INFO: Batch: 25/31	Total Loss 6.2721 (6.5390)
2022-11-03 00:08:40,242:INFO: Batch: 26/31	Total Loss 6.3216 (6.5308)
2022-11-03 00:08:40,721:INFO: Batch: 27/31	Total Loss 6.7784 (6.5391)
2022-11-03 00:08:41,198:INFO: Batch: 28/31	Total Loss 6.6305 (6.5423)
2022-11-03 00:08:41,676:INFO: Batch: 29/31	Total Loss 6.0925 (6.5278)
2022-11-03 00:08:42,069:INFO: Batch: 30/31	Total Loss 2.6921 (6.4909)
2022-11-03 00:08:42,212:INFO: - Computing ADE (validation o)
2022-11-03 00:08:42,796:INFO: 		 ADE on eth                       dataset:	 1.186955451965332
2022-11-03 00:08:42,796:INFO: Average validation o:	ADE  1.1870	FDE  1.8590
2022-11-03 00:08:42,797:INFO: - Computing ADE (validation)
2022-11-03 00:08:43,100:INFO: 		 ADE on hotel                     dataset:	 0.5390166640281677
2022-11-03 00:08:43,397:INFO: 		 ADE on univ                      dataset:	 0.6681886911392212
2022-11-03 00:08:43,652:INFO: 		 ADE on zara1                     dataset:	 0.7910642623901367
2022-11-03 00:08:43,995:INFO: 		 ADE on zara2                     dataset:	 0.562678337097168
2022-11-03 00:08:43,995:INFO: Average validation:	ADE  0.6296	FDE  1.0726
2022-11-03 00:08:43,996:INFO: - Computing ADE (training)
2022-11-03 00:08:44,516:INFO: 		 ADE on hotel                     dataset:	 0.6294713020324707
2022-11-03 00:08:45,208:INFO: 		 ADE on univ                      dataset:	 0.6402260065078735
2022-11-03 00:08:45,826:INFO: 		 ADE on zara1                     dataset:	 0.8138125538825989
2022-11-03 00:08:46,558:INFO: 		 ADE on zara2                     dataset:	 0.6227933168411255
2022-11-03 00:08:46,559:INFO: Average training:	ADE  0.6475	FDE  1.1263
2022-11-03 00:08:46,568:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_302.pth.tar
2022-11-03 00:08:46,568:INFO: 
===> EPOCH: 303 (P3)
2022-11-03 00:08:46,568:INFO: - Computing loss (training)
2022-11-03 00:08:47,658:INFO: Batch:  0/31	Total Loss 5.2960 (5.2960)
2022-11-03 00:08:48,131:INFO: Batch:  1/31	Total Loss 6.9564 (6.1029)
2022-11-03 00:08:48,609:INFO: Batch:  2/31	Total Loss 6.4316 (6.2064)
2022-11-03 00:08:49,079:INFO: Batch:  3/31	Total Loss 6.2964 (6.2278)
2022-11-03 00:08:49,551:INFO: Batch:  4/31	Total Loss 6.3032 (6.2408)
2022-11-03 00:08:50,027:INFO: Batch:  5/31	Total Loss 6.4552 (6.2732)
2022-11-03 00:08:50,499:INFO: Batch:  6/31	Total Loss 6.9238 (6.3639)
2022-11-03 00:08:50,969:INFO: Batch:  7/31	Total Loss 6.2267 (6.3481)
2022-11-03 00:08:51,441:INFO: Batch:  8/31	Total Loss 6.3593 (6.3493)
2022-11-03 00:08:51,914:INFO: Batch:  9/31	Total Loss 6.9613 (6.4157)
2022-11-03 00:08:52,387:INFO: Batch: 10/31	Total Loss 6.6273 (6.4337)
2022-11-03 00:08:52,861:INFO: Batch: 11/31	Total Loss 6.0132 (6.3936)
2022-11-03 00:08:53,336:INFO: Batch: 12/31	Total Loss 6.0085 (6.3646)
2022-11-03 00:08:53,811:INFO: Batch: 13/31	Total Loss 7.2738 (6.4315)
2022-11-03 00:08:54,287:INFO: Batch: 14/31	Total Loss 7.0487 (6.4734)
2022-11-03 00:08:54,761:INFO: Batch: 15/31	Total Loss 6.4185 (6.4702)
2022-11-03 00:08:55,237:INFO: Batch: 16/31	Total Loss 6.3983 (6.4658)
2022-11-03 00:08:55,712:INFO: Batch: 17/31	Total Loss 6.9027 (6.4905)
2022-11-03 00:08:56,188:INFO: Batch: 18/31	Total Loss 5.7779 (6.4517)
2022-11-03 00:08:56,665:INFO: Batch: 19/31	Total Loss 6.8804 (6.4718)
2022-11-03 00:08:57,141:INFO: Batch: 20/31	Total Loss 5.8866 (6.4427)
2022-11-03 00:08:57,614:INFO: Batch: 21/31	Total Loss 6.5170 (6.4463)
2022-11-03 00:08:58,087:INFO: Batch: 22/31	Total Loss 6.4774 (6.4477)
2022-11-03 00:08:58,565:INFO: Batch: 23/31	Total Loss 6.2076 (6.4380)
2022-11-03 00:08:59,038:INFO: Batch: 24/31	Total Loss 7.2919 (6.4706)
2022-11-03 00:08:59,513:INFO: Batch: 25/31	Total Loss 7.3537 (6.5003)
2022-11-03 00:08:59,986:INFO: Batch: 26/31	Total Loss 6.2537 (6.4907)
2022-11-03 00:09:00,463:INFO: Batch: 27/31	Total Loss 6.9215 (6.5069)
2022-11-03 00:09:00,937:INFO: Batch: 28/31	Total Loss 6.6342 (6.5113)
2022-11-03 00:09:01,414:INFO: Batch: 29/31	Total Loss 5.8835 (6.4892)
2022-11-03 00:09:01,802:INFO: Batch: 30/31	Total Loss 2.3140 (6.4571)
2022-11-03 00:09:01,962:INFO: - Computing ADE (validation o)
2022-11-03 00:09:02,562:INFO: 		 ADE on eth                       dataset:	 1.2170672416687012
2022-11-03 00:09:02,562:INFO: Average validation o:	ADE  1.2171	FDE  1.9221
2022-11-03 00:09:02,563:INFO: - Computing ADE (validation)
2022-11-03 00:09:02,828:INFO: 		 ADE on hotel                     dataset:	 0.595315158367157
2022-11-03 00:09:03,120:INFO: 		 ADE on univ                      dataset:	 0.6836533546447754
2022-11-03 00:09:03,363:INFO: 		 ADE on zara1                     dataset:	 0.8313770294189453
2022-11-03 00:09:03,710:INFO: 		 ADE on zara2                     dataset:	 0.6111800670623779
2022-11-03 00:09:03,710:INFO: Average validation:	ADE  0.6608	FDE  1.1586
2022-11-03 00:09:03,711:INFO: - Computing ADE (training)
2022-11-03 00:09:04,194:INFO: 		 ADE on hotel                     dataset:	 0.6869085431098938
2022-11-03 00:09:04,907:INFO: 		 ADE on univ                      dataset:	 0.6707711815834045
2022-11-03 00:09:05,446:INFO: 		 ADE on zara1                     dataset:	 0.8518992066383362
2022-11-03 00:09:06,241:INFO: 		 ADE on zara2                     dataset:	 0.6690596342086792
2022-11-03 00:09:06,241:INFO: Average training:	ADE  0.6824	FDE  1.2181
2022-11-03 00:09:06,250:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_303.pth.tar
2022-11-03 00:09:06,250:INFO: 
===> EPOCH: 304 (P3)
2022-11-03 00:09:06,250:INFO: - Computing loss (training)
2022-11-03 00:09:07,358:INFO: Batch:  0/31	Total Loss 5.9109 (5.9109)
2022-11-03 00:09:07,833:INFO: Batch:  1/31	Total Loss 6.7349 (6.3282)
2022-11-03 00:09:08,318:INFO: Batch:  2/31	Total Loss 7.1328 (6.5803)
2022-11-03 00:09:08,794:INFO: Batch:  3/31	Total Loss 7.5850 (6.8367)
2022-11-03 00:09:09,276:INFO: Batch:  4/31	Total Loss 6.6540 (6.8009)
2022-11-03 00:09:09,759:INFO: Batch:  5/31	Total Loss 8.3472 (7.0325)
2022-11-03 00:09:10,236:INFO: Batch:  6/31	Total Loss 6.2677 (6.9245)
2022-11-03 00:09:10,712:INFO: Batch:  7/31	Total Loss 6.5640 (6.8813)
2022-11-03 00:09:11,192:INFO: Batch:  8/31	Total Loss 6.6542 (6.8542)
2022-11-03 00:09:11,667:INFO: Batch:  9/31	Total Loss 6.1778 (6.7827)
2022-11-03 00:09:12,142:INFO: Batch: 10/31	Total Loss 6.4044 (6.7472)
2022-11-03 00:09:12,618:INFO: Batch: 11/31	Total Loss 6.4312 (6.7222)
2022-11-03 00:09:13,098:INFO: Batch: 12/31	Total Loss 6.7610 (6.7249)
2022-11-03 00:09:13,580:INFO: Batch: 13/31	Total Loss 6.2787 (6.6919)
2022-11-03 00:09:14,062:INFO: Batch: 14/31	Total Loss 6.5813 (6.6845)
2022-11-03 00:09:14,544:INFO: Batch: 15/31	Total Loss 5.9350 (6.6377)
2022-11-03 00:09:15,025:INFO: Batch: 16/31	Total Loss 7.4323 (6.6837)
2022-11-03 00:09:15,508:INFO: Batch: 17/31	Total Loss 6.8777 (6.6938)
2022-11-03 00:09:15,989:INFO: Batch: 18/31	Total Loss 6.7408 (6.6959)
2022-11-03 00:09:16,470:INFO: Batch: 19/31	Total Loss 6.0942 (6.6630)
2022-11-03 00:09:16,949:INFO: Batch: 20/31	Total Loss 7.2172 (6.6874)
2022-11-03 00:09:17,431:INFO: Batch: 21/31	Total Loss 6.3159 (6.6688)
2022-11-03 00:09:17,909:INFO: Batch: 22/31	Total Loss 6.4954 (6.6615)
2022-11-03 00:09:18,394:INFO: Batch: 23/31	Total Loss 6.6591 (6.6614)
2022-11-03 00:09:18,873:INFO: Batch: 24/31	Total Loss 6.5976 (6.6590)
2022-11-03 00:09:19,369:INFO: Batch: 25/31	Total Loss 7.2599 (6.6824)
2022-11-03 00:09:19,850:INFO: Batch: 26/31	Total Loss 6.5008 (6.6762)
2022-11-03 00:09:20,332:INFO: Batch: 27/31	Total Loss 6.2314 (6.6588)
2022-11-03 00:09:20,805:INFO: Batch: 28/31	Total Loss 6.3910 (6.6505)
2022-11-03 00:09:21,281:INFO: Batch: 29/31	Total Loss 6.1903 (6.6346)
2022-11-03 00:09:21,672:INFO: Batch: 30/31	Total Loss 2.1921 (6.5938)
2022-11-03 00:09:21,814:INFO: - Computing ADE (validation o)
2022-11-03 00:09:22,383:INFO: 		 ADE on eth                       dataset:	 1.2374621629714966
2022-11-03 00:09:22,383:INFO: Average validation o:	ADE  1.2375	FDE  1.8973
2022-11-03 00:09:22,384:INFO: - Computing ADE (validation)
2022-11-03 00:09:22,641:INFO: 		 ADE on hotel                     dataset:	 0.587385892868042
2022-11-03 00:09:22,949:INFO: 		 ADE on univ                      dataset:	 0.6934618353843689
2022-11-03 00:09:23,202:INFO: 		 ADE on zara1                     dataset:	 0.7456751465797424
2022-11-03 00:09:23,557:INFO: 		 ADE on zara2                     dataset:	 0.5920639038085938
2022-11-03 00:09:23,558:INFO: Average validation:	ADE  0.6535	FDE  1.1360
2022-11-03 00:09:23,558:INFO: - Computing ADE (training)
2022-11-03 00:09:24,016:INFO: 		 ADE on hotel                     dataset:	 0.6819179058074951
2022-11-03 00:09:24,708:INFO: 		 ADE on univ                      dataset:	 0.6537411212921143
2022-11-03 00:09:25,253:INFO: 		 ADE on zara1                     dataset:	 0.8501495718955994
2022-11-03 00:09:26,012:INFO: 		 ADE on zara2                     dataset:	 0.6694820523262024
2022-11-03 00:09:26,012:INFO: Average training:	ADE  0.6702	FDE  1.1763
2022-11-03 00:09:26,020:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_304.pth.tar
2022-11-03 00:09:26,021:INFO: 
===> EPOCH: 305 (P3)
2022-11-03 00:09:26,021:INFO: - Computing loss (training)
2022-11-03 00:09:27,135:INFO: Batch:  0/31	Total Loss 6.8166 (6.8166)
2022-11-03 00:09:27,609:INFO: Batch:  1/31	Total Loss 7.3524 (7.0821)
2022-11-03 00:09:28,091:INFO: Batch:  2/31	Total Loss 6.5599 (6.8909)
2022-11-03 00:09:28,567:INFO: Batch:  3/31	Total Loss 6.6756 (6.8359)
2022-11-03 00:09:29,039:INFO: Batch:  4/31	Total Loss 6.7371 (6.8161)
2022-11-03 00:09:29,518:INFO: Batch:  5/31	Total Loss 7.2462 (6.8839)
2022-11-03 00:09:29,999:INFO: Batch:  6/31	Total Loss 6.5742 (6.8408)
2022-11-03 00:09:30,472:INFO: Batch:  7/31	Total Loss 6.1585 (6.7595)
2022-11-03 00:09:30,945:INFO: Batch:  8/31	Total Loss 6.5996 (6.7418)
2022-11-03 00:09:31,419:INFO: Batch:  9/31	Total Loss 6.2843 (6.6995)
2022-11-03 00:09:31,889:INFO: Batch: 10/31	Total Loss 7.5755 (6.7779)
2022-11-03 00:09:32,362:INFO: Batch: 11/31	Total Loss 6.8968 (6.7884)
2022-11-03 00:09:32,841:INFO: Batch: 12/31	Total Loss 6.2486 (6.7473)
2022-11-03 00:09:33,317:INFO: Batch: 13/31	Total Loss 7.0632 (6.7709)
2022-11-03 00:09:33,795:INFO: Batch: 14/31	Total Loss 6.2626 (6.7342)
2022-11-03 00:09:34,273:INFO: Batch: 15/31	Total Loss 6.7978 (6.7382)
2022-11-03 00:09:34,759:INFO: Batch: 16/31	Total Loss 7.0877 (6.7609)
2022-11-03 00:09:35,260:INFO: Batch: 17/31	Total Loss 6.2163 (6.7315)
2022-11-03 00:09:35,862:INFO: Batch: 18/31	Total Loss 6.5501 (6.7219)
2022-11-03 00:09:36,362:INFO: Batch: 19/31	Total Loss 5.7420 (6.6694)
2022-11-03 00:09:36,842:INFO: Batch: 20/31	Total Loss 6.5102 (6.6620)
2022-11-03 00:09:37,323:INFO: Batch: 21/31	Total Loss 6.2659 (6.6441)
2022-11-03 00:09:37,819:INFO: Batch: 22/31	Total Loss 6.7188 (6.6472)
2022-11-03 00:09:38,302:INFO: Batch: 23/31	Total Loss 6.9429 (6.6589)
2022-11-03 00:09:38,792:INFO: Batch: 24/31	Total Loss 6.9913 (6.6735)
2022-11-03 00:09:39,293:INFO: Batch: 25/31	Total Loss 6.8068 (6.6786)
2022-11-03 00:09:39,781:INFO: Batch: 26/31	Total Loss 5.9874 (6.6557)
2022-11-03 00:09:40,269:INFO: Batch: 27/31	Total Loss 6.7923 (6.6607)
2022-11-03 00:09:40,757:INFO: Batch: 28/31	Total Loss 6.4736 (6.6546)
2022-11-03 00:09:41,256:INFO: Batch: 29/31	Total Loss 6.1253 (6.6369)
2022-11-03 00:09:41,728:INFO: Batch: 30/31	Total Loss 2.3823 (6.5865)
2022-11-03 00:09:42,046:INFO: - Computing ADE (validation o)
2022-11-03 00:09:42,772:INFO: 		 ADE on eth                       dataset:	 1.1825430393218994
2022-11-03 00:09:42,772:INFO: Average validation o:	ADE  1.1825	FDE  1.8807
2022-11-03 00:09:42,772:INFO: - Computing ADE (validation)
2022-11-03 00:09:43,130:INFO: 		 ADE on hotel                     dataset:	 0.5700515508651733
2022-11-03 00:09:43,451:INFO: 		 ADE on univ                      dataset:	 0.6825336217880249
2022-11-03 00:09:43,736:INFO: 		 ADE on zara1                     dataset:	 0.794408917427063
2022-11-03 00:09:44,116:INFO: 		 ADE on zara2                     dataset:	 0.5801410675048828
2022-11-03 00:09:44,116:INFO: Average validation:	ADE  0.6453	FDE  1.1358
2022-11-03 00:09:44,117:INFO: - Computing ADE (training)
2022-11-03 00:09:44,610:INFO: 		 ADE on hotel                     dataset:	 0.6683233380317688
2022-11-03 00:09:45,352:INFO: 		 ADE on univ                      dataset:	 0.6579710841178894
2022-11-03 00:09:45,909:INFO: 		 ADE on zara1                     dataset:	 0.8056373000144958
2022-11-03 00:09:46,676:INFO: 		 ADE on zara2                     dataset:	 0.6310160756111145
2022-11-03 00:09:46,676:INFO: Average training:	ADE  0.6622	FDE  1.1863
2022-11-03 00:09:46,685:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_305.pth.tar
2022-11-03 00:09:46,685:INFO: 
===> EPOCH: 306 (P3)
2022-11-03 00:09:46,685:INFO: - Computing loss (training)
2022-11-03 00:09:47,879:INFO: Batch:  0/31	Total Loss 6.2964 (6.2964)
2022-11-03 00:09:48,421:INFO: Batch:  1/31	Total Loss 6.8090 (6.5511)
2022-11-03 00:09:48,932:INFO: Batch:  2/31	Total Loss 6.8657 (6.6518)
2022-11-03 00:09:49,458:INFO: Batch:  3/31	Total Loss 6.7215 (6.6677)
2022-11-03 00:09:49,974:INFO: Batch:  4/31	Total Loss 5.8298 (6.4999)
2022-11-03 00:09:50,501:INFO: Batch:  5/31	Total Loss 6.7068 (6.5327)
2022-11-03 00:09:51,018:INFO: Batch:  6/31	Total Loss 5.9337 (6.4558)
2022-11-03 00:09:51,562:INFO: Batch:  7/31	Total Loss 5.9320 (6.3911)
2022-11-03 00:09:52,096:INFO: Batch:  8/31	Total Loss 6.7310 (6.4280)
2022-11-03 00:09:52,655:INFO: Batch:  9/31	Total Loss 5.8048 (6.3636)
2022-11-03 00:09:53,148:INFO: Batch: 10/31	Total Loss 6.2760 (6.3554)
2022-11-03 00:09:53,661:INFO: Batch: 11/31	Total Loss 6.0430 (6.3288)
2022-11-03 00:09:54,205:INFO: Batch: 12/31	Total Loss 6.9971 (6.3789)
2022-11-03 00:09:54,712:INFO: Batch: 13/31	Total Loss 6.6216 (6.3976)
2022-11-03 00:09:55,252:INFO: Batch: 14/31	Total Loss 5.8201 (6.3605)
2022-11-03 00:09:55,781:INFO: Batch: 15/31	Total Loss 6.3420 (6.3593)
2022-11-03 00:09:56,278:INFO: Batch: 16/31	Total Loss 6.2524 (6.3523)
2022-11-03 00:09:56,773:INFO: Batch: 17/31	Total Loss 6.4397 (6.3574)
2022-11-03 00:09:57,342:INFO: Batch: 18/31	Total Loss 7.3028 (6.4106)
2022-11-03 00:09:58,040:INFO: Batch: 19/31	Total Loss 5.7768 (6.3787)
2022-11-03 00:09:58,694:INFO: Batch: 20/31	Total Loss 6.1240 (6.3669)
2022-11-03 00:09:59,190:INFO: Batch: 21/31	Total Loss 6.2321 (6.3613)
2022-11-03 00:09:59,671:INFO: Batch: 22/31	Total Loss 6.3421 (6.3605)
2022-11-03 00:10:00,153:INFO: Batch: 23/31	Total Loss 7.1852 (6.3888)
2022-11-03 00:10:00,635:INFO: Batch: 24/31	Total Loss 6.1825 (6.3803)
2022-11-03 00:10:01,111:INFO: Batch: 25/31	Total Loss 6.9728 (6.4018)
2022-11-03 00:10:01,602:INFO: Batch: 26/31	Total Loss 6.7209 (6.4151)
2022-11-03 00:10:02,092:INFO: Batch: 27/31	Total Loss 6.7312 (6.4266)
2022-11-03 00:10:02,580:INFO: Batch: 28/31	Total Loss 6.2275 (6.4195)
2022-11-03 00:10:03,075:INFO: Batch: 29/31	Total Loss 6.2184 (6.4128)
2022-11-03 00:10:03,482:INFO: Batch: 30/31	Total Loss 2.3622 (6.3651)
2022-11-03 00:10:03,636:INFO: - Computing ADE (validation o)
2022-11-03 00:10:04,247:INFO: 		 ADE on eth                       dataset:	 1.206686019897461
2022-11-03 00:10:04,248:INFO: Average validation o:	ADE  1.2067	FDE  1.8665
2022-11-03 00:10:04,248:INFO: - Computing ADE (validation)
2022-11-03 00:10:04,527:INFO: 		 ADE on hotel                     dataset:	 0.5374957919120789
2022-11-03 00:10:04,831:INFO: 		 ADE on univ                      dataset:	 0.6598095297813416
2022-11-03 00:10:05,116:INFO: 		 ADE on zara1                     dataset:	 0.7516063451766968
2022-11-03 00:10:05,464:INFO: 		 ADE on zara2                     dataset:	 0.5637146830558777
2022-11-03 00:10:05,464:INFO: Average validation:	ADE  0.6232	FDE  1.0564
2022-11-03 00:10:05,465:INFO: - Computing ADE (training)
2022-11-03 00:10:05,887:INFO: 		 ADE on hotel                     dataset:	 0.6245975494384766
2022-11-03 00:10:06,611:INFO: 		 ADE on univ                      dataset:	 0.6319422721862793
2022-11-03 00:10:07,146:INFO: 		 ADE on zara1                     dataset:	 0.8226540684700012
2022-11-03 00:10:07,912:INFO: 		 ADE on zara2                     dataset:	 0.6312382221221924
2022-11-03 00:10:07,912:INFO: Average training:	ADE  0.6438	FDE  1.1116
2022-11-03 00:10:07,921:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_306.pth.tar
2022-11-03 00:10:07,921:INFO: 
===> EPOCH: 307 (P3)
2022-11-03 00:10:07,921:INFO: - Computing loss (training)
2022-11-03 00:10:09,013:INFO: Batch:  0/31	Total Loss 6.0194 (6.0194)
2022-11-03 00:10:09,490:INFO: Batch:  1/31	Total Loss 6.1075 (6.0629)
2022-11-03 00:10:09,975:INFO: Batch:  2/31	Total Loss 5.7402 (5.9608)
2022-11-03 00:10:10,458:INFO: Batch:  3/31	Total Loss 6.5881 (6.1266)
2022-11-03 00:10:10,930:INFO: Batch:  4/31	Total Loss 6.2687 (6.1555)
2022-11-03 00:10:11,402:INFO: Batch:  5/31	Total Loss 5.9279 (6.1200)
2022-11-03 00:10:11,872:INFO: Batch:  6/31	Total Loss 5.7586 (6.0687)
2022-11-03 00:10:12,339:INFO: Batch:  7/31	Total Loss 5.9415 (6.0548)
2022-11-03 00:10:12,807:INFO: Batch:  8/31	Total Loss 6.7738 (6.1330)
2022-11-03 00:10:13,277:INFO: Batch:  9/31	Total Loss 7.5132 (6.2646)
2022-11-03 00:10:13,749:INFO: Batch: 10/31	Total Loss 5.8015 (6.2192)
2022-11-03 00:10:14,221:INFO: Batch: 11/31	Total Loss 6.3077 (6.2268)
2022-11-03 00:10:14,695:INFO: Batch: 12/31	Total Loss 6.0508 (6.2137)
2022-11-03 00:10:15,170:INFO: Batch: 13/31	Total Loss 5.8732 (6.1918)
2022-11-03 00:10:15,653:INFO: Batch: 14/31	Total Loss 6.6663 (6.2233)
2022-11-03 00:10:16,135:INFO: Batch: 15/31	Total Loss 5.8500 (6.1992)
2022-11-03 00:10:16,608:INFO: Batch: 16/31	Total Loss 6.4094 (6.2134)
2022-11-03 00:10:17,086:INFO: Batch: 17/31	Total Loss 7.2763 (6.2736)
2022-11-03 00:10:17,564:INFO: Batch: 18/31	Total Loss 6.7065 (6.2977)
2022-11-03 00:10:18,039:INFO: Batch: 19/31	Total Loss 6.9208 (6.3332)
2022-11-03 00:10:18,511:INFO: Batch: 20/31	Total Loss 6.6779 (6.3499)
2022-11-03 00:10:18,984:INFO: Batch: 21/31	Total Loss 5.7912 (6.3242)
2022-11-03 00:10:19,457:INFO: Batch: 22/31	Total Loss 5.6119 (6.2923)
2022-11-03 00:10:19,932:INFO: Batch: 23/31	Total Loss 6.1031 (6.2847)
2022-11-03 00:10:20,403:INFO: Batch: 24/31	Total Loss 6.5968 (6.2962)
2022-11-03 00:10:20,873:INFO: Batch: 25/31	Total Loss 6.2268 (6.2934)
2022-11-03 00:10:21,346:INFO: Batch: 26/31	Total Loss 5.8943 (6.2785)
2022-11-03 00:10:21,819:INFO: Batch: 27/31	Total Loss 6.3707 (6.2819)
2022-11-03 00:10:22,299:INFO: Batch: 28/31	Total Loss 5.7109 (6.2603)
2022-11-03 00:10:22,780:INFO: Batch: 29/31	Total Loss 6.5687 (6.2716)
2022-11-03 00:10:23,175:INFO: Batch: 30/31	Total Loss 2.2675 (6.2298)
2022-11-03 00:10:23,332:INFO: - Computing ADE (validation o)
2022-11-03 00:10:23,925:INFO: 		 ADE on eth                       dataset:	 1.2199574708938599
2022-11-03 00:10:23,925:INFO: Average validation o:	ADE  1.2200	FDE  1.8943
2022-11-03 00:10:23,926:INFO: - Computing ADE (validation)
2022-11-03 00:10:24,193:INFO: 		 ADE on hotel                     dataset:	 0.5657658576965332
2022-11-03 00:10:24,486:INFO: 		 ADE on univ                      dataset:	 0.6667128801345825
2022-11-03 00:10:24,764:INFO: 		 ADE on zara1                     dataset:	 0.7679463624954224
2022-11-03 00:10:25,104:INFO: 		 ADE on zara2                     dataset:	 0.5844393968582153
2022-11-03 00:10:25,104:INFO: Average validation:	ADE  0.6369	FDE  1.0928
2022-11-03 00:10:25,105:INFO: - Computing ADE (training)
2022-11-03 00:10:25,538:INFO: 		 ADE on hotel                     dataset:	 0.6540680527687073
2022-11-03 00:10:26,248:INFO: 		 ADE on univ                      dataset:	 0.6465417742729187
2022-11-03 00:10:26,801:INFO: 		 ADE on zara1                     dataset:	 0.8420019745826721
2022-11-03 00:10:27,615:INFO: 		 ADE on zara2                     dataset:	 0.6509175896644592
2022-11-03 00:10:27,615:INFO: Average training:	ADE  0.6601	FDE  1.1537
2022-11-03 00:10:27,624:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_307.pth.tar
2022-11-03 00:10:27,624:INFO: 
===> EPOCH: 308 (P3)
2022-11-03 00:10:27,625:INFO: - Computing loss (training)
2022-11-03 00:10:28,720:INFO: Batch:  0/31	Total Loss 6.3639 (6.3639)
2022-11-03 00:10:29,197:INFO: Batch:  1/31	Total Loss 6.5347 (6.4550)
2022-11-03 00:10:29,679:INFO: Batch:  2/31	Total Loss 6.2611 (6.3906)
2022-11-03 00:10:30,163:INFO: Batch:  3/31	Total Loss 6.1447 (6.3293)
2022-11-03 00:10:30,729:INFO: Batch:  4/31	Total Loss 6.9638 (6.4698)
2022-11-03 00:10:31,219:INFO: Batch:  5/31	Total Loss 5.8965 (6.3724)
2022-11-03 00:10:31,704:INFO: Batch:  6/31	Total Loss 6.7730 (6.4258)
2022-11-03 00:10:32,197:INFO: Batch:  7/31	Total Loss 5.9897 (6.3696)
2022-11-03 00:10:32,686:INFO: Batch:  8/31	Total Loss 6.1285 (6.3436)
2022-11-03 00:10:33,169:INFO: Batch:  9/31	Total Loss 5.7445 (6.2888)
2022-11-03 00:10:33,652:INFO: Batch: 10/31	Total Loss 7.8752 (6.4352)
2022-11-03 00:10:34,144:INFO: Batch: 11/31	Total Loss 6.7593 (6.4617)
2022-11-03 00:10:34,636:INFO: Batch: 12/31	Total Loss 5.6068 (6.4001)
2022-11-03 00:10:35,174:INFO: Batch: 13/31	Total Loss 6.3211 (6.3940)
2022-11-03 00:10:35,710:INFO: Batch: 14/31	Total Loss 5.5636 (6.3330)
2022-11-03 00:10:36,248:INFO: Batch: 15/31	Total Loss 6.8016 (6.3619)
2022-11-03 00:10:36,786:INFO: Batch: 16/31	Total Loss 6.9307 (6.3926)
2022-11-03 00:10:37,278:INFO: Batch: 17/31	Total Loss 6.7808 (6.4120)
2022-11-03 00:10:37,757:INFO: Batch: 18/31	Total Loss 5.5950 (6.3639)
2022-11-03 00:10:38,248:INFO: Batch: 19/31	Total Loss 5.8431 (6.3359)
2022-11-03 00:10:38,763:INFO: Batch: 20/31	Total Loss 5.5741 (6.2953)
2022-11-03 00:10:39,259:INFO: Batch: 21/31	Total Loss 6.3710 (6.2987)
2022-11-03 00:10:39,783:INFO: Batch: 22/31	Total Loss 5.5893 (6.2669)
2022-11-03 00:10:40,282:INFO: Batch: 23/31	Total Loss 6.5487 (6.2791)
2022-11-03 00:10:40,773:INFO: Batch: 24/31	Total Loss 6.3350 (6.2811)
2022-11-03 00:10:41,323:INFO: Batch: 25/31	Total Loss 6.5365 (6.2902)
2022-11-03 00:10:41,863:INFO: Batch: 26/31	Total Loss 6.5040 (6.2984)
2022-11-03 00:10:42,351:INFO: Batch: 27/31	Total Loss 6.9512 (6.3188)
2022-11-03 00:10:42,873:INFO: Batch: 28/31	Total Loss 5.9926 (6.3074)
2022-11-03 00:10:43,414:INFO: Batch: 29/31	Total Loss 6.7871 (6.3232)
2022-11-03 00:10:43,815:INFO: Batch: 30/31	Total Loss 3.0245 (6.2980)
2022-11-03 00:10:43,967:INFO: - Computing ADE (validation o)
2022-11-03 00:10:44,576:INFO: 		 ADE on eth                       dataset:	 1.255651831626892
2022-11-03 00:10:44,576:INFO: Average validation o:	ADE  1.2557	FDE  1.9498
2022-11-03 00:10:44,577:INFO: - Computing ADE (validation)
2022-11-03 00:10:44,895:INFO: 		 ADE on hotel                     dataset:	 0.6110577583312988
2022-11-03 00:10:45,199:INFO: 		 ADE on univ                      dataset:	 0.6881245970726013
2022-11-03 00:10:45,450:INFO: 		 ADE on zara1                     dataset:	 0.7278429865837097
2022-11-03 00:10:45,822:INFO: 		 ADE on zara2                     dataset:	 0.6180868744850159
2022-11-03 00:10:45,823:INFO: Average validation:	ADE  0.6605	FDE  1.1734
2022-11-03 00:10:45,823:INFO: - Computing ADE (training)
2022-11-03 00:10:46,291:INFO: 		 ADE on hotel                     dataset:	 0.6888751983642578
2022-11-03 00:10:47,000:INFO: 		 ADE on univ                      dataset:	 0.6632425785064697
2022-11-03 00:10:47,579:INFO: 		 ADE on zara1                     dataset:	 0.8644095063209534
2022-11-03 00:10:48,619:INFO: 		 ADE on zara2                     dataset:	 0.6948615312576294
2022-11-03 00:10:48,619:INFO: Average training:	ADE  0.6831	FDE  1.2291
2022-11-03 00:10:48,629:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_308.pth.tar
2022-11-03 00:10:48,629:INFO: 
===> EPOCH: 309 (P3)
2022-11-03 00:10:48,629:INFO: - Computing loss (training)
2022-11-03 00:10:49,767:INFO: Batch:  0/31	Total Loss 6.3661 (6.3661)
2022-11-03 00:10:50,274:INFO: Batch:  1/31	Total Loss 7.0863 (6.7256)
2022-11-03 00:10:50,796:INFO: Batch:  2/31	Total Loss 7.3124 (6.9264)
2022-11-03 00:10:51,354:INFO: Batch:  3/31	Total Loss 7.3359 (7.0273)
2022-11-03 00:10:51,883:INFO: Batch:  4/31	Total Loss 5.8140 (6.7930)
2022-11-03 00:10:52,391:INFO: Batch:  5/31	Total Loss 6.3742 (6.7260)
2022-11-03 00:10:52,876:INFO: Batch:  6/31	Total Loss 6.7053 (6.7229)
2022-11-03 00:10:53,362:INFO: Batch:  7/31	Total Loss 6.4288 (6.6885)
2022-11-03 00:10:53,853:INFO: Batch:  8/31	Total Loss 6.6400 (6.6826)
2022-11-03 00:10:54,343:INFO: Batch:  9/31	Total Loss 5.6598 (6.5762)
2022-11-03 00:10:54,850:INFO: Batch: 10/31	Total Loss 5.6840 (6.4969)
2022-11-03 00:10:55,349:INFO: Batch: 11/31	Total Loss 6.5499 (6.5012)
2022-11-03 00:10:55,859:INFO: Batch: 12/31	Total Loss 6.4643 (6.4984)
2022-11-03 00:10:56,356:INFO: Batch: 13/31	Total Loss 6.1715 (6.4734)
2022-11-03 00:10:56,851:INFO: Batch: 14/31	Total Loss 6.1248 (6.4507)
2022-11-03 00:10:57,339:INFO: Batch: 15/31	Total Loss 6.1252 (6.4302)
2022-11-03 00:10:57,825:INFO: Batch: 16/31	Total Loss 6.1873 (6.4161)
2022-11-03 00:10:58,309:INFO: Batch: 17/31	Total Loss 6.2979 (6.4097)
2022-11-03 00:10:58,806:INFO: Batch: 18/31	Total Loss 6.2635 (6.4025)
2022-11-03 00:10:59,289:INFO: Batch: 19/31	Total Loss 5.8054 (6.3695)
2022-11-03 00:10:59,776:INFO: Batch: 20/31	Total Loss 6.3303 (6.3676)
2022-11-03 00:11:00,260:INFO: Batch: 21/31	Total Loss 6.0436 (6.3529)
2022-11-03 00:11:00,743:INFO: Batch: 22/31	Total Loss 6.8298 (6.3758)
2022-11-03 00:11:01,234:INFO: Batch: 23/31	Total Loss 6.5627 (6.3826)
2022-11-03 00:11:01,705:INFO: Batch: 24/31	Total Loss 6.3776 (6.3824)
2022-11-03 00:11:02,176:INFO: Batch: 25/31	Total Loss 5.9251 (6.3637)
2022-11-03 00:11:02,647:INFO: Batch: 26/31	Total Loss 5.3252 (6.3226)
2022-11-03 00:11:03,116:INFO: Batch: 27/31	Total Loss 6.0495 (6.3134)
2022-11-03 00:11:03,588:INFO: Batch: 28/31	Total Loss 5.4456 (6.2830)
2022-11-03 00:11:04,057:INFO: Batch: 29/31	Total Loss 6.2430 (6.2817)
2022-11-03 00:11:04,444:INFO: Batch: 30/31	Total Loss 2.1052 (6.2337)
2022-11-03 00:11:04,597:INFO: - Computing ADE (validation o)
2022-11-03 00:11:05,190:INFO: 		 ADE on eth                       dataset:	 1.1677335500717163
2022-11-03 00:11:05,191:INFO: Average validation o:	ADE  1.1677	FDE  1.7871
2022-11-03 00:11:05,191:INFO: - Computing ADE (validation)
2022-11-03 00:11:05,470:INFO: 		 ADE on hotel                     dataset:	 0.5417780876159668
2022-11-03 00:11:05,775:INFO: 		 ADE on univ                      dataset:	 0.6580682396888733
2022-11-03 00:11:06,023:INFO: 		 ADE on zara1                     dataset:	 0.7288969159126282
2022-11-03 00:11:06,370:INFO: 		 ADE on zara2                     dataset:	 0.5310213565826416
2022-11-03 00:11:06,370:INFO: Average validation:	ADE  0.6092	FDE  1.0276
2022-11-03 00:11:06,371:INFO: - Computing ADE (training)
2022-11-03 00:11:06,841:INFO: 		 ADE on hotel                     dataset:	 0.6390377283096313
2022-11-03 00:11:07,559:INFO: 		 ADE on univ                      dataset:	 0.6242093443870544
2022-11-03 00:11:08,135:INFO: 		 ADE on zara1                     dataset:	 0.7852330803871155
2022-11-03 00:11:08,882:INFO: 		 ADE on zara2                     dataset:	 0.5924072265625
2022-11-03 00:11:08,882:INFO: Average training:	ADE  0.6284	FDE  1.0780
2022-11-03 00:11:08,891:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_309.pth.tar
2022-11-03 00:11:08,891:INFO: 
===> EPOCH: 310 (P3)
2022-11-03 00:11:08,891:INFO: - Computing loss (training)
2022-11-03 00:11:09,982:INFO: Batch:  0/31	Total Loss 6.0386 (6.0386)
2022-11-03 00:11:10,465:INFO: Batch:  1/31	Total Loss 6.0801 (6.0579)
2022-11-03 00:11:10,936:INFO: Batch:  2/31	Total Loss 6.0751 (6.0638)
2022-11-03 00:11:11,410:INFO: Batch:  3/31	Total Loss 5.3562 (5.8678)
2022-11-03 00:11:11,885:INFO: Batch:  4/31	Total Loss 6.4136 (5.9730)
2022-11-03 00:11:12,367:INFO: Batch:  5/31	Total Loss 6.3511 (6.0346)
2022-11-03 00:11:12,847:INFO: Batch:  6/31	Total Loss 6.4139 (6.0890)
2022-11-03 00:11:13,326:INFO: Batch:  7/31	Total Loss 5.8667 (6.0627)
2022-11-03 00:11:13,804:INFO: Batch:  8/31	Total Loss 5.9854 (6.0547)
2022-11-03 00:11:14,285:INFO: Batch:  9/31	Total Loss 6.0428 (6.0535)
2022-11-03 00:11:14,762:INFO: Batch: 10/31	Total Loss 6.0272 (6.0512)
2022-11-03 00:11:15,244:INFO: Batch: 11/31	Total Loss 6.4578 (6.0852)
2022-11-03 00:11:15,727:INFO: Batch: 12/31	Total Loss 5.9108 (6.0709)
2022-11-03 00:11:16,210:INFO: Batch: 13/31	Total Loss 6.5095 (6.1040)
2022-11-03 00:11:16,693:INFO: Batch: 14/31	Total Loss 5.7799 (6.0823)
2022-11-03 00:11:17,175:INFO: Batch: 15/31	Total Loss 6.7138 (6.1176)
2022-11-03 00:11:17,657:INFO: Batch: 16/31	Total Loss 6.3436 (6.1301)
2022-11-03 00:11:18,138:INFO: Batch: 17/31	Total Loss 6.7333 (6.1612)
2022-11-03 00:11:18,618:INFO: Batch: 18/31	Total Loss 6.2218 (6.1647)
2022-11-03 00:11:19,099:INFO: Batch: 19/31	Total Loss 6.4745 (6.1799)
2022-11-03 00:11:19,581:INFO: Batch: 20/31	Total Loss 6.4387 (6.1928)
2022-11-03 00:11:20,068:INFO: Batch: 21/31	Total Loss 5.8250 (6.1764)
2022-11-03 00:11:20,551:INFO: Batch: 22/31	Total Loss 6.0969 (6.1732)
2022-11-03 00:11:21,038:INFO: Batch: 23/31	Total Loss 6.4594 (6.1840)
2022-11-03 00:11:21,518:INFO: Batch: 24/31	Total Loss 6.3210 (6.1895)
2022-11-03 00:11:21,996:INFO: Batch: 25/31	Total Loss 6.2848 (6.1933)
2022-11-03 00:11:22,550:INFO: Batch: 26/31	Total Loss 5.6747 (6.1738)
2022-11-03 00:11:23,026:INFO: Batch: 27/31	Total Loss 5.2518 (6.1383)
2022-11-03 00:11:23,503:INFO: Batch: 28/31	Total Loss 5.8804 (6.1302)
2022-11-03 00:11:23,980:INFO: Batch: 29/31	Total Loss 6.0875 (6.1287)
2022-11-03 00:11:24,372:INFO: Batch: 30/31	Total Loss 2.7401 (6.1035)
2022-11-03 00:11:24,528:INFO: - Computing ADE (validation o)
2022-11-03 00:11:25,128:INFO: 		 ADE on eth                       dataset:	 1.1961414813995361
2022-11-03 00:11:25,128:INFO: Average validation o:	ADE  1.1961	FDE  1.8485
2022-11-03 00:11:25,137:INFO: - Computing ADE (validation)
2022-11-03 00:11:25,403:INFO: 		 ADE on hotel                     dataset:	 0.5486447215080261
2022-11-03 00:11:25,692:INFO: 		 ADE on univ                      dataset:	 0.6570707559585571
2022-11-03 00:11:25,943:INFO: 		 ADE on zara1                     dataset:	 0.7224391102790833
2022-11-03 00:11:26,295:INFO: 		 ADE on zara2                     dataset:	 0.5501840114593506
2022-11-03 00:11:26,295:INFO: Average validation:	ADE  0.6157	FDE  1.0467
2022-11-03 00:11:26,295:INFO: - Computing ADE (training)
2022-11-03 00:11:26,756:INFO: 		 ADE on hotel                     dataset:	 0.6340136528015137
2022-11-03 00:11:27,466:INFO: 		 ADE on univ                      dataset:	 0.627392590045929
2022-11-03 00:11:27,987:INFO: 		 ADE on zara1                     dataset:	 0.806833028793335
2022-11-03 00:11:28,715:INFO: 		 ADE on zara2                     dataset:	 0.617218017578125
2022-11-03 00:11:28,715:INFO: Average training:	ADE  0.6369	FDE  1.1010
2022-11-03 00:11:28,724:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_310.pth.tar
2022-11-03 00:11:28,724:INFO: 
===> EPOCH: 311 (P3)
2022-11-03 00:11:28,724:INFO: - Computing loss (training)
2022-11-03 00:11:29,815:INFO: Batch:  0/31	Total Loss 6.3571 (6.3571)
2022-11-03 00:11:30,291:INFO: Batch:  1/31	Total Loss 6.0708 (6.2173)
2022-11-03 00:11:30,774:INFO: Batch:  2/31	Total Loss 5.9774 (6.1419)
2022-11-03 00:11:31,246:INFO: Batch:  3/31	Total Loss 5.8136 (6.0670)
2022-11-03 00:11:31,718:INFO: Batch:  4/31	Total Loss 6.9091 (6.2386)
2022-11-03 00:11:32,195:INFO: Batch:  5/31	Total Loss 5.8883 (6.1837)
2022-11-03 00:11:32,671:INFO: Batch:  6/31	Total Loss 5.8826 (6.1418)
2022-11-03 00:11:33,144:INFO: Batch:  7/31	Total Loss 6.3455 (6.1683)
2022-11-03 00:11:33,621:INFO: Batch:  8/31	Total Loss 7.3848 (6.2845)
2022-11-03 00:11:34,093:INFO: Batch:  9/31	Total Loss 6.1103 (6.2685)
2022-11-03 00:11:34,568:INFO: Batch: 10/31	Total Loss 5.9626 (6.2384)
2022-11-03 00:11:35,040:INFO: Batch: 11/31	Total Loss 5.9852 (6.2193)
2022-11-03 00:11:35,516:INFO: Batch: 12/31	Total Loss 5.7329 (6.1811)
2022-11-03 00:11:35,992:INFO: Batch: 13/31	Total Loss 5.7294 (6.1477)
2022-11-03 00:11:36,470:INFO: Batch: 14/31	Total Loss 6.1624 (6.1486)
2022-11-03 00:11:36,946:INFO: Batch: 15/31	Total Loss 5.7406 (6.1212)
2022-11-03 00:11:37,423:INFO: Batch: 16/31	Total Loss 6.0229 (6.1156)
2022-11-03 00:11:37,903:INFO: Batch: 17/31	Total Loss 5.7912 (6.0960)
2022-11-03 00:11:38,380:INFO: Batch: 18/31	Total Loss 5.7328 (6.0767)
2022-11-03 00:11:38,858:INFO: Batch: 19/31	Total Loss 6.7003 (6.1065)
2022-11-03 00:11:39,333:INFO: Batch: 20/31	Total Loss 5.7754 (6.0900)
2022-11-03 00:11:39,815:INFO: Batch: 21/31	Total Loss 6.1248 (6.0916)
2022-11-03 00:11:40,299:INFO: Batch: 22/31	Total Loss 6.6022 (6.1139)
2022-11-03 00:11:40,781:INFO: Batch: 23/31	Total Loss 6.2832 (6.1202)
2022-11-03 00:11:41,259:INFO: Batch: 24/31	Total Loss 6.1398 (6.1212)
2022-11-03 00:11:41,735:INFO: Batch: 25/31	Total Loss 5.8550 (6.1106)
2022-11-03 00:11:42,210:INFO: Batch: 26/31	Total Loss 6.6437 (6.1300)
2022-11-03 00:11:42,686:INFO: Batch: 27/31	Total Loss 6.2786 (6.1353)
2022-11-03 00:11:43,161:INFO: Batch: 28/31	Total Loss 6.3924 (6.1439)
2022-11-03 00:11:43,634:INFO: Batch: 29/31	Total Loss 6.3413 (6.1493)
2022-11-03 00:11:44,025:INFO: Batch: 30/31	Total Loss 2.3566 (6.1126)
2022-11-03 00:11:44,173:INFO: - Computing ADE (validation o)
2022-11-03 00:11:44,751:INFO: 		 ADE on eth                       dataset:	 1.1672887802124023
2022-11-03 00:11:44,751:INFO: Average validation o:	ADE  1.1673	FDE  1.8009
2022-11-03 00:11:44,752:INFO: - Computing ADE (validation)
2022-11-03 00:11:45,030:INFO: 		 ADE on hotel                     dataset:	 0.5201815962791443
2022-11-03 00:11:45,332:INFO: 		 ADE on univ                      dataset:	 0.6545401215553284
2022-11-03 00:11:45,590:INFO: 		 ADE on zara1                     dataset:	 0.7176039814949036
2022-11-03 00:11:45,935:INFO: 		 ADE on zara2                     dataset:	 0.5320671796798706
2022-11-03 00:11:45,935:INFO: Average validation:	ADE  0.6059	FDE  1.0312
2022-11-03 00:11:45,936:INFO: - Computing ADE (training)
2022-11-03 00:11:46,383:INFO: 		 ADE on hotel                     dataset:	 0.6061735153198242
2022-11-03 00:11:47,072:INFO: 		 ADE on univ                      dataset:	 0.6197136044502258
2022-11-03 00:11:47,603:INFO: 		 ADE on zara1                     dataset:	 0.7792673110961914
2022-11-03 00:11:48,350:INFO: 		 ADE on zara2                     dataset:	 0.5935190320014954
2022-11-03 00:11:48,350:INFO: Average training:	ADE  0.6242	FDE  1.0829
2022-11-03 00:11:48,358:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_311.pth.tar
2022-11-03 00:11:48,358:INFO: 
===> EPOCH: 312 (P3)
2022-11-03 00:11:48,359:INFO: - Computing loss (training)
2022-11-03 00:11:49,457:INFO: Batch:  0/31	Total Loss 7.2747 (7.2747)
2022-11-03 00:11:49,938:INFO: Batch:  1/31	Total Loss 5.9943 (6.6561)
2022-11-03 00:11:50,409:INFO: Batch:  2/31	Total Loss 6.2115 (6.5169)
2022-11-03 00:11:50,877:INFO: Batch:  3/31	Total Loss 6.7538 (6.5737)
2022-11-03 00:11:51,343:INFO: Batch:  4/31	Total Loss 7.2132 (6.7105)
2022-11-03 00:11:51,815:INFO: Batch:  5/31	Total Loss 6.5115 (6.6828)
2022-11-03 00:11:52,284:INFO: Batch:  6/31	Total Loss 5.9289 (6.5644)
2022-11-03 00:11:52,752:INFO: Batch:  7/31	Total Loss 5.6931 (6.4463)
2022-11-03 00:11:53,230:INFO: Batch:  8/31	Total Loss 6.4423 (6.4459)
2022-11-03 00:11:53,698:INFO: Batch:  9/31	Total Loss 5.6864 (6.3710)
2022-11-03 00:11:54,173:INFO: Batch: 10/31	Total Loss 5.8061 (6.3204)
2022-11-03 00:11:54,641:INFO: Batch: 11/31	Total Loss 6.8336 (6.3629)
2022-11-03 00:11:55,122:INFO: Batch: 12/31	Total Loss 6.2229 (6.3519)
2022-11-03 00:11:55,598:INFO: Batch: 13/31	Total Loss 5.9757 (6.3220)
2022-11-03 00:11:56,072:INFO: Batch: 14/31	Total Loss 6.3513 (6.3241)
2022-11-03 00:11:56,543:INFO: Batch: 15/31	Total Loss 6.6090 (6.3422)
2022-11-03 00:11:57,016:INFO: Batch: 16/31	Total Loss 5.7341 (6.3055)
2022-11-03 00:11:57,488:INFO: Batch: 17/31	Total Loss 6.1731 (6.2977)
2022-11-03 00:11:57,963:INFO: Batch: 18/31	Total Loss 5.8488 (6.2734)
2022-11-03 00:11:58,438:INFO: Batch: 19/31	Total Loss 5.6957 (6.2454)
2022-11-03 00:11:58,910:INFO: Batch: 20/31	Total Loss 6.2813 (6.2470)
2022-11-03 00:11:59,382:INFO: Batch: 21/31	Total Loss 5.6993 (6.2235)
2022-11-03 00:11:59,858:INFO: Batch: 22/31	Total Loss 5.8008 (6.2045)
2022-11-03 00:12:00,335:INFO: Batch: 23/31	Total Loss 5.7304 (6.1815)
2022-11-03 00:12:00,822:INFO: Batch: 24/31	Total Loss 6.4976 (6.1927)
2022-11-03 00:12:01,309:INFO: Batch: 25/31	Total Loss 5.2638 (6.1535)
2022-11-03 00:12:01,782:INFO: Batch: 26/31	Total Loss 6.0777 (6.1509)
2022-11-03 00:12:02,255:INFO: Batch: 27/31	Total Loss 5.9943 (6.1451)
2022-11-03 00:12:02,726:INFO: Batch: 28/31	Total Loss 5.8788 (6.1359)
2022-11-03 00:12:03,198:INFO: Batch: 29/31	Total Loss 5.8166 (6.1246)
2022-11-03 00:12:03,586:INFO: Batch: 30/31	Total Loss 1.9952 (6.0803)
2022-11-03 00:12:03,734:INFO: - Computing ADE (validation o)
2022-11-03 00:12:04,352:INFO: 		 ADE on eth                       dataset:	 1.2027429342269897
2022-11-03 00:12:04,352:INFO: Average validation o:	ADE  1.2027	FDE  1.9248
2022-11-03 00:12:04,353:INFO: - Computing ADE (validation)
2022-11-03 00:12:04,639:INFO: 		 ADE on hotel                     dataset:	 0.5703195929527283
2022-11-03 00:12:04,943:INFO: 		 ADE on univ                      dataset:	 0.662580668926239
2022-11-03 00:12:05,198:INFO: 		 ADE on zara1                     dataset:	 0.7685603499412537
2022-11-03 00:12:05,554:INFO: 		 ADE on zara2                     dataset:	 0.5904446244239807
2022-11-03 00:12:05,554:INFO: Average validation:	ADE  0.6372	FDE  1.1216
2022-11-03 00:12:05,555:INFO: - Computing ADE (training)
2022-11-03 00:12:06,014:INFO: 		 ADE on hotel                     dataset:	 0.6483498215675354
2022-11-03 00:12:06,691:INFO: 		 ADE on univ                      dataset:	 0.6500001549720764
2022-11-03 00:12:07,268:INFO: 		 ADE on zara1                     dataset:	 0.8175332546234131
2022-11-03 00:12:08,030:INFO: 		 ADE on zara2                     dataset:	 0.6461122632026672
2022-11-03 00:12:08,030:INFO: Average training:	ADE  0.6598	FDE  1.1837
2022-11-03 00:12:08,040:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_312.pth.tar
2022-11-03 00:12:08,040:INFO: 
===> EPOCH: 313 (P3)
2022-11-03 00:12:08,040:INFO: - Computing loss (training)
2022-11-03 00:12:09,139:INFO: Batch:  0/31	Total Loss 6.3438 (6.3438)
2022-11-03 00:12:09,613:INFO: Batch:  1/31	Total Loss 6.2732 (6.3087)
2022-11-03 00:12:10,093:INFO: Batch:  2/31	Total Loss 6.0269 (6.2277)
2022-11-03 00:12:10,571:INFO: Batch:  3/31	Total Loss 5.9230 (6.1567)
2022-11-03 00:12:11,047:INFO: Batch:  4/31	Total Loss 6.0919 (6.1427)
2022-11-03 00:12:11,531:INFO: Batch:  5/31	Total Loss 6.1114 (6.1377)
2022-11-03 00:12:12,013:INFO: Batch:  6/31	Total Loss 6.1456 (6.1387)
2022-11-03 00:12:12,495:INFO: Batch:  7/31	Total Loss 6.1564 (6.1409)
2022-11-03 00:12:12,977:INFO: Batch:  8/31	Total Loss 7.1421 (6.2487)
2022-11-03 00:12:13,460:INFO: Batch:  9/31	Total Loss 5.8040 (6.2024)
2022-11-03 00:12:13,944:INFO: Batch: 10/31	Total Loss 6.1232 (6.1951)
2022-11-03 00:12:14,428:INFO: Batch: 11/31	Total Loss 5.9129 (6.1735)
2022-11-03 00:12:14,913:INFO: Batch: 12/31	Total Loss 6.7259 (6.2122)
2022-11-03 00:12:15,401:INFO: Batch: 13/31	Total Loss 5.8542 (6.1866)
2022-11-03 00:12:15,964:INFO: Batch: 14/31	Total Loss 6.2961 (6.1930)
2022-11-03 00:12:16,451:INFO: Batch: 15/31	Total Loss 5.5847 (6.1535)
2022-11-03 00:12:16,937:INFO: Batch: 16/31	Total Loss 5.6716 (6.1257)
2022-11-03 00:12:17,424:INFO: Batch: 17/31	Total Loss 5.9791 (6.1180)
2022-11-03 00:12:17,911:INFO: Batch: 18/31	Total Loss 5.5365 (6.0863)
2022-11-03 00:12:18,396:INFO: Batch: 19/31	Total Loss 5.8386 (6.0734)
2022-11-03 00:12:18,884:INFO: Batch: 20/31	Total Loss 6.6133 (6.0992)
2022-11-03 00:12:19,361:INFO: Batch: 21/31	Total Loss 5.8609 (6.0877)
2022-11-03 00:12:19,837:INFO: Batch: 22/31	Total Loss 6.3067 (6.0962)
2022-11-03 00:12:20,309:INFO: Batch: 23/31	Total Loss 6.0932 (6.0961)
2022-11-03 00:12:20,784:INFO: Batch: 24/31	Total Loss 5.4648 (6.0687)
2022-11-03 00:12:21,258:INFO: Batch: 25/31	Total Loss 6.2446 (6.0754)
2022-11-03 00:12:21,733:INFO: Batch: 26/31	Total Loss 5.5660 (6.0552)
2022-11-03 00:12:22,207:INFO: Batch: 27/31	Total Loss 6.7308 (6.0779)
2022-11-03 00:12:22,679:INFO: Batch: 28/31	Total Loss 6.3926 (6.0875)
2022-11-03 00:12:23,152:INFO: Batch: 29/31	Total Loss 5.9535 (6.0828)
2022-11-03 00:12:23,541:INFO: Batch: 30/31	Total Loss 2.1945 (6.0431)
2022-11-03 00:12:23,689:INFO: - Computing ADE (validation o)
2022-11-03 00:12:24,302:INFO: 		 ADE on eth                       dataset:	 1.1871553659439087
2022-11-03 00:12:24,302:INFO: Average validation o:	ADE  1.1872	FDE  1.8417
2022-11-03 00:12:24,302:INFO: - Computing ADE (validation)
2022-11-03 00:12:24,568:INFO: 		 ADE on hotel                     dataset:	 0.5406081080436707
2022-11-03 00:12:24,879:INFO: 		 ADE on univ                      dataset:	 0.6557317972183228
2022-11-03 00:12:25,136:INFO: 		 ADE on zara1                     dataset:	 0.7183431386947632
2022-11-03 00:12:25,506:INFO: 		 ADE on zara2                     dataset:	 0.5423527956008911
2022-11-03 00:12:25,507:INFO: Average validation:	ADE  0.6115	FDE  1.0418
2022-11-03 00:12:25,507:INFO: - Computing ADE (training)
2022-11-03 00:12:25,938:INFO: 		 ADE on hotel                     dataset:	 0.6291626691818237
2022-11-03 00:12:26,648:INFO: 		 ADE on univ                      dataset:	 0.6238375306129456
2022-11-03 00:12:27,202:INFO: 		 ADE on zara1                     dataset:	 0.7971920967102051
2022-11-03 00:12:27,972:INFO: 		 ADE on zara2                     dataset:	 0.6094683408737183
2022-11-03 00:12:27,972:INFO: Average training:	ADE  0.6321	FDE  1.0944
2022-11-03 00:12:27,981:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_313.pth.tar
2022-11-03 00:12:27,982:INFO: 
===> EPOCH: 314 (P3)
2022-11-03 00:12:27,982:INFO: - Computing loss (training)
2022-11-03 00:12:29,068:INFO: Batch:  0/31	Total Loss 5.8650 (5.8650)
2022-11-03 00:12:29,544:INFO: Batch:  1/31	Total Loss 6.1735 (6.0307)
2022-11-03 00:12:30,022:INFO: Batch:  2/31	Total Loss 6.0453 (6.0352)
2022-11-03 00:12:30,495:INFO: Batch:  3/31	Total Loss 6.3343 (6.1150)
2022-11-03 00:12:30,968:INFO: Batch:  4/31	Total Loss 5.6122 (6.0151)
2022-11-03 00:12:31,441:INFO: Batch:  5/31	Total Loss 5.6624 (5.9617)
2022-11-03 00:12:31,911:INFO: Batch:  6/31	Total Loss 5.9066 (5.9541)
2022-11-03 00:12:32,386:INFO: Batch:  7/31	Total Loss 5.9481 (5.9534)
2022-11-03 00:12:32,860:INFO: Batch:  8/31	Total Loss 5.8821 (5.9450)
2022-11-03 00:12:33,332:INFO: Batch:  9/31	Total Loss 5.9263 (5.9429)
2022-11-03 00:12:33,808:INFO: Batch: 10/31	Total Loss 5.1108 (5.8599)
2022-11-03 00:12:34,285:INFO: Batch: 11/31	Total Loss 6.0630 (5.8773)
2022-11-03 00:12:34,761:INFO: Batch: 12/31	Total Loss 5.5699 (5.8533)
2022-11-03 00:12:35,237:INFO: Batch: 13/31	Total Loss 6.4484 (5.8881)
2022-11-03 00:12:35,712:INFO: Batch: 14/31	Total Loss 7.0455 (5.9682)
2022-11-03 00:12:36,186:INFO: Batch: 15/31	Total Loss 6.5217 (6.0001)
2022-11-03 00:12:36,662:INFO: Batch: 16/31	Total Loss 6.4760 (6.0268)
2022-11-03 00:12:37,138:INFO: Batch: 17/31	Total Loss 5.6876 (6.0078)
2022-11-03 00:12:37,615:INFO: Batch: 18/31	Total Loss 5.8308 (5.9981)
2022-11-03 00:12:38,091:INFO: Batch: 19/31	Total Loss 6.5011 (6.0216)
2022-11-03 00:12:38,568:INFO: Batch: 20/31	Total Loss 5.6156 (6.0010)
2022-11-03 00:12:39,044:INFO: Batch: 21/31	Total Loss 5.6418 (5.9826)
2022-11-03 00:12:39,520:INFO: Batch: 22/31	Total Loss 6.6842 (6.0138)
2022-11-03 00:12:39,994:INFO: Batch: 23/31	Total Loss 6.5819 (6.0336)
2022-11-03 00:12:40,474:INFO: Batch: 24/31	Total Loss 5.5731 (6.0141)
2022-11-03 00:12:40,948:INFO: Batch: 25/31	Total Loss 5.5586 (5.9962)
2022-11-03 00:12:41,422:INFO: Batch: 26/31	Total Loss 6.0085 (5.9967)
2022-11-03 00:12:41,899:INFO: Batch: 27/31	Total Loss 6.4588 (6.0119)
2022-11-03 00:12:42,374:INFO: Batch: 28/31	Total Loss 5.9713 (6.0106)
2022-11-03 00:12:42,850:INFO: Batch: 29/31	Total Loss 5.6200 (5.9982)
2022-11-03 00:12:43,242:INFO: Batch: 30/31	Total Loss 2.6716 (5.9644)
2022-11-03 00:12:43,396:INFO: - Computing ADE (validation o)
2022-11-03 00:12:44,018:INFO: 		 ADE on eth                       dataset:	 1.1841825246810913
2022-11-03 00:12:44,018:INFO: Average validation o:	ADE  1.1842	FDE  1.8209
2022-11-03 00:12:44,019:INFO: - Computing ADE (validation)
2022-11-03 00:12:44,287:INFO: 		 ADE on hotel                     dataset:	 0.5358700752258301
2022-11-03 00:12:44,584:INFO: 		 ADE on univ                      dataset:	 0.6589627265930176
2022-11-03 00:12:44,835:INFO: 		 ADE on zara1                     dataset:	 0.7014294266700745
2022-11-03 00:12:45,187:INFO: 		 ADE on zara2                     dataset:	 0.547169029712677
2022-11-03 00:12:45,187:INFO: Average validation:	ADE  0.6137	FDE  1.0562
2022-11-03 00:12:45,188:INFO: - Computing ADE (training)
2022-11-03 00:12:45,631:INFO: 		 ADE on hotel                     dataset:	 0.6178290247917175
2022-11-03 00:12:46,317:INFO: 		 ADE on univ                      dataset:	 0.6229055523872375
2022-11-03 00:12:46,848:INFO: 		 ADE on zara1                     dataset:	 0.7943309545516968
2022-11-03 00:12:47,586:INFO: 		 ADE on zara2                     dataset:	 0.6139357089996338
2022-11-03 00:12:47,586:INFO: Average training:	ADE  0.6319	FDE  1.1046
2022-11-03 00:12:47,595:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_314.pth.tar
2022-11-03 00:12:47,595:INFO: 
===> EPOCH: 315 (P3)
2022-11-03 00:12:47,595:INFO: - Computing loss (training)
2022-11-03 00:12:48,698:INFO: Batch:  0/31	Total Loss 5.5614 (5.5614)
2022-11-03 00:12:49,177:INFO: Batch:  1/31	Total Loss 5.9696 (5.7564)
2022-11-03 00:12:49,656:INFO: Batch:  2/31	Total Loss 5.7171 (5.7447)
2022-11-03 00:12:50,129:INFO: Batch:  3/31	Total Loss 6.3424 (5.9041)
2022-11-03 00:12:50,602:INFO: Batch:  4/31	Total Loss 5.5972 (5.8440)
2022-11-03 00:12:51,078:INFO: Batch:  5/31	Total Loss 5.8453 (5.8442)
2022-11-03 00:12:51,553:INFO: Batch:  6/31	Total Loss 5.9935 (5.8648)
2022-11-03 00:12:52,026:INFO: Batch:  7/31	Total Loss 6.3824 (5.9322)
2022-11-03 00:12:52,498:INFO: Batch:  8/31	Total Loss 5.8504 (5.9233)
2022-11-03 00:12:52,972:INFO: Batch:  9/31	Total Loss 5.4429 (5.8713)
2022-11-03 00:12:53,447:INFO: Batch: 10/31	Total Loss 4.8727 (5.7812)
2022-11-03 00:12:53,921:INFO: Batch: 11/31	Total Loss 6.7691 (5.8618)
2022-11-03 00:12:54,400:INFO: Batch: 12/31	Total Loss 6.3155 (5.8947)
2022-11-03 00:12:54,877:INFO: Batch: 13/31	Total Loss 6.0320 (5.9038)
2022-11-03 00:12:55,359:INFO: Batch: 14/31	Total Loss 6.2940 (5.9301)
2022-11-03 00:12:55,838:INFO: Batch: 15/31	Total Loss 5.1764 (5.8778)
2022-11-03 00:12:56,315:INFO: Batch: 16/31	Total Loss 5.6626 (5.8646)
2022-11-03 00:12:56,793:INFO: Batch: 17/31	Total Loss 6.7230 (5.9118)
2022-11-03 00:12:57,270:INFO: Batch: 18/31	Total Loss 5.9881 (5.9157)
2022-11-03 00:12:57,745:INFO: Batch: 19/31	Total Loss 6.0015 (5.9203)
2022-11-03 00:12:58,222:INFO: Batch: 20/31	Total Loss 5.9213 (5.9204)
2022-11-03 00:12:58,696:INFO: Batch: 21/31	Total Loss 6.5039 (5.9464)
2022-11-03 00:12:59,172:INFO: Batch: 22/31	Total Loss 6.1388 (5.9547)
2022-11-03 00:12:59,649:INFO: Batch: 23/31	Total Loss 5.8723 (5.9511)
2022-11-03 00:13:00,127:INFO: Batch: 24/31	Total Loss 5.6017 (5.9365)
2022-11-03 00:13:00,603:INFO: Batch: 25/31	Total Loss 5.6708 (5.9257)
2022-11-03 00:13:01,078:INFO: Batch: 26/31	Total Loss 5.9754 (5.9275)
2022-11-03 00:13:01,564:INFO: Batch: 27/31	Total Loss 6.3374 (5.9414)
2022-11-03 00:13:02,058:INFO: Batch: 28/31	Total Loss 5.4528 (5.9250)
2022-11-03 00:13:02,543:INFO: Batch: 29/31	Total Loss 5.6676 (5.9160)
2022-11-03 00:13:02,955:INFO: Batch: 30/31	Total Loss 2.4543 (5.8862)
2022-11-03 00:13:03,105:INFO: - Computing ADE (validation o)
2022-11-03 00:13:03,723:INFO: 		 ADE on eth                       dataset:	 1.2040469646453857
2022-11-03 00:13:03,723:INFO: Average validation o:	ADE  1.2040	FDE  1.8917
2022-11-03 00:13:03,724:INFO: - Computing ADE (validation)
2022-11-03 00:13:04,006:INFO: 		 ADE on hotel                     dataset:	 0.5453826785087585
2022-11-03 00:13:04,310:INFO: 		 ADE on univ                      dataset:	 0.6515434384346008
2022-11-03 00:13:04,558:INFO: 		 ADE on zara1                     dataset:	 0.742938756942749
2022-11-03 00:13:04,912:INFO: 		 ADE on zara2                     dataset:	 0.5656653642654419
2022-11-03 00:13:04,912:INFO: Average validation:	ADE  0.6195	FDE  1.0672
2022-11-03 00:13:04,912:INFO: - Computing ADE (training)
2022-11-03 00:13:05,408:INFO: 		 ADE on hotel                     dataset:	 0.6236973404884338
2022-11-03 00:13:06,147:INFO: 		 ADE on univ                      dataset:	 0.6314513683319092
2022-11-03 00:13:06,714:INFO: 		 ADE on zara1                     dataset:	 0.8092038631439209
2022-11-03 00:13:07,508:INFO: 		 ADE on zara2                     dataset:	 0.6275925040245056
2022-11-03 00:13:07,509:INFO: Average training:	ADE  0.6418	FDE  1.1262
2022-11-03 00:13:07,517:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_315.pth.tar
2022-11-03 00:13:07,517:INFO: 
===> EPOCH: 316 (P3)
2022-11-03 00:13:07,518:INFO: - Computing loss (training)
2022-11-03 00:13:08,630:INFO: Batch:  0/31	Total Loss 4.8034 (4.8034)
2022-11-03 00:13:09,107:INFO: Batch:  1/31	Total Loss 6.3613 (5.5269)
2022-11-03 00:13:09,608:INFO: Batch:  2/31	Total Loss 6.1331 (5.7240)
2022-11-03 00:13:10,193:INFO: Batch:  3/31	Total Loss 6.1195 (5.8260)
2022-11-03 00:13:10,678:INFO: Batch:  4/31	Total Loss 5.6783 (5.7949)
2022-11-03 00:13:11,166:INFO: Batch:  5/31	Total Loss 5.8967 (5.8118)
2022-11-03 00:13:11,656:INFO: Batch:  6/31	Total Loss 6.3371 (5.8884)
2022-11-03 00:13:12,142:INFO: Batch:  7/31	Total Loss 5.7443 (5.8712)
2022-11-03 00:13:12,763:INFO: Batch:  8/31	Total Loss 5.7372 (5.8577)
2022-11-03 00:13:13,460:INFO: Batch:  9/31	Total Loss 5.3779 (5.8123)
2022-11-03 00:13:14,016:INFO: Batch: 10/31	Total Loss 6.3604 (5.8556)
2022-11-03 00:13:14,549:INFO: Batch: 11/31	Total Loss 5.9034 (5.8596)
2022-11-03 00:13:15,112:INFO: Batch: 12/31	Total Loss 5.5188 (5.8345)
2022-11-03 00:13:15,621:INFO: Batch: 13/31	Total Loss 6.5208 (5.8797)
2022-11-03 00:13:16,123:INFO: Batch: 14/31	Total Loss 5.2955 (5.8440)
2022-11-03 00:13:16,661:INFO: Batch: 15/31	Total Loss 5.5771 (5.8275)
2022-11-03 00:13:17,188:INFO: Batch: 16/31	Total Loss 5.7744 (5.8244)
2022-11-03 00:13:17,706:INFO: Batch: 17/31	Total Loss 6.8765 (5.8730)
2022-11-03 00:13:18,241:INFO: Batch: 18/31	Total Loss 5.8108 (5.8697)
2022-11-03 00:13:18,719:INFO: Batch: 19/31	Total Loss 6.1210 (5.8826)
2022-11-03 00:13:19,278:INFO: Batch: 20/31	Total Loss 5.7370 (5.8757)
2022-11-03 00:13:19,807:INFO: Batch: 21/31	Total Loss 6.5947 (5.9095)
2022-11-03 00:13:20,314:INFO: Batch: 22/31	Total Loss 6.4659 (5.9340)
2022-11-03 00:13:20,863:INFO: Batch: 23/31	Total Loss 6.5880 (5.9637)
2022-11-03 00:13:21,386:INFO: Batch: 24/31	Total Loss 6.2968 (5.9765)
2022-11-03 00:13:21,885:INFO: Batch: 25/31	Total Loss 6.6726 (6.0057)
2022-11-03 00:13:22,426:INFO: Batch: 26/31	Total Loss 5.6820 (5.9924)
2022-11-03 00:13:22,913:INFO: Batch: 27/31	Total Loss 5.7909 (5.9855)
2022-11-03 00:13:23,413:INFO: Batch: 28/31	Total Loss 6.7707 (6.0137)
2022-11-03 00:13:23,910:INFO: Batch: 29/31	Total Loss 6.9943 (6.0464)
2022-11-03 00:13:24,350:INFO: Batch: 30/31	Total Loss 2.3668 (6.0067)
2022-11-03 00:13:24,548:INFO: - Computing ADE (validation o)
2022-11-03 00:13:25,394:INFO: 		 ADE on eth                       dataset:	 1.2120692729949951
2022-11-03 00:13:25,394:INFO: Average validation o:	ADE  1.2121	FDE  1.9062
2022-11-03 00:13:25,395:INFO: - Computing ADE (validation)
2022-11-03 00:13:25,721:INFO: 		 ADE on hotel                     dataset:	 0.5470314621925354
2022-11-03 00:13:26,024:INFO: 		 ADE on univ                      dataset:	 0.6621056795120239
2022-11-03 00:13:26,280:INFO: 		 ADE on zara1                     dataset:	 0.792273998260498
2022-11-03 00:13:26,628:INFO: 		 ADE on zara2                     dataset:	 0.5791603326797485
2022-11-03 00:13:26,628:INFO: Average validation:	ADE  0.6329	FDE  1.0930
2022-11-03 00:13:26,629:INFO: - Computing ADE (training)
2022-11-03 00:13:27,107:INFO: 		 ADE on hotel                     dataset:	 0.6275174021720886
2022-11-03 00:13:27,832:INFO: 		 ADE on univ                      dataset:	 0.6413520574569702
2022-11-03 00:13:28,369:INFO: 		 ADE on zara1                     dataset:	 0.8403638601303101
2022-11-03 00:13:29,125:INFO: 		 ADE on zara2                     dataset:	 0.6442079544067383
2022-11-03 00:13:29,125:INFO: Average training:	ADE  0.6543	FDE  1.1512
2022-11-03 00:13:29,134:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_316.pth.tar
2022-11-03 00:13:29,134:INFO: 
===> EPOCH: 317 (P3)
2022-11-03 00:13:29,135:INFO: - Computing loss (training)
2022-11-03 00:13:30,246:INFO: Batch:  0/31	Total Loss 6.2532 (6.2532)
2022-11-03 00:13:30,719:INFO: Batch:  1/31	Total Loss 6.8722 (6.5728)
2022-11-03 00:13:31,194:INFO: Batch:  2/31	Total Loss 6.1047 (6.4150)
2022-11-03 00:13:31,661:INFO: Batch:  3/31	Total Loss 6.0754 (6.3344)
2022-11-03 00:13:32,133:INFO: Batch:  4/31	Total Loss 5.9158 (6.2541)
2022-11-03 00:13:32,608:INFO: Batch:  5/31	Total Loss 5.8070 (6.1836)
2022-11-03 00:13:33,084:INFO: Batch:  6/31	Total Loss 6.0372 (6.1605)
2022-11-03 00:13:33,552:INFO: Batch:  7/31	Total Loss 6.3254 (6.1810)
2022-11-03 00:13:34,019:INFO: Batch:  8/31	Total Loss 5.6247 (6.1115)
2022-11-03 00:13:34,490:INFO: Batch:  9/31	Total Loss 6.9351 (6.1887)
2022-11-03 00:13:34,958:INFO: Batch: 10/31	Total Loss 6.3018 (6.1985)
2022-11-03 00:13:35,429:INFO: Batch: 11/31	Total Loss 5.5897 (6.1482)
2022-11-03 00:13:35,904:INFO: Batch: 12/31	Total Loss 6.5975 (6.1869)
2022-11-03 00:13:36,378:INFO: Batch: 13/31	Total Loss 6.3918 (6.2026)
2022-11-03 00:13:36,854:INFO: Batch: 14/31	Total Loss 5.9961 (6.1867)
2022-11-03 00:13:37,330:INFO: Batch: 15/31	Total Loss 5.6676 (6.1531)
2022-11-03 00:13:37,804:INFO: Batch: 16/31	Total Loss 5.3921 (6.1115)
2022-11-03 00:13:38,276:INFO: Batch: 17/31	Total Loss 6.4987 (6.1321)
2022-11-03 00:13:38,750:INFO: Batch: 18/31	Total Loss 7.0002 (6.1755)
2022-11-03 00:13:39,225:INFO: Batch: 19/31	Total Loss 6.4103 (6.1869)
2022-11-03 00:13:39,700:INFO: Batch: 20/31	Total Loss 5.4455 (6.1515)
2022-11-03 00:13:40,175:INFO: Batch: 21/31	Total Loss 6.0499 (6.1468)
2022-11-03 00:13:40,647:INFO: Batch: 22/31	Total Loss 5.8571 (6.1346)
2022-11-03 00:13:41,120:INFO: Batch: 23/31	Total Loss 5.9844 (6.1281)
2022-11-03 00:13:41,591:INFO: Batch: 24/31	Total Loss 6.2425 (6.1327)
2022-11-03 00:13:42,062:INFO: Batch: 25/31	Total Loss 5.7899 (6.1199)
2022-11-03 00:13:42,534:INFO: Batch: 26/31	Total Loss 6.3732 (6.1304)
2022-11-03 00:13:43,008:INFO: Batch: 27/31	Total Loss 7.2927 (6.1741)
2022-11-03 00:13:43,480:INFO: Batch: 28/31	Total Loss 6.2053 (6.1751)
2022-11-03 00:13:43,953:INFO: Batch: 29/31	Total Loss 5.4341 (6.1484)
2022-11-03 00:13:44,342:INFO: Batch: 30/31	Total Loss 2.3407 (6.1117)
2022-11-03 00:13:44,495:INFO: - Computing ADE (validation o)
2022-11-03 00:13:45,054:INFO: 		 ADE on eth                       dataset:	 1.233919382095337
2022-11-03 00:13:45,054:INFO: Average validation o:	ADE  1.2339	FDE  1.9436
2022-11-03 00:13:45,054:INFO: - Computing ADE (validation)
2022-11-03 00:13:45,345:INFO: 		 ADE on hotel                     dataset:	 0.5579935908317566
2022-11-03 00:13:45,640:INFO: 		 ADE on univ                      dataset:	 0.6656609773635864
2022-11-03 00:13:45,898:INFO: 		 ADE on zara1                     dataset:	 0.7836416363716125
2022-11-03 00:13:46,255:INFO: 		 ADE on zara2                     dataset:	 0.5906673669815063
2022-11-03 00:13:46,255:INFO: Average validation:	ADE  0.6391	FDE  1.1080
2022-11-03 00:13:46,256:INFO: - Computing ADE (training)
2022-11-03 00:13:46,702:INFO: 		 ADE on hotel                     dataset:	 0.6355623006820679
2022-11-03 00:13:47,410:INFO: 		 ADE on univ                      dataset:	 0.6445252895355225
2022-11-03 00:13:47,947:INFO: 		 ADE on zara1                     dataset:	 0.8522390723228455
2022-11-03 00:13:48,718:INFO: 		 ADE on zara2                     dataset:	 0.6562779545783997
2022-11-03 00:13:48,719:INFO: Average training:	ADE  0.6599	FDE  1.1625
2022-11-03 00:13:48,728:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_317.pth.tar
2022-11-03 00:13:48,728:INFO: 
===> EPOCH: 318 (P3)
2022-11-03 00:13:48,729:INFO: - Computing loss (training)
2022-11-03 00:13:49,830:INFO: Batch:  0/31	Total Loss 5.8598 (5.8598)
2022-11-03 00:13:50,309:INFO: Batch:  1/31	Total Loss 6.3852 (6.1379)
2022-11-03 00:13:50,793:INFO: Batch:  2/31	Total Loss 6.6962 (6.3205)
2022-11-03 00:13:51,279:INFO: Batch:  3/31	Total Loss 6.5619 (6.3760)
2022-11-03 00:13:51,764:INFO: Batch:  4/31	Total Loss 5.9397 (6.2819)
2022-11-03 00:13:52,253:INFO: Batch:  5/31	Total Loss 5.7756 (6.1968)
2022-11-03 00:13:52,739:INFO: Batch:  6/31	Total Loss 5.9287 (6.1597)
2022-11-03 00:13:53,210:INFO: Batch:  7/31	Total Loss 5.6327 (6.0988)
2022-11-03 00:13:53,679:INFO: Batch:  8/31	Total Loss 5.5794 (6.0502)
2022-11-03 00:13:54,149:INFO: Batch:  9/31	Total Loss 6.2924 (6.0745)
2022-11-03 00:13:54,618:INFO: Batch: 10/31	Total Loss 6.0174 (6.0692)
2022-11-03 00:13:55,091:INFO: Batch: 11/31	Total Loss 6.8855 (6.1402)
2022-11-03 00:13:55,566:INFO: Batch: 12/31	Total Loss 6.6156 (6.1746)
2022-11-03 00:13:56,042:INFO: Batch: 13/31	Total Loss 5.5986 (6.1309)
2022-11-03 00:13:56,519:INFO: Batch: 14/31	Total Loss 5.4374 (6.0814)
2022-11-03 00:13:56,994:INFO: Batch: 15/31	Total Loss 6.0629 (6.0803)
2022-11-03 00:13:57,469:INFO: Batch: 16/31	Total Loss 6.6666 (6.1127)
2022-11-03 00:13:57,945:INFO: Batch: 17/31	Total Loss 5.8544 (6.0968)
2022-11-03 00:13:58,419:INFO: Batch: 18/31	Total Loss 5.8786 (6.0859)
2022-11-03 00:13:58,895:INFO: Batch: 19/31	Total Loss 5.9125 (6.0769)
2022-11-03 00:13:59,369:INFO: Batch: 20/31	Total Loss 5.4304 (6.0394)
2022-11-03 00:13:59,845:INFO: Batch: 21/31	Total Loss 5.8483 (6.0305)
2022-11-03 00:14:00,317:INFO: Batch: 22/31	Total Loss 6.4507 (6.0486)
2022-11-03 00:14:00,792:INFO: Batch: 23/31	Total Loss 5.1154 (6.0120)
2022-11-03 00:14:01,270:INFO: Batch: 24/31	Total Loss 6.1463 (6.0176)
2022-11-03 00:14:01,745:INFO: Batch: 25/31	Total Loss 5.8214 (6.0096)
2022-11-03 00:14:02,220:INFO: Batch: 26/31	Total Loss 6.3793 (6.0230)
2022-11-03 00:14:02,694:INFO: Batch: 27/31	Total Loss 5.8308 (6.0160)
2022-11-03 00:14:03,167:INFO: Batch: 28/31	Total Loss 6.2320 (6.0244)
2022-11-03 00:14:03,641:INFO: Batch: 29/31	Total Loss 5.9722 (6.0226)
2022-11-03 00:14:04,029:INFO: Batch: 30/31	Total Loss 2.0834 (5.9852)
2022-11-03 00:14:04,179:INFO: - Computing ADE (validation o)
2022-11-03 00:14:04,767:INFO: 		 ADE on eth                       dataset:	 1.1884515285491943
2022-11-03 00:14:04,767:INFO: Average validation o:	ADE  1.1885	FDE  1.8811
2022-11-03 00:14:04,768:INFO: - Computing ADE (validation)
2022-11-03 00:14:05,120:INFO: 		 ADE on hotel                     dataset:	 0.5349991917610168
2022-11-03 00:14:05,421:INFO: 		 ADE on univ                      dataset:	 0.6527646780014038
2022-11-03 00:14:05,669:INFO: 		 ADE on zara1                     dataset:	 0.7562548518180847
2022-11-03 00:14:06,026:INFO: 		 ADE on zara2                     dataset:	 0.5482145547866821
2022-11-03 00:14:06,026:INFO: Average validation:	ADE  0.6140	FDE  1.0543
2022-11-03 00:14:06,027:INFO: - Computing ADE (training)
2022-11-03 00:14:06,462:INFO: 		 ADE on hotel                     dataset:	 0.6275334358215332
2022-11-03 00:14:07,159:INFO: 		 ADE on univ                      dataset:	 0.6281841397285461
2022-11-03 00:14:07,695:INFO: 		 ADE on zara1                     dataset:	 0.7998024225234985
2022-11-03 00:14:08,477:INFO: 		 ADE on zara2                     dataset:	 0.6082122921943665
2022-11-03 00:14:08,477:INFO: Average training:	ADE  0.6351	FDE  1.1091
2022-11-03 00:14:08,486:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_318.pth.tar
2022-11-03 00:14:08,486:INFO: 
===> EPOCH: 319 (P3)
2022-11-03 00:14:08,486:INFO: - Computing loss (training)
2022-11-03 00:14:09,564:INFO: Batch:  0/31	Total Loss 6.6410 (6.6410)
2022-11-03 00:14:10,045:INFO: Batch:  1/31	Total Loss 5.6620 (6.1092)
2022-11-03 00:14:10,525:INFO: Batch:  2/31	Total Loss 5.6621 (5.9725)
2022-11-03 00:14:11,003:INFO: Batch:  3/31	Total Loss 5.2934 (5.7786)
2022-11-03 00:14:11,477:INFO: Batch:  4/31	Total Loss 5.6752 (5.7562)
2022-11-03 00:14:11,959:INFO: Batch:  5/31	Total Loss 5.7542 (5.7558)
2022-11-03 00:14:12,437:INFO: Batch:  6/31	Total Loss 5.9074 (5.7781)
2022-11-03 00:14:12,913:INFO: Batch:  7/31	Total Loss 5.7035 (5.7688)
2022-11-03 00:14:13,391:INFO: Batch:  8/31	Total Loss 5.4463 (5.7346)
2022-11-03 00:14:13,864:INFO: Batch:  9/31	Total Loss 5.9448 (5.7540)
2022-11-03 00:14:14,341:INFO: Batch: 10/31	Total Loss 5.6227 (5.7418)
2022-11-03 00:14:14,816:INFO: Batch: 11/31	Total Loss 5.4498 (5.7156)
2022-11-03 00:14:15,297:INFO: Batch: 12/31	Total Loss 5.5139 (5.7013)
2022-11-03 00:14:15,776:INFO: Batch: 13/31	Total Loss 5.2200 (5.6701)
2022-11-03 00:14:16,255:INFO: Batch: 14/31	Total Loss 5.8811 (5.6845)
2022-11-03 00:14:16,733:INFO: Batch: 15/31	Total Loss 6.0524 (5.7056)
2022-11-03 00:14:17,214:INFO: Batch: 16/31	Total Loss 5.3264 (5.6822)
2022-11-03 00:14:17,696:INFO: Batch: 17/31	Total Loss 5.7169 (5.6841)
2022-11-03 00:14:18,179:INFO: Batch: 18/31	Total Loss 6.4067 (5.7208)
2022-11-03 00:14:18,660:INFO: Batch: 19/31	Total Loss 5.7931 (5.7242)
2022-11-03 00:14:19,139:INFO: Batch: 20/31	Total Loss 6.0254 (5.7372)
2022-11-03 00:14:19,622:INFO: Batch: 21/31	Total Loss 6.3721 (5.7692)
2022-11-03 00:14:20,104:INFO: Batch: 22/31	Total Loss 6.3227 (5.7945)
2022-11-03 00:14:20,585:INFO: Batch: 23/31	Total Loss 5.4748 (5.7802)
2022-11-03 00:14:21,066:INFO: Batch: 24/31	Total Loss 6.6315 (5.8138)
2022-11-03 00:14:21,550:INFO: Batch: 25/31	Total Loss 5.7127 (5.8098)
2022-11-03 00:14:22,043:INFO: Batch: 26/31	Total Loss 5.6991 (5.8057)
2022-11-03 00:14:22,525:INFO: Batch: 27/31	Total Loss 6.5248 (5.8317)
2022-11-03 00:14:23,004:INFO: Batch: 28/31	Total Loss 5.2161 (5.8087)
2022-11-03 00:14:23,483:INFO: Batch: 29/31	Total Loss 6.5686 (5.8326)
2022-11-03 00:14:23,874:INFO: Batch: 30/31	Total Loss 2.3866 (5.8005)
2022-11-03 00:14:24,032:INFO: - Computing ADE (validation o)
2022-11-03 00:14:24,643:INFO: 		 ADE on eth                       dataset:	 1.187269926071167
2022-11-03 00:14:24,644:INFO: Average validation o:	ADE  1.1873	FDE  1.8668
2022-11-03 00:14:24,644:INFO: - Computing ADE (validation)
2022-11-03 00:14:24,918:INFO: 		 ADE on hotel                     dataset:	 0.5256378054618835
2022-11-03 00:14:25,202:INFO: 		 ADE on univ                      dataset:	 0.6546128392219543
2022-11-03 00:14:25,446:INFO: 		 ADE on zara1                     dataset:	 0.7618436217308044
2022-11-03 00:14:25,805:INFO: 		 ADE on zara2                     dataset:	 0.5444278120994568
2022-11-03 00:14:25,806:INFO: Average validation:	ADE  0.6134	FDE  1.0457
2022-11-03 00:14:25,806:INFO: - Computing ADE (training)
2022-11-03 00:14:26,261:INFO: 		 ADE on hotel                     dataset:	 0.6177523136138916
2022-11-03 00:14:26,969:INFO: 		 ADE on univ                      dataset:	 0.6256825923919678
2022-11-03 00:14:27,503:INFO: 		 ADE on zara1                     dataset:	 0.8121320605278015
2022-11-03 00:14:28,259:INFO: 		 ADE on zara2                     dataset:	 0.60810786485672
2022-11-03 00:14:28,259:INFO: Average training:	ADE  0.6338	FDE  1.0991
2022-11-03 00:14:28,268:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_319.pth.tar
2022-11-03 00:14:28,268:INFO: 
===> EPOCH: 320 (P3)
2022-11-03 00:14:28,269:INFO: - Computing loss (training)
2022-11-03 00:14:29,375:INFO: Batch:  0/31	Total Loss 6.0745 (6.0745)
2022-11-03 00:14:29,858:INFO: Batch:  1/31	Total Loss 5.4830 (5.7796)
2022-11-03 00:14:30,339:INFO: Batch:  2/31	Total Loss 5.6450 (5.7348)
2022-11-03 00:14:30,823:INFO: Batch:  3/31	Total Loss 5.9294 (5.7793)
2022-11-03 00:14:31,301:INFO: Batch:  4/31	Total Loss 5.3655 (5.6938)
2022-11-03 00:14:31,782:INFO: Batch:  5/31	Total Loss 6.3525 (5.8073)
2022-11-03 00:14:32,261:INFO: Batch:  6/31	Total Loss 6.5178 (5.8953)
2022-11-03 00:14:32,738:INFO: Batch:  7/31	Total Loss 6.1968 (5.9293)
2022-11-03 00:14:33,216:INFO: Batch:  8/31	Total Loss 5.6716 (5.9004)
2022-11-03 00:14:33,695:INFO: Batch:  9/31	Total Loss 6.0800 (5.9170)
2022-11-03 00:14:34,175:INFO: Batch: 10/31	Total Loss 5.9888 (5.9237)
2022-11-03 00:14:34,653:INFO: Batch: 11/31	Total Loss 5.5759 (5.8933)
2022-11-03 00:14:35,138:INFO: Batch: 12/31	Total Loss 5.8025 (5.8861)
2022-11-03 00:14:35,619:INFO: Batch: 13/31	Total Loss 5.7202 (5.8728)
2022-11-03 00:14:36,101:INFO: Batch: 14/31	Total Loss 5.7282 (5.8631)
2022-11-03 00:14:36,583:INFO: Batch: 15/31	Total Loss 5.2674 (5.8204)
2022-11-03 00:14:37,067:INFO: Batch: 16/31	Total Loss 6.4213 (5.8544)
2022-11-03 00:14:37,555:INFO: Batch: 17/31	Total Loss 5.3630 (5.8269)
2022-11-03 00:14:38,040:INFO: Batch: 18/31	Total Loss 5.6537 (5.8176)
2022-11-03 00:14:38,521:INFO: Batch: 19/31	Total Loss 5.7777 (5.8158)
2022-11-03 00:14:39,004:INFO: Batch: 20/31	Total Loss 5.5100 (5.8008)
2022-11-03 00:14:39,486:INFO: Batch: 21/31	Total Loss 6.9491 (5.8520)
2022-11-03 00:14:39,969:INFO: Batch: 22/31	Total Loss 5.6198 (5.8404)
2022-11-03 00:14:40,452:INFO: Batch: 23/31	Total Loss 5.6305 (5.8313)
2022-11-03 00:14:40,930:INFO: Batch: 24/31	Total Loss 5.6891 (5.8258)
2022-11-03 00:14:41,413:INFO: Batch: 25/31	Total Loss 5.0984 (5.7948)
2022-11-03 00:14:41,895:INFO: Batch: 26/31	Total Loss 6.2439 (5.8120)
2022-11-03 00:14:42,374:INFO: Batch: 27/31	Total Loss 6.1786 (5.8245)
2022-11-03 00:14:42,855:INFO: Batch: 28/31	Total Loss 5.9069 (5.8275)
2022-11-03 00:14:43,334:INFO: Batch: 29/31	Total Loss 5.7234 (5.8246)
2022-11-03 00:14:43,728:INFO: Batch: 30/31	Total Loss 2.2047 (5.7931)
2022-11-03 00:14:43,885:INFO: - Computing ADE (validation o)
2022-11-03 00:14:44,486:INFO: 		 ADE on eth                       dataset:	 1.1870251893997192
2022-11-03 00:14:44,487:INFO: Average validation o:	ADE  1.1870	FDE  1.8644
2022-11-03 00:14:44,487:INFO: - Computing ADE (validation)
2022-11-03 00:14:44,778:INFO: 		 ADE on hotel                     dataset:	 0.531326174736023
2022-11-03 00:14:45,086:INFO: 		 ADE on univ                      dataset:	 0.6526679992675781
2022-11-03 00:14:45,350:INFO: 		 ADE on zara1                     dataset:	 0.7259935736656189
2022-11-03 00:14:45,705:INFO: 		 ADE on zara2                     dataset:	 0.5434605479240417
2022-11-03 00:14:45,705:INFO: Average validation:	ADE  0.6102	FDE  1.0432
2022-11-03 00:14:45,706:INFO: - Computing ADE (training)
2022-11-03 00:14:46,164:INFO: 		 ADE on hotel                     dataset:	 0.6166751384735107
2022-11-03 00:14:46,888:INFO: 		 ADE on univ                      dataset:	 0.6217501759529114
2022-11-03 00:14:47,415:INFO: 		 ADE on zara1                     dataset:	 0.803269624710083
2022-11-03 00:14:48,188:INFO: 		 ADE on zara2                     dataset:	 0.6100508570671082
2022-11-03 00:14:48,188:INFO: Average training:	ADE  0.6308	FDE  1.0960
2022-11-03 00:14:48,197:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_320.pth.tar
2022-11-03 00:14:48,197:INFO: 
===> EPOCH: 321 (P3)
2022-11-03 00:14:48,198:INFO: - Computing loss (training)
2022-11-03 00:14:49,315:INFO: Batch:  0/31	Total Loss 5.6687 (5.6687)
2022-11-03 00:14:49,792:INFO: Batch:  1/31	Total Loss 6.1011 (5.8820)
2022-11-03 00:14:50,268:INFO: Batch:  2/31	Total Loss 6.1545 (5.9720)
2022-11-03 00:14:50,737:INFO: Batch:  3/31	Total Loss 6.1013 (6.0020)
2022-11-03 00:14:51,209:INFO: Batch:  4/31	Total Loss 5.6725 (5.9374)
2022-11-03 00:14:51,684:INFO: Batch:  5/31	Total Loss 5.5416 (5.8756)
2022-11-03 00:14:52,153:INFO: Batch:  6/31	Total Loss 5.6306 (5.8448)
2022-11-03 00:14:52,625:INFO: Batch:  7/31	Total Loss 6.2531 (5.8993)
2022-11-03 00:14:53,097:INFO: Batch:  8/31	Total Loss 5.4834 (5.8551)
2022-11-03 00:14:53,566:INFO: Batch:  9/31	Total Loss 5.6072 (5.8292)
2022-11-03 00:14:54,037:INFO: Batch: 10/31	Total Loss 5.9433 (5.8408)
2022-11-03 00:14:54,508:INFO: Batch: 11/31	Total Loss 5.2675 (5.7913)
2022-11-03 00:14:54,981:INFO: Batch: 12/31	Total Loss 6.2627 (5.8268)
2022-11-03 00:14:55,455:INFO: Batch: 13/31	Total Loss 5.5350 (5.8071)
2022-11-03 00:14:55,928:INFO: Batch: 14/31	Total Loss 6.1442 (5.8301)
2022-11-03 00:14:56,402:INFO: Batch: 15/31	Total Loss 5.6970 (5.8214)
2022-11-03 00:14:56,876:INFO: Batch: 16/31	Total Loss 5.6687 (5.8121)
2022-11-03 00:14:57,429:INFO: Batch: 17/31	Total Loss 6.6700 (5.8597)
2022-11-03 00:14:57,902:INFO: Batch: 18/31	Total Loss 6.1756 (5.8755)
2022-11-03 00:14:58,374:INFO: Batch: 19/31	Total Loss 5.5928 (5.8604)
2022-11-03 00:14:58,847:INFO: Batch: 20/31	Total Loss 5.2999 (5.8307)
2022-11-03 00:14:59,319:INFO: Batch: 21/31	Total Loss 5.7430 (5.8266)
2022-11-03 00:14:59,796:INFO: Batch: 22/31	Total Loss 6.3288 (5.8480)
2022-11-03 00:15:00,269:INFO: Batch: 23/31	Total Loss 6.1199 (5.8591)
2022-11-03 00:15:00,742:INFO: Batch: 24/31	Total Loss 5.9596 (5.8633)
2022-11-03 00:15:01,219:INFO: Batch: 25/31	Total Loss 5.7854 (5.8602)
2022-11-03 00:15:01,692:INFO: Batch: 26/31	Total Loss 6.0622 (5.8681)
2022-11-03 00:15:02,165:INFO: Batch: 27/31	Total Loss 5.7917 (5.8655)
2022-11-03 00:15:02,649:INFO: Batch: 28/31	Total Loss 6.4730 (5.8864)
2022-11-03 00:15:03,121:INFO: Batch: 29/31	Total Loss 5.7179 (5.8813)
2022-11-03 00:15:03,509:INFO: Batch: 30/31	Total Loss 2.5726 (5.8552)
2022-11-03 00:15:03,653:INFO: - Computing ADE (validation o)
2022-11-03 00:15:04,248:INFO: 		 ADE on eth                       dataset:	 1.1643953323364258
2022-11-03 00:15:04,248:INFO: Average validation o:	ADE  1.1644	FDE  1.8305
2022-11-03 00:15:04,249:INFO: - Computing ADE (validation)
2022-11-03 00:15:04,513:INFO: 		 ADE on hotel                     dataset:	 0.5266833305358887
2022-11-03 00:15:04,823:INFO: 		 ADE on univ                      dataset:	 0.6399636268615723
2022-11-03 00:15:05,083:INFO: 		 ADE on zara1                     dataset:	 0.6876931190490723
2022-11-03 00:15:05,434:INFO: 		 ADE on zara2                     dataset:	 0.5191322565078735
2022-11-03 00:15:05,434:INFO: Average validation:	ADE  0.5922	FDE  1.0135
2022-11-03 00:15:05,435:INFO: - Computing ADE (training)
2022-11-03 00:15:05,914:INFO: 		 ADE on hotel                     dataset:	 0.6093199253082275
2022-11-03 00:15:06,587:INFO: 		 ADE on univ                      dataset:	 0.6115918159484863
2022-11-03 00:15:07,129:INFO: 		 ADE on zara1                     dataset:	 0.7599572539329529
2022-11-03 00:15:07,891:INFO: 		 ADE on zara2                     dataset:	 0.577913224697113
2022-11-03 00:15:07,891:INFO: Average training:	ADE  0.6142	FDE  1.0692
2022-11-03 00:15:07,900:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_321.pth.tar
2022-11-03 00:15:07,900:INFO: 
===> EPOCH: 322 (P3)
2022-11-03 00:15:07,900:INFO: - Computing loss (training)
2022-11-03 00:15:08,982:INFO: Batch:  0/31	Total Loss 5.9857 (5.9857)
2022-11-03 00:15:09,454:INFO: Batch:  1/31	Total Loss 7.3377 (6.6781)
2022-11-03 00:15:09,928:INFO: Batch:  2/31	Total Loss 5.8382 (6.3926)
2022-11-03 00:15:10,401:INFO: Batch:  3/31	Total Loss 5.9053 (6.2844)
2022-11-03 00:15:10,875:INFO: Batch:  4/31	Total Loss 5.3989 (6.1163)
2022-11-03 00:15:11,348:INFO: Batch:  5/31	Total Loss 6.0592 (6.1066)
2022-11-03 00:15:11,822:INFO: Batch:  6/31	Total Loss 6.0324 (6.0952)
2022-11-03 00:15:12,291:INFO: Batch:  7/31	Total Loss 5.8605 (6.0671)
2022-11-03 00:15:12,759:INFO: Batch:  8/31	Total Loss 5.9926 (6.0590)
2022-11-03 00:15:13,228:INFO: Batch:  9/31	Total Loss 6.1065 (6.0635)
2022-11-03 00:15:13,697:INFO: Batch: 10/31	Total Loss 5.7532 (6.0368)
2022-11-03 00:15:14,168:INFO: Batch: 11/31	Total Loss 5.8955 (6.0240)
2022-11-03 00:15:14,642:INFO: Batch: 12/31	Total Loss 5.9249 (6.0164)
2022-11-03 00:15:15,113:INFO: Batch: 13/31	Total Loss 5.3198 (5.9675)
2022-11-03 00:15:15,584:INFO: Batch: 14/31	Total Loss 5.9101 (5.9634)
2022-11-03 00:15:16,055:INFO: Batch: 15/31	Total Loss 6.7314 (6.0053)
2022-11-03 00:15:16,527:INFO: Batch: 16/31	Total Loss 5.8185 (5.9926)
2022-11-03 00:15:17,041:INFO: Batch: 17/31	Total Loss 5.4753 (5.9668)
2022-11-03 00:15:17,526:INFO: Batch: 18/31	Total Loss 5.9032 (5.9631)
2022-11-03 00:15:18,001:INFO: Batch: 19/31	Total Loss 5.5426 (5.9423)
2022-11-03 00:15:18,481:INFO: Batch: 20/31	Total Loss 6.8696 (5.9851)
2022-11-03 00:15:18,954:INFO: Batch: 21/31	Total Loss 6.3321 (6.0002)
2022-11-03 00:15:19,426:INFO: Batch: 22/31	Total Loss 5.6856 (5.9889)
2022-11-03 00:15:19,902:INFO: Batch: 23/31	Total Loss 5.6734 (5.9769)
2022-11-03 00:15:20,373:INFO: Batch: 24/31	Total Loss 5.5864 (5.9596)
2022-11-03 00:15:20,846:INFO: Batch: 25/31	Total Loss 6.2505 (5.9710)
2022-11-03 00:15:21,318:INFO: Batch: 26/31	Total Loss 6.4616 (5.9870)
2022-11-03 00:15:21,791:INFO: Batch: 27/31	Total Loss 6.9978 (6.0235)
2022-11-03 00:15:22,266:INFO: Batch: 28/31	Total Loss 5.6722 (6.0135)
2022-11-03 00:15:22,742:INFO: Batch: 29/31	Total Loss 5.2210 (5.9841)
2022-11-03 00:15:23,130:INFO: Batch: 30/31	Total Loss 1.8165 (5.9427)
2022-11-03 00:15:23,280:INFO: - Computing ADE (validation o)
2022-11-03 00:15:23,884:INFO: 		 ADE on eth                       dataset:	 1.2234703302383423
2022-11-03 00:15:23,884:INFO: Average validation o:	ADE  1.2235	FDE  1.9169
2022-11-03 00:15:23,885:INFO: - Computing ADE (validation)
2022-11-03 00:15:24,163:INFO: 		 ADE on hotel                     dataset:	 0.5476912260055542
2022-11-03 00:15:24,462:INFO: 		 ADE on univ                      dataset:	 0.6696550846099854
2022-11-03 00:15:24,728:INFO: 		 ADE on zara1                     dataset:	 0.7435860633850098
2022-11-03 00:15:25,083:INFO: 		 ADE on zara2                     dataset:	 0.5721448659896851
2022-11-03 00:15:25,083:INFO: Average validation:	ADE  0.6315	FDE  1.0953
2022-11-03 00:15:25,084:INFO: - Computing ADE (training)
2022-11-03 00:15:25,562:INFO: 		 ADE on hotel                     dataset:	 0.630435049533844
2022-11-03 00:15:26,260:INFO: 		 ADE on univ                      dataset:	 0.6338357329368591
2022-11-03 00:15:26,799:INFO: 		 ADE on zara1                     dataset:	 0.8337852954864502
2022-11-03 00:15:27,541:INFO: 		 ADE on zara2                     dataset:	 0.6472830176353455
2022-11-03 00:15:27,541:INFO: Average training:	ADE  0.6492	FDE  1.1404
2022-11-03 00:15:27,550:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_322.pth.tar
2022-11-03 00:15:27,550:INFO: 
===> EPOCH: 323 (P3)
2022-11-03 00:15:27,550:INFO: - Computing loss (training)
2022-11-03 00:15:28,656:INFO: Batch:  0/31	Total Loss 5.9713 (5.9713)
2022-11-03 00:15:29,136:INFO: Batch:  1/31	Total Loss 5.3930 (5.6823)
2022-11-03 00:15:29,609:INFO: Batch:  2/31	Total Loss 5.9931 (5.7881)
2022-11-03 00:15:30,084:INFO: Batch:  3/31	Total Loss 5.9672 (5.8390)
2022-11-03 00:15:30,557:INFO: Batch:  4/31	Total Loss 5.2066 (5.7205)
2022-11-03 00:15:31,029:INFO: Batch:  5/31	Total Loss 5.6613 (5.7106)
2022-11-03 00:15:31,503:INFO: Batch:  6/31	Total Loss 5.8117 (5.7246)
2022-11-03 00:15:31,971:INFO: Batch:  7/31	Total Loss 5.2118 (5.6565)
2022-11-03 00:15:32,441:INFO: Batch:  8/31	Total Loss 6.6088 (5.7701)
2022-11-03 00:15:32,911:INFO: Batch:  9/31	Total Loss 5.9735 (5.7912)
2022-11-03 00:15:33,381:INFO: Batch: 10/31	Total Loss 5.4179 (5.7595)
2022-11-03 00:15:33,853:INFO: Batch: 11/31	Total Loss 6.4393 (5.8187)
2022-11-03 00:15:34,328:INFO: Batch: 12/31	Total Loss 5.8984 (5.8252)
2022-11-03 00:15:34,802:INFO: Batch: 13/31	Total Loss 5.5351 (5.8028)
2022-11-03 00:15:35,277:INFO: Batch: 14/31	Total Loss 5.8061 (5.8030)
2022-11-03 00:15:35,752:INFO: Batch: 15/31	Total Loss 5.6332 (5.7924)
2022-11-03 00:15:36,226:INFO: Batch: 16/31	Total Loss 5.7812 (5.7918)
2022-11-03 00:15:36,700:INFO: Batch: 17/31	Total Loss 5.3429 (5.7648)
2022-11-03 00:15:37,173:INFO: Batch: 18/31	Total Loss 5.5028 (5.7514)
2022-11-03 00:15:37,650:INFO: Batch: 19/31	Total Loss 6.3482 (5.7785)
2022-11-03 00:15:38,122:INFO: Batch: 20/31	Total Loss 6.2807 (5.8019)
2022-11-03 00:15:38,596:INFO: Batch: 21/31	Total Loss 5.9288 (5.8079)
2022-11-03 00:15:39,070:INFO: Batch: 22/31	Total Loss 6.6606 (5.8433)
2022-11-03 00:15:39,544:INFO: Batch: 23/31	Total Loss 5.5952 (5.8325)
2022-11-03 00:15:40,017:INFO: Batch: 24/31	Total Loss 5.8453 (5.8330)
2022-11-03 00:15:40,491:INFO: Batch: 25/31	Total Loss 7.2251 (5.8848)
2022-11-03 00:15:40,964:INFO: Batch: 26/31	Total Loss 6.3816 (5.9046)
2022-11-03 00:15:41,437:INFO: Batch: 27/31	Total Loss 5.2448 (5.8790)
2022-11-03 00:15:41,912:INFO: Batch: 28/31	Total Loss 5.0178 (5.8503)
2022-11-03 00:15:42,385:INFO: Batch: 29/31	Total Loss 6.2456 (5.8628)
2022-11-03 00:15:42,772:INFO: Batch: 30/31	Total Loss 2.5196 (5.8291)
2022-11-03 00:15:42,931:INFO: - Computing ADE (validation o)
2022-11-03 00:15:43,518:INFO: 		 ADE on eth                       dataset:	 1.2123303413391113
2022-11-03 00:15:43,519:INFO: Average validation o:	ADE  1.2123	FDE  1.9673
2022-11-03 00:15:43,519:INFO: - Computing ADE (validation)
2022-11-03 00:15:43,804:INFO: 		 ADE on hotel                     dataset:	 0.5789095759391785
2022-11-03 00:15:44,094:INFO: 		 ADE on univ                      dataset:	 0.689726710319519
2022-11-03 00:15:44,336:INFO: 		 ADE on zara1                     dataset:	 0.8436281085014343
2022-11-03 00:15:44,666:INFO: 		 ADE on zara2                     dataset:	 0.6100071668624878
2022-11-03 00:15:44,667:INFO: Average validation:	ADE  0.6634	FDE  1.1945
2022-11-03 00:15:44,667:INFO: - Computing ADE (training)
2022-11-03 00:15:45,162:INFO: 		 ADE on hotel                     dataset:	 0.6684108376502991
2022-11-03 00:15:45,835:INFO: 		 ADE on univ                      dataset:	 0.6706544160842896
2022-11-03 00:15:46,390:INFO: 		 ADE on zara1                     dataset:	 0.8443283438682556
2022-11-03 00:15:47,180:INFO: 		 ADE on zara2                     dataset:	 0.6632633209228516
2022-11-03 00:15:47,180:INFO: Average training:	ADE  0.6802	FDE  1.2453
2022-11-03 00:15:47,189:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_323.pth.tar
2022-11-03 00:15:47,189:INFO: 
===> EPOCH: 324 (P3)
2022-11-03 00:15:47,190:INFO: - Computing loss (training)
2022-11-03 00:15:48,293:INFO: Batch:  0/31	Total Loss 5.4065 (5.4065)
2022-11-03 00:15:48,771:INFO: Batch:  1/31	Total Loss 6.4433 (5.9099)
2022-11-03 00:15:49,251:INFO: Batch:  2/31	Total Loss 6.2712 (6.0361)
2022-11-03 00:15:49,809:INFO: Batch:  3/31	Total Loss 5.4592 (5.8917)
2022-11-03 00:15:50,286:INFO: Batch:  4/31	Total Loss 6.5699 (6.0378)
2022-11-03 00:15:50,761:INFO: Batch:  5/31	Total Loss 5.5385 (5.9564)
2022-11-03 00:15:51,235:INFO: Batch:  6/31	Total Loss 5.8456 (5.9430)
2022-11-03 00:15:51,706:INFO: Batch:  7/31	Total Loss 5.5984 (5.9006)
2022-11-03 00:15:52,182:INFO: Batch:  8/31	Total Loss 5.8215 (5.8907)
2022-11-03 00:15:52,657:INFO: Batch:  9/31	Total Loss 5.7782 (5.8786)
2022-11-03 00:15:53,134:INFO: Batch: 10/31	Total Loss 5.3316 (5.8319)
2022-11-03 00:15:53,609:INFO: Batch: 11/31	Total Loss 5.8265 (5.8314)
2022-11-03 00:15:54,088:INFO: Batch: 12/31	Total Loss 5.6968 (5.8207)
2022-11-03 00:15:54,567:INFO: Batch: 13/31	Total Loss 6.2038 (5.8469)
2022-11-03 00:15:55,045:INFO: Batch: 14/31	Total Loss 6.2540 (5.8751)
2022-11-03 00:15:55,526:INFO: Batch: 15/31	Total Loss 5.4341 (5.8468)
2022-11-03 00:15:56,005:INFO: Batch: 16/31	Total Loss 5.9977 (5.8555)
2022-11-03 00:15:56,484:INFO: Batch: 17/31	Total Loss 6.2361 (5.8725)
2022-11-03 00:15:56,963:INFO: Batch: 18/31	Total Loss 5.6082 (5.8589)
2022-11-03 00:15:57,440:INFO: Batch: 19/31	Total Loss 5.9920 (5.8650)
2022-11-03 00:15:57,919:INFO: Batch: 20/31	Total Loss 5.4621 (5.8457)
2022-11-03 00:15:58,396:INFO: Batch: 21/31	Total Loss 5.9663 (5.8515)
2022-11-03 00:15:58,875:INFO: Batch: 22/31	Total Loss 5.5313 (5.8370)
2022-11-03 00:15:59,360:INFO: Batch: 23/31	Total Loss 5.7960 (5.8356)
2022-11-03 00:15:59,838:INFO: Batch: 24/31	Total Loss 5.4108 (5.8182)
2022-11-03 00:16:00,316:INFO: Batch: 25/31	Total Loss 5.6197 (5.8110)
2022-11-03 00:16:00,793:INFO: Batch: 26/31	Total Loss 5.8073 (5.8109)
2022-11-03 00:16:01,275:INFO: Batch: 27/31	Total Loss 6.3055 (5.8301)
2022-11-03 00:16:01,754:INFO: Batch: 28/31	Total Loss 5.9613 (5.8346)
2022-11-03 00:16:02,233:INFO: Batch: 29/31	Total Loss 5.4286 (5.8200)
2022-11-03 00:16:02,624:INFO: Batch: 30/31	Total Loss 2.0661 (5.7865)
2022-11-03 00:16:02,776:INFO: - Computing ADE (validation o)
2022-11-03 00:16:03,344:INFO: 		 ADE on eth                       dataset:	 1.1958760023117065
2022-11-03 00:16:03,344:INFO: Average validation o:	ADE  1.1959	FDE  1.8651
2022-11-03 00:16:03,345:INFO: - Computing ADE (validation)
2022-11-03 00:16:03,634:INFO: 		 ADE on hotel                     dataset:	 0.532204806804657
2022-11-03 00:16:03,938:INFO: 		 ADE on univ                      dataset:	 0.6589389443397522
2022-11-03 00:16:04,192:INFO: 		 ADE on zara1                     dataset:	 0.7339990139007568
2022-11-03 00:16:04,544:INFO: 		 ADE on zara2                     dataset:	 0.5471029877662659
2022-11-03 00:16:04,544:INFO: Average validation:	ADE  0.6153	FDE  1.0534
2022-11-03 00:16:04,545:INFO: - Computing ADE (training)
2022-11-03 00:16:04,998:INFO: 		 ADE on hotel                     dataset:	 0.6173885464668274
2022-11-03 00:16:05,731:INFO: 		 ADE on univ                      dataset:	 0.6236146688461304
2022-11-03 00:16:06,258:INFO: 		 ADE on zara1                     dataset:	 0.8122326731681824
2022-11-03 00:16:06,999:INFO: 		 ADE on zara2                     dataset:	 0.6163431406021118
2022-11-03 00:16:07,000:INFO: Average training:	ADE  0.6340	FDE  1.1016
2022-11-03 00:16:07,008:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_324.pth.tar
2022-11-03 00:16:07,008:INFO: 
===> EPOCH: 325 (P3)
2022-11-03 00:16:07,009:INFO: - Computing loss (training)
2022-11-03 00:16:08,113:INFO: Batch:  0/31	Total Loss 5.7270 (5.7270)
2022-11-03 00:16:08,595:INFO: Batch:  1/31	Total Loss 6.2576 (5.9965)
2022-11-03 00:16:09,081:INFO: Batch:  2/31	Total Loss 6.6252 (6.1747)
2022-11-03 00:16:09,560:INFO: Batch:  3/31	Total Loss 5.9418 (6.1139)
2022-11-03 00:16:10,032:INFO: Batch:  4/31	Total Loss 5.9112 (6.0709)
2022-11-03 00:16:10,506:INFO: Batch:  5/31	Total Loss 5.8199 (6.0259)
2022-11-03 00:16:10,977:INFO: Batch:  6/31	Total Loss 5.3764 (5.9316)
2022-11-03 00:16:11,444:INFO: Batch:  7/31	Total Loss 5.9093 (5.9287)
2022-11-03 00:16:11,911:INFO: Batch:  8/31	Total Loss 4.8824 (5.8076)
2022-11-03 00:16:12,377:INFO: Batch:  9/31	Total Loss 5.4840 (5.7733)
2022-11-03 00:16:12,844:INFO: Batch: 10/31	Total Loss 5.0953 (5.7068)
2022-11-03 00:16:13,313:INFO: Batch: 11/31	Total Loss 5.7385 (5.7093)
2022-11-03 00:16:13,784:INFO: Batch: 12/31	Total Loss 5.2664 (5.6728)
2022-11-03 00:16:14,259:INFO: Batch: 13/31	Total Loss 5.2158 (5.6386)
2022-11-03 00:16:14,729:INFO: Batch: 14/31	Total Loss 6.3357 (5.6860)
2022-11-03 00:16:15,200:INFO: Batch: 15/31	Total Loss 5.3569 (5.6655)
2022-11-03 00:16:15,670:INFO: Batch: 16/31	Total Loss 5.7195 (5.6689)
2022-11-03 00:16:16,144:INFO: Batch: 17/31	Total Loss 5.4038 (5.6540)
2022-11-03 00:16:16,617:INFO: Batch: 18/31	Total Loss 5.5504 (5.6494)
2022-11-03 00:16:17,087:INFO: Batch: 19/31	Total Loss 5.6712 (5.6504)
2022-11-03 00:16:17,560:INFO: Batch: 20/31	Total Loss 5.1289 (5.6277)
2022-11-03 00:16:18,033:INFO: Batch: 21/31	Total Loss 5.1967 (5.6073)
2022-11-03 00:16:18,504:INFO: Batch: 22/31	Total Loss 5.2200 (5.5916)
2022-11-03 00:16:18,976:INFO: Batch: 23/31	Total Loss 5.7046 (5.5964)
2022-11-03 00:16:19,446:INFO: Batch: 24/31	Total Loss 7.2800 (5.6544)
2022-11-03 00:16:19,922:INFO: Batch: 25/31	Total Loss 5.3524 (5.6433)
2022-11-03 00:16:20,392:INFO: Batch: 26/31	Total Loss 5.6744 (5.6445)
2022-11-03 00:16:20,867:INFO: Batch: 27/31	Total Loss 5.3016 (5.6318)
2022-11-03 00:16:21,351:INFO: Batch: 28/31	Total Loss 5.6294 (5.6318)
2022-11-03 00:16:21,823:INFO: Batch: 29/31	Total Loss 6.1051 (5.6471)
2022-11-03 00:16:22,211:INFO: Batch: 30/31	Total Loss 2.0431 (5.6164)
2022-11-03 00:16:22,360:INFO: - Computing ADE (validation o)
2022-11-03 00:16:22,948:INFO: 		 ADE on eth                       dataset:	 1.2171839475631714
2022-11-03 00:16:22,948:INFO: Average validation o:	ADE  1.2172	FDE  1.9198
2022-11-03 00:16:22,949:INFO: - Computing ADE (validation)
2022-11-03 00:16:23,240:INFO: 		 ADE on hotel                     dataset:	 0.5346485376358032
2022-11-03 00:16:23,544:INFO: 		 ADE on univ                      dataset:	 0.6581211090087891
2022-11-03 00:16:23,807:INFO: 		 ADE on zara1                     dataset:	 0.7794405817985535
2022-11-03 00:16:24,150:INFO: 		 ADE on zara2                     dataset:	 0.5677675604820251
2022-11-03 00:16:24,151:INFO: Average validation:	ADE  0.6253	FDE  1.0770
2022-11-03 00:16:24,151:INFO: - Computing ADE (training)
2022-11-03 00:16:24,599:INFO: 		 ADE on hotel                     dataset:	 0.6183996200561523
2022-11-03 00:16:25,300:INFO: 		 ADE on univ                      dataset:	 0.632869303226471
2022-11-03 00:16:25,848:INFO: 		 ADE on zara1                     dataset:	 0.8365601897239685
2022-11-03 00:16:26,591:INFO: 		 ADE on zara2                     dataset:	 0.6356675028800964
2022-11-03 00:16:26,591:INFO: Average training:	ADE  0.6461	FDE  1.1324
2022-11-03 00:16:26,600:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_325.pth.tar
2022-11-03 00:16:26,600:INFO: 
===> EPOCH: 326 (P3)
2022-11-03 00:16:26,600:INFO: - Computing loss (training)
2022-11-03 00:16:27,702:INFO: Batch:  0/31	Total Loss 6.2382 (6.2382)
2022-11-03 00:16:28,178:INFO: Batch:  1/31	Total Loss 5.4832 (5.8522)
2022-11-03 00:16:28,653:INFO: Batch:  2/31	Total Loss 5.7922 (5.8304)
2022-11-03 00:16:29,139:INFO: Batch:  3/31	Total Loss 5.6256 (5.7766)
2022-11-03 00:16:29,611:INFO: Batch:  4/31	Total Loss 5.9155 (5.8059)
2022-11-03 00:16:30,088:INFO: Batch:  5/31	Total Loss 5.5990 (5.7726)
2022-11-03 00:16:30,559:INFO: Batch:  6/31	Total Loss 5.6999 (5.7629)
2022-11-03 00:16:31,033:INFO: Batch:  7/31	Total Loss 6.1203 (5.8022)
2022-11-03 00:16:31,504:INFO: Batch:  8/31	Total Loss 5.2208 (5.7403)
2022-11-03 00:16:31,980:INFO: Batch:  9/31	Total Loss 5.3294 (5.7019)
2022-11-03 00:16:32,451:INFO: Batch: 10/31	Total Loss 5.3695 (5.6695)
2022-11-03 00:16:32,926:INFO: Batch: 11/31	Total Loss 5.8234 (5.6818)
2022-11-03 00:16:33,402:INFO: Batch: 12/31	Total Loss 5.4215 (5.6636)
2022-11-03 00:16:33,878:INFO: Batch: 13/31	Total Loss 6.2388 (5.7042)
2022-11-03 00:16:34,354:INFO: Batch: 14/31	Total Loss 5.6830 (5.7029)
2022-11-03 00:16:34,831:INFO: Batch: 15/31	Total Loss 5.3401 (5.6820)
2022-11-03 00:16:35,306:INFO: Batch: 16/31	Total Loss 4.8799 (5.6318)
2022-11-03 00:16:35,780:INFO: Batch: 17/31	Total Loss 5.9096 (5.6472)
2022-11-03 00:16:36,255:INFO: Batch: 18/31	Total Loss 5.9206 (5.6613)
2022-11-03 00:16:36,730:INFO: Batch: 19/31	Total Loss 5.3978 (5.6482)
2022-11-03 00:16:37,208:INFO: Batch: 20/31	Total Loss 5.3164 (5.6317)
2022-11-03 00:16:37,683:INFO: Batch: 21/31	Total Loss 6.0007 (5.6482)
2022-11-03 00:16:38,159:INFO: Batch: 22/31	Total Loss 5.6528 (5.6484)
2022-11-03 00:16:38,631:INFO: Batch: 23/31	Total Loss 5.8302 (5.6561)
2022-11-03 00:16:39,107:INFO: Batch: 24/31	Total Loss 5.4167 (5.6480)
2022-11-03 00:16:39,583:INFO: Batch: 25/31	Total Loss 5.6355 (5.6475)
2022-11-03 00:16:40,060:INFO: Batch: 26/31	Total Loss 5.2371 (5.6322)
2022-11-03 00:16:40,537:INFO: Batch: 27/31	Total Loss 5.2448 (5.6177)
2022-11-03 00:16:41,012:INFO: Batch: 28/31	Total Loss 5.7832 (5.6235)
2022-11-03 00:16:41,489:INFO: Batch: 29/31	Total Loss 5.5597 (5.6213)
2022-11-03 00:16:41,955:INFO: Batch: 30/31	Total Loss 2.1257 (5.5807)
2022-11-03 00:16:42,105:INFO: - Computing ADE (validation o)
2022-11-03 00:16:42,674:INFO: 		 ADE on eth                       dataset:	 1.1735777854919434
2022-11-03 00:16:42,674:INFO: Average validation o:	ADE  1.1736	FDE  1.8371
2022-11-03 00:16:42,675:INFO: - Computing ADE (validation)
2022-11-03 00:16:42,936:INFO: 		 ADE on hotel                     dataset:	 0.5316094160079956
2022-11-03 00:16:43,232:INFO: 		 ADE on univ                      dataset:	 0.6565834283828735
2022-11-03 00:16:43,489:INFO: 		 ADE on zara1                     dataset:	 0.7325342893600464
2022-11-03 00:16:43,831:INFO: 		 ADE on zara2                     dataset:	 0.5346303582191467
2022-11-03 00:16:43,832:INFO: Average validation:	ADE  0.6094	FDE  1.0453
2022-11-03 00:16:43,833:INFO: - Computing ADE (training)
2022-11-03 00:16:44,291:INFO: 		 ADE on hotel                     dataset:	 0.6238358020782471
2022-11-03 00:16:44,982:INFO: 		 ADE on univ                      dataset:	 0.6208186149597168
2022-11-03 00:16:45,501:INFO: 		 ADE on zara1                     dataset:	 0.788524329662323
2022-11-03 00:16:46,235:INFO: 		 ADE on zara2                     dataset:	 0.5991526246070862
2022-11-03 00:16:46,235:INFO: Average training:	ADE  0.6272	FDE  1.0918
2022-11-03 00:16:46,244:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_326.pth.tar
2022-11-03 00:16:46,244:INFO: 
===> EPOCH: 327 (P3)
2022-11-03 00:16:46,244:INFO: - Computing loss (training)
2022-11-03 00:16:47,341:INFO: Batch:  0/31	Total Loss 5.5480 (5.5480)
2022-11-03 00:16:47,823:INFO: Batch:  1/31	Total Loss 5.1721 (5.3412)
2022-11-03 00:16:48,312:INFO: Batch:  2/31	Total Loss 5.2791 (5.3222)
2022-11-03 00:16:48,795:INFO: Batch:  3/31	Total Loss 5.5742 (5.3889)
2022-11-03 00:16:49,285:INFO: Batch:  4/31	Total Loss 4.9929 (5.3094)
2022-11-03 00:16:49,772:INFO: Batch:  5/31	Total Loss 5.7191 (5.3777)
2022-11-03 00:16:50,258:INFO: Batch:  6/31	Total Loss 5.8669 (5.4517)
2022-11-03 00:16:50,744:INFO: Batch:  7/31	Total Loss 6.2483 (5.5376)
2022-11-03 00:16:51,229:INFO: Batch:  8/31	Total Loss 5.6880 (5.5556)
2022-11-03 00:16:51,714:INFO: Batch:  9/31	Total Loss 5.5951 (5.5594)
2022-11-03 00:16:52,205:INFO: Batch: 10/31	Total Loss 5.6626 (5.5699)
2022-11-03 00:16:52,683:INFO: Batch: 11/31	Total Loss 5.7253 (5.5827)
2022-11-03 00:16:53,160:INFO: Batch: 12/31	Total Loss 6.0520 (5.6235)
2022-11-03 00:16:53,637:INFO: Batch: 13/31	Total Loss 5.8955 (5.6449)
2022-11-03 00:16:54,111:INFO: Batch: 14/31	Total Loss 4.9411 (5.5961)
2022-11-03 00:16:54,594:INFO: Batch: 15/31	Total Loss 6.4446 (5.6487)
2022-11-03 00:16:55,066:INFO: Batch: 16/31	Total Loss 5.9443 (5.6659)
2022-11-03 00:16:55,542:INFO: Batch: 17/31	Total Loss 6.5368 (5.7172)
2022-11-03 00:16:56,017:INFO: Batch: 18/31	Total Loss 5.5910 (5.7109)
2022-11-03 00:16:56,493:INFO: Batch: 19/31	Total Loss 5.0718 (5.6790)
2022-11-03 00:16:56,966:INFO: Batch: 20/31	Total Loss 5.2591 (5.6583)
2022-11-03 00:16:57,439:INFO: Batch: 21/31	Total Loss 6.4094 (5.6939)
2022-11-03 00:16:57,914:INFO: Batch: 22/31	Total Loss 5.2567 (5.6758)
2022-11-03 00:16:58,391:INFO: Batch: 23/31	Total Loss 5.5781 (5.6716)
2022-11-03 00:16:58,864:INFO: Batch: 24/31	Total Loss 6.1920 (5.6923)
2022-11-03 00:16:59,338:INFO: Batch: 25/31	Total Loss 5.6172 (5.6894)
2022-11-03 00:16:59,810:INFO: Batch: 26/31	Total Loss 7.0862 (5.7352)
2022-11-03 00:17:00,283:INFO: Batch: 27/31	Total Loss 5.3180 (5.7205)
2022-11-03 00:17:00,754:INFO: Batch: 28/31	Total Loss 5.4164 (5.7088)
2022-11-03 00:17:01,229:INFO: Batch: 29/31	Total Loss 5.3990 (5.6982)
2022-11-03 00:17:01,617:INFO: Batch: 30/31	Total Loss 2.1562 (5.6649)
2022-11-03 00:17:01,772:INFO: - Computing ADE (validation o)
2022-11-03 00:17:02,360:INFO: 		 ADE on eth                       dataset:	 1.1875429153442383
2022-11-03 00:17:02,361:INFO: Average validation o:	ADE  1.1875	FDE  1.9244
2022-11-03 00:17:02,361:INFO: - Computing ADE (validation)
2022-11-03 00:17:02,635:INFO: 		 ADE on hotel                     dataset:	 0.5460795760154724
2022-11-03 00:17:02,922:INFO: 		 ADE on univ                      dataset:	 0.6578096151351929
2022-11-03 00:17:03,162:INFO: 		 ADE on zara1                     dataset:	 0.7791867852210999
2022-11-03 00:17:03,524:INFO: 		 ADE on zara2                     dataset:	 0.5652406811714172
2022-11-03 00:17:03,525:INFO: Average validation:	ADE  0.6248	FDE  1.0994
2022-11-03 00:17:03,525:INFO: - Computing ADE (training)
2022-11-03 00:17:04,020:INFO: 		 ADE on hotel                     dataset:	 0.6297464966773987
2022-11-03 00:17:04,743:INFO: 		 ADE on univ                      dataset:	 0.6371591091156006
2022-11-03 00:17:05,302:INFO: 		 ADE on zara1                     dataset:	 0.8051408529281616
2022-11-03 00:17:06,046:INFO: 		 ADE on zara2                     dataset:	 0.6225597858428955
2022-11-03 00:17:06,046:INFO: Average training:	ADE  0.6447	FDE  1.1544
2022-11-03 00:17:06,055:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_327.pth.tar
2022-11-03 00:17:06,055:INFO: 
===> EPOCH: 328 (P3)
2022-11-03 00:17:06,055:INFO: - Computing loss (training)
2022-11-03 00:17:07,149:INFO: Batch:  0/31	Total Loss 5.6364 (5.6364)
2022-11-03 00:17:07,625:INFO: Batch:  1/31	Total Loss 6.0200 (5.8314)
2022-11-03 00:17:08,102:INFO: Batch:  2/31	Total Loss 6.4818 (6.0394)
2022-11-03 00:17:08,578:INFO: Batch:  3/31	Total Loss 5.7314 (5.9691)
2022-11-03 00:17:09,052:INFO: Batch:  4/31	Total Loss 5.8955 (5.9540)
2022-11-03 00:17:09,527:INFO: Batch:  5/31	Total Loss 5.8890 (5.9437)
2022-11-03 00:17:10,000:INFO: Batch:  6/31	Total Loss 5.0906 (5.8154)
2022-11-03 00:17:10,472:INFO: Batch:  7/31	Total Loss 5.8020 (5.8137)
2022-11-03 00:17:10,942:INFO: Batch:  8/31	Total Loss 5.9955 (5.8342)
2022-11-03 00:17:11,411:INFO: Batch:  9/31	Total Loss 5.4619 (5.7952)
2022-11-03 00:17:11,879:INFO: Batch: 10/31	Total Loss 5.5697 (5.7747)
2022-11-03 00:17:12,363:INFO: Batch: 11/31	Total Loss 6.3320 (5.8182)
2022-11-03 00:17:12,839:INFO: Batch: 12/31	Total Loss 7.1557 (5.9132)
2022-11-03 00:17:13,326:INFO: Batch: 13/31	Total Loss 5.7828 (5.9039)
2022-11-03 00:17:13,807:INFO: Batch: 14/31	Total Loss 6.1774 (5.9222)
2022-11-03 00:17:14,291:INFO: Batch: 15/31	Total Loss 5.9318 (5.9228)
2022-11-03 00:17:14,770:INFO: Batch: 16/31	Total Loss 5.8558 (5.9188)
2022-11-03 00:17:15,251:INFO: Batch: 17/31	Total Loss 5.2131 (5.8750)
2022-11-03 00:17:15,731:INFO: Batch: 18/31	Total Loss 5.5045 (5.8558)
2022-11-03 00:17:16,211:INFO: Batch: 19/31	Total Loss 5.3174 (5.8264)
2022-11-03 00:17:16,689:INFO: Batch: 20/31	Total Loss 5.2304 (5.7986)
2022-11-03 00:17:17,166:INFO: Batch: 21/31	Total Loss 5.9892 (5.8072)
2022-11-03 00:17:17,643:INFO: Batch: 22/31	Total Loss 6.0671 (5.8180)
2022-11-03 00:17:18,123:INFO: Batch: 23/31	Total Loss 5.5607 (5.8075)
2022-11-03 00:17:18,601:INFO: Batch: 24/31	Total Loss 5.8322 (5.8084)
2022-11-03 00:17:19,080:INFO: Batch: 25/31	Total Loss 5.1882 (5.7825)
2022-11-03 00:17:19,559:INFO: Batch: 26/31	Total Loss 5.7498 (5.7813)
2022-11-03 00:17:20,037:INFO: Batch: 27/31	Total Loss 5.6599 (5.7771)
2022-11-03 00:17:20,515:INFO: Batch: 28/31	Total Loss 5.5033 (5.7674)
2022-11-03 00:17:20,994:INFO: Batch: 29/31	Total Loss 5.6033 (5.7621)
2022-11-03 00:17:21,385:INFO: Batch: 30/31	Total Loss 1.9643 (5.7278)
2022-11-03 00:17:21,533:INFO: - Computing ADE (validation o)
2022-11-03 00:17:22,159:INFO: 		 ADE on eth                       dataset:	 1.151625156402588
2022-11-03 00:17:22,159:INFO: Average validation o:	ADE  1.1516	FDE  1.8263
2022-11-03 00:17:22,160:INFO: - Computing ADE (validation)
2022-11-03 00:17:22,421:INFO: 		 ADE on hotel                     dataset:	 0.5213207602500916
2022-11-03 00:17:22,719:INFO: 		 ADE on univ                      dataset:	 0.6494969129562378
2022-11-03 00:17:22,984:INFO: 		 ADE on zara1                     dataset:	 0.7042737007141113
2022-11-03 00:17:23,343:INFO: 		 ADE on zara2                     dataset:	 0.5184330344200134
2022-11-03 00:17:23,344:INFO: Average validation:	ADE  0.5976	FDE  1.0346
2022-11-03 00:17:23,344:INFO: - Computing ADE (training)
2022-11-03 00:17:23,789:INFO: 		 ADE on hotel                     dataset:	 0.6085532903671265
2022-11-03 00:17:24,447:INFO: 		 ADE on univ                      dataset:	 0.6131653785705566
2022-11-03 00:17:24,983:INFO: 		 ADE on zara1                     dataset:	 0.7561047077178955
2022-11-03 00:17:25,751:INFO: 		 ADE on zara2                     dataset:	 0.5751553773880005
2022-11-03 00:17:25,751:INFO: Average training:	ADE  0.6144	FDE  1.0793
2022-11-03 00:17:25,761:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_328.pth.tar
2022-11-03 00:17:25,761:INFO: 
===> EPOCH: 329 (P3)
2022-11-03 00:17:25,761:INFO: - Computing loss (training)
2022-11-03 00:17:26,874:INFO: Batch:  0/31	Total Loss 6.1574 (6.1574)
2022-11-03 00:17:27,364:INFO: Batch:  1/31	Total Loss 6.6675 (6.4106)
2022-11-03 00:17:27,848:INFO: Batch:  2/31	Total Loss 6.0979 (6.3027)
2022-11-03 00:17:28,326:INFO: Batch:  3/31	Total Loss 5.5599 (6.1195)
2022-11-03 00:17:28,810:INFO: Batch:  4/31	Total Loss 5.3791 (5.9597)
2022-11-03 00:17:29,300:INFO: Batch:  5/31	Total Loss 5.4401 (5.8769)
2022-11-03 00:17:29,785:INFO: Batch:  6/31	Total Loss 6.2641 (5.9297)
2022-11-03 00:17:30,266:INFO: Batch:  7/31	Total Loss 5.5780 (5.8854)
2022-11-03 00:17:30,745:INFO: Batch:  8/31	Total Loss 5.3883 (5.8384)
2022-11-03 00:17:31,225:INFO: Batch:  9/31	Total Loss 5.6053 (5.8127)
2022-11-03 00:17:31,712:INFO: Batch: 10/31	Total Loss 5.8708 (5.8184)
2022-11-03 00:17:32,193:INFO: Batch: 11/31	Total Loss 6.7862 (5.9040)
2022-11-03 00:17:32,681:INFO: Batch: 12/31	Total Loss 6.6051 (5.9576)
2022-11-03 00:17:33,167:INFO: Batch: 13/31	Total Loss 5.3697 (5.9208)
2022-11-03 00:17:33,657:INFO: Batch: 14/31	Total Loss 5.1383 (5.8756)
2022-11-03 00:17:34,143:INFO: Batch: 15/31	Total Loss 5.6770 (5.8636)
2022-11-03 00:17:34,636:INFO: Batch: 16/31	Total Loss 5.7069 (5.8539)
2022-11-03 00:17:35,124:INFO: Batch: 17/31	Total Loss 5.0525 (5.8149)
2022-11-03 00:17:35,611:INFO: Batch: 18/31	Total Loss 5.6509 (5.8048)
2022-11-03 00:17:36,093:INFO: Batch: 19/31	Total Loss 5.6205 (5.7950)
2022-11-03 00:17:36,652:INFO: Batch: 20/31	Total Loss 5.0519 (5.7574)
2022-11-03 00:17:37,135:INFO: Batch: 21/31	Total Loss 5.6226 (5.7513)
2022-11-03 00:17:37,620:INFO: Batch: 22/31	Total Loss 5.5943 (5.7446)
2022-11-03 00:17:38,104:INFO: Batch: 23/31	Total Loss 5.8391 (5.7485)
2022-11-03 00:17:38,586:INFO: Batch: 24/31	Total Loss 6.4965 (5.7783)
2022-11-03 00:17:39,068:INFO: Batch: 25/31	Total Loss 5.7105 (5.7758)
2022-11-03 00:17:39,550:INFO: Batch: 26/31	Total Loss 5.3004 (5.7579)
2022-11-03 00:17:40,033:INFO: Batch: 27/31	Total Loss 5.3727 (5.7439)
2022-11-03 00:17:40,513:INFO: Batch: 28/31	Total Loss 6.2162 (5.7601)
2022-11-03 00:17:41,004:INFO: Batch: 29/31	Total Loss 5.7815 (5.7609)
2022-11-03 00:17:41,396:INFO: Batch: 30/31	Total Loss 1.8900 (5.7251)
2022-11-03 00:17:41,541:INFO: - Computing ADE (validation o)
2022-11-03 00:17:42,120:INFO: 		 ADE on eth                       dataset:	 1.1607087850570679
2022-11-03 00:17:42,120:INFO: Average validation o:	ADE  1.1607	FDE  1.8473
2022-11-03 00:17:42,121:INFO: - Computing ADE (validation)
2022-11-03 00:17:42,390:INFO: 		 ADE on hotel                     dataset:	 0.5240933299064636
2022-11-03 00:17:42,682:INFO: 		 ADE on univ                      dataset:	 0.6298489570617676
2022-11-03 00:17:42,936:INFO: 		 ADE on zara1                     dataset:	 0.6672089695930481
2022-11-03 00:17:43,286:INFO: 		 ADE on zara2                     dataset:	 0.5290380716323853
2022-11-03 00:17:43,287:INFO: Average validation:	ADE  0.5893	FDE  1.0309
2022-11-03 00:17:43,287:INFO: - Computing ADE (training)
2022-11-03 00:17:43,750:INFO: 		 ADE on hotel                     dataset:	 0.5908746719360352
2022-11-03 00:17:44,444:INFO: 		 ADE on univ                      dataset:	 0.608432412147522
2022-11-03 00:17:44,993:INFO: 		 ADE on zara1                     dataset:	 0.7512760758399963
2022-11-03 00:17:45,728:INFO: 		 ADE on zara2                     dataset:	 0.5837419629096985
2022-11-03 00:17:45,728:INFO: Average training:	ADE  0.6121	FDE  1.0897
2022-11-03 00:17:45,745:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_329.pth.tar
2022-11-03 00:17:45,745:INFO: 
===> EPOCH: 330 (P3)
2022-11-03 00:17:45,745:INFO: - Computing loss (training)
2022-11-03 00:17:46,825:INFO: Batch:  0/31	Total Loss 6.2097 (6.2097)
2022-11-03 00:17:47,299:INFO: Batch:  1/31	Total Loss 5.1177 (5.6248)
2022-11-03 00:17:47,768:INFO: Batch:  2/31	Total Loss 6.0148 (5.7540)
2022-11-03 00:17:48,240:INFO: Batch:  3/31	Total Loss 5.7074 (5.7429)
2022-11-03 00:17:48,712:INFO: Batch:  4/31	Total Loss 5.3869 (5.6783)
2022-11-03 00:17:49,185:INFO: Batch:  5/31	Total Loss 5.5086 (5.6492)
2022-11-03 00:17:49,659:INFO: Batch:  6/31	Total Loss 6.8117 (5.8083)
2022-11-03 00:17:50,135:INFO: Batch:  7/31	Total Loss 5.5543 (5.7729)
2022-11-03 00:17:50,604:INFO: Batch:  8/31	Total Loss 5.1419 (5.6986)
2022-11-03 00:17:51,074:INFO: Batch:  9/31	Total Loss 5.8422 (5.7120)
2022-11-03 00:17:51,546:INFO: Batch: 10/31	Total Loss 6.1034 (5.7499)
2022-11-03 00:17:52,016:INFO: Batch: 11/31	Total Loss 6.7098 (5.8359)
2022-11-03 00:17:52,495:INFO: Batch: 12/31	Total Loss 5.5965 (5.8176)
2022-11-03 00:17:52,969:INFO: Batch: 13/31	Total Loss 6.2319 (5.8504)
2022-11-03 00:17:53,444:INFO: Batch: 14/31	Total Loss 5.5971 (5.8329)
2022-11-03 00:17:53,918:INFO: Batch: 15/31	Total Loss 5.6764 (5.8233)
2022-11-03 00:17:54,392:INFO: Batch: 16/31	Total Loss 5.9082 (5.8278)
2022-11-03 00:17:54,870:INFO: Batch: 17/31	Total Loss 5.4644 (5.8093)
2022-11-03 00:17:55,346:INFO: Batch: 18/31	Total Loss 5.1476 (5.7721)
2022-11-03 00:17:55,818:INFO: Batch: 19/31	Total Loss 6.5225 (5.8074)
2022-11-03 00:17:56,291:INFO: Batch: 20/31	Total Loss 5.6368 (5.7996)
2022-11-03 00:17:56,762:INFO: Batch: 21/31	Total Loss 5.6518 (5.7919)
2022-11-03 00:17:57,237:INFO: Batch: 22/31	Total Loss 5.7615 (5.7909)
2022-11-03 00:17:57,795:INFO: Batch: 23/31	Total Loss 5.1563 (5.7623)
2022-11-03 00:17:58,344:INFO: Batch: 24/31	Total Loss 4.9204 (5.7279)
2022-11-03 00:17:58,828:INFO: Batch: 25/31	Total Loss 6.0439 (5.7392)
2022-11-03 00:17:59,302:INFO: Batch: 26/31	Total Loss 5.8806 (5.7439)
2022-11-03 00:17:59,775:INFO: Batch: 27/31	Total Loss 5.8090 (5.7462)
2022-11-03 00:18:00,248:INFO: Batch: 28/31	Total Loss 5.3096 (5.7306)
2022-11-03 00:18:00,722:INFO: Batch: 29/31	Total Loss 5.2964 (5.7178)
2022-11-03 00:18:01,110:INFO: Batch: 30/31	Total Loss 2.5674 (5.6885)
2022-11-03 00:18:01,270:INFO: - Computing ADE (validation o)
2022-11-03 00:18:01,882:INFO: 		 ADE on eth                       dataset:	 1.2214312553405762
2022-11-03 00:18:01,882:INFO: Average validation o:	ADE  1.2214	FDE  1.9223
2022-11-03 00:18:01,883:INFO: - Computing ADE (validation)
2022-11-03 00:18:02,161:INFO: 		 ADE on hotel                     dataset:	 0.5611606240272522
2022-11-03 00:18:02,449:INFO: 		 ADE on univ                      dataset:	 0.6682226061820984
2022-11-03 00:18:02,714:INFO: 		 ADE on zara1                     dataset:	 0.7385355830192566
2022-11-03 00:18:03,068:INFO: 		 ADE on zara2                     dataset:	 0.575751781463623
2022-11-03 00:18:03,068:INFO: Average validation:	ADE  0.6325	FDE  1.1050
2022-11-03 00:18:03,069:INFO: - Computing ADE (training)
2022-11-03 00:18:03,536:INFO: 		 ADE on hotel                     dataset:	 0.6478429436683655
2022-11-03 00:18:04,217:INFO: 		 ADE on univ                      dataset:	 0.6370580792427063
2022-11-03 00:18:04,773:INFO: 		 ADE on zara1                     dataset:	 0.8367906808853149
2022-11-03 00:18:05,556:INFO: 		 ADE on zara2                     dataset:	 0.6470843553543091
2022-11-03 00:18:05,556:INFO: Average training:	ADE  0.6521	FDE  1.1529
2022-11-03 00:18:05,565:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_330.pth.tar
2022-11-03 00:18:05,565:INFO: 
===> EPOCH: 331 (P3)
2022-11-03 00:18:05,566:INFO: - Computing loss (training)
2022-11-03 00:18:06,655:INFO: Batch:  0/31	Total Loss 5.6661 (5.6661)
2022-11-03 00:18:07,137:INFO: Batch:  1/31	Total Loss 5.6121 (5.6386)
2022-11-03 00:18:07,616:INFO: Batch:  2/31	Total Loss 5.8455 (5.7075)
2022-11-03 00:18:08,096:INFO: Batch:  3/31	Total Loss 5.4136 (5.6282)
2022-11-03 00:18:08,572:INFO: Batch:  4/31	Total Loss 5.6278 (5.6281)
2022-11-03 00:18:09,053:INFO: Batch:  5/31	Total Loss 5.4816 (5.6040)
2022-11-03 00:18:09,527:INFO: Batch:  6/31	Total Loss 5.7326 (5.6238)
2022-11-03 00:18:10,005:INFO: Batch:  7/31	Total Loss 5.3220 (5.5886)
2022-11-03 00:18:10,478:INFO: Batch:  8/31	Total Loss 5.8257 (5.6153)
2022-11-03 00:18:10,953:INFO: Batch:  9/31	Total Loss 5.4598 (5.5980)
2022-11-03 00:18:11,425:INFO: Batch: 10/31	Total Loss 6.1676 (5.6489)
2022-11-03 00:18:11,900:INFO: Batch: 11/31	Total Loss 5.7918 (5.6626)
2022-11-03 00:18:12,378:INFO: Batch: 12/31	Total Loss 5.6595 (5.6623)
2022-11-03 00:18:12,855:INFO: Batch: 13/31	Total Loss 5.4120 (5.6430)
2022-11-03 00:18:13,333:INFO: Batch: 14/31	Total Loss 5.1081 (5.6062)
2022-11-03 00:18:13,812:INFO: Batch: 15/31	Total Loss 5.6958 (5.6111)
2022-11-03 00:18:14,293:INFO: Batch: 16/31	Total Loss 5.6650 (5.6142)
2022-11-03 00:18:14,768:INFO: Batch: 17/31	Total Loss 6.5386 (5.6592)
2022-11-03 00:18:15,248:INFO: Batch: 18/31	Total Loss 5.5078 (5.6515)
2022-11-03 00:18:15,722:INFO: Batch: 19/31	Total Loss 5.4154 (5.6403)
2022-11-03 00:18:16,198:INFO: Batch: 20/31	Total Loss 5.2093 (5.6173)
2022-11-03 00:18:16,674:INFO: Batch: 21/31	Total Loss 5.6777 (5.6196)
2022-11-03 00:18:17,155:INFO: Batch: 22/31	Total Loss 5.1277 (5.5978)
2022-11-03 00:18:17,632:INFO: Batch: 23/31	Total Loss 5.4465 (5.5922)
2022-11-03 00:18:18,114:INFO: Batch: 24/31	Total Loss 6.0248 (5.6067)
2022-11-03 00:18:18,592:INFO: Batch: 25/31	Total Loss 7.9820 (5.6932)
2022-11-03 00:18:19,073:INFO: Batch: 26/31	Total Loss 5.6439 (5.6913)
2022-11-03 00:18:19,551:INFO: Batch: 27/31	Total Loss 5.3259 (5.6782)
2022-11-03 00:18:20,031:INFO: Batch: 28/31	Total Loss 5.6117 (5.6758)
2022-11-03 00:18:20,511:INFO: Batch: 29/31	Total Loss 5.2465 (5.6591)
2022-11-03 00:18:20,899:INFO: Batch: 30/31	Total Loss 2.0239 (5.6226)
2022-11-03 00:18:21,047:INFO: - Computing ADE (validation o)
2022-11-03 00:18:21,673:INFO: 		 ADE on eth                       dataset:	 1.1872419118881226
2022-11-03 00:18:21,673:INFO: Average validation o:	ADE  1.1872	FDE  1.8634
2022-11-03 00:18:21,674:INFO: - Computing ADE (validation)
2022-11-03 00:18:21,969:INFO: 		 ADE on hotel                     dataset:	 0.5291005373001099
2022-11-03 00:18:22,252:INFO: 		 ADE on univ                      dataset:	 0.6596933603286743
2022-11-03 00:18:22,498:INFO: 		 ADE on zara1                     dataset:	 0.7421211004257202
2022-11-03 00:18:22,863:INFO: 		 ADE on zara2                     dataset:	 0.550546407699585
2022-11-03 00:18:22,863:INFO: Average validation:	ADE  0.6173	FDE  1.0672
2022-11-03 00:18:22,864:INFO: - Computing ADE (training)
2022-11-03 00:18:23,331:INFO: 		 ADE on hotel                     dataset:	 0.6178709268569946
2022-11-03 00:18:24,007:INFO: 		 ADE on univ                      dataset:	 0.624973475933075
2022-11-03 00:18:24,526:INFO: 		 ADE on zara1                     dataset:	 0.8110295534133911
2022-11-03 00:18:25,297:INFO: 		 ADE on zara2                     dataset:	 0.6176104545593262
2022-11-03 00:18:25,298:INFO: Average training:	ADE  0.6352	FDE  1.1148
2022-11-03 00:18:25,307:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_331.pth.tar
2022-11-03 00:18:25,308:INFO: 
===> EPOCH: 332 (P3)
2022-11-03 00:18:25,308:INFO: - Computing loss (training)
2022-11-03 00:18:26,411:INFO: Batch:  0/31	Total Loss 6.4615 (6.4615)
2022-11-03 00:18:26,879:INFO: Batch:  1/31	Total Loss 6.1699 (6.3127)
2022-11-03 00:18:27,350:INFO: Batch:  2/31	Total Loss 5.3720 (5.9642)
2022-11-03 00:18:27,829:INFO: Batch:  3/31	Total Loss 5.8114 (5.9313)
2022-11-03 00:18:28,294:INFO: Batch:  4/31	Total Loss 5.0529 (5.7741)
2022-11-03 00:18:28,765:INFO: Batch:  5/31	Total Loss 5.4431 (5.7175)
2022-11-03 00:18:29,313:INFO: Batch:  6/31	Total Loss 5.6999 (5.7149)
2022-11-03 00:18:29,782:INFO: Batch:  7/31	Total Loss 5.7246 (5.7162)
2022-11-03 00:18:30,249:INFO: Batch:  8/31	Total Loss 5.7474 (5.7198)
2022-11-03 00:18:30,715:INFO: Batch:  9/31	Total Loss 5.2706 (5.6748)
2022-11-03 00:18:31,185:INFO: Batch: 10/31	Total Loss 5.5777 (5.6651)
2022-11-03 00:18:31,655:INFO: Batch: 11/31	Total Loss 5.4939 (5.6506)
2022-11-03 00:18:32,125:INFO: Batch: 12/31	Total Loss 6.3734 (5.7091)
2022-11-03 00:18:32,604:INFO: Batch: 13/31	Total Loss 5.5036 (5.6957)
2022-11-03 00:18:33,077:INFO: Batch: 14/31	Total Loss 5.7358 (5.6984)
2022-11-03 00:18:33,554:INFO: Batch: 15/31	Total Loss 5.1624 (5.6662)
2022-11-03 00:18:34,024:INFO: Batch: 16/31	Total Loss 5.3489 (5.6489)
2022-11-03 00:18:34,494:INFO: Batch: 17/31	Total Loss 5.5937 (5.6457)
2022-11-03 00:18:34,965:INFO: Batch: 18/31	Total Loss 5.6272 (5.6449)
2022-11-03 00:18:35,435:INFO: Batch: 19/31	Total Loss 5.8381 (5.6543)
2022-11-03 00:18:35,906:INFO: Batch: 20/31	Total Loss 5.3662 (5.6392)
2022-11-03 00:18:36,379:INFO: Batch: 21/31	Total Loss 5.8359 (5.6482)
2022-11-03 00:18:36,851:INFO: Batch: 22/31	Total Loss 5.4021 (5.6375)
2022-11-03 00:18:37,322:INFO: Batch: 23/31	Total Loss 5.6595 (5.6384)
2022-11-03 00:18:37,795:INFO: Batch: 24/31	Total Loss 5.4525 (5.6310)
2022-11-03 00:18:38,264:INFO: Batch: 25/31	Total Loss 5.7936 (5.6370)
2022-11-03 00:18:38,734:INFO: Batch: 26/31	Total Loss 5.1651 (5.6193)
2022-11-03 00:18:39,205:INFO: Batch: 27/31	Total Loss 5.6919 (5.6222)
2022-11-03 00:18:39,674:INFO: Batch: 28/31	Total Loss 5.1762 (5.6069)
2022-11-03 00:18:40,145:INFO: Batch: 29/31	Total Loss 5.9186 (5.6166)
2022-11-03 00:18:40,532:INFO: Batch: 30/31	Total Loss 2.3301 (5.5809)
2022-11-03 00:18:40,684:INFO: - Computing ADE (validation o)
2022-11-03 00:18:41,251:INFO: 		 ADE on eth                       dataset:	 1.1890414953231812
2022-11-03 00:18:41,252:INFO: Average validation o:	ADE  1.1890	FDE  1.8976
2022-11-03 00:18:41,252:INFO: - Computing ADE (validation)
2022-11-03 00:18:41,539:INFO: 		 ADE on hotel                     dataset:	 0.5487627387046814
2022-11-03 00:18:41,831:INFO: 		 ADE on univ                      dataset:	 0.651125431060791
2022-11-03 00:18:42,082:INFO: 		 ADE on zara1                     dataset:	 0.7430133819580078
2022-11-03 00:18:42,437:INFO: 		 ADE on zara2                     dataset:	 0.5600757002830505
2022-11-03 00:18:42,437:INFO: Average validation:	ADE  0.6175	FDE  1.0850
2022-11-03 00:18:42,438:INFO: - Computing ADE (training)
2022-11-03 00:18:42,902:INFO: 		 ADE on hotel                     dataset:	 0.6321585774421692
2022-11-03 00:18:43,633:INFO: 		 ADE on univ                      dataset:	 0.6303307414054871
2022-11-03 00:18:44,172:INFO: 		 ADE on zara1                     dataset:	 0.793932318687439
2022-11-03 00:18:44,957:INFO: 		 ADE on zara2                     dataset:	 0.615395724773407
2022-11-03 00:18:44,958:INFO: Average training:	ADE  0.6378	FDE  1.1389
2022-11-03 00:18:44,967:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_332.pth.tar
2022-11-03 00:18:44,967:INFO: 
===> EPOCH: 333 (P3)
2022-11-03 00:18:44,967:INFO: - Computing loss (training)
2022-11-03 00:18:46,073:INFO: Batch:  0/31	Total Loss 5.3539 (5.3539)
2022-11-03 00:18:46,552:INFO: Batch:  1/31	Total Loss 5.4461 (5.4002)
2022-11-03 00:18:47,027:INFO: Batch:  2/31	Total Loss 5.5148 (5.4380)
2022-11-03 00:18:47,495:INFO: Batch:  3/31	Total Loss 5.6182 (5.4857)
2022-11-03 00:18:47,971:INFO: Batch:  4/31	Total Loss 5.2909 (5.4414)
2022-11-03 00:18:48,444:INFO: Batch:  5/31	Total Loss 5.1139 (5.3805)
2022-11-03 00:18:48,915:INFO: Batch:  6/31	Total Loss 5.4320 (5.3871)
2022-11-03 00:18:49,386:INFO: Batch:  7/31	Total Loss 5.5478 (5.4071)
2022-11-03 00:18:49,860:INFO: Batch:  8/31	Total Loss 5.5739 (5.4237)
2022-11-03 00:18:50,329:INFO: Batch:  9/31	Total Loss 5.0573 (5.3845)
2022-11-03 00:18:50,803:INFO: Batch: 10/31	Total Loss 5.5277 (5.3961)
2022-11-03 00:18:51,272:INFO: Batch: 11/31	Total Loss 6.5896 (5.4925)
2022-11-03 00:18:51,748:INFO: Batch: 12/31	Total Loss 5.7306 (5.5099)
2022-11-03 00:18:52,224:INFO: Batch: 13/31	Total Loss 5.1400 (5.4834)
2022-11-03 00:18:52,702:INFO: Batch: 14/31	Total Loss 7.0736 (5.5898)
2022-11-03 00:18:53,178:INFO: Batch: 15/31	Total Loss 6.8221 (5.6638)
2022-11-03 00:18:53,654:INFO: Batch: 16/31	Total Loss 5.3824 (5.6460)
2022-11-03 00:18:54,131:INFO: Batch: 17/31	Total Loss 5.4768 (5.6367)
2022-11-03 00:18:54,608:INFO: Batch: 18/31	Total Loss 6.3919 (5.6759)
2022-11-03 00:18:55,086:INFO: Batch: 19/31	Total Loss 5.6559 (5.6748)
2022-11-03 00:18:55,562:INFO: Batch: 20/31	Total Loss 5.5201 (5.6673)
2022-11-03 00:18:56,039:INFO: Batch: 21/31	Total Loss 6.0557 (5.6830)
2022-11-03 00:18:56,514:INFO: Batch: 22/31	Total Loss 6.3221 (5.7091)
2022-11-03 00:18:56,991:INFO: Batch: 23/31	Total Loss 5.4672 (5.6983)
2022-11-03 00:18:57,468:INFO: Batch: 24/31	Total Loss 5.3920 (5.6860)
2022-11-03 00:18:57,944:INFO: Batch: 25/31	Total Loss 5.4658 (5.6775)
2022-11-03 00:18:58,420:INFO: Batch: 26/31	Total Loss 5.1786 (5.6574)
2022-11-03 00:18:58,897:INFO: Batch: 27/31	Total Loss 5.4750 (5.6506)
2022-11-03 00:18:59,373:INFO: Batch: 28/31	Total Loss 5.5565 (5.6473)
2022-11-03 00:18:59,849:INFO: Batch: 29/31	Total Loss 5.5671 (5.6448)
2022-11-03 00:19:00,241:INFO: Batch: 30/31	Total Loss 2.1040 (5.6175)
2022-11-03 00:19:00,400:INFO: - Computing ADE (validation o)
2022-11-03 00:19:00,993:INFO: 		 ADE on eth                       dataset:	 1.233378291130066
2022-11-03 00:19:00,994:INFO: Average validation o:	ADE  1.2334	FDE  1.9920
2022-11-03 00:19:00,994:INFO: - Computing ADE (validation)
2022-11-03 00:19:01,264:INFO: 		 ADE on hotel                     dataset:	 0.6168192028999329
2022-11-03 00:19:01,568:INFO: 		 ADE on univ                      dataset:	 0.67221599817276
2022-11-03 00:19:01,846:INFO: 		 ADE on zara1                     dataset:	 0.6700947880744934
2022-11-03 00:19:02,190:INFO: 		 ADE on zara2                     dataset:	 0.612213671207428
2022-11-03 00:19:02,191:INFO: Average validation:	ADE  0.6470	FDE  1.1973
2022-11-03 00:19:02,191:INFO: - Computing ADE (training)
2022-11-03 00:19:02,658:INFO: 		 ADE on hotel                     dataset:	 0.6775718927383423
2022-11-03 00:19:03,366:INFO: 		 ADE on univ                      dataset:	 0.6551377177238464
2022-11-03 00:19:03,956:INFO: 		 ADE on zara1                     dataset:	 0.8168988823890686
2022-11-03 00:19:04,718:INFO: 		 ADE on zara2                     dataset:	 0.6750072836875916
2022-11-03 00:19:04,718:INFO: Average training:	ADE  0.6701	FDE  1.2492
2022-11-03 00:19:04,727:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_333.pth.tar
2022-11-03 00:19:04,727:INFO: 
===> EPOCH: 334 (P3)
2022-11-03 00:19:04,727:INFO: - Computing loss (training)
2022-11-03 00:19:05,838:INFO: Batch:  0/31	Total Loss 5.9885 (5.9885)
2022-11-03 00:19:06,314:INFO: Batch:  1/31	Total Loss 5.8074 (5.9020)
2022-11-03 00:19:06,794:INFO: Batch:  2/31	Total Loss 5.1574 (5.6415)
2022-11-03 00:19:07,269:INFO: Batch:  3/31	Total Loss 5.4833 (5.5994)
2022-11-03 00:19:07,747:INFO: Batch:  4/31	Total Loss 5.1604 (5.5099)
2022-11-03 00:19:08,225:INFO: Batch:  5/31	Total Loss 5.6070 (5.5260)
2022-11-03 00:19:08,698:INFO: Batch:  6/31	Total Loss 6.7018 (5.6791)
2022-11-03 00:19:09,170:INFO: Batch:  7/31	Total Loss 5.4699 (5.6516)
2022-11-03 00:19:09,644:INFO: Batch:  8/31	Total Loss 5.7964 (5.6673)
2022-11-03 00:19:10,122:INFO: Batch:  9/31	Total Loss 5.7470 (5.6747)
2022-11-03 00:19:10,594:INFO: Batch: 10/31	Total Loss 5.3757 (5.6454)
2022-11-03 00:19:11,072:INFO: Batch: 11/31	Total Loss 5.3967 (5.6236)
2022-11-03 00:19:11,550:INFO: Batch: 12/31	Total Loss 5.8944 (5.6462)
2022-11-03 00:19:12,027:INFO: Batch: 13/31	Total Loss 5.5629 (5.6409)
2022-11-03 00:19:12,503:INFO: Batch: 14/31	Total Loss 5.1341 (5.6065)
2022-11-03 00:19:12,979:INFO: Batch: 15/31	Total Loss 5.5120 (5.6007)
2022-11-03 00:19:13,457:INFO: Batch: 16/31	Total Loss 5.5801 (5.5992)
2022-11-03 00:19:13,933:INFO: Batch: 17/31	Total Loss 6.0295 (5.6275)
2022-11-03 00:19:14,412:INFO: Batch: 18/31	Total Loss 6.5492 (5.6809)
2022-11-03 00:19:14,888:INFO: Batch: 19/31	Total Loss 5.5665 (5.6755)
2022-11-03 00:19:15,365:INFO: Batch: 20/31	Total Loss 5.2546 (5.6559)
2022-11-03 00:19:15,841:INFO: Batch: 21/31	Total Loss 5.7571 (5.6605)
2022-11-03 00:19:16,315:INFO: Batch: 22/31	Total Loss 5.2238 (5.6424)
2022-11-03 00:19:16,790:INFO: Batch: 23/31	Total Loss 5.2499 (5.6245)
2022-11-03 00:19:17,266:INFO: Batch: 24/31	Total Loss 4.7400 (5.5928)
2022-11-03 00:19:17,739:INFO: Batch: 25/31	Total Loss 5.0489 (5.5700)
2022-11-03 00:19:18,219:INFO: Batch: 26/31	Total Loss 6.0725 (5.5884)
2022-11-03 00:19:18,696:INFO: Batch: 27/31	Total Loss 5.2716 (5.5773)
2022-11-03 00:19:19,174:INFO: Batch: 28/31	Total Loss 5.4669 (5.5739)
2022-11-03 00:19:19,660:INFO: Batch: 29/31	Total Loss 6.0918 (5.5914)
2022-11-03 00:19:20,051:INFO: Batch: 30/31	Total Loss 2.0651 (5.5503)
2022-11-03 00:19:20,206:INFO: - Computing ADE (validation o)
2022-11-03 00:19:20,896:INFO: 		 ADE on eth                       dataset:	 1.1960060596466064
2022-11-03 00:19:20,896:INFO: Average validation o:	ADE  1.1960	FDE  1.9759
2022-11-03 00:19:20,897:INFO: - Computing ADE (validation)
2022-11-03 00:19:21,175:INFO: 		 ADE on hotel                     dataset:	 0.5919575691223145
2022-11-03 00:19:21,472:INFO: 		 ADE on univ                      dataset:	 0.6821040511131287
2022-11-03 00:19:21,717:INFO: 		 ADE on zara1                     dataset:	 0.8044236302375793
2022-11-03 00:19:22,072:INFO: 		 ADE on zara2                     dataset:	 0.616656482219696
2022-11-03 00:19:22,072:INFO: Average validation:	ADE  0.6603	FDE  1.2266
2022-11-03 00:19:22,073:INFO: - Computing ADE (training)
2022-11-03 00:19:22,514:INFO: 		 ADE on hotel                     dataset:	 0.6710538864135742
2022-11-03 00:19:23,215:INFO: 		 ADE on univ                      dataset:	 0.6730033159255981
2022-11-03 00:19:23,738:INFO: 		 ADE on zara1                     dataset:	 0.8149330615997314
2022-11-03 00:19:24,522:INFO: 		 ADE on zara2                     dataset:	 0.6586775779724121
2022-11-03 00:19:24,522:INFO: Average training:	ADE  0.6791	FDE  1.2828
2022-11-03 00:19:24,530:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_334.pth.tar
2022-11-03 00:19:24,530:INFO: 
===> EPOCH: 335 (P3)
2022-11-03 00:19:24,531:INFO: - Computing loss (training)
2022-11-03 00:19:25,629:INFO: Batch:  0/31	Total Loss 4.7616 (4.7616)
2022-11-03 00:19:26,102:INFO: Batch:  1/31	Total Loss 6.3453 (5.5530)
2022-11-03 00:19:26,575:INFO: Batch:  2/31	Total Loss 6.4376 (5.8585)
2022-11-03 00:19:27,045:INFO: Batch:  3/31	Total Loss 5.4159 (5.7337)
2022-11-03 00:19:27,515:INFO: Batch:  4/31	Total Loss 5.6327 (5.7153)
2022-11-03 00:19:27,985:INFO: Batch:  5/31	Total Loss 6.7215 (5.8643)
2022-11-03 00:19:28,453:INFO: Batch:  6/31	Total Loss 5.5504 (5.8195)
2022-11-03 00:19:28,920:INFO: Batch:  7/31	Total Loss 5.8376 (5.8219)
2022-11-03 00:19:29,390:INFO: Batch:  8/31	Total Loss 5.5865 (5.7937)
2022-11-03 00:19:29,858:INFO: Batch:  9/31	Total Loss 5.6632 (5.7803)
2022-11-03 00:19:30,327:INFO: Batch: 10/31	Total Loss 5.0880 (5.7135)
2022-11-03 00:19:30,797:INFO: Batch: 11/31	Total Loss 5.3605 (5.6857)
2022-11-03 00:19:31,269:INFO: Batch: 12/31	Total Loss 5.2439 (5.6535)
2022-11-03 00:19:31,743:INFO: Batch: 13/31	Total Loss 5.7282 (5.6596)
2022-11-03 00:19:32,215:INFO: Batch: 14/31	Total Loss 5.1567 (5.6252)
2022-11-03 00:19:32,693:INFO: Batch: 15/31	Total Loss 6.0964 (5.6536)
2022-11-03 00:19:33,166:INFO: Batch: 16/31	Total Loss 6.4362 (5.6989)
2022-11-03 00:19:33,645:INFO: Batch: 17/31	Total Loss 4.8431 (5.6506)
2022-11-03 00:19:34,123:INFO: Batch: 18/31	Total Loss 5.1184 (5.6211)
2022-11-03 00:19:34,599:INFO: Batch: 19/31	Total Loss 5.5373 (5.6168)
2022-11-03 00:19:35,077:INFO: Batch: 20/31	Total Loss 5.8916 (5.6301)
2022-11-03 00:19:35,559:INFO: Batch: 21/31	Total Loss 5.6490 (5.6309)
2022-11-03 00:19:36,035:INFO: Batch: 22/31	Total Loss 4.9736 (5.6036)
2022-11-03 00:19:36,513:INFO: Batch: 23/31	Total Loss 5.7422 (5.6102)
2022-11-03 00:19:36,990:INFO: Batch: 24/31	Total Loss 5.2626 (5.5972)
2022-11-03 00:19:37,472:INFO: Batch: 25/31	Total Loss 5.1681 (5.5795)
2022-11-03 00:19:37,949:INFO: Batch: 26/31	Total Loss 5.2391 (5.5659)
2022-11-03 00:19:38,426:INFO: Batch: 27/31	Total Loss 5.2305 (5.5535)
2022-11-03 00:19:38,901:INFO: Batch: 28/31	Total Loss 6.7358 (5.5962)
2022-11-03 00:19:39,377:INFO: Batch: 29/31	Total Loss 5.5990 (5.5963)
2022-11-03 00:19:39,766:INFO: Batch: 30/31	Total Loss 2.1088 (5.5640)
2022-11-03 00:19:39,918:INFO: - Computing ADE (validation o)
2022-11-03 00:19:40,501:INFO: 		 ADE on eth                       dataset:	 1.1697660684585571
2022-11-03 00:19:40,501:INFO: Average validation o:	ADE  1.1698	FDE  1.8290
2022-11-03 00:19:40,502:INFO: - Computing ADE (validation)
2022-11-03 00:19:40,777:INFO: 		 ADE on hotel                     dataset:	 0.5515165328979492
2022-11-03 00:19:41,083:INFO: 		 ADE on univ                      dataset:	 0.6520177125930786
2022-11-03 00:19:41,353:INFO: 		 ADE on zara1                     dataset:	 0.6693733930587769
2022-11-03 00:19:41,699:INFO: 		 ADE on zara2                     dataset:	 0.5360788106918335
2022-11-03 00:19:41,700:INFO: Average validation:	ADE  0.6050	FDE  1.0666
2022-11-03 00:19:41,700:INFO: - Computing ADE (training)
2022-11-03 00:19:42,144:INFO: 		 ADE on hotel                     dataset:	 0.635258138179779
2022-11-03 00:19:42,828:INFO: 		 ADE on univ                      dataset:	 0.6172635555267334
2022-11-03 00:19:43,394:INFO: 		 ADE on zara1                     dataset:	 0.7696840763092041
2022-11-03 00:19:44,176:INFO: 		 ADE on zara2                     dataset:	 0.5985189080238342
2022-11-03 00:19:44,177:INFO: Average training:	ADE  0.6236	FDE  1.1096
2022-11-03 00:19:44,185:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_335.pth.tar
2022-11-03 00:19:44,185:INFO: 
===> EPOCH: 336 (P3)
2022-11-03 00:19:44,186:INFO: - Computing loss (training)
2022-11-03 00:19:45,267:INFO: Batch:  0/31	Total Loss 5.4146 (5.4146)
2022-11-03 00:19:45,741:INFO: Batch:  1/31	Total Loss 5.7510 (5.5852)
2022-11-03 00:19:46,216:INFO: Batch:  2/31	Total Loss 5.3555 (5.5084)
2022-11-03 00:19:46,694:INFO: Batch:  3/31	Total Loss 5.9135 (5.6089)
2022-11-03 00:19:47,163:INFO: Batch:  4/31	Total Loss 5.2110 (5.5273)
2022-11-03 00:19:47,635:INFO: Batch:  5/31	Total Loss 6.2546 (5.6378)
2022-11-03 00:19:48,108:INFO: Batch:  6/31	Total Loss 5.4418 (5.6063)
2022-11-03 00:19:48,580:INFO: Batch:  7/31	Total Loss 5.1521 (5.5476)
2022-11-03 00:19:49,051:INFO: Batch:  8/31	Total Loss 5.4177 (5.5323)
2022-11-03 00:19:49,527:INFO: Batch:  9/31	Total Loss 5.1725 (5.4955)
2022-11-03 00:19:50,000:INFO: Batch: 10/31	Total Loss 6.6528 (5.6054)
2022-11-03 00:19:50,473:INFO: Batch: 11/31	Total Loss 5.7849 (5.6210)
2022-11-03 00:19:50,949:INFO: Batch: 12/31	Total Loss 5.3087 (5.5955)
2022-11-03 00:19:51,426:INFO: Batch: 13/31	Total Loss 5.5290 (5.5907)
2022-11-03 00:19:51,903:INFO: Batch: 14/31	Total Loss 5.4908 (5.5842)
2022-11-03 00:19:52,383:INFO: Batch: 15/31	Total Loss 5.6485 (5.5885)
2022-11-03 00:19:52,859:INFO: Batch: 16/31	Total Loss 5.4357 (5.5803)
2022-11-03 00:19:53,335:INFO: Batch: 17/31	Total Loss 6.0647 (5.6106)
2022-11-03 00:19:53,809:INFO: Batch: 18/31	Total Loss 5.2497 (5.5913)
2022-11-03 00:19:54,286:INFO: Batch: 19/31	Total Loss 5.4945 (5.5864)
2022-11-03 00:19:54,761:INFO: Batch: 20/31	Total Loss 5.3364 (5.5757)
2022-11-03 00:19:55,235:INFO: Batch: 21/31	Total Loss 5.6672 (5.5793)
2022-11-03 00:19:55,709:INFO: Batch: 22/31	Total Loss 5.3688 (5.5705)
2022-11-03 00:19:56,184:INFO: Batch: 23/31	Total Loss 5.5960 (5.5715)
2022-11-03 00:19:56,658:INFO: Batch: 24/31	Total Loss 5.2655 (5.5589)
2022-11-03 00:19:57,133:INFO: Batch: 25/31	Total Loss 5.0745 (5.5394)
2022-11-03 00:19:57,607:INFO: Batch: 26/31	Total Loss 5.5792 (5.5410)
2022-11-03 00:19:58,079:INFO: Batch: 27/31	Total Loss 5.4240 (5.5369)
2022-11-03 00:19:58,553:INFO: Batch: 28/31	Total Loss 5.0195 (5.5192)
2022-11-03 00:19:59,026:INFO: Batch: 29/31	Total Loss 5.5394 (5.5200)
2022-11-03 00:19:59,414:INFO: Batch: 30/31	Total Loss 2.4431 (5.4825)
2022-11-03 00:19:59,558:INFO: - Computing ADE (validation o)
2022-11-03 00:20:00,140:INFO: 		 ADE on eth                       dataset:	 1.198754906654358
2022-11-03 00:20:00,140:INFO: Average validation o:	ADE  1.1988	FDE  1.9050
2022-11-03 00:20:00,141:INFO: - Computing ADE (validation)
2022-11-03 00:20:00,403:INFO: 		 ADE on hotel                     dataset:	 0.5323288440704346
2022-11-03 00:20:00,702:INFO: 		 ADE on univ                      dataset:	 0.6561595797538757
2022-11-03 00:20:00,951:INFO: 		 ADE on zara1                     dataset:	 0.766624927520752
2022-11-03 00:20:01,305:INFO: 		 ADE on zara2                     dataset:	 0.5634263157844543
2022-11-03 00:20:01,305:INFO: Average validation:	ADE  0.6218	FDE  1.0894
2022-11-03 00:20:01,306:INFO: - Computing ADE (training)
2022-11-03 00:20:01,776:INFO: 		 ADE on hotel                     dataset:	 0.6205945611000061
2022-11-03 00:20:02,486:INFO: 		 ADE on univ                      dataset:	 0.6307218670845032
2022-11-03 00:20:03,019:INFO: 		 ADE on zara1                     dataset:	 0.8249843120574951
2022-11-03 00:20:03,759:INFO: 		 ADE on zara2                     dataset:	 0.6269240379333496
2022-11-03 00:20:03,759:INFO: Average training:	ADE  0.6421	FDE  1.1423
2022-11-03 00:20:03,768:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_336.pth.tar
2022-11-03 00:20:03,768:INFO: 
===> EPOCH: 337 (P3)
2022-11-03 00:20:03,768:INFO: - Computing loss (training)
2022-11-03 00:20:04,879:INFO: Batch:  0/31	Total Loss 6.7587 (6.7587)
2022-11-03 00:20:05,364:INFO: Batch:  1/31	Total Loss 6.4517 (6.6013)
2022-11-03 00:20:05,838:INFO: Batch:  2/31	Total Loss 5.2486 (6.1522)
2022-11-03 00:20:06,314:INFO: Batch:  3/31	Total Loss 4.8633 (5.8350)
2022-11-03 00:20:06,787:INFO: Batch:  4/31	Total Loss 5.0271 (5.6762)
2022-11-03 00:20:07,263:INFO: Batch:  5/31	Total Loss 6.2281 (5.7674)
2022-11-03 00:20:07,738:INFO: Batch:  6/31	Total Loss 6.3946 (5.8624)
2022-11-03 00:20:08,210:INFO: Batch:  7/31	Total Loss 5.0054 (5.7626)
2022-11-03 00:20:08,680:INFO: Batch:  8/31	Total Loss 5.4824 (5.7321)
2022-11-03 00:20:09,150:INFO: Batch:  9/31	Total Loss 5.4105 (5.6980)
2022-11-03 00:20:09,621:INFO: Batch: 10/31	Total Loss 4.8957 (5.6221)
2022-11-03 00:20:10,097:INFO: Batch: 11/31	Total Loss 6.0314 (5.6524)
2022-11-03 00:20:10,574:INFO: Batch: 12/31	Total Loss 5.5204 (5.6408)
2022-11-03 00:20:11,052:INFO: Batch: 13/31	Total Loss 6.1319 (5.6778)
2022-11-03 00:20:11,528:INFO: Batch: 14/31	Total Loss 5.5345 (5.6684)
2022-11-03 00:20:12,083:INFO: Batch: 15/31	Total Loss 5.8823 (5.6815)
2022-11-03 00:20:12,558:INFO: Batch: 16/31	Total Loss 5.4373 (5.6667)
2022-11-03 00:20:13,033:INFO: Batch: 17/31	Total Loss 5.7860 (5.6734)
2022-11-03 00:20:13,509:INFO: Batch: 18/31	Total Loss 6.1410 (5.6948)
2022-11-03 00:20:13,984:INFO: Batch: 19/31	Total Loss 5.9481 (5.7080)
2022-11-03 00:20:14,460:INFO: Batch: 20/31	Total Loss 5.8020 (5.7120)
2022-11-03 00:20:14,935:INFO: Batch: 21/31	Total Loss 5.3861 (5.6976)
2022-11-03 00:20:15,411:INFO: Batch: 22/31	Total Loss 5.7337 (5.6991)
2022-11-03 00:20:15,885:INFO: Batch: 23/31	Total Loss 5.1668 (5.6732)
2022-11-03 00:20:16,358:INFO: Batch: 24/31	Total Loss 5.3743 (5.6604)
2022-11-03 00:20:16,832:INFO: Batch: 25/31	Total Loss 5.3334 (5.6483)
2022-11-03 00:20:17,306:INFO: Batch: 26/31	Total Loss 5.6279 (5.6475)
2022-11-03 00:20:17,777:INFO: Batch: 27/31	Total Loss 5.8492 (5.6548)
2022-11-03 00:20:18,251:INFO: Batch: 28/31	Total Loss 5.4390 (5.6463)
2022-11-03 00:20:18,725:INFO: Batch: 29/31	Total Loss 5.1537 (5.6313)
2022-11-03 00:20:19,114:INFO: Batch: 30/31	Total Loss 1.9308 (5.5961)
2022-11-03 00:20:19,268:INFO: - Computing ADE (validation o)
2022-11-03 00:20:19,912:INFO: 		 ADE on eth                       dataset:	 1.240922212600708
2022-11-03 00:20:19,913:INFO: Average validation o:	ADE  1.2409	FDE  1.9592
2022-11-03 00:20:19,913:INFO: - Computing ADE (validation)
2022-11-03 00:20:20,185:INFO: 		 ADE on hotel                     dataset:	 0.5680980086326599
2022-11-03 00:20:20,488:INFO: 		 ADE on univ                      dataset:	 0.6703540086746216
2022-11-03 00:20:20,727:INFO: 		 ADE on zara1                     dataset:	 0.7228858470916748
2022-11-03 00:20:21,100:INFO: 		 ADE on zara2                     dataset:	 0.5884410738945007
2022-11-03 00:20:21,100:INFO: Average validation:	ADE  0.6378	FDE  1.1353
2022-11-03 00:20:21,101:INFO: - Computing ADE (training)
2022-11-03 00:20:21,554:INFO: 		 ADE on hotel                     dataset:	 0.6470671892166138
2022-11-03 00:20:22,228:INFO: 		 ADE on univ                      dataset:	 0.6396774649620056
2022-11-03 00:20:22,787:INFO: 		 ADE on zara1                     dataset:	 0.8502432107925415
2022-11-03 00:20:23,560:INFO: 		 ADE on zara2                     dataset:	 0.6637989282608032
2022-11-03 00:20:23,560:INFO: Average training:	ADE  0.6582	FDE  1.1839
2022-11-03 00:20:23,569:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_337.pth.tar
2022-11-03 00:20:23,569:INFO: 
===> EPOCH: 338 (P3)
2022-11-03 00:20:23,569:INFO: - Computing loss (training)
2022-11-03 00:20:24,665:INFO: Batch:  0/31	Total Loss 5.6432 (5.6432)
2022-11-03 00:20:25,140:INFO: Batch:  1/31	Total Loss 6.7431 (6.2046)
2022-11-03 00:20:25,614:INFO: Batch:  2/31	Total Loss 7.4988 (6.6326)
2022-11-03 00:20:26,088:INFO: Batch:  3/31	Total Loss 5.5232 (6.3810)
2022-11-03 00:20:26,559:INFO: Batch:  4/31	Total Loss 6.0834 (6.3239)
2022-11-03 00:20:27,033:INFO: Batch:  5/31	Total Loss 6.2929 (6.3183)
2022-11-03 00:20:27,504:INFO: Batch:  6/31	Total Loss 5.7996 (6.2442)
2022-11-03 00:20:27,973:INFO: Batch:  7/31	Total Loss 5.6647 (6.1708)
2022-11-03 00:20:28,444:INFO: Batch:  8/31	Total Loss 5.7788 (6.1315)
2022-11-03 00:20:28,914:INFO: Batch:  9/31	Total Loss 5.1470 (6.0339)
2022-11-03 00:20:29,383:INFO: Batch: 10/31	Total Loss 5.3037 (5.9636)
2022-11-03 00:20:29,858:INFO: Batch: 11/31	Total Loss 5.5326 (5.9278)
2022-11-03 00:20:30,331:INFO: Batch: 12/31	Total Loss 6.2061 (5.9507)
2022-11-03 00:20:30,810:INFO: Batch: 13/31	Total Loss 6.3440 (5.9792)
2022-11-03 00:20:31,284:INFO: Batch: 14/31	Total Loss 5.4294 (5.9419)
2022-11-03 00:20:31,758:INFO: Batch: 15/31	Total Loss 5.3887 (5.9098)
2022-11-03 00:20:32,231:INFO: Batch: 16/31	Total Loss 5.8161 (5.9038)
2022-11-03 00:20:32,708:INFO: Batch: 17/31	Total Loss 5.9193 (5.9046)
2022-11-03 00:20:33,184:INFO: Batch: 18/31	Total Loss 5.4859 (5.8835)
2022-11-03 00:20:33,660:INFO: Batch: 19/31	Total Loss 5.6817 (5.8732)
2022-11-03 00:20:34,135:INFO: Batch: 20/31	Total Loss 5.4005 (5.8503)
2022-11-03 00:20:34,608:INFO: Batch: 21/31	Total Loss 5.5392 (5.8351)
2022-11-03 00:20:35,084:INFO: Batch: 22/31	Total Loss 5.5051 (5.8213)
2022-11-03 00:20:35,558:INFO: Batch: 23/31	Total Loss 5.3731 (5.8020)
2022-11-03 00:20:36,032:INFO: Batch: 24/31	Total Loss 5.1490 (5.7743)
2022-11-03 00:20:36,507:INFO: Batch: 25/31	Total Loss 5.6897 (5.7711)
2022-11-03 00:20:36,980:INFO: Batch: 26/31	Total Loss 5.0012 (5.7420)
2022-11-03 00:20:37,457:INFO: Batch: 27/31	Total Loss 6.0393 (5.7514)
2022-11-03 00:20:37,931:INFO: Batch: 28/31	Total Loss 5.9054 (5.7568)
2022-11-03 00:20:38,406:INFO: Batch: 29/31	Total Loss 5.4780 (5.7464)
2022-11-03 00:20:38,796:INFO: Batch: 30/31	Total Loss 2.0202 (5.7119)
2022-11-03 00:20:38,940:INFO: - Computing ADE (validation o)
2022-11-03 00:20:39,567:INFO: 		 ADE on eth                       dataset:	 1.165567398071289
2022-11-03 00:20:39,567:INFO: Average validation o:	ADE  1.1656	FDE  1.8910
2022-11-03 00:20:39,568:INFO: - Computing ADE (validation)
2022-11-03 00:20:39,828:INFO: 		 ADE on hotel                     dataset:	 0.5525811910629272
2022-11-03 00:20:40,118:INFO: 		 ADE on univ                      dataset:	 0.6533652544021606
2022-11-03 00:20:40,360:INFO: 		 ADE on zara1                     dataset:	 0.7463364005088806
2022-11-03 00:20:40,722:INFO: 		 ADE on zara2                     dataset:	 0.5619601011276245
2022-11-03 00:20:40,722:INFO: Average validation:	ADE  0.6197	FDE  1.1179
2022-11-03 00:20:40,723:INFO: - Computing ADE (training)
2022-11-03 00:20:41,165:INFO: 		 ADE on hotel                     dataset:	 0.6335276365280151
2022-11-03 00:20:41,859:INFO: 		 ADE on univ                      dataset:	 0.6346439123153687
2022-11-03 00:20:42,382:INFO: 		 ADE on zara1                     dataset:	 0.7764602899551392
2022-11-03 00:20:43,119:INFO: 		 ADE on zara2                     dataset:	 0.6097429394721985
2022-11-03 00:20:43,119:INFO: Average training:	ADE  0.6386	FDE  1.1701
2022-11-03 00:20:43,127:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_338.pth.tar
2022-11-03 00:20:43,127:INFO: 
===> EPOCH: 339 (P3)
2022-11-03 00:20:43,128:INFO: - Computing loss (training)
2022-11-03 00:20:44,242:INFO: Batch:  0/31	Total Loss 5.5239 (5.5239)
2022-11-03 00:20:44,729:INFO: Batch:  1/31	Total Loss 4.6439 (5.0965)
2022-11-03 00:20:45,212:INFO: Batch:  2/31	Total Loss 5.5501 (5.2338)
2022-11-03 00:20:45,690:INFO: Batch:  3/31	Total Loss 5.5988 (5.3241)
2022-11-03 00:20:46,170:INFO: Batch:  4/31	Total Loss 6.5356 (5.5692)
2022-11-03 00:20:46,651:INFO: Batch:  5/31	Total Loss 5.3379 (5.5276)
2022-11-03 00:20:47,131:INFO: Batch:  6/31	Total Loss 5.6301 (5.5428)
2022-11-03 00:20:47,609:INFO: Batch:  7/31	Total Loss 5.3561 (5.5195)
2022-11-03 00:20:48,091:INFO: Batch:  8/31	Total Loss 4.9626 (5.4563)
2022-11-03 00:20:48,568:INFO: Batch:  9/31	Total Loss 5.3976 (5.4503)
2022-11-03 00:20:49,046:INFO: Batch: 10/31	Total Loss 5.6188 (5.4667)
2022-11-03 00:20:49,527:INFO: Batch: 11/31	Total Loss 5.4573 (5.4659)
2022-11-03 00:20:50,011:INFO: Batch: 12/31	Total Loss 5.6657 (5.4818)
2022-11-03 00:20:50,495:INFO: Batch: 13/31	Total Loss 5.4090 (5.4768)
2022-11-03 00:20:50,977:INFO: Batch: 14/31	Total Loss 5.0884 (5.4535)
2022-11-03 00:20:51,461:INFO: Batch: 15/31	Total Loss 5.1692 (5.4348)
2022-11-03 00:20:51,943:INFO: Batch: 16/31	Total Loss 5.8137 (5.4568)
2022-11-03 00:20:52,428:INFO: Batch: 17/31	Total Loss 5.9210 (5.4825)
2022-11-03 00:20:52,910:INFO: Batch: 18/31	Total Loss 5.3731 (5.4770)
2022-11-03 00:20:53,393:INFO: Batch: 19/31	Total Loss 5.4099 (5.4735)
2022-11-03 00:20:53,877:INFO: Batch: 20/31	Total Loss 5.1694 (5.4591)
2022-11-03 00:20:54,362:INFO: Batch: 21/31	Total Loss 5.2584 (5.4495)
2022-11-03 00:20:54,848:INFO: Batch: 22/31	Total Loss 5.2770 (5.4413)
2022-11-03 00:20:55,330:INFO: Batch: 23/31	Total Loss 5.3680 (5.4384)
2022-11-03 00:20:55,812:INFO: Batch: 24/31	Total Loss 5.7815 (5.4522)
2022-11-03 00:20:56,294:INFO: Batch: 25/31	Total Loss 5.3081 (5.4461)
2022-11-03 00:20:56,774:INFO: Batch: 26/31	Total Loss 6.1623 (5.4720)
2022-11-03 00:20:57,256:INFO: Batch: 27/31	Total Loss 5.0109 (5.4567)
2022-11-03 00:20:57,737:INFO: Batch: 28/31	Total Loss 4.9997 (5.4408)
2022-11-03 00:20:58,218:INFO: Batch: 29/31	Total Loss 5.2816 (5.4358)
2022-11-03 00:20:58,614:INFO: Batch: 30/31	Total Loss 2.0978 (5.4076)
2022-11-03 00:20:58,777:INFO: - Computing ADE (validation o)
2022-11-03 00:20:59,395:INFO: 		 ADE on eth                       dataset:	 1.1856842041015625
2022-11-03 00:20:59,395:INFO: Average validation o:	ADE  1.1857	FDE  1.8710
2022-11-03 00:20:59,396:INFO: - Computing ADE (validation)
2022-11-03 00:20:59,671:INFO: 		 ADE on hotel                     dataset:	 0.524865984916687
2022-11-03 00:20:59,960:INFO: 		 ADE on univ                      dataset:	 0.6449648141860962
2022-11-03 00:21:00,206:INFO: 		 ADE on zara1                     dataset:	 0.7071712613105774
2022-11-03 00:21:00,580:INFO: 		 ADE on zara2                     dataset:	 0.5370674133300781
2022-11-03 00:21:00,580:INFO: Average validation:	ADE  0.6024	FDE  1.0491
2022-11-03 00:21:00,589:INFO: - Computing ADE (training)
2022-11-03 00:21:01,044:INFO: 		 ADE on hotel                     dataset:	 0.6081258058547974
2022-11-03 00:21:01,759:INFO: 		 ADE on univ                      dataset:	 0.6154950857162476
2022-11-03 00:21:02,317:INFO: 		 ADE on zara1                     dataset:	 0.7985457181930542
2022-11-03 00:21:03,064:INFO: 		 ADE on zara2                     dataset:	 0.6022161245346069
2022-11-03 00:21:03,064:INFO: Average training:	ADE  0.6243	FDE  1.1044
2022-11-03 00:21:03,073:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_339.pth.tar
2022-11-03 00:21:03,073:INFO: 
===> EPOCH: 340 (P3)
2022-11-03 00:21:03,073:INFO: - Computing loss (training)
2022-11-03 00:21:04,162:INFO: Batch:  0/31	Total Loss 5.2645 (5.2645)
2022-11-03 00:21:04,634:INFO: Batch:  1/31	Total Loss 5.5329 (5.3963)
2022-11-03 00:21:05,112:INFO: Batch:  2/31	Total Loss 5.3048 (5.3660)
2022-11-03 00:21:05,581:INFO: Batch:  3/31	Total Loss 5.3121 (5.3532)
2022-11-03 00:21:06,133:INFO: Batch:  4/31	Total Loss 5.5726 (5.3966)
2022-11-03 00:21:06,611:INFO: Batch:  5/31	Total Loss 5.9545 (5.4998)
2022-11-03 00:21:07,085:INFO: Batch:  6/31	Total Loss 4.5914 (5.3807)
2022-11-03 00:21:07,563:INFO: Batch:  7/31	Total Loss 5.3185 (5.3731)
2022-11-03 00:21:08,036:INFO: Batch:  8/31	Total Loss 6.3671 (5.4946)
2022-11-03 00:21:08,510:INFO: Batch:  9/31	Total Loss 5.1764 (5.4618)
2022-11-03 00:21:08,984:INFO: Batch: 10/31	Total Loss 5.2703 (5.4447)
2022-11-03 00:21:09,461:INFO: Batch: 11/31	Total Loss 5.6305 (5.4618)
2022-11-03 00:21:09,944:INFO: Batch: 12/31	Total Loss 5.1672 (5.4397)
2022-11-03 00:21:10,426:INFO: Batch: 13/31	Total Loss 4.9303 (5.4024)
2022-11-03 00:21:10,910:INFO: Batch: 14/31	Total Loss 5.5875 (5.4140)
2022-11-03 00:21:11,394:INFO: Batch: 15/31	Total Loss 5.4068 (5.4135)
2022-11-03 00:21:11,872:INFO: Batch: 16/31	Total Loss 5.1657 (5.3995)
2022-11-03 00:21:12,354:INFO: Batch: 17/31	Total Loss 5.8265 (5.4273)
2022-11-03 00:21:12,830:INFO: Batch: 18/31	Total Loss 5.1963 (5.4148)
2022-11-03 00:21:13,307:INFO: Batch: 19/31	Total Loss 4.8898 (5.3879)
2022-11-03 00:21:13,783:INFO: Batch: 20/31	Total Loss 5.1025 (5.3747)
2022-11-03 00:21:14,262:INFO: Batch: 21/31	Total Loss 6.2946 (5.4164)
2022-11-03 00:21:14,738:INFO: Batch: 22/31	Total Loss 5.8681 (5.4355)
2022-11-03 00:21:15,217:INFO: Batch: 23/31	Total Loss 5.6300 (5.4429)
2022-11-03 00:21:15,694:INFO: Batch: 24/31	Total Loss 5.0233 (5.4250)
2022-11-03 00:21:16,170:INFO: Batch: 25/31	Total Loss 5.6456 (5.4327)
2022-11-03 00:21:16,647:INFO: Batch: 26/31	Total Loss 5.7790 (5.4453)
2022-11-03 00:21:17,124:INFO: Batch: 27/31	Total Loss 5.7835 (5.4563)
2022-11-03 00:21:17,601:INFO: Batch: 28/31	Total Loss 6.1127 (5.4826)
2022-11-03 00:21:18,079:INFO: Batch: 29/31	Total Loss 5.6308 (5.4875)
2022-11-03 00:21:18,469:INFO: Batch: 30/31	Total Loss 2.4554 (5.4535)
2022-11-03 00:21:18,615:INFO: - Computing ADE (validation o)
2022-11-03 00:21:19,192:INFO: 		 ADE on eth                       dataset:	 1.2080321311950684
2022-11-03 00:21:19,192:INFO: Average validation o:	ADE  1.2080	FDE  1.9308
2022-11-03 00:21:19,193:INFO: - Computing ADE (validation)
2022-11-03 00:21:19,464:INFO: 		 ADE on hotel                     dataset:	 0.560495913028717
2022-11-03 00:21:19,749:INFO: 		 ADE on univ                      dataset:	 0.6489719152450562
2022-11-03 00:21:20,012:INFO: 		 ADE on zara1                     dataset:	 0.7075083255767822
2022-11-03 00:21:20,363:INFO: 		 ADE on zara2                     dataset:	 0.5667974352836609
2022-11-03 00:21:20,364:INFO: Average validation:	ADE  0.6174	FDE  1.0979
2022-11-03 00:21:20,364:INFO: - Computing ADE (training)
2022-11-03 00:21:20,824:INFO: 		 ADE on hotel                     dataset:	 0.6331620812416077
2022-11-03 00:21:21,510:INFO: 		 ADE on univ                      dataset:	 0.6286595463752747
2022-11-03 00:21:22,027:INFO: 		 ADE on zara1                     dataset:	 0.8086581826210022
2022-11-03 00:21:22,757:INFO: 		 ADE on zara2                     dataset:	 0.6304593682289124
2022-11-03 00:21:22,757:INFO: Average training:	ADE  0.6406	FDE  1.1533
2022-11-03 00:21:22,766:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_340.pth.tar
2022-11-03 00:21:22,766:INFO: 
===> EPOCH: 341 (P3)
2022-11-03 00:21:22,766:INFO: - Computing loss (training)
2022-11-03 00:21:23,872:INFO: Batch:  0/31	Total Loss 5.7161 (5.7161)
2022-11-03 00:21:24,346:INFO: Batch:  1/31	Total Loss 5.9053 (5.8112)
2022-11-03 00:21:24,818:INFO: Batch:  2/31	Total Loss 5.4701 (5.6998)
2022-11-03 00:21:25,295:INFO: Batch:  3/31	Total Loss 5.3573 (5.6226)
2022-11-03 00:21:25,776:INFO: Batch:  4/31	Total Loss 5.9922 (5.7013)
2022-11-03 00:21:26,259:INFO: Batch:  5/31	Total Loss 5.8017 (5.7167)
2022-11-03 00:21:26,740:INFO: Batch:  6/31	Total Loss 5.4556 (5.6777)
2022-11-03 00:21:27,218:INFO: Batch:  7/31	Total Loss 5.2448 (5.6258)
2022-11-03 00:21:27,698:INFO: Batch:  8/31	Total Loss 5.2893 (5.5906)
2022-11-03 00:21:28,180:INFO: Batch:  9/31	Total Loss 5.3421 (5.5657)
2022-11-03 00:21:28,663:INFO: Batch: 10/31	Total Loss 6.1793 (5.6226)
2022-11-03 00:21:29,147:INFO: Batch: 11/31	Total Loss 6.3779 (5.6786)
2022-11-03 00:21:29,628:INFO: Batch: 12/31	Total Loss 4.7569 (5.6074)
2022-11-03 00:21:30,108:INFO: Batch: 13/31	Total Loss 5.3951 (5.5917)
2022-11-03 00:21:30,585:INFO: Batch: 14/31	Total Loss 5.4232 (5.5798)
2022-11-03 00:21:31,069:INFO: Batch: 15/31	Total Loss 4.8016 (5.5329)
2022-11-03 00:21:31,547:INFO: Batch: 16/31	Total Loss 5.3266 (5.5224)
2022-11-03 00:21:32,024:INFO: Batch: 17/31	Total Loss 6.2099 (5.5660)
2022-11-03 00:21:32,504:INFO: Batch: 18/31	Total Loss 5.0762 (5.5413)
2022-11-03 00:21:32,983:INFO: Batch: 19/31	Total Loss 5.7028 (5.5495)
2022-11-03 00:21:33,459:INFO: Batch: 20/31	Total Loss 4.9426 (5.5213)
2022-11-03 00:21:33,935:INFO: Batch: 21/31	Total Loss 5.4658 (5.5191)
2022-11-03 00:21:34,410:INFO: Batch: 22/31	Total Loss 5.5019 (5.5183)
2022-11-03 00:21:34,887:INFO: Batch: 23/31	Total Loss 5.1169 (5.5015)
2022-11-03 00:21:35,361:INFO: Batch: 24/31	Total Loss 5.1408 (5.4874)
2022-11-03 00:21:35,838:INFO: Batch: 25/31	Total Loss 5.5046 (5.4880)
2022-11-03 00:21:36,315:INFO: Batch: 26/31	Total Loss 5.1182 (5.4737)
2022-11-03 00:21:36,791:INFO: Batch: 27/31	Total Loss 5.0465 (5.4582)
2022-11-03 00:21:37,270:INFO: Batch: 28/31	Total Loss 5.4667 (5.4584)
2022-11-03 00:21:37,748:INFO: Batch: 29/31	Total Loss 5.1117 (5.4468)
2022-11-03 00:21:38,142:INFO: Batch: 30/31	Total Loss 1.7829 (5.4128)
2022-11-03 00:21:38,291:INFO: - Computing ADE (validation o)
2022-11-03 00:21:38,889:INFO: 		 ADE on eth                       dataset:	 1.160563588142395
2022-11-03 00:21:38,889:INFO: Average validation o:	ADE  1.1606	FDE  1.8491
2022-11-03 00:21:38,890:INFO: - Computing ADE (validation)
2022-11-03 00:21:39,147:INFO: 		 ADE on hotel                     dataset:	 0.5218104720115662
2022-11-03 00:21:39,446:INFO: 		 ADE on univ                      dataset:	 0.637332558631897
2022-11-03 00:21:39,705:INFO: 		 ADE on zara1                     dataset:	 0.6878623366355896
2022-11-03 00:21:40,058:INFO: 		 ADE on zara2                     dataset:	 0.5166691541671753
2022-11-03 00:21:40,058:INFO: Average validation:	ADE  0.5897	FDE  1.0299
2022-11-03 00:21:40,059:INFO: - Computing ADE (training)
2022-11-03 00:21:40,503:INFO: 		 ADE on hotel                     dataset:	 0.5976664423942566
2022-11-03 00:21:41,179:INFO: 		 ADE on univ                      dataset:	 0.6060216426849365
2022-11-03 00:21:41,716:INFO: 		 ADE on zara1                     dataset:	 0.7627336382865906
2022-11-03 00:21:42,470:INFO: 		 ADE on zara2                     dataset:	 0.5756203532218933
2022-11-03 00:21:42,470:INFO: Average training:	ADE  0.6096	FDE  1.0806
2022-11-03 00:21:42,479:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_341.pth.tar
2022-11-03 00:21:42,479:INFO: 
===> EPOCH: 342 (P3)
2022-11-03 00:21:42,480:INFO: - Computing loss (training)
2022-11-03 00:21:43,574:INFO: Batch:  0/31	Total Loss 4.9186 (4.9186)
2022-11-03 00:21:44,052:INFO: Batch:  1/31	Total Loss 5.9393 (5.3787)
2022-11-03 00:21:44,535:INFO: Batch:  2/31	Total Loss 4.8679 (5.2074)
2022-11-03 00:21:45,011:INFO: Batch:  3/31	Total Loss 5.1597 (5.1960)
2022-11-03 00:21:45,485:INFO: Batch:  4/31	Total Loss 4.9437 (5.1428)
2022-11-03 00:21:45,964:INFO: Batch:  5/31	Total Loss 5.4688 (5.1914)
2022-11-03 00:21:46,441:INFO: Batch:  6/31	Total Loss 5.5219 (5.2463)
2022-11-03 00:21:46,912:INFO: Batch:  7/31	Total Loss 5.3614 (5.2598)
2022-11-03 00:21:47,387:INFO: Batch:  8/31	Total Loss 5.2235 (5.2554)
2022-11-03 00:21:47,863:INFO: Batch:  9/31	Total Loss 5.3337 (5.2633)
2022-11-03 00:21:48,339:INFO: Batch: 10/31	Total Loss 5.3148 (5.2680)
2022-11-03 00:21:48,815:INFO: Batch: 11/31	Total Loss 5.3736 (5.2754)
2022-11-03 00:21:49,291:INFO: Batch: 12/31	Total Loss 5.9164 (5.3287)
2022-11-03 00:21:49,773:INFO: Batch: 13/31	Total Loss 5.6335 (5.3495)
2022-11-03 00:21:50,251:INFO: Batch: 14/31	Total Loss 6.0260 (5.3929)
2022-11-03 00:21:50,728:INFO: Batch: 15/31	Total Loss 5.2964 (5.3867)
2022-11-03 00:21:51,208:INFO: Batch: 16/31	Total Loss 5.2953 (5.3808)
2022-11-03 00:21:51,685:INFO: Batch: 17/31	Total Loss 6.0824 (5.4155)
2022-11-03 00:21:52,161:INFO: Batch: 18/31	Total Loss 5.6263 (5.4260)
2022-11-03 00:21:52,640:INFO: Batch: 19/31	Total Loss 5.7869 (5.4437)
2022-11-03 00:21:53,119:INFO: Batch: 20/31	Total Loss 5.2557 (5.4344)
2022-11-03 00:21:53,600:INFO: Batch: 21/31	Total Loss 6.1501 (5.4717)
2022-11-03 00:21:54,076:INFO: Batch: 22/31	Total Loss 5.7097 (5.4811)
2022-11-03 00:21:54,564:INFO: Batch: 23/31	Total Loss 4.2682 (5.4235)
2022-11-03 00:21:55,041:INFO: Batch: 24/31	Total Loss 5.2509 (5.4167)
2022-11-03 00:21:55,519:INFO: Batch: 25/31	Total Loss 5.0817 (5.4040)
2022-11-03 00:21:55,997:INFO: Batch: 26/31	Total Loss 5.7013 (5.4160)
2022-11-03 00:21:56,474:INFO: Batch: 27/31	Total Loss 4.9136 (5.3972)
2022-11-03 00:21:57,028:INFO: Batch: 28/31	Total Loss 4.7439 (5.3761)
2022-11-03 00:21:57,508:INFO: Batch: 29/31	Total Loss 5.3188 (5.3743)
2022-11-03 00:21:57,899:INFO: Batch: 30/31	Total Loss 2.1180 (5.3362)
2022-11-03 00:21:58,056:INFO: - Computing ADE (validation o)
2022-11-03 00:21:58,652:INFO: 		 ADE on eth                       dataset:	 1.1468303203582764
2022-11-03 00:21:58,652:INFO: Average validation o:	ADE  1.1468	FDE  1.8380
2022-11-03 00:21:58,653:INFO: - Computing ADE (validation)
2022-11-03 00:21:58,930:INFO: 		 ADE on hotel                     dataset:	 0.5413470268249512
2022-11-03 00:21:59,232:INFO: 		 ADE on univ                      dataset:	 0.6303878426551819
2022-11-03 00:21:59,471:INFO: 		 ADE on zara1                     dataset:	 0.6409429907798767
2022-11-03 00:21:59,827:INFO: 		 ADE on zara2                     dataset:	 0.5159605741500854
2022-11-03 00:21:59,827:INFO: Average validation:	ADE  0.5842	FDE  1.0333
2022-11-03 00:21:59,828:INFO: - Computing ADE (training)
2022-11-03 00:22:00,274:INFO: 		 ADE on hotel                     dataset:	 0.6144627928733826
2022-11-03 00:22:00,958:INFO: 		 ADE on univ                      dataset:	 0.6048112511634827
2022-11-03 00:22:01,491:INFO: 		 ADE on zara1                     dataset:	 0.7327712774276733
2022-11-03 00:22:02,243:INFO: 		 ADE on zara2                     dataset:	 0.5699905753135681
2022-11-03 00:22:02,243:INFO: Average training:	ADE  0.6061	FDE  1.0867
2022-11-03 00:22:02,252:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_342.pth.tar
2022-11-03 00:22:02,253:INFO: 
===> EPOCH: 343 (P3)
2022-11-03 00:22:02,253:INFO: - Computing loss (training)
2022-11-03 00:22:03,374:INFO: Batch:  0/31	Total Loss 7.5812 (7.5812)
2022-11-03 00:22:03,859:INFO: Batch:  1/31	Total Loss 5.2004 (6.3470)
2022-11-03 00:22:04,342:INFO: Batch:  2/31	Total Loss 5.5908 (6.1286)
2022-11-03 00:22:04,818:INFO: Batch:  3/31	Total Loss 5.5242 (5.9789)
2022-11-03 00:22:05,301:INFO: Batch:  4/31	Total Loss 5.3747 (5.8519)
2022-11-03 00:22:05,783:INFO: Batch:  5/31	Total Loss 5.4074 (5.7698)
2022-11-03 00:22:06,263:INFO: Batch:  6/31	Total Loss 4.9162 (5.6358)
2022-11-03 00:22:06,740:INFO: Batch:  7/31	Total Loss 5.2252 (5.5875)
2022-11-03 00:22:07,221:INFO: Batch:  8/31	Total Loss 5.0447 (5.5249)
2022-11-03 00:22:07,697:INFO: Batch:  9/31	Total Loss 4.6835 (5.4322)
2022-11-03 00:22:08,170:INFO: Batch: 10/31	Total Loss 5.7649 (5.4610)
2022-11-03 00:22:08,644:INFO: Batch: 11/31	Total Loss 5.2656 (5.4462)
2022-11-03 00:22:09,122:INFO: Batch: 12/31	Total Loss 5.2683 (5.4327)
2022-11-03 00:22:09,599:INFO: Batch: 13/31	Total Loss 6.6664 (5.5113)
2022-11-03 00:22:10,079:INFO: Batch: 14/31	Total Loss 4.9407 (5.4720)
2022-11-03 00:22:10,555:INFO: Batch: 15/31	Total Loss 4.4205 (5.3984)
2022-11-03 00:22:11,032:INFO: Batch: 16/31	Total Loss 5.1259 (5.3848)
2022-11-03 00:22:11,509:INFO: Batch: 17/31	Total Loss 5.8804 (5.4071)
2022-11-03 00:22:11,985:INFO: Batch: 18/31	Total Loss 5.7992 (5.4272)
2022-11-03 00:22:12,463:INFO: Batch: 19/31	Total Loss 5.5983 (5.4365)
2022-11-03 00:22:12,939:INFO: Batch: 20/31	Total Loss 5.0653 (5.4195)
2022-11-03 00:22:13,416:INFO: Batch: 21/31	Total Loss 5.3811 (5.4177)
2022-11-03 00:22:13,892:INFO: Batch: 22/31	Total Loss 5.6555 (5.4281)
2022-11-03 00:22:14,370:INFO: Batch: 23/31	Total Loss 7.0283 (5.4869)
2022-11-03 00:22:14,849:INFO: Batch: 24/31	Total Loss 5.4571 (5.4858)
2022-11-03 00:22:15,322:INFO: Batch: 25/31	Total Loss 5.1546 (5.4718)
2022-11-03 00:22:15,793:INFO: Batch: 26/31	Total Loss 5.6718 (5.4800)
2022-11-03 00:22:16,265:INFO: Batch: 27/31	Total Loss 5.4079 (5.4773)
2022-11-03 00:22:16,736:INFO: Batch: 28/31	Total Loss 5.6866 (5.4844)
2022-11-03 00:22:17,211:INFO: Batch: 29/31	Total Loss 6.2227 (5.5086)
2022-11-03 00:22:17,599:INFO: Batch: 30/31	Total Loss 2.2451 (5.4803)
2022-11-03 00:22:17,740:INFO: - Computing ADE (validation o)
2022-11-03 00:22:18,307:INFO: 		 ADE on eth                       dataset:	 1.2142552137374878
2022-11-03 00:22:18,307:INFO: Average validation o:	ADE  1.2143	FDE  1.9367
2022-11-03 00:22:18,308:INFO: - Computing ADE (validation)
2022-11-03 00:22:18,575:INFO: 		 ADE on hotel                     dataset:	 0.6003098487854004
2022-11-03 00:22:18,864:INFO: 		 ADE on univ                      dataset:	 0.6990301609039307
2022-11-03 00:22:19,104:INFO: 		 ADE on zara1                     dataset:	 0.7034725546836853
2022-11-03 00:22:19,444:INFO: 		 ADE on zara2                     dataset:	 0.5839585661888123
2022-11-03 00:22:19,445:INFO: Average validation:	ADE  0.6517	FDE  1.1980
2022-11-03 00:22:19,445:INFO: - Computing ADE (training)
2022-11-03 00:22:19,887:INFO: 		 ADE on hotel                     dataset:	 0.6875239610671997
2022-11-03 00:22:20,604:INFO: 		 ADE on univ                      dataset:	 0.6492131352424622
2022-11-03 00:22:21,168:INFO: 		 ADE on zara1                     dataset:	 0.8181688189506531
2022-11-03 00:22:21,942:INFO: 		 ADE on zara2                     dataset:	 0.6561282277107239
2022-11-03 00:22:21,942:INFO: Average training:	ADE  0.6624	FDE  1.2198
2022-11-03 00:22:21,951:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_343.pth.tar
2022-11-03 00:22:21,951:INFO: 
===> EPOCH: 344 (P3)
2022-11-03 00:22:21,952:INFO: - Computing loss (training)
2022-11-03 00:22:23,047:INFO: Batch:  0/31	Total Loss 5.5641 (5.5641)
2022-11-03 00:22:23,527:INFO: Batch:  1/31	Total Loss 5.6601 (5.6146)
2022-11-03 00:22:23,999:INFO: Batch:  2/31	Total Loss 5.5839 (5.6049)
2022-11-03 00:22:24,474:INFO: Batch:  3/31	Total Loss 4.9015 (5.4215)
2022-11-03 00:22:24,942:INFO: Batch:  4/31	Total Loss 4.9030 (5.3210)
2022-11-03 00:22:25,415:INFO: Batch:  5/31	Total Loss 5.1955 (5.3013)
2022-11-03 00:22:25,887:INFO: Batch:  6/31	Total Loss 5.4417 (5.3211)
2022-11-03 00:22:26,358:INFO: Batch:  7/31	Total Loss 6.3034 (5.4436)
2022-11-03 00:22:26,828:INFO: Batch:  8/31	Total Loss 5.5653 (5.4552)
2022-11-03 00:22:27,298:INFO: Batch:  9/31	Total Loss 5.2477 (5.4350)
2022-11-03 00:22:27,767:INFO: Batch: 10/31	Total Loss 6.7155 (5.5491)
2022-11-03 00:22:28,238:INFO: Batch: 11/31	Total Loss 6.0753 (5.5897)
2022-11-03 00:22:28,711:INFO: Batch: 12/31	Total Loss 5.9471 (5.6144)
2022-11-03 00:22:29,183:INFO: Batch: 13/31	Total Loss 5.3906 (5.5992)
2022-11-03 00:22:29,657:INFO: Batch: 14/31	Total Loss 5.0539 (5.5657)
2022-11-03 00:22:30,134:INFO: Batch: 15/31	Total Loss 5.0871 (5.5339)
2022-11-03 00:22:30,608:INFO: Batch: 16/31	Total Loss 5.3089 (5.5207)
2022-11-03 00:22:31,084:INFO: Batch: 17/31	Total Loss 5.4575 (5.5174)
2022-11-03 00:22:31,559:INFO: Batch: 18/31	Total Loss 6.0250 (5.5454)
2022-11-03 00:22:32,031:INFO: Batch: 19/31	Total Loss 6.1997 (5.5780)
2022-11-03 00:22:32,504:INFO: Batch: 20/31	Total Loss 5.1225 (5.5555)
2022-11-03 00:22:32,978:INFO: Batch: 21/31	Total Loss 5.5721 (5.5563)
2022-11-03 00:22:33,453:INFO: Batch: 22/31	Total Loss 5.0851 (5.5363)
2022-11-03 00:22:33,927:INFO: Batch: 23/31	Total Loss 4.9886 (5.5123)
2022-11-03 00:22:34,398:INFO: Batch: 24/31	Total Loss 5.5264 (5.5128)
2022-11-03 00:22:34,870:INFO: Batch: 25/31	Total Loss 5.2059 (5.5018)
2022-11-03 00:22:35,342:INFO: Batch: 26/31	Total Loss 5.1610 (5.4902)
2022-11-03 00:22:35,814:INFO: Batch: 27/31	Total Loss 5.2491 (5.4822)
2022-11-03 00:22:36,287:INFO: Batch: 28/31	Total Loss 5.4495 (5.4811)
2022-11-03 00:22:36,760:INFO: Batch: 29/31	Total Loss 5.1154 (5.4685)
2022-11-03 00:22:37,151:INFO: Batch: 30/31	Total Loss 1.6289 (5.4286)
2022-11-03 00:22:37,300:INFO: - Computing ADE (validation o)
2022-11-03 00:22:37,901:INFO: 		 ADE on eth                       dataset:	 1.1863740682601929
2022-11-03 00:22:37,901:INFO: Average validation o:	ADE  1.1864	FDE  1.9224
2022-11-03 00:22:37,902:INFO: - Computing ADE (validation)
2022-11-03 00:22:38,179:INFO: 		 ADE on hotel                     dataset:	 0.55466628074646
2022-11-03 00:22:38,466:INFO: 		 ADE on univ                      dataset:	 0.6479097008705139
2022-11-03 00:22:38,724:INFO: 		 ADE on zara1                     dataset:	 0.7414871454238892
2022-11-03 00:22:39,070:INFO: 		 ADE on zara2                     dataset:	 0.5734536051750183
2022-11-03 00:22:39,070:INFO: Average validation:	ADE  0.6209	FDE  1.1212
2022-11-03 00:22:39,071:INFO: - Computing ADE (training)
2022-11-03 00:22:39,517:INFO: 		 ADE on hotel                     dataset:	 0.6243374347686768
2022-11-03 00:22:40,251:INFO: 		 ADE on univ                      dataset:	 0.6333117485046387
2022-11-03 00:22:40,768:INFO: 		 ADE on zara1                     dataset:	 0.802513062953949
2022-11-03 00:22:41,509:INFO: 		 ADE on zara2                     dataset:	 0.6284261345863342
2022-11-03 00:22:41,510:INFO: Average training:	ADE  0.6429	FDE  1.1787
2022-11-03 00:22:41,518:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_344.pth.tar
2022-11-03 00:22:41,518:INFO: 
===> EPOCH: 345 (P3)
2022-11-03 00:22:41,518:INFO: - Computing loss (training)
2022-11-03 00:22:42,595:INFO: Batch:  0/31	Total Loss 6.1173 (6.1173)
2022-11-03 00:22:43,064:INFO: Batch:  1/31	Total Loss 6.3892 (6.2490)
2022-11-03 00:22:43,544:INFO: Batch:  2/31	Total Loss 5.7787 (6.0867)
2022-11-03 00:22:44,014:INFO: Batch:  3/31	Total Loss 5.4410 (5.9189)
2022-11-03 00:22:44,487:INFO: Batch:  4/31	Total Loss 5.4051 (5.8065)
2022-11-03 00:22:44,957:INFO: Batch:  5/31	Total Loss 6.0153 (5.8420)
2022-11-03 00:22:45,427:INFO: Batch:  6/31	Total Loss 4.6318 (5.6436)
2022-11-03 00:22:45,896:INFO: Batch:  7/31	Total Loss 4.9594 (5.5640)
2022-11-03 00:22:46,362:INFO: Batch:  8/31	Total Loss 5.5110 (5.5582)
2022-11-03 00:22:46,831:INFO: Batch:  9/31	Total Loss 4.9490 (5.5033)
2022-11-03 00:22:47,302:INFO: Batch: 10/31	Total Loss 5.6834 (5.5178)
2022-11-03 00:22:47,771:INFO: Batch: 11/31	Total Loss 5.5405 (5.5198)
2022-11-03 00:22:48,243:INFO: Batch: 12/31	Total Loss 5.2171 (5.4978)
2022-11-03 00:22:48,714:INFO: Batch: 13/31	Total Loss 4.9418 (5.4611)
2022-11-03 00:22:49,187:INFO: Batch: 14/31	Total Loss 5.0639 (5.4340)
2022-11-03 00:22:49,665:INFO: Batch: 15/31	Total Loss 5.3931 (5.4313)
2022-11-03 00:22:50,149:INFO: Batch: 16/31	Total Loss 5.8712 (5.4551)
2022-11-03 00:22:50,629:INFO: Batch: 17/31	Total Loss 5.6715 (5.4682)
2022-11-03 00:22:51,103:INFO: Batch: 18/31	Total Loss 5.2083 (5.4553)
2022-11-03 00:22:51,655:INFO: Batch: 19/31	Total Loss 5.1145 (5.4390)
2022-11-03 00:22:52,131:INFO: Batch: 20/31	Total Loss 6.9411 (5.5046)
2022-11-03 00:22:52,613:INFO: Batch: 21/31	Total Loss 4.9329 (5.4757)
2022-11-03 00:22:53,095:INFO: Batch: 22/31	Total Loss 6.1906 (5.5043)
2022-11-03 00:22:53,578:INFO: Batch: 23/31	Total Loss 5.2754 (5.4950)
2022-11-03 00:22:54,059:INFO: Batch: 24/31	Total Loss 5.0461 (5.4777)
2022-11-03 00:22:54,542:INFO: Batch: 25/31	Total Loss 4.9507 (5.4575)
2022-11-03 00:22:55,025:INFO: Batch: 26/31	Total Loss 5.1840 (5.4480)
2022-11-03 00:22:55,506:INFO: Batch: 27/31	Total Loss 4.9750 (5.4313)
2022-11-03 00:22:55,989:INFO: Batch: 28/31	Total Loss 5.8092 (5.4433)
2022-11-03 00:22:56,471:INFO: Batch: 29/31	Total Loss 4.9302 (5.4258)
2022-11-03 00:22:56,867:INFO: Batch: 30/31	Total Loss 1.9104 (5.3978)
2022-11-03 00:22:57,024:INFO: - Computing ADE (validation o)
2022-11-03 00:22:57,637:INFO: 		 ADE on eth                       dataset:	 1.1680221557617188
2022-11-03 00:22:57,637:INFO: Average validation o:	ADE  1.1680	FDE  1.8505
2022-11-03 00:22:57,638:INFO: - Computing ADE (validation)
2022-11-03 00:22:57,925:INFO: 		 ADE on hotel                     dataset:	 0.5369930267333984
2022-11-03 00:22:58,238:INFO: 		 ADE on univ                      dataset:	 0.6496110558509827
2022-11-03 00:22:58,483:INFO: 		 ADE on zara1                     dataset:	 0.6649458408355713
2022-11-03 00:22:58,820:INFO: 		 ADE on zara2                     dataset:	 0.526814341545105
2022-11-03 00:22:58,820:INFO: Average validation:	ADE  0.5993	FDE  1.0684
2022-11-03 00:22:58,820:INFO: - Computing ADE (training)
2022-11-03 00:22:59,276:INFO: 		 ADE on hotel                     dataset:	 0.6167662143707275
2022-11-03 00:22:59,952:INFO: 		 ADE on univ                      dataset:	 0.6118022203445435
2022-11-03 00:23:00,494:INFO: 		 ADE on zara1                     dataset:	 0.7615503072738647
2022-11-03 00:23:01,226:INFO: 		 ADE on zara2                     dataset:	 0.5893376469612122
2022-11-03 00:23:01,227:INFO: Average training:	ADE  0.6169	FDE  1.1108
2022-11-03 00:23:01,235:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_345.pth.tar
2022-11-03 00:23:01,236:INFO: 
===> EPOCH: 346 (P3)
2022-11-03 00:23:01,236:INFO: - Computing loss (training)
2022-11-03 00:23:02,330:INFO: Batch:  0/31	Total Loss 5.7811 (5.7811)
2022-11-03 00:23:02,812:INFO: Batch:  1/31	Total Loss 5.0941 (5.4062)
2022-11-03 00:23:03,282:INFO: Batch:  2/31	Total Loss 5.4415 (5.4176)
2022-11-03 00:23:03,752:INFO: Batch:  3/31	Total Loss 5.3598 (5.4028)
2022-11-03 00:23:04,228:INFO: Batch:  4/31	Total Loss 5.0012 (5.3133)
2022-11-03 00:23:04,697:INFO: Batch:  5/31	Total Loss 6.7423 (5.5460)
2022-11-03 00:23:05,170:INFO: Batch:  6/31	Total Loss 5.0657 (5.4743)
2022-11-03 00:23:05,637:INFO: Batch:  7/31	Total Loss 5.3241 (5.4548)
2022-11-03 00:23:06,104:INFO: Batch:  8/31	Total Loss 4.7631 (5.3678)
2022-11-03 00:23:06,572:INFO: Batch:  9/31	Total Loss 4.9363 (5.3246)
2022-11-03 00:23:07,040:INFO: Batch: 10/31	Total Loss 6.1022 (5.3854)
2022-11-03 00:23:07,511:INFO: Batch: 11/31	Total Loss 5.1734 (5.3682)
2022-11-03 00:23:07,984:INFO: Batch: 12/31	Total Loss 5.5541 (5.3832)
2022-11-03 00:23:08,457:INFO: Batch: 13/31	Total Loss 6.0948 (5.4363)
2022-11-03 00:23:08,931:INFO: Batch: 14/31	Total Loss 4.9058 (5.4007)
2022-11-03 00:23:09,402:INFO: Batch: 15/31	Total Loss 5.0698 (5.3813)
2022-11-03 00:23:09,875:INFO: Batch: 16/31	Total Loss 6.1939 (5.4284)
2022-11-03 00:23:10,346:INFO: Batch: 17/31	Total Loss 5.5003 (5.4323)
2022-11-03 00:23:10,817:INFO: Batch: 18/31	Total Loss 5.3151 (5.4258)
2022-11-03 00:23:11,293:INFO: Batch: 19/31	Total Loss 6.0655 (5.4546)
2022-11-03 00:23:11,768:INFO: Batch: 20/31	Total Loss 5.4388 (5.4538)
2022-11-03 00:23:12,242:INFO: Batch: 21/31	Total Loss 5.0614 (5.4365)
2022-11-03 00:23:12,719:INFO: Batch: 22/31	Total Loss 5.8402 (5.4536)
2022-11-03 00:23:13,198:INFO: Batch: 23/31	Total Loss 5.2902 (5.4467)
2022-11-03 00:23:13,673:INFO: Batch: 24/31	Total Loss 5.1289 (5.4342)
2022-11-03 00:23:14,156:INFO: Batch: 25/31	Total Loss 5.2084 (5.4254)
2022-11-03 00:23:14,633:INFO: Batch: 26/31	Total Loss 5.1646 (5.4150)
2022-11-03 00:23:15,115:INFO: Batch: 27/31	Total Loss 5.9974 (5.4357)
2022-11-03 00:23:15,593:INFO: Batch: 28/31	Total Loss 5.5055 (5.4379)
2022-11-03 00:23:16,067:INFO: Batch: 29/31	Total Loss 5.2720 (5.4324)
2022-11-03 00:23:16,457:INFO: Batch: 30/31	Total Loss 2.0640 (5.4020)
2022-11-03 00:23:16,613:INFO: - Computing ADE (validation o)
2022-11-03 00:23:17,217:INFO: 		 ADE on eth                       dataset:	 1.1545902490615845
2022-11-03 00:23:17,217:INFO: Average validation o:	ADE  1.1546	FDE  1.8515
2022-11-03 00:23:17,218:INFO: - Computing ADE (validation)
2022-11-03 00:23:17,519:INFO: 		 ADE on hotel                     dataset:	 0.5427907109260559
2022-11-03 00:23:17,814:INFO: 		 ADE on univ                      dataset:	 0.6375184059143066
2022-11-03 00:23:18,079:INFO: 		 ADE on zara1                     dataset:	 0.6338939070701599
2022-11-03 00:23:18,427:INFO: 		 ADE on zara2                     dataset:	 0.5203886032104492
2022-11-03 00:23:18,427:INFO: Average validation:	ADE  0.5892	FDE  1.0518
2022-11-03 00:23:18,428:INFO: - Computing ADE (training)
2022-11-03 00:23:18,890:INFO: 		 ADE on hotel                     dataset:	 0.6188356876373291
2022-11-03 00:23:19,556:INFO: 		 ADE on univ                      dataset:	 0.6068323254585266
2022-11-03 00:23:20,110:INFO: 		 ADE on zara1                     dataset:	 0.7418778538703918
2022-11-03 00:23:20,848:INFO: 		 ADE on zara2                     dataset:	 0.577863335609436
2022-11-03 00:23:20,848:INFO: Average training:	ADE  0.6099	FDE  1.1003
2022-11-03 00:23:20,856:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_346.pth.tar
2022-11-03 00:23:20,856:INFO: 
===> EPOCH: 347 (P3)
2022-11-03 00:23:20,857:INFO: - Computing loss (training)
2022-11-03 00:23:21,945:INFO: Batch:  0/31	Total Loss 5.5470 (5.5470)
2022-11-03 00:23:22,426:INFO: Batch:  1/31	Total Loss 5.3434 (5.4544)
2022-11-03 00:23:22,901:INFO: Batch:  2/31	Total Loss 5.3313 (5.4117)
2022-11-03 00:23:23,376:INFO: Batch:  3/31	Total Loss 5.3530 (5.3970)
2022-11-03 00:23:23,847:INFO: Batch:  4/31	Total Loss 4.8732 (5.2974)
2022-11-03 00:23:24,326:INFO: Batch:  5/31	Total Loss 5.5773 (5.3430)
2022-11-03 00:23:24,803:INFO: Batch:  6/31	Total Loss 5.0538 (5.3023)
2022-11-03 00:23:25,278:INFO: Batch:  7/31	Total Loss 5.4301 (5.3189)
2022-11-03 00:23:25,750:INFO: Batch:  8/31	Total Loss 6.1101 (5.4042)
2022-11-03 00:23:26,226:INFO: Batch:  9/31	Total Loss 5.6357 (5.4268)
2022-11-03 00:23:26,698:INFO: Batch: 10/31	Total Loss 5.8493 (5.4575)
2022-11-03 00:23:27,174:INFO: Batch: 11/31	Total Loss 5.8285 (5.4907)
2022-11-03 00:23:27,652:INFO: Batch: 12/31	Total Loss 5.2172 (5.4682)
2022-11-03 00:23:28,132:INFO: Batch: 13/31	Total Loss 5.1483 (5.4435)
2022-11-03 00:23:28,610:INFO: Batch: 14/31	Total Loss 5.0397 (5.4172)
2022-11-03 00:23:29,087:INFO: Batch: 15/31	Total Loss 5.0004 (5.3902)
2022-11-03 00:23:29,566:INFO: Batch: 16/31	Total Loss 4.9699 (5.3636)
2022-11-03 00:23:30,045:INFO: Batch: 17/31	Total Loss 5.2484 (5.3574)
2022-11-03 00:23:30,522:INFO: Batch: 18/31	Total Loss 5.3587 (5.3574)
2022-11-03 00:23:30,998:INFO: Batch: 19/31	Total Loss 5.6579 (5.3716)
2022-11-03 00:23:31,475:INFO: Batch: 20/31	Total Loss 5.2247 (5.3645)
2022-11-03 00:23:31,952:INFO: Batch: 21/31	Total Loss 5.2872 (5.3606)
2022-11-03 00:23:32,427:INFO: Batch: 22/31	Total Loss 5.5930 (5.3699)
2022-11-03 00:23:32,905:INFO: Batch: 23/31	Total Loss 4.8231 (5.3475)
2022-11-03 00:23:33,380:INFO: Batch: 24/31	Total Loss 5.2396 (5.3433)
2022-11-03 00:23:33,855:INFO: Batch: 25/31	Total Loss 5.0561 (5.3330)
2022-11-03 00:23:34,332:INFO: Batch: 26/31	Total Loss 4.7380 (5.3113)
2022-11-03 00:23:34,809:INFO: Batch: 27/31	Total Loss 4.8635 (5.2949)
2022-11-03 00:23:35,284:INFO: Batch: 28/31	Total Loss 6.2066 (5.3239)
2022-11-03 00:23:35,760:INFO: Batch: 29/31	Total Loss 5.1709 (5.3191)
2022-11-03 00:23:36,151:INFO: Batch: 30/31	Total Loss 2.2137 (5.2887)
2022-11-03 00:23:36,294:INFO: - Computing ADE (validation o)
2022-11-03 00:23:36,894:INFO: 		 ADE on eth                       dataset:	 1.1410545110702515
2022-11-03 00:23:36,895:INFO: Average validation o:	ADE  1.1411	FDE  1.8205
2022-11-03 00:23:36,895:INFO: - Computing ADE (validation)
2022-11-03 00:23:37,171:INFO: 		 ADE on hotel                     dataset:	 0.5319217443466187
2022-11-03 00:23:37,472:INFO: 		 ADE on univ                      dataset:	 0.636629581451416
2022-11-03 00:23:37,723:INFO: 		 ADE on zara1                     dataset:	 0.627041220664978
2022-11-03 00:23:38,075:INFO: 		 ADE on zara2                     dataset:	 0.5111262798309326
2022-11-03 00:23:38,076:INFO: Average validation:	ADE  0.5843	FDE  1.0473
2022-11-03 00:23:38,077:INFO: - Computing ADE (training)
2022-11-03 00:23:38,536:INFO: 		 ADE on hotel                     dataset:	 0.6059370040893555
2022-11-03 00:23:39,251:INFO: 		 ADE on univ                      dataset:	 0.6016490459442139
2022-11-03 00:23:39,784:INFO: 		 ADE on zara1                     dataset:	 0.7259697318077087
2022-11-03 00:23:40,530:INFO: 		 ADE on zara2                     dataset:	 0.5650975108146667
2022-11-03 00:23:40,530:INFO: Average training:	ADE  0.6023	FDE  1.0890
2022-11-03 00:23:40,539:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_347.pth.tar
2022-11-03 00:23:40,539:INFO: 
===> EPOCH: 348 (P3)
2022-11-03 00:23:40,539:INFO: - Computing loss (training)
2022-11-03 00:23:41,619:INFO: Batch:  0/31	Total Loss 6.5521 (6.5521)
2022-11-03 00:23:42,091:INFO: Batch:  1/31	Total Loss 5.9209 (6.2306)
2022-11-03 00:23:42,562:INFO: Batch:  2/31	Total Loss 5.3459 (5.9312)
2022-11-03 00:23:43,034:INFO: Batch:  3/31	Total Loss 4.8277 (5.6279)
2022-11-03 00:23:43,511:INFO: Batch:  4/31	Total Loss 5.3115 (5.5603)
2022-11-03 00:23:43,994:INFO: Batch:  5/31	Total Loss 5.8222 (5.5993)
2022-11-03 00:23:44,473:INFO: Batch:  6/31	Total Loss 5.7895 (5.6260)
2022-11-03 00:23:44,949:INFO: Batch:  7/31	Total Loss 6.1576 (5.6923)
2022-11-03 00:23:45,502:INFO: Batch:  8/31	Total Loss 5.2077 (5.6416)
2022-11-03 00:23:45,977:INFO: Batch:  9/31	Total Loss 4.9091 (5.5571)
2022-11-03 00:23:46,451:INFO: Batch: 10/31	Total Loss 5.9301 (5.5908)
2022-11-03 00:23:46,927:INFO: Batch: 11/31	Total Loss 6.1230 (5.6313)
2022-11-03 00:23:47,405:INFO: Batch: 12/31	Total Loss 5.7716 (5.6422)
2022-11-03 00:23:47,883:INFO: Batch: 13/31	Total Loss 5.1868 (5.6132)
2022-11-03 00:23:48,362:INFO: Batch: 14/31	Total Loss 5.6598 (5.6160)
2022-11-03 00:23:48,842:INFO: Batch: 15/31	Total Loss 5.2405 (5.5928)
2022-11-03 00:23:49,320:INFO: Batch: 16/31	Total Loss 4.7718 (5.5435)
2022-11-03 00:23:49,801:INFO: Batch: 17/31	Total Loss 5.4373 (5.5375)
2022-11-03 00:23:50,282:INFO: Batch: 18/31	Total Loss 5.6578 (5.5438)
2022-11-03 00:23:50,759:INFO: Batch: 19/31	Total Loss 5.7278 (5.5522)
2022-11-03 00:23:51,238:INFO: Batch: 20/31	Total Loss 6.1982 (5.5854)
2022-11-03 00:23:51,716:INFO: Batch: 21/31	Total Loss 5.1832 (5.5646)
2022-11-03 00:23:52,195:INFO: Batch: 22/31	Total Loss 4.8038 (5.5319)
2022-11-03 00:23:52,677:INFO: Batch: 23/31	Total Loss 5.0871 (5.5123)
2022-11-03 00:23:53,159:INFO: Batch: 24/31	Total Loss 5.1731 (5.4987)
2022-11-03 00:23:53,643:INFO: Batch: 25/31	Total Loss 5.7760 (5.5089)
2022-11-03 00:23:54,124:INFO: Batch: 26/31	Total Loss 5.3376 (5.5031)
2022-11-03 00:23:54,606:INFO: Batch: 27/31	Total Loss 4.8714 (5.4804)
2022-11-03 00:23:55,087:INFO: Batch: 28/31	Total Loss 6.0255 (5.4988)
2022-11-03 00:23:55,568:INFO: Batch: 29/31	Total Loss 5.7191 (5.5061)
2022-11-03 00:23:55,964:INFO: Batch: 30/31	Total Loss 1.8624 (5.4645)
2022-11-03 00:23:56,125:INFO: - Computing ADE (validation o)
2022-11-03 00:23:56,730:INFO: 		 ADE on eth                       dataset:	 1.174553632736206
2022-11-03 00:23:56,731:INFO: Average validation o:	ADE  1.1746	FDE  1.9338
2022-11-03 00:23:56,731:INFO: - Computing ADE (validation)
2022-11-03 00:23:57,002:INFO: 		 ADE on hotel                     dataset:	 0.5603424310684204
2022-11-03 00:23:57,304:INFO: 		 ADE on univ                      dataset:	 0.6455041766166687
2022-11-03 00:23:57,570:INFO: 		 ADE on zara1                     dataset:	 0.7415735125541687
2022-11-03 00:23:57,929:INFO: 		 ADE on zara2                     dataset:	 0.5642884969711304
2022-11-03 00:23:57,929:INFO: Average validation:	ADE  0.6166	FDE  1.1335
2022-11-03 00:23:57,930:INFO: - Computing ADE (training)
2022-11-03 00:23:58,396:INFO: 		 ADE on hotel                     dataset:	 0.6317750811576843
2022-11-03 00:23:59,096:INFO: 		 ADE on univ                      dataset:	 0.6316403746604919
2022-11-03 00:23:59,646:INFO: 		 ADE on zara1                     dataset:	 0.7724064588546753
2022-11-03 00:24:00,404:INFO: 		 ADE on zara2                     dataset:	 0.612835168838501
2022-11-03 00:24:00,404:INFO: Average training:	ADE  0.6368	FDE  1.1853
2022-11-03 00:24:00,412:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_348.pth.tar
2022-11-03 00:24:00,412:INFO: 
===> EPOCH: 349 (P3)
2022-11-03 00:24:00,413:INFO: - Computing loss (training)
2022-11-03 00:24:01,519:INFO: Batch:  0/31	Total Loss 5.4281 (5.4281)
2022-11-03 00:24:01,997:INFO: Batch:  1/31	Total Loss 5.5181 (5.4728)
2022-11-03 00:24:02,474:INFO: Batch:  2/31	Total Loss 5.0050 (5.3360)
2022-11-03 00:24:02,952:INFO: Batch:  3/31	Total Loss 5.2078 (5.3035)
2022-11-03 00:24:03,433:INFO: Batch:  4/31	Total Loss 5.6631 (5.3786)
2022-11-03 00:24:03,911:INFO: Batch:  5/31	Total Loss 5.7129 (5.4332)
2022-11-03 00:24:04,385:INFO: Batch:  6/31	Total Loss 5.8028 (5.4843)
2022-11-03 00:24:04,859:INFO: Batch:  7/31	Total Loss 5.4659 (5.4821)
2022-11-03 00:24:05,336:INFO: Batch:  8/31	Total Loss 6.0216 (5.5429)
2022-11-03 00:24:05,811:INFO: Batch:  9/31	Total Loss 5.2803 (5.5161)
2022-11-03 00:24:06,285:INFO: Batch: 10/31	Total Loss 5.8460 (5.5446)
2022-11-03 00:24:06,760:INFO: Batch: 11/31	Total Loss 5.3868 (5.5313)
2022-11-03 00:24:07,240:INFO: Batch: 12/31	Total Loss 5.3658 (5.5164)
2022-11-03 00:24:07,722:INFO: Batch: 13/31	Total Loss 5.8848 (5.5436)
2022-11-03 00:24:08,201:INFO: Batch: 14/31	Total Loss 5.4994 (5.5408)
2022-11-03 00:24:08,680:INFO: Batch: 15/31	Total Loss 4.9859 (5.5032)
2022-11-03 00:24:09,158:INFO: Batch: 16/31	Total Loss 5.9044 (5.5263)
2022-11-03 00:24:09,635:INFO: Batch: 17/31	Total Loss 4.8020 (5.4846)
2022-11-03 00:24:10,119:INFO: Batch: 18/31	Total Loss 5.9660 (5.5090)
2022-11-03 00:24:10,598:INFO: Batch: 19/31	Total Loss 5.2841 (5.4983)
2022-11-03 00:24:11,079:INFO: Batch: 20/31	Total Loss 5.3392 (5.4911)
2022-11-03 00:24:11,559:INFO: Batch: 21/31	Total Loss 5.2928 (5.4811)
2022-11-03 00:24:12,037:INFO: Batch: 22/31	Total Loss 5.3074 (5.4729)
2022-11-03 00:24:12,516:INFO: Batch: 23/31	Total Loss 5.1011 (5.4591)
2022-11-03 00:24:12,996:INFO: Batch: 24/31	Total Loss 5.0335 (5.4402)
2022-11-03 00:24:13,476:INFO: Batch: 25/31	Total Loss 5.5018 (5.4427)
2022-11-03 00:24:13,950:INFO: Batch: 26/31	Total Loss 5.1292 (5.4309)
2022-11-03 00:24:14,422:INFO: Batch: 27/31	Total Loss 5.0510 (5.4170)
2022-11-03 00:24:14,894:INFO: Batch: 28/31	Total Loss 5.2058 (5.4102)
2022-11-03 00:24:15,367:INFO: Batch: 29/31	Total Loss 4.9579 (5.3945)
2022-11-03 00:24:15,753:INFO: Batch: 30/31	Total Loss 1.9471 (5.3640)
2022-11-03 00:24:15,892:INFO: - Computing ADE (validation o)
2022-11-03 00:24:16,491:INFO: 		 ADE on eth                       dataset:	 1.1423900127410889
2022-11-03 00:24:16,491:INFO: Average validation o:	ADE  1.1424	FDE  1.8306
2022-11-03 00:24:16,492:INFO: - Computing ADE (validation)
2022-11-03 00:24:16,755:INFO: 		 ADE on hotel                     dataset:	 0.5234354734420776
2022-11-03 00:24:17,051:INFO: 		 ADE on univ                      dataset:	 0.6292558312416077
2022-11-03 00:24:17,303:INFO: 		 ADE on zara1                     dataset:	 0.6463704705238342
2022-11-03 00:24:17,639:INFO: 		 ADE on zara2                     dataset:	 0.5072969198226929
2022-11-03 00:24:17,639:INFO: Average validation:	ADE  0.5797	FDE  1.0281
2022-11-03 00:24:17,640:INFO: - Computing ADE (training)
2022-11-03 00:24:18,087:INFO: 		 ADE on hotel                     dataset:	 0.5954357981681824
2022-11-03 00:24:18,795:INFO: 		 ADE on univ                      dataset:	 0.5978105068206787
2022-11-03 00:24:19,324:INFO: 		 ADE on zara1                     dataset:	 0.7365160584449768
2022-11-03 00:24:20,084:INFO: 		 ADE on zara2                     dataset:	 0.5644378066062927
2022-11-03 00:24:20,084:INFO: Average training:	ADE  0.5998	FDE  1.0773
2022-11-03 00:24:20,093:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_349.pth.tar
2022-11-03 00:24:20,093:INFO: 
===> EPOCH: 350 (P3)
2022-11-03 00:24:20,093:INFO: - Computing loss (training)
2022-11-03 00:24:21,168:INFO: Batch:  0/31	Total Loss 4.7411 (4.7411)
2022-11-03 00:24:21,640:INFO: Batch:  1/31	Total Loss 5.1131 (4.9305)
2022-11-03 00:24:22,117:INFO: Batch:  2/31	Total Loss 5.3080 (5.0655)
2022-11-03 00:24:22,591:INFO: Batch:  3/31	Total Loss 6.6616 (5.4570)
2022-11-03 00:24:23,055:INFO: Batch:  4/31	Total Loss 5.5555 (5.4736)
2022-11-03 00:24:23,526:INFO: Batch:  5/31	Total Loss 6.2169 (5.5966)
2022-11-03 00:24:23,996:INFO: Batch:  6/31	Total Loss 5.4283 (5.5743)
2022-11-03 00:24:24,462:INFO: Batch:  7/31	Total Loss 6.0555 (5.6278)
2022-11-03 00:24:24,929:INFO: Batch:  8/31	Total Loss 6.0432 (5.6818)
2022-11-03 00:24:25,395:INFO: Batch:  9/31	Total Loss 5.0883 (5.6203)
2022-11-03 00:24:25,860:INFO: Batch: 10/31	Total Loss 5.5460 (5.6129)
2022-11-03 00:24:26,328:INFO: Batch: 11/31	Total Loss 4.8915 (5.5484)
2022-11-03 00:24:26,800:INFO: Batch: 12/31	Total Loss 4.8233 (5.4936)
2022-11-03 00:24:27,270:INFO: Batch: 13/31	Total Loss 5.1454 (5.4702)
2022-11-03 00:24:27,742:INFO: Batch: 14/31	Total Loss 4.7113 (5.4179)
2022-11-03 00:24:28,213:INFO: Batch: 15/31	Total Loss 5.1531 (5.4031)
2022-11-03 00:24:28,684:INFO: Batch: 16/31	Total Loss 5.5271 (5.4102)
2022-11-03 00:24:29,157:INFO: Batch: 17/31	Total Loss 5.1519 (5.3964)
2022-11-03 00:24:29,633:INFO: Batch: 18/31	Total Loss 5.0600 (5.3787)
2022-11-03 00:24:30,106:INFO: Batch: 19/31	Total Loss 4.9297 (5.3575)
2022-11-03 00:24:30,579:INFO: Batch: 20/31	Total Loss 4.3853 (5.3097)
2022-11-03 00:24:31,050:INFO: Batch: 21/31	Total Loss 4.8244 (5.2882)
2022-11-03 00:24:31,519:INFO: Batch: 22/31	Total Loss 5.6019 (5.3010)
2022-11-03 00:24:31,988:INFO: Batch: 23/31	Total Loss 5.7513 (5.3207)
2022-11-03 00:24:32,455:INFO: Batch: 24/31	Total Loss 5.1975 (5.3159)
2022-11-03 00:24:32,925:INFO: Batch: 25/31	Total Loss 5.4429 (5.3206)
2022-11-03 00:24:33,393:INFO: Batch: 26/31	Total Loss 5.1163 (5.3133)
2022-11-03 00:24:33,863:INFO: Batch: 27/31	Total Loss 5.2606 (5.3114)
2022-11-03 00:24:34,331:INFO: Batch: 28/31	Total Loss 4.8555 (5.2927)
2022-11-03 00:24:34,799:INFO: Batch: 29/31	Total Loss 5.0792 (5.2859)
2022-11-03 00:24:35,184:INFO: Batch: 30/31	Total Loss 1.9045 (5.2502)
2022-11-03 00:24:35,338:INFO: - Computing ADE (validation o)
2022-11-03 00:24:35,937:INFO: 		 ADE on eth                       dataset:	 1.1334507465362549
2022-11-03 00:24:35,937:INFO: Average validation o:	ADE  1.1335	FDE  1.8515
2022-11-03 00:24:35,937:INFO: - Computing ADE (validation)
2022-11-03 00:24:36,203:INFO: 		 ADE on hotel                     dataset:	 0.5068736672401428
2022-11-03 00:24:36,507:INFO: 		 ADE on univ                      dataset:	 0.6175426840782166
2022-11-03 00:24:36,760:INFO: 		 ADE on zara1                     dataset:	 0.6550557613372803
2022-11-03 00:24:37,094:INFO: 		 ADE on zara2                     dataset:	 0.5054978132247925
2022-11-03 00:24:37,095:INFO: Average validation:	ADE  0.5726	FDE  1.0322
2022-11-03 00:24:37,095:INFO: - Computing ADE (training)
2022-11-03 00:24:37,567:INFO: 		 ADE on hotel                     dataset:	 0.576339602470398
2022-11-03 00:24:38,302:INFO: 		 ADE on univ                      dataset:	 0.5956441760063171
2022-11-03 00:24:38,850:INFO: 		 ADE on zara1                     dataset:	 0.7149799466133118
2022-11-03 00:24:39,610:INFO: 		 ADE on zara2                     dataset:	 0.5520241260528564
2022-11-03 00:24:39,610:INFO: Average training:	ADE  0.5939	FDE  1.0866
2022-11-03 00:24:39,618:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_350.pth.tar
2022-11-03 00:24:39,619:INFO: 
===> EPOCH: 351 (P3)
2022-11-03 00:24:39,619:INFO: - Computing loss (training)
2022-11-03 00:24:40,702:INFO: Batch:  0/31	Total Loss 5.2885 (5.2885)
2022-11-03 00:24:41,181:INFO: Batch:  1/31	Total Loss 5.3155 (5.3006)
2022-11-03 00:24:41,661:INFO: Batch:  2/31	Total Loss 5.6795 (5.4289)
2022-11-03 00:24:42,135:INFO: Batch:  3/31	Total Loss 5.5899 (5.4648)
2022-11-03 00:24:42,688:INFO: Batch:  4/31	Total Loss 4.9896 (5.3674)
2022-11-03 00:24:43,163:INFO: Batch:  5/31	Total Loss 5.3305 (5.3610)
2022-11-03 00:24:43,634:INFO: Batch:  6/31	Total Loss 5.0368 (5.3150)
2022-11-03 00:24:44,105:INFO: Batch:  7/31	Total Loss 5.0417 (5.2807)
2022-11-03 00:24:44,578:INFO: Batch:  8/31	Total Loss 5.3726 (5.2908)
2022-11-03 00:24:45,049:INFO: Batch:  9/31	Total Loss 5.2921 (5.2910)
2022-11-03 00:24:45,523:INFO: Batch: 10/31	Total Loss 5.5681 (5.3166)
2022-11-03 00:24:45,995:INFO: Batch: 11/31	Total Loss 6.1204 (5.3832)
2022-11-03 00:24:46,472:INFO: Batch: 12/31	Total Loss 5.3213 (5.3786)
2022-11-03 00:24:46,947:INFO: Batch: 13/31	Total Loss 5.7573 (5.4038)
2022-11-03 00:24:47,424:INFO: Batch: 14/31	Total Loss 5.0440 (5.3784)
2022-11-03 00:24:47,902:INFO: Batch: 15/31	Total Loss 4.8767 (5.3465)
2022-11-03 00:24:48,378:INFO: Batch: 16/31	Total Loss 5.4020 (5.3498)
2022-11-03 00:24:48,852:INFO: Batch: 17/31	Total Loss 5.3598 (5.3503)
2022-11-03 00:24:49,327:INFO: Batch: 18/31	Total Loss 5.1709 (5.3406)
2022-11-03 00:24:49,805:INFO: Batch: 19/31	Total Loss 5.5123 (5.3477)
2022-11-03 00:24:50,283:INFO: Batch: 20/31	Total Loss 4.7485 (5.3195)
2022-11-03 00:24:50,758:INFO: Batch: 21/31	Total Loss 5.6435 (5.3350)
2022-11-03 00:24:51,232:INFO: Batch: 22/31	Total Loss 5.0251 (5.3218)
2022-11-03 00:24:51,708:INFO: Batch: 23/31	Total Loss 5.0533 (5.3108)
2022-11-03 00:24:52,184:INFO: Batch: 24/31	Total Loss 5.2014 (5.3066)
2022-11-03 00:24:52,661:INFO: Batch: 25/31	Total Loss 5.6149 (5.3198)
2022-11-03 00:24:53,137:INFO: Batch: 26/31	Total Loss 5.0751 (5.3112)
2022-11-03 00:24:53,612:INFO: Batch: 27/31	Total Loss 5.0775 (5.3026)
2022-11-03 00:24:54,086:INFO: Batch: 28/31	Total Loss 5.2275 (5.3001)
2022-11-03 00:24:54,561:INFO: Batch: 29/31	Total Loss 4.9827 (5.2903)
2022-11-03 00:24:54,950:INFO: Batch: 30/31	Total Loss 2.1173 (5.2631)
2022-11-03 00:24:55,093:INFO: - Computing ADE (validation o)
2022-11-03 00:24:55,696:INFO: 		 ADE on eth                       dataset:	 1.1451961994171143
2022-11-03 00:24:55,696:INFO: Average validation o:	ADE  1.1452	FDE  1.8655
2022-11-03 00:24:55,696:INFO: - Computing ADE (validation)
2022-11-03 00:24:55,943:INFO: 		 ADE on hotel                     dataset:	 0.5270718932151794
2022-11-03 00:24:56,236:INFO: 		 ADE on univ                      dataset:	 0.6246495246887207
2022-11-03 00:24:56,482:INFO: 		 ADE on zara1                     dataset:	 0.6707931160926819
2022-11-03 00:24:56,835:INFO: 		 ADE on zara2                     dataset:	 0.51613450050354
2022-11-03 00:24:56,835:INFO: Average validation:	ADE  0.5822	FDE  1.0438
2022-11-03 00:24:56,835:INFO: - Computing ADE (training)
2022-11-03 00:24:57,289:INFO: 		 ADE on hotel                     dataset:	 0.6051427721977234
2022-11-03 00:24:57,962:INFO: 		 ADE on univ                      dataset:	 0.6033558249473572
2022-11-03 00:24:58,484:INFO: 		 ADE on zara1                     dataset:	 0.7396445274353027
2022-11-03 00:24:59,258:INFO: 		 ADE on zara2                     dataset:	 0.5670011639595032
2022-11-03 00:24:59,258:INFO: Average training:	ADE  0.6047	FDE  1.0991
2022-11-03 00:24:59,267:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_351.pth.tar
2022-11-03 00:24:59,267:INFO: 
===> EPOCH: 352 (P3)
2022-11-03 00:24:59,268:INFO: - Computing loss (training)
2022-11-03 00:25:00,380:INFO: Batch:  0/31	Total Loss 4.7979 (4.7979)
2022-11-03 00:25:00,853:INFO: Batch:  1/31	Total Loss 5.1015 (4.9363)
2022-11-03 00:25:01,330:INFO: Batch:  2/31	Total Loss 5.6161 (5.1665)
2022-11-03 00:25:01,803:INFO: Batch:  3/31	Total Loss 5.6390 (5.2837)
2022-11-03 00:25:02,290:INFO: Batch:  4/31	Total Loss 4.5055 (5.1103)
2022-11-03 00:25:02,783:INFO: Batch:  5/31	Total Loss 5.0855 (5.1062)
2022-11-03 00:25:03,275:INFO: Batch:  6/31	Total Loss 4.7033 (5.0443)
2022-11-03 00:25:03,805:INFO: Batch:  7/31	Total Loss 5.9743 (5.1561)
2022-11-03 00:25:04,526:INFO: Batch:  8/31	Total Loss 5.3949 (5.1831)
2022-11-03 00:25:05,159:INFO: Batch:  9/31	Total Loss 4.9381 (5.1569)
2022-11-03 00:25:05,694:INFO: Batch: 10/31	Total Loss 5.4756 (5.1827)
2022-11-03 00:25:06,198:INFO: Batch: 11/31	Total Loss 6.1312 (5.2689)
2022-11-03 00:25:06,715:INFO: Batch: 12/31	Total Loss 5.0587 (5.2531)
2022-11-03 00:25:07,246:INFO: Batch: 13/31	Total Loss 5.1316 (5.2440)
2022-11-03 00:25:07,780:INFO: Batch: 14/31	Total Loss 5.1170 (5.2359)
2022-11-03 00:25:08,265:INFO: Batch: 15/31	Total Loss 4.9062 (5.2171)
2022-11-03 00:25:08,778:INFO: Batch: 16/31	Total Loss 4.6249 (5.1823)
2022-11-03 00:25:09,264:INFO: Batch: 17/31	Total Loss 5.4082 (5.1953)
2022-11-03 00:25:09,755:INFO: Batch: 18/31	Total Loss 5.7606 (5.2242)
2022-11-03 00:25:10,268:INFO: Batch: 19/31	Total Loss 5.9996 (5.2621)
2022-11-03 00:25:10,811:INFO: Batch: 20/31	Total Loss 4.8649 (5.2444)
2022-11-03 00:25:11,365:INFO: Batch: 21/31	Total Loss 5.5215 (5.2565)
2022-11-03 00:25:11,889:INFO: Batch: 22/31	Total Loss 5.1942 (5.2540)
2022-11-03 00:25:12,459:INFO: Batch: 23/31	Total Loss 4.9963 (5.2432)
2022-11-03 00:25:12,965:INFO: Batch: 24/31	Total Loss 5.8955 (5.2685)
2022-11-03 00:25:13,505:INFO: Batch: 25/31	Total Loss 5.8976 (5.2937)
2022-11-03 00:25:14,040:INFO: Batch: 26/31	Total Loss 5.4636 (5.2994)
2022-11-03 00:25:14,537:INFO: Batch: 27/31	Total Loss 4.8933 (5.2847)
2022-11-03 00:25:15,047:INFO: Batch: 28/31	Total Loss 5.2735 (5.2844)
2022-11-03 00:25:15,581:INFO: Batch: 29/31	Total Loss 4.9885 (5.2746)
2022-11-03 00:25:16,007:INFO: Batch: 30/31	Total Loss 1.7229 (5.2408)
2022-11-03 00:25:16,169:INFO: - Computing ADE (validation o)
2022-11-03 00:25:16,799:INFO: 		 ADE on eth                       dataset:	 1.1483246088027954
2022-11-03 00:25:16,799:INFO: Average validation o:	ADE  1.1483	FDE  1.8639
2022-11-03 00:25:16,800:INFO: - Computing ADE (validation)
2022-11-03 00:25:17,168:INFO: 		 ADE on hotel                     dataset:	 0.5557494759559631
2022-11-03 00:25:17,582:INFO: 		 ADE on univ                      dataset:	 0.6497501730918884
2022-11-03 00:25:17,980:INFO: 		 ADE on zara1                     dataset:	 0.6292188167572021
2022-11-03 00:25:18,333:INFO: 		 ADE on zara2                     dataset:	 0.5220109224319458
2022-11-03 00:25:18,333:INFO: Average validation:	ADE  0.5966	FDE  1.0883
2022-11-03 00:25:18,333:INFO: - Computing ADE (training)
2022-11-03 00:25:18,823:INFO: 		 ADE on hotel                     dataset:	 0.6328811049461365
2022-11-03 00:25:19,514:INFO: 		 ADE on univ                      dataset:	 0.6106398105621338
2022-11-03 00:25:20,059:INFO: 		 ADE on zara1                     dataset:	 0.7295805811882019
2022-11-03 00:25:20,897:INFO: 		 ADE on zara2                     dataset:	 0.5799592733383179
2022-11-03 00:25:20,898:INFO: Average training:	ADE  0.6126	FDE  1.1253
2022-11-03 00:25:20,911:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_352.pth.tar
2022-11-03 00:25:20,911:INFO: 
===> EPOCH: 353 (P3)
2022-11-03 00:25:20,912:INFO: - Computing loss (training)
2022-11-03 00:25:22,056:INFO: Batch:  0/31	Total Loss 5.5244 (5.5244)
2022-11-03 00:25:22,535:INFO: Batch:  1/31	Total Loss 5.5954 (5.5613)
2022-11-03 00:25:23,016:INFO: Batch:  2/31	Total Loss 4.6948 (5.2262)
2022-11-03 00:25:23,493:INFO: Batch:  3/31	Total Loss 5.8677 (5.3759)
2022-11-03 00:25:23,971:INFO: Batch:  4/31	Total Loss 5.0840 (5.3164)
2022-11-03 00:25:24,465:INFO: Batch:  5/31	Total Loss 5.6396 (5.3710)
2022-11-03 00:25:24,951:INFO: Batch:  6/31	Total Loss 5.4689 (5.3860)
2022-11-03 00:25:25,436:INFO: Batch:  7/31	Total Loss 5.2535 (5.3711)
2022-11-03 00:25:25,921:INFO: Batch:  8/31	Total Loss 5.2341 (5.3558)
2022-11-03 00:25:26,409:INFO: Batch:  9/31	Total Loss 5.5799 (5.3791)
2022-11-03 00:25:26,888:INFO: Batch: 10/31	Total Loss 5.3485 (5.3764)
2022-11-03 00:25:27,367:INFO: Batch: 11/31	Total Loss 5.0621 (5.3508)
2022-11-03 00:25:27,852:INFO: Batch: 12/31	Total Loss 5.4284 (5.3566)
2022-11-03 00:25:28,337:INFO: Batch: 13/31	Total Loss 4.7576 (5.3060)
2022-11-03 00:25:28,820:INFO: Batch: 14/31	Total Loss 4.5905 (5.2603)
2022-11-03 00:25:29,302:INFO: Batch: 15/31	Total Loss 4.4726 (5.2102)
2022-11-03 00:25:29,785:INFO: Batch: 16/31	Total Loss 5.0721 (5.2014)
2022-11-03 00:25:30,267:INFO: Batch: 17/31	Total Loss 5.6254 (5.2232)
2022-11-03 00:25:30,750:INFO: Batch: 18/31	Total Loss 5.3418 (5.2297)
2022-11-03 00:25:31,228:INFO: Batch: 19/31	Total Loss 4.6023 (5.1976)
2022-11-03 00:25:31,706:INFO: Batch: 20/31	Total Loss 6.4160 (5.2502)
2022-11-03 00:25:32,184:INFO: Batch: 21/31	Total Loss 4.7241 (5.2280)
2022-11-03 00:25:32,664:INFO: Batch: 22/31	Total Loss 5.1708 (5.2254)
2022-11-03 00:25:33,144:INFO: Batch: 23/31	Total Loss 4.8292 (5.2099)
2022-11-03 00:25:33,623:INFO: Batch: 24/31	Total Loss 5.0432 (5.2031)
2022-11-03 00:25:34,102:INFO: Batch: 25/31	Total Loss 4.5709 (5.1781)
2022-11-03 00:25:34,581:INFO: Batch: 26/31	Total Loss 4.9693 (5.1690)
2022-11-03 00:25:35,060:INFO: Batch: 27/31	Total Loss 4.7312 (5.1535)
2022-11-03 00:25:35,536:INFO: Batch: 28/31	Total Loss 5.0689 (5.1511)
2022-11-03 00:25:36,093:INFO: Batch: 29/31	Total Loss 5.4626 (5.1613)
2022-11-03 00:25:36,485:INFO: Batch: 30/31	Total Loss 2.4548 (5.1367)
2022-11-03 00:25:36,645:INFO: - Computing ADE (validation o)
2022-11-03 00:25:37,293:INFO: 		 ADE on eth                       dataset:	 1.1250853538513184
2022-11-03 00:25:37,293:INFO: Average validation o:	ADE  1.1251	FDE  1.8765
2022-11-03 00:25:37,294:INFO: - Computing ADE (validation)
2022-11-03 00:25:37,623:INFO: 		 ADE on hotel                     dataset:	 0.5137581825256348
2022-11-03 00:25:37,924:INFO: 		 ADE on univ                      dataset:	 0.6158761382102966
2022-11-03 00:25:38,183:INFO: 		 ADE on zara1                     dataset:	 0.6444719433784485
2022-11-03 00:25:38,527:INFO: 		 ADE on zara2                     dataset:	 0.5016459226608276
2022-11-03 00:25:38,527:INFO: Average validation:	ADE  0.5700	FDE  1.0301
2022-11-03 00:25:38,528:INFO: - Computing ADE (training)
2022-11-03 00:25:38,994:INFO: 		 ADE on hotel                     dataset:	 0.5807717442512512
2022-11-03 00:25:39,687:INFO: 		 ADE on univ                      dataset:	 0.5953761339187622
2022-11-03 00:25:40,229:INFO: 		 ADE on zara1                     dataset:	 0.7094560861587524
2022-11-03 00:25:40,999:INFO: 		 ADE on zara2                     dataset:	 0.5480234026908875
2022-11-03 00:25:41,000:INFO: Average training:	ADE  0.5927	FDE  1.0869
2022-11-03 00:25:41,009:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_353.pth.tar
2022-11-03 00:25:41,009:INFO: 
===> EPOCH: 354 (P3)
2022-11-03 00:25:41,009:INFO: - Computing loss (training)
2022-11-03 00:25:42,112:INFO: Batch:  0/31	Total Loss 5.5568 (5.5568)
2022-11-03 00:25:42,587:INFO: Batch:  1/31	Total Loss 4.8052 (5.1787)
2022-11-03 00:25:43,066:INFO: Batch:  2/31	Total Loss 5.1696 (5.1754)
2022-11-03 00:25:43,548:INFO: Batch:  3/31	Total Loss 5.1067 (5.1577)
2022-11-03 00:25:44,022:INFO: Batch:  4/31	Total Loss 5.3121 (5.1870)
2022-11-03 00:25:44,502:INFO: Batch:  5/31	Total Loss 5.6808 (5.2677)
2022-11-03 00:25:44,980:INFO: Batch:  6/31	Total Loss 5.9301 (5.3680)
2022-11-03 00:25:45,456:INFO: Batch:  7/31	Total Loss 4.8155 (5.3011)
2022-11-03 00:25:45,926:INFO: Batch:  8/31	Total Loss 5.3166 (5.3030)
2022-11-03 00:25:46,395:INFO: Batch:  9/31	Total Loss 5.6527 (5.3375)
2022-11-03 00:25:46,864:INFO: Batch: 10/31	Total Loss 5.4026 (5.3434)
2022-11-03 00:25:47,334:INFO: Batch: 11/31	Total Loss 5.1796 (5.3298)
2022-11-03 00:25:47,807:INFO: Batch: 12/31	Total Loss 5.6650 (5.3550)
2022-11-03 00:25:48,283:INFO: Batch: 13/31	Total Loss 6.2358 (5.4209)
2022-11-03 00:25:48,755:INFO: Batch: 14/31	Total Loss 5.0000 (5.3917)
2022-11-03 00:25:49,228:INFO: Batch: 15/31	Total Loss 5.6391 (5.4077)
2022-11-03 00:25:49,701:INFO: Batch: 16/31	Total Loss 5.1658 (5.3933)
2022-11-03 00:25:50,179:INFO: Batch: 17/31	Total Loss 5.6392 (5.4080)
2022-11-03 00:25:50,652:INFO: Batch: 18/31	Total Loss 5.0339 (5.3886)
2022-11-03 00:25:51,123:INFO: Batch: 19/31	Total Loss 5.0286 (5.3685)
2022-11-03 00:25:51,595:INFO: Batch: 20/31	Total Loss 5.4559 (5.3725)
2022-11-03 00:25:52,068:INFO: Batch: 21/31	Total Loss 5.3881 (5.3733)
2022-11-03 00:25:52,540:INFO: Batch: 22/31	Total Loss 5.6125 (5.3851)
2022-11-03 00:25:53,011:INFO: Batch: 23/31	Total Loss 5.2947 (5.3814)
2022-11-03 00:25:53,483:INFO: Batch: 24/31	Total Loss 5.0998 (5.3698)
2022-11-03 00:25:53,955:INFO: Batch: 25/31	Total Loss 5.4273 (5.3722)
2022-11-03 00:25:54,427:INFO: Batch: 26/31	Total Loss 4.9592 (5.3563)
2022-11-03 00:25:54,898:INFO: Batch: 27/31	Total Loss 4.8805 (5.3383)
2022-11-03 00:25:55,369:INFO: Batch: 28/31	Total Loss 6.3179 (5.3696)
2022-11-03 00:25:55,843:INFO: Batch: 29/31	Total Loss 5.0924 (5.3589)
2022-11-03 00:25:56,232:INFO: Batch: 30/31	Total Loss 1.8324 (5.3262)
2022-11-03 00:25:56,388:INFO: - Computing ADE (validation o)
2022-11-03 00:25:57,008:INFO: 		 ADE on eth                       dataset:	 1.1454261541366577
2022-11-03 00:25:57,008:INFO: Average validation o:	ADE  1.1454	FDE  1.8332
2022-11-03 00:25:57,009:INFO: - Computing ADE (validation)
2022-11-03 00:25:57,282:INFO: 		 ADE on hotel                     dataset:	 0.5471176505088806
2022-11-03 00:25:57,595:INFO: 		 ADE on univ                      dataset:	 0.6352086663246155
2022-11-03 00:25:57,833:INFO: 		 ADE on zara1                     dataset:	 0.6130326986312866
2022-11-03 00:25:58,171:INFO: 		 ADE on zara2                     dataset:	 0.517004668712616
2022-11-03 00:25:58,171:INFO: Average validation:	ADE  0.5857	FDE  1.0611
2022-11-03 00:25:58,172:INFO: - Computing ADE (training)
2022-11-03 00:25:58,614:INFO: 		 ADE on hotel                     dataset:	 0.6234855651855469
2022-11-03 00:25:59,331:INFO: 		 ADE on univ                      dataset:	 0.6034154295921326
2022-11-03 00:25:59,866:INFO: 		 ADE on zara1                     dataset:	 0.7263486385345459
2022-11-03 00:26:00,631:INFO: 		 ADE on zara2                     dataset:	 0.5697911977767944
2022-11-03 00:26:00,632:INFO: Average training:	ADE  0.6049	FDE  1.1030
2022-11-03 00:26:00,640:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_354.pth.tar
2022-11-03 00:26:00,640:INFO: 
===> EPOCH: 355 (P3)
2022-11-03 00:26:00,641:INFO: - Computing loss (training)
2022-11-03 00:26:01,757:INFO: Batch:  0/31	Total Loss 4.6814 (4.6814)
2022-11-03 00:26:02,239:INFO: Batch:  1/31	Total Loss 4.5958 (4.6340)
2022-11-03 00:26:02,717:INFO: Batch:  2/31	Total Loss 4.7438 (4.6718)
2022-11-03 00:26:03,205:INFO: Batch:  3/31	Total Loss 5.3384 (4.8427)
2022-11-03 00:26:03,698:INFO: Batch:  4/31	Total Loss 5.3666 (4.9498)
2022-11-03 00:26:04,190:INFO: Batch:  5/31	Total Loss 5.7091 (5.0622)
2022-11-03 00:26:04,682:INFO: Batch:  6/31	Total Loss 5.1872 (5.0803)
2022-11-03 00:26:05,172:INFO: Batch:  7/31	Total Loss 5.5789 (5.1420)
2022-11-03 00:26:05,662:INFO: Batch:  8/31	Total Loss 6.2072 (5.2610)
2022-11-03 00:26:06,151:INFO: Batch:  9/31	Total Loss 4.8207 (5.2221)
2022-11-03 00:26:06,643:INFO: Batch: 10/31	Total Loss 5.1162 (5.2128)
2022-11-03 00:26:07,123:INFO: Batch: 11/31	Total Loss 6.3021 (5.2928)
2022-11-03 00:26:07,616:INFO: Batch: 12/31	Total Loss 5.4785 (5.3058)
2022-11-03 00:26:08,096:INFO: Batch: 13/31	Total Loss 5.4239 (5.3144)
2022-11-03 00:26:08,590:INFO: Batch: 14/31	Total Loss 5.5137 (5.3265)
2022-11-03 00:26:09,076:INFO: Batch: 15/31	Total Loss 4.9405 (5.3033)
2022-11-03 00:26:09,566:INFO: Batch: 16/31	Total Loss 5.4943 (5.3147)
2022-11-03 00:26:10,059:INFO: Batch: 17/31	Total Loss 5.3382 (5.3160)
2022-11-03 00:26:10,546:INFO: Batch: 18/31	Total Loss 5.0942 (5.3041)
2022-11-03 00:26:11,030:INFO: Batch: 19/31	Total Loss 4.6295 (5.2686)
2022-11-03 00:26:11,519:INFO: Batch: 20/31	Total Loss 4.9715 (5.2538)
2022-11-03 00:26:12,003:INFO: Batch: 21/31	Total Loss 5.5578 (5.2667)
2022-11-03 00:26:12,490:INFO: Batch: 22/31	Total Loss 4.8913 (5.2516)
2022-11-03 00:26:12,990:INFO: Batch: 23/31	Total Loss 4.8095 (5.2330)
2022-11-03 00:26:13,504:INFO: Batch: 24/31	Total Loss 5.9340 (5.2612)
2022-11-03 00:26:14,000:INFO: Batch: 25/31	Total Loss 4.8050 (5.2443)
2022-11-03 00:26:14,522:INFO: Batch: 26/31	Total Loss 5.1647 (5.2412)
2022-11-03 00:26:15,022:INFO: Batch: 27/31	Total Loss 5.4387 (5.2491)
2022-11-03 00:26:15,518:INFO: Batch: 28/31	Total Loss 4.5597 (5.2246)
2022-11-03 00:26:16,018:INFO: Batch: 29/31	Total Loss 4.6649 (5.2053)
2022-11-03 00:26:16,423:INFO: Batch: 30/31	Total Loss 2.0640 (5.1719)
2022-11-03 00:26:16,568:INFO: - Computing ADE (validation o)
2022-11-03 00:26:17,187:INFO: 		 ADE on eth                       dataset:	 1.1326558589935303
2022-11-03 00:26:17,188:INFO: Average validation o:	ADE  1.1327	FDE  1.8147
2022-11-03 00:26:17,188:INFO: - Computing ADE (validation)
2022-11-03 00:26:17,477:INFO: 		 ADE on hotel                     dataset:	 0.5144630074501038
2022-11-03 00:26:17,776:INFO: 		 ADE on univ                      dataset:	 0.6206448674201965
2022-11-03 00:26:18,039:INFO: 		 ADE on zara1                     dataset:	 0.6218678951263428
2022-11-03 00:26:18,379:INFO: 		 ADE on zara2                     dataset:	 0.5009347796440125
2022-11-03 00:26:18,379:INFO: Average validation:	ADE  0.5710	FDE  1.0254
2022-11-03 00:26:18,388:INFO: - Computing ADE (training)
2022-11-03 00:26:18,858:INFO: 		 ADE on hotel                     dataset:	 0.580401599407196
2022-11-03 00:26:19,534:INFO: 		 ADE on univ                      dataset:	 0.5918410420417786
2022-11-03 00:26:20,064:INFO: 		 ADE on zara1                     dataset:	 0.7182120084762573
2022-11-03 00:26:20,820:INFO: 		 ADE on zara2                     dataset:	 0.5527581572532654
2022-11-03 00:26:20,821:INFO: Average training:	ADE  0.5917	FDE  1.0774
2022-11-03 00:26:20,830:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_355.pth.tar
2022-11-03 00:26:20,830:INFO: 
===> EPOCH: 356 (P3)
2022-11-03 00:26:20,830:INFO: - Computing loss (training)
2022-11-03 00:26:21,903:INFO: Batch:  0/31	Total Loss 4.4650 (4.4650)
2022-11-03 00:26:22,381:INFO: Batch:  1/31	Total Loss 4.4291 (4.4478)
2022-11-03 00:26:22,861:INFO: Batch:  2/31	Total Loss 5.1329 (4.7009)
2022-11-03 00:26:23,356:INFO: Batch:  3/31	Total Loss 4.8221 (4.7310)
2022-11-03 00:26:23,844:INFO: Batch:  4/31	Total Loss 5.3089 (4.8472)
2022-11-03 00:26:24,336:INFO: Batch:  5/31	Total Loss 4.9420 (4.8626)
2022-11-03 00:26:24,820:INFO: Batch:  6/31	Total Loss 5.4238 (4.9437)
2022-11-03 00:26:25,310:INFO: Batch:  7/31	Total Loss 5.3828 (5.0029)
2022-11-03 00:26:25,788:INFO: Batch:  8/31	Total Loss 5.1497 (5.0188)
2022-11-03 00:26:26,267:INFO: Batch:  9/31	Total Loss 4.9475 (5.0114)
2022-11-03 00:26:26,745:INFO: Batch: 10/31	Total Loss 5.4607 (5.0519)
2022-11-03 00:26:27,220:INFO: Batch: 11/31	Total Loss 5.1125 (5.0568)
2022-11-03 00:26:27,700:INFO: Batch: 12/31	Total Loss 4.9885 (5.0517)
2022-11-03 00:26:28,179:INFO: Batch: 13/31	Total Loss 4.9160 (5.0417)
2022-11-03 00:26:28,660:INFO: Batch: 14/31	Total Loss 4.8242 (5.0274)
2022-11-03 00:26:29,139:INFO: Batch: 15/31	Total Loss 4.9993 (5.0255)
2022-11-03 00:26:29,632:INFO: Batch: 16/31	Total Loss 5.0504 (5.0270)
2022-11-03 00:26:30,116:INFO: Batch: 17/31	Total Loss 5.1602 (5.0344)
2022-11-03 00:26:30,676:INFO: Batch: 18/31	Total Loss 5.4170 (5.0544)
2022-11-03 00:26:31,155:INFO: Batch: 19/31	Total Loss 5.4071 (5.0696)
2022-11-03 00:26:31,632:INFO: Batch: 20/31	Total Loss 4.4910 (5.0411)
2022-11-03 00:26:32,110:INFO: Batch: 21/31	Total Loss 4.8906 (5.0354)
2022-11-03 00:26:32,588:INFO: Batch: 22/31	Total Loss 5.6084 (5.0629)
2022-11-03 00:26:33,069:INFO: Batch: 23/31	Total Loss 4.9613 (5.0586)
2022-11-03 00:26:33,547:INFO: Batch: 24/31	Total Loss 5.3526 (5.0694)
2022-11-03 00:26:34,026:INFO: Batch: 25/31	Total Loss 5.1165 (5.0714)
2022-11-03 00:26:34,505:INFO: Batch: 26/31	Total Loss 4.8327 (5.0616)
2022-11-03 00:26:34,982:INFO: Batch: 27/31	Total Loss 5.4692 (5.0767)
2022-11-03 00:26:35,458:INFO: Batch: 28/31	Total Loss 4.7869 (5.0675)
2022-11-03 00:26:35,937:INFO: Batch: 29/31	Total Loss 5.9160 (5.0941)
2022-11-03 00:26:36,327:INFO: Batch: 30/31	Total Loss 1.8953 (5.0645)
2022-11-03 00:26:36,485:INFO: - Computing ADE (validation o)
2022-11-03 00:26:37,080:INFO: 		 ADE on eth                       dataset:	 1.120381474494934
2022-11-03 00:26:37,081:INFO: Average validation o:	ADE  1.1204	FDE  1.8594
2022-11-03 00:26:37,081:INFO: - Computing ADE (validation)
2022-11-03 00:26:37,347:INFO: 		 ADE on hotel                     dataset:	 0.5148850679397583
2022-11-03 00:26:37,658:INFO: 		 ADE on univ                      dataset:	 0.615066409111023
2022-11-03 00:26:37,905:INFO: 		 ADE on zara1                     dataset:	 0.6471404433250427
2022-11-03 00:26:38,246:INFO: 		 ADE on zara2                     dataset:	 0.49994680285453796
2022-11-03 00:26:38,247:INFO: Average validation:	ADE  0.5692	FDE  1.0337
2022-11-03 00:26:38,248:INFO: - Computing ADE (training)
2022-11-03 00:26:38,712:INFO: 		 ADE on hotel                     dataset:	 0.5800752639770508
2022-11-03 00:26:39,419:INFO: 		 ADE on univ                      dataset:	 0.5933043956756592
2022-11-03 00:26:39,956:INFO: 		 ADE on zara1                     dataset:	 0.7105868458747864
2022-11-03 00:26:40,690:INFO: 		 ADE on zara2                     dataset:	 0.5471602082252502
2022-11-03 00:26:40,690:INFO: Average training:	ADE  0.5911	FDE  1.0874
2022-11-03 00:26:40,699:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_356.pth.tar
2022-11-03 00:26:40,699:INFO: 
===> EPOCH: 357 (P3)
2022-11-03 00:26:40,699:INFO: - Computing loss (training)
2022-11-03 00:26:41,791:INFO: Batch:  0/31	Total Loss 5.4863 (5.4863)
2022-11-03 00:26:42,267:INFO: Batch:  1/31	Total Loss 4.7269 (5.0938)
2022-11-03 00:26:42,737:INFO: Batch:  2/31	Total Loss 4.9138 (5.0340)
2022-11-03 00:26:43,202:INFO: Batch:  3/31	Total Loss 6.0192 (5.2756)
2022-11-03 00:26:43,669:INFO: Batch:  4/31	Total Loss 5.4175 (5.3022)
2022-11-03 00:26:44,140:INFO: Batch:  5/31	Total Loss 4.7617 (5.2150)
2022-11-03 00:26:44,609:INFO: Batch:  6/31	Total Loss 4.9734 (5.1814)
2022-11-03 00:26:45,078:INFO: Batch:  7/31	Total Loss 6.3554 (5.3363)
2022-11-03 00:26:45,546:INFO: Batch:  8/31	Total Loss 4.5735 (5.2609)
2022-11-03 00:26:46,016:INFO: Batch:  9/31	Total Loss 5.1591 (5.2509)
2022-11-03 00:26:46,481:INFO: Batch: 10/31	Total Loss 5.1916 (5.2459)
2022-11-03 00:26:46,958:INFO: Batch: 11/31	Total Loss 5.0590 (5.2303)
2022-11-03 00:26:47,433:INFO: Batch: 12/31	Total Loss 5.6520 (5.2613)
2022-11-03 00:26:47,903:INFO: Batch: 13/31	Total Loss 6.0058 (5.3126)
2022-11-03 00:26:48,380:INFO: Batch: 14/31	Total Loss 6.1675 (5.3701)
2022-11-03 00:26:48,857:INFO: Batch: 15/31	Total Loss 5.0597 (5.3510)
2022-11-03 00:26:49,334:INFO: Batch: 16/31	Total Loss 5.8926 (5.3803)
2022-11-03 00:26:49,821:INFO: Batch: 17/31	Total Loss 5.1374 (5.3664)
2022-11-03 00:26:50,306:INFO: Batch: 18/31	Total Loss 5.8003 (5.3901)
2022-11-03 00:26:50,809:INFO: Batch: 19/31	Total Loss 5.8813 (5.4154)
2022-11-03 00:26:51,483:INFO: Batch: 20/31	Total Loss 5.4549 (5.4176)
2022-11-03 00:26:51,999:INFO: Batch: 21/31	Total Loss 5.6343 (5.4282)
2022-11-03 00:26:52,595:INFO: Batch: 22/31	Total Loss 5.2044 (5.4175)
2022-11-03 00:26:53,123:INFO: Batch: 23/31	Total Loss 4.7233 (5.3855)
2022-11-03 00:26:53,669:INFO: Batch: 24/31	Total Loss 4.7969 (5.3605)
2022-11-03 00:26:54,218:INFO: Batch: 25/31	Total Loss 5.1018 (5.3508)
2022-11-03 00:26:54,747:INFO: Batch: 26/31	Total Loss 4.7141 (5.3302)
2022-11-03 00:26:55,297:INFO: Batch: 27/31	Total Loss 4.7568 (5.3102)
2022-11-03 00:26:55,812:INFO: Batch: 28/31	Total Loss 4.5474 (5.2848)
2022-11-03 00:26:56,324:INFO: Batch: 29/31	Total Loss 5.0439 (5.2775)
2022-11-03 00:26:56,755:INFO: Batch: 30/31	Total Loss 2.0638 (5.2469)
2022-11-03 00:26:56,914:INFO: - Computing ADE (validation o)
2022-11-03 00:26:57,531:INFO: 		 ADE on eth                       dataset:	 1.1040468215942383
2022-11-03 00:26:57,532:INFO: Average validation o:	ADE  1.1040	FDE  1.8067
2022-11-03 00:26:57,533:INFO: - Computing ADE (validation)
2022-11-03 00:26:57,840:INFO: 		 ADE on hotel                     dataset:	 0.52047199010849
2022-11-03 00:26:58,167:INFO: 		 ADE on univ                      dataset:	 0.6186764240264893
2022-11-03 00:26:58,440:INFO: 		 ADE on zara1                     dataset:	 0.5841602087020874
2022-11-03 00:26:58,815:INFO: 		 ADE on zara2                     dataset:	 0.482576459646225
2022-11-03 00:26:58,815:INFO: Average validation:	ADE  0.5614	FDE  1.0241
2022-11-03 00:26:58,816:INFO: - Computing ADE (training)
2022-11-03 00:26:59,260:INFO: 		 ADE on hotel                     dataset:	 0.5870009064674377
2022-11-03 00:27:00,007:INFO: 		 ADE on univ                      dataset:	 0.5881667733192444
2022-11-03 00:27:00,580:INFO: 		 ADE on zara1                     dataset:	 0.6700771450996399
2022-11-03 00:27:01,417:INFO: 		 ADE on zara2                     dataset:	 0.5257822275161743
2022-11-03 00:27:01,417:INFO: Average training:	ADE  0.5807	FDE  1.0708
2022-11-03 00:27:01,427:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_357.pth.tar
2022-11-03 00:27:01,428:INFO: 
===> EPOCH: 358 (P3)
2022-11-03 00:27:01,428:INFO: - Computing loss (training)
2022-11-03 00:27:02,915:INFO: Batch:  0/31	Total Loss 5.0529 (5.0529)
2022-11-03 00:27:03,403:INFO: Batch:  1/31	Total Loss 4.4612 (4.7729)
2022-11-03 00:27:03,879:INFO: Batch:  2/31	Total Loss 5.6430 (5.0585)
2022-11-03 00:27:04,356:INFO: Batch:  3/31	Total Loss 5.0640 (5.0599)
2022-11-03 00:27:04,845:INFO: Batch:  4/31	Total Loss 4.9957 (5.0467)
2022-11-03 00:27:05,326:INFO: Batch:  5/31	Total Loss 4.9774 (5.0358)
2022-11-03 00:27:05,807:INFO: Batch:  6/31	Total Loss 7.1105 (5.2933)
2022-11-03 00:27:06,285:INFO: Batch:  7/31	Total Loss 6.0144 (5.3789)
2022-11-03 00:27:06,762:INFO: Batch:  8/31	Total Loss 5.4912 (5.3909)
2022-11-03 00:27:07,240:INFO: Batch:  9/31	Total Loss 5.1960 (5.3713)
2022-11-03 00:27:07,718:INFO: Batch: 10/31	Total Loss 5.0962 (5.3463)
2022-11-03 00:27:08,199:INFO: Batch: 11/31	Total Loss 4.8158 (5.2962)
2022-11-03 00:27:08,682:INFO: Batch: 12/31	Total Loss 5.9719 (5.3500)
2022-11-03 00:27:09,159:INFO: Batch: 13/31	Total Loss 5.5668 (5.3649)
2022-11-03 00:27:09,633:INFO: Batch: 14/31	Total Loss 4.7899 (5.3259)
2022-11-03 00:27:10,112:INFO: Batch: 15/31	Total Loss 4.7379 (5.2930)
2022-11-03 00:27:10,592:INFO: Batch: 16/31	Total Loss 5.4940 (5.3046)
2022-11-03 00:27:11,062:INFO: Batch: 17/31	Total Loss 5.2432 (5.3009)
2022-11-03 00:27:11,534:INFO: Batch: 18/31	Total Loss 4.6525 (5.2658)
2022-11-03 00:27:12,005:INFO: Batch: 19/31	Total Loss 5.9324 (5.2991)
2022-11-03 00:27:12,475:INFO: Batch: 20/31	Total Loss 5.5676 (5.3115)
2022-11-03 00:27:12,947:INFO: Batch: 21/31	Total Loss 4.9824 (5.2965)
2022-11-03 00:27:13,418:INFO: Batch: 22/31	Total Loss 5.9458 (5.3230)
2022-11-03 00:27:13,888:INFO: Batch: 23/31	Total Loss 5.9399 (5.3505)
2022-11-03 00:27:14,361:INFO: Batch: 24/31	Total Loss 5.8233 (5.3671)
2022-11-03 00:27:14,834:INFO: Batch: 25/31	Total Loss 5.5956 (5.3761)
2022-11-03 00:27:15,309:INFO: Batch: 26/31	Total Loss 4.8399 (5.3586)
2022-11-03 00:27:15,783:INFO: Batch: 27/31	Total Loss 4.9694 (5.3456)
2022-11-03 00:27:16,252:INFO: Batch: 28/31	Total Loss 5.2908 (5.3438)
2022-11-03 00:27:16,725:INFO: Batch: 29/31	Total Loss 4.8127 (5.3267)
2022-11-03 00:27:17,160:INFO: Batch: 30/31	Total Loss 1.9152 (5.2914)
2022-11-03 00:27:17,314:INFO: - Computing ADE (validation o)
2022-11-03 00:27:17,924:INFO: 		 ADE on eth                       dataset:	 1.118558406829834
2022-11-03 00:27:17,924:INFO: Average validation o:	ADE  1.1186	FDE  1.8576
2022-11-03 00:27:17,925:INFO: - Computing ADE (validation)
2022-11-03 00:27:18,207:INFO: 		 ADE on hotel                     dataset:	 0.5087421536445618
2022-11-03 00:27:18,512:INFO: 		 ADE on univ                      dataset:	 0.6144106388092041
2022-11-03 00:27:18,758:INFO: 		 ADE on zara1                     dataset:	 0.6291161775588989
2022-11-03 00:27:19,107:INFO: 		 ADE on zara2                     dataset:	 0.48878049850463867
2022-11-03 00:27:19,108:INFO: Average validation:	ADE  0.5634	FDE  1.0223
2022-11-03 00:27:19,108:INFO: - Computing ADE (training)
2022-11-03 00:27:19,564:INFO: 		 ADE on hotel                     dataset:	 0.5735806822776794
2022-11-03 00:27:20,255:INFO: 		 ADE on univ                      dataset:	 0.5877726674079895
2022-11-03 00:27:20,782:INFO: 		 ADE on zara1                     dataset:	 0.7009507417678833
2022-11-03 00:27:21,588:INFO: 		 ADE on zara2                     dataset:	 0.5359485149383545
2022-11-03 00:27:21,589:INFO: Average training:	ADE  0.5841	FDE  1.0737
2022-11-03 00:27:21,598:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_358.pth.tar
2022-11-03 00:27:21,598:INFO: 
===> EPOCH: 359 (P3)
2022-11-03 00:27:21,598:INFO: - Computing loss (training)
2022-11-03 00:27:22,693:INFO: Batch:  0/31	Total Loss 5.3560 (5.3560)
2022-11-03 00:27:23,160:INFO: Batch:  1/31	Total Loss 4.6314 (4.9861)
2022-11-03 00:27:23,635:INFO: Batch:  2/31	Total Loss 5.1108 (5.0273)
2022-11-03 00:27:24,110:INFO: Batch:  3/31	Total Loss 5.3646 (5.1080)
2022-11-03 00:27:24,578:INFO: Batch:  4/31	Total Loss 4.9185 (5.0674)
2022-11-03 00:27:25,051:INFO: Batch:  5/31	Total Loss 4.6029 (4.9898)
2022-11-03 00:27:25,597:INFO: Batch:  6/31	Total Loss 5.1459 (5.0119)
2022-11-03 00:27:26,065:INFO: Batch:  7/31	Total Loss 4.8690 (4.9959)
2022-11-03 00:27:26,533:INFO: Batch:  8/31	Total Loss 4.8451 (4.9781)
2022-11-03 00:27:27,000:INFO: Batch:  9/31	Total Loss 4.8939 (4.9692)
2022-11-03 00:27:27,468:INFO: Batch: 10/31	Total Loss 5.1726 (4.9888)
2022-11-03 00:27:27,938:INFO: Batch: 11/31	Total Loss 4.9878 (4.9887)
2022-11-03 00:27:28,411:INFO: Batch: 12/31	Total Loss 5.2057 (5.0058)
2022-11-03 00:27:28,883:INFO: Batch: 13/31	Total Loss 5.0618 (5.0101)
2022-11-03 00:27:29,357:INFO: Batch: 14/31	Total Loss 4.8164 (4.9964)
2022-11-03 00:27:29,840:INFO: Batch: 15/31	Total Loss 5.1322 (5.0041)
2022-11-03 00:27:30,318:INFO: Batch: 16/31	Total Loss 5.8678 (5.0542)
2022-11-03 00:27:30,792:INFO: Batch: 17/31	Total Loss 4.3959 (5.0169)
2022-11-03 00:27:31,266:INFO: Batch: 18/31	Total Loss 5.1176 (5.0220)
2022-11-03 00:27:31,740:INFO: Batch: 19/31	Total Loss 4.5183 (4.9985)
2022-11-03 00:27:32,214:INFO: Batch: 20/31	Total Loss 5.6064 (5.0246)
2022-11-03 00:27:32,688:INFO: Batch: 21/31	Total Loss 4.8812 (5.0183)
2022-11-03 00:27:33,162:INFO: Batch: 22/31	Total Loss 5.3964 (5.0341)
2022-11-03 00:27:33,636:INFO: Batch: 23/31	Total Loss 4.4836 (5.0125)
2022-11-03 00:27:34,109:INFO: Batch: 24/31	Total Loss 5.3768 (5.0248)
2022-11-03 00:27:34,583:INFO: Batch: 25/31	Total Loss 4.9453 (5.0214)
2022-11-03 00:27:35,056:INFO: Batch: 26/31	Total Loss 5.6562 (5.0456)
2022-11-03 00:27:35,528:INFO: Batch: 27/31	Total Loss 6.6914 (5.1024)
2022-11-03 00:27:36,001:INFO: Batch: 28/31	Total Loss 5.3431 (5.1098)
2022-11-03 00:27:36,475:INFO: Batch: 29/31	Total Loss 5.0919 (5.1093)
2022-11-03 00:27:36,862:INFO: Batch: 30/31	Total Loss 2.2192 (5.0857)
2022-11-03 00:27:37,016:INFO: - Computing ADE (validation o)
2022-11-03 00:27:37,640:INFO: 		 ADE on eth                       dataset:	 1.1581732034683228
2022-11-03 00:27:37,640:INFO: Average validation o:	ADE  1.1582	FDE  1.9536
2022-11-03 00:27:37,641:INFO: - Computing ADE (validation)
2022-11-03 00:27:37,910:INFO: 		 ADE on hotel                     dataset:	 0.5551961064338684
2022-11-03 00:27:38,206:INFO: 		 ADE on univ                      dataset:	 0.6417510509490967
2022-11-03 00:27:38,492:INFO: 		 ADE on zara1                     dataset:	 0.7245131731033325
2022-11-03 00:27:38,847:INFO: 		 ADE on zara2                     dataset:	 0.5535750389099121
2022-11-03 00:27:38,847:INFO: Average validation:	ADE  0.6095	FDE  1.1503
2022-11-03 00:27:38,848:INFO: - Computing ADE (training)
2022-11-03 00:27:39,312:INFO: 		 ADE on hotel                     dataset:	 0.6213521361351013
2022-11-03 00:27:39,996:INFO: 		 ADE on univ                      dataset:	 0.6266710162162781
2022-11-03 00:27:40,572:INFO: 		 ADE on zara1                     dataset:	 0.7553352117538452
2022-11-03 00:27:41,310:INFO: 		 ADE on zara2                     dataset:	 0.5978624820709229
2022-11-03 00:27:41,310:INFO: Average training:	ADE  0.6289	FDE  1.2005
2022-11-03 00:27:41,319:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_359.pth.tar
2022-11-03 00:27:41,319:INFO: 
===> EPOCH: 360 (P3)
2022-11-03 00:27:41,320:INFO: - Computing loss (training)
2022-11-03 00:27:42,427:INFO: Batch:  0/31	Total Loss 5.3674 (5.3674)
2022-11-03 00:27:42,902:INFO: Batch:  1/31	Total Loss 4.4641 (4.9287)
2022-11-03 00:27:43,373:INFO: Batch:  2/31	Total Loss 5.2852 (5.0363)
2022-11-03 00:27:43,845:INFO: Batch:  3/31	Total Loss 6.6394 (5.4452)
2022-11-03 00:27:44,317:INFO: Batch:  4/31	Total Loss 4.9390 (5.3442)
2022-11-03 00:27:44,792:INFO: Batch:  5/31	Total Loss 5.3345 (5.3426)
2022-11-03 00:27:45,268:INFO: Batch:  6/31	Total Loss 5.4868 (5.3614)
2022-11-03 00:27:45,741:INFO: Batch:  7/31	Total Loss 5.0434 (5.3253)
2022-11-03 00:27:46,218:INFO: Batch:  8/31	Total Loss 5.0183 (5.2915)
2022-11-03 00:27:46,691:INFO: Batch:  9/31	Total Loss 4.8003 (5.2419)
2022-11-03 00:27:47,166:INFO: Batch: 10/31	Total Loss 4.9943 (5.2158)
2022-11-03 00:27:47,643:INFO: Batch: 11/31	Total Loss 5.0738 (5.2038)
2022-11-03 00:27:48,121:INFO: Batch: 12/31	Total Loss 5.2385 (5.2065)
2022-11-03 00:27:48,599:INFO: Batch: 13/31	Total Loss 4.6637 (5.1690)
2022-11-03 00:27:49,077:INFO: Batch: 14/31	Total Loss 4.5029 (5.1270)
2022-11-03 00:27:49,554:INFO: Batch: 15/31	Total Loss 4.7667 (5.1037)
2022-11-03 00:27:50,036:INFO: Batch: 16/31	Total Loss 5.0445 (5.0999)
2022-11-03 00:27:50,515:INFO: Batch: 17/31	Total Loss 4.8019 (5.0832)
2022-11-03 00:27:50,993:INFO: Batch: 18/31	Total Loss 5.3348 (5.0951)
2022-11-03 00:27:51,469:INFO: Batch: 19/31	Total Loss 5.1868 (5.0994)
2022-11-03 00:27:51,946:INFO: Batch: 20/31	Total Loss 5.1818 (5.1033)
2022-11-03 00:27:52,423:INFO: Batch: 21/31	Total Loss 6.0941 (5.1498)
2022-11-03 00:27:52,900:INFO: Batch: 22/31	Total Loss 4.7057 (5.1311)
2022-11-03 00:27:53,378:INFO: Batch: 23/31	Total Loss 5.7411 (5.1567)
2022-11-03 00:27:53,846:INFO: Batch: 24/31	Total Loss 4.9850 (5.1491)
2022-11-03 00:27:54,317:INFO: Batch: 25/31	Total Loss 4.8907 (5.1387)
2022-11-03 00:27:54,789:INFO: Batch: 26/31	Total Loss 4.5630 (5.1188)
2022-11-03 00:27:55,260:INFO: Batch: 27/31	Total Loss 5.1650 (5.1206)
2022-11-03 00:27:55,733:INFO: Batch: 28/31	Total Loss 5.0775 (5.1192)
2022-11-03 00:27:56,203:INFO: Batch: 29/31	Total Loss 5.4417 (5.1300)
2022-11-03 00:27:56,589:INFO: Batch: 30/31	Total Loss 1.7579 (5.0997)
2022-11-03 00:27:56,755:INFO: - Computing ADE (validation o)
2022-11-03 00:27:57,379:INFO: 		 ADE on eth                       dataset:	 1.1223104000091553
2022-11-03 00:27:57,379:INFO: Average validation o:	ADE  1.1223	FDE  1.8422
2022-11-03 00:27:57,380:INFO: - Computing ADE (validation)
2022-11-03 00:27:57,672:INFO: 		 ADE on hotel                     dataset:	 0.5078321099281311
2022-11-03 00:27:57,958:INFO: 		 ADE on univ                      dataset:	 0.6111117005348206
2022-11-03 00:27:58,200:INFO: 		 ADE on zara1                     dataset:	 0.6082703471183777
2022-11-03 00:27:58,534:INFO: 		 ADE on zara2                     dataset:	 0.4919419586658478
2022-11-03 00:27:58,534:INFO: Average validation:	ADE  0.5616	FDE  1.0174
2022-11-03 00:27:58,535:INFO: - Computing ADE (training)
2022-11-03 00:27:59,015:INFO: 		 ADE on hotel                     dataset:	 0.569146990776062
2022-11-03 00:27:59,713:INFO: 		 ADE on univ                      dataset:	 0.5848914384841919
2022-11-03 00:28:00,256:INFO: 		 ADE on zara1                     dataset:	 0.6969153881072998
2022-11-03 00:28:01,008:INFO: 		 ADE on zara2                     dataset:	 0.5414020419120789
2022-11-03 00:28:01,008:INFO: Average training:	ADE  0.5828	FDE  1.0686
2022-11-03 00:28:01,017:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_360.pth.tar
2022-11-03 00:28:01,017:INFO: 
===> EPOCH: 361 (P3)
2022-11-03 00:28:01,017:INFO: - Computing loss (training)
2022-11-03 00:28:02,123:INFO: Batch:  0/31	Total Loss 4.5848 (4.5848)
2022-11-03 00:28:02,599:INFO: Batch:  1/31	Total Loss 4.9055 (4.7388)
2022-11-03 00:28:03,071:INFO: Batch:  2/31	Total Loss 5.5462 (4.9650)
2022-11-03 00:28:03,543:INFO: Batch:  3/31	Total Loss 4.5697 (4.8659)
2022-11-03 00:28:04,014:INFO: Batch:  4/31	Total Loss 4.9631 (4.8839)
2022-11-03 00:28:04,488:INFO: Batch:  5/31	Total Loss 4.4563 (4.8149)
2022-11-03 00:28:04,959:INFO: Batch:  6/31	Total Loss 4.8957 (4.8262)
2022-11-03 00:28:05,433:INFO: Batch:  7/31	Total Loss 4.7143 (4.8124)
2022-11-03 00:28:05,902:INFO: Batch:  8/31	Total Loss 4.6251 (4.7923)
2022-11-03 00:28:06,373:INFO: Batch:  9/31	Total Loss 4.8764 (4.8004)
2022-11-03 00:28:06,845:INFO: Batch: 10/31	Total Loss 4.9107 (4.8102)
2022-11-03 00:28:07,317:INFO: Batch: 11/31	Total Loss 4.5882 (4.7899)
2022-11-03 00:28:07,794:INFO: Batch: 12/31	Total Loss 5.2389 (4.8254)
2022-11-03 00:28:08,270:INFO: Batch: 13/31	Total Loss 5.0867 (4.8456)
2022-11-03 00:28:08,746:INFO: Batch: 14/31	Total Loss 4.5616 (4.8266)
2022-11-03 00:28:09,219:INFO: Batch: 15/31	Total Loss 5.1678 (4.8446)
2022-11-03 00:28:09,695:INFO: Batch: 16/31	Total Loss 6.2497 (4.9271)
2022-11-03 00:28:10,172:INFO: Batch: 17/31	Total Loss 5.0709 (4.9343)
2022-11-03 00:28:10,646:INFO: Batch: 18/31	Total Loss 4.8830 (4.9320)
2022-11-03 00:28:11,119:INFO: Batch: 19/31	Total Loss 4.6028 (4.9135)
2022-11-03 00:28:11,594:INFO: Batch: 20/31	Total Loss 4.8373 (4.9096)
2022-11-03 00:28:12,068:INFO: Batch: 21/31	Total Loss 4.6375 (4.8983)
2022-11-03 00:28:12,541:INFO: Batch: 22/31	Total Loss 6.2236 (4.9583)
2022-11-03 00:28:13,014:INFO: Batch: 23/31	Total Loss 4.7313 (4.9492)
2022-11-03 00:28:13,487:INFO: Batch: 24/31	Total Loss 5.5156 (4.9721)
2022-11-03 00:28:13,960:INFO: Batch: 25/31	Total Loss 6.3357 (5.0188)
2022-11-03 00:28:14,435:INFO: Batch: 26/31	Total Loss 4.6260 (5.0048)
2022-11-03 00:28:14,912:INFO: Batch: 27/31	Total Loss 6.1564 (5.0442)
2022-11-03 00:28:15,387:INFO: Batch: 28/31	Total Loss 4.6286 (5.0306)
2022-11-03 00:28:15,862:INFO: Batch: 29/31	Total Loss 5.5607 (5.0486)
2022-11-03 00:28:16,250:INFO: Batch: 30/31	Total Loss 2.0278 (5.0234)
2022-11-03 00:28:16,396:INFO: - Computing ADE (validation o)
2022-11-03 00:28:17,002:INFO: 		 ADE on eth                       dataset:	 1.1739411354064941
2022-11-03 00:28:17,003:INFO: Average validation o:	ADE  1.1739	FDE  2.0439
2022-11-03 00:28:17,003:INFO: - Computing ADE (validation)
2022-11-03 00:28:17,266:INFO: 		 ADE on hotel                     dataset:	 0.6003125309944153
2022-11-03 00:28:17,551:INFO: 		 ADE on univ                      dataset:	 0.6885061264038086
2022-11-03 00:28:17,811:INFO: 		 ADE on zara1                     dataset:	 0.8297549486160278
2022-11-03 00:28:18,147:INFO: 		 ADE on zara2                     dataset:	 0.6210894584655762
2022-11-03 00:28:18,147:INFO: Average validation:	ADE  0.6672	FDE  1.3264
2022-11-03 00:28:18,156:INFO: - Computing ADE (training)
2022-11-03 00:28:18,611:INFO: 		 ADE on hotel                     dataset:	 0.6691972017288208
2022-11-03 00:28:19,315:INFO: 		 ADE on univ                      dataset:	 0.6768937706947327
2022-11-03 00:28:19,848:INFO: 		 ADE on zara1                     dataset:	 0.8027175664901733
2022-11-03 00:28:20,624:INFO: 		 ADE on zara2                     dataset:	 0.659071147441864
2022-11-03 00:28:20,625:INFO: Average training:	ADE  0.6811	FDE  1.3658
2022-11-03 00:28:20,634:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_361.pth.tar
2022-11-03 00:28:20,634:INFO: 
===> EPOCH: 362 (P3)
2022-11-03 00:28:20,634:INFO: - Computing loss (training)
2022-11-03 00:28:21,833:INFO: Batch:  0/31	Total Loss 4.1238 (4.1238)
2022-11-03 00:28:22,302:INFO: Batch:  1/31	Total Loss 5.0648 (4.5481)
2022-11-03 00:28:22,777:INFO: Batch:  2/31	Total Loss 6.4797 (5.2833)
2022-11-03 00:28:23,246:INFO: Batch:  3/31	Total Loss 5.3614 (5.3044)
2022-11-03 00:28:23,716:INFO: Batch:  4/31	Total Loss 5.5710 (5.3603)
2022-11-03 00:28:24,188:INFO: Batch:  5/31	Total Loss 6.3148 (5.5188)
2022-11-03 00:28:24,659:INFO: Batch:  6/31	Total Loss 5.8629 (5.5701)
2022-11-03 00:28:25,126:INFO: Batch:  7/31	Total Loss 5.5663 (5.5696)
2022-11-03 00:28:25,593:INFO: Batch:  8/31	Total Loss 5.7228 (5.5892)
2022-11-03 00:28:26,060:INFO: Batch:  9/31	Total Loss 5.7381 (5.6041)
2022-11-03 00:28:26,528:INFO: Batch: 10/31	Total Loss 5.4333 (5.5867)
2022-11-03 00:28:26,997:INFO: Batch: 11/31	Total Loss 5.4911 (5.5780)
2022-11-03 00:28:27,467:INFO: Batch: 12/31	Total Loss 5.6344 (5.5826)
2022-11-03 00:28:27,938:INFO: Batch: 13/31	Total Loss 5.0852 (5.5451)
2022-11-03 00:28:28,411:INFO: Batch: 14/31	Total Loss 5.1727 (5.5190)
2022-11-03 00:28:28,882:INFO: Batch: 15/31	Total Loss 5.5514 (5.5210)
2022-11-03 00:28:29,355:INFO: Batch: 16/31	Total Loss 5.5200 (5.5210)
2022-11-03 00:28:29,831:INFO: Batch: 17/31	Total Loss 5.1609 (5.5005)
2022-11-03 00:28:30,307:INFO: Batch: 18/31	Total Loss 6.5285 (5.5493)
2022-11-03 00:28:30,785:INFO: Batch: 19/31	Total Loss 4.6608 (5.5039)
2022-11-03 00:28:31,258:INFO: Batch: 20/31	Total Loss 5.5803 (5.5075)
2022-11-03 00:28:31,732:INFO: Batch: 21/31	Total Loss 5.2486 (5.4968)
2022-11-03 00:28:32,205:INFO: Batch: 22/31	Total Loss 5.6579 (5.5038)
2022-11-03 00:28:32,678:INFO: Batch: 23/31	Total Loss 5.0516 (5.4852)
2022-11-03 00:28:33,148:INFO: Batch: 24/31	Total Loss 4.9815 (5.4665)
2022-11-03 00:28:33,619:INFO: Batch: 25/31	Total Loss 5.0253 (5.4497)
2022-11-03 00:28:34,091:INFO: Batch: 26/31	Total Loss 4.9260 (5.4304)
2022-11-03 00:28:34,562:INFO: Batch: 27/31	Total Loss 5.0785 (5.4160)
2022-11-03 00:28:35,033:INFO: Batch: 28/31	Total Loss 6.2885 (5.4461)
2022-11-03 00:28:35,505:INFO: Batch: 29/31	Total Loss 4.6153 (5.4166)
2022-11-03 00:28:35,893:INFO: Batch: 30/31	Total Loss 1.9641 (5.3816)
2022-11-03 00:28:36,052:INFO: - Computing ADE (validation o)
2022-11-03 00:28:36,668:INFO: 		 ADE on eth                       dataset:	 1.1589590311050415
2022-11-03 00:28:36,669:INFO: Average validation o:	ADE  1.1590	FDE  1.9348
2022-11-03 00:28:36,669:INFO: - Computing ADE (validation)
2022-11-03 00:28:36,939:INFO: 		 ADE on hotel                     dataset:	 0.5449906587600708
2022-11-03 00:28:37,233:INFO: 		 ADE on univ                      dataset:	 0.6205846667289734
2022-11-03 00:28:37,478:INFO: 		 ADE on zara1                     dataset:	 0.6408321857452393
2022-11-03 00:28:37,853:INFO: 		 ADE on zara2                     dataset:	 0.5367146730422974
2022-11-03 00:28:37,853:INFO: Average validation:	ADE  0.5869	FDE  1.0841
2022-11-03 00:28:37,854:INFO: - Computing ADE (training)
2022-11-03 00:28:38,320:INFO: 		 ADE on hotel                     dataset:	 0.6014752388000488
2022-11-03 00:28:39,011:INFO: 		 ADE on univ                      dataset:	 0.6072161793708801
2022-11-03 00:28:39,533:INFO: 		 ADE on zara1                     dataset:	 0.7352607846260071
2022-11-03 00:28:40,294:INFO: 		 ADE on zara2                     dataset:	 0.5863596200942993
2022-11-03 00:28:40,294:INFO: Average training:	ADE  0.6110	FDE  1.1414
2022-11-03 00:28:40,303:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_362.pth.tar
2022-11-03 00:28:40,303:INFO: 
===> EPOCH: 363 (P3)
2022-11-03 00:28:40,303:INFO: - Computing loss (training)
2022-11-03 00:28:41,391:INFO: Batch:  0/31	Total Loss 5.0842 (5.0842)
2022-11-03 00:28:41,865:INFO: Batch:  1/31	Total Loss 5.9381 (5.4813)
2022-11-03 00:28:42,342:INFO: Batch:  2/31	Total Loss 5.3473 (5.4374)
2022-11-03 00:28:42,815:INFO: Batch:  3/31	Total Loss 4.5958 (5.2139)
2022-11-03 00:28:43,292:INFO: Batch:  4/31	Total Loss 6.2293 (5.4043)
2022-11-03 00:28:43,764:INFO: Batch:  5/31	Total Loss 5.3168 (5.3894)
2022-11-03 00:28:44,238:INFO: Batch:  6/31	Total Loss 5.4053 (5.3917)
2022-11-03 00:28:44,711:INFO: Batch:  7/31	Total Loss 4.6934 (5.3031)
2022-11-03 00:28:45,182:INFO: Batch:  8/31	Total Loss 4.7403 (5.2397)
2022-11-03 00:28:45,652:INFO: Batch:  9/31	Total Loss 5.1449 (5.2313)
2022-11-03 00:28:46,124:INFO: Batch: 10/31	Total Loss 4.8103 (5.1925)
2022-11-03 00:28:46,597:INFO: Batch: 11/31	Total Loss 5.2972 (5.2009)
2022-11-03 00:28:47,078:INFO: Batch: 12/31	Total Loss 5.0342 (5.1872)
2022-11-03 00:28:47,553:INFO: Batch: 13/31	Total Loss 4.5456 (5.1423)
2022-11-03 00:28:48,029:INFO: Batch: 14/31	Total Loss 4.9782 (5.1323)
2022-11-03 00:28:48,506:INFO: Batch: 15/31	Total Loss 4.9531 (5.1213)
2022-11-03 00:28:48,981:INFO: Batch: 16/31	Total Loss 5.4875 (5.1410)
2022-11-03 00:28:49,456:INFO: Batch: 17/31	Total Loss 4.9583 (5.1321)
2022-11-03 00:28:49,933:INFO: Batch: 18/31	Total Loss 5.3358 (5.1421)
2022-11-03 00:28:50,407:INFO: Batch: 19/31	Total Loss 4.9032 (5.1308)
2022-11-03 00:28:50,886:INFO: Batch: 20/31	Total Loss 4.8072 (5.1137)
2022-11-03 00:28:51,362:INFO: Batch: 21/31	Total Loss 5.0703 (5.1116)
2022-11-03 00:28:51,836:INFO: Batch: 22/31	Total Loss 5.0224 (5.1073)
2022-11-03 00:28:52,310:INFO: Batch: 23/31	Total Loss 5.1783 (5.1101)
2022-11-03 00:28:52,785:INFO: Batch: 24/31	Total Loss 5.3068 (5.1170)
2022-11-03 00:28:53,260:INFO: Batch: 25/31	Total Loss 4.3897 (5.0867)
2022-11-03 00:28:53,734:INFO: Batch: 26/31	Total Loss 5.2484 (5.0930)
2022-11-03 00:28:54,207:INFO: Batch: 27/31	Total Loss 5.5048 (5.1095)
2022-11-03 00:28:54,681:INFO: Batch: 28/31	Total Loss 4.9029 (5.1018)
2022-11-03 00:28:55,154:INFO: Batch: 29/31	Total Loss 4.7196 (5.0896)
2022-11-03 00:28:55,545:INFO: Batch: 30/31	Total Loss 1.7951 (5.0564)
2022-11-03 00:28:55,705:INFO: - Computing ADE (validation o)
2022-11-03 00:28:56,303:INFO: 		 ADE on eth                       dataset:	 1.1540042161941528
2022-11-03 00:28:56,303:INFO: Average validation o:	ADE  1.1540	FDE  1.9424
2022-11-03 00:28:56,304:INFO: - Computing ADE (validation)
2022-11-03 00:28:56,568:INFO: 		 ADE on hotel                     dataset:	 0.5083122253417969
2022-11-03 00:28:56,860:INFO: 		 ADE on univ                      dataset:	 0.6214101910591125
2022-11-03 00:28:57,108:INFO: 		 ADE on zara1                     dataset:	 0.7191921472549438
2022-11-03 00:28:57,457:INFO: 		 ADE on zara2                     dataset:	 0.5325316190719604
2022-11-03 00:28:57,457:INFO: Average validation:	ADE  0.5883	FDE  1.0830
2022-11-03 00:28:57,458:INFO: - Computing ADE (training)
2022-11-03 00:28:57,889:INFO: 		 ADE on hotel                     dataset:	 0.5721101760864258
2022-11-03 00:28:58,570:INFO: 		 ADE on univ                      dataset:	 0.6034705638885498
2022-11-03 00:28:59,119:INFO: 		 ADE on zara1                     dataset:	 0.7605942487716675
2022-11-03 00:28:59,876:INFO: 		 ADE on zara2                     dataset:	 0.5873477458953857
2022-11-03 00:28:59,876:INFO: Average training:	ADE  0.6094	FDE  1.1357
2022-11-03 00:28:59,885:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_363.pth.tar
2022-11-03 00:28:59,885:INFO: 
===> EPOCH: 364 (P3)
2022-11-03 00:28:59,885:INFO: - Computing loss (training)
2022-11-03 00:29:00,965:INFO: Batch:  0/31	Total Loss 5.4218 (5.4218)
2022-11-03 00:29:01,440:INFO: Batch:  1/31	Total Loss 5.1754 (5.2973)
2022-11-03 00:29:01,912:INFO: Batch:  2/31	Total Loss 5.7160 (5.4236)
2022-11-03 00:29:02,384:INFO: Batch:  3/31	Total Loss 5.0068 (5.3218)
2022-11-03 00:29:02,850:INFO: Batch:  4/31	Total Loss 5.4895 (5.3541)
2022-11-03 00:29:03,322:INFO: Batch:  5/31	Total Loss 5.1114 (5.3131)
2022-11-03 00:29:03,795:INFO: Batch:  6/31	Total Loss 5.9021 (5.4052)
2022-11-03 00:29:04,262:INFO: Batch:  7/31	Total Loss 5.8099 (5.4533)
2022-11-03 00:29:04,730:INFO: Batch:  8/31	Total Loss 6.8917 (5.6180)
2022-11-03 00:29:05,197:INFO: Batch:  9/31	Total Loss 5.1255 (5.5720)
2022-11-03 00:29:05,668:INFO: Batch: 10/31	Total Loss 5.1167 (5.5224)
2022-11-03 00:29:06,136:INFO: Batch: 11/31	Total Loss 5.9582 (5.5582)
2022-11-03 00:29:06,608:INFO: Batch: 12/31	Total Loss 4.9959 (5.5107)
2022-11-03 00:29:07,079:INFO: Batch: 13/31	Total Loss 5.9758 (5.5484)
2022-11-03 00:29:07,549:INFO: Batch: 14/31	Total Loss 6.1076 (5.5814)
2022-11-03 00:29:08,023:INFO: Batch: 15/31	Total Loss 4.9012 (5.5370)
2022-11-03 00:29:08,496:INFO: Batch: 16/31	Total Loss 5.5656 (5.5387)
2022-11-03 00:29:08,967:INFO: Batch: 17/31	Total Loss 5.3756 (5.5302)
2022-11-03 00:29:09,439:INFO: Batch: 18/31	Total Loss 6.3371 (5.5686)
2022-11-03 00:29:09,915:INFO: Batch: 19/31	Total Loss 5.9176 (5.5862)
2022-11-03 00:29:10,389:INFO: Batch: 20/31	Total Loss 4.4098 (5.5318)
2022-11-03 00:29:10,936:INFO: Batch: 21/31	Total Loss 5.6471 (5.5371)
2022-11-03 00:29:11,408:INFO: Batch: 22/31	Total Loss 5.4207 (5.5326)
2022-11-03 00:29:11,879:INFO: Batch: 23/31	Total Loss 5.2837 (5.5228)
2022-11-03 00:29:12,350:INFO: Batch: 24/31	Total Loss 5.2856 (5.5132)
2022-11-03 00:29:12,823:INFO: Batch: 25/31	Total Loss 5.0859 (5.4991)
2022-11-03 00:29:13,299:INFO: Batch: 26/31	Total Loss 5.5212 (5.4999)
2022-11-03 00:29:13,769:INFO: Batch: 27/31	Total Loss 4.6480 (5.4670)
2022-11-03 00:29:14,241:INFO: Batch: 28/31	Total Loss 5.3245 (5.4621)
2022-11-03 00:29:14,715:INFO: Batch: 29/31	Total Loss 5.4199 (5.4607)
2022-11-03 00:29:15,106:INFO: Batch: 30/31	Total Loss 2.2068 (5.4262)
2022-11-03 00:29:15,258:INFO: - Computing ADE (validation o)
2022-11-03 00:29:15,822:INFO: 		 ADE on eth                       dataset:	 1.1557722091674805
2022-11-03 00:29:15,822:INFO: Average validation o:	ADE  1.1558	FDE  1.9517
2022-11-03 00:29:15,831:INFO: - Computing ADE (validation)
2022-11-03 00:29:16,090:INFO: 		 ADE on hotel                     dataset:	 0.5463207960128784
2022-11-03 00:29:16,416:INFO: 		 ADE on univ                      dataset:	 0.6506054997444153
2022-11-03 00:29:16,657:INFO: 		 ADE on zara1                     dataset:	 0.730353593826294
2022-11-03 00:29:17,007:INFO: 		 ADE on zara2                     dataset:	 0.5405614972114563
2022-11-03 00:29:17,008:INFO: Average validation:	ADE  0.6092	FDE  1.1449
2022-11-03 00:29:17,008:INFO: - Computing ADE (training)
2022-11-03 00:29:17,482:INFO: 		 ADE on hotel                     dataset:	 0.6237462162971497
2022-11-03 00:29:18,178:INFO: 		 ADE on univ                      dataset:	 0.6214960813522339
2022-11-03 00:29:18,753:INFO: 		 ADE on zara1                     dataset:	 0.7698357105255127
2022-11-03 00:29:19,523:INFO: 		 ADE on zara2                     dataset:	 0.5938543081283569
2022-11-03 00:29:19,524:INFO: Average training:	ADE  0.6254	FDE  1.1843
2022-11-03 00:29:19,532:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_364.pth.tar
2022-11-03 00:29:19,533:INFO: 
===> EPOCH: 365 (P3)
2022-11-03 00:29:19,533:INFO: - Computing loss (training)
2022-11-03 00:29:20,641:INFO: Batch:  0/31	Total Loss 5.4801 (5.4801)
2022-11-03 00:29:21,125:INFO: Batch:  1/31	Total Loss 5.0570 (5.2824)
2022-11-03 00:29:21,607:INFO: Batch:  2/31	Total Loss 5.0964 (5.2185)
2022-11-03 00:29:22,083:INFO: Batch:  3/31	Total Loss 5.1134 (5.1920)
2022-11-03 00:29:22,559:INFO: Batch:  4/31	Total Loss 5.5755 (5.2632)
2022-11-03 00:29:23,039:INFO: Batch:  5/31	Total Loss 4.9558 (5.2117)
2022-11-03 00:29:23,516:INFO: Batch:  6/31	Total Loss 5.2404 (5.2158)
2022-11-03 00:29:23,995:INFO: Batch:  7/31	Total Loss 5.2366 (5.2184)
2022-11-03 00:29:24,478:INFO: Batch:  8/31	Total Loss 4.9216 (5.1841)
2022-11-03 00:29:24,953:INFO: Batch:  9/31	Total Loss 5.2226 (5.1879)
2022-11-03 00:29:25,428:INFO: Batch: 10/31	Total Loss 4.6453 (5.1391)
2022-11-03 00:29:25,905:INFO: Batch: 11/31	Total Loss 4.2767 (5.0658)
2022-11-03 00:29:26,387:INFO: Batch: 12/31	Total Loss 5.1710 (5.0739)
2022-11-03 00:29:26,868:INFO: Batch: 13/31	Total Loss 5.1308 (5.0773)
2022-11-03 00:29:27,350:INFO: Batch: 14/31	Total Loss 5.3715 (5.0969)
2022-11-03 00:29:27,821:INFO: Batch: 15/31	Total Loss 5.0455 (5.0941)
2022-11-03 00:29:28,295:INFO: Batch: 16/31	Total Loss 5.3301 (5.1075)
2022-11-03 00:29:28,768:INFO: Batch: 17/31	Total Loss 5.1208 (5.1082)
2022-11-03 00:29:29,241:INFO: Batch: 18/31	Total Loss 5.2307 (5.1150)
2022-11-03 00:29:29,713:INFO: Batch: 19/31	Total Loss 5.3228 (5.1249)
2022-11-03 00:29:30,188:INFO: Batch: 20/31	Total Loss 4.6297 (5.1020)
2022-11-03 00:29:30,661:INFO: Batch: 21/31	Total Loss 4.7233 (5.0831)
2022-11-03 00:29:31,131:INFO: Batch: 22/31	Total Loss 5.0239 (5.0805)
2022-11-03 00:29:31,603:INFO: Batch: 23/31	Total Loss 4.4177 (5.0526)
2022-11-03 00:29:32,075:INFO: Batch: 24/31	Total Loss 5.5399 (5.0706)
2022-11-03 00:29:32,546:INFO: Batch: 25/31	Total Loss 5.4075 (5.0834)
2022-11-03 00:29:33,018:INFO: Batch: 26/31	Total Loss 4.7215 (5.0700)
2022-11-03 00:29:33,487:INFO: Batch: 27/31	Total Loss 5.9215 (5.1029)
2022-11-03 00:29:33,957:INFO: Batch: 28/31	Total Loss 4.7218 (5.0892)
2022-11-03 00:29:34,428:INFO: Batch: 29/31	Total Loss 5.7426 (5.1098)
2022-11-03 00:29:34,814:INFO: Batch: 30/31	Total Loss 2.0603 (5.0847)
2022-11-03 00:29:34,973:INFO: - Computing ADE (validation o)
2022-11-03 00:29:35,542:INFO: 		 ADE on eth                       dataset:	 1.1266746520996094
2022-11-03 00:29:35,542:INFO: Average validation o:	ADE  1.1267	FDE  1.9150
2022-11-03 00:29:35,543:INFO: - Computing ADE (validation)
2022-11-03 00:29:35,818:INFO: 		 ADE on hotel                     dataset:	 0.5165426135063171
2022-11-03 00:29:36,116:INFO: 		 ADE on univ                      dataset:	 0.6115750670433044
2022-11-03 00:29:36,384:INFO: 		 ADE on zara1                     dataset:	 0.6512826085090637
2022-11-03 00:29:36,750:INFO: 		 ADE on zara2                     dataset:	 0.5023760795593262
2022-11-03 00:29:36,751:INFO: Average validation:	ADE  0.5686	FDE  1.0540
2022-11-03 00:29:36,751:INFO: - Computing ADE (training)
2022-11-03 00:29:37,206:INFO: 		 ADE on hotel                     dataset:	 0.5777466893196106
2022-11-03 00:29:37,920:INFO: 		 ADE on univ                      dataset:	 0.5929121375083923
2022-11-03 00:29:38,488:INFO: 		 ADE on zara1                     dataset:	 0.7081518769264221
2022-11-03 00:29:39,238:INFO: 		 ADE on zara2                     dataset:	 0.5478364825248718
2022-11-03 00:29:39,238:INFO: Average training:	ADE  0.5907	FDE  1.1077
2022-11-03 00:29:39,247:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_365.pth.tar
2022-11-03 00:29:39,248:INFO: 
===> EPOCH: 366 (P3)
2022-11-03 00:29:39,248:INFO: - Computing loss (training)
2022-11-03 00:29:40,364:INFO: Batch:  0/31	Total Loss 5.8464 (5.8464)
2022-11-03 00:29:40,838:INFO: Batch:  1/31	Total Loss 5.5544 (5.6915)
2022-11-03 00:29:41,313:INFO: Batch:  2/31	Total Loss 5.1285 (5.4992)
2022-11-03 00:29:41,786:INFO: Batch:  3/31	Total Loss 5.4159 (5.4801)
2022-11-03 00:29:42,255:INFO: Batch:  4/31	Total Loss 4.8114 (5.3464)
2022-11-03 00:29:42,726:INFO: Batch:  5/31	Total Loss 4.5990 (5.2218)
2022-11-03 00:29:43,193:INFO: Batch:  6/31	Total Loss 5.4544 (5.2554)
2022-11-03 00:29:43,662:INFO: Batch:  7/31	Total Loss 5.4828 (5.2832)
2022-11-03 00:29:44,131:INFO: Batch:  8/31	Total Loss 5.0698 (5.2574)
2022-11-03 00:29:44,600:INFO: Batch:  9/31	Total Loss 4.2364 (5.1566)
2022-11-03 00:29:45,070:INFO: Batch: 10/31	Total Loss 4.8331 (5.1261)
2022-11-03 00:29:45,539:INFO: Batch: 11/31	Total Loss 5.1667 (5.1298)
2022-11-03 00:29:46,011:INFO: Batch: 12/31	Total Loss 4.9604 (5.1162)
2022-11-03 00:29:46,484:INFO: Batch: 13/31	Total Loss 4.8430 (5.0950)
2022-11-03 00:29:46,959:INFO: Batch: 14/31	Total Loss 4.9045 (5.0818)
2022-11-03 00:29:47,433:INFO: Batch: 15/31	Total Loss 4.2750 (5.0280)
2022-11-03 00:29:47,904:INFO: Batch: 16/31	Total Loss 4.7091 (5.0091)
2022-11-03 00:29:48,378:INFO: Batch: 17/31	Total Loss 4.8850 (5.0020)
2022-11-03 00:29:48,851:INFO: Batch: 18/31	Total Loss 4.5975 (4.9816)
2022-11-03 00:29:49,321:INFO: Batch: 19/31	Total Loss 4.6583 (4.9653)
2022-11-03 00:29:49,797:INFO: Batch: 20/31	Total Loss 5.0358 (4.9684)
2022-11-03 00:29:50,270:INFO: Batch: 21/31	Total Loss 4.8986 (4.9653)
2022-11-03 00:29:50,740:INFO: Batch: 22/31	Total Loss 5.0628 (4.9695)
2022-11-03 00:29:51,210:INFO: Batch: 23/31	Total Loss 5.0284 (4.9719)
2022-11-03 00:29:51,681:INFO: Batch: 24/31	Total Loss 5.1277 (4.9784)
2022-11-03 00:29:52,153:INFO: Batch: 25/31	Total Loss 5.5259 (4.9998)
2022-11-03 00:29:52,622:INFO: Batch: 26/31	Total Loss 4.4491 (4.9796)
2022-11-03 00:29:53,093:INFO: Batch: 27/31	Total Loss 5.0793 (4.9831)
2022-11-03 00:29:53,565:INFO: Batch: 28/31	Total Loss 4.6980 (4.9734)
2022-11-03 00:29:54,035:INFO: Batch: 29/31	Total Loss 5.2553 (4.9827)
2022-11-03 00:29:54,422:INFO: Batch: 30/31	Total Loss 1.9047 (4.9522)
2022-11-03 00:29:54,580:INFO: - Computing ADE (validation o)
2022-11-03 00:29:55,156:INFO: 		 ADE on eth                       dataset:	 1.1182972192764282
2022-11-03 00:29:55,156:INFO: Average validation o:	ADE  1.1183	FDE  1.8849
2022-11-03 00:29:55,157:INFO: - Computing ADE (validation)
2022-11-03 00:29:55,432:INFO: 		 ADE on hotel                     dataset:	 0.5050519704818726
2022-11-03 00:29:55,739:INFO: 		 ADE on univ                      dataset:	 0.6078184843063354
2022-11-03 00:29:56,001:INFO: 		 ADE on zara1                     dataset:	 0.6246196031570435
2022-11-03 00:29:56,347:INFO: 		 ADE on zara2                     dataset:	 0.4922136664390564
2022-11-03 00:29:56,347:INFO: Average validation:	ADE  0.5608	FDE  1.0265
2022-11-03 00:29:56,348:INFO: - Computing ADE (training)
2022-11-03 00:29:56,816:INFO: 		 ADE on hotel                     dataset:	 0.5613003969192505
2022-11-03 00:29:57,495:INFO: 		 ADE on univ                      dataset:	 0.5852755904197693
2022-11-03 00:29:58,018:INFO: 		 ADE on zara1                     dataset:	 0.7020046710968018
2022-11-03 00:29:58,798:INFO: 		 ADE on zara2                     dataset:	 0.5412803292274475
2022-11-03 00:29:58,798:INFO: Average training:	ADE  0.5832	FDE  1.0828
2022-11-03 00:29:58,806:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_366.pth.tar
2022-11-03 00:29:58,806:INFO: 
===> EPOCH: 367 (P3)
2022-11-03 00:29:58,807:INFO: - Computing loss (training)
2022-11-03 00:29:59,939:INFO: Batch:  0/31	Total Loss 4.8108 (4.8108)
2022-11-03 00:30:00,421:INFO: Batch:  1/31	Total Loss 5.3915 (5.1051)
2022-11-03 00:30:00,899:INFO: Batch:  2/31	Total Loss 4.6243 (4.9387)
2022-11-03 00:30:01,377:INFO: Batch:  3/31	Total Loss 5.0579 (4.9676)
2022-11-03 00:30:01,855:INFO: Batch:  4/31	Total Loss 4.5881 (4.9031)
2022-11-03 00:30:02,327:INFO: Batch:  5/31	Total Loss 5.6911 (5.0471)
2022-11-03 00:30:02,804:INFO: Batch:  6/31	Total Loss 5.2505 (5.0761)
2022-11-03 00:30:03,350:INFO: Batch:  7/31	Total Loss 5.7158 (5.1480)
2022-11-03 00:30:03,821:INFO: Batch:  8/31	Total Loss 4.8387 (5.1118)
2022-11-03 00:30:04,291:INFO: Batch:  9/31	Total Loss 4.7888 (5.0762)
2022-11-03 00:30:04,764:INFO: Batch: 10/31	Total Loss 5.3256 (5.0983)
2022-11-03 00:30:05,235:INFO: Batch: 11/31	Total Loss 5.1802 (5.1045)
2022-11-03 00:30:05,720:INFO: Batch: 12/31	Total Loss 5.1857 (5.1103)
2022-11-03 00:30:06,201:INFO: Batch: 13/31	Total Loss 5.0409 (5.1057)
2022-11-03 00:30:06,681:INFO: Batch: 14/31	Total Loss 4.8818 (5.0896)
2022-11-03 00:30:07,162:INFO: Batch: 15/31	Total Loss 5.3513 (5.1049)
2022-11-03 00:30:07,636:INFO: Batch: 16/31	Total Loss 4.8005 (5.0869)
2022-11-03 00:30:08,110:INFO: Batch: 17/31	Total Loss 4.8489 (5.0751)
2022-11-03 00:30:08,586:INFO: Batch: 18/31	Total Loss 4.7793 (5.0595)
2022-11-03 00:30:09,059:INFO: Batch: 19/31	Total Loss 5.0280 (5.0580)
2022-11-03 00:30:09,532:INFO: Batch: 20/31	Total Loss 5.0973 (5.0597)
2022-11-03 00:30:10,010:INFO: Batch: 21/31	Total Loss 5.1702 (5.0644)
2022-11-03 00:30:10,484:INFO: Batch: 22/31	Total Loss 4.3666 (5.0313)
2022-11-03 00:30:10,956:INFO: Batch: 23/31	Total Loss 4.5094 (5.0078)
2022-11-03 00:30:11,434:INFO: Batch: 24/31	Total Loss 4.5386 (4.9880)
2022-11-03 00:30:11,913:INFO: Batch: 25/31	Total Loss 5.4585 (5.0060)
2022-11-03 00:30:12,391:INFO: Batch: 26/31	Total Loss 4.4549 (4.9848)
2022-11-03 00:30:12,865:INFO: Batch: 27/31	Total Loss 5.1835 (4.9919)
2022-11-03 00:30:13,342:INFO: Batch: 28/31	Total Loss 5.1361 (4.9970)
2022-11-03 00:30:13,819:INFO: Batch: 29/31	Total Loss 5.1573 (5.0020)
2022-11-03 00:30:14,212:INFO: Batch: 30/31	Total Loss 1.7129 (4.9666)
2022-11-03 00:30:14,359:INFO: - Computing ADE (validation o)
2022-11-03 00:30:14,918:INFO: 		 ADE on eth                       dataset:	 1.0961343050003052
2022-11-03 00:30:14,918:INFO: Average validation o:	ADE  1.0961	FDE  1.8347
2022-11-03 00:30:14,919:INFO: - Computing ADE (validation)
2022-11-03 00:30:15,196:INFO: 		 ADE on hotel                     dataset:	 0.5043462514877319
2022-11-03 00:30:15,488:INFO: 		 ADE on univ                      dataset:	 0.6027040481567383
2022-11-03 00:30:15,759:INFO: 		 ADE on zara1                     dataset:	 0.5972760915756226
2022-11-03 00:30:16,113:INFO: 		 ADE on zara2                     dataset:	 0.47869402170181274
2022-11-03 00:30:16,114:INFO: Average validation:	ADE  0.5515	FDE  1.0159
2022-11-03 00:30:16,114:INFO: - Computing ADE (training)
2022-11-03 00:30:16,588:INFO: 		 ADE on hotel                     dataset:	 0.5602979063987732
2022-11-03 00:30:17,282:INFO: 		 ADE on univ                      dataset:	 0.5791475772857666
2022-11-03 00:30:17,827:INFO: 		 ADE on zara1                     dataset:	 0.6732120513916016
2022-11-03 00:30:18,580:INFO: 		 ADE on zara2                     dataset:	 0.5229678153991699
2022-11-03 00:30:18,580:INFO: Average training:	ADE  0.5733	FDE  1.0688
2022-11-03 00:30:18,589:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_367.pth.tar
2022-11-03 00:30:18,589:INFO: 
===> EPOCH: 368 (P3)
2022-11-03 00:30:18,589:INFO: - Computing loss (training)
2022-11-03 00:30:19,673:INFO: Batch:  0/31	Total Loss 5.3543 (5.3543)
2022-11-03 00:30:20,143:INFO: Batch:  1/31	Total Loss 4.6410 (4.9677)
2022-11-03 00:30:20,615:INFO: Batch:  2/31	Total Loss 5.0922 (5.0069)
2022-11-03 00:30:21,082:INFO: Batch:  3/31	Total Loss 4.4992 (4.8742)
2022-11-03 00:30:21,550:INFO: Batch:  4/31	Total Loss 4.7466 (4.8490)
2022-11-03 00:30:22,019:INFO: Batch:  5/31	Total Loss 4.4733 (4.7879)
2022-11-03 00:30:22,488:INFO: Batch:  6/31	Total Loss 4.3134 (4.7158)
2022-11-03 00:30:22,952:INFO: Batch:  7/31	Total Loss 5.0010 (4.7512)
2022-11-03 00:30:23,420:INFO: Batch:  8/31	Total Loss 4.5860 (4.7331)
2022-11-03 00:30:23,885:INFO: Batch:  9/31	Total Loss 5.4367 (4.8059)
2022-11-03 00:30:24,352:INFO: Batch: 10/31	Total Loss 5.3321 (4.8559)
2022-11-03 00:30:24,819:INFO: Batch: 11/31	Total Loss 5.4623 (4.9059)
2022-11-03 00:30:25,290:INFO: Batch: 12/31	Total Loss 4.9492 (4.9091)
2022-11-03 00:30:25,759:INFO: Batch: 13/31	Total Loss 5.5694 (4.9574)
2022-11-03 00:30:26,228:INFO: Batch: 14/31	Total Loss 4.6631 (4.9385)
2022-11-03 00:30:26,700:INFO: Batch: 15/31	Total Loss 5.1520 (4.9517)
2022-11-03 00:30:27,172:INFO: Batch: 16/31	Total Loss 5.0900 (4.9588)
2022-11-03 00:30:27,640:INFO: Batch: 17/31	Total Loss 4.8813 (4.9540)
2022-11-03 00:30:28,111:INFO: Batch: 18/31	Total Loss 4.9501 (4.9538)
2022-11-03 00:30:28,580:INFO: Batch: 19/31	Total Loss 4.9178 (4.9518)
2022-11-03 00:30:29,051:INFO: Batch: 20/31	Total Loss 5.1994 (4.9642)
2022-11-03 00:30:29,520:INFO: Batch: 21/31	Total Loss 4.4397 (4.9397)
2022-11-03 00:30:29,996:INFO: Batch: 22/31	Total Loss 4.6051 (4.9247)
2022-11-03 00:30:30,468:INFO: Batch: 23/31	Total Loss 4.5776 (4.9090)
2022-11-03 00:30:30,935:INFO: Batch: 24/31	Total Loss 5.5208 (4.9318)
2022-11-03 00:30:31,405:INFO: Batch: 25/31	Total Loss 4.4035 (4.9127)
2022-11-03 00:30:31,873:INFO: Batch: 26/31	Total Loss 4.4880 (4.8985)
2022-11-03 00:30:32,345:INFO: Batch: 27/31	Total Loss 5.0662 (4.9044)
2022-11-03 00:30:32,819:INFO: Batch: 28/31	Total Loss 4.4122 (4.8872)
2022-11-03 00:30:33,289:INFO: Batch: 29/31	Total Loss 4.7900 (4.8838)
2022-11-03 00:30:33,675:INFO: Batch: 30/31	Total Loss 1.9863 (4.8572)
2022-11-03 00:30:33,828:INFO: - Computing ADE (validation o)
2022-11-03 00:30:34,404:INFO: 		 ADE on eth                       dataset:	 1.0756345987319946
2022-11-03 00:30:34,404:INFO: Average validation o:	ADE  1.0756	FDE  1.8071
2022-11-03 00:30:34,405:INFO: - Computing ADE (validation)
2022-11-03 00:30:34,682:INFO: 		 ADE on hotel                     dataset:	 0.5024139285087585
2022-11-03 00:30:34,982:INFO: 		 ADE on univ                      dataset:	 0.5921543836593628
2022-11-03 00:30:35,247:INFO: 		 ADE on zara1                     dataset:	 0.5542572736740112
2022-11-03 00:30:35,615:INFO: 		 ADE on zara2                     dataset:	 0.46722379326820374
2022-11-03 00:30:35,615:INFO: Average validation:	ADE  0.5392	FDE  1.0000
2022-11-03 00:30:35,616:INFO: - Computing ADE (training)
2022-11-03 00:30:36,100:INFO: 		 ADE on hotel                     dataset:	 0.5546936392784119
2022-11-03 00:30:36,831:INFO: 		 ADE on univ                      dataset:	 0.5729400515556335
2022-11-03 00:30:37,343:INFO: 		 ADE on zara1                     dataset:	 0.6389203071594238
2022-11-03 00:30:38,098:INFO: 		 ADE on zara2                     dataset:	 0.5018368363380432
2022-11-03 00:30:38,098:INFO: Average training:	ADE  0.5623	FDE  1.0568
2022-11-03 00:30:38,107:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_368.pth.tar
2022-11-03 00:30:38,107:INFO: 
===> EPOCH: 369 (P3)
2022-11-03 00:30:38,108:INFO: - Computing loss (training)
2022-11-03 00:30:39,232:INFO: Batch:  0/31	Total Loss 6.8011 (6.8011)
2022-11-03 00:30:39,725:INFO: Batch:  1/31	Total Loss 5.3133 (6.0888)
2022-11-03 00:30:40,216:INFO: Batch:  2/31	Total Loss 4.7574 (5.6949)
2022-11-03 00:30:40,702:INFO: Batch:  3/31	Total Loss 4.8915 (5.4961)
2022-11-03 00:30:41,179:INFO: Batch:  4/31	Total Loss 5.5494 (5.5056)
2022-11-03 00:30:41,656:INFO: Batch:  5/31	Total Loss 5.3748 (5.4857)
2022-11-03 00:30:42,128:INFO: Batch:  6/31	Total Loss 4.6800 (5.3579)
2022-11-03 00:30:42,597:INFO: Batch:  7/31	Total Loss 4.7156 (5.2778)
2022-11-03 00:30:43,068:INFO: Batch:  8/31	Total Loss 4.6442 (5.1994)
2022-11-03 00:30:43,540:INFO: Batch:  9/31	Total Loss 4.4950 (5.1299)
2022-11-03 00:30:44,011:INFO: Batch: 10/31	Total Loss 6.6600 (5.2867)
2022-11-03 00:30:44,487:INFO: Batch: 11/31	Total Loss 5.3470 (5.2919)
2022-11-03 00:30:44,972:INFO: Batch: 12/31	Total Loss 5.0204 (5.2705)
2022-11-03 00:30:45,455:INFO: Batch: 13/31	Total Loss 5.3740 (5.2779)
2022-11-03 00:30:45,940:INFO: Batch: 14/31	Total Loss 4.9411 (5.2553)
2022-11-03 00:30:46,424:INFO: Batch: 15/31	Total Loss 4.9867 (5.2371)
2022-11-03 00:30:46,908:INFO: Batch: 16/31	Total Loss 4.7648 (5.2083)
2022-11-03 00:30:47,395:INFO: Batch: 17/31	Total Loss 4.3786 (5.1605)
2022-11-03 00:30:47,877:INFO: Batch: 18/31	Total Loss 4.9786 (5.1509)
2022-11-03 00:30:48,361:INFO: Batch: 19/31	Total Loss 4.4222 (5.1141)
2022-11-03 00:30:48,844:INFO: Batch: 20/31	Total Loss 4.4068 (5.0777)
2022-11-03 00:30:49,326:INFO: Batch: 21/31	Total Loss 5.3274 (5.0875)
2022-11-03 00:30:49,810:INFO: Batch: 22/31	Total Loss 4.9220 (5.0793)
2022-11-03 00:30:50,295:INFO: Batch: 23/31	Total Loss 5.5516 (5.0978)
2022-11-03 00:30:50,778:INFO: Batch: 24/31	Total Loss 5.5316 (5.1149)
2022-11-03 00:30:51,259:INFO: Batch: 25/31	Total Loss 5.0112 (5.1111)
2022-11-03 00:30:51,742:INFO: Batch: 26/31	Total Loss 4.4350 (5.0849)
2022-11-03 00:30:52,223:INFO: Batch: 27/31	Total Loss 5.0268 (5.0829)
2022-11-03 00:30:52,705:INFO: Batch: 28/31	Total Loss 4.8862 (5.0756)
2022-11-03 00:30:53,188:INFO: Batch: 29/31	Total Loss 4.6949 (5.0624)
2022-11-03 00:30:53,584:INFO: Batch: 30/31	Total Loss 2.3757 (5.0422)
2022-11-03 00:30:53,736:INFO: - Computing ADE (validation o)
2022-11-03 00:30:54,311:INFO: 		 ADE on eth                       dataset:	 1.1290183067321777
2022-11-03 00:30:54,311:INFO: Average validation o:	ADE  1.1290	FDE  1.9484
2022-11-03 00:30:54,311:INFO: - Computing ADE (validation)
2022-11-03 00:30:54,595:INFO: 		 ADE on hotel                     dataset:	 0.5319198369979858
2022-11-03 00:30:54,894:INFO: 		 ADE on univ                      dataset:	 0.6167379021644592
2022-11-03 00:30:55,151:INFO: 		 ADE on zara1                     dataset:	 0.6687425971031189
2022-11-03 00:30:55,506:INFO: 		 ADE on zara2                     dataset:	 0.5297075510025024
2022-11-03 00:30:55,506:INFO: Average validation:	ADE  0.5832	FDE  1.1114
2022-11-03 00:30:55,507:INFO: - Computing ADE (training)
2022-11-03 00:30:55,979:INFO: 		 ADE on hotel                     dataset:	 0.5839771628379822
2022-11-03 00:30:56,678:INFO: 		 ADE on univ                      dataset:	 0.6051102876663208
2022-11-03 00:30:57,214:INFO: 		 ADE on zara1                     dataset:	 0.7172753810882568
2022-11-03 00:30:58,011:INFO: 		 ADE on zara2                     dataset:	 0.5699562430381775
2022-11-03 00:30:58,012:INFO: Average training:	ADE  0.6046	FDE  1.1641
2022-11-03 00:30:58,020:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_369.pth.tar
2022-11-03 00:30:58,020:INFO: 
===> EPOCH: 370 (P3)
2022-11-03 00:30:58,021:INFO: - Computing loss (training)
2022-11-03 00:30:59,100:INFO: Batch:  0/31	Total Loss 4.9274 (4.9274)
2022-11-03 00:30:59,648:INFO: Batch:  1/31	Total Loss 5.1778 (5.0466)
2022-11-03 00:31:00,127:INFO: Batch:  2/31	Total Loss 4.8102 (4.9661)
2022-11-03 00:31:00,594:INFO: Batch:  3/31	Total Loss 4.9385 (4.9592)
2022-11-03 00:31:01,061:INFO: Batch:  4/31	Total Loss 5.1510 (4.9930)
2022-11-03 00:31:01,531:INFO: Batch:  5/31	Total Loss 4.8108 (4.9644)
2022-11-03 00:31:01,999:INFO: Batch:  6/31	Total Loss 4.9741 (4.9657)
2022-11-03 00:31:02,467:INFO: Batch:  7/31	Total Loss 5.5314 (5.0379)
2022-11-03 00:31:02,940:INFO: Batch:  8/31	Total Loss 5.2002 (5.0563)
2022-11-03 00:31:03,408:INFO: Batch:  9/31	Total Loss 5.1204 (5.0620)
2022-11-03 00:31:03,876:INFO: Batch: 10/31	Total Loss 4.6797 (5.0252)
2022-11-03 00:31:04,341:INFO: Batch: 11/31	Total Loss 5.5265 (5.0625)
2022-11-03 00:31:04,811:INFO: Batch: 12/31	Total Loss 4.8674 (5.0490)
2022-11-03 00:31:05,284:INFO: Batch: 13/31	Total Loss 4.9907 (5.0455)
2022-11-03 00:31:05,755:INFO: Batch: 14/31	Total Loss 5.2681 (5.0604)
2022-11-03 00:31:06,225:INFO: Batch: 15/31	Total Loss 4.8269 (5.0469)
2022-11-03 00:31:06,695:INFO: Batch: 16/31	Total Loss 4.5776 (5.0243)
2022-11-03 00:31:07,164:INFO: Batch: 17/31	Total Loss 4.4549 (4.9909)
2022-11-03 00:31:07,632:INFO: Batch: 18/31	Total Loss 5.1453 (4.9998)
2022-11-03 00:31:08,102:INFO: Batch: 19/31	Total Loss 5.0769 (5.0038)
2022-11-03 00:31:08,571:INFO: Batch: 20/31	Total Loss 4.8207 (4.9950)
2022-11-03 00:31:09,041:INFO: Batch: 21/31	Total Loss 5.2066 (5.0043)
2022-11-03 00:31:09,510:INFO: Batch: 22/31	Total Loss 4.8972 (4.9992)
2022-11-03 00:31:09,983:INFO: Batch: 23/31	Total Loss 4.7829 (4.9899)
2022-11-03 00:31:10,454:INFO: Batch: 24/31	Total Loss 4.7455 (4.9793)
2022-11-03 00:31:10,924:INFO: Batch: 25/31	Total Loss 4.6943 (4.9674)
2022-11-03 00:31:11,393:INFO: Batch: 26/31	Total Loss 4.7551 (4.9594)
2022-11-03 00:31:11,863:INFO: Batch: 27/31	Total Loss 5.0569 (4.9628)
2022-11-03 00:31:12,333:INFO: Batch: 28/31	Total Loss 5.3453 (4.9764)
2022-11-03 00:31:12,804:INFO: Batch: 29/31	Total Loss 5.2951 (4.9869)
2022-11-03 00:31:13,189:INFO: Batch: 30/31	Total Loss 1.6823 (4.9608)
2022-11-03 00:31:13,328:INFO: - Computing ADE (validation o)
2022-11-03 00:31:13,947:INFO: 		 ADE on eth                       dataset:	 1.0925624370574951
2022-11-03 00:31:13,948:INFO: Average validation o:	ADE  1.0926	FDE  1.8577
2022-11-03 00:31:13,949:INFO: - Computing ADE (validation)
2022-11-03 00:31:14,223:INFO: 		 ADE on hotel                     dataset:	 0.5066625475883484
2022-11-03 00:31:14,519:INFO: 		 ADE on univ                      dataset:	 0.5966628789901733
2022-11-03 00:31:14,780:INFO: 		 ADE on zara1                     dataset:	 0.5721504092216492
2022-11-03 00:31:15,131:INFO: 		 ADE on zara2                     dataset:	 0.4741079807281494
2022-11-03 00:31:15,131:INFO: Average validation:	ADE  0.5454	FDE  1.0079
2022-11-03 00:31:15,132:INFO: - Computing ADE (training)
2022-11-03 00:31:15,590:INFO: 		 ADE on hotel                     dataset:	 0.5555360913276672
2022-11-03 00:31:16,290:INFO: 		 ADE on univ                      dataset:	 0.5754399299621582
2022-11-03 00:31:16,867:INFO: 		 ADE on zara1                     dataset:	 0.6597651839256287
2022-11-03 00:31:17,627:INFO: 		 ADE on zara2                     dataset:	 0.5162877440452576
2022-11-03 00:31:17,627:INFO: Average training:	ADE  0.5683	FDE  1.0642
2022-11-03 00:31:17,637:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_370.pth.tar
2022-11-03 00:31:17,637:INFO: 
===> EPOCH: 371 (P3)
2022-11-03 00:31:17,638:INFO: - Computing loss (training)
2022-11-03 00:31:18,707:INFO: Batch:  0/31	Total Loss 4.6327 (4.6327)
2022-11-03 00:31:19,176:INFO: Batch:  1/31	Total Loss 5.2722 (4.9483)
2022-11-03 00:31:19,649:INFO: Batch:  2/31	Total Loss 5.4927 (5.1148)
2022-11-03 00:31:20,124:INFO: Batch:  3/31	Total Loss 4.9862 (5.0823)
2022-11-03 00:31:20,589:INFO: Batch:  4/31	Total Loss 4.3900 (4.9457)
2022-11-03 00:31:21,073:INFO: Batch:  5/31	Total Loss 5.0259 (4.9598)
2022-11-03 00:31:21,547:INFO: Batch:  6/31	Total Loss 5.8829 (5.0728)
2022-11-03 00:31:22,017:INFO: Batch:  7/31	Total Loss 4.8079 (5.0395)
2022-11-03 00:31:22,491:INFO: Batch:  8/31	Total Loss 4.7485 (5.0076)
2022-11-03 00:31:22,963:INFO: Batch:  9/31	Total Loss 5.0349 (5.0105)
2022-11-03 00:31:23,436:INFO: Batch: 10/31	Total Loss 4.2630 (4.9310)
2022-11-03 00:31:23,911:INFO: Batch: 11/31	Total Loss 4.9719 (4.9349)
2022-11-03 00:31:24,387:INFO: Batch: 12/31	Total Loss 5.6462 (4.9892)
2022-11-03 00:31:24,864:INFO: Batch: 13/31	Total Loss 4.6608 (4.9643)
2022-11-03 00:31:25,341:INFO: Batch: 14/31	Total Loss 4.5403 (4.9350)
2022-11-03 00:31:25,819:INFO: Batch: 15/31	Total Loss 4.9838 (4.9381)
2022-11-03 00:31:26,296:INFO: Batch: 16/31	Total Loss 4.6633 (4.9195)
2022-11-03 00:31:26,773:INFO: Batch: 17/31	Total Loss 5.3285 (4.9389)
2022-11-03 00:31:27,251:INFO: Batch: 18/31	Total Loss 4.9548 (4.9398)
2022-11-03 00:31:27,727:INFO: Batch: 19/31	Total Loss 4.9428 (4.9400)
2022-11-03 00:31:28,206:INFO: Batch: 20/31	Total Loss 5.1228 (4.9488)
2022-11-03 00:31:28,683:INFO: Batch: 21/31	Total Loss 5.5247 (4.9746)
2022-11-03 00:31:29,161:INFO: Batch: 22/31	Total Loss 4.8664 (4.9700)
2022-11-03 00:31:29,638:INFO: Batch: 23/31	Total Loss 4.7799 (4.9629)
2022-11-03 00:31:30,120:INFO: Batch: 24/31	Total Loss 5.4845 (4.9838)
2022-11-03 00:31:30,597:INFO: Batch: 25/31	Total Loss 4.2123 (4.9535)
2022-11-03 00:31:31,072:INFO: Batch: 26/31	Total Loss 4.7977 (4.9473)
2022-11-03 00:31:31,550:INFO: Batch: 27/31	Total Loss 4.8252 (4.9431)
2022-11-03 00:31:32,027:INFO: Batch: 28/31	Total Loss 4.9997 (4.9449)
2022-11-03 00:31:32,504:INFO: Batch: 29/31	Total Loss 5.5211 (4.9652)
2022-11-03 00:31:32,902:INFO: Batch: 30/31	Total Loss 1.6914 (4.9423)
2022-11-03 00:31:33,057:INFO: - Computing ADE (validation o)
2022-11-03 00:31:33,650:INFO: 		 ADE on eth                       dataset:	 1.0931206941604614
2022-11-03 00:31:33,650:INFO: Average validation o:	ADE  1.0931	FDE  1.8899
2022-11-03 00:31:33,651:INFO: - Computing ADE (validation)
2022-11-03 00:31:33,961:INFO: 		 ADE on hotel                     dataset:	 0.5031962990760803
2022-11-03 00:31:34,253:INFO: 		 ADE on univ                      dataset:	 0.6040807366371155
2022-11-03 00:31:34,507:INFO: 		 ADE on zara1                     dataset:	 0.6281843185424805
2022-11-03 00:31:34,848:INFO: 		 ADE on zara2                     dataset:	 0.4861399531364441
2022-11-03 00:31:34,848:INFO: Average validation:	ADE  0.5567	FDE  1.0527
2022-11-03 00:31:34,848:INFO: - Computing ADE (training)
2022-11-03 00:31:35,303:INFO: 		 ADE on hotel                     dataset:	 0.557600200176239
2022-11-03 00:31:36,046:INFO: 		 ADE on univ                      dataset:	 0.5828316807746887
2022-11-03 00:31:36,595:INFO: 		 ADE on zara1                     dataset:	 0.6783226728439331
2022-11-03 00:31:37,398:INFO: 		 ADE on zara2                     dataset:	 0.5281471014022827
2022-11-03 00:31:37,399:INFO: Average training:	ADE  0.5772	FDE  1.1026
2022-11-03 00:31:37,409:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_371.pth.tar
2022-11-03 00:31:37,409:INFO: 
===> EPOCH: 372 (P3)
2022-11-03 00:31:37,409:INFO: - Computing loss (training)
2022-11-03 00:31:38,829:INFO: Batch:  0/31	Total Loss 4.5041 (4.5041)
2022-11-03 00:31:39,368:INFO: Batch:  1/31	Total Loss 5.2897 (4.9050)
2022-11-03 00:31:39,913:INFO: Batch:  2/31	Total Loss 5.4493 (5.0820)
2022-11-03 00:31:40,403:INFO: Batch:  3/31	Total Loss 5.4458 (5.1708)
2022-11-03 00:31:40,937:INFO: Batch:  4/31	Total Loss 4.9040 (5.1193)
2022-11-03 00:31:41,430:INFO: Batch:  5/31	Total Loss 5.0411 (5.1062)
2022-11-03 00:31:41,918:INFO: Batch:  6/31	Total Loss 4.7283 (5.0508)
2022-11-03 00:31:42,418:INFO: Batch:  7/31	Total Loss 4.8122 (5.0214)
2022-11-03 00:31:42,916:INFO: Batch:  8/31	Total Loss 5.3039 (5.0528)
2022-11-03 00:31:43,406:INFO: Batch:  9/31	Total Loss 4.4569 (4.9887)
2022-11-03 00:31:43,907:INFO: Batch: 10/31	Total Loss 5.0060 (4.9902)
2022-11-03 00:31:44,439:INFO: Batch: 11/31	Total Loss 4.7023 (4.9667)
2022-11-03 00:31:44,962:INFO: Batch: 12/31	Total Loss 5.2930 (4.9926)
2022-11-03 00:31:45,443:INFO: Batch: 13/31	Total Loss 4.7374 (4.9748)
2022-11-03 00:31:45,921:INFO: Batch: 14/31	Total Loss 5.3323 (5.0001)
2022-11-03 00:31:46,466:INFO: Batch: 15/31	Total Loss 5.3242 (5.0187)
2022-11-03 00:31:46,942:INFO: Batch: 16/31	Total Loss 5.0985 (5.0234)
2022-11-03 00:31:47,415:INFO: Batch: 17/31	Total Loss 5.6951 (5.0538)
2022-11-03 00:31:47,890:INFO: Batch: 18/31	Total Loss 4.8520 (5.0430)
2022-11-03 00:31:48,363:INFO: Batch: 19/31	Total Loss 4.4595 (5.0146)
2022-11-03 00:31:48,909:INFO: Batch: 20/31	Total Loss 4.6938 (4.9987)
2022-11-03 00:31:49,382:INFO: Batch: 21/31	Total Loss 4.9473 (4.9964)
2022-11-03 00:31:49,854:INFO: Batch: 22/31	Total Loss 3.9886 (4.9560)
2022-11-03 00:31:50,327:INFO: Batch: 23/31	Total Loss 4.6095 (4.9412)
2022-11-03 00:31:50,812:INFO: Batch: 24/31	Total Loss 4.9785 (4.9426)
2022-11-03 00:31:51,282:INFO: Batch: 25/31	Total Loss 5.1334 (4.9507)
2022-11-03 00:31:51,754:INFO: Batch: 26/31	Total Loss 4.1716 (4.9187)
2022-11-03 00:31:52,224:INFO: Batch: 27/31	Total Loss 4.6671 (4.9094)
2022-11-03 00:31:52,701:INFO: Batch: 28/31	Total Loss 4.8578 (4.9076)
2022-11-03 00:31:53,180:INFO: Batch: 29/31	Total Loss 4.9459 (4.9088)
2022-11-03 00:31:53,571:INFO: Batch: 30/31	Total Loss 1.7697 (4.8777)
2022-11-03 00:31:53,730:INFO: - Computing ADE (validation o)
2022-11-03 00:31:54,339:INFO: 		 ADE on eth                       dataset:	 1.1284700632095337
2022-11-03 00:31:54,340:INFO: Average validation o:	ADE  1.1285	FDE  1.8852
2022-11-03 00:31:54,340:INFO: - Computing ADE (validation)
2022-11-03 00:31:54,624:INFO: 		 ADE on hotel                     dataset:	 0.5222081542015076
2022-11-03 00:31:54,911:INFO: 		 ADE on univ                      dataset:	 0.6074645519256592
2022-11-03 00:31:55,195:INFO: 		 ADE on zara1                     dataset:	 0.5981963276863098
2022-11-03 00:31:55,544:INFO: 		 ADE on zara2                     dataset:	 0.5097590684890747
2022-11-03 00:31:55,544:INFO: Average validation:	ADE  0.5664	FDE  1.0495
2022-11-03 00:31:55,545:INFO: - Computing ADE (training)
2022-11-03 00:31:55,993:INFO: 		 ADE on hotel                     dataset:	 0.5727996230125427
2022-11-03 00:31:56,714:INFO: 		 ADE on univ                      dataset:	 0.5870469212532043
2022-11-03 00:31:57,258:INFO: 		 ADE on zara1                     dataset:	 0.7021292448043823
2022-11-03 00:31:58,032:INFO: 		 ADE on zara2                     dataset:	 0.5591888427734375
2022-11-03 00:31:58,032:INFO: Average training:	ADE  0.5884	FDE  1.1019
2022-11-03 00:31:58,041:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_372.pth.tar
2022-11-03 00:31:58,041:INFO: 
===> EPOCH: 373 (P3)
2022-11-03 00:31:58,042:INFO: - Computing loss (training)
2022-11-03 00:31:59,151:INFO: Batch:  0/31	Total Loss 4.9546 (4.9546)
2022-11-03 00:31:59,627:INFO: Batch:  1/31	Total Loss 4.9461 (4.9504)
2022-11-03 00:32:00,104:INFO: Batch:  2/31	Total Loss 4.6481 (4.8460)
2022-11-03 00:32:00,571:INFO: Batch:  3/31	Total Loss 5.1220 (4.9143)
2022-11-03 00:32:01,034:INFO: Batch:  4/31	Total Loss 4.7408 (4.8834)
2022-11-03 00:32:01,511:INFO: Batch:  5/31	Total Loss 5.5612 (4.9972)
2022-11-03 00:32:01,977:INFO: Batch:  6/31	Total Loss 5.8456 (5.1163)
2022-11-03 00:32:02,443:INFO: Batch:  7/31	Total Loss 4.9359 (5.0958)
2022-11-03 00:32:02,910:INFO: Batch:  8/31	Total Loss 4.9553 (5.0832)
2022-11-03 00:32:03,375:INFO: Batch:  9/31	Total Loss 4.7143 (5.0441)
2022-11-03 00:32:03,840:INFO: Batch: 10/31	Total Loss 5.1073 (5.0496)
2022-11-03 00:32:04,309:INFO: Batch: 11/31	Total Loss 5.6100 (5.1044)
2022-11-03 00:32:04,779:INFO: Batch: 12/31	Total Loss 4.5079 (5.0542)
2022-11-03 00:32:05,250:INFO: Batch: 13/31	Total Loss 4.6800 (5.0274)
2022-11-03 00:32:05,721:INFO: Batch: 14/31	Total Loss 5.2289 (5.0414)
2022-11-03 00:32:06,193:INFO: Batch: 15/31	Total Loss 4.6142 (5.0153)
2022-11-03 00:32:06,663:INFO: Batch: 16/31	Total Loss 4.9393 (5.0110)
2022-11-03 00:32:07,133:INFO: Batch: 17/31	Total Loss 4.9831 (5.0093)
2022-11-03 00:32:07,603:INFO: Batch: 18/31	Total Loss 4.9019 (5.0029)
2022-11-03 00:32:08,072:INFO: Batch: 19/31	Total Loss 4.7937 (4.9927)
2022-11-03 00:32:08,541:INFO: Batch: 20/31	Total Loss 5.1328 (4.9986)
2022-11-03 00:32:09,011:INFO: Batch: 21/31	Total Loss 4.3951 (4.9706)
2022-11-03 00:32:09,479:INFO: Batch: 22/31	Total Loss 4.6577 (4.9558)
2022-11-03 00:32:09,952:INFO: Batch: 23/31	Total Loss 4.9938 (4.9573)
2022-11-03 00:32:10,427:INFO: Batch: 24/31	Total Loss 4.4706 (4.9383)
2022-11-03 00:32:10,895:INFO: Batch: 25/31	Total Loss 4.8376 (4.9343)
2022-11-03 00:32:11,363:INFO: Batch: 26/31	Total Loss 4.8417 (4.9312)
2022-11-03 00:32:11,833:INFO: Batch: 27/31	Total Loss 4.9884 (4.9333)
2022-11-03 00:32:12,302:INFO: Batch: 28/31	Total Loss 5.1658 (4.9409)
2022-11-03 00:32:12,769:INFO: Batch: 29/31	Total Loss 5.0808 (4.9459)
2022-11-03 00:32:13,155:INFO: Batch: 30/31	Total Loss 2.1561 (4.9187)
2022-11-03 00:32:13,308:INFO: - Computing ADE (validation o)
2022-11-03 00:32:13,878:INFO: 		 ADE on eth                       dataset:	 1.0867842435836792
2022-11-03 00:32:13,878:INFO: Average validation o:	ADE  1.0868	FDE  1.8202
2022-11-03 00:32:13,879:INFO: - Computing ADE (validation)
2022-11-03 00:32:14,153:INFO: 		 ADE on hotel                     dataset:	 0.5098180174827576
2022-11-03 00:32:14,439:INFO: 		 ADE on univ                      dataset:	 0.6007575988769531
2022-11-03 00:32:14,696:INFO: 		 ADE on zara1                     dataset:	 0.5736442804336548
2022-11-03 00:32:15,041:INFO: 		 ADE on zara2                     dataset:	 0.47414717078208923
2022-11-03 00:32:15,041:INFO: Average validation:	ADE  0.5478	FDE  1.0171
2022-11-03 00:32:15,042:INFO: - Computing ADE (training)
2022-11-03 00:32:15,480:INFO: 		 ADE on hotel                     dataset:	 0.5665519833564758
2022-11-03 00:32:16,207:INFO: 		 ADE on univ                      dataset:	 0.5767548084259033
2022-11-03 00:32:16,736:INFO: 		 ADE on zara1                     dataset:	 0.6619578003883362
2022-11-03 00:32:17,476:INFO: 		 ADE on zara2                     dataset:	 0.5164310336112976
2022-11-03 00:32:17,476:INFO: Average training:	ADE  0.5697	FDE  1.0690
2022-11-03 00:32:17,485:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_373.pth.tar
2022-11-03 00:32:17,485:INFO: 
===> EPOCH: 374 (P3)
2022-11-03 00:32:17,485:INFO: - Computing loss (training)
2022-11-03 00:32:18,561:INFO: Batch:  0/31	Total Loss 4.6379 (4.6379)
2022-11-03 00:32:19,036:INFO: Batch:  1/31	Total Loss 4.5568 (4.5950)
2022-11-03 00:32:19,511:INFO: Batch:  2/31	Total Loss 4.8015 (4.6655)
2022-11-03 00:32:19,992:INFO: Batch:  3/31	Total Loss 5.1300 (4.7899)
2022-11-03 00:32:20,466:INFO: Batch:  4/31	Total Loss 4.4352 (4.7214)
2022-11-03 00:32:20,940:INFO: Batch:  5/31	Total Loss 4.5902 (4.7001)
2022-11-03 00:32:21,413:INFO: Batch:  6/31	Total Loss 5.3229 (4.7868)
2022-11-03 00:32:21,883:INFO: Batch:  7/31	Total Loss 4.7367 (4.7811)
2022-11-03 00:32:22,355:INFO: Batch:  8/31	Total Loss 4.9513 (4.7995)
2022-11-03 00:32:22,827:INFO: Batch:  9/31	Total Loss 4.9661 (4.8167)
2022-11-03 00:32:23,299:INFO: Batch: 10/31	Total Loss 4.3323 (4.7733)
2022-11-03 00:32:23,774:INFO: Batch: 11/31	Total Loss 4.7216 (4.7690)
2022-11-03 00:32:24,254:INFO: Batch: 12/31	Total Loss 4.7962 (4.7710)
2022-11-03 00:32:24,730:INFO: Batch: 13/31	Total Loss 4.7199 (4.7671)
2022-11-03 00:32:25,203:INFO: Batch: 14/31	Total Loss 5.5819 (4.8184)
2022-11-03 00:32:25,679:INFO: Batch: 15/31	Total Loss 4.6444 (4.8062)
2022-11-03 00:32:26,155:INFO: Batch: 16/31	Total Loss 4.7705 (4.8040)
2022-11-03 00:32:26,632:INFO: Batch: 17/31	Total Loss 5.0718 (4.8196)
2022-11-03 00:32:27,108:INFO: Batch: 18/31	Total Loss 5.3319 (4.8462)
2022-11-03 00:32:27,583:INFO: Batch: 19/31	Total Loss 5.1386 (4.8620)
2022-11-03 00:32:28,057:INFO: Batch: 20/31	Total Loss 4.7347 (4.8560)
2022-11-03 00:32:28,531:INFO: Batch: 21/31	Total Loss 4.9406 (4.8592)
2022-11-03 00:32:29,004:INFO: Batch: 22/31	Total Loss 5.5284 (4.8916)
2022-11-03 00:32:29,484:INFO: Batch: 23/31	Total Loss 4.9990 (4.8961)
2022-11-03 00:32:29,959:INFO: Batch: 24/31	Total Loss 4.3621 (4.8748)
2022-11-03 00:32:30,434:INFO: Batch: 25/31	Total Loss 4.9247 (4.8764)
2022-11-03 00:32:30,907:INFO: Batch: 26/31	Total Loss 4.5837 (4.8652)
2022-11-03 00:32:31,379:INFO: Batch: 27/31	Total Loss 5.5151 (4.8881)
2022-11-03 00:32:31,852:INFO: Batch: 28/31	Total Loss 5.0577 (4.8937)
2022-11-03 00:32:32,324:INFO: Batch: 29/31	Total Loss 5.0925 (4.8992)
2022-11-03 00:32:32,717:INFO: Batch: 30/31	Total Loss 2.2961 (4.8718)
2022-11-03 00:32:32,865:INFO: - Computing ADE (validation o)
2022-11-03 00:32:33,484:INFO: 		 ADE on eth                       dataset:	 1.118012547492981
2022-11-03 00:32:33,484:INFO: Average validation o:	ADE  1.1180	FDE  1.8747
2022-11-03 00:32:33,485:INFO: - Computing ADE (validation)
2022-11-03 00:32:33,743:INFO: 		 ADE on hotel                     dataset:	 0.5082138776779175
2022-11-03 00:32:34,050:INFO: 		 ADE on univ                      dataset:	 0.6046145558357239
2022-11-03 00:32:34,293:INFO: 		 ADE on zara1                     dataset:	 0.6057398915290833
2022-11-03 00:32:34,654:INFO: 		 ADE on zara2                     dataset:	 0.5018172860145569
2022-11-03 00:32:34,654:INFO: Average validation:	ADE  0.5617	FDE  1.0426
2022-11-03 00:32:34,655:INFO: - Computing ADE (training)
2022-11-03 00:32:35,094:INFO: 		 ADE on hotel                     dataset:	 0.5627487301826477
2022-11-03 00:32:35,770:INFO: 		 ADE on univ                      dataset:	 0.5839444994926453
2022-11-03 00:32:36,312:INFO: 		 ADE on zara1                     dataset:	 0.706051230430603
2022-11-03 00:32:37,059:INFO: 		 ADE on zara2                     dataset:	 0.5528807640075684
2022-11-03 00:32:37,060:INFO: Average training:	ADE  0.5849	FDE  1.0986
2022-11-03 00:32:37,068:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_374.pth.tar
2022-11-03 00:32:37,068:INFO: 
===> EPOCH: 375 (P3)
2022-11-03 00:32:37,069:INFO: - Computing loss (training)
2022-11-03 00:32:38,167:INFO: Batch:  0/31	Total Loss 4.7647 (4.7647)
2022-11-03 00:32:38,640:INFO: Batch:  1/31	Total Loss 5.1439 (4.9350)
2022-11-03 00:32:39,110:INFO: Batch:  2/31	Total Loss 5.1344 (5.0071)
2022-11-03 00:32:39,575:INFO: Batch:  3/31	Total Loss 4.5797 (4.9007)
2022-11-03 00:32:40,047:INFO: Batch:  4/31	Total Loss 5.3502 (4.9943)
2022-11-03 00:32:40,519:INFO: Batch:  5/31	Total Loss 5.0104 (4.9972)
2022-11-03 00:32:40,990:INFO: Batch:  6/31	Total Loss 5.0919 (5.0099)
2022-11-03 00:32:41,466:INFO: Batch:  7/31	Total Loss 4.8526 (4.9874)
2022-11-03 00:32:41,937:INFO: Batch:  8/31	Total Loss 5.3164 (5.0207)
2022-11-03 00:32:42,407:INFO: Batch:  9/31	Total Loss 4.7588 (4.9949)
2022-11-03 00:32:42,957:INFO: Batch: 10/31	Total Loss 4.7331 (4.9712)
2022-11-03 00:32:43,429:INFO: Batch: 11/31	Total Loss 4.7157 (4.9498)
2022-11-03 00:32:43,903:INFO: Batch: 12/31	Total Loss 5.4236 (4.9819)
2022-11-03 00:32:44,380:INFO: Batch: 13/31	Total Loss 6.6098 (5.0992)
2022-11-03 00:32:44,854:INFO: Batch: 14/31	Total Loss 4.9360 (5.0882)
2022-11-03 00:32:45,330:INFO: Batch: 15/31	Total Loss 4.8694 (5.0753)
2022-11-03 00:32:45,799:INFO: Batch: 16/31	Total Loss 4.6845 (5.0517)
2022-11-03 00:32:46,270:INFO: Batch: 17/31	Total Loss 4.8951 (5.0443)
2022-11-03 00:32:46,754:INFO: Batch: 18/31	Total Loss 4.8113 (5.0314)
2022-11-03 00:32:47,225:INFO: Batch: 19/31	Total Loss 4.9913 (5.0293)
2022-11-03 00:32:47,696:INFO: Batch: 20/31	Total Loss 5.3111 (5.0428)
2022-11-03 00:32:48,165:INFO: Batch: 21/31	Total Loss 4.9101 (5.0372)
2022-11-03 00:32:48,637:INFO: Batch: 22/31	Total Loss 5.0592 (5.0382)
2022-11-03 00:32:49,106:INFO: Batch: 23/31	Total Loss 4.7429 (5.0241)
2022-11-03 00:32:49,574:INFO: Batch: 24/31	Total Loss 4.4062 (4.9977)
2022-11-03 00:32:50,045:INFO: Batch: 25/31	Total Loss 5.9813 (5.0339)
2022-11-03 00:32:50,522:INFO: Batch: 26/31	Total Loss 5.0595 (5.0349)
2022-11-03 00:32:50,993:INFO: Batch: 27/31	Total Loss 4.7487 (5.0249)
2022-11-03 00:32:51,462:INFO: Batch: 28/31	Total Loss 4.9143 (5.0213)
2022-11-03 00:32:51,931:INFO: Batch: 29/31	Total Loss 5.2614 (5.0293)
2022-11-03 00:32:52,316:INFO: Batch: 30/31	Total Loss 2.3331 (5.0058)
2022-11-03 00:32:52,462:INFO: - Computing ADE (validation o)
2022-11-03 00:32:53,050:INFO: 		 ADE on eth                       dataset:	 1.10797119140625
2022-11-03 00:32:53,051:INFO: Average validation o:	ADE  1.1080	FDE  1.8903
2022-11-03 00:32:53,051:INFO: - Computing ADE (validation)
2022-11-03 00:32:53,311:INFO: 		 ADE on hotel                     dataset:	 0.5162855386734009
2022-11-03 00:32:53,611:INFO: 		 ADE on univ                      dataset:	 0.6021914482116699
2022-11-03 00:32:53,860:INFO: 		 ADE on zara1                     dataset:	 0.6074052453041077
2022-11-03 00:32:54,210:INFO: 		 ADE on zara2                     dataset:	 0.5016836524009705
2022-11-03 00:32:54,211:INFO: Average validation:	ADE  0.5609	FDE  1.0565
2022-11-03 00:32:54,211:INFO: - Computing ADE (training)
2022-11-03 00:32:54,712:INFO: 		 ADE on hotel                     dataset:	 0.5756895542144775
2022-11-03 00:32:55,409:INFO: 		 ADE on univ                      dataset:	 0.5879325270652771
2022-11-03 00:32:55,940:INFO: 		 ADE on zara1                     dataset:	 0.6940453052520752
2022-11-03 00:32:56,674:INFO: 		 ADE on zara2                     dataset:	 0.5454965829849243
2022-11-03 00:32:56,675:INFO: Average training:	ADE  0.5858	FDE  1.1150
2022-11-03 00:32:56,683:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_375.pth.tar
2022-11-03 00:32:56,683:INFO: 
===> EPOCH: 376 (P3)
2022-11-03 00:32:56,684:INFO: - Computing loss (training)
2022-11-03 00:32:57,804:INFO: Batch:  0/31	Total Loss 4.6928 (4.6928)
2022-11-03 00:32:58,280:INFO: Batch:  1/31	Total Loss 4.9185 (4.8055)
2022-11-03 00:32:58,751:INFO: Batch:  2/31	Total Loss 5.2476 (4.9430)
2022-11-03 00:32:59,226:INFO: Batch:  3/31	Total Loss 5.0437 (4.9690)
2022-11-03 00:32:59,700:INFO: Batch:  4/31	Total Loss 4.8314 (4.9413)
2022-11-03 00:33:00,174:INFO: Batch:  5/31	Total Loss 4.4163 (4.8584)
2022-11-03 00:33:00,646:INFO: Batch:  6/31	Total Loss 5.1336 (4.8977)
2022-11-03 00:33:01,113:INFO: Batch:  7/31	Total Loss 4.6939 (4.8732)
2022-11-03 00:33:01,584:INFO: Batch:  8/31	Total Loss 5.0846 (4.8942)
2022-11-03 00:33:02,052:INFO: Batch:  9/31	Total Loss 4.9086 (4.8957)
2022-11-03 00:33:02,523:INFO: Batch: 10/31	Total Loss 4.9575 (4.9005)
2022-11-03 00:33:02,992:INFO: Batch: 11/31	Total Loss 5.5999 (4.9591)
2022-11-03 00:33:03,467:INFO: Batch: 12/31	Total Loss 5.1585 (4.9745)
2022-11-03 00:33:03,939:INFO: Batch: 13/31	Total Loss 4.5733 (4.9465)
2022-11-03 00:33:04,411:INFO: Batch: 14/31	Total Loss 5.0145 (4.9513)
2022-11-03 00:33:04,883:INFO: Batch: 15/31	Total Loss 5.0939 (4.9615)
2022-11-03 00:33:05,358:INFO: Batch: 16/31	Total Loss 4.9856 (4.9628)
2022-11-03 00:33:05,834:INFO: Batch: 17/31	Total Loss 4.5758 (4.9403)
2022-11-03 00:33:06,313:INFO: Batch: 18/31	Total Loss 5.2254 (4.9543)
2022-11-03 00:33:06,791:INFO: Batch: 19/31	Total Loss 5.0147 (4.9572)
2022-11-03 00:33:07,268:INFO: Batch: 20/31	Total Loss 5.0034 (4.9594)
2022-11-03 00:33:07,744:INFO: Batch: 21/31	Total Loss 5.0118 (4.9619)
2022-11-03 00:33:08,219:INFO: Batch: 22/31	Total Loss 4.5943 (4.9463)
2022-11-03 00:33:08,695:INFO: Batch: 23/31	Total Loss 4.9159 (4.9451)
2022-11-03 00:33:09,171:INFO: Batch: 24/31	Total Loss 4.9035 (4.9434)
2022-11-03 00:33:09,646:INFO: Batch: 25/31	Total Loss 4.7490 (4.9356)
2022-11-03 00:33:10,125:INFO: Batch: 26/31	Total Loss 4.0819 (4.9025)
2022-11-03 00:33:10,600:INFO: Batch: 27/31	Total Loss 4.7522 (4.8975)
2022-11-03 00:33:11,076:INFO: Batch: 28/31	Total Loss 4.5832 (4.8856)
2022-11-03 00:33:11,551:INFO: Batch: 29/31	Total Loss 4.7166 (4.8807)
2022-11-03 00:33:11,942:INFO: Batch: 30/31	Total Loss 2.1643 (4.8531)
2022-11-03 00:33:12,086:INFO: - Computing ADE (validation o)
2022-11-03 00:33:12,652:INFO: 		 ADE on eth                       dataset:	 1.085146427154541
2022-11-03 00:33:12,653:INFO: Average validation o:	ADE  1.0851	FDE  1.8796
2022-11-03 00:33:12,653:INFO: - Computing ADE (validation)
2022-11-03 00:33:12,920:INFO: 		 ADE on hotel                     dataset:	 0.49942344427108765
2022-11-03 00:33:13,223:INFO: 		 ADE on univ                      dataset:	 0.589363157749176
2022-11-03 00:33:13,478:INFO: 		 ADE on zara1                     dataset:	 0.5694234371185303
2022-11-03 00:33:13,823:INFO: 		 ADE on zara2                     dataset:	 0.48469725251197815
2022-11-03 00:33:13,824:INFO: Average validation:	ADE  0.5449	FDE  1.0402
2022-11-03 00:33:13,824:INFO: - Computing ADE (training)
2022-11-03 00:33:14,298:INFO: 		 ADE on hotel                     dataset:	 0.5461168885231018
2022-11-03 00:33:14,971:INFO: 		 ADE on univ                      dataset:	 0.5774906873703003
2022-11-03 00:33:15,535:INFO: 		 ADE on zara1                     dataset:	 0.64604252576828
2022-11-03 00:33:16,300:INFO: 		 ADE on zara2                     dataset:	 0.5183582305908203
2022-11-03 00:33:16,301:INFO: Average training:	ADE  0.5691	FDE  1.0994
2022-11-03 00:33:16,310:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_376.pth.tar
2022-11-03 00:33:16,310:INFO: 
===> EPOCH: 377 (P3)
2022-11-03 00:33:16,310:INFO: - Computing loss (training)
2022-11-03 00:33:17,392:INFO: Batch:  0/31	Total Loss 5.3847 (5.3847)
2022-11-03 00:33:17,868:INFO: Batch:  1/31	Total Loss 5.3786 (5.3817)
2022-11-03 00:33:18,338:INFO: Batch:  2/31	Total Loss 4.7871 (5.1811)
2022-11-03 00:33:18,807:INFO: Batch:  3/31	Total Loss 5.2581 (5.2016)
2022-11-03 00:33:19,276:INFO: Batch:  4/31	Total Loss 4.4515 (5.0509)
2022-11-03 00:33:19,745:INFO: Batch:  5/31	Total Loss 4.7060 (4.9943)
2022-11-03 00:33:20,213:INFO: Batch:  6/31	Total Loss 5.3871 (5.0437)
2022-11-03 00:33:20,678:INFO: Batch:  7/31	Total Loss 4.6827 (4.9968)
2022-11-03 00:33:21,146:INFO: Batch:  8/31	Total Loss 5.0599 (5.0039)
2022-11-03 00:33:21,613:INFO: Batch:  9/31	Total Loss 4.8704 (4.9897)
2022-11-03 00:33:22,080:INFO: Batch: 10/31	Total Loss 4.5704 (4.9514)
2022-11-03 00:33:22,547:INFO: Batch: 11/31	Total Loss 5.0107 (4.9558)
2022-11-03 00:33:23,017:INFO: Batch: 12/31	Total Loss 4.4479 (4.9165)
2022-11-03 00:33:23,487:INFO: Batch: 13/31	Total Loss 4.6863 (4.9008)
2022-11-03 00:33:23,956:INFO: Batch: 14/31	Total Loss 4.7250 (4.8896)
2022-11-03 00:33:24,425:INFO: Batch: 15/31	Total Loss 4.8354 (4.8863)
2022-11-03 00:33:24,894:INFO: Batch: 16/31	Total Loss 4.9952 (4.8931)
2022-11-03 00:33:25,364:INFO: Batch: 17/31	Total Loss 5.7527 (4.9410)
2022-11-03 00:33:25,834:INFO: Batch: 18/31	Total Loss 5.1061 (4.9502)
2022-11-03 00:33:26,302:INFO: Batch: 19/31	Total Loss 4.3752 (4.9229)
2022-11-03 00:33:26,772:INFO: Batch: 20/31	Total Loss 4.8250 (4.9181)
2022-11-03 00:33:27,242:INFO: Batch: 21/31	Total Loss 4.8617 (4.9152)
2022-11-03 00:33:27,711:INFO: Batch: 22/31	Total Loss 6.5262 (4.9822)
2022-11-03 00:33:28,180:INFO: Batch: 23/31	Total Loss 5.8827 (5.0237)
2022-11-03 00:33:28,649:INFO: Batch: 24/31	Total Loss 5.3028 (5.0348)
2022-11-03 00:33:29,121:INFO: Batch: 25/31	Total Loss 5.2498 (5.0438)
2022-11-03 00:33:29,591:INFO: Batch: 26/31	Total Loss 5.7324 (5.0706)
2022-11-03 00:33:30,065:INFO: Batch: 27/31	Total Loss 5.2491 (5.0775)
2022-11-03 00:33:30,536:INFO: Batch: 28/31	Total Loss 5.0364 (5.0762)
2022-11-03 00:33:31,005:INFO: Batch: 29/31	Total Loss 4.7069 (5.0638)
2022-11-03 00:33:31,390:INFO: Batch: 30/31	Total Loss 1.9286 (5.0326)
2022-11-03 00:33:31,541:INFO: - Computing ADE (validation o)
2022-11-03 00:33:32,141:INFO: 		 ADE on eth                       dataset:	 1.0715322494506836
2022-11-03 00:33:32,141:INFO: Average validation o:	ADE  1.0715	FDE  1.8483
2022-11-03 00:33:32,142:INFO: - Computing ADE (validation)
2022-11-03 00:33:32,415:INFO: 		 ADE on hotel                     dataset:	 0.5466734170913696
2022-11-03 00:33:32,714:INFO: 		 ADE on univ                      dataset:	 0.629950225353241
2022-11-03 00:33:32,959:INFO: 		 ADE on zara1                     dataset:	 0.5595798492431641
2022-11-03 00:33:33,291:INFO: 		 ADE on zara2                     dataset:	 0.4920037090778351
2022-11-03 00:33:33,291:INFO: Average validation:	ADE  0.5707	FDE  1.1140
2022-11-03 00:33:33,292:INFO: - Computing ADE (training)
2022-11-03 00:33:33,753:INFO: 		 ADE on hotel                     dataset:	 0.6108918190002441
2022-11-03 00:33:34,461:INFO: 		 ADE on univ                      dataset:	 0.5934536457061768
2022-11-03 00:33:35,007:INFO: 		 ADE on zara1                     dataset:	 0.6453043222427368
2022-11-03 00:33:35,849:INFO: 		 ADE on zara2                     dataset:	 0.5271660685539246
2022-11-03 00:33:35,850:INFO: Average training:	ADE  0.5838	FDE  1.1399
2022-11-03 00:33:35,858:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_377.pth.tar
2022-11-03 00:33:35,858:INFO: 
===> EPOCH: 378 (P3)
2022-11-03 00:33:35,859:INFO: - Computing loss (training)
2022-11-03 00:33:36,973:INFO: Batch:  0/31	Total Loss 5.1275 (5.1275)
2022-11-03 00:33:37,456:INFO: Batch:  1/31	Total Loss 5.8085 (5.4742)
2022-11-03 00:33:37,935:INFO: Batch:  2/31	Total Loss 4.7106 (5.2201)
2022-11-03 00:33:38,407:INFO: Batch:  3/31	Total Loss 5.4960 (5.2848)
2022-11-03 00:33:38,879:INFO: Batch:  4/31	Total Loss 5.3911 (5.3066)
2022-11-03 00:33:39,356:INFO: Batch:  5/31	Total Loss 5.0336 (5.2657)
2022-11-03 00:33:39,827:INFO: Batch:  6/31	Total Loss 4.4968 (5.1536)
2022-11-03 00:33:40,298:INFO: Batch:  7/31	Total Loss 6.0791 (5.2643)
2022-11-03 00:33:40,770:INFO: Batch:  8/31	Total Loss 5.1281 (5.2489)
2022-11-03 00:33:41,244:INFO: Batch:  9/31	Total Loss 4.5420 (5.1723)
2022-11-03 00:33:41,716:INFO: Batch: 10/31	Total Loss 4.9036 (5.1488)
2022-11-03 00:33:42,189:INFO: Batch: 11/31	Total Loss 4.9691 (5.1346)
2022-11-03 00:33:42,664:INFO: Batch: 12/31	Total Loss 6.3625 (5.2169)
2022-11-03 00:33:43,139:INFO: Batch: 13/31	Total Loss 5.1522 (5.2120)
2022-11-03 00:33:43,615:INFO: Batch: 14/31	Total Loss 4.7624 (5.1833)
2022-11-03 00:33:44,089:INFO: Batch: 15/31	Total Loss 4.8546 (5.1647)
2022-11-03 00:33:44,566:INFO: Batch: 16/31	Total Loss 4.9095 (5.1506)
2022-11-03 00:33:45,042:INFO: Batch: 17/31	Total Loss 4.7939 (5.1291)
2022-11-03 00:33:45,516:INFO: Batch: 18/31	Total Loss 4.9687 (5.1212)
2022-11-03 00:33:45,990:INFO: Batch: 19/31	Total Loss 5.1980 (5.1250)
2022-11-03 00:33:46,466:INFO: Batch: 20/31	Total Loss 4.7604 (5.1073)
2022-11-03 00:33:46,939:INFO: Batch: 21/31	Total Loss 4.5865 (5.0823)
2022-11-03 00:33:47,412:INFO: Batch: 22/31	Total Loss 4.4942 (5.0542)
2022-11-03 00:33:47,885:INFO: Batch: 23/31	Total Loss 5.6640 (5.0782)
2022-11-03 00:33:48,359:INFO: Batch: 24/31	Total Loss 4.2648 (5.0451)
2022-11-03 00:33:48,832:INFO: Batch: 25/31	Total Loss 4.6766 (5.0323)
2022-11-03 00:33:49,306:INFO: Batch: 26/31	Total Loss 5.4481 (5.0464)
2022-11-03 00:33:49,783:INFO: Batch: 27/31	Total Loss 4.6467 (5.0332)
2022-11-03 00:33:50,259:INFO: Batch: 28/31	Total Loss 5.6356 (5.0530)
2022-11-03 00:33:50,740:INFO: Batch: 29/31	Total Loss 4.7760 (5.0451)
2022-11-03 00:33:51,131:INFO: Batch: 30/31	Total Loss 1.6147 (5.0142)
2022-11-03 00:33:51,283:INFO: - Computing ADE (validation o)
2022-11-03 00:33:51,874:INFO: 		 ADE on eth                       dataset:	 1.1051162481307983
2022-11-03 00:33:51,875:INFO: Average validation o:	ADE  1.1051	FDE  1.8729
2022-11-03 00:33:51,875:INFO: - Computing ADE (validation)
2022-11-03 00:33:52,159:INFO: 		 ADE on hotel                     dataset:	 0.544909656047821
2022-11-03 00:33:52,443:INFO: 		 ADE on univ                      dataset:	 0.6214114427566528
2022-11-03 00:33:52,700:INFO: 		 ADE on zara1                     dataset:	 0.5556522011756897
2022-11-03 00:33:53,040:INFO: 		 ADE on zara2                     dataset:	 0.5010011196136475
2022-11-03 00:33:53,040:INFO: Average validation:	ADE  0.5692	FDE  1.0899
2022-11-03 00:33:53,041:INFO: - Computing ADE (training)
2022-11-03 00:33:53,526:INFO: 		 ADE on hotel                     dataset:	 0.6071251630783081
2022-11-03 00:33:54,205:INFO: 		 ADE on univ                      dataset:	 0.5915724635124207
2022-11-03 00:33:54,742:INFO: 		 ADE on zara1                     dataset:	 0.6638921499252319
2022-11-03 00:33:55,500:INFO: 		 ADE on zara2                     dataset:	 0.5441859364509583
2022-11-03 00:33:55,500:INFO: Average training:	ADE  0.5870	FDE  1.1274
2022-11-03 00:33:55,509:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_378.pth.tar
2022-11-03 00:33:55,509:INFO: 
===> EPOCH: 379 (P3)
2022-11-03 00:33:55,510:INFO: - Computing loss (training)
2022-11-03 00:33:56,620:INFO: Batch:  0/31	Total Loss 4.4380 (4.4380)
2022-11-03 00:33:57,096:INFO: Batch:  1/31	Total Loss 4.8110 (4.6319)
2022-11-03 00:33:57,576:INFO: Batch:  2/31	Total Loss 5.1020 (4.7737)
2022-11-03 00:33:58,048:INFO: Batch:  3/31	Total Loss 5.1294 (4.8663)
2022-11-03 00:33:58,521:INFO: Batch:  4/31	Total Loss 4.5100 (4.7949)
2022-11-03 00:33:59,000:INFO: Batch:  5/31	Total Loss 4.3473 (4.7118)
2022-11-03 00:33:59,479:INFO: Batch:  6/31	Total Loss 5.1952 (4.7773)
2022-11-03 00:33:59,956:INFO: Batch:  7/31	Total Loss 5.0512 (4.8106)
2022-11-03 00:34:00,433:INFO: Batch:  8/31	Total Loss 5.6464 (4.9029)
2022-11-03 00:34:00,912:INFO: Batch:  9/31	Total Loss 5.5095 (4.9627)
2022-11-03 00:34:01,389:INFO: Batch: 10/31	Total Loss 4.9526 (4.9618)
2022-11-03 00:34:01,864:INFO: Batch: 11/31	Total Loss 4.9543 (4.9611)
2022-11-03 00:34:02,345:INFO: Batch: 12/31	Total Loss 4.6560 (4.9344)
2022-11-03 00:34:02,826:INFO: Batch: 13/31	Total Loss 4.9281 (4.9339)
2022-11-03 00:34:03,304:INFO: Batch: 14/31	Total Loss 4.4699 (4.9051)
2022-11-03 00:34:03,785:INFO: Batch: 15/31	Total Loss 4.3304 (4.8701)
2022-11-03 00:34:04,263:INFO: Batch: 16/31	Total Loss 5.4876 (4.9054)
2022-11-03 00:34:04,744:INFO: Batch: 17/31	Total Loss 4.2430 (4.8691)
2022-11-03 00:34:05,224:INFO: Batch: 18/31	Total Loss 4.8783 (4.8696)
2022-11-03 00:34:05,703:INFO: Batch: 19/31	Total Loss 5.4356 (4.8987)
2022-11-03 00:34:06,180:INFO: Batch: 20/31	Total Loss 4.5336 (4.8828)
2022-11-03 00:34:06,661:INFO: Batch: 21/31	Total Loss 4.7657 (4.8770)
2022-11-03 00:34:07,138:INFO: Batch: 22/31	Total Loss 4.9696 (4.8807)
2022-11-03 00:34:07,616:INFO: Batch: 23/31	Total Loss 5.0674 (4.8880)
2022-11-03 00:34:08,092:INFO: Batch: 24/31	Total Loss 6.1845 (4.9380)
2022-11-03 00:34:08,568:INFO: Batch: 25/31	Total Loss 4.7529 (4.9309)
2022-11-03 00:34:09,045:INFO: Batch: 26/31	Total Loss 4.8043 (4.9261)
2022-11-03 00:34:09,523:INFO: Batch: 27/31	Total Loss 5.2205 (4.9376)
2022-11-03 00:34:10,001:INFO: Batch: 28/31	Total Loss 4.5890 (4.9260)
2022-11-03 00:34:10,479:INFO: Batch: 29/31	Total Loss 4.6781 (4.9172)
2022-11-03 00:34:10,869:INFO: Batch: 30/31	Total Loss 1.9697 (4.8885)
2022-11-03 00:34:11,011:INFO: - Computing ADE (validation o)
2022-11-03 00:34:11,604:INFO: 		 ADE on eth                       dataset:	 1.0938773155212402
2022-11-03 00:34:11,605:INFO: Average validation o:	ADE  1.0939	FDE  1.8759
2022-11-03 00:34:11,605:INFO: - Computing ADE (validation)
2022-11-03 00:34:11,885:INFO: 		 ADE on hotel                     dataset:	 0.5037881135940552
2022-11-03 00:34:12,172:INFO: 		 ADE on univ                      dataset:	 0.5944904088973999
2022-11-03 00:34:12,420:INFO: 		 ADE on zara1                     dataset:	 0.5784333944320679
2022-11-03 00:34:12,752:INFO: 		 ADE on zara2                     dataset:	 0.47865551710128784
2022-11-03 00:34:12,752:INFO: Average validation:	ADE  0.5461	FDE  1.0270
2022-11-03 00:34:12,753:INFO: - Computing ADE (training)
2022-11-03 00:34:13,223:INFO: 		 ADE on hotel                     dataset:	 0.5586223602294922
2022-11-03 00:34:13,923:INFO: 		 ADE on univ                      dataset:	 0.5754691958427429
2022-11-03 00:34:14,465:INFO: 		 ADE on zara1                     dataset:	 0.6626191139221191
2022-11-03 00:34:15,222:INFO: 		 ADE on zara2                     dataset:	 0.519415557384491
2022-11-03 00:34:15,223:INFO: Average training:	ADE  0.5692	FDE  1.0814
2022-11-03 00:34:15,233:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_379.pth.tar
2022-11-03 00:34:15,233:INFO: 
===> EPOCH: 380 (P3)
2022-11-03 00:34:15,233:INFO: - Computing loss (training)
2022-11-03 00:34:16,328:INFO: Batch:  0/31	Total Loss 5.2209 (5.2209)
2022-11-03 00:34:16,805:INFO: Batch:  1/31	Total Loss 4.3967 (4.8050)
2022-11-03 00:34:17,287:INFO: Batch:  2/31	Total Loss 4.5411 (4.7184)
2022-11-03 00:34:17,764:INFO: Batch:  3/31	Total Loss 4.5674 (4.6811)
2022-11-03 00:34:18,244:INFO: Batch:  4/31	Total Loss 4.9781 (4.7400)
2022-11-03 00:34:18,725:INFO: Batch:  5/31	Total Loss 5.0681 (4.7913)
2022-11-03 00:34:19,207:INFO: Batch:  6/31	Total Loss 4.4725 (4.7425)
2022-11-03 00:34:19,692:INFO: Batch:  7/31	Total Loss 5.0585 (4.7809)
2022-11-03 00:34:20,162:INFO: Batch:  8/31	Total Loss 4.7399 (4.7768)
2022-11-03 00:34:20,629:INFO: Batch:  9/31	Total Loss 4.5083 (4.7515)
2022-11-03 00:34:21,100:INFO: Batch: 10/31	Total Loss 4.9919 (4.7720)
2022-11-03 00:34:21,570:INFO: Batch: 11/31	Total Loss 4.3621 (4.7379)
2022-11-03 00:34:22,046:INFO: Batch: 12/31	Total Loss 5.5531 (4.8031)
2022-11-03 00:34:22,519:INFO: Batch: 13/31	Total Loss 4.6645 (4.7925)
2022-11-03 00:34:22,994:INFO: Batch: 14/31	Total Loss 5.0910 (4.8138)
2022-11-03 00:34:23,468:INFO: Batch: 15/31	Total Loss 4.8923 (4.8185)
2022-11-03 00:34:24,020:INFO: Batch: 16/31	Total Loss 4.9458 (4.8254)
2022-11-03 00:34:24,495:INFO: Batch: 17/31	Total Loss 4.7335 (4.8199)
2022-11-03 00:34:24,969:INFO: Batch: 18/31	Total Loss 5.2746 (4.8416)
2022-11-03 00:34:25,440:INFO: Batch: 19/31	Total Loss 6.2092 (4.9068)
2022-11-03 00:34:25,913:INFO: Batch: 20/31	Total Loss 4.3977 (4.8796)
2022-11-03 00:34:26,385:INFO: Batch: 21/31	Total Loss 5.5487 (4.9125)
2022-11-03 00:34:26,863:INFO: Batch: 22/31	Total Loss 5.2731 (4.9281)
2022-11-03 00:34:27,335:INFO: Batch: 23/31	Total Loss 5.2181 (4.9410)
2022-11-03 00:34:27,806:INFO: Batch: 24/31	Total Loss 4.7371 (4.9333)
2022-11-03 00:34:28,279:INFO: Batch: 25/31	Total Loss 5.0961 (4.9388)
2022-11-03 00:34:28,753:INFO: Batch: 26/31	Total Loss 5.9485 (4.9747)
2022-11-03 00:34:29,232:INFO: Batch: 27/31	Total Loss 4.4129 (4.9533)
2022-11-03 00:34:29,706:INFO: Batch: 28/31	Total Loss 5.5912 (4.9749)
2022-11-03 00:34:30,181:INFO: Batch: 29/31	Total Loss 4.6912 (4.9661)
2022-11-03 00:34:30,570:INFO: Batch: 30/31	Total Loss 2.2049 (4.9376)
2022-11-03 00:34:30,728:INFO: - Computing ADE (validation o)
2022-11-03 00:34:31,323:INFO: 		 ADE on eth                       dataset:	 1.1799768209457397
2022-11-03 00:34:31,323:INFO: Average validation o:	ADE  1.1800	FDE  2.1164
2022-11-03 00:34:31,324:INFO: - Computing ADE (validation)
2022-11-03 00:34:31,593:INFO: 		 ADE on hotel                     dataset:	 0.6332073211669922
2022-11-03 00:34:31,885:INFO: 		 ADE on univ                      dataset:	 0.6804139018058777
2022-11-03 00:34:32,138:INFO: 		 ADE on zara1                     dataset:	 0.7957034707069397
2022-11-03 00:34:32,479:INFO: 		 ADE on zara2                     dataset:	 0.6409136056900024
2022-11-03 00:34:32,479:INFO: Average validation:	ADE  0.6700	FDE  1.3853
2022-11-03 00:34:32,480:INFO: - Computing ADE (training)
2022-11-03 00:34:32,937:INFO: 		 ADE on hotel                     dataset:	 0.6740238070487976
2022-11-03 00:34:33,643:INFO: 		 ADE on univ                      dataset:	 0.6876674294471741
2022-11-03 00:34:34,184:INFO: 		 ADE on zara1                     dataset:	 0.7898970246315002
2022-11-03 00:34:34,931:INFO: 		 ADE on zara2                     dataset:	 0.6707471013069153
2022-11-03 00:34:34,931:INFO: Average training:	ADE  0.6904	FDE  1.4377
2022-11-03 00:34:34,940:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_380.pth.tar
2022-11-03 00:34:34,940:INFO: 
===> EPOCH: 381 (P3)
2022-11-03 00:34:34,940:INFO: - Computing loss (training)
2022-11-03 00:34:36,036:INFO: Batch:  0/31	Total Loss 6.0655 (6.0655)
2022-11-03 00:34:36,508:INFO: Batch:  1/31	Total Loss 6.3711 (6.2134)
2022-11-03 00:34:36,984:INFO: Batch:  2/31	Total Loss 5.3033 (5.9184)
2022-11-03 00:34:37,449:INFO: Batch:  3/31	Total Loss 5.5223 (5.8134)
2022-11-03 00:34:37,917:INFO: Batch:  4/31	Total Loss 6.1388 (5.8737)
2022-11-03 00:34:38,389:INFO: Batch:  5/31	Total Loss 5.0749 (5.7238)
2022-11-03 00:34:38,859:INFO: Batch:  6/31	Total Loss 4.7707 (5.5858)
2022-11-03 00:34:39,330:INFO: Batch:  7/31	Total Loss 5.1436 (5.5275)
2022-11-03 00:34:39,799:INFO: Batch:  8/31	Total Loss 5.8650 (5.5641)
2022-11-03 00:34:40,268:INFO: Batch:  9/31	Total Loss 4.5181 (5.4675)
2022-11-03 00:34:40,739:INFO: Batch: 10/31	Total Loss 4.6521 (5.3954)
2022-11-03 00:34:41,210:INFO: Batch: 11/31	Total Loss 4.4097 (5.3055)
2022-11-03 00:34:41,683:INFO: Batch: 12/31	Total Loss 5.7115 (5.3358)
2022-11-03 00:34:42,156:INFO: Batch: 13/31	Total Loss 5.0630 (5.3169)
2022-11-03 00:34:42,629:INFO: Batch: 14/31	Total Loss 4.8908 (5.2887)
2022-11-03 00:34:43,103:INFO: Batch: 15/31	Total Loss 4.9385 (5.2661)
2022-11-03 00:34:43,580:INFO: Batch: 16/31	Total Loss 4.7647 (5.2355)
2022-11-03 00:34:44,053:INFO: Batch: 17/31	Total Loss 5.0246 (5.2243)
2022-11-03 00:34:44,531:INFO: Batch: 18/31	Total Loss 4.8896 (5.2065)
2022-11-03 00:34:45,004:INFO: Batch: 19/31	Total Loss 4.9351 (5.1929)
2022-11-03 00:34:45,477:INFO: Batch: 20/31	Total Loss 5.8103 (5.2203)
2022-11-03 00:34:45,950:INFO: Batch: 21/31	Total Loss 5.1243 (5.2158)
2022-11-03 00:34:46,422:INFO: Batch: 22/31	Total Loss 4.7080 (5.1906)
2022-11-03 00:34:46,895:INFO: Batch: 23/31	Total Loss 5.1022 (5.1872)
2022-11-03 00:34:47,366:INFO: Batch: 24/31	Total Loss 4.4160 (5.1585)
2022-11-03 00:34:47,838:INFO: Batch: 25/31	Total Loss 4.5327 (5.1347)
2022-11-03 00:34:48,310:INFO: Batch: 26/31	Total Loss 4.3827 (5.1059)
2022-11-03 00:34:48,783:INFO: Batch: 27/31	Total Loss 5.3167 (5.1138)
2022-11-03 00:34:49,255:INFO: Batch: 28/31	Total Loss 4.1730 (5.0780)
2022-11-03 00:34:49,731:INFO: Batch: 29/31	Total Loss 4.5996 (5.0597)
2022-11-03 00:34:50,118:INFO: Batch: 30/31	Total Loss 1.6705 (5.0319)
2022-11-03 00:34:50,272:INFO: - Computing ADE (validation o)
2022-11-03 00:34:50,862:INFO: 		 ADE on eth                       dataset:	 1.074389934539795
2022-11-03 00:34:50,863:INFO: Average validation o:	ADE  1.0744	FDE  1.8445
2022-11-03 00:34:50,863:INFO: - Computing ADE (validation)
2022-11-03 00:34:51,124:INFO: 		 ADE on hotel                     dataset:	 0.5331131219863892
2022-11-03 00:34:51,412:INFO: 		 ADE on univ                      dataset:	 0.6100015640258789
2022-11-03 00:34:51,668:INFO: 		 ADE on zara1                     dataset:	 0.533089816570282
2022-11-03 00:34:52,003:INFO: 		 ADE on zara2                     dataset:	 0.4922690689563751
2022-11-03 00:34:52,003:INFO: Average validation:	ADE  0.5581	FDE  1.0722
2022-11-03 00:34:52,004:INFO: - Computing ADE (training)
2022-11-03 00:34:52,462:INFO: 		 ADE on hotel                     dataset:	 0.5815945267677307
2022-11-03 00:34:53,153:INFO: 		 ADE on univ                      dataset:	 0.5840394496917725
2022-11-03 00:34:53,671:INFO: 		 ADE on zara1                     dataset:	 0.644402265548706
2022-11-03 00:34:54,429:INFO: 		 ADE on zara2                     dataset:	 0.5310481190681458
2022-11-03 00:34:54,429:INFO: Average training:	ADE  0.5771	FDE  1.1153
2022-11-03 00:34:54,437:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_381.pth.tar
2022-11-03 00:34:54,437:INFO: 
===> EPOCH: 382 (P3)
2022-11-03 00:34:54,438:INFO: - Computing loss (training)
2022-11-03 00:34:55,534:INFO: Batch:  0/31	Total Loss 5.0342 (5.0342)
2022-11-03 00:34:56,010:INFO: Batch:  1/31	Total Loss 4.6106 (4.8278)
2022-11-03 00:34:56,482:INFO: Batch:  2/31	Total Loss 5.0440 (4.8927)
2022-11-03 00:34:56,955:INFO: Batch:  3/31	Total Loss 4.7417 (4.8543)
2022-11-03 00:34:57,426:INFO: Batch:  4/31	Total Loss 5.0363 (4.8883)
2022-11-03 00:34:57,899:INFO: Batch:  5/31	Total Loss 4.8264 (4.8781)
2022-11-03 00:34:58,370:INFO: Batch:  6/31	Total Loss 4.4871 (4.8222)
2022-11-03 00:34:58,840:INFO: Batch:  7/31	Total Loss 5.1601 (4.8631)
2022-11-03 00:34:59,314:INFO: Batch:  8/31	Total Loss 6.0680 (4.9896)
2022-11-03 00:34:59,784:INFO: Batch:  9/31	Total Loss 4.8447 (4.9750)
2022-11-03 00:35:00,259:INFO: Batch: 10/31	Total Loss 4.7563 (4.9566)
2022-11-03 00:35:00,730:INFO: Batch: 11/31	Total Loss 4.9652 (4.9572)
2022-11-03 00:35:01,206:INFO: Batch: 12/31	Total Loss 4.7342 (4.9397)
2022-11-03 00:35:01,682:INFO: Batch: 13/31	Total Loss 4.7118 (4.9244)
2022-11-03 00:35:02,158:INFO: Batch: 14/31	Total Loss 4.9054 (4.9231)
2022-11-03 00:35:02,633:INFO: Batch: 15/31	Total Loss 4.7878 (4.9144)
2022-11-03 00:35:03,108:INFO: Batch: 16/31	Total Loss 4.7160 (4.9023)
2022-11-03 00:35:03,582:INFO: Batch: 17/31	Total Loss 4.2198 (4.8649)
2022-11-03 00:35:04,058:INFO: Batch: 18/31	Total Loss 4.9378 (4.8693)
2022-11-03 00:35:04,530:INFO: Batch: 19/31	Total Loss 4.8631 (4.8690)
2022-11-03 00:35:05,004:INFO: Batch: 20/31	Total Loss 4.7869 (4.8655)
2022-11-03 00:35:05,479:INFO: Batch: 21/31	Total Loss 4.7989 (4.8624)
2022-11-03 00:35:05,953:INFO: Batch: 22/31	Total Loss 4.7646 (4.8578)
2022-11-03 00:35:06,429:INFO: Batch: 23/31	Total Loss 4.3035 (4.8326)
2022-11-03 00:35:06,903:INFO: Batch: 24/31	Total Loss 4.8521 (4.8335)
2022-11-03 00:35:07,376:INFO: Batch: 25/31	Total Loss 5.0427 (4.8412)
2022-11-03 00:35:07,850:INFO: Batch: 26/31	Total Loss 4.3942 (4.8249)
2022-11-03 00:35:08,325:INFO: Batch: 27/31	Total Loss 5.8191 (4.8599)
2022-11-03 00:35:08,801:INFO: Batch: 28/31	Total Loss 5.4612 (4.8828)
2022-11-03 00:35:09,275:INFO: Batch: 29/31	Total Loss 5.1484 (4.8916)
2022-11-03 00:35:09,665:INFO: Batch: 30/31	Total Loss 2.1765 (4.8730)
2022-11-03 00:35:09,823:INFO: - Computing ADE (validation o)
2022-11-03 00:35:10,430:INFO: 		 ADE on eth                       dataset:	 1.0696138143539429
2022-11-03 00:35:10,431:INFO: Average validation o:	ADE  1.0696	FDE  1.9409
2022-11-03 00:35:10,431:INFO: - Computing ADE (validation)
2022-11-03 00:35:10,691:INFO: 		 ADE on hotel                     dataset:	 0.5326946973800659
2022-11-03 00:35:11,003:INFO: 		 ADE on univ                      dataset:	 0.6095722913742065
2022-11-03 00:35:11,250:INFO: 		 ADE on zara1                     dataset:	 0.603691041469574
2022-11-03 00:35:11,604:INFO: 		 ADE on zara2                     dataset:	 0.5006752014160156
2022-11-03 00:35:11,604:INFO: Average validation:	ADE  0.5651	FDE  1.1286
2022-11-03 00:35:11,605:INFO: - Computing ADE (training)
2022-11-03 00:35:12,061:INFO: 		 ADE on hotel                     dataset:	 0.5812104940414429
2022-11-03 00:35:12,748:INFO: 		 ADE on univ                      dataset:	 0.596393883228302
2022-11-03 00:35:13,276:INFO: 		 ADE on zara1                     dataset:	 0.6334185600280762
2022-11-03 00:35:14,064:INFO: 		 ADE on zara2                     dataset:	 0.5250030159950256
2022-11-03 00:35:14,064:INFO: Average training:	ADE  0.5839	FDE  1.1744
2022-11-03 00:35:14,073:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_382.pth.tar
2022-11-03 00:35:14,073:INFO: 
===> EPOCH: 383 (P3)
2022-11-03 00:35:14,073:INFO: - Computing loss (training)
2022-11-03 00:35:15,166:INFO: Batch:  0/31	Total Loss 6.1378 (6.1378)
2022-11-03 00:35:15,637:INFO: Batch:  1/31	Total Loss 4.8399 (5.5141)
2022-11-03 00:35:16,114:INFO: Batch:  2/31	Total Loss 4.5383 (5.1771)
2022-11-03 00:35:16,584:INFO: Batch:  3/31	Total Loss 4.2276 (4.9244)
2022-11-03 00:35:17,056:INFO: Batch:  4/31	Total Loss 5.0329 (4.9465)
2022-11-03 00:35:17,528:INFO: Batch:  5/31	Total Loss 5.1573 (4.9830)
2022-11-03 00:35:17,996:INFO: Batch:  6/31	Total Loss 5.3992 (5.0377)
2022-11-03 00:35:18,546:INFO: Batch:  7/31	Total Loss 5.0091 (5.0341)
2022-11-03 00:35:19,015:INFO: Batch:  8/31	Total Loss 5.1199 (5.0434)
2022-11-03 00:35:19,484:INFO: Batch:  9/31	Total Loss 5.5425 (5.0949)
2022-11-03 00:35:19,960:INFO: Batch: 10/31	Total Loss 5.0083 (5.0873)
2022-11-03 00:35:20,432:INFO: Batch: 11/31	Total Loss 5.8104 (5.1550)
2022-11-03 00:35:20,907:INFO: Batch: 12/31	Total Loss 5.0125 (5.1441)
2022-11-03 00:35:21,381:INFO: Batch: 13/31	Total Loss 5.0805 (5.1395)
2022-11-03 00:35:21,856:INFO: Batch: 14/31	Total Loss 5.5204 (5.1668)
2022-11-03 00:35:22,329:INFO: Batch: 15/31	Total Loss 4.4595 (5.1238)
2022-11-03 00:35:22,805:INFO: Batch: 16/31	Total Loss 5.6287 (5.1541)
2022-11-03 00:35:23,285:INFO: Batch: 17/31	Total Loss 4.9647 (5.1417)
2022-11-03 00:35:23,767:INFO: Batch: 18/31	Total Loss 4.7600 (5.1206)
2022-11-03 00:35:24,248:INFO: Batch: 19/31	Total Loss 4.5363 (5.0928)
2022-11-03 00:35:24,728:INFO: Batch: 20/31	Total Loss 4.4367 (5.0642)
2022-11-03 00:35:25,208:INFO: Batch: 21/31	Total Loss 5.0879 (5.0652)
2022-11-03 00:35:25,688:INFO: Batch: 22/31	Total Loss 4.7780 (5.0528)
2022-11-03 00:35:26,167:INFO: Batch: 23/31	Total Loss 5.2944 (5.0631)
2022-11-03 00:35:26,648:INFO: Batch: 24/31	Total Loss 4.4199 (5.0384)
2022-11-03 00:35:27,128:INFO: Batch: 25/31	Total Loss 4.4675 (5.0166)
2022-11-03 00:35:27,606:INFO: Batch: 26/31	Total Loss 5.2690 (5.0260)
2022-11-03 00:35:28,085:INFO: Batch: 27/31	Total Loss 4.4531 (5.0040)
2022-11-03 00:35:28,564:INFO: Batch: 28/31	Total Loss 5.3175 (5.0149)
2022-11-03 00:35:29,044:INFO: Batch: 29/31	Total Loss 4.2313 (4.9881)
2022-11-03 00:35:29,440:INFO: Batch: 30/31	Total Loss 1.8267 (4.9575)
2022-11-03 00:35:29,589:INFO: - Computing ADE (validation o)
2022-11-03 00:35:30,187:INFO: 		 ADE on eth                       dataset:	 1.106386423110962
2022-11-03 00:35:30,187:INFO: Average validation o:	ADE  1.1064	FDE  1.9909
2022-11-03 00:35:30,188:INFO: - Computing ADE (validation)
2022-11-03 00:35:30,462:INFO: 		 ADE on hotel                     dataset:	 0.5410385727882385
2022-11-03 00:35:30,765:INFO: 		 ADE on univ                      dataset:	 0.615926206111908
2022-11-03 00:35:31,010:INFO: 		 ADE on zara1                     dataset:	 0.6575859785079956
2022-11-03 00:35:31,367:INFO: 		 ADE on zara2                     dataset:	 0.5384747982025146
2022-11-03 00:35:31,367:INFO: Average validation:	ADE  0.5858	FDE  1.1674
2022-11-03 00:35:31,368:INFO: - Computing ADE (training)
2022-11-03 00:35:31,831:INFO: 		 ADE on hotel                     dataset:	 0.5861700177192688
2022-11-03 00:35:32,519:INFO: 		 ADE on univ                      dataset:	 0.6111623644828796
2022-11-03 00:35:33,070:INFO: 		 ADE on zara1                     dataset:	 0.6864840388298035
2022-11-03 00:35:33,840:INFO: 		 ADE on zara2                     dataset:	 0.5670908689498901
2022-11-03 00:35:33,840:INFO: Average training:	ADE  0.6064	FDE  1.2189
2022-11-03 00:35:33,849:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_383.pth.tar
2022-11-03 00:35:33,849:INFO: 
===> EPOCH: 384 (P3)
2022-11-03 00:35:33,849:INFO: - Computing loss (training)
2022-11-03 00:35:34,952:INFO: Batch:  0/31	Total Loss 4.7137 (4.7137)
2022-11-03 00:35:35,420:INFO: Batch:  1/31	Total Loss 3.7482 (4.2447)
2022-11-03 00:35:35,889:INFO: Batch:  2/31	Total Loss 5.5366 (4.6880)
2022-11-03 00:35:36,360:INFO: Batch:  3/31	Total Loss 4.4476 (4.6216)
2022-11-03 00:35:36,828:INFO: Batch:  4/31	Total Loss 5.1129 (4.7191)
2022-11-03 00:35:37,296:INFO: Batch:  5/31	Total Loss 4.9621 (4.7564)
2022-11-03 00:35:37,766:INFO: Batch:  6/31	Total Loss 5.2502 (4.8331)
2022-11-03 00:35:38,232:INFO: Batch:  7/31	Total Loss 4.8971 (4.8407)
2022-11-03 00:35:38,698:INFO: Batch:  8/31	Total Loss 5.0906 (4.8670)
2022-11-03 00:35:39,168:INFO: Batch:  9/31	Total Loss 4.6666 (4.8469)
2022-11-03 00:35:39,640:INFO: Batch: 10/31	Total Loss 4.4982 (4.8158)
2022-11-03 00:35:40,111:INFO: Batch: 11/31	Total Loss 5.2049 (4.8485)
2022-11-03 00:35:40,581:INFO: Batch: 12/31	Total Loss 6.3986 (4.9724)
2022-11-03 00:35:41,050:INFO: Batch: 13/31	Total Loss 4.5767 (4.9416)
2022-11-03 00:35:41,520:INFO: Batch: 14/31	Total Loss 4.8319 (4.9341)
2022-11-03 00:35:41,992:INFO: Batch: 15/31	Total Loss 5.2560 (4.9531)
2022-11-03 00:35:42,462:INFO: Batch: 16/31	Total Loss 5.0964 (4.9607)
2022-11-03 00:35:42,933:INFO: Batch: 17/31	Total Loss 4.6508 (4.9433)
2022-11-03 00:35:43,402:INFO: Batch: 18/31	Total Loss 5.5093 (4.9723)
2022-11-03 00:35:43,872:INFO: Batch: 19/31	Total Loss 5.3702 (4.9947)
2022-11-03 00:35:44,342:INFO: Batch: 20/31	Total Loss 4.7820 (4.9836)
2022-11-03 00:35:44,844:INFO: Batch: 21/31	Total Loss 4.8274 (4.9752)
2022-11-03 00:35:45,326:INFO: Batch: 22/31	Total Loss 4.7900 (4.9674)
2022-11-03 00:35:45,796:INFO: Batch: 23/31	Total Loss 6.1329 (5.0158)
2022-11-03 00:35:46,267:INFO: Batch: 24/31	Total Loss 4.4634 (4.9934)
2022-11-03 00:35:46,738:INFO: Batch: 25/31	Total Loss 4.3061 (4.9661)
2022-11-03 00:35:47,208:INFO: Batch: 26/31	Total Loss 4.5283 (4.9486)
2022-11-03 00:35:47,678:INFO: Batch: 27/31	Total Loss 5.4452 (4.9658)
2022-11-03 00:35:48,148:INFO: Batch: 28/31	Total Loss 4.9318 (4.9646)
2022-11-03 00:35:48,619:INFO: Batch: 29/31	Total Loss 4.8268 (4.9602)
2022-11-03 00:35:49,002:INFO: Batch: 30/31	Total Loss 1.9480 (4.9282)
2022-11-03 00:35:49,158:INFO: - Computing ADE (validation o)
2022-11-03 00:35:49,751:INFO: 		 ADE on eth                       dataset:	 1.1073251962661743
2022-11-03 00:35:49,751:INFO: Average validation o:	ADE  1.1073	FDE  1.9480
2022-11-03 00:35:49,752:INFO: - Computing ADE (validation)
2022-11-03 00:35:50,019:INFO: 		 ADE on hotel                     dataset:	 0.5781711935997009
2022-11-03 00:35:50,298:INFO: 		 ADE on univ                      dataset:	 0.6368998885154724
2022-11-03 00:35:50,542:INFO: 		 ADE on zara1                     dataset:	 0.5459378957748413
2022-11-03 00:35:50,888:INFO: 		 ADE on zara2                     dataset:	 0.525922954082489
2022-11-03 00:35:50,888:INFO: Average validation:	ADE  0.5877	FDE  1.1525
2022-11-03 00:35:50,889:INFO: - Computing ADE (training)
2022-11-03 00:35:51,329:INFO: 		 ADE on hotel                     dataset:	 0.6237511038780212
2022-11-03 00:35:52,016:INFO: 		 ADE on univ                      dataset:	 0.6051850914955139
2022-11-03 00:35:52,547:INFO: 		 ADE on zara1                     dataset:	 0.6645034551620483
2022-11-03 00:35:53,305:INFO: 		 ADE on zara2                     dataset:	 0.5689140558242798
2022-11-03 00:35:53,305:INFO: Average training:	ADE  0.6021	FDE  1.1839
2022-11-03 00:35:53,313:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_384.pth.tar
2022-11-03 00:35:53,313:INFO: 
===> EPOCH: 385 (P3)
2022-11-03 00:35:53,314:INFO: - Computing loss (training)
2022-11-03 00:35:54,412:INFO: Batch:  0/31	Total Loss 4.5783 (4.5783)
2022-11-03 00:35:54,882:INFO: Batch:  1/31	Total Loss 5.2637 (4.9025)
2022-11-03 00:35:55,351:INFO: Batch:  2/31	Total Loss 4.8147 (4.8708)
2022-11-03 00:35:55,821:INFO: Batch:  3/31	Total Loss 4.6805 (4.8222)
2022-11-03 00:35:56,290:INFO: Batch:  4/31	Total Loss 4.7684 (4.8122)
2022-11-03 00:35:56,759:INFO: Batch:  5/31	Total Loss 3.9944 (4.6757)
2022-11-03 00:35:57,225:INFO: Batch:  6/31	Total Loss 4.3404 (4.6294)
2022-11-03 00:35:57,689:INFO: Batch:  7/31	Total Loss 4.8382 (4.6553)
2022-11-03 00:35:58,156:INFO: Batch:  8/31	Total Loss 5.1180 (4.7057)
2022-11-03 00:35:58,622:INFO: Batch:  9/31	Total Loss 5.4341 (4.7738)
2022-11-03 00:35:59,086:INFO: Batch: 10/31	Total Loss 4.4704 (4.7457)
2022-11-03 00:35:59,557:INFO: Batch: 11/31	Total Loss 5.0410 (4.7698)
2022-11-03 00:36:00,032:INFO: Batch: 12/31	Total Loss 5.0325 (4.7893)
2022-11-03 00:36:00,502:INFO: Batch: 13/31	Total Loss 4.7171 (4.7840)
2022-11-03 00:36:00,971:INFO: Batch: 14/31	Total Loss 4.9339 (4.7933)
2022-11-03 00:36:01,443:INFO: Batch: 15/31	Total Loss 5.3573 (4.8282)
2022-11-03 00:36:01,914:INFO: Batch: 16/31	Total Loss 4.7107 (4.8220)
2022-11-03 00:36:02,384:INFO: Batch: 17/31	Total Loss 4.1230 (4.7813)
2022-11-03 00:36:02,852:INFO: Batch: 18/31	Total Loss 4.8964 (4.7878)
2022-11-03 00:36:03,321:INFO: Batch: 19/31	Total Loss 4.4789 (4.7732)
2022-11-03 00:36:03,791:INFO: Batch: 20/31	Total Loss 4.5041 (4.7609)
2022-11-03 00:36:04,259:INFO: Batch: 21/31	Total Loss 4.9826 (4.7709)
2022-11-03 00:36:04,729:INFO: Batch: 22/31	Total Loss 4.4969 (4.7599)
2022-11-03 00:36:05,200:INFO: Batch: 23/31	Total Loss 4.1273 (4.7351)
2022-11-03 00:36:05,673:INFO: Batch: 24/31	Total Loss 4.9131 (4.7425)
2022-11-03 00:36:06,150:INFO: Batch: 25/31	Total Loss 4.9957 (4.7504)
2022-11-03 00:36:06,627:INFO: Batch: 26/31	Total Loss 4.4755 (4.7398)
2022-11-03 00:36:07,184:INFO: Batch: 27/31	Total Loss 5.0446 (4.7512)
2022-11-03 00:36:07,662:INFO: Batch: 28/31	Total Loss 5.2341 (4.7663)
2022-11-03 00:36:08,137:INFO: Batch: 29/31	Total Loss 5.1539 (4.7774)
2022-11-03 00:36:08,527:INFO: Batch: 30/31	Total Loss 1.8805 (4.7508)
2022-11-03 00:36:08,677:INFO: - Computing ADE (validation o)
2022-11-03 00:36:09,264:INFO: 		 ADE on eth                       dataset:	 1.0702439546585083
2022-11-03 00:36:09,264:INFO: Average validation o:	ADE  1.0702	FDE  1.8838
2022-11-03 00:36:09,264:INFO: - Computing ADE (validation)
2022-11-03 00:36:09,543:INFO: 		 ADE on hotel                     dataset:	 0.506864070892334
2022-11-03 00:36:09,824:INFO: 		 ADE on univ                      dataset:	 0.5904017686843872
2022-11-03 00:36:10,080:INFO: 		 ADE on zara1                     dataset:	 0.5821788311004639
2022-11-03 00:36:10,426:INFO: 		 ADE on zara2                     dataset:	 0.4721590578556061
2022-11-03 00:36:10,426:INFO: Average validation:	ADE  0.5420	FDE  1.0374
2022-11-03 00:36:10,427:INFO: - Computing ADE (training)
2022-11-03 00:36:10,859:INFO: 		 ADE on hotel                     dataset:	 0.5555766820907593
2022-11-03 00:36:11,595:INFO: 		 ADE on univ                      dataset:	 0.5735839009284973
2022-11-03 00:36:12,173:INFO: 		 ADE on zara1                     dataset:	 0.6451238393783569
2022-11-03 00:36:12,885:INFO: 		 ADE on zara2                     dataset:	 0.5086870193481445
2022-11-03 00:36:12,885:INFO: Average training:	ADE  0.5645	FDE  1.0912
2022-11-03 00:36:12,894:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_385.pth.tar
2022-11-03 00:36:12,894:INFO: 
===> EPOCH: 386 (P3)
2022-11-03 00:36:12,894:INFO: - Computing loss (training)
2022-11-03 00:36:13,982:INFO: Batch:  0/31	Total Loss 5.0566 (5.0566)
2022-11-03 00:36:14,460:INFO: Batch:  1/31	Total Loss 5.1606 (5.1049)
2022-11-03 00:36:14,930:INFO: Batch:  2/31	Total Loss 4.5653 (4.9196)
2022-11-03 00:36:15,404:INFO: Batch:  3/31	Total Loss 4.5038 (4.8178)
2022-11-03 00:36:15,874:INFO: Batch:  4/31	Total Loss 4.8640 (4.8270)
2022-11-03 00:36:16,347:INFO: Batch:  5/31	Total Loss 5.8891 (5.0040)
2022-11-03 00:36:16,817:INFO: Batch:  6/31	Total Loss 5.6769 (5.0929)
2022-11-03 00:36:17,285:INFO: Batch:  7/31	Total Loss 5.0510 (5.0877)
2022-11-03 00:36:17,755:INFO: Batch:  8/31	Total Loss 4.7912 (5.0560)
2022-11-03 00:36:18,225:INFO: Batch:  9/31	Total Loss 5.2849 (5.0792)
2022-11-03 00:36:18,695:INFO: Batch: 10/31	Total Loss 4.7115 (5.0461)
2022-11-03 00:36:19,166:INFO: Batch: 11/31	Total Loss 4.3683 (4.9940)
2022-11-03 00:36:19,639:INFO: Batch: 12/31	Total Loss 5.2167 (5.0112)
2022-11-03 00:36:20,116:INFO: Batch: 13/31	Total Loss 4.4572 (4.9704)
2022-11-03 00:36:20,590:INFO: Batch: 14/31	Total Loss 5.4995 (5.0063)
2022-11-03 00:36:21,068:INFO: Batch: 15/31	Total Loss 4.7396 (4.9890)
2022-11-03 00:36:21,543:INFO: Batch: 16/31	Total Loss 5.3019 (5.0055)
2022-11-03 00:36:22,016:INFO: Batch: 17/31	Total Loss 5.0169 (5.0061)
2022-11-03 00:36:22,489:INFO: Batch: 18/31	Total Loss 5.5284 (5.0319)
2022-11-03 00:36:22,965:INFO: Batch: 19/31	Total Loss 4.3385 (4.9948)
2022-11-03 00:36:23,437:INFO: Batch: 20/31	Total Loss 4.8038 (4.9847)
2022-11-03 00:36:23,912:INFO: Batch: 21/31	Total Loss 4.9790 (4.9845)
2022-11-03 00:36:24,384:INFO: Batch: 22/31	Total Loss 4.3765 (4.9554)
2022-11-03 00:36:24,856:INFO: Batch: 23/31	Total Loss 4.8822 (4.9524)
2022-11-03 00:36:25,328:INFO: Batch: 24/31	Total Loss 4.2632 (4.9230)
2022-11-03 00:36:25,800:INFO: Batch: 25/31	Total Loss 4.1718 (4.8946)
2022-11-03 00:36:26,274:INFO: Batch: 26/31	Total Loss 4.3709 (4.8755)
2022-11-03 00:36:26,746:INFO: Batch: 27/31	Total Loss 5.2479 (4.8885)
2022-11-03 00:36:27,219:INFO: Batch: 28/31	Total Loss 5.5191 (4.9123)
2022-11-03 00:36:27,691:INFO: Batch: 29/31	Total Loss 4.7907 (4.9078)
2022-11-03 00:36:28,078:INFO: Batch: 30/31	Total Loss 1.5804 (4.8730)
2022-11-03 00:36:28,232:INFO: - Computing ADE (validation o)
2022-11-03 00:36:28,796:INFO: 		 ADE on eth                       dataset:	 1.0692161321640015
2022-11-03 00:36:28,796:INFO: Average validation o:	ADE  1.0692	FDE  1.8728
2022-11-03 00:36:28,797:INFO: - Computing ADE (validation)
2022-11-03 00:36:29,083:INFO: 		 ADE on hotel                     dataset:	 0.5003015995025635
2022-11-03 00:36:29,388:INFO: 		 ADE on univ                      dataset:	 0.5892370343208313
2022-11-03 00:36:29,639:INFO: 		 ADE on zara1                     dataset:	 0.5817674994468689
2022-11-03 00:36:29,986:INFO: 		 ADE on zara2                     dataset:	 0.47341570258140564
2022-11-03 00:36:29,986:INFO: Average validation:	ADE  0.5414	FDE  1.0464
2022-11-03 00:36:29,987:INFO: - Computing ADE (training)
2022-11-03 00:36:30,443:INFO: 		 ADE on hotel                     dataset:	 0.5486218929290771
2022-11-03 00:36:31,136:INFO: 		 ADE on univ                      dataset:	 0.5741881728172302
2022-11-03 00:36:31,673:INFO: 		 ADE on zara1                     dataset:	 0.6417355537414551
2022-11-03 00:36:32,416:INFO: 		 ADE on zara2                     dataset:	 0.5072141289710999
2022-11-03 00:36:32,416:INFO: Average training:	ADE  0.5643	FDE  1.1000
2022-11-03 00:36:32,424:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_386.pth.tar
2022-11-03 00:36:32,424:INFO: 
===> EPOCH: 387 (P3)
2022-11-03 00:36:32,425:INFO: - Computing loss (training)
2022-11-03 00:36:33,519:INFO: Batch:  0/31	Total Loss 5.2594 (5.2594)
2022-11-03 00:36:33,993:INFO: Batch:  1/31	Total Loss 5.0222 (5.1361)
2022-11-03 00:36:34,462:INFO: Batch:  2/31	Total Loss 4.4810 (4.9138)
2022-11-03 00:36:34,929:INFO: Batch:  3/31	Total Loss 4.7937 (4.8852)
2022-11-03 00:36:35,397:INFO: Batch:  4/31	Total Loss 4.5628 (4.8214)
2022-11-03 00:36:35,874:INFO: Batch:  5/31	Total Loss 4.4445 (4.7616)
2022-11-03 00:36:36,352:INFO: Batch:  6/31	Total Loss 4.4376 (4.7142)
2022-11-03 00:36:36,830:INFO: Batch:  7/31	Total Loss 5.2594 (4.7837)
2022-11-03 00:36:37,306:INFO: Batch:  8/31	Total Loss 5.6078 (4.8689)
2022-11-03 00:36:37,782:INFO: Batch:  9/31	Total Loss 5.0114 (4.8818)
2022-11-03 00:36:38,258:INFO: Batch: 10/31	Total Loss 4.3898 (4.8352)
2022-11-03 00:36:38,732:INFO: Batch: 11/31	Total Loss 4.6087 (4.8153)
2022-11-03 00:36:39,206:INFO: Batch: 12/31	Total Loss 4.4330 (4.7846)
2022-11-03 00:36:39,680:INFO: Batch: 13/31	Total Loss 4.3725 (4.7542)
2022-11-03 00:36:40,160:INFO: Batch: 14/31	Total Loss 4.6273 (4.7463)
2022-11-03 00:36:40,634:INFO: Batch: 15/31	Total Loss 4.9741 (4.7623)
2022-11-03 00:36:41,108:INFO: Batch: 16/31	Total Loss 5.4684 (4.8020)
2022-11-03 00:36:41,583:INFO: Batch: 17/31	Total Loss 4.5013 (4.7837)
2022-11-03 00:36:42,058:INFO: Batch: 18/31	Total Loss 4.8397 (4.7865)
2022-11-03 00:36:42,532:INFO: Batch: 19/31	Total Loss 5.4559 (4.8182)
2022-11-03 00:36:43,006:INFO: Batch: 20/31	Total Loss 4.5047 (4.8027)
2022-11-03 00:36:43,481:INFO: Batch: 21/31	Total Loss 4.8162 (4.8033)
2022-11-03 00:36:43,955:INFO: Batch: 22/31	Total Loss 4.9064 (4.8081)
2022-11-03 00:36:44,431:INFO: Batch: 23/31	Total Loss 4.5822 (4.7990)
2022-11-03 00:36:44,906:INFO: Batch: 24/31	Total Loss 4.9803 (4.8068)
2022-11-03 00:36:45,380:INFO: Batch: 25/31	Total Loss 4.6115 (4.8001)
2022-11-03 00:36:45,855:INFO: Batch: 26/31	Total Loss 4.5076 (4.7877)
2022-11-03 00:36:46,329:INFO: Batch: 27/31	Total Loss 4.3082 (4.7712)
2022-11-03 00:36:46,804:INFO: Batch: 28/31	Total Loss 4.8133 (4.7727)
2022-11-03 00:36:47,278:INFO: Batch: 29/31	Total Loss 4.5802 (4.7663)
2022-11-03 00:36:47,668:INFO: Batch: 30/31	Total Loss 1.5879 (4.7354)
2022-11-03 00:36:47,815:INFO: - Computing ADE (validation o)
2022-11-03 00:36:48,410:INFO: 		 ADE on eth                       dataset:	 1.077878713607788
2022-11-03 00:36:48,410:INFO: Average validation o:	ADE  1.0779	FDE  1.9040
2022-11-03 00:36:48,410:INFO: - Computing ADE (validation)
2022-11-03 00:36:48,675:INFO: 		 ADE on hotel                     dataset:	 0.5042652487754822
2022-11-03 00:36:48,970:INFO: 		 ADE on univ                      dataset:	 0.5862473249435425
2022-11-03 00:36:49,224:INFO: 		 ADE on zara1                     dataset:	 0.5537279844284058
2022-11-03 00:36:49,585:INFO: 		 ADE on zara2                     dataset:	 0.4803452789783478
2022-11-03 00:36:49,585:INFO: Average validation:	ADE  0.5410	FDE  1.0328
2022-11-03 00:36:49,586:INFO: - Computing ADE (training)
2022-11-03 00:36:50,036:INFO: 		 ADE on hotel                     dataset:	 0.5407751798629761
2022-11-03 00:36:50,794:INFO: 		 ADE on univ                      dataset:	 0.5729999542236328
2022-11-03 00:36:51,383:INFO: 		 ADE on zara1                     dataset:	 0.6388595104217529
2022-11-03 00:36:52,262:INFO: 		 ADE on zara2                     dataset:	 0.5151655673980713
2022-11-03 00:36:52,262:INFO: Average training:	ADE  0.5646	FDE  1.0909
2022-11-03 00:36:52,271:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_387.pth.tar
2022-11-03 00:36:52,271:INFO: 
===> EPOCH: 388 (P3)
2022-11-03 00:36:52,271:INFO: - Computing loss (training)
2022-11-03 00:36:53,401:INFO: Batch:  0/31	Total Loss 4.8606 (4.8606)
2022-11-03 00:36:53,894:INFO: Batch:  1/31	Total Loss 4.7256 (4.7865)
2022-11-03 00:36:54,438:INFO: Batch:  2/31	Total Loss 4.7369 (4.7712)
2022-11-03 00:36:55,165:INFO: Batch:  3/31	Total Loss 4.5777 (4.7216)
2022-11-03 00:36:55,758:INFO: Batch:  4/31	Total Loss 4.4251 (4.6549)
2022-11-03 00:36:56,254:INFO: Batch:  5/31	Total Loss 5.1221 (4.7306)
2022-11-03 00:36:56,751:INFO: Batch:  6/31	Total Loss 5.2628 (4.8061)
2022-11-03 00:36:57,230:INFO: Batch:  7/31	Total Loss 4.8849 (4.8157)
2022-11-03 00:36:57,808:INFO: Batch:  8/31	Total Loss 4.2330 (4.7492)
2022-11-03 00:36:58,282:INFO: Batch:  9/31	Total Loss 4.5257 (4.7275)
2022-11-03 00:36:58,756:INFO: Batch: 10/31	Total Loss 4.9187 (4.7437)
2022-11-03 00:36:59,239:INFO: Batch: 11/31	Total Loss 4.6416 (4.7356)
2022-11-03 00:36:59,750:INFO: Batch: 12/31	Total Loss 4.8322 (4.7442)
2022-11-03 00:37:00,246:INFO: Batch: 13/31	Total Loss 4.9997 (4.7605)
2022-11-03 00:37:00,748:INFO: Batch: 14/31	Total Loss 4.8610 (4.7668)
2022-11-03 00:37:01,258:INFO: Batch: 15/31	Total Loss 5.9602 (4.8334)
2022-11-03 00:37:01,880:INFO: Batch: 16/31	Total Loss 5.0821 (4.8486)
2022-11-03 00:37:02,469:INFO: Batch: 17/31	Total Loss 5.4496 (4.8792)
2022-11-03 00:37:02,994:INFO: Batch: 18/31	Total Loss 5.8515 (4.9261)
2022-11-03 00:37:03,486:INFO: Batch: 19/31	Total Loss 4.5525 (4.9065)
2022-11-03 00:37:04,017:INFO: Batch: 20/31	Total Loss 4.4527 (4.8870)
2022-11-03 00:37:04,499:INFO: Batch: 21/31	Total Loss 5.2818 (4.9062)
2022-11-03 00:37:04,977:INFO: Batch: 22/31	Total Loss 4.1805 (4.8764)
2022-11-03 00:37:05,455:INFO: Batch: 23/31	Total Loss 5.2228 (4.8909)
2022-11-03 00:37:05,933:INFO: Batch: 24/31	Total Loss 4.8952 (4.8910)
2022-11-03 00:37:06,420:INFO: Batch: 25/31	Total Loss 4.9526 (4.8932)
2022-11-03 00:37:06,899:INFO: Batch: 26/31	Total Loss 4.6236 (4.8830)
2022-11-03 00:37:07,377:INFO: Batch: 27/31	Total Loss 5.2976 (4.8962)
2022-11-03 00:37:07,869:INFO: Batch: 28/31	Total Loss 5.1242 (4.9036)
2022-11-03 00:37:08,425:INFO: Batch: 29/31	Total Loss 5.0405 (4.9083)
2022-11-03 00:37:08,882:INFO: Batch: 30/31	Total Loss 2.0170 (4.8780)
2022-11-03 00:37:09,044:INFO: - Computing ADE (validation o)
2022-11-03 00:37:09,673:INFO: 		 ADE on eth                       dataset:	 1.0844687223434448
2022-11-03 00:37:09,673:INFO: Average validation o:	ADE  1.0845	FDE  1.9370
2022-11-03 00:37:09,673:INFO: - Computing ADE (validation)
2022-11-03 00:37:09,969:INFO: 		 ADE on hotel                     dataset:	 0.5361540913581848
2022-11-03 00:37:10,283:INFO: 		 ADE on univ                      dataset:	 0.5949975848197937
2022-11-03 00:37:10,544:INFO: 		 ADE on zara1                     dataset:	 0.5629351139068604
2022-11-03 00:37:10,899:INFO: 		 ADE on zara2                     dataset:	 0.5089815258979797
2022-11-03 00:37:10,900:INFO: Average validation:	ADE  0.5584	FDE  1.0992
2022-11-03 00:37:10,900:INFO: - Computing ADE (training)
2022-11-03 00:37:11,347:INFO: 		 ADE on hotel                     dataset:	 0.5665488243103027
2022-11-03 00:37:12,086:INFO: 		 ADE on univ                      dataset:	 0.593246579170227
2022-11-03 00:37:12,614:INFO: 		 ADE on zara1                     dataset:	 0.6440683007240295
2022-11-03 00:37:13,399:INFO: 		 ADE on zara2                     dataset:	 0.5360371470451355
2022-11-03 00:37:13,399:INFO: Average training:	ADE  0.5842	FDE  1.1626
2022-11-03 00:37:13,416:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_388.pth.tar
2022-11-03 00:37:13,416:INFO: 
===> EPOCH: 389 (P3)
2022-11-03 00:37:13,416:INFO: - Computing loss (training)
2022-11-03 00:37:14,518:INFO: Batch:  0/31	Total Loss 4.9985 (4.9985)
2022-11-03 00:37:15,021:INFO: Batch:  1/31	Total Loss 4.7296 (4.8626)
2022-11-03 00:37:15,510:INFO: Batch:  2/31	Total Loss 6.5347 (5.4325)
2022-11-03 00:37:15,998:INFO: Batch:  3/31	Total Loss 4.8823 (5.3062)
2022-11-03 00:37:16,467:INFO: Batch:  4/31	Total Loss 4.8163 (5.2080)
2022-11-03 00:37:16,963:INFO: Batch:  5/31	Total Loss 5.1378 (5.1955)
2022-11-03 00:37:17,501:INFO: Batch:  6/31	Total Loss 5.1242 (5.1846)
2022-11-03 00:37:18,013:INFO: Batch:  7/31	Total Loss 5.1994 (5.1863)
2022-11-03 00:37:18,495:INFO: Batch:  8/31	Total Loss 4.4346 (5.1018)
2022-11-03 00:37:18,997:INFO: Batch:  9/31	Total Loss 4.4136 (5.0342)
2022-11-03 00:37:19,538:INFO: Batch: 10/31	Total Loss 5.0395 (5.0348)
2022-11-03 00:37:20,299:INFO: Batch: 11/31	Total Loss 4.9720 (5.0295)
2022-11-03 00:37:20,793:INFO: Batch: 12/31	Total Loss 4.5222 (4.9885)
2022-11-03 00:37:21,299:INFO: Batch: 13/31	Total Loss 5.3179 (5.0114)
2022-11-03 00:37:21,797:INFO: Batch: 14/31	Total Loss 5.0436 (5.0137)
2022-11-03 00:37:22,287:INFO: Batch: 15/31	Total Loss 4.7945 (5.0004)
2022-11-03 00:37:22,783:INFO: Batch: 16/31	Total Loss 4.9118 (4.9955)
2022-11-03 00:37:23,264:INFO: Batch: 17/31	Total Loss 5.5964 (5.0266)
2022-11-03 00:37:23,743:INFO: Batch: 18/31	Total Loss 4.8781 (5.0188)
2022-11-03 00:37:24,228:INFO: Batch: 19/31	Total Loss 5.1073 (5.0227)
2022-11-03 00:37:24,717:INFO: Batch: 20/31	Total Loss 4.6972 (5.0051)
2022-11-03 00:37:25,202:INFO: Batch: 21/31	Total Loss 4.6110 (4.9893)
2022-11-03 00:37:25,678:INFO: Batch: 22/31	Total Loss 4.7007 (4.9775)
2022-11-03 00:37:26,156:INFO: Batch: 23/31	Total Loss 3.9168 (4.9337)
2022-11-03 00:37:26,638:INFO: Batch: 24/31	Total Loss 4.5924 (4.9210)
2022-11-03 00:37:27,119:INFO: Batch: 25/31	Total Loss 4.5883 (4.9076)
2022-11-03 00:37:27,600:INFO: Batch: 26/31	Total Loss 4.7107 (4.9006)
2022-11-03 00:37:28,082:INFO: Batch: 27/31	Total Loss 4.7572 (4.8949)
2022-11-03 00:37:28,562:INFO: Batch: 28/31	Total Loss 4.9340 (4.8963)
2022-11-03 00:37:29,038:INFO: Batch: 29/31	Total Loss 5.3011 (4.9093)
2022-11-03 00:37:29,428:INFO: Batch: 30/31	Total Loss 1.9259 (4.8785)
2022-11-03 00:37:29,574:INFO: - Computing ADE (validation o)
2022-11-03 00:37:30,195:INFO: 		 ADE on eth                       dataset:	 1.0646742582321167
2022-11-03 00:37:30,195:INFO: Average validation o:	ADE  1.0647	FDE  1.8268
2022-11-03 00:37:30,196:INFO: - Computing ADE (validation)
2022-11-03 00:37:30,460:INFO: 		 ADE on hotel                     dataset:	 0.5038213133811951
2022-11-03 00:37:30,772:INFO: 		 ADE on univ                      dataset:	 0.5885595679283142
2022-11-03 00:37:31,020:INFO: 		 ADE on zara1                     dataset:	 0.5244002342224121
2022-11-03 00:37:31,376:INFO: 		 ADE on zara2                     dataset:	 0.455481618642807
2022-11-03 00:37:31,376:INFO: Average validation:	ADE  0.5314	FDE  1.0168
2022-11-03 00:37:31,377:INFO: - Computing ADE (training)
2022-11-03 00:37:31,847:INFO: 		 ADE on hotel                     dataset:	 0.5489767789840698
2022-11-03 00:37:32,544:INFO: 		 ADE on univ                      dataset:	 0.5648257732391357
2022-11-03 00:37:33,064:INFO: 		 ADE on zara1                     dataset:	 0.6201972365379333
2022-11-03 00:37:33,839:INFO: 		 ADE on zara2                     dataset:	 0.48919790983200073
2022-11-03 00:37:33,839:INFO: Average training:	ADE  0.5526	FDE  1.0652
2022-11-03 00:37:33,848:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_389.pth.tar
2022-11-03 00:37:33,848:INFO: 
===> EPOCH: 390 (P3)
2022-11-03 00:37:33,848:INFO: - Computing loss (training)
2022-11-03 00:37:34,938:INFO: Batch:  0/31	Total Loss 4.7155 (4.7155)
2022-11-03 00:37:35,414:INFO: Batch:  1/31	Total Loss 4.3895 (4.5513)
2022-11-03 00:37:35,899:INFO: Batch:  2/31	Total Loss 4.2645 (4.4611)
2022-11-03 00:37:36,370:INFO: Batch:  3/31	Total Loss 4.4884 (4.4683)
2022-11-03 00:37:36,845:INFO: Batch:  4/31	Total Loss 4.8097 (4.5322)
2022-11-03 00:37:37,322:INFO: Batch:  5/31	Total Loss 4.7099 (4.5616)
2022-11-03 00:37:37,797:INFO: Batch:  6/31	Total Loss 5.5452 (4.6932)
2022-11-03 00:37:38,267:INFO: Batch:  7/31	Total Loss 5.0730 (4.7365)
2022-11-03 00:37:38,743:INFO: Batch:  8/31	Total Loss 5.0058 (4.7677)
2022-11-03 00:37:39,215:INFO: Batch:  9/31	Total Loss 5.0227 (4.7947)
2022-11-03 00:37:39,691:INFO: Batch: 10/31	Total Loss 5.1723 (4.8297)
2022-11-03 00:37:40,166:INFO: Batch: 11/31	Total Loss 4.9101 (4.8368)
2022-11-03 00:37:40,636:INFO: Batch: 12/31	Total Loss 5.7300 (4.9017)
2022-11-03 00:37:41,106:INFO: Batch: 13/31	Total Loss 4.8141 (4.8955)
2022-11-03 00:37:41,578:INFO: Batch: 14/31	Total Loss 5.1410 (4.9117)
2022-11-03 00:37:42,048:INFO: Batch: 15/31	Total Loss 5.1503 (4.9268)
2022-11-03 00:37:42,518:INFO: Batch: 16/31	Total Loss 4.4884 (4.9003)
2022-11-03 00:37:42,992:INFO: Batch: 17/31	Total Loss 4.5581 (4.8829)
2022-11-03 00:37:43,466:INFO: Batch: 18/31	Total Loss 4.5847 (4.8675)
2022-11-03 00:37:43,936:INFO: Batch: 19/31	Total Loss 4.7401 (4.8615)
2022-11-03 00:37:44,407:INFO: Batch: 20/31	Total Loss 5.0055 (4.8690)
2022-11-03 00:37:44,877:INFO: Batch: 21/31	Total Loss 4.8965 (4.8703)
2022-11-03 00:37:45,348:INFO: Batch: 22/31	Total Loss 5.1943 (4.8828)
2022-11-03 00:37:45,816:INFO: Batch: 23/31	Total Loss 5.6712 (4.9107)
2022-11-03 00:37:46,292:INFO: Batch: 24/31	Total Loss 5.0433 (4.9155)
2022-11-03 00:37:46,762:INFO: Batch: 25/31	Total Loss 5.2027 (4.9271)
2022-11-03 00:37:47,231:INFO: Batch: 26/31	Total Loss 5.1498 (4.9353)
2022-11-03 00:37:47,699:INFO: Batch: 27/31	Total Loss 4.7960 (4.9303)
2022-11-03 00:37:48,170:INFO: Batch: 28/31	Total Loss 4.7478 (4.9246)
2022-11-03 00:37:48,640:INFO: Batch: 29/31	Total Loss 4.3485 (4.9061)
2022-11-03 00:37:49,027:INFO: Batch: 30/31	Total Loss 1.9092 (4.8766)
2022-11-03 00:37:49,168:INFO: - Computing ADE (validation o)
2022-11-03 00:37:49,774:INFO: 		 ADE on eth                       dataset:	 1.0535281896591187
2022-11-03 00:37:49,774:INFO: Average validation o:	ADE  1.0535	FDE  1.8234
2022-11-03 00:37:49,775:INFO: - Computing ADE (validation)
2022-11-03 00:37:50,050:INFO: 		 ADE on hotel                     dataset:	 0.5314583778381348
2022-11-03 00:37:50,350:INFO: 		 ADE on univ                      dataset:	 0.6043259501457214
2022-11-03 00:37:50,600:INFO: 		 ADE on zara1                     dataset:	 0.49726739525794983
2022-11-03 00:37:50,927:INFO: 		 ADE on zara2                     dataset:	 0.47206005454063416
2022-11-03 00:37:50,928:INFO: Average validation:	ADE  0.5456	FDE  1.0805
2022-11-03 00:37:50,928:INFO: - Computing ADE (training)
2022-11-03 00:37:51,379:INFO: 		 ADE on hotel                     dataset:	 0.5770695805549622
2022-11-03 00:37:52,065:INFO: 		 ADE on univ                      dataset:	 0.5799405574798584
2022-11-03 00:37:52,603:INFO: 		 ADE on zara1                     dataset:	 0.6002841591835022
2022-11-03 00:37:53,331:INFO: 		 ADE on zara2                     dataset:	 0.49789732694625854
2022-11-03 00:37:53,331:INFO: Average training:	ADE  0.5645	FDE  1.1229
2022-11-03 00:37:53,339:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_390.pth.tar
2022-11-03 00:37:53,339:INFO: 
===> EPOCH: 391 (P3)
2022-11-03 00:37:53,340:INFO: - Computing loss (training)
2022-11-03 00:37:54,438:INFO: Batch:  0/31	Total Loss 4.7179 (4.7179)
2022-11-03 00:37:54,910:INFO: Batch:  1/31	Total Loss 6.9782 (5.8796)
2022-11-03 00:37:55,384:INFO: Batch:  2/31	Total Loss 5.0162 (5.5929)
2022-11-03 00:37:55,938:INFO: Batch:  3/31	Total Loss 4.7074 (5.3402)
2022-11-03 00:37:56,411:INFO: Batch:  4/31	Total Loss 4.5741 (5.1906)
2022-11-03 00:37:56,886:INFO: Batch:  5/31	Total Loss 5.9727 (5.3261)
2022-11-03 00:37:57,362:INFO: Batch:  6/31	Total Loss 5.3365 (5.3276)
2022-11-03 00:37:57,835:INFO: Batch:  7/31	Total Loss 6.5286 (5.4752)
2022-11-03 00:37:58,307:INFO: Batch:  8/31	Total Loss 6.3139 (5.5783)
2022-11-03 00:37:58,778:INFO: Batch:  9/31	Total Loss 5.5633 (5.5768)
2022-11-03 00:37:59,250:INFO: Batch: 10/31	Total Loss 4.9074 (5.5203)
2022-11-03 00:37:59,737:INFO: Batch: 11/31	Total Loss 4.8033 (5.4575)
2022-11-03 00:38:00,223:INFO: Batch: 12/31	Total Loss 4.7676 (5.4041)
2022-11-03 00:38:00,700:INFO: Batch: 13/31	Total Loss 5.0879 (5.3816)
2022-11-03 00:38:01,182:INFO: Batch: 14/31	Total Loss 5.3347 (5.3787)
2022-11-03 00:38:01,658:INFO: Batch: 15/31	Total Loss 4.5696 (5.3305)
2022-11-03 00:38:02,132:INFO: Batch: 16/31	Total Loss 4.6493 (5.2875)
2022-11-03 00:38:02,606:INFO: Batch: 17/31	Total Loss 5.3406 (5.2904)
2022-11-03 00:38:03,079:INFO: Batch: 18/31	Total Loss 5.6812 (5.3113)
2022-11-03 00:38:03,553:INFO: Batch: 19/31	Total Loss 5.6337 (5.3273)
2022-11-03 00:38:04,037:INFO: Batch: 20/31	Total Loss 4.4194 (5.2813)
2022-11-03 00:38:04,509:INFO: Batch: 21/31	Total Loss 4.8763 (5.2631)
2022-11-03 00:38:04,983:INFO: Batch: 22/31	Total Loss 4.8343 (5.2459)
2022-11-03 00:38:05,457:INFO: Batch: 23/31	Total Loss 5.1474 (5.2418)
2022-11-03 00:38:05,930:INFO: Batch: 24/31	Total Loss 4.6001 (5.2141)
2022-11-03 00:38:06,403:INFO: Batch: 25/31	Total Loss 4.9934 (5.2064)
2022-11-03 00:38:06,876:INFO: Batch: 26/31	Total Loss 4.8533 (5.1951)
2022-11-03 00:38:07,349:INFO: Batch: 27/31	Total Loss 4.6736 (5.1774)
2022-11-03 00:38:07,821:INFO: Batch: 28/31	Total Loss 4.6755 (5.1597)
2022-11-03 00:38:08,294:INFO: Batch: 29/31	Total Loss 4.2440 (5.1299)
2022-11-03 00:38:08,684:INFO: Batch: 30/31	Total Loss 1.8587 (5.0967)
2022-11-03 00:38:08,839:INFO: - Computing ADE (validation o)
2022-11-03 00:38:09,414:INFO: 		 ADE on eth                       dataset:	 1.044674038887024
2022-11-03 00:38:09,414:INFO: Average validation o:	ADE  1.0447	FDE  1.8671
2022-11-03 00:38:09,415:INFO: - Computing ADE (validation)
2022-11-03 00:38:09,681:INFO: 		 ADE on hotel                     dataset:	 0.5166621804237366
2022-11-03 00:38:09,984:INFO: 		 ADE on univ                      dataset:	 0.6010470390319824
2022-11-03 00:38:10,248:INFO: 		 ADE on zara1                     dataset:	 0.5200353264808655
2022-11-03 00:38:10,618:INFO: 		 ADE on zara2                     dataset:	 0.44638025760650635
2022-11-03 00:38:10,618:INFO: Average validation:	ADE  0.5350	FDE  1.0421
2022-11-03 00:38:10,619:INFO: - Computing ADE (training)
2022-11-03 00:38:11,067:INFO: 		 ADE on hotel                     dataset:	 0.5758213400840759
2022-11-03 00:38:11,756:INFO: 		 ADE on univ                      dataset:	 0.5709960460662842
2022-11-03 00:38:12,295:INFO: 		 ADE on zara1                     dataset:	 0.5994683504104614
2022-11-03 00:38:13,041:INFO: 		 ADE on zara2                     dataset:	 0.4751407206058502
2022-11-03 00:38:13,041:INFO: Average training:	ADE  0.5535	FDE  1.0836
2022-11-03 00:38:13,050:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_391.pth.tar
2022-11-03 00:38:13,050:INFO: 
===> EPOCH: 392 (P3)
2022-11-03 00:38:13,050:INFO: - Computing loss (training)
2022-11-03 00:38:14,177:INFO: Batch:  0/31	Total Loss 4.5403 (4.5403)
2022-11-03 00:38:14,649:INFO: Batch:  1/31	Total Loss 4.5256 (4.5335)
2022-11-03 00:38:15,125:INFO: Batch:  2/31	Total Loss 4.6727 (4.5791)
2022-11-03 00:38:15,588:INFO: Batch:  3/31	Total Loss 6.2468 (4.9820)
2022-11-03 00:38:16,053:INFO: Batch:  4/31	Total Loss 4.8732 (4.9601)
2022-11-03 00:38:16,520:INFO: Batch:  5/31	Total Loss 4.5606 (4.8920)
2022-11-03 00:38:16,990:INFO: Batch:  6/31	Total Loss 5.3850 (4.9709)
2022-11-03 00:38:17,458:INFO: Batch:  7/31	Total Loss 5.2849 (5.0058)
2022-11-03 00:38:17,932:INFO: Batch:  8/31	Total Loss 5.1911 (5.0268)
2022-11-03 00:38:18,399:INFO: Batch:  9/31	Total Loss 4.5184 (4.9790)
2022-11-03 00:38:18,870:INFO: Batch: 10/31	Total Loss 5.4290 (5.0193)
2022-11-03 00:38:19,337:INFO: Batch: 11/31	Total Loss 6.3545 (5.1328)
2022-11-03 00:38:19,811:INFO: Batch: 12/31	Total Loss 4.9421 (5.1168)
2022-11-03 00:38:20,287:INFO: Batch: 13/31	Total Loss 4.3418 (5.0601)
2022-11-03 00:38:20,761:INFO: Batch: 14/31	Total Loss 4.9117 (5.0507)
2022-11-03 00:38:21,232:INFO: Batch: 15/31	Total Loss 4.4135 (5.0123)
2022-11-03 00:38:21,705:INFO: Batch: 16/31	Total Loss 3.9899 (4.9532)
2022-11-03 00:38:22,177:INFO: Batch: 17/31	Total Loss 5.0126 (4.9564)
2022-11-03 00:38:22,648:INFO: Batch: 18/31	Total Loss 5.1115 (4.9659)
2022-11-03 00:38:23,119:INFO: Batch: 19/31	Total Loss 4.8856 (4.9612)
2022-11-03 00:38:23,590:INFO: Batch: 20/31	Total Loss 4.9438 (4.9604)
2022-11-03 00:38:24,062:INFO: Batch: 21/31	Total Loss 3.9543 (4.9125)
2022-11-03 00:38:24,535:INFO: Batch: 22/31	Total Loss 4.2633 (4.8855)
2022-11-03 00:38:25,008:INFO: Batch: 23/31	Total Loss 4.6880 (4.8770)
2022-11-03 00:38:25,480:INFO: Batch: 24/31	Total Loss 5.5908 (4.9055)
2022-11-03 00:38:25,953:INFO: Batch: 25/31	Total Loss 4.9361 (4.9068)
2022-11-03 00:38:26,425:INFO: Batch: 26/31	Total Loss 4.6149 (4.8961)
2022-11-03 00:38:26,898:INFO: Batch: 27/31	Total Loss 4.9320 (4.8976)
2022-11-03 00:38:27,369:INFO: Batch: 28/31	Total Loss 5.0388 (4.9018)
2022-11-03 00:38:27,839:INFO: Batch: 29/31	Total Loss 4.9229 (4.9025)
2022-11-03 00:38:28,227:INFO: Batch: 30/31	Total Loss 1.7725 (4.8675)
2022-11-03 00:38:28,383:INFO: - Computing ADE (validation o)
2022-11-03 00:38:28,974:INFO: 		 ADE on eth                       dataset:	 1.061476230621338
2022-11-03 00:38:28,974:INFO: Average validation o:	ADE  1.0615	FDE  1.8575
2022-11-03 00:38:28,975:INFO: - Computing ADE (validation)
2022-11-03 00:38:29,250:INFO: 		 ADE on hotel                     dataset:	 0.5258283019065857
2022-11-03 00:38:29,545:INFO: 		 ADE on univ                      dataset:	 0.5966122150421143
2022-11-03 00:38:29,789:INFO: 		 ADE on zara1                     dataset:	 0.5024934411048889
2022-11-03 00:38:30,155:INFO: 		 ADE on zara2                     dataset:	 0.4774494469165802
2022-11-03 00:38:30,155:INFO: Average validation:	ADE  0.5436	FDE  1.0523
2022-11-03 00:38:30,165:INFO: - Computing ADE (training)
2022-11-03 00:38:30,614:INFO: 		 ADE on hotel                     dataset:	 0.5711585879325867
2022-11-03 00:38:31,300:INFO: 		 ADE on univ                      dataset:	 0.5761092305183411
2022-11-03 00:38:31,829:INFO: 		 ADE on zara1                     dataset:	 0.622355043888092
2022-11-03 00:38:32,586:INFO: 		 ADE on zara2                     dataset:	 0.5111827850341797
2022-11-03 00:38:32,586:INFO: Average training:	ADE  0.5658	FDE  1.1028
2022-11-03 00:38:32,595:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_392.pth.tar
2022-11-03 00:38:32,595:INFO: 
===> EPOCH: 393 (P3)
2022-11-03 00:38:32,596:INFO: - Computing loss (training)
2022-11-03 00:38:33,689:INFO: Batch:  0/31	Total Loss 4.9574 (4.9574)
2022-11-03 00:38:34,160:INFO: Batch:  1/31	Total Loss 4.6203 (4.7797)
2022-11-03 00:38:34,633:INFO: Batch:  2/31	Total Loss 4.3768 (4.6389)
2022-11-03 00:38:35,104:INFO: Batch:  3/31	Total Loss 4.7102 (4.6574)
2022-11-03 00:38:35,573:INFO: Batch:  4/31	Total Loss 4.3909 (4.6067)
2022-11-03 00:38:36,045:INFO: Batch:  5/31	Total Loss 4.0937 (4.5236)
2022-11-03 00:38:36,519:INFO: Batch:  6/31	Total Loss 4.5785 (4.5313)
2022-11-03 00:38:36,991:INFO: Batch:  7/31	Total Loss 5.9595 (4.6709)
2022-11-03 00:38:37,460:INFO: Batch:  8/31	Total Loss 4.7038 (4.6747)
2022-11-03 00:38:37,930:INFO: Batch:  9/31	Total Loss 4.9251 (4.6987)
2022-11-03 00:38:38,403:INFO: Batch: 10/31	Total Loss 6.5745 (4.8569)
2022-11-03 00:38:38,874:INFO: Batch: 11/31	Total Loss 4.7048 (4.8427)
2022-11-03 00:38:39,348:INFO: Batch: 12/31	Total Loss 4.4902 (4.8140)
2022-11-03 00:38:39,822:INFO: Batch: 13/31	Total Loss 5.0958 (4.8323)
2022-11-03 00:38:40,299:INFO: Batch: 14/31	Total Loss 4.6938 (4.8228)
2022-11-03 00:38:40,775:INFO: Batch: 15/31	Total Loss 4.6924 (4.8141)
2022-11-03 00:38:41,248:INFO: Batch: 16/31	Total Loss 4.6796 (4.8057)
2022-11-03 00:38:41,722:INFO: Batch: 17/31	Total Loss 5.0450 (4.8191)
2022-11-03 00:38:42,197:INFO: Batch: 18/31	Total Loss 4.6937 (4.8130)
2022-11-03 00:38:42,671:INFO: Batch: 19/31	Total Loss 5.6094 (4.8510)
2022-11-03 00:38:43,143:INFO: Batch: 20/31	Total Loss 4.6474 (4.8407)
2022-11-03 00:38:43,616:INFO: Batch: 21/31	Total Loss 4.7073 (4.8348)
2022-11-03 00:38:44,089:INFO: Batch: 22/31	Total Loss 5.1350 (4.8478)
2022-11-03 00:38:44,564:INFO: Batch: 23/31	Total Loss 5.0081 (4.8540)
2022-11-03 00:38:45,033:INFO: Batch: 24/31	Total Loss 4.9063 (4.8559)
2022-11-03 00:38:45,581:INFO: Batch: 25/31	Total Loss 4.4447 (4.8384)
2022-11-03 00:38:46,053:INFO: Batch: 26/31	Total Loss 5.3532 (4.8568)
2022-11-03 00:38:46,522:INFO: Batch: 27/31	Total Loss 4.4794 (4.8453)
2022-11-03 00:38:46,992:INFO: Batch: 28/31	Total Loss 3.7400 (4.8107)
2022-11-03 00:38:47,461:INFO: Batch: 29/31	Total Loss 5.1128 (4.8204)
2022-11-03 00:38:47,848:INFO: Batch: 30/31	Total Loss 2.1026 (4.7962)
2022-11-03 00:38:47,986:INFO: - Computing ADE (validation o)
2022-11-03 00:38:48,576:INFO: 		 ADE on eth                       dataset:	 1.0762847661972046
2022-11-03 00:38:48,577:INFO: Average validation o:	ADE  1.0763	FDE  1.8954
2022-11-03 00:38:48,578:INFO: - Computing ADE (validation)
2022-11-03 00:38:48,891:INFO: 		 ADE on hotel                     dataset:	 0.5153440237045288
2022-11-03 00:38:49,187:INFO: 		 ADE on univ                      dataset:	 0.6013301610946655
2022-11-03 00:38:49,432:INFO: 		 ADE on zara1                     dataset:	 0.5984012484550476
2022-11-03 00:38:49,783:INFO: 		 ADE on zara2                     dataset:	 0.4964008927345276
2022-11-03 00:38:49,784:INFO: Average validation:	ADE  0.5580	FDE  1.1071
2022-11-03 00:38:49,785:INFO: - Computing ADE (training)
2022-11-03 00:38:50,244:INFO: 		 ADE on hotel                     dataset:	 0.5664236545562744
2022-11-03 00:38:50,922:INFO: 		 ADE on univ                      dataset:	 0.5867478251457214
2022-11-03 00:38:51,454:INFO: 		 ADE on zara1                     dataset:	 0.6560397744178772
2022-11-03 00:38:52,217:INFO: 		 ADE on zara2                     dataset:	 0.5264642834663391
2022-11-03 00:38:52,217:INFO: Average training:	ADE  0.5784	FDE  1.1554
2022-11-03 00:38:52,226:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_393.pth.tar
2022-11-03 00:38:52,226:INFO: 
===> EPOCH: 394 (P3)
2022-11-03 00:38:52,226:INFO: - Computing loss (training)
2022-11-03 00:38:53,327:INFO: Batch:  0/31	Total Loss 4.3451 (4.3451)
2022-11-03 00:38:53,804:INFO: Batch:  1/31	Total Loss 4.6075 (4.4820)
2022-11-03 00:38:54,275:INFO: Batch:  2/31	Total Loss 4.0954 (4.3540)
2022-11-03 00:38:54,739:INFO: Batch:  3/31	Total Loss 4.7615 (4.4483)
2022-11-03 00:38:55,203:INFO: Batch:  4/31	Total Loss 5.3966 (4.6363)
2022-11-03 00:38:55,676:INFO: Batch:  5/31	Total Loss 5.0384 (4.7080)
2022-11-03 00:38:56,143:INFO: Batch:  6/31	Total Loss 4.6988 (4.7067)
2022-11-03 00:38:56,609:INFO: Batch:  7/31	Total Loss 4.4257 (4.6698)
2022-11-03 00:38:57,076:INFO: Batch:  8/31	Total Loss 4.6659 (4.6694)
2022-11-03 00:38:57,542:INFO: Batch:  9/31	Total Loss 4.8180 (4.6846)
2022-11-03 00:38:58,008:INFO: Batch: 10/31	Total Loss 5.3826 (4.7445)
2022-11-03 00:38:58,478:INFO: Batch: 11/31	Total Loss 5.2552 (4.7831)
2022-11-03 00:38:58,950:INFO: Batch: 12/31	Total Loss 5.1337 (4.8105)
2022-11-03 00:38:59,420:INFO: Batch: 13/31	Total Loss 4.8302 (4.8118)
2022-11-03 00:38:59,893:INFO: Batch: 14/31	Total Loss 4.8976 (4.8171)
2022-11-03 00:39:00,369:INFO: Batch: 15/31	Total Loss 4.3063 (4.7828)
2022-11-03 00:39:00,844:INFO: Batch: 16/31	Total Loss 4.3787 (4.7547)
2022-11-03 00:39:01,323:INFO: Batch: 17/31	Total Loss 4.2031 (4.7245)
2022-11-03 00:39:01,796:INFO: Batch: 18/31	Total Loss 4.8379 (4.7297)
2022-11-03 00:39:02,268:INFO: Batch: 19/31	Total Loss 4.3545 (4.7107)
2022-11-03 00:39:02,739:INFO: Batch: 20/31	Total Loss 5.7348 (4.7609)
2022-11-03 00:39:03,208:INFO: Batch: 21/31	Total Loss 4.6830 (4.7574)
2022-11-03 00:39:03,680:INFO: Batch: 22/31	Total Loss 4.9543 (4.7659)
2022-11-03 00:39:04,153:INFO: Batch: 23/31	Total Loss 4.6204 (4.7595)
2022-11-03 00:39:04,622:INFO: Batch: 24/31	Total Loss 4.7035 (4.7574)
2022-11-03 00:39:05,089:INFO: Batch: 25/31	Total Loss 4.9569 (4.7649)
2022-11-03 00:39:05,558:INFO: Batch: 26/31	Total Loss 4.6106 (4.7585)
2022-11-03 00:39:06,028:INFO: Batch: 27/31	Total Loss 4.6631 (4.7551)
2022-11-03 00:39:06,500:INFO: Batch: 28/31	Total Loss 4.4739 (4.7450)
2022-11-03 00:39:06,970:INFO: Batch: 29/31	Total Loss 4.4406 (4.7358)
2022-11-03 00:39:07,355:INFO: Batch: 30/31	Total Loss 1.7212 (4.7103)
2022-11-03 00:39:07,505:INFO: - Computing ADE (validation o)
2022-11-03 00:39:08,085:INFO: 		 ADE on eth                       dataset:	 1.0411432981491089
2022-11-03 00:39:08,085:INFO: Average validation o:	ADE  1.0411	FDE  1.8305
2022-11-03 00:39:08,086:INFO: - Computing ADE (validation)
2022-11-03 00:39:08,374:INFO: 		 ADE on hotel                     dataset:	 0.49280813336372375
2022-11-03 00:39:08,655:INFO: 		 ADE on univ                      dataset:	 0.5801058411598206
2022-11-03 00:39:08,898:INFO: 		 ADE on zara1                     dataset:	 0.5119982361793518
2022-11-03 00:39:09,262:INFO: 		 ADE on zara2                     dataset:	 0.44534632563591003
2022-11-03 00:39:09,263:INFO: Average validation:	ADE  0.5219	FDE  1.0057
2022-11-03 00:39:09,264:INFO: - Computing ADE (training)
2022-11-03 00:39:09,706:INFO: 		 ADE on hotel                     dataset:	 0.53754061460495
2022-11-03 00:39:10,387:INFO: 		 ADE on univ                      dataset:	 0.5595885515213013
2022-11-03 00:39:10,926:INFO: 		 ADE on zara1                     dataset:	 0.5930799245834351
2022-11-03 00:39:11,667:INFO: 		 ADE on zara2                     dataset:	 0.47492098808288574
2022-11-03 00:39:11,668:INFO: Average training:	ADE  0.5440	FDE  1.0583
2022-11-03 00:39:11,676:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_394.pth.tar
2022-11-03 00:39:11,676:INFO: 
===> EPOCH: 395 (P3)
2022-11-03 00:39:11,677:INFO: - Computing loss (training)
2022-11-03 00:39:12,775:INFO: Batch:  0/31	Total Loss 4.4818 (4.4818)
2022-11-03 00:39:13,244:INFO: Batch:  1/31	Total Loss 4.6753 (4.5739)
2022-11-03 00:39:13,721:INFO: Batch:  2/31	Total Loss 4.7225 (4.6178)
2022-11-03 00:39:14,197:INFO: Batch:  3/31	Total Loss 4.5699 (4.6061)
2022-11-03 00:39:14,668:INFO: Batch:  4/31	Total Loss 4.9328 (4.6786)
2022-11-03 00:39:15,144:INFO: Batch:  5/31	Total Loss 5.2537 (4.7640)
2022-11-03 00:39:15,618:INFO: Batch:  6/31	Total Loss 4.4303 (4.7137)
2022-11-03 00:39:16,090:INFO: Batch:  7/31	Total Loss 4.7913 (4.7240)
2022-11-03 00:39:16,562:INFO: Batch:  8/31	Total Loss 4.6168 (4.7115)
2022-11-03 00:39:17,035:INFO: Batch:  9/31	Total Loss 4.4553 (4.6837)
2022-11-03 00:39:17,507:INFO: Batch: 10/31	Total Loss 4.4643 (4.6614)
2022-11-03 00:39:17,981:INFO: Batch: 11/31	Total Loss 4.4007 (4.6397)
2022-11-03 00:39:18,462:INFO: Batch: 12/31	Total Loss 4.6101 (4.6374)
2022-11-03 00:39:18,938:INFO: Batch: 13/31	Total Loss 4.7165 (4.6432)
2022-11-03 00:39:19,427:INFO: Batch: 14/31	Total Loss 4.7105 (4.6488)
2022-11-03 00:39:19,905:INFO: Batch: 15/31	Total Loss 3.8688 (4.6015)
2022-11-03 00:39:20,382:INFO: Batch: 16/31	Total Loss 4.5994 (4.6014)
2022-11-03 00:39:20,859:INFO: Batch: 17/31	Total Loss 4.5448 (4.5982)
2022-11-03 00:39:21,335:INFO: Batch: 18/31	Total Loss 4.7369 (4.6060)
2022-11-03 00:39:21,813:INFO: Batch: 19/31	Total Loss 4.5394 (4.6025)
2022-11-03 00:39:22,290:INFO: Batch: 20/31	Total Loss 4.6895 (4.6070)
2022-11-03 00:39:22,767:INFO: Batch: 21/31	Total Loss 4.9895 (4.6238)
2022-11-03 00:39:23,244:INFO: Batch: 22/31	Total Loss 4.9063 (4.6357)
2022-11-03 00:39:23,722:INFO: Batch: 23/31	Total Loss 4.5903 (4.6337)
2022-11-03 00:39:24,201:INFO: Batch: 24/31	Total Loss 4.6038 (4.6325)
2022-11-03 00:39:24,679:INFO: Batch: 25/31	Total Loss 4.9535 (4.6443)
2022-11-03 00:39:25,157:INFO: Batch: 26/31	Total Loss 5.3365 (4.6690)
2022-11-03 00:39:25,634:INFO: Batch: 27/31	Total Loss 5.3422 (4.6951)
2022-11-03 00:39:26,112:INFO: Batch: 28/31	Total Loss 5.1740 (4.7115)
2022-11-03 00:39:26,591:INFO: Batch: 29/31	Total Loss 4.4015 (4.7016)
2022-11-03 00:39:26,985:INFO: Batch: 30/31	Total Loss 1.7451 (4.6693)
2022-11-03 00:39:27,133:INFO: - Computing ADE (validation o)
2022-11-03 00:39:27,691:INFO: 		 ADE on eth                       dataset:	 1.0673292875289917
2022-11-03 00:39:27,691:INFO: Average validation o:	ADE  1.0673	FDE  1.8955
2022-11-03 00:39:27,692:INFO: - Computing ADE (validation)
2022-11-03 00:39:27,971:INFO: 		 ADE on hotel                     dataset:	 0.4892493188381195
2022-11-03 00:39:28,281:INFO: 		 ADE on univ                      dataset:	 0.5827984809875488
2022-11-03 00:39:28,541:INFO: 		 ADE on zara1                     dataset:	 0.5656057596206665
2022-11-03 00:39:28,886:INFO: 		 ADE on zara2                     dataset:	 0.4709733724594116
2022-11-03 00:39:28,886:INFO: Average validation:	ADE  0.5357	FDE  1.0288
2022-11-03 00:39:28,887:INFO: - Computing ADE (training)
2022-11-03 00:39:29,330:INFO: 		 ADE on hotel                     dataset:	 0.5302295088768005
2022-11-03 00:39:30,012:INFO: 		 ADE on univ                      dataset:	 0.5668864846229553
2022-11-03 00:39:30,556:INFO: 		 ADE on zara1                     dataset:	 0.6460584998130798
2022-11-03 00:39:31,324:INFO: 		 ADE on zara2                     dataset:	 0.5099464654922485
2022-11-03 00:39:31,324:INFO: Average training:	ADE  0.5594	FDE  1.0858
2022-11-03 00:39:31,333:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_395.pth.tar
2022-11-03 00:39:31,333:INFO: 
===> EPOCH: 396 (P3)
2022-11-03 00:39:31,333:INFO: - Computing loss (training)
2022-11-03 00:39:32,408:INFO: Batch:  0/31	Total Loss 4.7086 (4.7086)
2022-11-03 00:39:32,883:INFO: Batch:  1/31	Total Loss 4.6006 (4.6539)
2022-11-03 00:39:33,356:INFO: Batch:  2/31	Total Loss 4.9529 (4.7569)
2022-11-03 00:39:33,827:INFO: Batch:  3/31	Total Loss 4.3579 (4.6628)
2022-11-03 00:39:34,294:INFO: Batch:  4/31	Total Loss 5.5138 (4.8244)
2022-11-03 00:39:34,767:INFO: Batch:  5/31	Total Loss 4.5229 (4.7801)
2022-11-03 00:39:35,240:INFO: Batch:  6/31	Total Loss 5.9904 (4.9456)
2022-11-03 00:39:35,707:INFO: Batch:  7/31	Total Loss 4.4432 (4.8839)
2022-11-03 00:39:36,176:INFO: Batch:  8/31	Total Loss 4.2694 (4.8128)
2022-11-03 00:39:36,644:INFO: Batch:  9/31	Total Loss 4.7360 (4.8049)
2022-11-03 00:39:37,112:INFO: Batch: 10/31	Total Loss 4.5883 (4.7872)
2022-11-03 00:39:37,658:INFO: Batch: 11/31	Total Loss 4.6631 (4.7776)
2022-11-03 00:39:38,130:INFO: Batch: 12/31	Total Loss 4.9151 (4.7875)
2022-11-03 00:39:38,603:INFO: Batch: 13/31	Total Loss 4.2971 (4.7533)
2022-11-03 00:39:39,078:INFO: Batch: 14/31	Total Loss 5.5759 (4.8057)
2022-11-03 00:39:39,555:INFO: Batch: 15/31	Total Loss 5.4919 (4.8478)
2022-11-03 00:39:40,032:INFO: Batch: 16/31	Total Loss 4.3860 (4.8202)
2022-11-03 00:39:40,506:INFO: Batch: 17/31	Total Loss 4.3931 (4.7981)
2022-11-03 00:39:40,980:INFO: Batch: 18/31	Total Loss 4.5828 (4.7876)
2022-11-03 00:39:41,465:INFO: Batch: 19/31	Total Loss 4.5952 (4.7782)
2022-11-03 00:39:41,950:INFO: Batch: 20/31	Total Loss 5.0348 (4.7913)
2022-11-03 00:39:42,437:INFO: Batch: 21/31	Total Loss 4.5675 (4.7811)
2022-11-03 00:39:42,921:INFO: Batch: 22/31	Total Loss 4.8626 (4.7845)
2022-11-03 00:39:43,404:INFO: Batch: 23/31	Total Loss 4.5925 (4.7764)
2022-11-03 00:39:43,887:INFO: Batch: 24/31	Total Loss 4.7312 (4.7743)
2022-11-03 00:39:44,371:INFO: Batch: 25/31	Total Loss 4.9754 (4.7823)
2022-11-03 00:39:44,856:INFO: Batch: 26/31	Total Loss 4.8054 (4.7831)
2022-11-03 00:39:45,337:INFO: Batch: 27/31	Total Loss 4.7236 (4.7810)
2022-11-03 00:39:45,816:INFO: Batch: 28/31	Total Loss 4.7401 (4.7795)
2022-11-03 00:39:46,298:INFO: Batch: 29/31	Total Loss 4.6495 (4.7751)
2022-11-03 00:39:46,692:INFO: Batch: 30/31	Total Loss 1.6808 (4.7391)
2022-11-03 00:39:46,854:INFO: - Computing ADE (validation o)
2022-11-03 00:39:47,458:INFO: 		 ADE on eth                       dataset:	 1.059515118598938
2022-11-03 00:39:47,458:INFO: Average validation o:	ADE  1.0595	FDE  1.8682
2022-11-03 00:39:47,459:INFO: - Computing ADE (validation)
2022-11-03 00:39:47,719:INFO: 		 ADE on hotel                     dataset:	 0.49822860956192017
2022-11-03 00:39:48,025:INFO: 		 ADE on univ                      dataset:	 0.5817281603813171
2022-11-03 00:39:48,272:INFO: 		 ADE on zara1                     dataset:	 0.5306012034416199
2022-11-03 00:39:48,610:INFO: 		 ADE on zara2                     dataset:	 0.47109830379486084
2022-11-03 00:39:48,611:INFO: Average validation:	ADE  0.5336	FDE  1.0300
2022-11-03 00:39:48,611:INFO: - Computing ADE (training)
2022-11-03 00:39:49,062:INFO: 		 ADE on hotel                     dataset:	 0.535423219203949
2022-11-03 00:39:49,764:INFO: 		 ADE on univ                      dataset:	 0.5660436749458313
2022-11-03 00:39:50,308:INFO: 		 ADE on zara1                     dataset:	 0.6226151585578918
2022-11-03 00:39:51,038:INFO: 		 ADE on zara2                     dataset:	 0.5050830245018005
2022-11-03 00:39:51,038:INFO: Average training:	ADE  0.5565	FDE  1.0841
2022-11-03 00:39:51,047:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_396.pth.tar
2022-11-03 00:39:51,047:INFO: 
===> EPOCH: 397 (P3)
2022-11-03 00:39:51,047:INFO: - Computing loss (training)
2022-11-03 00:39:52,150:INFO: Batch:  0/31	Total Loss 4.7594 (4.7594)
2022-11-03 00:39:52,627:INFO: Batch:  1/31	Total Loss 5.4474 (5.1157)
2022-11-03 00:39:53,106:INFO: Batch:  2/31	Total Loss 3.6291 (4.6425)
2022-11-03 00:39:53,581:INFO: Batch:  3/31	Total Loss 4.2959 (4.5517)
2022-11-03 00:39:54,059:INFO: Batch:  4/31	Total Loss 6.5684 (5.0036)
2022-11-03 00:39:54,542:INFO: Batch:  5/31	Total Loss 5.6543 (5.1029)
2022-11-03 00:39:55,019:INFO: Batch:  6/31	Total Loss 4.5373 (5.0075)
2022-11-03 00:39:55,495:INFO: Batch:  7/31	Total Loss 4.2320 (4.9169)
2022-11-03 00:39:55,972:INFO: Batch:  8/31	Total Loss 4.2252 (4.8397)
2022-11-03 00:39:56,447:INFO: Batch:  9/31	Total Loss 4.3092 (4.7905)
2022-11-03 00:39:56,918:INFO: Batch: 10/31	Total Loss 4.8810 (4.7985)
2022-11-03 00:39:57,393:INFO: Batch: 11/31	Total Loss 4.3693 (4.7635)
2022-11-03 00:39:57,869:INFO: Batch: 12/31	Total Loss 4.6157 (4.7520)
2022-11-03 00:39:58,346:INFO: Batch: 13/31	Total Loss 4.7101 (4.7490)
2022-11-03 00:39:58,822:INFO: Batch: 14/31	Total Loss 4.6463 (4.7428)
2022-11-03 00:39:59,298:INFO: Batch: 15/31	Total Loss 4.4441 (4.7239)
2022-11-03 00:39:59,770:INFO: Batch: 16/31	Total Loss 4.4370 (4.7078)
2022-11-03 00:40:00,246:INFO: Batch: 17/31	Total Loss 4.2953 (4.6837)
2022-11-03 00:40:00,719:INFO: Batch: 18/31	Total Loss 3.8742 (4.6382)
2022-11-03 00:40:01,195:INFO: Batch: 19/31	Total Loss 4.2173 (4.6181)
2022-11-03 00:40:01,666:INFO: Batch: 20/31	Total Loss 4.6583 (4.6199)
2022-11-03 00:40:02,139:INFO: Batch: 21/31	Total Loss 4.4287 (4.6120)
2022-11-03 00:40:02,612:INFO: Batch: 22/31	Total Loss 4.5891 (4.6110)
2022-11-03 00:40:03,086:INFO: Batch: 23/31	Total Loss 4.9270 (4.6239)
2022-11-03 00:40:03,559:INFO: Batch: 24/31	Total Loss 4.5239 (4.6199)
2022-11-03 00:40:04,032:INFO: Batch: 25/31	Total Loss 4.5498 (4.6171)
2022-11-03 00:40:04,505:INFO: Batch: 26/31	Total Loss 5.2727 (4.6384)
2022-11-03 00:40:04,978:INFO: Batch: 27/31	Total Loss 4.5948 (4.6367)
2022-11-03 00:40:05,450:INFO: Batch: 28/31	Total Loss 5.2212 (4.6543)
2022-11-03 00:40:05,924:INFO: Batch: 29/31	Total Loss 4.8334 (4.6601)
2022-11-03 00:40:06,315:INFO: Batch: 30/31	Total Loss 1.6533 (4.6318)
2022-11-03 00:40:06,473:INFO: - Computing ADE (validation o)
2022-11-03 00:40:07,078:INFO: 		 ADE on eth                       dataset:	 1.0277234315872192
2022-11-03 00:40:07,078:INFO: Average validation o:	ADE  1.0277	FDE  1.8292
2022-11-03 00:40:07,079:INFO: - Computing ADE (validation)
2022-11-03 00:40:07,364:INFO: 		 ADE on hotel                     dataset:	 0.48553594946861267
2022-11-03 00:40:07,663:INFO: 		 ADE on univ                      dataset:	 0.5747660398483276
2022-11-03 00:40:07,923:INFO: 		 ADE on zara1                     dataset:	 0.5204090476036072
2022-11-03 00:40:08,264:INFO: 		 ADE on zara2                     dataset:	 0.44462907314300537
2022-11-03 00:40:08,264:INFO: Average validation:	ADE  0.5190	FDE  1.0071
2022-11-03 00:40:08,265:INFO: - Computing ADE (training)
2022-11-03 00:40:08,734:INFO: 		 ADE on hotel                     dataset:	 0.5254530310630798
2022-11-03 00:40:09,396:INFO: 		 ADE on univ                      dataset:	 0.5574164390563965
2022-11-03 00:40:09,928:INFO: 		 ADE on zara1                     dataset:	 0.5919737815856934
2022-11-03 00:40:10,673:INFO: 		 ADE on zara2                     dataset:	 0.4724067747592926
2022-11-03 00:40:10,674:INFO: Average training:	ADE  0.5416	FDE  1.0597
2022-11-03 00:40:10,682:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_397.pth.tar
2022-11-03 00:40:10,682:INFO: 
===> EPOCH: 398 (P3)
2022-11-03 00:40:10,683:INFO: - Computing loss (training)
2022-11-03 00:40:11,767:INFO: Batch:  0/31	Total Loss 5.8966 (5.8966)
2022-11-03 00:40:12,236:INFO: Batch:  1/31	Total Loss 4.3793 (5.1187)
2022-11-03 00:40:12,700:INFO: Batch:  2/31	Total Loss 4.1704 (4.7861)
2022-11-03 00:40:13,168:INFO: Batch:  3/31	Total Loss 5.1221 (4.8610)
2022-11-03 00:40:13,632:INFO: Batch:  4/31	Total Loss 5.5993 (5.0055)
2022-11-03 00:40:14,101:INFO: Batch:  5/31	Total Loss 5.2315 (5.0399)
2022-11-03 00:40:14,567:INFO: Batch:  6/31	Total Loss 4.1481 (4.8977)
2022-11-03 00:40:15,031:INFO: Batch:  7/31	Total Loss 4.6120 (4.8625)
2022-11-03 00:40:15,498:INFO: Batch:  8/31	Total Loss 5.2347 (4.9067)
2022-11-03 00:40:15,965:INFO: Batch:  9/31	Total Loss 4.6960 (4.8869)
2022-11-03 00:40:16,430:INFO: Batch: 10/31	Total Loss 7.0842 (5.1039)
2022-11-03 00:40:16,896:INFO: Batch: 11/31	Total Loss 5.1656 (5.1090)
2022-11-03 00:40:17,365:INFO: Batch: 12/31	Total Loss 4.6037 (5.0720)
2022-11-03 00:40:17,835:INFO: Batch: 13/31	Total Loss 4.3098 (5.0091)
2022-11-03 00:40:18,305:INFO: Batch: 14/31	Total Loss 4.7063 (4.9897)
2022-11-03 00:40:18,775:INFO: Batch: 15/31	Total Loss 5.3753 (5.0167)
2022-11-03 00:40:19,242:INFO: Batch: 16/31	Total Loss 4.2000 (4.9645)
2022-11-03 00:40:19,710:INFO: Batch: 17/31	Total Loss 4.3411 (4.9297)
2022-11-03 00:40:20,180:INFO: Batch: 18/31	Total Loss 4.9129 (4.9289)
2022-11-03 00:40:20,647:INFO: Batch: 19/31	Total Loss 5.0907 (4.9364)
2022-11-03 00:40:21,114:INFO: Batch: 20/31	Total Loss 4.5185 (4.9168)
2022-11-03 00:40:21,584:INFO: Batch: 21/31	Total Loss 4.5348 (4.9004)
2022-11-03 00:40:22,053:INFO: Batch: 22/31	Total Loss 4.3116 (4.8728)
2022-11-03 00:40:22,521:INFO: Batch: 23/31	Total Loss 4.4567 (4.8555)
2022-11-03 00:40:22,989:INFO: Batch: 24/31	Total Loss 4.7498 (4.8513)
2022-11-03 00:40:23,457:INFO: Batch: 25/31	Total Loss 4.6564 (4.8438)
2022-11-03 00:40:23,925:INFO: Batch: 26/31	Total Loss 4.6841 (4.8387)
2022-11-03 00:40:24,392:INFO: Batch: 27/31	Total Loss 4.8470 (4.8390)
2022-11-03 00:40:24,860:INFO: Batch: 28/31	Total Loss 4.7873 (4.8372)
2022-11-03 00:40:25,327:INFO: Batch: 29/31	Total Loss 4.7660 (4.8348)
2022-11-03 00:40:25,711:INFO: Batch: 30/31	Total Loss 2.0773 (4.8090)
2022-11-03 00:40:25,861:INFO: - Computing ADE (validation o)
2022-11-03 00:40:26,438:INFO: 		 ADE on eth                       dataset:	 1.046863079071045
2022-11-03 00:40:26,438:INFO: Average validation o:	ADE  1.0469	FDE  1.8368
2022-11-03 00:40:26,439:INFO: - Computing ADE (validation)
2022-11-03 00:40:26,699:INFO: 		 ADE on hotel                     dataset:	 0.4933014214038849
2022-11-03 00:40:26,999:INFO: 		 ADE on univ                      dataset:	 0.5815844535827637
2022-11-03 00:40:27,254:INFO: 		 ADE on zara1                     dataset:	 0.5383656620979309
2022-11-03 00:40:27,589:INFO: 		 ADE on zara2                     dataset:	 0.45675650238990784
2022-11-03 00:40:27,589:INFO: Average validation:	ADE  0.5284	FDE  1.0213
2022-11-03 00:40:27,590:INFO: - Computing ADE (training)
2022-11-03 00:40:28,035:INFO: 		 ADE on hotel                     dataset:	 0.5354577898979187
2022-11-03 00:40:28,711:INFO: 		 ADE on univ                      dataset:	 0.5618221759796143
2022-11-03 00:40:29,240:INFO: 		 ADE on zara1                     dataset:	 0.620588481426239
2022-11-03 00:40:29,972:INFO: 		 ADE on zara2                     dataset:	 0.4900531470775604
2022-11-03 00:40:29,972:INFO: Average training:	ADE  0.5503	FDE  1.0725
2022-11-03 00:40:29,981:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_398.pth.tar
2022-11-03 00:40:29,981:INFO: 
===> EPOCH: 399 (P3)
2022-11-03 00:40:29,981:INFO: - Computing loss (training)
2022-11-03 00:40:31,162:INFO: Batch:  0/31	Total Loss 4.3490 (4.3490)
2022-11-03 00:40:31,631:INFO: Batch:  1/31	Total Loss 4.8570 (4.6041)
2022-11-03 00:40:32,105:INFO: Batch:  2/31	Total Loss 4.7063 (4.6374)
2022-11-03 00:40:32,574:INFO: Batch:  3/31	Total Loss 4.8920 (4.7015)
2022-11-03 00:40:33,047:INFO: Batch:  4/31	Total Loss 4.9798 (4.7572)
2022-11-03 00:40:33,522:INFO: Batch:  5/31	Total Loss 5.0195 (4.8024)
2022-11-03 00:40:33,989:INFO: Batch:  6/31	Total Loss 4.5340 (4.7680)
2022-11-03 00:40:34,454:INFO: Batch:  7/31	Total Loss 4.3436 (4.7154)
2022-11-03 00:40:34,919:INFO: Batch:  8/31	Total Loss 5.4722 (4.8003)
2022-11-03 00:40:35,386:INFO: Batch:  9/31	Total Loss 5.3998 (4.8543)
2022-11-03 00:40:35,851:INFO: Batch: 10/31	Total Loss 4.5065 (4.8176)
2022-11-03 00:40:36,318:INFO: Batch: 11/31	Total Loss 5.0379 (4.8337)
2022-11-03 00:40:36,789:INFO: Batch: 12/31	Total Loss 4.3966 (4.7989)
2022-11-03 00:40:37,258:INFO: Batch: 13/31	Total Loss 5.0109 (4.8151)
2022-11-03 00:40:37,727:INFO: Batch: 14/31	Total Loss 4.4922 (4.7920)
2022-11-03 00:40:38,198:INFO: Batch: 15/31	Total Loss 5.0881 (4.8103)
2022-11-03 00:40:38,667:INFO: Batch: 16/31	Total Loss 4.2259 (4.7742)
2022-11-03 00:40:39,137:INFO: Batch: 17/31	Total Loss 4.7120 (4.7706)
2022-11-03 00:40:39,607:INFO: Batch: 18/31	Total Loss 4.6338 (4.7630)
2022-11-03 00:40:40,081:INFO: Batch: 19/31	Total Loss 4.9388 (4.7727)
2022-11-03 00:40:40,552:INFO: Batch: 20/31	Total Loss 4.2575 (4.7500)
2022-11-03 00:40:41,020:INFO: Batch: 21/31	Total Loss 4.4064 (4.7356)
2022-11-03 00:40:41,489:INFO: Batch: 22/31	Total Loss 4.6306 (4.7310)
2022-11-03 00:40:41,957:INFO: Batch: 23/31	Total Loss 4.7149 (4.7303)
2022-11-03 00:40:42,427:INFO: Batch: 24/31	Total Loss 4.6833 (4.7284)
2022-11-03 00:40:42,896:INFO: Batch: 25/31	Total Loss 4.4198 (4.7145)
2022-11-03 00:40:43,364:INFO: Batch: 26/31	Total Loss 4.9113 (4.7218)
2022-11-03 00:40:43,834:INFO: Batch: 27/31	Total Loss 5.2195 (4.7397)
2022-11-03 00:40:44,303:INFO: Batch: 28/31	Total Loss 4.3581 (4.7264)
2022-11-03 00:40:44,770:INFO: Batch: 29/31	Total Loss 4.4012 (4.7162)
2022-11-03 00:40:45,154:INFO: Batch: 30/31	Total Loss 1.9343 (4.6871)
2022-11-03 00:40:45,305:INFO: - Computing ADE (validation o)
2022-11-03 00:40:45,863:INFO: 		 ADE on eth                       dataset:	 1.0205997228622437
2022-11-03 00:40:45,864:INFO: Average validation o:	ADE  1.0206	FDE  1.8487
2022-11-03 00:40:45,864:INFO: - Computing ADE (validation)
2022-11-03 00:40:46,155:INFO: 		 ADE on hotel                     dataset:	 0.5029502511024475
2022-11-03 00:40:46,443:INFO: 		 ADE on univ                      dataset:	 0.5814324021339417
2022-11-03 00:40:46,715:INFO: 		 ADE on zara1                     dataset:	 0.5141676068305969
2022-11-03 00:40:47,074:INFO: 		 ADE on zara2                     dataset:	 0.4495534896850586
2022-11-03 00:40:47,074:INFO: Average validation:	ADE  0.5248	FDE  1.0430
2022-11-03 00:40:47,075:INFO: - Computing ADE (training)
2022-11-03 00:40:47,526:INFO: 		 ADE on hotel                     dataset:	 0.5440007448196411
2022-11-03 00:40:48,199:INFO: 		 ADE on univ                      dataset:	 0.5659257769584656
2022-11-03 00:40:48,748:INFO: 		 ADE on zara1                     dataset:	 0.5751376748085022
2022-11-03 00:40:49,478:INFO: 		 ADE on zara2                     dataset:	 0.47173967957496643
2022-11-03 00:40:49,479:INFO: Average training:	ADE  0.5468	FDE  1.0938
2022-11-03 00:40:49,488:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_399.pth.tar
2022-11-03 00:40:49,488:INFO: 
===> EPOCH: 400 (P3)
2022-11-03 00:40:49,488:INFO: - Computing loss (training)
2022-11-03 00:40:50,565:INFO: Batch:  0/31	Total Loss 5.0175 (5.0175)
2022-11-03 00:40:51,047:INFO: Batch:  1/31	Total Loss 4.7492 (4.8844)
2022-11-03 00:40:51,521:INFO: Batch:  2/31	Total Loss 4.3855 (4.7235)
2022-11-03 00:40:51,994:INFO: Batch:  3/31	Total Loss 4.8865 (4.7672)
2022-11-03 00:40:52,467:INFO: Batch:  4/31	Total Loss 4.2898 (4.6675)
2022-11-03 00:40:52,947:INFO: Batch:  5/31	Total Loss 4.6446 (4.6634)
2022-11-03 00:40:53,419:INFO: Batch:  6/31	Total Loss 5.1013 (4.7341)
2022-11-03 00:40:53,891:INFO: Batch:  7/31	Total Loss 4.5148 (4.7084)
2022-11-03 00:40:54,356:INFO: Batch:  8/31	Total Loss 4.2563 (4.6567)
2022-11-03 00:40:54,823:INFO: Batch:  9/31	Total Loss 3.8564 (4.5777)
2022-11-03 00:40:55,288:INFO: Batch: 10/31	Total Loss 4.3959 (4.5604)
2022-11-03 00:40:55,754:INFO: Batch: 11/31	Total Loss 4.7292 (4.5737)
2022-11-03 00:40:56,223:INFO: Batch: 12/31	Total Loss 4.3158 (4.5533)
2022-11-03 00:40:56,692:INFO: Batch: 13/31	Total Loss 4.4703 (4.5473)
2022-11-03 00:40:57,160:INFO: Batch: 14/31	Total Loss 4.5238 (4.5459)
2022-11-03 00:40:57,631:INFO: Batch: 15/31	Total Loss 4.5072 (4.5433)
2022-11-03 00:40:58,099:INFO: Batch: 16/31	Total Loss 4.3924 (4.5341)
2022-11-03 00:40:58,569:INFO: Batch: 17/31	Total Loss 4.1354 (4.5144)
2022-11-03 00:40:59,040:INFO: Batch: 18/31	Total Loss 4.5406 (4.5158)
2022-11-03 00:40:59,508:INFO: Batch: 19/31	Total Loss 4.3468 (4.5070)
2022-11-03 00:40:59,985:INFO: Batch: 20/31	Total Loss 5.2551 (4.5371)
2022-11-03 00:41:00,455:INFO: Batch: 21/31	Total Loss 4.4620 (4.5338)
2022-11-03 00:41:00,927:INFO: Batch: 22/31	Total Loss 5.4713 (4.5759)
2022-11-03 00:41:01,397:INFO: Batch: 23/31	Total Loss 4.6040 (4.5770)
2022-11-03 00:41:01,868:INFO: Batch: 24/31	Total Loss 4.3307 (4.5675)
2022-11-03 00:41:02,338:INFO: Batch: 25/31	Total Loss 5.0964 (4.5877)
2022-11-03 00:41:02,808:INFO: Batch: 26/31	Total Loss 4.7956 (4.5949)
2022-11-03 00:41:03,275:INFO: Batch: 27/31	Total Loss 4.3934 (4.5877)
2022-11-03 00:41:03,743:INFO: Batch: 28/31	Total Loss 5.3511 (4.6107)
2022-11-03 00:41:04,212:INFO: Batch: 29/31	Total Loss 4.9556 (4.6231)
2022-11-03 00:41:04,599:INFO: Batch: 30/31	Total Loss 2.1024 (4.5980)
2022-11-03 00:41:04,738:INFO: - Computing ADE (validation o)
2022-11-03 00:41:05,322:INFO: 		 ADE on eth                       dataset:	 1.0723893642425537
2022-11-03 00:41:05,322:INFO: Average validation o:	ADE  1.0724	FDE  1.9035
2022-11-03 00:41:05,323:INFO: - Computing ADE (validation)
2022-11-03 00:41:05,612:INFO: 		 ADE on hotel                     dataset:	 0.5511749386787415
2022-11-03 00:41:05,903:INFO: 		 ADE on univ                      dataset:	 0.6109985113143921
2022-11-03 00:41:06,162:INFO: 		 ADE on zara1                     dataset:	 0.4918687641620636
2022-11-03 00:41:06,504:INFO: 		 ADE on zara2                     dataset:	 0.5018765330314636
2022-11-03 00:41:06,504:INFO: Average validation:	ADE  0.5608	FDE  1.1284
2022-11-03 00:41:06,505:INFO: - Computing ADE (training)
2022-11-03 00:41:06,966:INFO: 		 ADE on hotel                     dataset:	 0.5801275968551636
2022-11-03 00:41:07,679:INFO: 		 ADE on univ                      dataset:	 0.590735673904419
2022-11-03 00:41:08,227:INFO: 		 ADE on zara1                     dataset:	 0.621076226234436
2022-11-03 00:41:08,990:INFO: 		 ADE on zara2                     dataset:	 0.532199501991272
2022-11-03 00:41:08,990:INFO: Average training:	ADE  0.5805	FDE  1.1722
2022-11-03 00:41:09,000:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_400.pth.tar
2022-11-03 00:41:09,000:INFO: 
===> EPOCH: 401 (P3)
2022-11-03 00:41:09,000:INFO: - Computing loss (training)
2022-11-03 00:41:10,096:INFO: Batch:  0/31	Total Loss 4.7020 (4.7020)
2022-11-03 00:41:10,569:INFO: Batch:  1/31	Total Loss 4.5099 (4.6013)
2022-11-03 00:41:11,042:INFO: Batch:  2/31	Total Loss 4.7895 (4.6629)
2022-11-03 00:41:11,518:INFO: Batch:  3/31	Total Loss 5.9175 (4.9718)
2022-11-03 00:41:11,991:INFO: Batch:  4/31	Total Loss 5.2702 (5.0213)
2022-11-03 00:41:12,464:INFO: Batch:  5/31	Total Loss 5.3301 (5.0714)
2022-11-03 00:41:12,936:INFO: Batch:  6/31	Total Loss 5.1784 (5.0868)
2022-11-03 00:41:13,405:INFO: Batch:  7/31	Total Loss 4.7045 (5.0382)
2022-11-03 00:41:13,875:INFO: Batch:  8/31	Total Loss 4.3329 (4.9645)
2022-11-03 00:41:14,346:INFO: Batch:  9/31	Total Loss 4.7537 (4.9459)
2022-11-03 00:41:14,819:INFO: Batch: 10/31	Total Loss 4.8882 (4.9407)
2022-11-03 00:41:15,288:INFO: Batch: 11/31	Total Loss 4.0861 (4.8720)
2022-11-03 00:41:15,764:INFO: Batch: 12/31	Total Loss 5.0250 (4.8843)
2022-11-03 00:41:16,240:INFO: Batch: 13/31	Total Loss 5.3258 (4.9191)
2022-11-03 00:41:16,714:INFO: Batch: 14/31	Total Loss 5.0251 (4.9258)
2022-11-03 00:41:17,187:INFO: Batch: 15/31	Total Loss 4.8676 (4.9223)
2022-11-03 00:41:17,660:INFO: Batch: 16/31	Total Loss 5.2576 (4.9417)
2022-11-03 00:41:18,133:INFO: Batch: 17/31	Total Loss 4.7045 (4.9287)
2022-11-03 00:41:18,609:INFO: Batch: 18/31	Total Loss 4.4811 (4.9060)
2022-11-03 00:41:19,082:INFO: Batch: 19/31	Total Loss 5.0547 (4.9129)
2022-11-03 00:41:19,557:INFO: Batch: 20/31	Total Loss 4.6139 (4.8993)
2022-11-03 00:41:20,032:INFO: Batch: 21/31	Total Loss 4.9026 (4.8995)
2022-11-03 00:41:20,506:INFO: Batch: 22/31	Total Loss 4.2524 (4.8734)
2022-11-03 00:41:21,073:INFO: Batch: 23/31	Total Loss 4.5039 (4.8568)
2022-11-03 00:41:21,570:INFO: Batch: 24/31	Total Loss 4.2688 (4.8335)
2022-11-03 00:41:22,044:INFO: Batch: 25/31	Total Loss 4.9797 (4.8392)
2022-11-03 00:41:22,585:INFO: Batch: 26/31	Total Loss 4.2493 (4.8175)
2022-11-03 00:41:23,069:INFO: Batch: 27/31	Total Loss 4.4541 (4.8049)
2022-11-03 00:41:23,550:INFO: Batch: 28/31	Total Loss 4.4660 (4.7929)
2022-11-03 00:41:24,025:INFO: Batch: 29/31	Total Loss 4.7230 (4.7908)
2022-11-03 00:41:24,419:INFO: Batch: 30/31	Total Loss 1.8296 (4.7627)
2022-11-03 00:41:24,580:INFO: - Computing ADE (validation o)
2022-11-03 00:41:25,154:INFO: 		 ADE on eth                       dataset:	 1.0381096601486206
2022-11-03 00:41:25,154:INFO: Average validation o:	ADE  1.0381	FDE  1.8453
2022-11-03 00:41:25,155:INFO: - Computing ADE (validation)
2022-11-03 00:41:25,451:INFO: 		 ADE on hotel                     dataset:	 0.4953402876853943
2022-11-03 00:41:25,753:INFO: 		 ADE on univ                      dataset:	 0.5834633708000183
2022-11-03 00:41:26,002:INFO: 		 ADE on zara1                     dataset:	 0.5316397547721863
2022-11-03 00:41:26,362:INFO: 		 ADE on zara2                     dataset:	 0.4494816064834595
2022-11-03 00:41:26,362:INFO: Average validation:	ADE  0.5265	FDE  1.0370
2022-11-03 00:41:26,363:INFO: - Computing ADE (training)
2022-11-03 00:41:26,799:INFO: 		 ADE on hotel                     dataset:	 0.5444905757904053
2022-11-03 00:41:27,468:INFO: 		 ADE on univ                      dataset:	 0.5629755258560181
2022-11-03 00:41:27,999:INFO: 		 ADE on zara1                     dataset:	 0.6006798148155212
2022-11-03 00:41:28,747:INFO: 		 ADE on zara2                     dataset:	 0.4781065285205841
2022-11-03 00:41:28,747:INFO: Average training:	ADE  0.5477	FDE  1.0852
2022-11-03 00:41:28,757:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_401.pth.tar
2022-11-03 00:41:28,757:INFO: 
===> EPOCH: 402 (P3)
2022-11-03 00:41:28,758:INFO: - Computing loss (training)
2022-11-03 00:41:29,854:INFO: Batch:  0/31	Total Loss 4.3668 (4.3668)
2022-11-03 00:41:30,327:INFO: Batch:  1/31	Total Loss 5.3248 (4.8285)
2022-11-03 00:41:30,798:INFO: Batch:  2/31	Total Loss 4.5202 (4.7216)
2022-11-03 00:41:31,273:INFO: Batch:  3/31	Total Loss 4.1701 (4.5862)
2022-11-03 00:41:31,745:INFO: Batch:  4/31	Total Loss 4.6096 (4.5909)
2022-11-03 00:41:32,221:INFO: Batch:  5/31	Total Loss 4.5316 (4.5809)
2022-11-03 00:41:32,698:INFO: Batch:  6/31	Total Loss 4.9229 (4.6231)
2022-11-03 00:41:33,169:INFO: Batch:  7/31	Total Loss 4.8811 (4.6566)
2022-11-03 00:41:33,640:INFO: Batch:  8/31	Total Loss 5.4591 (4.7453)
2022-11-03 00:41:34,110:INFO: Batch:  9/31	Total Loss 4.8148 (4.7519)
2022-11-03 00:41:34,579:INFO: Batch: 10/31	Total Loss 4.2392 (4.7058)
2022-11-03 00:41:35,051:INFO: Batch: 11/31	Total Loss 5.0594 (4.7318)
2022-11-03 00:41:35,527:INFO: Batch: 12/31	Total Loss 4.9263 (4.7469)
2022-11-03 00:41:36,003:INFO: Batch: 13/31	Total Loss 4.6290 (4.7381)
2022-11-03 00:41:36,480:INFO: Batch: 14/31	Total Loss 4.2878 (4.7118)
2022-11-03 00:41:36,954:INFO: Batch: 15/31	Total Loss 4.5067 (4.6980)
2022-11-03 00:41:37,426:INFO: Batch: 16/31	Total Loss 4.6399 (4.6945)
2022-11-03 00:41:37,900:INFO: Batch: 17/31	Total Loss 4.9487 (4.7094)
2022-11-03 00:41:38,372:INFO: Batch: 18/31	Total Loss 4.1654 (4.6793)
2022-11-03 00:41:38,846:INFO: Batch: 19/31	Total Loss 5.7767 (4.7315)
2022-11-03 00:41:39,316:INFO: Batch: 20/31	Total Loss 4.0759 (4.7017)
2022-11-03 00:41:39,793:INFO: Batch: 21/31	Total Loss 4.3966 (4.6852)
2022-11-03 00:41:40,267:INFO: Batch: 22/31	Total Loss 4.8182 (4.6911)
2022-11-03 00:41:40,738:INFO: Batch: 23/31	Total Loss 4.8622 (4.6985)
2022-11-03 00:41:41,210:INFO: Batch: 24/31	Total Loss 4.6666 (4.6973)
2022-11-03 00:41:41,680:INFO: Batch: 25/31	Total Loss 4.8893 (4.7048)
2022-11-03 00:41:42,152:INFO: Batch: 26/31	Total Loss 4.4719 (4.6971)
2022-11-03 00:41:42,624:INFO: Batch: 27/31	Total Loss 4.7968 (4.7006)
2022-11-03 00:41:43,096:INFO: Batch: 28/31	Total Loss 4.6688 (4.6993)
2022-11-03 00:41:43,570:INFO: Batch: 29/31	Total Loss 4.8412 (4.7044)
2022-11-03 00:41:43,958:INFO: Batch: 30/31	Total Loss 1.7703 (4.6798)
2022-11-03 00:41:44,110:INFO: - Computing ADE (validation o)
2022-11-03 00:41:44,684:INFO: 		 ADE on eth                       dataset:	 1.025618314743042
2022-11-03 00:41:44,684:INFO: Average validation o:	ADE  1.0256	FDE  1.8138
2022-11-03 00:41:44,685:INFO: - Computing ADE (validation)
2022-11-03 00:41:44,959:INFO: 		 ADE on hotel                     dataset:	 0.48336729407310486
2022-11-03 00:41:45,246:INFO: 		 ADE on univ                      dataset:	 0.5740031599998474
2022-11-03 00:41:45,498:INFO: 		 ADE on zara1                     dataset:	 0.4974651336669922
2022-11-03 00:41:45,872:INFO: 		 ADE on zara2                     dataset:	 0.44571322202682495
2022-11-03 00:41:45,872:INFO: Average validation:	ADE  0.5175	FDE  1.0089
2022-11-03 00:41:45,873:INFO: - Computing ADE (training)
2022-11-03 00:41:46,324:INFO: 		 ADE on hotel                     dataset:	 0.5249563455581665
2022-11-03 00:41:46,990:INFO: 		 ADE on univ                      dataset:	 0.5574650168418884
2022-11-03 00:41:47,535:INFO: 		 ADE on zara1                     dataset:	 0.5944003462791443
2022-11-03 00:41:48,271:INFO: 		 ADE on zara2                     dataset:	 0.4717773199081421
2022-11-03 00:41:48,272:INFO: Average training:	ADE  0.5416	FDE  1.0645
2022-11-03 00:41:48,280:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_402.pth.tar
2022-11-03 00:41:48,281:INFO: 
===> EPOCH: 403 (P3)
2022-11-03 00:41:48,281:INFO: - Computing loss (training)
2022-11-03 00:41:49,368:INFO: Batch:  0/31	Total Loss 4.0587 (4.0587)
2022-11-03 00:41:49,844:INFO: Batch:  1/31	Total Loss 5.0968 (4.5322)
2022-11-03 00:41:50,314:INFO: Batch:  2/31	Total Loss 4.0706 (4.3742)
2022-11-03 00:41:50,784:INFO: Batch:  3/31	Total Loss 4.7493 (4.4717)
2022-11-03 00:41:51,252:INFO: Batch:  4/31	Total Loss 4.6976 (4.5192)
2022-11-03 00:41:51,722:INFO: Batch:  5/31	Total Loss 4.4701 (4.5117)
2022-11-03 00:41:52,190:INFO: Batch:  6/31	Total Loss 4.3708 (4.4894)
2022-11-03 00:41:52,655:INFO: Batch:  7/31	Total Loss 4.4916 (4.4897)
2022-11-03 00:41:53,121:INFO: Batch:  8/31	Total Loss 4.6862 (4.5125)
2022-11-03 00:41:53,588:INFO: Batch:  9/31	Total Loss 4.4579 (4.5071)
2022-11-03 00:41:54,052:INFO: Batch: 10/31	Total Loss 4.4323 (4.5003)
2022-11-03 00:41:54,525:INFO: Batch: 11/31	Total Loss 4.4472 (4.4961)
2022-11-03 00:41:55,005:INFO: Batch: 12/31	Total Loss 5.1380 (4.5448)
2022-11-03 00:41:55,480:INFO: Batch: 13/31	Total Loss 4.6410 (4.5510)
2022-11-03 00:41:55,959:INFO: Batch: 14/31	Total Loss 4.7933 (4.5683)
2022-11-03 00:41:56,429:INFO: Batch: 15/31	Total Loss 5.0278 (4.5987)
2022-11-03 00:41:56,900:INFO: Batch: 16/31	Total Loss 5.1180 (4.6296)
2022-11-03 00:41:57,368:INFO: Batch: 17/31	Total Loss 4.2302 (4.6045)
2022-11-03 00:41:57,839:INFO: Batch: 18/31	Total Loss 5.4407 (4.6427)
2022-11-03 00:41:58,308:INFO: Batch: 19/31	Total Loss 4.0159 (4.6085)
2022-11-03 00:41:58,779:INFO: Batch: 20/31	Total Loss 4.5536 (4.6058)
2022-11-03 00:41:59,249:INFO: Batch: 21/31	Total Loss 5.0038 (4.6227)
2022-11-03 00:41:59,718:INFO: Batch: 22/31	Total Loss 5.0117 (4.6401)
2022-11-03 00:42:00,191:INFO: Batch: 23/31	Total Loss 5.0929 (4.6602)
2022-11-03 00:42:00,660:INFO: Batch: 24/31	Total Loss 4.4102 (4.6485)
2022-11-03 00:42:01,131:INFO: Batch: 25/31	Total Loss 4.5913 (4.6465)
2022-11-03 00:42:01,603:INFO: Batch: 26/31	Total Loss 4.6622 (4.6470)
2022-11-03 00:42:02,073:INFO: Batch: 27/31	Total Loss 4.2269 (4.6319)
2022-11-03 00:42:02,543:INFO: Batch: 28/31	Total Loss 6.5558 (4.6956)
2022-11-03 00:42:03,010:INFO: Batch: 29/31	Total Loss 4.5171 (4.6900)
2022-11-03 00:42:03,396:INFO: Batch: 30/31	Total Loss 2.0104 (4.6639)
2022-11-03 00:42:03,544:INFO: - Computing ADE (validation o)
2022-11-03 00:42:04,120:INFO: 		 ADE on eth                       dataset:	 1.0567258596420288
2022-11-03 00:42:04,120:INFO: Average validation o:	ADE  1.0567	FDE  1.9117
2022-11-03 00:42:04,120:INFO: - Computing ADE (validation)
2022-11-03 00:42:04,378:INFO: 		 ADE on hotel                     dataset:	 0.5064577460289001
2022-11-03 00:42:04,661:INFO: 		 ADE on univ                      dataset:	 0.5837514996528625
2022-11-03 00:42:04,911:INFO: 		 ADE on zara1                     dataset:	 0.5527805685997009
2022-11-03 00:42:05,263:INFO: 		 ADE on zara2                     dataset:	 0.48222866654396057
2022-11-03 00:42:05,264:INFO: Average validation:	ADE  0.5405	FDE  1.0648
2022-11-03 00:42:05,264:INFO: - Computing ADE (training)
2022-11-03 00:42:05,704:INFO: 		 ADE on hotel                     dataset:	 0.5437363982200623
2022-11-03 00:42:06,406:INFO: 		 ADE on univ                      dataset:	 0.5765702128410339
2022-11-03 00:42:06,984:INFO: 		 ADE on zara1                     dataset:	 0.6205190420150757
2022-11-03 00:42:07,734:INFO: 		 ADE on zara2                     dataset:	 0.5108761787414551
2022-11-03 00:42:07,734:INFO: Average training:	ADE  0.5652	FDE  1.1249
2022-11-03 00:42:07,742:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_403.pth.tar
2022-11-03 00:42:07,742:INFO: 
===> EPOCH: 404 (P3)
2022-11-03 00:42:07,743:INFO: - Computing loss (training)
2022-11-03 00:42:08,826:INFO: Batch:  0/31	Total Loss 4.6965 (4.6965)
2022-11-03 00:42:09,306:INFO: Batch:  1/31	Total Loss 4.6201 (4.6593)
2022-11-03 00:42:09,787:INFO: Batch:  2/31	Total Loss 4.8326 (4.7170)
2022-11-03 00:42:10,264:INFO: Batch:  3/31	Total Loss 5.2072 (4.8501)
2022-11-03 00:42:10,736:INFO: Batch:  4/31	Total Loss 4.1826 (4.7070)
2022-11-03 00:42:11,215:INFO: Batch:  5/31	Total Loss 4.5291 (4.6777)
2022-11-03 00:42:11,687:INFO: Batch:  6/31	Total Loss 5.2475 (4.7541)
2022-11-03 00:42:12,165:INFO: Batch:  7/31	Total Loss 4.7536 (4.7540)
2022-11-03 00:42:12,638:INFO: Batch:  8/31	Total Loss 4.9448 (4.7740)
2022-11-03 00:42:13,111:INFO: Batch:  9/31	Total Loss 4.6709 (4.7649)
2022-11-03 00:42:13,585:INFO: Batch: 10/31	Total Loss 4.4295 (4.7347)
2022-11-03 00:42:14,061:INFO: Batch: 11/31	Total Loss 4.9300 (4.7521)
2022-11-03 00:42:14,542:INFO: Batch: 12/31	Total Loss 4.6873 (4.7471)
2022-11-03 00:42:15,020:INFO: Batch: 13/31	Total Loss 4.0464 (4.6964)
2022-11-03 00:42:15,580:INFO: Batch: 14/31	Total Loss 4.8448 (4.7057)
2022-11-03 00:42:16,059:INFO: Batch: 15/31	Total Loss 4.8316 (4.7132)
2022-11-03 00:42:16,538:INFO: Batch: 16/31	Total Loss 4.2632 (4.6878)
2022-11-03 00:42:17,013:INFO: Batch: 17/31	Total Loss 4.8284 (4.6940)
2022-11-03 00:42:17,492:INFO: Batch: 18/31	Total Loss 5.1643 (4.7202)
2022-11-03 00:42:17,970:INFO: Batch: 19/31	Total Loss 4.7495 (4.7217)
2022-11-03 00:42:18,447:INFO: Batch: 20/31	Total Loss 4.9184 (4.7317)
2022-11-03 00:42:18,925:INFO: Batch: 21/31	Total Loss 3.8759 (4.6898)
2022-11-03 00:42:19,402:INFO: Batch: 22/31	Total Loss 4.6331 (4.6873)
2022-11-03 00:42:19,884:INFO: Batch: 23/31	Total Loss 4.7830 (4.6913)
2022-11-03 00:42:20,361:INFO: Batch: 24/31	Total Loss 4.5624 (4.6857)
2022-11-03 00:42:20,838:INFO: Batch: 25/31	Total Loss 5.1263 (4.7040)
2022-11-03 00:42:21,311:INFO: Batch: 26/31	Total Loss 4.1380 (4.6826)
2022-11-03 00:42:21,785:INFO: Batch: 27/31	Total Loss 4.3983 (4.6714)
2022-11-03 00:42:22,259:INFO: Batch: 28/31	Total Loss 4.5040 (4.6650)
2022-11-03 00:42:22,732:INFO: Batch: 29/31	Total Loss 4.2556 (4.6506)
2022-11-03 00:42:23,122:INFO: Batch: 30/31	Total Loss 1.6421 (4.6205)
2022-11-03 00:42:23,273:INFO: - Computing ADE (validation o)
2022-11-03 00:42:23,864:INFO: 		 ADE on eth                       dataset:	 1.015595555305481
2022-11-03 00:42:23,864:INFO: Average validation o:	ADE  1.0156	FDE  1.8347
2022-11-03 00:42:23,865:INFO: - Computing ADE (validation)
2022-11-03 00:42:24,145:INFO: 		 ADE on hotel                     dataset:	 0.48023098707199097
2022-11-03 00:42:24,432:INFO: 		 ADE on univ                      dataset:	 0.5674892067909241
2022-11-03 00:42:24,683:INFO: 		 ADE on zara1                     dataset:	 0.48210275173187256
2022-11-03 00:42:25,027:INFO: 		 ADE on zara2                     dataset:	 0.4364817440509796
2022-11-03 00:42:25,027:INFO: Average validation:	ADE  0.5097	FDE  1.0020
2022-11-03 00:42:25,028:INFO: - Computing ADE (training)
2022-11-03 00:42:25,474:INFO: 		 ADE on hotel                     dataset:	 0.5126397609710693
2022-11-03 00:42:26,178:INFO: 		 ADE on univ                      dataset:	 0.5540452599525452
2022-11-03 00:42:26,724:INFO: 		 ADE on zara1                     dataset:	 0.5592445731163025
2022-11-03 00:42:27,499:INFO: 		 ADE on zara2                     dataset:	 0.45566701889038086
2022-11-03 00:42:27,499:INFO: Average training:	ADE  0.5334	FDE  1.0587
2022-11-03 00:42:27,507:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_404.pth.tar
2022-11-03 00:42:27,508:INFO: 
===> EPOCH: 405 (P3)
2022-11-03 00:42:27,508:INFO: - Computing loss (training)
2022-11-03 00:42:28,612:INFO: Batch:  0/31	Total Loss 6.3700 (6.3700)
2022-11-03 00:42:29,090:INFO: Batch:  1/31	Total Loss 4.4995 (5.3370)
2022-11-03 00:42:29,562:INFO: Batch:  2/31	Total Loss 4.8186 (5.1860)
2022-11-03 00:42:30,034:INFO: Batch:  3/31	Total Loss 4.7845 (5.0855)
2022-11-03 00:42:30,511:INFO: Batch:  4/31	Total Loss 4.5102 (4.9560)
2022-11-03 00:42:30,983:INFO: Batch:  5/31	Total Loss 4.1344 (4.8085)
2022-11-03 00:42:31,450:INFO: Batch:  6/31	Total Loss 4.7667 (4.8033)
2022-11-03 00:42:31,924:INFO: Batch:  7/31	Total Loss 4.2088 (4.7211)
2022-11-03 00:42:32,405:INFO: Batch:  8/31	Total Loss 4.0811 (4.6482)
2022-11-03 00:42:32,880:INFO: Batch:  9/31	Total Loss 4.2454 (4.6028)
2022-11-03 00:42:33,356:INFO: Batch: 10/31	Total Loss 4.7195 (4.6132)
2022-11-03 00:42:33,836:INFO: Batch: 11/31	Total Loss 4.3597 (4.5916)
2022-11-03 00:42:34,323:INFO: Batch: 12/31	Total Loss 4.2866 (4.5679)
2022-11-03 00:42:34,803:INFO: Batch: 13/31	Total Loss 4.8286 (4.5877)
2022-11-03 00:42:35,283:INFO: Batch: 14/31	Total Loss 4.8253 (4.6047)
2022-11-03 00:42:35,768:INFO: Batch: 15/31	Total Loss 4.7234 (4.6119)
2022-11-03 00:42:36,267:INFO: Batch: 16/31	Total Loss 4.7735 (4.6221)
2022-11-03 00:42:36,820:INFO: Batch: 17/31	Total Loss 5.0318 (4.6430)
2022-11-03 00:42:37,342:INFO: Batch: 18/31	Total Loss 4.5423 (4.6378)
2022-11-03 00:42:37,832:INFO: Batch: 19/31	Total Loss 4.6383 (4.6378)
2022-11-03 00:42:38,401:INFO: Batch: 20/31	Total Loss 4.8153 (4.6463)
2022-11-03 00:42:38,951:INFO: Batch: 21/31	Total Loss 4.0593 (4.6177)
2022-11-03 00:42:39,495:INFO: Batch: 22/31	Total Loss 4.1809 (4.5971)
2022-11-03 00:42:39,993:INFO: Batch: 23/31	Total Loss 4.5290 (4.5944)
2022-11-03 00:42:40,515:INFO: Batch: 24/31	Total Loss 4.5793 (4.5938)
2022-11-03 00:42:41,007:INFO: Batch: 25/31	Total Loss 4.6329 (4.5953)
2022-11-03 00:42:41,492:INFO: Batch: 26/31	Total Loss 4.9734 (4.6098)
2022-11-03 00:42:41,992:INFO: Batch: 27/31	Total Loss 4.0156 (4.5883)
2022-11-03 00:42:42,520:INFO: Batch: 28/31	Total Loss 4.5065 (4.5854)
2022-11-03 00:42:43,000:INFO: Batch: 29/31	Total Loss 4.9007 (4.5951)
2022-11-03 00:42:43,424:INFO: Batch: 30/31	Total Loss 1.7958 (4.5678)
2022-11-03 00:42:43,607:INFO: - Computing ADE (validation o)
2022-11-03 00:42:44,223:INFO: 		 ADE on eth                       dataset:	 1.0358717441558838
2022-11-03 00:42:44,224:INFO: Average validation o:	ADE  1.0359	FDE  1.8463
2022-11-03 00:42:44,224:INFO: - Computing ADE (validation)
2022-11-03 00:42:44,520:INFO: 		 ADE on hotel                     dataset:	 0.4852791130542755
2022-11-03 00:42:44,869:INFO: 		 ADE on univ                      dataset:	 0.5726912617683411
2022-11-03 00:42:45,144:INFO: 		 ADE on zara1                     dataset:	 0.5051336884498596
2022-11-03 00:42:45,506:INFO: 		 ADE on zara2                     dataset:	 0.45100194215774536
2022-11-03 00:42:45,506:INFO: Average validation:	ADE  0.5193	FDE  1.0127
2022-11-03 00:42:45,507:INFO: - Computing ADE (training)
2022-11-03 00:42:45,943:INFO: 		 ADE on hotel                     dataset:	 0.5208469033241272
2022-11-03 00:42:46,697:INFO: 		 ADE on univ                      dataset:	 0.5564392805099487
2022-11-03 00:42:47,294:INFO: 		 ADE on zara1                     dataset:	 0.5947177410125732
2022-11-03 00:42:48,047:INFO: 		 ADE on zara2                     dataset:	 0.47995758056640625
2022-11-03 00:42:48,048:INFO: Average training:	ADE  0.5425	FDE  1.0683
2022-11-03 00:42:48,057:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_405.pth.tar
2022-11-03 00:42:48,057:INFO: 
===> EPOCH: 406 (P3)
2022-11-03 00:42:48,057:INFO: - Computing loss (training)
2022-11-03 00:42:49,151:INFO: Batch:  0/31	Total Loss 4.0356 (4.0356)
2022-11-03 00:42:49,670:INFO: Batch:  1/31	Total Loss 4.7567 (4.3890)
2022-11-03 00:42:50,144:INFO: Batch:  2/31	Total Loss 4.8848 (4.5609)
2022-11-03 00:42:50,654:INFO: Batch:  3/31	Total Loss 4.4653 (4.5382)
2022-11-03 00:42:51,136:INFO: Batch:  4/31	Total Loss 4.7709 (4.5841)
2022-11-03 00:42:51,680:INFO: Batch:  5/31	Total Loss 5.2623 (4.6959)
2022-11-03 00:42:52,223:INFO: Batch:  6/31	Total Loss 4.8658 (4.7206)
2022-11-03 00:42:52,766:INFO: Batch:  7/31	Total Loss 4.8313 (4.7352)
2022-11-03 00:42:53,268:INFO: Batch:  8/31	Total Loss 4.4824 (4.7073)
2022-11-03 00:42:53,755:INFO: Batch:  9/31	Total Loss 5.0402 (4.7403)
2022-11-03 00:42:54,319:INFO: Batch: 10/31	Total Loss 4.1831 (4.6953)
2022-11-03 00:42:55,093:INFO: Batch: 11/31	Total Loss 4.0584 (4.6374)
2022-11-03 00:42:55,670:INFO: Batch: 12/31	Total Loss 4.4750 (4.6260)
2022-11-03 00:42:56,166:INFO: Batch: 13/31	Total Loss 4.1642 (4.5898)
2022-11-03 00:42:56,664:INFO: Batch: 14/31	Total Loss 4.5265 (4.5857)
2022-11-03 00:42:57,145:INFO: Batch: 15/31	Total Loss 4.5072 (4.5803)
2022-11-03 00:42:57,627:INFO: Batch: 16/31	Total Loss 5.0901 (4.6103)
2022-11-03 00:42:58,104:INFO: Batch: 17/31	Total Loss 6.4225 (4.7085)
2022-11-03 00:42:58,588:INFO: Batch: 18/31	Total Loss 4.4217 (4.6934)
2022-11-03 00:42:59,066:INFO: Batch: 19/31	Total Loss 4.6703 (4.6923)
2022-11-03 00:42:59,544:INFO: Batch: 20/31	Total Loss 5.1623 (4.7152)
2022-11-03 00:43:00,026:INFO: Batch: 21/31	Total Loss 5.2374 (4.7380)
2022-11-03 00:43:00,507:INFO: Batch: 22/31	Total Loss 5.7164 (4.7767)
2022-11-03 00:43:00,983:INFO: Batch: 23/31	Total Loss 4.9361 (4.7839)
2022-11-03 00:43:01,463:INFO: Batch: 24/31	Total Loss 4.3871 (4.7674)
2022-11-03 00:43:01,945:INFO: Batch: 25/31	Total Loss 5.4191 (4.7920)
2022-11-03 00:43:02,425:INFO: Batch: 26/31	Total Loss 5.1575 (4.8074)
2022-11-03 00:43:02,905:INFO: Batch: 27/31	Total Loss 4.1022 (4.7819)
2022-11-03 00:43:03,384:INFO: Batch: 28/31	Total Loss 4.5807 (4.7750)
2022-11-03 00:43:03,863:INFO: Batch: 29/31	Total Loss 4.2974 (4.7608)
2022-11-03 00:43:04,255:INFO: Batch: 30/31	Total Loss 1.5032 (4.7315)
2022-11-03 00:43:04,406:INFO: - Computing ADE (validation o)
2022-11-03 00:43:05,014:INFO: 		 ADE on eth                       dataset:	 1.0299522876739502
2022-11-03 00:43:05,014:INFO: Average validation o:	ADE  1.0300	FDE  1.9001
2022-11-03 00:43:05,015:INFO: - Computing ADE (validation)
2022-11-03 00:43:05,272:INFO: 		 ADE on hotel                     dataset:	 0.5143010020256042
2022-11-03 00:43:05,565:INFO: 		 ADE on univ                      dataset:	 0.5836755037307739
2022-11-03 00:43:05,822:INFO: 		 ADE on zara1                     dataset:	 0.5252779722213745
2022-11-03 00:43:06,156:INFO: 		 ADE on zara2                     dataset:	 0.4788062870502472
2022-11-03 00:43:06,156:INFO: Average validation:	ADE  0.5380	FDE  1.0945
2022-11-03 00:43:06,157:INFO: - Computing ADE (training)
2022-11-03 00:43:06,599:INFO: 		 ADE on hotel                     dataset:	 0.5453699827194214
2022-11-03 00:43:07,282:INFO: 		 ADE on univ                      dataset:	 0.5786271691322327
2022-11-03 00:43:07,875:INFO: 		 ADE on zara1                     dataset:	 0.5772008895874023
2022-11-03 00:43:08,638:INFO: 		 ADE on zara2                     dataset:	 0.4930024743080139
2022-11-03 00:43:08,638:INFO: Average training:	ADE  0.5603	FDE  1.1488
2022-11-03 00:43:08,647:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_406.pth.tar
2022-11-03 00:43:08,647:INFO: 
===> EPOCH: 407 (P3)
2022-11-03 00:43:08,647:INFO: - Computing loss (training)
2022-11-03 00:43:09,761:INFO: Batch:  0/31	Total Loss 4.7383 (4.7383)
2022-11-03 00:43:10,314:INFO: Batch:  1/31	Total Loss 4.1278 (4.4288)
2022-11-03 00:43:10,784:INFO: Batch:  2/31	Total Loss 4.7708 (4.5505)
2022-11-03 00:43:11,249:INFO: Batch:  3/31	Total Loss 4.6776 (4.5841)
2022-11-03 00:43:11,715:INFO: Batch:  4/31	Total Loss 4.6844 (4.6041)
2022-11-03 00:43:12,187:INFO: Batch:  5/31	Total Loss 4.7996 (4.6380)
2022-11-03 00:43:12,655:INFO: Batch:  6/31	Total Loss 5.1174 (4.7148)
2022-11-03 00:43:13,123:INFO: Batch:  7/31	Total Loss 4.6499 (4.7067)
2022-11-03 00:43:13,594:INFO: Batch:  8/31	Total Loss 5.1838 (4.7633)
2022-11-03 00:43:14,060:INFO: Batch:  9/31	Total Loss 4.1543 (4.6976)
2022-11-03 00:43:14,531:INFO: Batch: 10/31	Total Loss 4.9489 (4.7196)
2022-11-03 00:43:15,001:INFO: Batch: 11/31	Total Loss 4.9946 (4.7439)
2022-11-03 00:43:15,475:INFO: Batch: 12/31	Total Loss 5.3526 (4.7893)
2022-11-03 00:43:15,948:INFO: Batch: 13/31	Total Loss 3.9895 (4.7382)
2022-11-03 00:43:16,420:INFO: Batch: 14/31	Total Loss 4.7413 (4.7384)
2022-11-03 00:43:16,891:INFO: Batch: 15/31	Total Loss 4.6188 (4.7308)
2022-11-03 00:43:17,362:INFO: Batch: 16/31	Total Loss 5.1620 (4.7540)
2022-11-03 00:43:17,834:INFO: Batch: 17/31	Total Loss 4.0968 (4.7136)
2022-11-03 00:43:18,303:INFO: Batch: 18/31	Total Loss 5.2868 (4.7420)
2022-11-03 00:43:18,774:INFO: Batch: 19/31	Total Loss 4.7625 (4.7430)
2022-11-03 00:43:19,245:INFO: Batch: 20/31	Total Loss 4.9136 (4.7519)
2022-11-03 00:43:19,715:INFO: Batch: 21/31	Total Loss 4.7445 (4.7516)
2022-11-03 00:43:20,190:INFO: Batch: 22/31	Total Loss 4.5766 (4.7440)
2022-11-03 00:43:20,659:INFO: Batch: 23/31	Total Loss 3.9259 (4.7075)
2022-11-03 00:43:21,131:INFO: Batch: 24/31	Total Loss 3.7835 (4.6698)
2022-11-03 00:43:21,603:INFO: Batch: 25/31	Total Loss 4.7994 (4.6743)
2022-11-03 00:43:22,076:INFO: Batch: 26/31	Total Loss 4.8577 (4.6799)
2022-11-03 00:43:22,548:INFO: Batch: 27/31	Total Loss 5.5725 (4.7114)
2022-11-03 00:43:23,022:INFO: Batch: 28/31	Total Loss 4.3520 (4.6989)
2022-11-03 00:43:23,494:INFO: Batch: 29/31	Total Loss 4.3545 (4.6872)
2022-11-03 00:43:23,882:INFO: Batch: 30/31	Total Loss 1.7135 (4.6636)
2022-11-03 00:43:24,027:INFO: - Computing ADE (validation o)
2022-11-03 00:43:24,604:INFO: 		 ADE on eth                       dataset:	 1.0487596988677979
2022-11-03 00:43:24,604:INFO: Average validation o:	ADE  1.0488	FDE  1.9005
2022-11-03 00:43:24,605:INFO: - Computing ADE (validation)
2022-11-03 00:43:24,876:INFO: 		 ADE on hotel                     dataset:	 0.49398428201675415
2022-11-03 00:43:25,166:INFO: 		 ADE on univ                      dataset:	 0.5737008452415466
2022-11-03 00:43:25,419:INFO: 		 ADE on zara1                     dataset:	 0.5143287181854248
2022-11-03 00:43:25,774:INFO: 		 ADE on zara2                     dataset:	 0.4647265374660492
2022-11-03 00:43:25,775:INFO: Average validation:	ADE  0.5259	FDE  1.0445
2022-11-03 00:43:25,775:INFO: - Computing ADE (training)
2022-11-03 00:43:26,231:INFO: 		 ADE on hotel                     dataset:	 0.5300439596176147
2022-11-03 00:43:26,891:INFO: 		 ADE on univ                      dataset:	 0.5654773712158203
2022-11-03 00:43:27,419:INFO: 		 ADE on zara1                     dataset:	 0.5952028036117554
2022-11-03 00:43:28,156:INFO: 		 ADE on zara2                     dataset:	 0.48829105496406555
2022-11-03 00:43:28,156:INFO: Average training:	ADE  0.5508	FDE  1.1033
2022-11-03 00:43:28,165:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_407.pth.tar
2022-11-03 00:43:28,165:INFO: 
===> EPOCH: 408 (P3)
2022-11-03 00:43:28,165:INFO: - Computing loss (training)
2022-11-03 00:43:29,277:INFO: Batch:  0/31	Total Loss 4.5896 (4.5896)
2022-11-03 00:43:29,755:INFO: Batch:  1/31	Total Loss 5.2911 (4.9274)
2022-11-03 00:43:30,242:INFO: Batch:  2/31	Total Loss 5.2520 (5.0396)
2022-11-03 00:43:30,720:INFO: Batch:  3/31	Total Loss 3.8833 (4.7381)
2022-11-03 00:43:31,197:INFO: Batch:  4/31	Total Loss 4.9324 (4.7714)
2022-11-03 00:43:31,674:INFO: Batch:  5/31	Total Loss 4.9706 (4.8043)
2022-11-03 00:43:32,149:INFO: Batch:  6/31	Total Loss 4.3308 (4.7327)
2022-11-03 00:43:32,622:INFO: Batch:  7/31	Total Loss 4.7296 (4.7323)
2022-11-03 00:43:33,096:INFO: Batch:  8/31	Total Loss 4.9353 (4.7554)
2022-11-03 00:43:33,573:INFO: Batch:  9/31	Total Loss 4.5130 (4.7301)
2022-11-03 00:43:34,046:INFO: Batch: 10/31	Total Loss 5.0958 (4.7611)
2022-11-03 00:43:34,519:INFO: Batch: 11/31	Total Loss 4.6063 (4.7475)
2022-11-03 00:43:34,997:INFO: Batch: 12/31	Total Loss 4.7724 (4.7494)
2022-11-03 00:43:35,473:INFO: Batch: 13/31	Total Loss 5.0547 (4.7707)
2022-11-03 00:43:35,951:INFO: Batch: 14/31	Total Loss 4.7130 (4.7666)
2022-11-03 00:43:36,427:INFO: Batch: 15/31	Total Loss 4.4973 (4.7499)
2022-11-03 00:43:36,903:INFO: Batch: 16/31	Total Loss 4.3488 (4.7282)
2022-11-03 00:43:37,379:INFO: Batch: 17/31	Total Loss 3.9171 (4.6819)
2022-11-03 00:43:37,857:INFO: Batch: 18/31	Total Loss 4.3525 (4.6648)
2022-11-03 00:43:38,332:INFO: Batch: 19/31	Total Loss 4.1682 (4.6443)
2022-11-03 00:43:38,807:INFO: Batch: 20/31	Total Loss 4.7310 (4.6482)
2022-11-03 00:43:39,282:INFO: Batch: 21/31	Total Loss 4.3151 (4.6324)
2022-11-03 00:43:39,757:INFO: Batch: 22/31	Total Loss 4.3668 (4.6211)
2022-11-03 00:43:40,233:INFO: Batch: 23/31	Total Loss 5.0900 (4.6407)
2022-11-03 00:43:40,707:INFO: Batch: 24/31	Total Loss 4.6855 (4.6426)
2022-11-03 00:43:41,182:INFO: Batch: 25/31	Total Loss 4.0139 (4.6184)
2022-11-03 00:43:41,653:INFO: Batch: 26/31	Total Loss 4.3543 (4.6076)
2022-11-03 00:43:42,127:INFO: Batch: 27/31	Total Loss 4.8937 (4.6188)
2022-11-03 00:43:42,600:INFO: Batch: 28/31	Total Loss 5.3534 (4.6442)
2022-11-03 00:43:43,072:INFO: Batch: 29/31	Total Loss 4.6714 (4.6451)
2022-11-03 00:43:43,459:INFO: Batch: 30/31	Total Loss 1.8391 (4.6148)
2022-11-03 00:43:43,613:INFO: - Computing ADE (validation o)
2022-11-03 00:43:44,175:INFO: 		 ADE on eth                       dataset:	 1.0229451656341553
2022-11-03 00:43:44,175:INFO: Average validation o:	ADE  1.0229	FDE  1.8521
2022-11-03 00:43:44,176:INFO: - Computing ADE (validation)
2022-11-03 00:43:44,486:INFO: 		 ADE on hotel                     dataset:	 0.48034870624542236
2022-11-03 00:43:44,785:INFO: 		 ADE on univ                      dataset:	 0.5798308253288269
2022-11-03 00:43:45,039:INFO: 		 ADE on zara1                     dataset:	 0.5115044116973877
2022-11-03 00:43:45,382:INFO: 		 ADE on zara2                     dataset:	 0.4442107379436493
2022-11-03 00:43:45,382:INFO: Average validation:	ADE  0.5207	FDE  1.0428
2022-11-03 00:43:45,383:INFO: - Computing ADE (training)
2022-11-03 00:43:45,826:INFO: 		 ADE on hotel                     dataset:	 0.5227673053741455
2022-11-03 00:43:46,554:INFO: 		 ADE on univ                      dataset:	 0.5594825744628906
2022-11-03 00:43:47,097:INFO: 		 ADE on zara1                     dataset:	 0.5714500546455383
2022-11-03 00:43:47,839:INFO: 		 ADE on zara2                     dataset:	 0.4663783013820648
2022-11-03 00:43:47,839:INFO: Average training:	ADE  0.5404	FDE  1.0878
2022-11-03 00:43:47,847:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_408.pth.tar
2022-11-03 00:43:47,847:INFO: 
===> EPOCH: 409 (P3)
2022-11-03 00:43:47,848:INFO: - Computing loss (training)
2022-11-03 00:43:48,933:INFO: Batch:  0/31	Total Loss 4.5499 (4.5499)
2022-11-03 00:43:49,414:INFO: Batch:  1/31	Total Loss 4.9533 (4.7565)
2022-11-03 00:43:49,895:INFO: Batch:  2/31	Total Loss 4.4818 (4.6660)
2022-11-03 00:43:50,370:INFO: Batch:  3/31	Total Loss 4.9043 (4.7243)
2022-11-03 00:43:50,844:INFO: Batch:  4/31	Total Loss 4.9372 (4.7654)
2022-11-03 00:43:51,318:INFO: Batch:  5/31	Total Loss 4.7500 (4.7629)
2022-11-03 00:43:51,791:INFO: Batch:  6/31	Total Loss 4.6305 (4.7427)
2022-11-03 00:43:52,262:INFO: Batch:  7/31	Total Loss 4.4374 (4.7042)
2022-11-03 00:43:52,737:INFO: Batch:  8/31	Total Loss 5.3871 (4.7707)
2022-11-03 00:43:53,207:INFO: Batch:  9/31	Total Loss 4.5279 (4.7439)
2022-11-03 00:43:53,678:INFO: Batch: 10/31	Total Loss 4.4632 (4.7164)
2022-11-03 00:43:54,153:INFO: Batch: 11/31	Total Loss 5.1549 (4.7549)
2022-11-03 00:43:54,630:INFO: Batch: 12/31	Total Loss 4.2366 (4.7208)
2022-11-03 00:43:55,106:INFO: Batch: 13/31	Total Loss 5.2241 (4.7582)
2022-11-03 00:43:55,584:INFO: Batch: 14/31	Total Loss 4.2156 (4.7236)
2022-11-03 00:43:56,061:INFO: Batch: 15/31	Total Loss 5.2650 (4.7569)
2022-11-03 00:43:56,537:INFO: Batch: 16/31	Total Loss 4.1530 (4.7189)
2022-11-03 00:43:57,014:INFO: Batch: 17/31	Total Loss 4.5415 (4.7093)
2022-11-03 00:43:57,489:INFO: Batch: 18/31	Total Loss 4.5772 (4.7023)
2022-11-03 00:43:57,964:INFO: Batch: 19/31	Total Loss 4.4656 (4.6909)
2022-11-03 00:43:58,438:INFO: Batch: 20/31	Total Loss 3.9625 (4.6591)
2022-11-03 00:43:58,989:INFO: Batch: 21/31	Total Loss 4.4128 (4.6467)
2022-11-03 00:43:59,462:INFO: Batch: 22/31	Total Loss 4.6107 (4.6452)
2022-11-03 00:43:59,940:INFO: Batch: 23/31	Total Loss 4.2676 (4.6277)
2022-11-03 00:44:00,417:INFO: Batch: 24/31	Total Loss 4.4019 (4.6194)
2022-11-03 00:44:00,891:INFO: Batch: 25/31	Total Loss 4.7311 (4.6240)
2022-11-03 00:44:01,365:INFO: Batch: 26/31	Total Loss 5.0135 (4.6370)
2022-11-03 00:44:01,839:INFO: Batch: 27/31	Total Loss 5.0507 (4.6494)
2022-11-03 00:44:02,312:INFO: Batch: 28/31	Total Loss 4.8820 (4.6580)
2022-11-03 00:44:02,798:INFO: Batch: 29/31	Total Loss 4.9331 (4.6673)
2022-11-03 00:44:03,205:INFO: Batch: 30/31	Total Loss 1.8518 (4.6407)
2022-11-03 00:44:03,361:INFO: - Computing ADE (validation o)
2022-11-03 00:44:03,959:INFO: 		 ADE on eth                       dataset:	 1.0444018840789795
2022-11-03 00:44:03,960:INFO: Average validation o:	ADE  1.0444	FDE  1.8581
2022-11-03 00:44:03,960:INFO: - Computing ADE (validation)
2022-11-03 00:44:04,238:INFO: 		 ADE on hotel                     dataset:	 0.5715112090110779
2022-11-03 00:44:04,530:INFO: 		 ADE on univ                      dataset:	 0.6181930899620056
2022-11-03 00:44:04,788:INFO: 		 ADE on zara1                     dataset:	 0.4882582426071167
2022-11-03 00:44:05,154:INFO: 		 ADE on zara2                     dataset:	 0.5036128759384155
2022-11-03 00:44:05,155:INFO: Average validation:	ADE  0.5661	FDE  1.1628
2022-11-03 00:44:05,155:INFO: - Computing ADE (training)
2022-11-03 00:44:05,663:INFO: 		 ADE on hotel                     dataset:	 0.6104589104652405
2022-11-03 00:44:06,399:INFO: 		 ADE on univ                      dataset:	 0.5954169034957886
2022-11-03 00:44:07,037:INFO: 		 ADE on zara1                     dataset:	 0.5974025130271912
2022-11-03 00:44:07,821:INFO: 		 ADE on zara2                     dataset:	 0.5215277075767517
2022-11-03 00:44:07,821:INFO: Average training:	ADE  0.5809	FDE  1.1907
2022-11-03 00:44:07,831:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_409.pth.tar
2022-11-03 00:44:07,832:INFO: 
===> EPOCH: 410 (P3)
2022-11-03 00:44:07,832:INFO: - Computing loss (training)
2022-11-03 00:44:09,042:INFO: Batch:  0/31	Total Loss 4.5507 (4.5507)
2022-11-03 00:44:09,535:INFO: Batch:  1/31	Total Loss 5.0190 (4.7969)
2022-11-03 00:44:10,058:INFO: Batch:  2/31	Total Loss 4.3918 (4.6672)
2022-11-03 00:44:10,638:INFO: Batch:  3/31	Total Loss 4.5085 (4.6286)
2022-11-03 00:44:11,169:INFO: Batch:  4/31	Total Loss 4.7459 (4.6503)
2022-11-03 00:44:11,711:INFO: Batch:  5/31	Total Loss 4.8490 (4.6797)
2022-11-03 00:44:12,231:INFO: Batch:  6/31	Total Loss 4.1208 (4.5960)
2022-11-03 00:44:12,781:INFO: Batch:  7/31	Total Loss 4.4386 (4.5766)
2022-11-03 00:44:13,315:INFO: Batch:  8/31	Total Loss 4.7140 (4.5922)
2022-11-03 00:44:13,805:INFO: Batch:  9/31	Total Loss 5.3007 (4.6546)
2022-11-03 00:44:14,298:INFO: Batch: 10/31	Total Loss 5.5144 (4.7309)
2022-11-03 00:44:14,836:INFO: Batch: 11/31	Total Loss 5.2178 (4.7700)
2022-11-03 00:44:15,352:INFO: Batch: 12/31	Total Loss 4.7242 (4.7662)
2022-11-03 00:44:15,848:INFO: Batch: 13/31	Total Loss 3.6793 (4.6866)
2022-11-03 00:44:16,363:INFO: Batch: 14/31	Total Loss 4.3554 (4.6651)
2022-11-03 00:44:16,874:INFO: Batch: 15/31	Total Loss 4.7854 (4.6733)
2022-11-03 00:44:17,441:INFO: Batch: 16/31	Total Loss 4.6551 (4.6723)
2022-11-03 00:44:18,185:INFO: Batch: 17/31	Total Loss 4.3955 (4.6581)
2022-11-03 00:44:18,680:INFO: Batch: 18/31	Total Loss 4.5925 (4.6545)
2022-11-03 00:44:19,164:INFO: Batch: 19/31	Total Loss 4.1355 (4.6262)
2022-11-03 00:44:19,636:INFO: Batch: 20/31	Total Loss 4.7796 (4.6334)
2022-11-03 00:44:20,110:INFO: Batch: 21/31	Total Loss 4.5117 (4.6279)
2022-11-03 00:44:20,585:INFO: Batch: 22/31	Total Loss 4.3780 (4.6159)
2022-11-03 00:44:21,058:INFO: Batch: 23/31	Total Loss 4.9823 (4.6318)
2022-11-03 00:44:21,531:INFO: Batch: 24/31	Total Loss 4.6557 (4.6326)
2022-11-03 00:44:22,007:INFO: Batch: 25/31	Total Loss 4.1743 (4.6142)
2022-11-03 00:44:22,476:INFO: Batch: 26/31	Total Loss 4.4215 (4.6071)
2022-11-03 00:44:22,945:INFO: Batch: 27/31	Total Loss 5.1067 (4.6262)
2022-11-03 00:44:23,420:INFO: Batch: 28/31	Total Loss 4.0004 (4.6037)
2022-11-03 00:44:23,892:INFO: Batch: 29/31	Total Loss 4.7383 (4.6080)
2022-11-03 00:44:24,279:INFO: Batch: 30/31	Total Loss 1.7435 (4.5773)
2022-11-03 00:44:24,440:INFO: - Computing ADE (validation o)
2022-11-03 00:44:25,031:INFO: 		 ADE on eth                       dataset:	 1.0006825923919678
2022-11-03 00:44:25,031:INFO: Average validation o:	ADE  1.0007	FDE  1.8101
2022-11-03 00:44:25,032:INFO: - Computing ADE (validation)
2022-11-03 00:44:25,295:INFO: 		 ADE on hotel                     dataset:	 0.48111000657081604
2022-11-03 00:44:25,591:INFO: 		 ADE on univ                      dataset:	 0.5699005722999573
2022-11-03 00:44:25,843:INFO: 		 ADE on zara1                     dataset:	 0.5088898539543152
2022-11-03 00:44:26,195:INFO: 		 ADE on zara2                     dataset:	 0.4379747807979584
2022-11-03 00:44:26,195:INFO: Average validation:	ADE  0.5131	FDE  1.0276
2022-11-03 00:44:26,196:INFO: - Computing ADE (training)
2022-11-03 00:44:26,647:INFO: 		 ADE on hotel                     dataset:	 0.5137710571289062
2022-11-03 00:44:27,341:INFO: 		 ADE on univ                      dataset:	 0.5549156665802002
2022-11-03 00:44:27,892:INFO: 		 ADE on zara1                     dataset:	 0.5604444742202759
2022-11-03 00:44:28,682:INFO: 		 ADE on zara2                     dataset:	 0.4575417637825012
2022-11-03 00:44:28,682:INFO: Average training:	ADE  0.5345	FDE  1.0773
2022-11-03 00:44:28,692:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_410.pth.tar
2022-11-03 00:44:28,692:INFO: 
===> EPOCH: 411 (P3)
2022-11-03 00:44:28,692:INFO: - Computing loss (training)
2022-11-03 00:44:29,788:INFO: Batch:  0/31	Total Loss 4.4550 (4.4550)
2022-11-03 00:44:30,267:INFO: Batch:  1/31	Total Loss 4.5864 (4.5209)
2022-11-03 00:44:30,749:INFO: Batch:  2/31	Total Loss 4.5925 (4.5418)
2022-11-03 00:44:31,211:INFO: Batch:  3/31	Total Loss 4.1953 (4.4603)
2022-11-03 00:44:31,678:INFO: Batch:  4/31	Total Loss 4.7297 (4.5141)
2022-11-03 00:44:32,151:INFO: Batch:  5/31	Total Loss 4.8704 (4.5712)
2022-11-03 00:44:32,616:INFO: Batch:  6/31	Total Loss 4.2193 (4.5179)
2022-11-03 00:44:33,081:INFO: Batch:  7/31	Total Loss 4.6661 (4.5390)
2022-11-03 00:44:33,545:INFO: Batch:  8/31	Total Loss 4.8787 (4.5721)
2022-11-03 00:44:34,010:INFO: Batch:  9/31	Total Loss 4.4938 (4.5644)
2022-11-03 00:44:34,485:INFO: Batch: 10/31	Total Loss 4.1076 (4.5217)
2022-11-03 00:44:34,953:INFO: Batch: 11/31	Total Loss 4.6174 (4.5296)
2022-11-03 00:44:35,421:INFO: Batch: 12/31	Total Loss 4.3774 (4.5188)
2022-11-03 00:44:35,889:INFO: Batch: 13/31	Total Loss 4.9633 (4.5507)
2022-11-03 00:44:36,357:INFO: Batch: 14/31	Total Loss 4.3684 (4.5392)
2022-11-03 00:44:36,831:INFO: Batch: 15/31	Total Loss 4.7239 (4.5512)
2022-11-03 00:44:37,298:INFO: Batch: 16/31	Total Loss 4.4267 (4.5445)
2022-11-03 00:44:37,766:INFO: Batch: 17/31	Total Loss 4.7621 (4.5557)
2022-11-03 00:44:38,235:INFO: Batch: 18/31	Total Loss 4.4413 (4.5496)
2022-11-03 00:44:38,702:INFO: Batch: 19/31	Total Loss 4.4625 (4.5452)
2022-11-03 00:44:39,168:INFO: Batch: 20/31	Total Loss 4.3177 (4.5354)
2022-11-03 00:44:39,635:INFO: Batch: 21/31	Total Loss 5.1622 (4.5652)
2022-11-03 00:44:40,105:INFO: Batch: 22/31	Total Loss 4.7847 (4.5755)
2022-11-03 00:44:40,573:INFO: Batch: 23/31	Total Loss 4.3175 (4.5639)
2022-11-03 00:44:41,041:INFO: Batch: 24/31	Total Loss 4.6783 (4.5685)
2022-11-03 00:44:41,510:INFO: Batch: 25/31	Total Loss 4.4866 (4.5655)
2022-11-03 00:44:41,979:INFO: Batch: 26/31	Total Loss 4.5778 (4.5659)
2022-11-03 00:44:42,448:INFO: Batch: 27/31	Total Loss 4.4814 (4.5630)
2022-11-03 00:44:42,920:INFO: Batch: 28/31	Total Loss 4.3261 (4.5541)
2022-11-03 00:44:43,388:INFO: Batch: 29/31	Total Loss 4.1758 (4.5427)
2022-11-03 00:44:43,773:INFO: Batch: 30/31	Total Loss 1.8715 (4.5169)
2022-11-03 00:44:43,925:INFO: - Computing ADE (validation o)
2022-11-03 00:44:44,492:INFO: 		 ADE on eth                       dataset:	 1.0271320343017578
2022-11-03 00:44:44,493:INFO: Average validation o:	ADE  1.0271	FDE  1.8407
2022-11-03 00:44:44,493:INFO: - Computing ADE (validation)
2022-11-03 00:44:44,752:INFO: 		 ADE on hotel                     dataset:	 0.5260196924209595
2022-11-03 00:44:45,043:INFO: 		 ADE on univ                      dataset:	 0.5915219187736511
2022-11-03 00:44:45,291:INFO: 		 ADE on zara1                     dataset:	 0.482012540102005
2022-11-03 00:44:45,630:INFO: 		 ADE on zara2                     dataset:	 0.46773257851600647
2022-11-03 00:44:45,630:INFO: Average validation:	ADE  0.5362	FDE  1.0794
2022-11-03 00:44:45,631:INFO: - Computing ADE (training)
2022-11-03 00:44:46,108:INFO: 		 ADE on hotel                     dataset:	 0.5635237097740173
2022-11-03 00:44:46,800:INFO: 		 ADE on univ                      dataset:	 0.5714054703712463
2022-11-03 00:44:47,350:INFO: 		 ADE on zara1                     dataset:	 0.5737545490264893
2022-11-03 00:44:48,096:INFO: 		 ADE on zara2                     dataset:	 0.4890371561050415
2022-11-03 00:44:48,096:INFO: Average training:	ADE  0.5546	FDE  1.1206
2022-11-03 00:44:48,104:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_411.pth.tar
2022-11-03 00:44:48,104:INFO: 
===> EPOCH: 412 (P3)
2022-11-03 00:44:48,105:INFO: - Computing loss (training)
2022-11-03 00:44:49,191:INFO: Batch:  0/31	Total Loss 5.6198 (5.6198)
2022-11-03 00:44:49,656:INFO: Batch:  1/31	Total Loss 4.6107 (5.0955)
2022-11-03 00:44:50,135:INFO: Batch:  2/31	Total Loss 4.5390 (4.8975)
2022-11-03 00:44:50,596:INFO: Batch:  3/31	Total Loss 4.0053 (4.6691)
2022-11-03 00:44:51,061:INFO: Batch:  4/31	Total Loss 4.9065 (4.7170)
2022-11-03 00:44:51,601:INFO: Batch:  5/31	Total Loss 4.3699 (4.6575)
2022-11-03 00:44:52,064:INFO: Batch:  6/31	Total Loss 4.3398 (4.6119)
2022-11-03 00:44:52,529:INFO: Batch:  7/31	Total Loss 5.0308 (4.6608)
2022-11-03 00:44:52,992:INFO: Batch:  8/31	Total Loss 4.4066 (4.6329)
2022-11-03 00:44:53,454:INFO: Batch:  9/31	Total Loss 5.1096 (4.6790)
2022-11-03 00:44:53,920:INFO: Batch: 10/31	Total Loss 4.6655 (4.6778)
2022-11-03 00:44:54,385:INFO: Batch: 11/31	Total Loss 4.6241 (4.6736)
2022-11-03 00:44:54,858:INFO: Batch: 12/31	Total Loss 4.0358 (4.6167)
2022-11-03 00:44:55,327:INFO: Batch: 13/31	Total Loss 4.4943 (4.6078)
2022-11-03 00:44:55,796:INFO: Batch: 14/31	Total Loss 4.7724 (4.6192)
2022-11-03 00:44:56,264:INFO: Batch: 15/31	Total Loss 5.4560 (4.6681)
2022-11-03 00:44:56,734:INFO: Batch: 16/31	Total Loss 4.3542 (4.6506)
2022-11-03 00:44:57,203:INFO: Batch: 17/31	Total Loss 4.4223 (4.6374)
2022-11-03 00:44:57,671:INFO: Batch: 18/31	Total Loss 3.9874 (4.6008)
2022-11-03 00:44:58,139:INFO: Batch: 19/31	Total Loss 4.4686 (4.5943)
2022-11-03 00:44:58,609:INFO: Batch: 20/31	Total Loss 4.8973 (4.6093)
2022-11-03 00:44:59,075:INFO: Batch: 21/31	Total Loss 4.9804 (4.6268)
2022-11-03 00:44:59,543:INFO: Batch: 22/31	Total Loss 4.1896 (4.6055)
2022-11-03 00:45:00,014:INFO: Batch: 23/31	Total Loss 4.1103 (4.5846)
2022-11-03 00:45:00,497:INFO: Batch: 24/31	Total Loss 4.4831 (4.5804)
2022-11-03 00:45:00,982:INFO: Batch: 25/31	Total Loss 4.7194 (4.5854)
2022-11-03 00:45:01,467:INFO: Batch: 26/31	Total Loss 4.4270 (4.5794)
2022-11-03 00:45:01,943:INFO: Batch: 27/31	Total Loss 4.4263 (4.5732)
2022-11-03 00:45:02,409:INFO: Batch: 28/31	Total Loss 4.6462 (4.5757)
2022-11-03 00:45:02,885:INFO: Batch: 29/31	Total Loss 4.3895 (4.5697)
2022-11-03 00:45:03,269:INFO: Batch: 30/31	Total Loss 1.8572 (4.5423)
2022-11-03 00:45:03,432:INFO: - Computing ADE (validation o)
2022-11-03 00:45:04,055:INFO: 		 ADE on eth                       dataset:	 1.000817894935608
2022-11-03 00:45:04,055:INFO: Average validation o:	ADE  1.0008	FDE  1.7999
2022-11-03 00:45:04,065:INFO: - Computing ADE (validation)
2022-11-03 00:45:04,330:INFO: 		 ADE on hotel                     dataset:	 0.48476478457450867
2022-11-03 00:45:04,624:INFO: 		 ADE on univ                      dataset:	 0.5751132369041443
2022-11-03 00:45:04,895:INFO: 		 ADE on zara1                     dataset:	 0.48466286063194275
2022-11-03 00:45:05,269:INFO: 		 ADE on zara2                     dataset:	 0.4333922863006592
2022-11-03 00:45:05,270:INFO: Average validation:	ADE  0.5129	FDE  1.0279
2022-11-03 00:45:05,271:INFO: - Computing ADE (training)
2022-11-03 00:45:05,846:INFO: 		 ADE on hotel                     dataset:	 0.5278865694999695
2022-11-03 00:45:06,600:INFO: 		 ADE on univ                      dataset:	 0.5544946193695068
2022-11-03 00:45:07,183:INFO: 		 ADE on zara1                     dataset:	 0.5499619841575623
2022-11-03 00:45:08,015:INFO: 		 ADE on zara2                     dataset:	 0.45181357860565186
2022-11-03 00:45:08,015:INFO: Average training:	ADE  0.5327	FDE  1.0722
2022-11-03 00:45:08,025:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_412.pth.tar
2022-11-03 00:45:08,025:INFO: 
===> EPOCH: 413 (P3)
2022-11-03 00:45:08,026:INFO: - Computing loss (training)
2022-11-03 00:45:09,135:INFO: Batch:  0/31	Total Loss 4.0713 (4.0713)
2022-11-03 00:45:09,649:INFO: Batch:  1/31	Total Loss 4.5585 (4.3155)
2022-11-03 00:45:10,170:INFO: Batch:  2/31	Total Loss 4.1649 (4.2632)
2022-11-03 00:45:10,691:INFO: Batch:  3/31	Total Loss 4.1300 (4.2287)
2022-11-03 00:45:11,208:INFO: Batch:  4/31	Total Loss 4.8547 (4.3406)
2022-11-03 00:45:11,710:INFO: Batch:  5/31	Total Loss 5.7725 (4.5918)
2022-11-03 00:45:12,198:INFO: Batch:  6/31	Total Loss 4.1725 (4.5271)
2022-11-03 00:45:12,714:INFO: Batch:  7/31	Total Loss 4.7892 (4.5582)
2022-11-03 00:45:13,203:INFO: Batch:  8/31	Total Loss 4.6028 (4.5633)
2022-11-03 00:45:13,692:INFO: Batch:  9/31	Total Loss 4.6410 (4.5716)
2022-11-03 00:45:14,203:INFO: Batch: 10/31	Total Loss 5.1080 (4.6168)
2022-11-03 00:45:14,726:INFO: Batch: 11/31	Total Loss 4.1615 (4.5795)
2022-11-03 00:45:15,260:INFO: Batch: 12/31	Total Loss 4.9802 (4.6071)
2022-11-03 00:45:15,800:INFO: Batch: 13/31	Total Loss 4.7411 (4.6171)
2022-11-03 00:45:16,335:INFO: Batch: 14/31	Total Loss 4.7955 (4.6291)
2022-11-03 00:45:16,851:INFO: Batch: 15/31	Total Loss 4.5434 (4.6239)
2022-11-03 00:45:17,422:INFO: Batch: 16/31	Total Loss 4.9012 (4.6404)
2022-11-03 00:45:17,971:INFO: Batch: 17/31	Total Loss 4.2142 (4.6169)
2022-11-03 00:45:18,480:INFO: Batch: 18/31	Total Loss 4.2472 (4.6001)
2022-11-03 00:45:19,032:INFO: Batch: 19/31	Total Loss 4.8088 (4.6115)
2022-11-03 00:45:19,585:INFO: Batch: 20/31	Total Loss 4.0768 (4.5850)
2022-11-03 00:45:20,098:INFO: Batch: 21/31	Total Loss 5.3788 (4.6183)
2022-11-03 00:45:20,584:INFO: Batch: 22/31	Total Loss 3.9953 (4.5912)
2022-11-03 00:45:21,054:INFO: Batch: 23/31	Total Loss 4.4455 (4.5850)
2022-11-03 00:45:21,534:INFO: Batch: 24/31	Total Loss 4.4320 (4.5784)
2022-11-03 00:45:22,012:INFO: Batch: 25/31	Total Loss 4.7162 (4.5832)
2022-11-03 00:45:22,520:INFO: Batch: 26/31	Total Loss 4.7058 (4.5875)
2022-11-03 00:45:23,015:INFO: Batch: 27/31	Total Loss 4.6786 (4.5907)
2022-11-03 00:45:23,513:INFO: Batch: 28/31	Total Loss 4.9811 (4.6038)
2022-11-03 00:45:24,001:INFO: Batch: 29/31	Total Loss 4.3128 (4.5946)
2022-11-03 00:45:24,405:INFO: Batch: 30/31	Total Loss 1.5671 (4.5647)
2022-11-03 00:45:24,566:INFO: - Computing ADE (validation o)
2022-11-03 00:45:25,206:INFO: 		 ADE on eth                       dataset:	 0.9995529055595398
2022-11-03 00:45:25,206:INFO: Average validation o:	ADE  0.9996	FDE  1.8135
2022-11-03 00:45:25,207:INFO: - Computing ADE (validation)
2022-11-03 00:45:25,556:INFO: 		 ADE on hotel                     dataset:	 0.49617889523506165
2022-11-03 00:45:25,990:INFO: 		 ADE on univ                      dataset:	 0.5698447823524475
2022-11-03 00:45:26,308:INFO: 		 ADE on zara1                     dataset:	 0.4660817086696625
2022-11-03 00:45:26,684:INFO: 		 ADE on zara2                     dataset:	 0.4336283206939697
2022-11-03 00:45:26,685:INFO: Average validation:	ADE  0.5098	FDE  1.0086
2022-11-03 00:45:26,685:INFO: - Computing ADE (training)
2022-11-03 00:45:27,138:INFO: 		 ADE on hotel                     dataset:	 0.5317853093147278
2022-11-03 00:45:27,838:INFO: 		 ADE on univ                      dataset:	 0.5546039342880249
2022-11-03 00:45:28,367:INFO: 		 ADE on zara1                     dataset:	 0.5485941767692566
2022-11-03 00:45:29,114:INFO: 		 ADE on zara2                     dataset:	 0.4526732563972473
2022-11-03 00:45:29,115:INFO: Average training:	ADE  0.5330	FDE  1.0617
2022-11-03 00:45:29,123:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_413.pth.tar
2022-11-03 00:45:29,124:INFO: 
===> EPOCH: 414 (P3)
2022-11-03 00:45:29,124:INFO: - Computing loss (training)
2022-11-03 00:45:30,215:INFO: Batch:  0/31	Total Loss 4.6272 (4.6272)
2022-11-03 00:45:30,708:INFO: Batch:  1/31	Total Loss 4.7187 (4.6741)
2022-11-03 00:45:31,194:INFO: Batch:  2/31	Total Loss 4.2403 (4.5370)
2022-11-03 00:45:31,662:INFO: Batch:  3/31	Total Loss 4.4666 (4.5188)
2022-11-03 00:45:32,133:INFO: Batch:  4/31	Total Loss 5.2169 (4.6513)
2022-11-03 00:45:32,604:INFO: Batch:  5/31	Total Loss 4.8130 (4.6803)
2022-11-03 00:45:33,071:INFO: Batch:  6/31	Total Loss 4.6833 (4.6808)
2022-11-03 00:45:33,534:INFO: Batch:  7/31	Total Loss 4.7202 (4.6855)
2022-11-03 00:45:34,003:INFO: Batch:  8/31	Total Loss 4.4814 (4.6621)
2022-11-03 00:45:34,477:INFO: Batch:  9/31	Total Loss 4.4793 (4.6415)
2022-11-03 00:45:34,960:INFO: Batch: 10/31	Total Loss 4.5314 (4.6306)
2022-11-03 00:45:35,427:INFO: Batch: 11/31	Total Loss 4.8110 (4.6468)
2022-11-03 00:45:35,897:INFO: Batch: 12/31	Total Loss 4.4905 (4.6344)
2022-11-03 00:45:36,366:INFO: Batch: 13/31	Total Loss 4.3713 (4.6153)
2022-11-03 00:45:36,837:INFO: Batch: 14/31	Total Loss 4.5376 (4.6095)
2022-11-03 00:45:37,305:INFO: Batch: 15/31	Total Loss 4.3538 (4.5929)
2022-11-03 00:45:37,776:INFO: Batch: 16/31	Total Loss 4.3431 (4.5776)
2022-11-03 00:45:38,246:INFO: Batch: 17/31	Total Loss 4.0376 (4.5442)
2022-11-03 00:45:38,723:INFO: Batch: 18/31	Total Loss 4.2945 (4.5304)
2022-11-03 00:45:39,192:INFO: Batch: 19/31	Total Loss 4.7776 (4.5418)
2022-11-03 00:45:39,661:INFO: Batch: 20/31	Total Loss 4.3330 (4.5326)
2022-11-03 00:45:40,133:INFO: Batch: 21/31	Total Loss 4.0075 (4.5102)
2022-11-03 00:45:40,602:INFO: Batch: 22/31	Total Loss 6.9577 (4.6156)
2022-11-03 00:45:41,071:INFO: Batch: 23/31	Total Loss 4.1404 (4.5933)
2022-11-03 00:45:41,540:INFO: Batch: 24/31	Total Loss 4.6152 (4.5941)
2022-11-03 00:45:42,007:INFO: Batch: 25/31	Total Loss 4.6326 (4.5955)
2022-11-03 00:45:42,475:INFO: Batch: 26/31	Total Loss 5.0850 (4.6148)
2022-11-03 00:45:42,945:INFO: Batch: 27/31	Total Loss 4.2368 (4.6034)
2022-11-03 00:45:43,413:INFO: Batch: 28/31	Total Loss 4.3574 (4.5952)
2022-11-03 00:45:43,884:INFO: Batch: 29/31	Total Loss 4.8736 (4.6037)
2022-11-03 00:45:44,345:INFO: Batch: 30/31	Total Loss 1.6531 (4.5775)
2022-11-03 00:45:44,508:INFO: - Computing ADE (validation o)
2022-11-03 00:45:45,092:INFO: 		 ADE on eth                       dataset:	 1.0114649534225464
2022-11-03 00:45:45,092:INFO: Average validation o:	ADE  1.0115	FDE  1.8620
2022-11-03 00:45:45,093:INFO: - Computing ADE (validation)
2022-11-03 00:45:45,355:INFO: 		 ADE on hotel                     dataset:	 0.5146210789680481
2022-11-03 00:45:45,651:INFO: 		 ADE on univ                      dataset:	 0.5876678824424744
2022-11-03 00:45:45,941:INFO: 		 ADE on zara1                     dataset:	 0.5025216937065125
2022-11-03 00:45:46,296:INFO: 		 ADE on zara2                     dataset:	 0.45435819029808044
2022-11-03 00:45:46,296:INFO: Average validation:	ADE  0.5298	FDE  1.0846
2022-11-03 00:45:46,297:INFO: - Computing ADE (training)
2022-11-03 00:45:46,773:INFO: 		 ADE on hotel                     dataset:	 0.563048243522644
2022-11-03 00:45:47,450:INFO: 		 ADE on univ                      dataset:	 0.5719559788703918
2022-11-03 00:45:47,987:INFO: 		 ADE on zara1                     dataset:	 0.5554603338241577
2022-11-03 00:45:48,730:INFO: 		 ADE on zara2                     dataset:	 0.4698883295059204
2022-11-03 00:45:48,730:INFO: Average training:	ADE  0.5500	FDE  1.1300
2022-11-03 00:45:48,739:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_414.pth.tar
2022-11-03 00:45:48,739:INFO: 
===> EPOCH: 415 (P3)
2022-11-03 00:45:48,739:INFO: - Computing loss (training)
2022-11-03 00:45:49,823:INFO: Batch:  0/31	Total Loss 4.1107 (4.1107)
2022-11-03 00:45:50,307:INFO: Batch:  1/31	Total Loss 5.8405 (4.9819)
2022-11-03 00:45:50,786:INFO: Batch:  2/31	Total Loss 4.7117 (4.8906)
2022-11-03 00:45:51,263:INFO: Batch:  3/31	Total Loss 3.7246 (4.5960)
2022-11-03 00:45:51,737:INFO: Batch:  4/31	Total Loss 4.7610 (4.6277)
2022-11-03 00:45:52,216:INFO: Batch:  5/31	Total Loss 4.5683 (4.6176)
2022-11-03 00:45:52,693:INFO: Batch:  6/31	Total Loss 4.7689 (4.6360)
2022-11-03 00:45:53,166:INFO: Batch:  7/31	Total Loss 4.5867 (4.6300)
2022-11-03 00:45:53,642:INFO: Batch:  8/31	Total Loss 4.9195 (4.6609)
2022-11-03 00:45:54,117:INFO: Batch:  9/31	Total Loss 4.2089 (4.6161)
2022-11-03 00:45:54,592:INFO: Batch: 10/31	Total Loss 4.2515 (4.5848)
2022-11-03 00:45:55,071:INFO: Batch: 11/31	Total Loss 4.5121 (4.5784)
2022-11-03 00:45:55,549:INFO: Batch: 12/31	Total Loss 4.9463 (4.6050)
2022-11-03 00:45:56,027:INFO: Batch: 13/31	Total Loss 4.5951 (4.6044)
2022-11-03 00:45:56,507:INFO: Batch: 14/31	Total Loss 4.5295 (4.5990)
2022-11-03 00:45:56,989:INFO: Batch: 15/31	Total Loss 4.2305 (4.5768)
2022-11-03 00:45:57,467:INFO: Batch: 16/31	Total Loss 4.5727 (4.5766)
2022-11-03 00:45:57,946:INFO: Batch: 17/31	Total Loss 4.7888 (4.5887)
2022-11-03 00:45:58,423:INFO: Batch: 18/31	Total Loss 4.7377 (4.5965)
2022-11-03 00:45:58,900:INFO: Batch: 19/31	Total Loss 4.9608 (4.6133)
2022-11-03 00:45:59,378:INFO: Batch: 20/31	Total Loss 4.4594 (4.6066)
2022-11-03 00:45:59,856:INFO: Batch: 21/31	Total Loss 4.4116 (4.5981)
2022-11-03 00:46:00,335:INFO: Batch: 22/31	Total Loss 4.4514 (4.5920)
2022-11-03 00:46:00,816:INFO: Batch: 23/31	Total Loss 4.5166 (4.5885)
2022-11-03 00:46:01,294:INFO: Batch: 24/31	Total Loss 4.1591 (4.5697)
2022-11-03 00:46:01,768:INFO: Batch: 25/31	Total Loss 5.1633 (4.5928)
2022-11-03 00:46:02,246:INFO: Batch: 26/31	Total Loss 4.5679 (4.5919)
2022-11-03 00:46:02,723:INFO: Batch: 27/31	Total Loss 4.3805 (4.5856)
2022-11-03 00:46:03,202:INFO: Batch: 28/31	Total Loss 4.6207 (4.5868)
2022-11-03 00:46:03,680:INFO: Batch: 29/31	Total Loss 4.9669 (4.5994)
2022-11-03 00:46:04,072:INFO: Batch: 30/31	Total Loss 1.6760 (4.5688)
2022-11-03 00:46:04,227:INFO: - Computing ADE (validation o)
2022-11-03 00:46:04,856:INFO: 		 ADE on eth                       dataset:	 1.0217199325561523
2022-11-03 00:46:04,856:INFO: Average validation o:	ADE  1.0217	FDE  1.8754
2022-11-03 00:46:04,857:INFO: - Computing ADE (validation)
2022-11-03 00:46:05,123:INFO: 		 ADE on hotel                     dataset:	 0.48639413714408875
2022-11-03 00:46:05,439:INFO: 		 ADE on univ                      dataset:	 0.5655237436294556
2022-11-03 00:46:05,689:INFO: 		 ADE on zara1                     dataset:	 0.4769028425216675
2022-11-03 00:46:06,049:INFO: 		 ADE on zara2                     dataset:	 0.4511442482471466
2022-11-03 00:46:06,049:INFO: Average validation:	ADE  0.5141	FDE  1.0283
2022-11-03 00:46:06,050:INFO: - Computing ADE (training)
2022-11-03 00:46:06,507:INFO: 		 ADE on hotel                     dataset:	 0.5183771848678589
2022-11-03 00:46:07,208:INFO: 		 ADE on univ                      dataset:	 0.5595749020576477
2022-11-03 00:46:07,717:INFO: 		 ADE on zara1                     dataset:	 0.5614384412765503
2022-11-03 00:46:08,461:INFO: 		 ADE on zara2                     dataset:	 0.46948495507240295
2022-11-03 00:46:08,461:INFO: Average training:	ADE  0.5404	FDE  1.0905
2022-11-03 00:46:08,470:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_415.pth.tar
2022-11-03 00:46:08,470:INFO: 
===> EPOCH: 416 (P3)
2022-11-03 00:46:08,470:INFO: - Computing loss (training)
2022-11-03 00:46:09,552:INFO: Batch:  0/31	Total Loss 4.9387 (4.9387)
2022-11-03 00:46:10,036:INFO: Batch:  1/31	Total Loss 5.6031 (5.2701)
2022-11-03 00:46:10,511:INFO: Batch:  2/31	Total Loss 4.7568 (5.1017)
2022-11-03 00:46:10,983:INFO: Batch:  3/31	Total Loss 4.9123 (5.0528)
2022-11-03 00:46:11,455:INFO: Batch:  4/31	Total Loss 4.4395 (4.9292)
2022-11-03 00:46:11,928:INFO: Batch:  5/31	Total Loss 6.2486 (5.1207)
2022-11-03 00:46:12,403:INFO: Batch:  6/31	Total Loss 4.7328 (5.0695)
2022-11-03 00:46:12,883:INFO: Batch:  7/31	Total Loss 4.1442 (4.9482)
2022-11-03 00:46:13,354:INFO: Batch:  8/31	Total Loss 4.7595 (4.9286)
2022-11-03 00:46:13,824:INFO: Batch:  9/31	Total Loss 4.2923 (4.8597)
2022-11-03 00:46:14,298:INFO: Batch: 10/31	Total Loss 3.8914 (4.7738)
2022-11-03 00:46:14,769:INFO: Batch: 11/31	Total Loss 5.4676 (4.8349)
2022-11-03 00:46:15,245:INFO: Batch: 12/31	Total Loss 4.1211 (4.7831)
2022-11-03 00:46:15,724:INFO: Batch: 13/31	Total Loss 4.5005 (4.7642)
2022-11-03 00:46:16,200:INFO: Batch: 14/31	Total Loss 4.1616 (4.7276)
2022-11-03 00:46:16,677:INFO: Batch: 15/31	Total Loss 4.3475 (4.7036)
2022-11-03 00:46:17,153:INFO: Batch: 16/31	Total Loss 4.7441 (4.7060)
2022-11-03 00:46:17,628:INFO: Batch: 17/31	Total Loss 5.1166 (4.7269)
2022-11-03 00:46:18,104:INFO: Batch: 18/31	Total Loss 5.4462 (4.7648)
2022-11-03 00:46:18,579:INFO: Batch: 19/31	Total Loss 4.2226 (4.7410)
2022-11-03 00:46:19,055:INFO: Batch: 20/31	Total Loss 4.3158 (4.7194)
2022-11-03 00:46:19,532:INFO: Batch: 21/31	Total Loss 4.6453 (4.7160)
2022-11-03 00:46:20,009:INFO: Batch: 22/31	Total Loss 4.7668 (4.7181)
2022-11-03 00:46:20,488:INFO: Batch: 23/31	Total Loss 6.5575 (4.8034)
2022-11-03 00:46:20,983:INFO: Batch: 24/31	Total Loss 4.6115 (4.7948)
2022-11-03 00:46:21,475:INFO: Batch: 25/31	Total Loss 4.6615 (4.7899)
2022-11-03 00:46:21,951:INFO: Batch: 26/31	Total Loss 4.5002 (4.7792)
2022-11-03 00:46:22,426:INFO: Batch: 27/31	Total Loss 4.0353 (4.7521)
2022-11-03 00:46:22,902:INFO: Batch: 28/31	Total Loss 5.9104 (4.7854)
2022-11-03 00:46:23,377:INFO: Batch: 29/31	Total Loss 4.7459 (4.7841)
2022-11-03 00:46:23,767:INFO: Batch: 30/31	Total Loss 2.2389 (4.7547)
2022-11-03 00:46:23,917:INFO: - Computing ADE (validation o)
2022-11-03 00:46:24,487:INFO: 		 ADE on eth                       dataset:	 1.0736433267593384
2022-11-03 00:46:24,487:INFO: Average validation o:	ADE  1.0736	FDE  1.9465
2022-11-03 00:46:24,488:INFO: - Computing ADE (validation)
2022-11-03 00:46:24,784:INFO: 		 ADE on hotel                     dataset:	 0.5800962448120117
2022-11-03 00:46:25,075:INFO: 		 ADE on univ                      dataset:	 0.6452839374542236
2022-11-03 00:46:25,371:INFO: 		 ADE on zara1                     dataset:	 0.5490906834602356
2022-11-03 00:46:25,730:INFO: 		 ADE on zara2                     dataset:	 0.5242687463760376
2022-11-03 00:46:25,730:INFO: Average validation:	ADE  0.5917	FDE  1.2262
2022-11-03 00:46:25,731:INFO: - Computing ADE (training)
2022-11-03 00:46:26,177:INFO: 		 ADE on hotel                     dataset:	 0.6340038180351257
2022-11-03 00:46:26,850:INFO: 		 ADE on univ                      dataset:	 0.6077835559844971
2022-11-03 00:46:27,385:INFO: 		 ADE on zara1                     dataset:	 0.6442776322364807
2022-11-03 00:46:28,147:INFO: 		 ADE on zara2                     dataset:	 0.5587117671966553
2022-11-03 00:46:28,148:INFO: Average training:	ADE  0.6008	FDE  1.2407
2022-11-03 00:46:28,156:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_416.pth.tar
2022-11-03 00:46:28,156:INFO: 
===> EPOCH: 417 (P3)
2022-11-03 00:46:28,157:INFO: - Computing loss (training)
2022-11-03 00:46:29,268:INFO: Batch:  0/31	Total Loss 4.7963 (4.7963)
2022-11-03 00:46:29,747:INFO: Batch:  1/31	Total Loss 5.0012 (4.9042)
2022-11-03 00:46:30,229:INFO: Batch:  2/31	Total Loss 4.9256 (4.9112)
2022-11-03 00:46:30,701:INFO: Batch:  3/31	Total Loss 4.9587 (4.9239)
2022-11-03 00:46:31,174:INFO: Batch:  4/31	Total Loss 4.2609 (4.7775)
2022-11-03 00:46:31,648:INFO: Batch:  5/31	Total Loss 5.0617 (4.8221)
2022-11-03 00:46:32,121:INFO: Batch:  6/31	Total Loss 4.3041 (4.7372)
2022-11-03 00:46:32,594:INFO: Batch:  7/31	Total Loss 4.0915 (4.6448)
2022-11-03 00:46:33,061:INFO: Batch:  8/31	Total Loss 4.2558 (4.5975)
2022-11-03 00:46:33,527:INFO: Batch:  9/31	Total Loss 5.1250 (4.6510)
2022-11-03 00:46:33,996:INFO: Batch: 10/31	Total Loss 4.9821 (4.6794)
2022-11-03 00:46:34,467:INFO: Batch: 11/31	Total Loss 4.6018 (4.6729)
2022-11-03 00:46:34,938:INFO: Batch: 12/31	Total Loss 4.9786 (4.6961)
2022-11-03 00:46:35,411:INFO: Batch: 13/31	Total Loss 4.5881 (4.6871)
2022-11-03 00:46:35,960:INFO: Batch: 14/31	Total Loss 4.8226 (4.6956)
2022-11-03 00:46:36,432:INFO: Batch: 15/31	Total Loss 4.5357 (4.6856)
2022-11-03 00:46:36,904:INFO: Batch: 16/31	Total Loss 4.5189 (4.6755)
2022-11-03 00:46:37,374:INFO: Batch: 17/31	Total Loss 4.7983 (4.6827)
2022-11-03 00:46:37,845:INFO: Batch: 18/31	Total Loss 4.3356 (4.6629)
2022-11-03 00:46:38,316:INFO: Batch: 19/31	Total Loss 4.0835 (4.6301)
2022-11-03 00:46:38,792:INFO: Batch: 20/31	Total Loss 4.3926 (4.6194)
2022-11-03 00:46:39,264:INFO: Batch: 21/31	Total Loss 4.0332 (4.5915)
2022-11-03 00:46:39,734:INFO: Batch: 22/31	Total Loss 4.2909 (4.5781)
2022-11-03 00:46:40,210:INFO: Batch: 23/31	Total Loss 3.9933 (4.5529)
2022-11-03 00:46:40,680:INFO: Batch: 24/31	Total Loss 4.5294 (4.5520)
2022-11-03 00:46:41,154:INFO: Batch: 25/31	Total Loss 4.6197 (4.5546)
2022-11-03 00:46:41,626:INFO: Batch: 26/31	Total Loss 4.3291 (4.5459)
2022-11-03 00:46:42,098:INFO: Batch: 27/31	Total Loss 4.7316 (4.5522)
2022-11-03 00:46:42,567:INFO: Batch: 28/31	Total Loss 4.6851 (4.5565)
2022-11-03 00:46:43,042:INFO: Batch: 29/31	Total Loss 4.8049 (4.5646)
2022-11-03 00:46:43,429:INFO: Batch: 30/31	Total Loss 1.7424 (4.5415)
2022-11-03 00:46:43,593:INFO: - Computing ADE (validation o)
2022-11-03 00:46:44,151:INFO: 		 ADE on eth                       dataset:	 1.0035558938980103
2022-11-03 00:46:44,151:INFO: Average validation o:	ADE  1.0036	FDE  1.8163
2022-11-03 00:46:44,152:INFO: - Computing ADE (validation)
2022-11-03 00:46:44,423:INFO: 		 ADE on hotel                     dataset:	 0.47786176204681396
2022-11-03 00:46:44,719:INFO: 		 ADE on univ                      dataset:	 0.5659061074256897
2022-11-03 00:46:44,985:INFO: 		 ADE on zara1                     dataset:	 0.4766363203525543
2022-11-03 00:46:45,330:INFO: 		 ADE on zara2                     dataset:	 0.4292329251766205
2022-11-03 00:46:45,331:INFO: Average validation:	ADE  0.5058	FDE  0.9992
2022-11-03 00:46:45,331:INFO: - Computing ADE (training)
2022-11-03 00:46:45,771:INFO: 		 ADE on hotel                     dataset:	 0.5135249495506287
2022-11-03 00:46:46,464:INFO: 		 ADE on univ                      dataset:	 0.5494279265403748
2022-11-03 00:46:46,986:INFO: 		 ADE on zara1                     dataset:	 0.5610733032226562
2022-11-03 00:46:47,764:INFO: 		 ADE on zara2                     dataset:	 0.45312145352363586
2022-11-03 00:46:47,764:INFO: Average training:	ADE  0.5297	FDE  1.0553
2022-11-03 00:46:47,773:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_417.pth.tar
2022-11-03 00:46:47,773:INFO: 
===> EPOCH: 418 (P3)
2022-11-03 00:46:47,773:INFO: - Computing loss (training)
2022-11-03 00:46:48,849:INFO: Batch:  0/31	Total Loss 4.3979 (4.3979)
2022-11-03 00:46:49,331:INFO: Batch:  1/31	Total Loss 4.5765 (4.4882)
2022-11-03 00:46:49,807:INFO: Batch:  2/31	Total Loss 4.8973 (4.6178)
2022-11-03 00:46:50,281:INFO: Batch:  3/31	Total Loss 4.4397 (4.5702)
2022-11-03 00:46:50,754:INFO: Batch:  4/31	Total Loss 4.1304 (4.4831)
2022-11-03 00:46:51,231:INFO: Batch:  5/31	Total Loss 4.4488 (4.4771)
2022-11-03 00:46:51,706:INFO: Batch:  6/31	Total Loss 5.5070 (4.6319)
2022-11-03 00:46:52,180:INFO: Batch:  7/31	Total Loss 4.7660 (4.6485)
2022-11-03 00:46:52,653:INFO: Batch:  8/31	Total Loss 4.0804 (4.5831)
2022-11-03 00:46:53,125:INFO: Batch:  9/31	Total Loss 4.4246 (4.5669)
2022-11-03 00:46:53,598:INFO: Batch: 10/31	Total Loss 4.5719 (4.5673)
2022-11-03 00:46:54,073:INFO: Batch: 11/31	Total Loss 4.6602 (4.5745)
2022-11-03 00:46:54,550:INFO: Batch: 12/31	Total Loss 4.5927 (4.5758)
2022-11-03 00:46:55,038:INFO: Batch: 13/31	Total Loss 4.0403 (4.5358)
2022-11-03 00:46:55,517:INFO: Batch: 14/31	Total Loss 5.8689 (4.6199)
2022-11-03 00:46:56,005:INFO: Batch: 15/31	Total Loss 3.9939 (4.5821)
2022-11-03 00:46:56,478:INFO: Batch: 16/31	Total Loss 4.3825 (4.5693)
2022-11-03 00:46:56,952:INFO: Batch: 17/31	Total Loss 4.5320 (4.5673)
2022-11-03 00:46:57,425:INFO: Batch: 18/31	Total Loss 4.5879 (4.5684)
2022-11-03 00:46:57,901:INFO: Batch: 19/31	Total Loss 4.3635 (4.5578)
2022-11-03 00:46:58,372:INFO: Batch: 20/31	Total Loss 4.4401 (4.5521)
2022-11-03 00:46:58,845:INFO: Batch: 21/31	Total Loss 4.6864 (4.5587)
2022-11-03 00:46:59,316:INFO: Batch: 22/31	Total Loss 4.6220 (4.5616)
2022-11-03 00:46:59,787:INFO: Batch: 23/31	Total Loss 4.3114 (4.5502)
2022-11-03 00:47:00,262:INFO: Batch: 24/31	Total Loss 4.5218 (4.5490)
2022-11-03 00:47:00,735:INFO: Batch: 25/31	Total Loss 4.2429 (4.5366)
2022-11-03 00:47:01,209:INFO: Batch: 26/31	Total Loss 4.2507 (4.5271)
2022-11-03 00:47:01,682:INFO: Batch: 27/31	Total Loss 4.9332 (4.5402)
2022-11-03 00:47:02,153:INFO: Batch: 28/31	Total Loss 4.3243 (4.5319)
2022-11-03 00:47:02,623:INFO: Batch: 29/31	Total Loss 4.4930 (4.5306)
2022-11-03 00:47:03,009:INFO: Batch: 30/31	Total Loss 1.6068 (4.5016)
2022-11-03 00:47:03,163:INFO: - Computing ADE (validation o)
2022-11-03 00:47:03,753:INFO: 		 ADE on eth                       dataset:	 1.0269516706466675
2022-11-03 00:47:03,754:INFO: Average validation o:	ADE  1.0270	FDE  1.8826
2022-11-03 00:47:03,754:INFO: - Computing ADE (validation)
2022-11-03 00:47:04,019:INFO: 		 ADE on hotel                     dataset:	 0.49775251746177673
2022-11-03 00:47:04,309:INFO: 		 ADE on univ                      dataset:	 0.5704711675643921
2022-11-03 00:47:04,562:INFO: 		 ADE on zara1                     dataset:	 0.48271626234054565
2022-11-03 00:47:04,940:INFO: 		 ADE on zara2                     dataset:	 0.4695301353931427
2022-11-03 00:47:04,940:INFO: Average validation:	ADE  0.5244	FDE  1.0487
2022-11-03 00:47:04,941:INFO: - Computing ADE (training)
2022-11-03 00:47:05,409:INFO: 		 ADE on hotel                     dataset:	 0.5217050909996033
2022-11-03 00:47:06,089:INFO: 		 ADE on univ                      dataset:	 0.5653247833251953
2022-11-03 00:47:06,631:INFO: 		 ADE on zara1                     dataset:	 0.5801103711128235
2022-11-03 00:47:07,378:INFO: 		 ADE on zara2                     dataset:	 0.4888498783111572
2022-11-03 00:47:07,378:INFO: Average training:	ADE  0.5496	FDE  1.1088
2022-11-03 00:47:07,388:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_418.pth.tar
2022-11-03 00:47:07,388:INFO: 
===> EPOCH: 419 (P3)
2022-11-03 00:47:07,388:INFO: - Computing loss (training)
2022-11-03 00:47:08,491:INFO: Batch:  0/31	Total Loss 4.6309 (4.6309)
2022-11-03 00:47:08,976:INFO: Batch:  1/31	Total Loss 4.9550 (4.7916)
2022-11-03 00:47:09,458:INFO: Batch:  2/31	Total Loss 4.2678 (4.6005)
2022-11-03 00:47:09,940:INFO: Batch:  3/31	Total Loss 4.4055 (4.5514)
2022-11-03 00:47:10,417:INFO: Batch:  4/31	Total Loss 4.3730 (4.5173)
2022-11-03 00:47:10,899:INFO: Batch:  5/31	Total Loss 4.5588 (4.5239)
2022-11-03 00:47:11,375:INFO: Batch:  6/31	Total Loss 5.3205 (4.6352)
2022-11-03 00:47:11,850:INFO: Batch:  7/31	Total Loss 4.4534 (4.6134)
2022-11-03 00:47:12,324:INFO: Batch:  8/31	Total Loss 4.5113 (4.6016)
2022-11-03 00:47:12,802:INFO: Batch:  9/31	Total Loss 4.5699 (4.5987)
2022-11-03 00:47:13,278:INFO: Batch: 10/31	Total Loss 4.3565 (4.5773)
2022-11-03 00:47:13,754:INFO: Batch: 11/31	Total Loss 5.2224 (4.6264)
2022-11-03 00:47:14,234:INFO: Batch: 12/31	Total Loss 4.7552 (4.6345)
2022-11-03 00:47:14,716:INFO: Batch: 13/31	Total Loss 4.3570 (4.6150)
2022-11-03 00:47:15,197:INFO: Batch: 14/31	Total Loss 4.7056 (4.6214)
2022-11-03 00:47:15,680:INFO: Batch: 15/31	Total Loss 4.3846 (4.6068)
2022-11-03 00:47:16,160:INFO: Batch: 16/31	Total Loss 4.4194 (4.5962)
2022-11-03 00:47:16,639:INFO: Batch: 17/31	Total Loss 4.8055 (4.6075)
2022-11-03 00:47:17,119:INFO: Batch: 18/31	Total Loss 4.6911 (4.6117)
2022-11-03 00:47:17,597:INFO: Batch: 19/31	Total Loss 3.9389 (4.5782)
2022-11-03 00:47:18,076:INFO: Batch: 20/31	Total Loss 3.9943 (4.5502)
2022-11-03 00:47:18,553:INFO: Batch: 21/31	Total Loss 4.5282 (4.5492)
2022-11-03 00:47:19,033:INFO: Batch: 22/31	Total Loss 4.7771 (4.5584)
2022-11-03 00:47:19,513:INFO: Batch: 23/31	Total Loss 4.4755 (4.5548)
2022-11-03 00:47:19,992:INFO: Batch: 24/31	Total Loss 4.3783 (4.5479)
2022-11-03 00:47:20,471:INFO: Batch: 25/31	Total Loss 3.9329 (4.5238)
2022-11-03 00:47:20,948:INFO: Batch: 26/31	Total Loss 4.6103 (4.5267)
2022-11-03 00:47:21,425:INFO: Batch: 27/31	Total Loss 4.6067 (4.5297)
2022-11-03 00:47:21,904:INFO: Batch: 28/31	Total Loss 5.4616 (4.5587)
2022-11-03 00:47:22,382:INFO: Batch: 29/31	Total Loss 4.5587 (4.5587)
2022-11-03 00:47:22,773:INFO: Batch: 30/31	Total Loss 1.7797 (4.5274)
2022-11-03 00:47:22,921:INFO: - Computing ADE (validation o)
2022-11-03 00:47:23,497:INFO: 		 ADE on eth                       dataset:	 1.0523860454559326
2022-11-03 00:47:23,497:INFO: Average validation o:	ADE  1.0524	FDE  1.9335
2022-11-03 00:47:23,498:INFO: - Computing ADE (validation)
2022-11-03 00:47:23,760:INFO: 		 ADE on hotel                     dataset:	 0.5161616802215576
2022-11-03 00:47:24,052:INFO: 		 ADE on univ                      dataset:	 0.5824264287948608
2022-11-03 00:47:24,295:INFO: 		 ADE on zara1                     dataset:	 0.5222011804580688
2022-11-03 00:47:24,638:INFO: 		 ADE on zara2                     dataset:	 0.48994550108909607
2022-11-03 00:47:24,639:INFO: Average validation:	ADE  0.5414	FDE  1.0845
2022-11-03 00:47:24,639:INFO: - Computing ADE (training)
2022-11-03 00:47:25,084:INFO: 		 ADE on hotel                     dataset:	 0.5505174398422241
2022-11-03 00:47:25,762:INFO: 		 ADE on univ                      dataset:	 0.5775977373123169
2022-11-03 00:47:26,298:INFO: 		 ADE on zara1                     dataset:	 0.6251407265663147
2022-11-03 00:47:27,052:INFO: 		 ADE on zara2                     dataset:	 0.5189774036407471
2022-11-03 00:47:27,052:INFO: Average training:	ADE  0.5680	FDE  1.1487
2022-11-03 00:47:27,061:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_419.pth.tar
2022-11-03 00:47:27,061:INFO: 
===> EPOCH: 420 (P3)
2022-11-03 00:47:27,061:INFO: - Computing loss (training)
2022-11-03 00:47:28,164:INFO: Batch:  0/31	Total Loss 4.9479 (4.9479)
2022-11-03 00:47:28,650:INFO: Batch:  1/31	Total Loss 5.2158 (5.0899)
2022-11-03 00:47:29,144:INFO: Batch:  2/31	Total Loss 4.0849 (4.7096)
2022-11-03 00:47:29,629:INFO: Batch:  3/31	Total Loss 4.8274 (4.7370)
2022-11-03 00:47:30,115:INFO: Batch:  4/31	Total Loss 4.4126 (4.6818)
2022-11-03 00:47:30,679:INFO: Batch:  5/31	Total Loss 4.9465 (4.7225)
2022-11-03 00:47:31,166:INFO: Batch:  6/31	Total Loss 4.8390 (4.7397)
2022-11-03 00:47:31,650:INFO: Batch:  7/31	Total Loss 4.9799 (4.7711)
2022-11-03 00:47:32,135:INFO: Batch:  8/31	Total Loss 4.4479 (4.7347)
2022-11-03 00:47:32,618:INFO: Batch:  9/31	Total Loss 5.4436 (4.8051)
2022-11-03 00:47:33,099:INFO: Batch: 10/31	Total Loss 4.3361 (4.7587)
2022-11-03 00:47:33,577:INFO: Batch: 11/31	Total Loss 4.6602 (4.7507)
2022-11-03 00:47:34,059:INFO: Batch: 12/31	Total Loss 4.7557 (4.7511)
2022-11-03 00:47:34,538:INFO: Batch: 13/31	Total Loss 5.7429 (4.8244)
2022-11-03 00:47:35,019:INFO: Batch: 14/31	Total Loss 5.5135 (4.8722)
2022-11-03 00:47:35,499:INFO: Batch: 15/31	Total Loss 4.6555 (4.8578)
2022-11-03 00:47:35,981:INFO: Batch: 16/31	Total Loss 4.4732 (4.8357)
2022-11-03 00:47:36,462:INFO: Batch: 17/31	Total Loss 4.7485 (4.8306)
2022-11-03 00:47:36,943:INFO: Batch: 18/31	Total Loss 4.5325 (4.8151)
2022-11-03 00:47:37,422:INFO: Batch: 19/31	Total Loss 4.3909 (4.7926)
2022-11-03 00:47:37,903:INFO: Batch: 20/31	Total Loss 4.5436 (4.7814)
2022-11-03 00:47:38,382:INFO: Batch: 21/31	Total Loss 4.4955 (4.7700)
2022-11-03 00:47:38,863:INFO: Batch: 22/31	Total Loss 4.9610 (4.7790)
2022-11-03 00:47:39,341:INFO: Batch: 23/31	Total Loss 4.6416 (4.7736)
2022-11-03 00:47:39,823:INFO: Batch: 24/31	Total Loss 4.6843 (4.7698)
2022-11-03 00:47:40,304:INFO: Batch: 25/31	Total Loss 4.5008 (4.7586)
2022-11-03 00:47:40,788:INFO: Batch: 26/31	Total Loss 4.8600 (4.7624)
2022-11-03 00:47:41,269:INFO: Batch: 27/31	Total Loss 5.0659 (4.7724)
2022-11-03 00:47:41,751:INFO: Batch: 28/31	Total Loss 4.4652 (4.7601)
2022-11-03 00:47:42,232:INFO: Batch: 29/31	Total Loss 4.0320 (4.7313)
2022-11-03 00:47:42,626:INFO: Batch: 30/31	Total Loss 1.8914 (4.7091)
2022-11-03 00:47:42,784:INFO: - Computing ADE (validation o)
2022-11-03 00:47:43,376:INFO: 		 ADE on eth                       dataset:	 1.0191172361373901
2022-11-03 00:47:43,376:INFO: Average validation o:	ADE  1.0191	FDE  1.8502
2022-11-03 00:47:43,376:INFO: - Computing ADE (validation)
2022-11-03 00:47:43,654:INFO: 		 ADE on hotel                     dataset:	 0.5209478735923767
2022-11-03 00:47:43,940:INFO: 		 ADE on univ                      dataset:	 0.596289336681366
2022-11-03 00:47:44,195:INFO: 		 ADE on zara1                     dataset:	 0.4788329601287842
2022-11-03 00:47:44,548:INFO: 		 ADE on zara2                     dataset:	 0.4744386076927185
2022-11-03 00:47:44,548:INFO: Average validation:	ADE  0.5406	FDE  1.1075
2022-11-03 00:47:44,549:INFO: - Computing ADE (training)
2022-11-03 00:47:44,996:INFO: 		 ADE on hotel                     dataset:	 0.5531236529350281
2022-11-03 00:47:45,691:INFO: 		 ADE on univ                      dataset:	 0.572773814201355
2022-11-03 00:47:46,203:INFO: 		 ADE on zara1                     dataset:	 0.57718425989151
2022-11-03 00:47:46,940:INFO: 		 ADE on zara2                     dataset:	 0.4955565631389618
2022-11-03 00:47:46,940:INFO: Average training:	ADE  0.5569	FDE  1.1418
2022-11-03 00:47:46,949:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_420.pth.tar
2022-11-03 00:47:46,949:INFO: 
===> EPOCH: 421 (P3)
2022-11-03 00:47:46,949:INFO: - Computing loss (training)
2022-11-03 00:47:48,032:INFO: Batch:  0/31	Total Loss 4.4860 (4.4860)
2022-11-03 00:47:48,511:INFO: Batch:  1/31	Total Loss 5.5161 (5.0005)
2022-11-03 00:47:48,993:INFO: Batch:  2/31	Total Loss 5.0368 (5.0128)
2022-11-03 00:47:49,479:INFO: Batch:  3/31	Total Loss 4.7540 (4.9515)
2022-11-03 00:47:49,956:INFO: Batch:  4/31	Total Loss 5.4242 (5.0415)
2022-11-03 00:47:50,436:INFO: Batch:  5/31	Total Loss 4.7580 (4.9972)
2022-11-03 00:47:50,913:INFO: Batch:  6/31	Total Loss 4.9362 (4.9886)
2022-11-03 00:47:51,386:INFO: Batch:  7/31	Total Loss 5.0601 (4.9976)
2022-11-03 00:47:51,862:INFO: Batch:  8/31	Total Loss 4.8307 (4.9786)
2022-11-03 00:47:52,343:INFO: Batch:  9/31	Total Loss 4.0693 (4.8808)
2022-11-03 00:47:52,820:INFO: Batch: 10/31	Total Loss 4.6238 (4.8577)
2022-11-03 00:47:53,296:INFO: Batch: 11/31	Total Loss 4.1573 (4.7981)
2022-11-03 00:47:53,777:INFO: Batch: 12/31	Total Loss 4.7954 (4.7979)
2022-11-03 00:47:54,258:INFO: Batch: 13/31	Total Loss 4.8988 (4.8057)
2022-11-03 00:47:54,738:INFO: Batch: 14/31	Total Loss 4.6687 (4.7964)
2022-11-03 00:47:55,221:INFO: Batch: 15/31	Total Loss 3.7092 (4.7271)
2022-11-03 00:47:55,702:INFO: Batch: 16/31	Total Loss 4.2840 (4.7004)
2022-11-03 00:47:56,186:INFO: Batch: 17/31	Total Loss 4.1464 (4.6698)
2022-11-03 00:47:56,666:INFO: Batch: 18/31	Total Loss 4.5301 (4.6629)
2022-11-03 00:47:57,148:INFO: Batch: 19/31	Total Loss 4.9272 (4.6772)
2022-11-03 00:47:57,627:INFO: Batch: 20/31	Total Loss 4.4583 (4.6660)
2022-11-03 00:47:58,109:INFO: Batch: 21/31	Total Loss 4.6590 (4.6657)
2022-11-03 00:47:58,590:INFO: Batch: 22/31	Total Loss 4.7147 (4.6676)
2022-11-03 00:47:59,070:INFO: Batch: 23/31	Total Loss 4.4478 (4.6583)
2022-11-03 00:47:59,555:INFO: Batch: 24/31	Total Loss 4.2161 (4.6408)
2022-11-03 00:48:00,073:INFO: Batch: 25/31	Total Loss 4.7824 (4.6456)
2022-11-03 00:48:00,582:INFO: Batch: 26/31	Total Loss 4.8849 (4.6550)
2022-11-03 00:48:01,067:INFO: Batch: 27/31	Total Loss 4.7710 (4.6587)
2022-11-03 00:48:01,544:INFO: Batch: 28/31	Total Loss 4.3945 (4.6485)
2022-11-03 00:48:02,014:INFO: Batch: 29/31	Total Loss 5.2302 (4.6675)
2022-11-03 00:48:02,399:INFO: Batch: 30/31	Total Loss 1.7975 (4.6462)
2022-11-03 00:48:02,547:INFO: - Computing ADE (validation o)
2022-11-03 00:48:03,149:INFO: 		 ADE on eth                       dataset:	 1.0430090427398682
2022-11-03 00:48:03,149:INFO: Average validation o:	ADE  1.0430	FDE  1.9052
2022-11-03 00:48:03,150:INFO: - Computing ADE (validation)
2022-11-03 00:48:03,411:INFO: 		 ADE on hotel                     dataset:	 0.5439345240592957
2022-11-03 00:48:03,700:INFO: 		 ADE on univ                      dataset:	 0.6045988202095032
2022-11-03 00:48:03,946:INFO: 		 ADE on zara1                     dataset:	 0.4754151999950409
2022-11-03 00:48:04,290:INFO: 		 ADE on zara2                     dataset:	 0.49230754375457764
2022-11-03 00:48:04,291:INFO: Average validation:	ADE  0.5526	FDE  1.1336
2022-11-03 00:48:04,291:INFO: - Computing ADE (training)
2022-11-03 00:48:04,756:INFO: 		 ADE on hotel                     dataset:	 0.577797532081604
2022-11-03 00:48:05,442:INFO: 		 ADE on univ                      dataset:	 0.5841394066810608
2022-11-03 00:48:05,965:INFO: 		 ADE on zara1                     dataset:	 0.6013304591178894
2022-11-03 00:48:06,714:INFO: 		 ADE on zara2                     dataset:	 0.5183920860290527
2022-11-03 00:48:06,715:INFO: Average training:	ADE  0.5717	FDE  1.1748
2022-11-03 00:48:06,732:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_421.pth.tar
2022-11-03 00:48:06,732:INFO: 
===> EPOCH: 422 (P3)
2022-11-03 00:48:06,733:INFO: - Computing loss (training)
2022-11-03 00:48:07,857:INFO: Batch:  0/31	Total Loss 4.7969 (4.7969)
2022-11-03 00:48:08,338:INFO: Batch:  1/31	Total Loss 4.1747 (4.5005)
2022-11-03 00:48:08,822:INFO: Batch:  2/31	Total Loss 5.2252 (4.7583)
2022-11-03 00:48:09,304:INFO: Batch:  3/31	Total Loss 4.8900 (4.7907)
2022-11-03 00:48:09,785:INFO: Batch:  4/31	Total Loss 4.6700 (4.7657)
2022-11-03 00:48:10,269:INFO: Batch:  5/31	Total Loss 4.5296 (4.7263)
2022-11-03 00:48:10,748:INFO: Batch:  6/31	Total Loss 4.5359 (4.7013)
2022-11-03 00:48:11,227:INFO: Batch:  7/31	Total Loss 4.7673 (4.7089)
2022-11-03 00:48:11,704:INFO: Batch:  8/31	Total Loss 4.8254 (4.7228)
2022-11-03 00:48:12,180:INFO: Batch:  9/31	Total Loss 4.9761 (4.7493)
2022-11-03 00:48:12,661:INFO: Batch: 10/31	Total Loss 4.4375 (4.7192)
2022-11-03 00:48:13,142:INFO: Batch: 11/31	Total Loss 4.4525 (4.6964)
2022-11-03 00:48:13,623:INFO: Batch: 12/31	Total Loss 4.7404 (4.6993)
2022-11-03 00:48:14,106:INFO: Batch: 13/31	Total Loss 4.3548 (4.6747)
2022-11-03 00:48:14,590:INFO: Batch: 14/31	Total Loss 3.8644 (4.6146)
2022-11-03 00:48:15,073:INFO: Batch: 15/31	Total Loss 4.3143 (4.5940)
2022-11-03 00:48:15,556:INFO: Batch: 16/31	Total Loss 4.7370 (4.6026)
2022-11-03 00:48:16,040:INFO: Batch: 17/31	Total Loss 5.4582 (4.6461)
2022-11-03 00:48:16,521:INFO: Batch: 18/31	Total Loss 4.6044 (4.6439)
2022-11-03 00:48:17,003:INFO: Batch: 19/31	Total Loss 4.2745 (4.6241)
2022-11-03 00:48:17,484:INFO: Batch: 20/31	Total Loss 4.0982 (4.5972)
2022-11-03 00:48:17,965:INFO: Batch: 21/31	Total Loss 4.8604 (4.6076)
2022-11-03 00:48:18,446:INFO: Batch: 22/31	Total Loss 3.9207 (4.5770)
2022-11-03 00:48:18,926:INFO: Batch: 23/31	Total Loss 3.9915 (4.5530)
2022-11-03 00:48:19,410:INFO: Batch: 24/31	Total Loss 4.6343 (4.5560)
2022-11-03 00:48:19,892:INFO: Batch: 25/31	Total Loss 4.8109 (4.5655)
2022-11-03 00:48:20,377:INFO: Batch: 26/31	Total Loss 4.9750 (4.5817)
2022-11-03 00:48:20,850:INFO: Batch: 27/31	Total Loss 4.3637 (4.5736)
2022-11-03 00:48:21,321:INFO: Batch: 28/31	Total Loss 4.5787 (4.5737)
2022-11-03 00:48:21,791:INFO: Batch: 29/31	Total Loss 5.4635 (4.6021)
2022-11-03 00:48:22,254:INFO: Batch: 30/31	Total Loss 1.6690 (4.5762)
2022-11-03 00:48:22,410:INFO: - Computing ADE (validation o)
2022-11-03 00:48:23,006:INFO: 		 ADE on eth                       dataset:	 1.0347198247909546
2022-11-03 00:48:23,007:INFO: Average validation o:	ADE  1.0347	FDE  1.9188
2022-11-03 00:48:23,016:INFO: - Computing ADE (validation)
2022-11-03 00:48:23,282:INFO: 		 ADE on hotel                     dataset:	 0.5095478892326355
2022-11-03 00:48:23,575:INFO: 		 ADE on univ                      dataset:	 0.5730007886886597
2022-11-03 00:48:23,826:INFO: 		 ADE on zara1                     dataset:	 0.47727063298225403
2022-11-03 00:48:24,188:INFO: 		 ADE on zara2                     dataset:	 0.4827178716659546
2022-11-03 00:48:24,189:INFO: Average validation:	ADE  0.5308	FDE  1.0723
2022-11-03 00:48:24,189:INFO: - Computing ADE (training)
2022-11-03 00:48:24,619:INFO: 		 ADE on hotel                     dataset:	 0.5267426371574402
2022-11-03 00:48:25,286:INFO: 		 ADE on univ                      dataset:	 0.5716467499732971
2022-11-03 00:48:25,823:INFO: 		 ADE on zara1                     dataset:	 0.5836105942726135
2022-11-03 00:48:26,566:INFO: 		 ADE on zara2                     dataset:	 0.5019650459289551
2022-11-03 00:48:26,566:INFO: Average training:	ADE  0.5571	FDE  1.1351
2022-11-03 00:48:26,575:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_422.pth.tar
2022-11-03 00:48:26,575:INFO: 
===> EPOCH: 423 (P3)
2022-11-03 00:48:26,575:INFO: - Computing loss (training)
2022-11-03 00:48:27,670:INFO: Batch:  0/31	Total Loss 5.0229 (5.0229)
2022-11-03 00:48:28,145:INFO: Batch:  1/31	Total Loss 4.2950 (4.6922)
2022-11-03 00:48:28,625:INFO: Batch:  2/31	Total Loss 5.2032 (4.8548)
2022-11-03 00:48:29,100:INFO: Batch:  3/31	Total Loss 4.6621 (4.8074)
2022-11-03 00:48:29,573:INFO: Batch:  4/31	Total Loss 3.9808 (4.6379)
2022-11-03 00:48:30,048:INFO: Batch:  5/31	Total Loss 4.6251 (4.6355)
2022-11-03 00:48:30,523:INFO: Batch:  6/31	Total Loss 4.8670 (4.6702)
2022-11-03 00:48:30,998:INFO: Batch:  7/31	Total Loss 3.9568 (4.5804)
2022-11-03 00:48:31,475:INFO: Batch:  8/31	Total Loss 4.7414 (4.5978)
2022-11-03 00:48:31,947:INFO: Batch:  9/31	Total Loss 4.5985 (4.5978)
2022-11-03 00:48:32,422:INFO: Batch: 10/31	Total Loss 4.3497 (4.5753)
2022-11-03 00:48:32,898:INFO: Batch: 11/31	Total Loss 4.4477 (4.5648)
2022-11-03 00:48:33,376:INFO: Batch: 12/31	Total Loss 4.4336 (4.5539)
2022-11-03 00:48:33,851:INFO: Batch: 13/31	Total Loss 4.4125 (4.5437)
2022-11-03 00:48:34,325:INFO: Batch: 14/31	Total Loss 4.3995 (4.5354)
2022-11-03 00:48:34,799:INFO: Batch: 15/31	Total Loss 4.3196 (4.5218)
2022-11-03 00:48:35,271:INFO: Batch: 16/31	Total Loss 5.0365 (4.5501)
2022-11-03 00:48:35,743:INFO: Batch: 17/31	Total Loss 4.4297 (4.5433)
2022-11-03 00:48:36,216:INFO: Batch: 18/31	Total Loss 4.4075 (4.5359)
2022-11-03 00:48:36,686:INFO: Batch: 19/31	Total Loss 4.5450 (4.5363)
2022-11-03 00:48:37,158:INFO: Batch: 20/31	Total Loss 4.4828 (4.5338)
2022-11-03 00:48:37,628:INFO: Batch: 21/31	Total Loss 4.1302 (4.5165)
2022-11-03 00:48:38,098:INFO: Batch: 22/31	Total Loss 4.6206 (4.5208)
2022-11-03 00:48:38,567:INFO: Batch: 23/31	Total Loss 4.7917 (4.5318)
2022-11-03 00:48:39,036:INFO: Batch: 24/31	Total Loss 4.4158 (4.5270)
2022-11-03 00:48:39,505:INFO: Batch: 25/31	Total Loss 4.6228 (4.5305)
2022-11-03 00:48:39,976:INFO: Batch: 26/31	Total Loss 4.6500 (4.5348)
2022-11-03 00:48:40,445:INFO: Batch: 27/31	Total Loss 4.5940 (4.5369)
2022-11-03 00:48:40,913:INFO: Batch: 28/31	Total Loss 4.5085 (4.5359)
2022-11-03 00:48:41,381:INFO: Batch: 29/31	Total Loss 4.6586 (4.5396)
2022-11-03 00:48:41,766:INFO: Batch: 30/31	Total Loss 1.5703 (4.5092)
2022-11-03 00:48:41,912:INFO: - Computing ADE (validation o)
2022-11-03 00:48:42,503:INFO: 		 ADE on eth                       dataset:	 0.9987065196037292
2022-11-03 00:48:42,503:INFO: Average validation o:	ADE  0.9987	FDE  1.8127
2022-11-03 00:48:42,504:INFO: - Computing ADE (validation)
2022-11-03 00:48:42,782:INFO: 		 ADE on hotel                     dataset:	 0.49234944581985474
2022-11-03 00:48:43,072:INFO: 		 ADE on univ                      dataset:	 0.5785119533538818
2022-11-03 00:48:43,326:INFO: 		 ADE on zara1                     dataset:	 0.4921186566352844
2022-11-03 00:48:43,671:INFO: 		 ADE on zara2                     dataset:	 0.44070249795913696
2022-11-03 00:48:43,672:INFO: Average validation:	ADE  0.5182	FDE  1.0456
2022-11-03 00:48:43,672:INFO: - Computing ADE (training)
2022-11-03 00:48:44,131:INFO: 		 ADE on hotel                     dataset:	 0.5277387499809265
2022-11-03 00:48:44,851:INFO: 		 ADE on univ                      dataset:	 0.5563583374023438
2022-11-03 00:48:45,363:INFO: 		 ADE on zara1                     dataset:	 0.5649453997612
2022-11-03 00:48:46,142:INFO: 		 ADE on zara2                     dataset:	 0.463515043258667
2022-11-03 00:48:46,142:INFO: Average training:	ADE  0.5373	FDE  1.0861
2022-11-03 00:48:46,152:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_423.pth.tar
2022-11-03 00:48:46,152:INFO: 
===> EPOCH: 424 (P3)
2022-11-03 00:48:46,152:INFO: - Computing loss (training)
2022-11-03 00:48:47,229:INFO: Batch:  0/31	Total Loss 4.5402 (4.5402)
2022-11-03 00:48:47,700:INFO: Batch:  1/31	Total Loss 4.7598 (4.6472)
2022-11-03 00:48:48,172:INFO: Batch:  2/31	Total Loss 5.2373 (4.8396)
2022-11-03 00:48:48,642:INFO: Batch:  3/31	Total Loss 4.5872 (4.7792)
2022-11-03 00:48:49,112:INFO: Batch:  4/31	Total Loss 4.5015 (4.7290)
2022-11-03 00:48:49,587:INFO: Batch:  5/31	Total Loss 4.0101 (4.5901)
2022-11-03 00:48:50,060:INFO: Batch:  6/31	Total Loss 4.4778 (4.5734)
2022-11-03 00:48:50,531:INFO: Batch:  7/31	Total Loss 4.6257 (4.5797)
2022-11-03 00:48:51,002:INFO: Batch:  8/31	Total Loss 4.8472 (4.6096)
2022-11-03 00:48:51,472:INFO: Batch:  9/31	Total Loss 4.7023 (4.6189)
2022-11-03 00:48:51,944:INFO: Batch: 10/31	Total Loss 4.3156 (4.5917)
2022-11-03 00:48:52,415:INFO: Batch: 11/31	Total Loss 4.5794 (4.5907)
2022-11-03 00:48:52,888:INFO: Batch: 12/31	Total Loss 4.3267 (4.5707)
2022-11-03 00:48:53,362:INFO: Batch: 13/31	Total Loss 4.6101 (4.5735)
2022-11-03 00:48:53,836:INFO: Batch: 14/31	Total Loss 5.2001 (4.6113)
2022-11-03 00:48:54,309:INFO: Batch: 15/31	Total Loss 4.6216 (4.6120)
2022-11-03 00:48:54,782:INFO: Batch: 16/31	Total Loss 4.3801 (4.5967)
2022-11-03 00:48:55,255:INFO: Batch: 17/31	Total Loss 3.8324 (4.5571)
2022-11-03 00:48:55,729:INFO: Batch: 18/31	Total Loss 5.0930 (4.5875)
2022-11-03 00:48:56,203:INFO: Batch: 19/31	Total Loss 5.1315 (4.6160)
2022-11-03 00:48:56,678:INFO: Batch: 20/31	Total Loss 5.0340 (4.6351)
2022-11-03 00:48:57,151:INFO: Batch: 21/31	Total Loss 4.2146 (4.6128)
2022-11-03 00:48:57,623:INFO: Batch: 22/31	Total Loss 5.0217 (4.6302)
2022-11-03 00:48:58,097:INFO: Batch: 23/31	Total Loss 5.2182 (4.6571)
2022-11-03 00:48:58,571:INFO: Batch: 24/31	Total Loss 4.2571 (4.6427)
2022-11-03 00:48:59,044:INFO: Batch: 25/31	Total Loss 4.0205 (4.6184)
2022-11-03 00:48:59,517:INFO: Batch: 26/31	Total Loss 4.1902 (4.6020)
2022-11-03 00:48:59,991:INFO: Batch: 27/31	Total Loss 4.7460 (4.6077)
2022-11-03 00:49:00,466:INFO: Batch: 28/31	Total Loss 4.9674 (4.6191)
2022-11-03 00:49:00,940:INFO: Batch: 29/31	Total Loss 4.5915 (4.6182)
2022-11-03 00:49:01,330:INFO: Batch: 30/31	Total Loss 1.7431 (4.5874)
2022-11-03 00:49:01,483:INFO: - Computing ADE (validation o)
2022-11-03 00:49:02,058:INFO: 		 ADE on eth                       dataset:	 1.0411359071731567
2022-11-03 00:49:02,058:INFO: Average validation o:	ADE  1.0411	FDE  1.9967
2022-11-03 00:49:02,059:INFO: - Computing ADE (validation)
2022-11-03 00:49:02,319:INFO: 		 ADE on hotel                     dataset:	 0.554689884185791
2022-11-03 00:49:02,613:INFO: 		 ADE on univ                      dataset:	 0.6050237417221069
2022-11-03 00:49:02,867:INFO: 		 ADE on zara1                     dataset:	 0.5513734817504883
2022-11-03 00:49:03,198:INFO: 		 ADE on zara2                     dataset:	 0.5238319635391235
2022-11-03 00:49:03,198:INFO: Average validation:	ADE  0.5694	FDE  1.2018
2022-11-03 00:49:03,199:INFO: - Computing ADE (training)
2022-11-03 00:49:03,640:INFO: 		 ADE on hotel                     dataset:	 0.5815155506134033
2022-11-03 00:49:04,323:INFO: 		 ADE on univ                      dataset:	 0.6123844385147095
2022-11-03 00:49:04,870:INFO: 		 ADE on zara1                     dataset:	 0.592797577381134
2022-11-03 00:49:05,617:INFO: 		 ADE on zara2                     dataset:	 0.5348665118217468
2022-11-03 00:49:05,618:INFO: Average training:	ADE  0.5946	FDE  1.2632
2022-11-03 00:49:05,626:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_424.pth.tar
2022-11-03 00:49:05,626:INFO: 
===> EPOCH: 425 (P3)
2022-11-03 00:49:05,627:INFO: - Computing loss (training)
2022-11-03 00:49:06,703:INFO: Batch:  0/31	Total Loss 4.7775 (4.7775)
2022-11-03 00:49:07,176:INFO: Batch:  1/31	Total Loss 4.6271 (4.6992)
2022-11-03 00:49:07,650:INFO: Batch:  2/31	Total Loss 4.2603 (4.5393)
2022-11-03 00:49:08,120:INFO: Batch:  3/31	Total Loss 4.6931 (4.5801)
2022-11-03 00:49:08,589:INFO: Batch:  4/31	Total Loss 4.6347 (4.5920)
2022-11-03 00:49:09,061:INFO: Batch:  5/31	Total Loss 4.4068 (4.5601)
2022-11-03 00:49:09,530:INFO: Batch:  6/31	Total Loss 3.9648 (4.4765)
2022-11-03 00:49:10,000:INFO: Batch:  7/31	Total Loss 4.3897 (4.4646)
2022-11-03 00:49:10,468:INFO: Batch:  8/31	Total Loss 5.0757 (4.5360)
2022-11-03 00:49:10,935:INFO: Batch:  9/31	Total Loss 5.4648 (4.6264)
2022-11-03 00:49:11,405:INFO: Batch: 10/31	Total Loss 4.9487 (4.6529)
2022-11-03 00:49:11,875:INFO: Batch: 11/31	Total Loss 4.4092 (4.6322)
2022-11-03 00:49:12,347:INFO: Batch: 12/31	Total Loss 4.2780 (4.6026)
2022-11-03 00:49:12,822:INFO: Batch: 13/31	Total Loss 4.9666 (4.6274)
2022-11-03 00:49:13,293:INFO: Batch: 14/31	Total Loss 5.2119 (4.6648)
2022-11-03 00:49:13,767:INFO: Batch: 15/31	Total Loss 4.8130 (4.6749)
2022-11-03 00:49:14,240:INFO: Batch: 16/31	Total Loss 4.6807 (4.6752)
2022-11-03 00:49:14,713:INFO: Batch: 17/31	Total Loss 4.3742 (4.6588)
2022-11-03 00:49:15,185:INFO: Batch: 18/31	Total Loss 4.7677 (4.6647)
2022-11-03 00:49:15,667:INFO: Batch: 19/31	Total Loss 5.1295 (4.6896)
2022-11-03 00:49:16,154:INFO: Batch: 20/31	Total Loss 4.2780 (4.6687)
2022-11-03 00:49:16,639:INFO: Batch: 21/31	Total Loss 4.2753 (4.6519)
2022-11-03 00:49:17,111:INFO: Batch: 22/31	Total Loss 3.3788 (4.5910)
2022-11-03 00:49:17,581:INFO: Batch: 23/31	Total Loss 4.7345 (4.5968)
2022-11-03 00:49:18,052:INFO: Batch: 24/31	Total Loss 4.7852 (4.6041)
2022-11-03 00:49:18,529:INFO: Batch: 25/31	Total Loss 4.6901 (4.6079)
2022-11-03 00:49:19,077:INFO: Batch: 26/31	Total Loss 5.3169 (4.6353)
2022-11-03 00:49:19,558:INFO: Batch: 27/31	Total Loss 5.0688 (4.6501)
2022-11-03 00:49:20,030:INFO: Batch: 28/31	Total Loss 4.5001 (4.6451)
2022-11-03 00:49:20,502:INFO: Batch: 29/31	Total Loss 4.1382 (4.6284)
2022-11-03 00:49:20,888:INFO: Batch: 30/31	Total Loss 1.6315 (4.5995)
2022-11-03 00:49:21,031:INFO: - Computing ADE (validation o)
2022-11-03 00:49:21,623:INFO: 		 ADE on eth                       dataset:	 0.9877398014068604
2022-11-03 00:49:21,623:INFO: Average validation o:	ADE  0.9877	FDE  1.8824
2022-11-03 00:49:21,624:INFO: - Computing ADE (validation)
2022-11-03 00:49:21,889:INFO: 		 ADE on hotel                     dataset:	 0.4968426525592804
2022-11-03 00:49:22,174:INFO: 		 ADE on univ                      dataset:	 0.585763692855835
2022-11-03 00:49:22,433:INFO: 		 ADE on zara1                     dataset:	 0.5164162516593933
2022-11-03 00:49:22,790:INFO: 		 ADE on zara2                     dataset:	 0.46052318811416626
2022-11-03 00:49:22,790:INFO: Average validation:	ADE  0.5309	FDE  1.1093
2022-11-03 00:49:22,791:INFO: - Computing ADE (training)
2022-11-03 00:49:23,268:INFO: 		 ADE on hotel                     dataset:	 0.5344520807266235
2022-11-03 00:49:24,003:INFO: 		 ADE on univ                      dataset:	 0.5735395550727844
2022-11-03 00:49:24,566:INFO: 		 ADE on zara1                     dataset:	 0.5368837118148804
2022-11-03 00:49:25,324:INFO: 		 ADE on zara2                     dataset:	 0.4683493375778198
2022-11-03 00:49:25,324:INFO: Average training:	ADE  0.5489	FDE  1.1507
2022-11-03 00:49:25,333:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_425.pth.tar
2022-11-03 00:49:25,333:INFO: 
===> EPOCH: 426 (P3)
2022-11-03 00:49:25,334:INFO: - Computing loss (training)
2022-11-03 00:49:26,440:INFO: Batch:  0/31	Total Loss 4.7898 (4.7898)
2022-11-03 00:49:26,911:INFO: Batch:  1/31	Total Loss 3.8383 (4.3234)
2022-11-03 00:49:27,388:INFO: Batch:  2/31	Total Loss 4.7247 (4.4601)
2022-11-03 00:49:27,857:INFO: Batch:  3/31	Total Loss 4.9426 (4.5809)
2022-11-03 00:49:28,327:INFO: Batch:  4/31	Total Loss 4.7890 (4.6172)
2022-11-03 00:49:28,805:INFO: Batch:  5/31	Total Loss 4.5119 (4.6006)
2022-11-03 00:49:29,277:INFO: Batch:  6/31	Total Loss 5.3060 (4.7023)
2022-11-03 00:49:29,748:INFO: Batch:  7/31	Total Loss 4.7424 (4.7075)
2022-11-03 00:49:30,221:INFO: Batch:  8/31	Total Loss 4.9386 (4.7325)
2022-11-03 00:49:30,690:INFO: Batch:  9/31	Total Loss 5.0487 (4.7611)
2022-11-03 00:49:31,162:INFO: Batch: 10/31	Total Loss 4.5338 (4.7390)
2022-11-03 00:49:31,633:INFO: Batch: 11/31	Total Loss 3.7802 (4.6584)
2022-11-03 00:49:32,107:INFO: Batch: 12/31	Total Loss 4.7308 (4.6637)
2022-11-03 00:49:32,583:INFO: Batch: 13/31	Total Loss 4.2405 (4.6349)
2022-11-03 00:49:33,059:INFO: Batch: 14/31	Total Loss 4.2145 (4.6051)
2022-11-03 00:49:33,532:INFO: Batch: 15/31	Total Loss 4.2908 (4.5856)
2022-11-03 00:49:34,006:INFO: Batch: 16/31	Total Loss 4.1179 (4.5559)
2022-11-03 00:49:34,479:INFO: Batch: 17/31	Total Loss 5.0256 (4.5817)
2022-11-03 00:49:34,949:INFO: Batch: 18/31	Total Loss 5.1900 (4.6119)
2022-11-03 00:49:35,418:INFO: Batch: 19/31	Total Loss 5.1390 (4.6384)
2022-11-03 00:49:35,887:INFO: Batch: 20/31	Total Loss 3.9877 (4.6090)
2022-11-03 00:49:36,355:INFO: Batch: 21/31	Total Loss 4.6135 (4.6092)
2022-11-03 00:49:36,828:INFO: Batch: 22/31	Total Loss 5.3683 (4.6421)
2022-11-03 00:49:37,300:INFO: Batch: 23/31	Total Loss 4.5708 (4.6390)
2022-11-03 00:49:37,770:INFO: Batch: 24/31	Total Loss 4.1395 (4.6176)
2022-11-03 00:49:38,241:INFO: Batch: 25/31	Total Loss 5.0285 (4.6313)
2022-11-03 00:49:38,708:INFO: Batch: 26/31	Total Loss 4.3643 (4.6216)
2022-11-03 00:49:39,178:INFO: Batch: 27/31	Total Loss 5.6532 (4.6537)
2022-11-03 00:49:39,648:INFO: Batch: 28/31	Total Loss 4.2859 (4.6396)
2022-11-03 00:49:40,118:INFO: Batch: 29/31	Total Loss 5.1850 (4.6578)
2022-11-03 00:49:40,505:INFO: Batch: 30/31	Total Loss 1.4604 (4.6232)
2022-11-03 00:49:40,653:INFO: - Computing ADE (validation o)
2022-11-03 00:49:41,229:INFO: 		 ADE on eth                       dataset:	 1.0098224878311157
2022-11-03 00:49:41,229:INFO: Average validation o:	ADE  1.0098	FDE  1.9218
2022-11-03 00:49:41,230:INFO: - Computing ADE (validation)
2022-11-03 00:49:41,502:INFO: 		 ADE on hotel                     dataset:	 0.5198449492454529
2022-11-03 00:49:41,788:INFO: 		 ADE on univ                      dataset:	 0.5769997835159302
2022-11-03 00:49:42,038:INFO: 		 ADE on zara1                     dataset:	 0.46610233187675476
2022-11-03 00:49:42,393:INFO: 		 ADE on zara2                     dataset:	 0.47245436906814575
2022-11-03 00:49:42,393:INFO: Average validation:	ADE  0.5291	FDE  1.0928
2022-11-03 00:49:42,394:INFO: - Computing ADE (training)
2022-11-03 00:49:42,852:INFO: 		 ADE on hotel                     dataset:	 0.539951741695404
2022-11-03 00:49:43,548:INFO: 		 ADE on univ                      dataset:	 0.5795902609825134
2022-11-03 00:49:44,112:INFO: 		 ADE on zara1                     dataset:	 0.5417544841766357
2022-11-03 00:49:44,840:INFO: 		 ADE on zara2                     dataset:	 0.4788483679294586
2022-11-03 00:49:44,840:INFO: Average training:	ADE  0.5557	FDE  1.1576
2022-11-03 00:49:44,849:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_426.pth.tar
2022-11-03 00:49:44,849:INFO: 
===> EPOCH: 427 (P3)
2022-11-03 00:49:44,849:INFO: - Computing loss (training)
2022-11-03 00:49:45,929:INFO: Batch:  0/31	Total Loss 4.6656 (4.6656)
2022-11-03 00:49:46,404:INFO: Batch:  1/31	Total Loss 5.7737 (5.2522)
2022-11-03 00:49:46,880:INFO: Batch:  2/31	Total Loss 4.4849 (4.9931)
2022-11-03 00:49:47,357:INFO: Batch:  3/31	Total Loss 4.5340 (4.8910)
2022-11-03 00:49:47,827:INFO: Batch:  4/31	Total Loss 3.7710 (4.6698)
2022-11-03 00:49:48,304:INFO: Batch:  5/31	Total Loss 4.8090 (4.6954)
2022-11-03 00:49:48,777:INFO: Batch:  6/31	Total Loss 4.7901 (4.7096)
2022-11-03 00:49:49,248:INFO: Batch:  7/31	Total Loss 4.9198 (4.7353)
2022-11-03 00:49:49,722:INFO: Batch:  8/31	Total Loss 4.7375 (4.7356)
2022-11-03 00:49:50,197:INFO: Batch:  9/31	Total Loss 4.5745 (4.7188)
2022-11-03 00:49:50,677:INFO: Batch: 10/31	Total Loss 3.9595 (4.6508)
2022-11-03 00:49:51,158:INFO: Batch: 11/31	Total Loss 4.7314 (4.6569)
2022-11-03 00:49:51,633:INFO: Batch: 12/31	Total Loss 4.2887 (4.6256)
2022-11-03 00:49:52,103:INFO: Batch: 13/31	Total Loss 4.2877 (4.6009)
2022-11-03 00:49:52,572:INFO: Batch: 14/31	Total Loss 4.3569 (4.5859)
2022-11-03 00:49:53,043:INFO: Batch: 15/31	Total Loss 4.4430 (4.5769)
2022-11-03 00:49:53,513:INFO: Batch: 16/31	Total Loss 4.3648 (4.5635)
2022-11-03 00:49:53,984:INFO: Batch: 17/31	Total Loss 4.7732 (4.5751)
2022-11-03 00:49:54,451:INFO: Batch: 18/31	Total Loss 4.3472 (4.5624)
2022-11-03 00:49:54,921:INFO: Batch: 19/31	Total Loss 6.1956 (4.6322)
2022-11-03 00:49:55,390:INFO: Batch: 20/31	Total Loss 4.5142 (4.6271)
2022-11-03 00:49:55,858:INFO: Batch: 21/31	Total Loss 4.1384 (4.6044)
2022-11-03 00:49:56,327:INFO: Batch: 22/31	Total Loss 4.5460 (4.6020)
2022-11-03 00:49:56,795:INFO: Batch: 23/31	Total Loss 4.4891 (4.5971)
2022-11-03 00:49:57,264:INFO: Batch: 24/31	Total Loss 4.7196 (4.6027)
2022-11-03 00:49:57,734:INFO: Batch: 25/31	Total Loss 5.1787 (4.6235)
2022-11-03 00:49:58,205:INFO: Batch: 26/31	Total Loss 4.5344 (4.6200)
2022-11-03 00:49:58,673:INFO: Batch: 27/31	Total Loss 4.5056 (4.6162)
2022-11-03 00:49:59,143:INFO: Batch: 28/31	Total Loss 4.1122 (4.5982)
2022-11-03 00:49:59,614:INFO: Batch: 29/31	Total Loss 4.3676 (4.5906)
2022-11-03 00:50:00,005:INFO: Batch: 30/31	Total Loss 1.7194 (4.5608)
2022-11-03 00:50:00,152:INFO: - Computing ADE (validation o)
2022-11-03 00:50:00,732:INFO: 		 ADE on eth                       dataset:	 1.0070723295211792
2022-11-03 00:50:00,733:INFO: Average validation o:	ADE  1.0071	FDE  1.9375
2022-11-03 00:50:00,733:INFO: - Computing ADE (validation)
2022-11-03 00:50:00,996:INFO: 		 ADE on hotel                     dataset:	 0.5063494443893433
2022-11-03 00:50:01,294:INFO: 		 ADE on univ                      dataset:	 0.5737318992614746
2022-11-03 00:50:01,536:INFO: 		 ADE on zara1                     dataset:	 0.46547478437423706
2022-11-03 00:50:01,895:INFO: 		 ADE on zara2                     dataset:	 0.4632249176502228
2022-11-03 00:50:01,895:INFO: Average validation:	ADE  0.5232	FDE  1.0853
2022-11-03 00:50:01,896:INFO: - Computing ADE (training)
2022-11-03 00:50:02,352:INFO: 		 ADE on hotel                     dataset:	 0.5301221609115601
2022-11-03 00:50:03,016:INFO: 		 ADE on univ                      dataset:	 0.5737477540969849
2022-11-03 00:50:03,550:INFO: 		 ADE on zara1                     dataset:	 0.529296875
2022-11-03 00:50:04,302:INFO: 		 ADE on zara2                     dataset:	 0.46819791197776794
2022-11-03 00:50:04,302:INFO: Average training:	ADE  0.5484	FDE  1.1456
2022-11-03 00:50:04,311:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_427.pth.tar
2022-11-03 00:50:04,311:INFO: 
===> EPOCH: 428 (P3)
2022-11-03 00:50:04,311:INFO: - Computing loss (training)
2022-11-03 00:50:05,403:INFO: Batch:  0/31	Total Loss 5.4551 (5.4551)
2022-11-03 00:50:05,873:INFO: Batch:  1/31	Total Loss 4.7878 (5.1149)
2022-11-03 00:50:06,345:INFO: Batch:  2/31	Total Loss 4.2603 (4.8284)
2022-11-03 00:50:06,823:INFO: Batch:  3/31	Total Loss 4.6444 (4.7807)
2022-11-03 00:50:07,292:INFO: Batch:  4/31	Total Loss 4.4395 (4.7060)
2022-11-03 00:50:07,766:INFO: Batch:  5/31	Total Loss 4.2897 (4.6362)
2022-11-03 00:50:08,238:INFO: Batch:  6/31	Total Loss 4.1263 (4.5591)
2022-11-03 00:50:08,713:INFO: Batch:  7/31	Total Loss 4.2143 (4.5130)
2022-11-03 00:50:09,181:INFO: Batch:  8/31	Total Loss 4.6422 (4.5271)
2022-11-03 00:50:09,649:INFO: Batch:  9/31	Total Loss 4.2596 (4.5018)
2022-11-03 00:50:10,128:INFO: Batch: 10/31	Total Loss 4.6173 (4.5122)
2022-11-03 00:50:10,674:INFO: Batch: 11/31	Total Loss 4.6383 (4.5234)
2022-11-03 00:50:11,146:INFO: Batch: 12/31	Total Loss 4.2825 (4.5039)
2022-11-03 00:50:11,620:INFO: Batch: 13/31	Total Loss 4.6194 (4.5120)
2022-11-03 00:50:12,094:INFO: Batch: 14/31	Total Loss 4.3435 (4.5003)
2022-11-03 00:50:12,567:INFO: Batch: 15/31	Total Loss 3.9554 (4.4649)
2022-11-03 00:50:13,041:INFO: Batch: 16/31	Total Loss 3.9397 (4.4320)
2022-11-03 00:50:13,514:INFO: Batch: 17/31	Total Loss 4.1792 (4.4194)
2022-11-03 00:50:13,988:INFO: Batch: 18/31	Total Loss 4.0850 (4.4006)
2022-11-03 00:50:14,461:INFO: Batch: 19/31	Total Loss 4.7169 (4.4165)
2022-11-03 00:50:14,935:INFO: Batch: 20/31	Total Loss 4.2606 (4.4087)
2022-11-03 00:50:15,407:INFO: Batch: 21/31	Total Loss 4.5537 (4.4144)
2022-11-03 00:50:15,879:INFO: Batch: 22/31	Total Loss 4.9324 (4.4346)
2022-11-03 00:50:16,355:INFO: Batch: 23/31	Total Loss 4.3552 (4.4312)
2022-11-03 00:50:16,828:INFO: Batch: 24/31	Total Loss 3.9478 (4.4103)
2022-11-03 00:50:17,300:INFO: Batch: 25/31	Total Loss 4.3441 (4.4077)
2022-11-03 00:50:17,773:INFO: Batch: 26/31	Total Loss 4.3143 (4.4042)
2022-11-03 00:50:18,247:INFO: Batch: 27/31	Total Loss 4.8257 (4.4184)
2022-11-03 00:50:18,721:INFO: Batch: 28/31	Total Loss 4.4312 (4.4189)
2022-11-03 00:50:19,197:INFO: Batch: 29/31	Total Loss 5.1267 (4.4430)
2022-11-03 00:50:19,588:INFO: Batch: 30/31	Total Loss 1.7069 (4.4219)
2022-11-03 00:50:19,736:INFO: - Computing ADE (validation o)
2022-11-03 00:50:20,338:INFO: 		 ADE on eth                       dataset:	 0.990682065486908
2022-11-03 00:50:20,338:INFO: Average validation o:	ADE  0.9907	FDE  1.8456
2022-11-03 00:50:20,339:INFO: - Computing ADE (validation)
2022-11-03 00:50:20,607:INFO: 		 ADE on hotel                     dataset:	 0.4629417657852173
2022-11-03 00:50:20,900:INFO: 		 ADE on univ                      dataset:	 0.559050440788269
2022-11-03 00:50:21,150:INFO: 		 ADE on zara1                     dataset:	 0.4671862721443176
2022-11-03 00:50:21,493:INFO: 		 ADE on zara2                     dataset:	 0.42263686656951904
2022-11-03 00:50:21,493:INFO: Average validation:	ADE  0.4984	FDE  1.0052
2022-11-03 00:50:21,494:INFO: - Computing ADE (training)
2022-11-03 00:50:21,946:INFO: 		 ADE on hotel                     dataset:	 0.4893490672111511
2022-11-03 00:50:22,651:INFO: 		 ADE on univ                      dataset:	 0.5472062230110168
2022-11-03 00:50:23,180:INFO: 		 ADE on zara1                     dataset:	 0.5265278816223145
2022-11-03 00:50:23,901:INFO: 		 ADE on zara2                     dataset:	 0.4364785850048065
2022-11-03 00:50:23,901:INFO: Average training:	ADE  0.5219	FDE  1.0618
2022-11-03 00:50:23,910:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_428.pth.tar
2022-11-03 00:50:23,910:INFO: 
===> EPOCH: 429 (P3)
2022-11-03 00:50:23,910:INFO: - Computing loss (training)
2022-11-03 00:50:25,001:INFO: Batch:  0/31	Total Loss 4.2839 (4.2839)
2022-11-03 00:50:25,477:INFO: Batch:  1/31	Total Loss 4.3542 (4.3186)
2022-11-03 00:50:25,954:INFO: Batch:  2/31	Total Loss 4.7146 (4.4585)
2022-11-03 00:50:26,425:INFO: Batch:  3/31	Total Loss 4.0482 (4.3487)
2022-11-03 00:50:26,895:INFO: Batch:  4/31	Total Loss 4.2526 (4.3298)
2022-11-03 00:50:27,369:INFO: Batch:  5/31	Total Loss 4.4185 (4.3436)
2022-11-03 00:50:27,843:INFO: Batch:  6/31	Total Loss 4.2120 (4.3217)
2022-11-03 00:50:28,314:INFO: Batch:  7/31	Total Loss 4.3336 (4.3233)
2022-11-03 00:50:28,786:INFO: Batch:  8/31	Total Loss 4.2470 (4.3157)
2022-11-03 00:50:29,258:INFO: Batch:  9/31	Total Loss 4.1425 (4.2997)
2022-11-03 00:50:29,728:INFO: Batch: 10/31	Total Loss 5.9309 (4.4620)
2022-11-03 00:50:30,208:INFO: Batch: 11/31	Total Loss 4.6295 (4.4742)
2022-11-03 00:50:30,681:INFO: Batch: 12/31	Total Loss 4.1107 (4.4491)
2022-11-03 00:50:31,157:INFO: Batch: 13/31	Total Loss 4.5893 (4.4594)
2022-11-03 00:50:31,630:INFO: Batch: 14/31	Total Loss 4.3219 (4.4501)
2022-11-03 00:50:32,104:INFO: Batch: 15/31	Total Loss 5.6656 (4.5220)
2022-11-03 00:50:32,578:INFO: Batch: 16/31	Total Loss 4.2618 (4.5063)
2022-11-03 00:50:33,054:INFO: Batch: 17/31	Total Loss 4.2442 (4.4931)
2022-11-03 00:50:33,529:INFO: Batch: 18/31	Total Loss 4.1759 (4.4754)
2022-11-03 00:50:34,003:INFO: Batch: 19/31	Total Loss 4.3905 (4.4711)
2022-11-03 00:50:34,478:INFO: Batch: 20/31	Total Loss 4.4919 (4.4721)
2022-11-03 00:50:34,951:INFO: Batch: 21/31	Total Loss 4.7451 (4.4841)
2022-11-03 00:50:35,422:INFO: Batch: 22/31	Total Loss 4.3263 (4.4774)
2022-11-03 00:50:35,895:INFO: Batch: 23/31	Total Loss 4.2693 (4.4688)
2022-11-03 00:50:36,369:INFO: Batch: 24/31	Total Loss 4.0026 (4.4488)
2022-11-03 00:50:36,842:INFO: Batch: 25/31	Total Loss 4.6065 (4.4545)
2022-11-03 00:50:37,316:INFO: Batch: 26/31	Total Loss 4.5739 (4.4589)
2022-11-03 00:50:37,786:INFO: Batch: 27/31	Total Loss 4.0998 (4.4461)
2022-11-03 00:50:38,256:INFO: Batch: 28/31	Total Loss 4.1058 (4.4352)
2022-11-03 00:50:38,729:INFO: Batch: 29/31	Total Loss 4.3606 (4.4328)
2022-11-03 00:50:39,118:INFO: Batch: 30/31	Total Loss 1.8675 (4.4111)
2022-11-03 00:50:39,258:INFO: - Computing ADE (validation o)
2022-11-03 00:50:39,844:INFO: 		 ADE on eth                       dataset:	 1.0034515857696533
2022-11-03 00:50:39,844:INFO: Average validation o:	ADE  1.0035	FDE  1.8910
2022-11-03 00:50:39,845:INFO: - Computing ADE (validation)
2022-11-03 00:50:40,135:INFO: 		 ADE on hotel                     dataset:	 0.47962042689323425
2022-11-03 00:50:40,438:INFO: 		 ADE on univ                      dataset:	 0.5590147376060486
2022-11-03 00:50:40,703:INFO: 		 ADE on zara1                     dataset:	 0.45941224694252014
2022-11-03 00:50:41,047:INFO: 		 ADE on zara2                     dataset:	 0.43927809596061707
2022-11-03 00:50:41,048:INFO: Average validation:	ADE  0.5050	FDE  1.0186
2022-11-03 00:50:41,048:INFO: - Computing ADE (training)
2022-11-03 00:50:41,503:INFO: 		 ADE on hotel                     dataset:	 0.5032252073287964
2022-11-03 00:50:42,189:INFO: 		 ADE on univ                      dataset:	 0.5526853799819946
2022-11-03 00:50:42,719:INFO: 		 ADE on zara1                     dataset:	 0.5394960641860962
2022-11-03 00:50:43,465:INFO: 		 ADE on zara2                     dataset:	 0.45375409722328186
2022-11-03 00:50:43,466:INFO: Average training:	ADE  0.5305	FDE  1.0790
2022-11-03 00:50:43,474:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_429.pth.tar
2022-11-03 00:50:43,474:INFO: 
===> EPOCH: 430 (P3)
2022-11-03 00:50:43,474:INFO: - Computing loss (training)
2022-11-03 00:50:44,652:INFO: Batch:  0/31	Total Loss 3.8468 (3.8468)
2022-11-03 00:50:45,399:INFO: Batch:  1/31	Total Loss 3.9841 (3.9169)
2022-11-03 00:50:45,950:INFO: Batch:  2/31	Total Loss 4.1865 (4.0014)
2022-11-03 00:50:46,468:INFO: Batch:  3/31	Total Loss 4.5778 (4.1464)
2022-11-03 00:50:46,967:INFO: Batch:  4/31	Total Loss 4.2503 (4.1667)
2022-11-03 00:50:47,440:INFO: Batch:  5/31	Total Loss 4.2701 (4.1810)
2022-11-03 00:50:47,916:INFO: Batch:  6/31	Total Loss 4.7746 (4.2682)
2022-11-03 00:50:48,426:INFO: Batch:  7/31	Total Loss 4.2685 (4.2683)
2022-11-03 00:50:48,907:INFO: Batch:  8/31	Total Loss 4.6891 (4.3147)
2022-11-03 00:50:49,391:INFO: Batch:  9/31	Total Loss 4.5754 (4.3403)
2022-11-03 00:50:49,901:INFO: Batch: 10/31	Total Loss 4.9922 (4.3869)
2022-11-03 00:50:50,434:INFO: Batch: 11/31	Total Loss 5.4742 (4.4675)
2022-11-03 00:50:50,925:INFO: Batch: 12/31	Total Loss 4.5706 (4.4766)
2022-11-03 00:50:51,449:INFO: Batch: 13/31	Total Loss 3.9614 (4.4386)
2022-11-03 00:50:51,968:INFO: Batch: 14/31	Total Loss 3.9341 (4.4031)
2022-11-03 00:50:52,457:INFO: Batch: 15/31	Total Loss 4.1291 (4.3857)
2022-11-03 00:50:52,950:INFO: Batch: 16/31	Total Loss 4.4805 (4.3914)
2022-11-03 00:50:53,469:INFO: Batch: 17/31	Total Loss 4.0791 (4.3729)
2022-11-03 00:50:53,961:INFO: Batch: 18/31	Total Loss 5.0285 (4.4042)
2022-11-03 00:50:54,478:INFO: Batch: 19/31	Total Loss 4.1641 (4.3914)
2022-11-03 00:50:55,079:INFO: Batch: 20/31	Total Loss 4.5709 (4.3995)
2022-11-03 00:50:55,746:INFO: Batch: 21/31	Total Loss 4.4511 (4.4020)
2022-11-03 00:50:56,228:INFO: Batch: 22/31	Total Loss 4.3687 (4.4006)
2022-11-03 00:50:56,707:INFO: Batch: 23/31	Total Loss 4.5245 (4.4061)
2022-11-03 00:50:57,183:INFO: Batch: 24/31	Total Loss 4.4200 (4.4066)
2022-11-03 00:50:57,668:INFO: Batch: 25/31	Total Loss 5.0391 (4.4313)
2022-11-03 00:50:58,153:INFO: Batch: 26/31	Total Loss 4.3654 (4.4288)
2022-11-03 00:50:58,628:INFO: Batch: 27/31	Total Loss 3.9890 (4.4135)
2022-11-03 00:50:59,107:INFO: Batch: 28/31	Total Loss 3.9888 (4.3991)
2022-11-03 00:50:59,587:INFO: Batch: 29/31	Total Loss 4.4925 (4.4027)
2022-11-03 00:50:59,983:INFO: Batch: 30/31	Total Loss 1.7693 (4.3749)
2022-11-03 00:51:00,142:INFO: - Computing ADE (validation o)
2022-11-03 00:51:00,750:INFO: 		 ADE on eth                       dataset:	 0.9829056262969971
2022-11-03 00:51:00,751:INFO: Average validation o:	ADE  0.9829	FDE  1.8404
2022-11-03 00:51:00,751:INFO: - Computing ADE (validation)
2022-11-03 00:51:01,016:INFO: 		 ADE on hotel                     dataset:	 0.46648964285850525
2022-11-03 00:51:01,326:INFO: 		 ADE on univ                      dataset:	 0.5592435598373413
2022-11-03 00:51:01,607:INFO: 		 ADE on zara1                     dataset:	 0.4541679918766022
2022-11-03 00:51:01,948:INFO: 		 ADE on zara2                     dataset:	 0.4288080930709839
2022-11-03 00:51:01,949:INFO: Average validation:	ADE  0.5002	FDE  1.0033
2022-11-03 00:51:01,949:INFO: - Computing ADE (training)
2022-11-03 00:51:02,399:INFO: 		 ADE on hotel                     dataset:	 0.49519363045692444
2022-11-03 00:51:03,144:INFO: 		 ADE on univ                      dataset:	 0.5486770868301392
2022-11-03 00:51:03,724:INFO: 		 ADE on zara1                     dataset:	 0.5313978791236877
2022-11-03 00:51:04,507:INFO: 		 ADE on zara2                     dataset:	 0.4430498778820038
2022-11-03 00:51:04,507:INFO: Average training:	ADE  0.5248	FDE  1.0628
2022-11-03 00:51:04,516:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_430.pth.tar
2022-11-03 00:51:04,516:INFO: 
===> EPOCH: 431 (P3)
2022-11-03 00:51:04,516:INFO: - Computing loss (training)
2022-11-03 00:51:05,686:INFO: Batch:  0/31	Total Loss 4.6041 (4.6041)
2022-11-03 00:51:06,153:INFO: Batch:  1/31	Total Loss 4.8213 (4.7136)
2022-11-03 00:51:06,628:INFO: Batch:  2/31	Total Loss 4.0679 (4.4765)
2022-11-03 00:51:07,098:INFO: Batch:  3/31	Total Loss 4.1714 (4.3988)
2022-11-03 00:51:07,568:INFO: Batch:  4/31	Total Loss 4.1987 (4.3592)
2022-11-03 00:51:08,041:INFO: Batch:  5/31	Total Loss 4.6413 (4.4038)
2022-11-03 00:51:08,509:INFO: Batch:  6/31	Total Loss 4.6218 (4.4362)
2022-11-03 00:51:08,977:INFO: Batch:  7/31	Total Loss 4.3117 (4.4221)
2022-11-03 00:51:09,444:INFO: Batch:  8/31	Total Loss 4.4202 (4.4219)
2022-11-03 00:51:09,914:INFO: Batch:  9/31	Total Loss 3.8869 (4.3655)
2022-11-03 00:51:10,386:INFO: Batch: 10/31	Total Loss 4.4748 (4.3757)
2022-11-03 00:51:10,853:INFO: Batch: 11/31	Total Loss 4.3411 (4.3731)
2022-11-03 00:51:11,324:INFO: Batch: 12/31	Total Loss 5.2156 (4.4433)
2022-11-03 00:51:11,795:INFO: Batch: 13/31	Total Loss 4.5081 (4.4477)
2022-11-03 00:51:12,267:INFO: Batch: 14/31	Total Loss 4.0514 (4.4213)
2022-11-03 00:51:12,738:INFO: Batch: 15/31	Total Loss 4.8186 (4.4469)
2022-11-03 00:51:13,209:INFO: Batch: 16/31	Total Loss 4.7910 (4.4648)
2022-11-03 00:51:13,681:INFO: Batch: 17/31	Total Loss 4.1339 (4.4472)
2022-11-03 00:51:14,151:INFO: Batch: 18/31	Total Loss 3.9079 (4.4197)
2022-11-03 00:51:14,623:INFO: Batch: 19/31	Total Loss 4.7810 (4.4389)
2022-11-03 00:51:15,092:INFO: Batch: 20/31	Total Loss 4.2009 (4.4275)
2022-11-03 00:51:15,563:INFO: Batch: 21/31	Total Loss 3.9361 (4.4049)
2022-11-03 00:51:16,032:INFO: Batch: 22/31	Total Loss 4.8026 (4.4216)
2022-11-03 00:51:16,504:INFO: Batch: 23/31	Total Loss 4.9022 (4.4421)
2022-11-03 00:51:16,974:INFO: Batch: 24/31	Total Loss 4.3033 (4.4363)
2022-11-03 00:51:17,446:INFO: Batch: 25/31	Total Loss 4.1323 (4.4256)
2022-11-03 00:51:17,916:INFO: Batch: 26/31	Total Loss 4.8801 (4.4419)
2022-11-03 00:51:18,386:INFO: Batch: 27/31	Total Loss 4.0517 (4.4268)
2022-11-03 00:51:18,857:INFO: Batch: 28/31	Total Loss 4.6513 (4.4349)
2022-11-03 00:51:19,326:INFO: Batch: 29/31	Total Loss 4.2955 (4.4303)
2022-11-03 00:51:19,713:INFO: Batch: 30/31	Total Loss 1.9257 (4.4136)
2022-11-03 00:51:19,871:INFO: - Computing ADE (validation o)
2022-11-03 00:51:20,510:INFO: 		 ADE on eth                       dataset:	 1.0014011859893799
2022-11-03 00:51:20,511:INFO: Average validation o:	ADE  1.0014	FDE  1.8530
2022-11-03 00:51:20,511:INFO: - Computing ADE (validation)
2022-11-03 00:51:20,793:INFO: 		 ADE on hotel                     dataset:	 0.47548946738243103
2022-11-03 00:51:21,095:INFO: 		 ADE on univ                      dataset:	 0.5623843669891357
2022-11-03 00:51:21,357:INFO: 		 ADE on zara1                     dataset:	 0.4851759970188141
2022-11-03 00:51:21,703:INFO: 		 ADE on zara2                     dataset:	 0.43319171667099
2022-11-03 00:51:21,703:INFO: Average validation:	ADE  0.5057	FDE  1.0119
2022-11-03 00:51:21,704:INFO: - Computing ADE (training)
2022-11-03 00:51:22,170:INFO: 		 ADE on hotel                     dataset:	 0.5101948380470276
2022-11-03 00:51:22,843:INFO: 		 ADE on univ                      dataset:	 0.5486505627632141
2022-11-03 00:51:23,419:INFO: 		 ADE on zara1                     dataset:	 0.5566505193710327
2022-11-03 00:51:24,153:INFO: 		 ADE on zara2                     dataset:	 0.4556989371776581
2022-11-03 00:51:24,154:INFO: Average training:	ADE  0.5293	FDE  1.0671
2022-11-03 00:51:24,162:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_431.pth.tar
2022-11-03 00:51:24,163:INFO: 
===> EPOCH: 432 (P3)
2022-11-03 00:51:24,163:INFO: - Computing loss (training)
2022-11-03 00:51:25,242:INFO: Batch:  0/31	Total Loss 6.0996 (6.0996)
2022-11-03 00:51:25,711:INFO: Batch:  1/31	Total Loss 4.3466 (5.1732)
2022-11-03 00:51:26,193:INFO: Batch:  2/31	Total Loss 4.6193 (4.9690)
2022-11-03 00:51:26,668:INFO: Batch:  3/31	Total Loss 4.2180 (4.7684)
2022-11-03 00:51:27,141:INFO: Batch:  4/31	Total Loss 4.7727 (4.7693)
2022-11-03 00:51:27,621:INFO: Batch:  5/31	Total Loss 4.7652 (4.7686)
2022-11-03 00:51:28,096:INFO: Batch:  6/31	Total Loss 3.9244 (4.6428)
2022-11-03 00:51:28,576:INFO: Batch:  7/31	Total Loss 4.5704 (4.6342)
2022-11-03 00:51:29,051:INFO: Batch:  8/31	Total Loss 4.7453 (4.6467)
2022-11-03 00:51:29,534:INFO: Batch:  9/31	Total Loss 4.6745 (4.6497)
2022-11-03 00:51:30,018:INFO: Batch: 10/31	Total Loss 3.8605 (4.5767)
2022-11-03 00:51:30,512:INFO: Batch: 11/31	Total Loss 4.4123 (4.5623)
2022-11-03 00:51:30,994:INFO: Batch: 12/31	Total Loss 4.0873 (4.5252)
2022-11-03 00:51:31,476:INFO: Batch: 13/31	Total Loss 4.7819 (4.5439)
2022-11-03 00:51:31,957:INFO: Batch: 14/31	Total Loss 3.8809 (4.4996)
2022-11-03 00:51:32,435:INFO: Batch: 15/31	Total Loss 4.9530 (4.5303)
2022-11-03 00:51:32,908:INFO: Batch: 16/31	Total Loss 3.9780 (4.4996)
2022-11-03 00:51:33,377:INFO: Batch: 17/31	Total Loss 4.2147 (4.4833)
2022-11-03 00:51:33,848:INFO: Batch: 18/31	Total Loss 4.4817 (4.4833)
2022-11-03 00:51:34,329:INFO: Batch: 19/31	Total Loss 4.8392 (4.5027)
2022-11-03 00:51:34,799:INFO: Batch: 20/31	Total Loss 3.9760 (4.4793)
2022-11-03 00:51:35,270:INFO: Batch: 21/31	Total Loss 4.4814 (4.4794)
2022-11-03 00:51:35,742:INFO: Batch: 22/31	Total Loss 4.3974 (4.4757)
2022-11-03 00:51:36,214:INFO: Batch: 23/31	Total Loss 4.3821 (4.4719)
2022-11-03 00:51:36,683:INFO: Batch: 24/31	Total Loss 4.7834 (4.4846)
2022-11-03 00:51:37,162:INFO: Batch: 25/31	Total Loss 3.9405 (4.4649)
2022-11-03 00:51:37,632:INFO: Batch: 26/31	Total Loss 4.1848 (4.4528)
2022-11-03 00:51:38,103:INFO: Batch: 27/31	Total Loss 4.5236 (4.4553)
2022-11-03 00:51:38,573:INFO: Batch: 28/31	Total Loss 6.0519 (4.5099)
2022-11-03 00:51:39,046:INFO: Batch: 29/31	Total Loss 4.8638 (4.5210)
2022-11-03 00:51:39,434:INFO: Batch: 30/31	Total Loss 1.7732 (4.4976)
2022-11-03 00:51:39,586:INFO: - Computing ADE (validation o)
2022-11-03 00:51:40,170:INFO: 		 ADE on eth                       dataset:	 0.9904873371124268
2022-11-03 00:51:40,170:INFO: Average validation o:	ADE  0.9905	FDE  1.8103
2022-11-03 00:51:40,171:INFO: - Computing ADE (validation)
2022-11-03 00:51:40,443:INFO: 		 ADE on hotel                     dataset:	 0.5030003190040588
2022-11-03 00:51:40,724:INFO: 		 ADE on univ                      dataset:	 0.5696327686309814
2022-11-03 00:51:40,984:INFO: 		 ADE on zara1                     dataset:	 0.4504794180393219
2022-11-03 00:51:41,342:INFO: 		 ADE on zara2                     dataset:	 0.4405413568019867
2022-11-03 00:51:41,342:INFO: Average validation:	ADE  0.5117	FDE  1.0257
2022-11-03 00:51:41,352:INFO: - Computing ADE (training)
2022-11-03 00:51:41,795:INFO: 		 ADE on hotel                     dataset:	 0.5420121550559998
2022-11-03 00:51:42,469:INFO: 		 ADE on univ                      dataset:	 0.5566726326942444
2022-11-03 00:51:43,047:INFO: 		 ADE on zara1                     dataset:	 0.5516443848609924
2022-11-03 00:51:43,785:INFO: 		 ADE on zara2                     dataset:	 0.4571787416934967
2022-11-03 00:51:43,786:INFO: Average training:	ADE  0.5358	FDE  1.0807
2022-11-03 00:51:43,794:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_432.pth.tar
2022-11-03 00:51:43,794:INFO: 
===> EPOCH: 433 (P3)
2022-11-03 00:51:43,795:INFO: - Computing loss (training)
2022-11-03 00:51:44,896:INFO: Batch:  0/31	Total Loss 5.0173 (5.0173)
2022-11-03 00:51:45,366:INFO: Batch:  1/31	Total Loss 4.0769 (4.5340)
2022-11-03 00:51:45,839:INFO: Batch:  2/31	Total Loss 4.5962 (4.5527)
2022-11-03 00:51:46,307:INFO: Batch:  3/31	Total Loss 4.3846 (4.5115)
2022-11-03 00:51:46,777:INFO: Batch:  4/31	Total Loss 4.1650 (4.4482)
2022-11-03 00:51:47,249:INFO: Batch:  5/31	Total Loss 4.0617 (4.3817)
2022-11-03 00:51:47,718:INFO: Batch:  6/31	Total Loss 4.4927 (4.3968)
2022-11-03 00:51:48,188:INFO: Batch:  7/31	Total Loss 4.5096 (4.4108)
2022-11-03 00:51:48,654:INFO: Batch:  8/31	Total Loss 4.5240 (4.4235)
2022-11-03 00:51:49,119:INFO: Batch:  9/31	Total Loss 4.7224 (4.4552)
2022-11-03 00:51:49,588:INFO: Batch: 10/31	Total Loss 4.2616 (4.4366)
2022-11-03 00:51:50,058:INFO: Batch: 11/31	Total Loss 3.8022 (4.3867)
2022-11-03 00:51:50,531:INFO: Batch: 12/31	Total Loss 4.2715 (4.3768)
2022-11-03 00:51:51,003:INFO: Batch: 13/31	Total Loss 4.5222 (4.3871)
2022-11-03 00:51:51,471:INFO: Batch: 14/31	Total Loss 4.7015 (4.4090)
2022-11-03 00:51:51,944:INFO: Batch: 15/31	Total Loss 4.9995 (4.4454)
2022-11-03 00:51:52,417:INFO: Batch: 16/31	Total Loss 4.7650 (4.4630)
2022-11-03 00:51:52,887:INFO: Batch: 17/31	Total Loss 4.3415 (4.4560)
2022-11-03 00:51:53,359:INFO: Batch: 18/31	Total Loss 4.1408 (4.4395)
2022-11-03 00:51:53,830:INFO: Batch: 19/31	Total Loss 5.1348 (4.4745)
2022-11-03 00:51:54,300:INFO: Batch: 20/31	Total Loss 4.3778 (4.4704)
2022-11-03 00:51:54,770:INFO: Batch: 21/31	Total Loss 4.1879 (4.4585)
2022-11-03 00:51:55,323:INFO: Batch: 22/31	Total Loss 4.5275 (4.4612)
2022-11-03 00:51:55,795:INFO: Batch: 23/31	Total Loss 4.5660 (4.4649)
2022-11-03 00:51:56,273:INFO: Batch: 24/31	Total Loss 4.3114 (4.4594)
2022-11-03 00:51:56,744:INFO: Batch: 25/31	Total Loss 4.2298 (4.4495)
2022-11-03 00:51:57,215:INFO: Batch: 26/31	Total Loss 4.4318 (4.4489)
2022-11-03 00:51:57,684:INFO: Batch: 27/31	Total Loss 5.2138 (4.4756)
2022-11-03 00:51:58,154:INFO: Batch: 28/31	Total Loss 4.2073 (4.4668)
2022-11-03 00:51:58,622:INFO: Batch: 29/31	Total Loss 4.0739 (4.4536)
2022-11-03 00:51:59,007:INFO: Batch: 30/31	Total Loss 1.5437 (4.4195)
2022-11-03 00:51:59,160:INFO: - Computing ADE (validation o)
2022-11-03 00:51:59,756:INFO: 		 ADE on eth                       dataset:	 0.9805677533149719
2022-11-03 00:51:59,757:INFO: Average validation o:	ADE  0.9806	FDE  1.8474
2022-11-03 00:51:59,757:INFO: - Computing ADE (validation)
2022-11-03 00:52:00,018:INFO: 		 ADE on hotel                     dataset:	 0.4521408677101135
2022-11-03 00:52:00,319:INFO: 		 ADE on univ                      dataset:	 0.55583655834198
2022-11-03 00:52:00,561:INFO: 		 ADE on zara1                     dataset:	 0.4619579315185547
2022-11-03 00:52:00,899:INFO: 		 ADE on zara2                     dataset:	 0.4264196753501892
2022-11-03 00:52:00,899:INFO: Average validation:	ADE  0.4972	FDE  1.0107
2022-11-03 00:52:00,900:INFO: - Computing ADE (training)
2022-11-03 00:52:01,369:INFO: 		 ADE on hotel                     dataset:	 0.4792811870574951
2022-11-03 00:52:02,051:INFO: 		 ADE on univ                      dataset:	 0.5481516718864441
2022-11-03 00:52:02,573:INFO: 		 ADE on zara1                     dataset:	 0.5258041024208069
2022-11-03 00:52:03,335:INFO: 		 ADE on zara2                     dataset:	 0.4398908019065857
2022-11-03 00:52:03,335:INFO: Average training:	ADE  0.5230	FDE  1.0726
2022-11-03 00:52:03,344:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_433.pth.tar
2022-11-03 00:52:03,344:INFO: 
===> EPOCH: 434 (P3)
2022-11-03 00:52:03,345:INFO: - Computing loss (training)
2022-11-03 00:52:04,449:INFO: Batch:  0/31	Total Loss 4.1066 (4.1066)
2022-11-03 00:52:04,916:INFO: Batch:  1/31	Total Loss 5.4248 (4.7407)
2022-11-03 00:52:05,386:INFO: Batch:  2/31	Total Loss 4.1010 (4.5277)
2022-11-03 00:52:05,859:INFO: Batch:  3/31	Total Loss 4.2980 (4.4759)
2022-11-03 00:52:06,327:INFO: Batch:  4/31	Total Loss 4.6090 (4.5015)
2022-11-03 00:52:06,798:INFO: Batch:  5/31	Total Loss 4.9674 (4.5805)
2022-11-03 00:52:07,270:INFO: Batch:  6/31	Total Loss 4.3287 (4.5441)
2022-11-03 00:52:07,735:INFO: Batch:  7/31	Total Loss 3.9348 (4.4755)
2022-11-03 00:52:08,209:INFO: Batch:  8/31	Total Loss 3.7422 (4.4020)
2022-11-03 00:52:08,680:INFO: Batch:  9/31	Total Loss 4.5009 (4.4113)
2022-11-03 00:52:09,151:INFO: Batch: 10/31	Total Loss 4.2945 (4.4007)
2022-11-03 00:52:09,619:INFO: Batch: 11/31	Total Loss 3.8237 (4.3544)
2022-11-03 00:52:10,095:INFO: Batch: 12/31	Total Loss 4.0047 (4.3292)
2022-11-03 00:52:10,570:INFO: Batch: 13/31	Total Loss 4.4072 (4.3349)
2022-11-03 00:52:11,044:INFO: Batch: 14/31	Total Loss 4.1934 (4.3260)
2022-11-03 00:52:11,518:INFO: Batch: 15/31	Total Loss 3.7823 (4.2937)
2022-11-03 00:52:11,995:INFO: Batch: 16/31	Total Loss 4.2221 (4.2892)
2022-11-03 00:52:12,470:INFO: Batch: 17/31	Total Loss 4.6531 (4.3050)
2022-11-03 00:52:12,946:INFO: Batch: 18/31	Total Loss 4.9718 (4.3371)
2022-11-03 00:52:13,420:INFO: Batch: 19/31	Total Loss 4.7419 (4.3591)
2022-11-03 00:52:13,896:INFO: Batch: 20/31	Total Loss 4.6311 (4.3726)
2022-11-03 00:52:14,371:INFO: Batch: 21/31	Total Loss 4.9339 (4.3975)
2022-11-03 00:52:14,846:INFO: Batch: 22/31	Total Loss 5.0599 (4.4242)
2022-11-03 00:52:15,318:INFO: Batch: 23/31	Total Loss 5.5752 (4.4736)
2022-11-03 00:52:15,793:INFO: Batch: 24/31	Total Loss 4.6623 (4.4808)
2022-11-03 00:52:16,269:INFO: Batch: 25/31	Total Loss 4.4116 (4.4781)
2022-11-03 00:52:16,743:INFO: Batch: 26/31	Total Loss 4.5410 (4.4804)
2022-11-03 00:52:17,217:INFO: Batch: 27/31	Total Loss 4.5164 (4.4817)
2022-11-03 00:52:17,690:INFO: Batch: 28/31	Total Loss 4.2662 (4.4742)
2022-11-03 00:52:18,163:INFO: Batch: 29/31	Total Loss 4.1596 (4.4648)
2022-11-03 00:52:18,551:INFO: Batch: 30/31	Total Loss 1.7946 (4.4336)
2022-11-03 00:52:18,694:INFO: - Computing ADE (validation o)
2022-11-03 00:52:19,262:INFO: 		 ADE on eth                       dataset:	 0.9853923916816711
2022-11-03 00:52:19,262:INFO: Average validation o:	ADE  0.9854	FDE  1.8370
2022-11-03 00:52:19,263:INFO: - Computing ADE (validation)
2022-11-03 00:52:19,526:INFO: 		 ADE on hotel                     dataset:	 0.48637059330940247
2022-11-03 00:52:19,823:INFO: 		 ADE on univ                      dataset:	 0.5741758942604065
2022-11-03 00:52:20,078:INFO: 		 ADE on zara1                     dataset:	 0.47955310344696045
2022-11-03 00:52:20,428:INFO: 		 ADE on zara2                     dataset:	 0.42334312200546265
2022-11-03 00:52:20,428:INFO: Average validation:	ADE  0.5085	FDE  1.0325
2022-11-03 00:52:20,429:INFO: - Computing ADE (training)
2022-11-03 00:52:20,871:INFO: 		 ADE on hotel                     dataset:	 0.5317575335502625
2022-11-03 00:52:21,556:INFO: 		 ADE on univ                      dataset:	 0.5521213412284851
2022-11-03 00:52:22,076:INFO: 		 ADE on zara1                     dataset:	 0.5371133089065552
2022-11-03 00:52:22,803:INFO: 		 ADE on zara2                     dataset:	 0.4413605332374573
2022-11-03 00:52:22,804:INFO: Average training:	ADE  0.5282	FDE  1.0755
2022-11-03 00:52:22,812:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_434.pth.tar
2022-11-03 00:52:22,812:INFO: 
===> EPOCH: 435 (P3)
2022-11-03 00:52:22,813:INFO: - Computing loss (training)
2022-11-03 00:52:23,885:INFO: Batch:  0/31	Total Loss 4.2578 (4.2578)
2022-11-03 00:52:24,360:INFO: Batch:  1/31	Total Loss 4.5140 (4.3804)
2022-11-03 00:52:24,834:INFO: Batch:  2/31	Total Loss 3.7651 (4.1744)
2022-11-03 00:52:25,319:INFO: Batch:  3/31	Total Loss 3.9755 (4.1254)
2022-11-03 00:52:25,786:INFO: Batch:  4/31	Total Loss 4.5354 (4.2093)
2022-11-03 00:52:26,260:INFO: Batch:  5/31	Total Loss 4.0904 (4.1925)
2022-11-03 00:52:26,728:INFO: Batch:  6/31	Total Loss 4.0902 (4.1762)
2022-11-03 00:52:27,196:INFO: Batch:  7/31	Total Loss 5.6630 (4.3678)
2022-11-03 00:52:27,663:INFO: Batch:  8/31	Total Loss 4.6987 (4.4057)
2022-11-03 00:52:28,131:INFO: Batch:  9/31	Total Loss 4.5688 (4.4227)
2022-11-03 00:52:28,598:INFO: Batch: 10/31	Total Loss 4.6071 (4.4378)
2022-11-03 00:52:29,068:INFO: Batch: 11/31	Total Loss 4.5673 (4.4482)
2022-11-03 00:52:29,540:INFO: Batch: 12/31	Total Loss 3.7103 (4.3842)
2022-11-03 00:52:30,015:INFO: Batch: 13/31	Total Loss 4.8410 (4.4158)
2022-11-03 00:52:30,491:INFO: Batch: 14/31	Total Loss 4.1354 (4.3947)
2022-11-03 00:52:30,966:INFO: Batch: 15/31	Total Loss 5.2249 (4.4420)
2022-11-03 00:52:31,440:INFO: Batch: 16/31	Total Loss 3.6815 (4.3973)
2022-11-03 00:52:31,913:INFO: Batch: 17/31	Total Loss 4.0310 (4.3771)
2022-11-03 00:52:32,387:INFO: Batch: 18/31	Total Loss 5.4810 (4.4335)
2022-11-03 00:52:32,861:INFO: Batch: 19/31	Total Loss 3.6182 (4.3946)
2022-11-03 00:52:33,333:INFO: Batch: 20/31	Total Loss 4.1494 (4.3816)
2022-11-03 00:52:33,805:INFO: Batch: 21/31	Total Loss 3.8638 (4.3587)
2022-11-03 00:52:34,284:INFO: Batch: 22/31	Total Loss 4.4545 (4.3625)
2022-11-03 00:52:34,758:INFO: Batch: 23/31	Total Loss 4.3056 (4.3601)
2022-11-03 00:52:35,230:INFO: Batch: 24/31	Total Loss 4.5831 (4.3689)
2022-11-03 00:52:35,701:INFO: Batch: 25/31	Total Loss 4.4241 (4.3708)
2022-11-03 00:52:36,172:INFO: Batch: 26/31	Total Loss 4.6200 (4.3794)
2022-11-03 00:52:36,643:INFO: Batch: 27/31	Total Loss 5.1179 (4.4053)
2022-11-03 00:52:37,113:INFO: Batch: 28/31	Total Loss 4.5357 (4.4096)
2022-11-03 00:52:37,584:INFO: Batch: 29/31	Total Loss 5.2928 (4.4406)
2022-11-03 00:52:37,973:INFO: Batch: 30/31	Total Loss 1.8652 (4.4177)
2022-11-03 00:52:38,118:INFO: - Computing ADE (validation o)
2022-11-03 00:52:38,692:INFO: 		 ADE on eth                       dataset:	 0.9782830476760864
2022-11-03 00:52:38,692:INFO: Average validation o:	ADE  0.9783	FDE  1.8369
2022-11-03 00:52:38,693:INFO: - Computing ADE (validation)
2022-11-03 00:52:38,963:INFO: 		 ADE on hotel                     dataset:	 0.4622718095779419
2022-11-03 00:52:39,255:INFO: 		 ADE on univ                      dataset:	 0.5553932189941406
2022-11-03 00:52:39,515:INFO: 		 ADE on zara1                     dataset:	 0.46073034405708313
2022-11-03 00:52:39,876:INFO: 		 ADE on zara2                     dataset:	 0.41534557938575745
2022-11-03 00:52:39,876:INFO: Average validation:	ADE  0.4934	FDE  0.9943
2022-11-03 00:52:39,877:INFO: - Computing ADE (training)
2022-11-03 00:52:40,334:INFO: 		 ADE on hotel                     dataset:	 0.4918365776538849
2022-11-03 00:52:41,040:INFO: 		 ADE on univ                      dataset:	 0.5429644584655762
2022-11-03 00:52:41,597:INFO: 		 ADE on zara1                     dataset:	 0.5236178636550903
2022-11-03 00:52:42,333:INFO: 		 ADE on zara2                     dataset:	 0.43129000067710876
2022-11-03 00:52:42,334:INFO: Average training:	ADE  0.5178	FDE  1.0511
2022-11-03 00:52:42,342:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_435.pth.tar
2022-11-03 00:52:42,342:INFO: 
===> EPOCH: 436 (P3)
2022-11-03 00:52:42,342:INFO: - Computing loss (training)
2022-11-03 00:52:43,437:INFO: Batch:  0/31	Total Loss 4.4002 (4.4002)
2022-11-03 00:52:43,923:INFO: Batch:  1/31	Total Loss 3.9695 (4.1996)
2022-11-03 00:52:44,399:INFO: Batch:  2/31	Total Loss 4.5851 (4.3396)
2022-11-03 00:52:44,867:INFO: Batch:  3/31	Total Loss 4.4340 (4.3633)
2022-11-03 00:52:45,337:INFO: Batch:  4/31	Total Loss 3.6578 (4.2301)
2022-11-03 00:52:45,811:INFO: Batch:  5/31	Total Loss 4.6631 (4.2955)
2022-11-03 00:52:46,283:INFO: Batch:  6/31	Total Loss 4.2394 (4.2877)
2022-11-03 00:52:46,751:INFO: Batch:  7/31	Total Loss 4.2626 (4.2845)
2022-11-03 00:52:47,223:INFO: Batch:  8/31	Total Loss 4.5275 (4.3132)
2022-11-03 00:52:47,694:INFO: Batch:  9/31	Total Loss 4.5815 (4.3400)
2022-11-03 00:52:48,163:INFO: Batch: 10/31	Total Loss 4.1150 (4.3170)
2022-11-03 00:52:48,710:INFO: Batch: 11/31	Total Loss 4.0925 (4.2974)
2022-11-03 00:52:49,185:INFO: Batch: 12/31	Total Loss 4.0941 (4.2821)
2022-11-03 00:52:49,658:INFO: Batch: 13/31	Total Loss 3.8924 (4.2578)
2022-11-03 00:52:50,134:INFO: Batch: 14/31	Total Loss 4.0896 (4.2463)
2022-11-03 00:52:50,608:INFO: Batch: 15/31	Total Loss 4.7711 (4.2738)
2022-11-03 00:52:51,082:INFO: Batch: 16/31	Total Loss 4.0530 (4.2607)
2022-11-03 00:52:51,556:INFO: Batch: 17/31	Total Loss 4.0204 (4.2465)
2022-11-03 00:52:52,030:INFO: Batch: 18/31	Total Loss 4.4474 (4.2582)
2022-11-03 00:52:52,506:INFO: Batch: 19/31	Total Loss 3.9780 (4.2427)
2022-11-03 00:52:52,981:INFO: Batch: 20/31	Total Loss 5.0985 (4.2834)
2022-11-03 00:52:53,455:INFO: Batch: 21/31	Total Loss 4.0615 (4.2735)
2022-11-03 00:52:53,928:INFO: Batch: 22/31	Total Loss 4.7791 (4.2942)
2022-11-03 00:52:54,400:INFO: Batch: 23/31	Total Loss 4.3188 (4.2952)
2022-11-03 00:52:54,876:INFO: Batch: 24/31	Total Loss 4.6716 (4.3095)
2022-11-03 00:52:55,349:INFO: Batch: 25/31	Total Loss 4.1832 (4.3043)
2022-11-03 00:52:55,822:INFO: Batch: 26/31	Total Loss 3.9501 (4.2904)
2022-11-03 00:52:56,296:INFO: Batch: 27/31	Total Loss 5.1746 (4.3247)
2022-11-03 00:52:56,770:INFO: Batch: 28/31	Total Loss 4.0724 (4.3156)
2022-11-03 00:52:57,242:INFO: Batch: 29/31	Total Loss 4.4480 (4.3197)
2022-11-03 00:52:57,631:INFO: Batch: 30/31	Total Loss 1.5449 (4.2915)
2022-11-03 00:52:57,780:INFO: - Computing ADE (validation o)
2022-11-03 00:52:58,373:INFO: 		 ADE on eth                       dataset:	 1.0038944482803345
2022-11-03 00:52:58,374:INFO: Average validation o:	ADE  1.0039	FDE  1.8707
2022-11-03 00:52:58,374:INFO: - Computing ADE (validation)
2022-11-03 00:52:58,647:INFO: 		 ADE on hotel                     dataset:	 0.4744715690612793
2022-11-03 00:52:58,926:INFO: 		 ADE on univ                      dataset:	 0.5566097497940063
2022-11-03 00:52:59,188:INFO: 		 ADE on zara1                     dataset:	 0.4599642753601074
2022-11-03 00:52:59,530:INFO: 		 ADE on zara2                     dataset:	 0.43941426277160645
2022-11-03 00:52:59,531:INFO: Average validation:	ADE  0.5035	FDE  1.0165
2022-11-03 00:52:59,531:INFO: - Computing ADE (training)
2022-11-03 00:52:59,961:INFO: 		 ADE on hotel                     dataset:	 0.5015053153038025
2022-11-03 00:53:00,648:INFO: 		 ADE on univ                      dataset:	 0.5501015782356262
2022-11-03 00:53:01,194:INFO: 		 ADE on zara1                     dataset:	 0.5427502989768982
2022-11-03 00:53:01,986:INFO: 		 ADE on zara2                     dataset:	 0.456881582736969
2022-11-03 00:53:01,986:INFO: Average training:	ADE  0.5295	FDE  1.0786
2022-11-03 00:53:01,995:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_436.pth.tar
2022-11-03 00:53:01,995:INFO: 
===> EPOCH: 437 (P3)
2022-11-03 00:53:01,995:INFO: - Computing loss (training)
2022-11-03 00:53:03,073:INFO: Batch:  0/31	Total Loss 4.8832 (4.8832)
2022-11-03 00:53:03,546:INFO: Batch:  1/31	Total Loss 4.3722 (4.6198)
2022-11-03 00:53:04,016:INFO: Batch:  2/31	Total Loss 4.7796 (4.6770)
2022-11-03 00:53:04,487:INFO: Batch:  3/31	Total Loss 4.2309 (4.5660)
2022-11-03 00:53:04,953:INFO: Batch:  4/31	Total Loss 4.8245 (4.6183)
2022-11-03 00:53:05,424:INFO: Batch:  5/31	Total Loss 4.0912 (4.5291)
2022-11-03 00:53:05,894:INFO: Batch:  6/31	Total Loss 4.3014 (4.4927)
2022-11-03 00:53:06,361:INFO: Batch:  7/31	Total Loss 4.5490 (4.5002)
2022-11-03 00:53:06,832:INFO: Batch:  8/31	Total Loss 3.5381 (4.3745)
2022-11-03 00:53:07,303:INFO: Batch:  9/31	Total Loss 4.5072 (4.3877)
2022-11-03 00:53:07,768:INFO: Batch: 10/31	Total Loss 4.0836 (4.3563)
2022-11-03 00:53:08,243:INFO: Batch: 11/31	Total Loss 4.5409 (4.3722)
2022-11-03 00:53:08,714:INFO: Batch: 12/31	Total Loss 4.7578 (4.3983)
2022-11-03 00:53:09,186:INFO: Batch: 13/31	Total Loss 4.2686 (4.3891)
2022-11-03 00:53:09,655:INFO: Batch: 14/31	Total Loss 4.0040 (4.3658)
2022-11-03 00:53:10,130:INFO: Batch: 15/31	Total Loss 4.6326 (4.3821)
2022-11-03 00:53:10,599:INFO: Batch: 16/31	Total Loss 4.7616 (4.4029)
2022-11-03 00:53:11,067:INFO: Batch: 17/31	Total Loss 4.5533 (4.4111)
2022-11-03 00:53:11,538:INFO: Batch: 18/31	Total Loss 4.2601 (4.4022)
2022-11-03 00:53:12,009:INFO: Batch: 19/31	Total Loss 4.0970 (4.3865)
2022-11-03 00:53:12,479:INFO: Batch: 20/31	Total Loss 4.0265 (4.3686)
2022-11-03 00:53:12,949:INFO: Batch: 21/31	Total Loss 4.0287 (4.3534)
2022-11-03 00:53:13,419:INFO: Batch: 22/31	Total Loss 4.1309 (4.3434)
2022-11-03 00:53:13,889:INFO: Batch: 23/31	Total Loss 4.0940 (4.3340)
2022-11-03 00:53:14,357:INFO: Batch: 24/31	Total Loss 4.6392 (4.3468)
2022-11-03 00:53:14,829:INFO: Batch: 25/31	Total Loss 4.9778 (4.3696)
2022-11-03 00:53:15,297:INFO: Batch: 26/31	Total Loss 5.2658 (4.4019)
2022-11-03 00:53:15,768:INFO: Batch: 27/31	Total Loss 4.2840 (4.3974)
2022-11-03 00:53:16,240:INFO: Batch: 28/31	Total Loss 4.1484 (4.3886)
2022-11-03 00:53:16,708:INFO: Batch: 29/31	Total Loss 4.8298 (4.4032)
2022-11-03 00:53:17,092:INFO: Batch: 30/31	Total Loss 2.1911 (4.3818)
2022-11-03 00:53:17,240:INFO: - Computing ADE (validation o)
2022-11-03 00:53:17,814:INFO: 		 ADE on eth                       dataset:	 0.994202733039856
2022-11-03 00:53:17,814:INFO: Average validation o:	ADE  0.9942	FDE  1.8315
2022-11-03 00:53:17,815:INFO: - Computing ADE (validation)
2022-11-03 00:53:18,079:INFO: 		 ADE on hotel                     dataset:	 0.46341410279273987
2022-11-03 00:53:18,395:INFO: 		 ADE on univ                      dataset:	 0.5607170462608337
2022-11-03 00:53:18,639:INFO: 		 ADE on zara1                     dataset:	 0.4821552038192749
2022-11-03 00:53:19,001:INFO: 		 ADE on zara2                     dataset:	 0.43157199025154114
2022-11-03 00:53:19,002:INFO: Average validation:	ADE  0.5034	FDE  1.0144
2022-11-03 00:53:19,003:INFO: - Computing ADE (training)
2022-11-03 00:53:19,456:INFO: 		 ADE on hotel                     dataset:	 0.5006349086761475
2022-11-03 00:53:20,129:INFO: 		 ADE on univ                      dataset:	 0.5464782118797302
2022-11-03 00:53:20,684:INFO: 		 ADE on zara1                     dataset:	 0.5534231662750244
2022-11-03 00:53:21,432:INFO: 		 ADE on zara2                     dataset:	 0.4511649012565613
2022-11-03 00:53:21,432:INFO: Average training:	ADE  0.5264	FDE  1.0690
2022-11-03 00:53:21,441:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_437.pth.tar
2022-11-03 00:53:21,441:INFO: 
===> EPOCH: 438 (P3)
2022-11-03 00:53:21,441:INFO: - Computing loss (training)
2022-11-03 00:53:22,538:INFO: Batch:  0/31	Total Loss 4.4844 (4.4844)
2022-11-03 00:53:23,009:INFO: Batch:  1/31	Total Loss 4.6762 (4.5815)
2022-11-03 00:53:23,480:INFO: Batch:  2/31	Total Loss 4.1025 (4.3977)
2022-11-03 00:53:23,951:INFO: Batch:  3/31	Total Loss 4.2334 (4.3580)
2022-11-03 00:53:24,425:INFO: Batch:  4/31	Total Loss 4.6812 (4.4261)
2022-11-03 00:53:24,896:INFO: Batch:  5/31	Total Loss 4.6238 (4.4558)
2022-11-03 00:53:25,366:INFO: Batch:  6/31	Total Loss 4.4288 (4.4521)
2022-11-03 00:53:25,833:INFO: Batch:  7/31	Total Loss 3.7892 (4.3597)
2022-11-03 00:53:26,301:INFO: Batch:  8/31	Total Loss 5.1845 (4.4479)
2022-11-03 00:53:26,768:INFO: Batch:  9/31	Total Loss 4.1715 (4.4217)
2022-11-03 00:53:27,236:INFO: Batch: 10/31	Total Loss 3.8466 (4.3695)
2022-11-03 00:53:27,704:INFO: Batch: 11/31	Total Loss 4.1749 (4.3539)
2022-11-03 00:53:28,176:INFO: Batch: 12/31	Total Loss 4.4937 (4.3633)
2022-11-03 00:53:28,645:INFO: Batch: 13/31	Total Loss 4.3275 (4.3607)
2022-11-03 00:53:29,114:INFO: Batch: 14/31	Total Loss 4.3104 (4.3572)
2022-11-03 00:53:29,583:INFO: Batch: 15/31	Total Loss 4.3669 (4.3577)
2022-11-03 00:53:30,055:INFO: Batch: 16/31	Total Loss 4.7943 (4.3856)
2022-11-03 00:53:30,530:INFO: Batch: 17/31	Total Loss 4.0828 (4.3678)
2022-11-03 00:53:31,000:INFO: Batch: 18/31	Total Loss 4.0633 (4.3529)
2022-11-03 00:53:31,472:INFO: Batch: 19/31	Total Loss 4.1272 (4.3410)
2022-11-03 00:53:31,944:INFO: Batch: 20/31	Total Loss 4.6752 (4.3556)
2022-11-03 00:53:32,413:INFO: Batch: 21/31	Total Loss 4.3345 (4.3546)
2022-11-03 00:53:32,883:INFO: Batch: 22/31	Total Loss 4.3934 (4.3564)
2022-11-03 00:53:33,351:INFO: Batch: 23/31	Total Loss 4.9657 (4.3846)
2022-11-03 00:53:33,821:INFO: Batch: 24/31	Total Loss 4.3963 (4.3850)
2022-11-03 00:53:34,292:INFO: Batch: 25/31	Total Loss 4.3842 (4.3850)
2022-11-03 00:53:34,761:INFO: Batch: 26/31	Total Loss 3.8768 (4.3648)
2022-11-03 00:53:35,231:INFO: Batch: 27/31	Total Loss 4.5283 (4.3706)
2022-11-03 00:53:35,699:INFO: Batch: 28/31	Total Loss 5.6627 (4.4134)
2022-11-03 00:53:36,169:INFO: Batch: 29/31	Total Loss 5.4516 (4.4471)
2022-11-03 00:53:36,554:INFO: Batch: 30/31	Total Loss 1.9125 (4.4233)
2022-11-03 00:53:36,708:INFO: - Computing ADE (validation o)
2022-11-03 00:53:37,274:INFO: 		 ADE on eth                       dataset:	 1.0056215524673462
2022-11-03 00:53:37,274:INFO: Average validation o:	ADE  1.0056	FDE  1.8496
2022-11-03 00:53:37,274:INFO: - Computing ADE (validation)
2022-11-03 00:53:37,565:INFO: 		 ADE on hotel                     dataset:	 0.5092248916625977
2022-11-03 00:53:37,844:INFO: 		 ADE on univ                      dataset:	 0.5785415768623352
2022-11-03 00:53:38,102:INFO: 		 ADE on zara1                     dataset:	 0.4726986885070801
2022-11-03 00:53:38,456:INFO: 		 ADE on zara2                     dataset:	 0.4558413326740265
2022-11-03 00:53:38,457:INFO: Average validation:	ADE  0.5236	FDE  1.0718
2022-11-03 00:53:38,457:INFO: - Computing ADE (training)
2022-11-03 00:53:38,902:INFO: 		 ADE on hotel                     dataset:	 0.544893205165863
2022-11-03 00:53:39,576:INFO: 		 ADE on univ                      dataset:	 0.5615324974060059
2022-11-03 00:53:40,120:INFO: 		 ADE on zara1                     dataset:	 0.5651129484176636
2022-11-03 00:53:40,860:INFO: 		 ADE on zara2                     dataset:	 0.4790554940700531
2022-11-03 00:53:40,860:INFO: Average training:	ADE  0.5446	FDE  1.1174
2022-11-03 00:53:40,869:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_438.pth.tar
2022-11-03 00:53:40,869:INFO: 
===> EPOCH: 439 (P3)
2022-11-03 00:53:40,869:INFO: - Computing loss (training)
2022-11-03 00:53:42,047:INFO: Batch:  0/31	Total Loss 4.3480 (4.3480)
2022-11-03 00:53:42,514:INFO: Batch:  1/31	Total Loss 4.6215 (4.4835)
2022-11-03 00:53:42,992:INFO: Batch:  2/31	Total Loss 3.9142 (4.2962)
2022-11-03 00:53:43,456:INFO: Batch:  3/31	Total Loss 3.9280 (4.1990)
2022-11-03 00:53:43,924:INFO: Batch:  4/31	Total Loss 4.2673 (4.2126)
2022-11-03 00:53:44,391:INFO: Batch:  5/31	Total Loss 4.7538 (4.2937)
2022-11-03 00:53:44,857:INFO: Batch:  6/31	Total Loss 4.5789 (4.3364)
2022-11-03 00:53:45,326:INFO: Batch:  7/31	Total Loss 4.0852 (4.3051)
2022-11-03 00:53:45,796:INFO: Batch:  8/31	Total Loss 4.2957 (4.3040)
2022-11-03 00:53:46,263:INFO: Batch:  9/31	Total Loss 4.5723 (4.3294)
2022-11-03 00:53:46,731:INFO: Batch: 10/31	Total Loss 4.3303 (4.3295)
2022-11-03 00:53:47,198:INFO: Batch: 11/31	Total Loss 4.8869 (4.3809)
2022-11-03 00:53:47,667:INFO: Batch: 12/31	Total Loss 4.3661 (4.3799)
2022-11-03 00:53:48,138:INFO: Batch: 13/31	Total Loss 3.9681 (4.3522)
2022-11-03 00:53:48,609:INFO: Batch: 14/31	Total Loss 4.5550 (4.3643)
2022-11-03 00:53:49,083:INFO: Batch: 15/31	Total Loss 4.3377 (4.3627)
2022-11-03 00:53:49,555:INFO: Batch: 16/31	Total Loss 4.1091 (4.3482)
2022-11-03 00:53:50,025:INFO: Batch: 17/31	Total Loss 4.0679 (4.3341)
2022-11-03 00:53:50,495:INFO: Batch: 18/31	Total Loss 4.3341 (4.3341)
2022-11-03 00:53:50,965:INFO: Batch: 19/31	Total Loss 4.1632 (4.3246)
2022-11-03 00:53:51,434:INFO: Batch: 20/31	Total Loss 4.1107 (4.3143)
2022-11-03 00:53:51,905:INFO: Batch: 21/31	Total Loss 4.0437 (4.3021)
2022-11-03 00:53:52,374:INFO: Batch: 22/31	Total Loss 4.8559 (4.3270)
2022-11-03 00:53:52,842:INFO: Batch: 23/31	Total Loss 4.2186 (4.3224)
2022-11-03 00:53:53,314:INFO: Batch: 24/31	Total Loss 4.4823 (4.3290)
2022-11-03 00:53:53,783:INFO: Batch: 25/31	Total Loss 4.8273 (4.3464)
2022-11-03 00:53:54,252:INFO: Batch: 26/31	Total Loss 4.3969 (4.3484)
2022-11-03 00:53:54,720:INFO: Batch: 27/31	Total Loss 5.2300 (4.3766)
2022-11-03 00:53:55,189:INFO: Batch: 28/31	Total Loss 4.6511 (4.3862)
2022-11-03 00:53:55,657:INFO: Batch: 29/31	Total Loss 4.7491 (4.3977)
2022-11-03 00:53:56,042:INFO: Batch: 30/31	Total Loss 1.5696 (4.3657)
2022-11-03 00:53:56,184:INFO: - Computing ADE (validation o)
2022-11-03 00:53:56,771:INFO: 		 ADE on eth                       dataset:	 0.9699013829231262
2022-11-03 00:53:56,771:INFO: Average validation o:	ADE  0.9699	FDE  1.7812
2022-11-03 00:53:56,772:INFO: - Computing ADE (validation)
2022-11-03 00:53:57,064:INFO: 		 ADE on hotel                     dataset:	 0.47711533308029175
2022-11-03 00:53:57,359:INFO: 		 ADE on univ                      dataset:	 0.5580931901931763
2022-11-03 00:53:57,612:INFO: 		 ADE on zara1                     dataset:	 0.44555750489234924
2022-11-03 00:53:57,959:INFO: 		 ADE on zara2                     dataset:	 0.41540223360061646
2022-11-03 00:53:57,960:INFO: Average validation:	ADE  0.4948	FDE  0.9979
2022-11-03 00:53:57,960:INFO: - Computing ADE (training)
2022-11-03 00:53:58,403:INFO: 		 ADE on hotel                     dataset:	 0.5121495723724365
2022-11-03 00:53:59,064:INFO: 		 ADE on univ                      dataset:	 0.5458837747573853
2022-11-03 00:53:59,602:INFO: 		 ADE on zara1                     dataset:	 0.5230764150619507
2022-11-03 00:54:00,371:INFO: 		 ADE on zara2                     dataset:	 0.42861416935920715
2022-11-03 00:54:00,371:INFO: Average training:	ADE  0.5198	FDE  1.0552
2022-11-03 00:54:00,380:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_439.pth.tar
2022-11-03 00:54:00,380:INFO: 
===> EPOCH: 440 (P3)
2022-11-03 00:54:00,381:INFO: - Computing loss (training)
2022-11-03 00:54:01,485:INFO: Batch:  0/31	Total Loss 4.1532 (4.1532)
2022-11-03 00:54:01,955:INFO: Batch:  1/31	Total Loss 4.4972 (4.3212)
2022-11-03 00:54:02,426:INFO: Batch:  2/31	Total Loss 4.2808 (4.3065)
2022-11-03 00:54:02,900:INFO: Batch:  3/31	Total Loss 4.2256 (4.2837)
2022-11-03 00:54:03,368:INFO: Batch:  4/31	Total Loss 4.2666 (4.2800)
2022-11-03 00:54:03,839:INFO: Batch:  5/31	Total Loss 5.2050 (4.4272)
2022-11-03 00:54:04,306:INFO: Batch:  6/31	Total Loss 3.8728 (4.3632)
2022-11-03 00:54:04,771:INFO: Batch:  7/31	Total Loss 4.2566 (4.3497)
2022-11-03 00:54:05,239:INFO: Batch:  8/31	Total Loss 5.0100 (4.4185)
2022-11-03 00:54:05,703:INFO: Batch:  9/31	Total Loss 4.8061 (4.4544)
2022-11-03 00:54:06,171:INFO: Batch: 10/31	Total Loss 4.4723 (4.4560)
2022-11-03 00:54:06,639:INFO: Batch: 11/31	Total Loss 4.1921 (4.4331)
2022-11-03 00:54:07,111:INFO: Batch: 12/31	Total Loss 5.1751 (4.4850)
2022-11-03 00:54:07,582:INFO: Batch: 13/31	Total Loss 4.7473 (4.5046)
2022-11-03 00:54:08,055:INFO: Batch: 14/31	Total Loss 4.1858 (4.4838)
2022-11-03 00:54:08,525:INFO: Batch: 15/31	Total Loss 4.3190 (4.4730)
2022-11-03 00:54:08,996:INFO: Batch: 16/31	Total Loss 4.6079 (4.4808)
2022-11-03 00:54:09,466:INFO: Batch: 17/31	Total Loss 4.3911 (4.4762)
2022-11-03 00:54:09,938:INFO: Batch: 18/31	Total Loss 4.5458 (4.4801)
2022-11-03 00:54:10,410:INFO: Batch: 19/31	Total Loss 4.3144 (4.4720)
2022-11-03 00:54:10,878:INFO: Batch: 20/31	Total Loss 4.4252 (4.4699)
2022-11-03 00:54:11,349:INFO: Batch: 21/31	Total Loss 4.2671 (4.4612)
2022-11-03 00:54:11,818:INFO: Batch: 22/31	Total Loss 4.2947 (4.4542)
2022-11-03 00:54:12,289:INFO: Batch: 23/31	Total Loss 4.4365 (4.4535)
2022-11-03 00:54:12,757:INFO: Batch: 24/31	Total Loss 4.5292 (4.4563)
2022-11-03 00:54:13,228:INFO: Batch: 25/31	Total Loss 4.1303 (4.4422)
2022-11-03 00:54:13,697:INFO: Batch: 26/31	Total Loss 5.2269 (4.4730)
2022-11-03 00:54:14,168:INFO: Batch: 27/31	Total Loss 4.2024 (4.4624)
2022-11-03 00:54:14,640:INFO: Batch: 28/31	Total Loss 4.9947 (4.4804)
2022-11-03 00:54:15,109:INFO: Batch: 29/31	Total Loss 4.2719 (4.4724)
2022-11-03 00:54:15,494:INFO: Batch: 30/31	Total Loss 1.6961 (4.4427)
2022-11-03 00:54:15,643:INFO: - Computing ADE (validation o)
2022-11-03 00:54:16,231:INFO: 		 ADE on eth                       dataset:	 0.977050244808197
2022-11-03 00:54:16,231:INFO: Average validation o:	ADE  0.9771	FDE  1.8106
2022-11-03 00:54:16,232:INFO: - Computing ADE (validation)
2022-11-03 00:54:16,506:INFO: 		 ADE on hotel                     dataset:	 0.46600377559661865
2022-11-03 00:54:16,814:INFO: 		 ADE on univ                      dataset:	 0.5588341951370239
2022-11-03 00:54:17,084:INFO: 		 ADE on zara1                     dataset:	 0.43916088342666626
2022-11-03 00:54:17,439:INFO: 		 ADE on zara2                     dataset:	 0.43242794275283813
2022-11-03 00:54:17,439:INFO: Average validation:	ADE  0.5004	FDE  1.0197
2022-11-03 00:54:17,440:INFO: - Computing ADE (training)
2022-11-03 00:54:17,885:INFO: 		 ADE on hotel                     dataset:	 0.48818549513816833
2022-11-03 00:54:18,554:INFO: 		 ADE on univ                      dataset:	 0.5492311120033264
2022-11-03 00:54:19,095:INFO: 		 ADE on zara1                     dataset:	 0.5277901291847229
2022-11-03 00:54:19,853:INFO: 		 ADE on zara2                     dataset:	 0.4436790347099304
2022-11-03 00:54:19,853:INFO: Average training:	ADE  0.5249	FDE  1.0764
2022-11-03 00:54:19,862:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_440.pth.tar
2022-11-03 00:54:19,862:INFO: 
===> EPOCH: 441 (P3)
2022-11-03 00:54:19,863:INFO: - Computing loss (training)
2022-11-03 00:54:20,951:INFO: Batch:  0/31	Total Loss 4.8194 (4.8194)
2022-11-03 00:54:21,424:INFO: Batch:  1/31	Total Loss 4.0551 (4.4506)
2022-11-03 00:54:21,896:INFO: Batch:  2/31	Total Loss 4.0225 (4.3060)
2022-11-03 00:54:22,372:INFO: Batch:  3/31	Total Loss 4.1159 (4.2630)
2022-11-03 00:54:22,838:INFO: Batch:  4/31	Total Loss 4.9400 (4.3998)
2022-11-03 00:54:23,312:INFO: Batch:  5/31	Total Loss 5.0764 (4.5102)
2022-11-03 00:54:23,781:INFO: Batch:  6/31	Total Loss 5.0406 (4.5775)
2022-11-03 00:54:24,251:INFO: Batch:  7/31	Total Loss 4.4077 (4.5576)
2022-11-03 00:54:24,721:INFO: Batch:  8/31	Total Loss 4.2924 (4.5289)
2022-11-03 00:54:25,191:INFO: Batch:  9/31	Total Loss 4.5954 (4.5354)
2022-11-03 00:54:25,662:INFO: Batch: 10/31	Total Loss 5.1604 (4.5930)
2022-11-03 00:54:26,130:INFO: Batch: 11/31	Total Loss 4.5904 (4.5928)
2022-11-03 00:54:26,604:INFO: Batch: 12/31	Total Loss 4.8193 (4.6103)
2022-11-03 00:54:27,078:INFO: Batch: 13/31	Total Loss 4.8486 (4.6294)
2022-11-03 00:54:27,550:INFO: Batch: 14/31	Total Loss 4.5771 (4.6260)
2022-11-03 00:54:28,026:INFO: Batch: 15/31	Total Loss 4.4371 (4.6153)
2022-11-03 00:54:28,498:INFO: Batch: 16/31	Total Loss 3.8459 (4.5700)
2022-11-03 00:54:28,973:INFO: Batch: 17/31	Total Loss 4.7159 (4.5786)
2022-11-03 00:54:29,448:INFO: Batch: 18/31	Total Loss 4.8389 (4.5935)
2022-11-03 00:54:29,999:INFO: Batch: 19/31	Total Loss 4.1242 (4.5706)
2022-11-03 00:54:30,474:INFO: Batch: 20/31	Total Loss 4.2263 (4.5562)
2022-11-03 00:54:30,945:INFO: Batch: 21/31	Total Loss 4.2306 (4.5411)
2022-11-03 00:54:31,417:INFO: Batch: 22/31	Total Loss 3.8992 (4.5161)
2022-11-03 00:54:31,888:INFO: Batch: 23/31	Total Loss 4.3672 (4.5110)
2022-11-03 00:54:32,361:INFO: Batch: 24/31	Total Loss 4.2235 (4.4996)
2022-11-03 00:54:32,835:INFO: Batch: 25/31	Total Loss 4.6821 (4.5071)
2022-11-03 00:54:33,308:INFO: Batch: 26/31	Total Loss 4.2006 (4.4971)
2022-11-03 00:54:33,781:INFO: Batch: 27/31	Total Loss 4.3383 (4.4907)
2022-11-03 00:54:34,259:INFO: Batch: 28/31	Total Loss 4.5236 (4.4917)
2022-11-03 00:54:34,732:INFO: Batch: 29/31	Total Loss 4.5258 (4.4927)
2022-11-03 00:54:35,120:INFO: Batch: 30/31	Total Loss 1.5696 (4.4647)
2022-11-03 00:54:35,261:INFO: - Computing ADE (validation o)
2022-11-03 00:54:35,860:INFO: 		 ADE on eth                       dataset:	 1.0322216749191284
2022-11-03 00:54:35,861:INFO: Average validation o:	ADE  1.0322	FDE  2.0203
2022-11-03 00:54:35,861:INFO: - Computing ADE (validation)
2022-11-03 00:54:36,137:INFO: 		 ADE on hotel                     dataset:	 0.5650237798690796
2022-11-03 00:54:36,437:INFO: 		 ADE on univ                      dataset:	 0.6288273334503174
2022-11-03 00:54:36,694:INFO: 		 ADE on zara1                     dataset:	 0.5885358452796936
2022-11-03 00:54:37,042:INFO: 		 ADE on zara2                     dataset:	 0.5420268177986145
2022-11-03 00:54:37,042:INFO: Average validation:	ADE  0.5912	FDE  1.2726
2022-11-03 00:54:37,043:INFO: - Computing ADE (training)
2022-11-03 00:54:37,505:INFO: 		 ADE on hotel                     dataset:	 0.6000106930732727
2022-11-03 00:54:38,183:INFO: 		 ADE on univ                      dataset:	 0.6302237510681152
2022-11-03 00:54:38,743:INFO: 		 ADE on zara1                     dataset:	 0.6018620729446411
2022-11-03 00:54:39,518:INFO: 		 ADE on zara2                     dataset:	 0.5507268309593201
2022-11-03 00:54:39,518:INFO: Average training:	ADE  0.6115	FDE  1.3231
2022-11-03 00:54:39,527:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_441.pth.tar
2022-11-03 00:54:39,527:INFO: 
===> EPOCH: 442 (P3)
2022-11-03 00:54:39,527:INFO: - Computing loss (training)
2022-11-03 00:54:40,618:INFO: Batch:  0/31	Total Loss 4.7793 (4.7793)
2022-11-03 00:54:41,094:INFO: Batch:  1/31	Total Loss 4.6827 (4.7272)
2022-11-03 00:54:41,574:INFO: Batch:  2/31	Total Loss 4.7862 (4.7463)
2022-11-03 00:54:42,050:INFO: Batch:  3/31	Total Loss 4.5091 (4.6801)
2022-11-03 00:54:42,519:INFO: Batch:  4/31	Total Loss 4.7818 (4.7003)
2022-11-03 00:54:42,992:INFO: Batch:  5/31	Total Loss 5.2511 (4.7914)
2022-11-03 00:54:43,461:INFO: Batch:  6/31	Total Loss 3.9075 (4.6674)
2022-11-03 00:54:43,928:INFO: Batch:  7/31	Total Loss 3.9372 (4.5687)
2022-11-03 00:54:44,395:INFO: Batch:  8/31	Total Loss 5.6272 (4.6777)
2022-11-03 00:54:44,861:INFO: Batch:  9/31	Total Loss 4.7746 (4.6877)
2022-11-03 00:54:45,328:INFO: Batch: 10/31	Total Loss 4.6395 (4.6834)
2022-11-03 00:54:45,796:INFO: Batch: 11/31	Total Loss 4.7621 (4.6905)
2022-11-03 00:54:46,267:INFO: Batch: 12/31	Total Loss 4.6379 (4.6869)
2022-11-03 00:54:46,738:INFO: Batch: 13/31	Total Loss 4.3758 (4.6608)
2022-11-03 00:54:47,207:INFO: Batch: 14/31	Total Loss 4.6548 (4.6604)
2022-11-03 00:54:47,676:INFO: Batch: 15/31	Total Loss 4.4054 (4.6444)
2022-11-03 00:54:48,146:INFO: Batch: 16/31	Total Loss 4.8114 (4.6528)
2022-11-03 00:54:48,615:INFO: Batch: 17/31	Total Loss 4.6549 (4.6530)
2022-11-03 00:54:49,085:INFO: Batch: 18/31	Total Loss 3.9274 (4.6145)
2022-11-03 00:54:49,555:INFO: Batch: 19/31	Total Loss 3.8026 (4.5772)
2022-11-03 00:54:50,026:INFO: Batch: 20/31	Total Loss 4.5480 (4.5759)
2022-11-03 00:54:50,505:INFO: Batch: 21/31	Total Loss 4.4529 (4.5706)
2022-11-03 00:54:50,977:INFO: Batch: 22/31	Total Loss 5.2424 (4.5991)
2022-11-03 00:54:51,448:INFO: Batch: 23/31	Total Loss 4.2533 (4.5836)
2022-11-03 00:54:51,918:INFO: Batch: 24/31	Total Loss 4.6972 (4.5884)
2022-11-03 00:54:52,391:INFO: Batch: 25/31	Total Loss 4.0811 (4.5699)
2022-11-03 00:54:52,861:INFO: Batch: 26/31	Total Loss 4.1399 (4.5540)
2022-11-03 00:54:53,334:INFO: Batch: 27/31	Total Loss 4.7037 (4.5593)
2022-11-03 00:54:53,806:INFO: Batch: 28/31	Total Loss 4.0732 (4.5413)
2022-11-03 00:54:54,278:INFO: Batch: 29/31	Total Loss 3.9686 (4.5207)
2022-11-03 00:54:54,664:INFO: Batch: 30/31	Total Loss 1.8097 (4.4952)
2022-11-03 00:54:54,820:INFO: - Computing ADE (validation o)
2022-11-03 00:54:55,390:INFO: 		 ADE on eth                       dataset:	 0.9943110346794128
2022-11-03 00:54:55,390:INFO: Average validation o:	ADE  0.9943	FDE  1.9102
2022-11-03 00:54:55,391:INFO: - Computing ADE (validation)
2022-11-03 00:54:55,676:INFO: 		 ADE on hotel                     dataset:	 0.4914124011993408
2022-11-03 00:54:55,978:INFO: 		 ADE on univ                      dataset:	 0.5721748471260071
2022-11-03 00:54:56,227:INFO: 		 ADE on zara1                     dataset:	 0.4771668612957001
2022-11-03 00:54:56,575:INFO: 		 ADE on zara2                     dataset:	 0.4683127999305725
2022-11-03 00:54:56,575:INFO: Average validation:	ADE  0.5241	FDE  1.0877
2022-11-03 00:54:56,576:INFO: - Computing ADE (training)
2022-11-03 00:54:57,016:INFO: 		 ADE on hotel                     dataset:	 0.5172483921051025
2022-11-03 00:54:57,686:INFO: 		 ADE on univ                      dataset:	 0.5728510022163391
2022-11-03 00:54:58,231:INFO: 		 ADE on zara1                     dataset:	 0.5417056083679199
2022-11-03 00:54:59,017:INFO: 		 ADE on zara2                     dataset:	 0.4780428111553192
2022-11-03 00:54:59,017:INFO: Average training:	ADE  0.5502	FDE  1.1509
2022-11-03 00:54:59,025:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_442.pth.tar
2022-11-03 00:54:59,026:INFO: 
===> EPOCH: 443 (P3)
2022-11-03 00:54:59,026:INFO: - Computing loss (training)
2022-11-03 00:55:00,114:INFO: Batch:  0/31	Total Loss 4.9356 (4.9356)
2022-11-03 00:55:00,588:INFO: Batch:  1/31	Total Loss 4.6221 (4.7739)
2022-11-03 00:55:01,059:INFO: Batch:  2/31	Total Loss 4.2963 (4.6037)
2022-11-03 00:55:01,532:INFO: Batch:  3/31	Total Loss 5.0004 (4.7025)
2022-11-03 00:55:02,000:INFO: Batch:  4/31	Total Loss 4.0329 (4.5614)
2022-11-03 00:55:02,471:INFO: Batch:  5/31	Total Loss 4.0291 (4.4749)
2022-11-03 00:55:02,941:INFO: Batch:  6/31	Total Loss 4.9787 (4.5425)
2022-11-03 00:55:03,408:INFO: Batch:  7/31	Total Loss 4.6215 (4.5534)
2022-11-03 00:55:03,877:INFO: Batch:  8/31	Total Loss 4.0780 (4.4986)
2022-11-03 00:55:04,347:INFO: Batch:  9/31	Total Loss 4.5207 (4.5008)
2022-11-03 00:55:04,815:INFO: Batch: 10/31	Total Loss 4.2811 (4.4817)
2022-11-03 00:55:05,284:INFO: Batch: 11/31	Total Loss 4.2535 (4.4648)
2022-11-03 00:55:05,757:INFO: Batch: 12/31	Total Loss 4.0819 (4.4350)
2022-11-03 00:55:06,229:INFO: Batch: 13/31	Total Loss 4.4241 (4.4341)
2022-11-03 00:55:06,704:INFO: Batch: 14/31	Total Loss 4.3131 (4.4249)
2022-11-03 00:55:07,178:INFO: Batch: 15/31	Total Loss 4.2030 (4.4101)
2022-11-03 00:55:07,651:INFO: Batch: 16/31	Total Loss 4.3331 (4.4055)
2022-11-03 00:55:08,125:INFO: Batch: 17/31	Total Loss 4.1290 (4.3896)
2022-11-03 00:55:08,598:INFO: Batch: 18/31	Total Loss 4.5435 (4.3974)
2022-11-03 00:55:09,069:INFO: Batch: 19/31	Total Loss 4.3945 (4.3973)
2022-11-03 00:55:09,542:INFO: Batch: 20/31	Total Loss 3.9906 (4.3780)
2022-11-03 00:55:10,021:INFO: Batch: 21/31	Total Loss 4.8804 (4.4008)
2022-11-03 00:55:10,503:INFO: Batch: 22/31	Total Loss 4.5541 (4.4067)
2022-11-03 00:55:10,983:INFO: Batch: 23/31	Total Loss 5.1231 (4.4374)
2022-11-03 00:55:11,460:INFO: Batch: 24/31	Total Loss 4.2319 (4.4286)
2022-11-03 00:55:11,939:INFO: Batch: 25/31	Total Loss 4.3542 (4.4256)
2022-11-03 00:55:12,417:INFO: Batch: 26/31	Total Loss 4.3829 (4.4242)
2022-11-03 00:55:12,893:INFO: Batch: 27/31	Total Loss 4.3592 (4.4218)
2022-11-03 00:55:13,371:INFO: Batch: 28/31	Total Loss 4.8911 (4.4378)
2022-11-03 00:55:13,850:INFO: Batch: 29/31	Total Loss 4.2025 (4.4296)
2022-11-03 00:55:14,244:INFO: Batch: 30/31	Total Loss 1.7564 (4.4018)
2022-11-03 00:55:14,392:INFO: - Computing ADE (validation o)
2022-11-03 00:55:14,959:INFO: 		 ADE on eth                       dataset:	 0.9948528409004211
2022-11-03 00:55:14,959:INFO: Average validation o:	ADE  0.9949	FDE  1.9192
2022-11-03 00:55:14,960:INFO: - Computing ADE (validation)
2022-11-03 00:55:15,242:INFO: 		 ADE on hotel                     dataset:	 0.5100465416908264
2022-11-03 00:55:15,529:INFO: 		 ADE on univ                      dataset:	 0.5955216288566589
2022-11-03 00:55:15,773:INFO: 		 ADE on zara1                     dataset:	 0.5361184477806091
2022-11-03 00:55:16,124:INFO: 		 ADE on zara2                     dataset:	 0.4727422595024109
2022-11-03 00:55:16,124:INFO: Average validation:	ADE  0.5424	FDE  1.1432
2022-11-03 00:55:16,125:INFO: - Computing ADE (training)
2022-11-03 00:55:16,577:INFO: 		 ADE on hotel                     dataset:	 0.5617231130599976
2022-11-03 00:55:17,261:INFO: 		 ADE on univ                      dataset:	 0.5839315056800842
2022-11-03 00:55:17,801:INFO: 		 ADE on zara1                     dataset:	 0.548782467842102
2022-11-03 00:55:18,575:INFO: 		 ADE on zara2                     dataset:	 0.4848678410053253
2022-11-03 00:55:18,575:INFO: Average training:	ADE  0.5610	FDE  1.1858
2022-11-03 00:55:18,584:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_443.pth.tar
2022-11-03 00:55:18,584:INFO: 
===> EPOCH: 444 (P3)
2022-11-03 00:55:18,585:INFO: - Computing loss (training)
2022-11-03 00:55:19,718:INFO: Batch:  0/31	Total Loss 4.3977 (4.3977)
2022-11-03 00:55:20,194:INFO: Batch:  1/31	Total Loss 4.3391 (4.3686)
2022-11-03 00:55:20,669:INFO: Batch:  2/31	Total Loss 4.1742 (4.3049)
2022-11-03 00:55:21,139:INFO: Batch:  3/31	Total Loss 4.2879 (4.3006)
2022-11-03 00:55:21,616:INFO: Batch:  4/31	Total Loss 4.0575 (4.2535)
2022-11-03 00:55:22,093:INFO: Batch:  5/31	Total Loss 5.8138 (4.4861)
2022-11-03 00:55:22,565:INFO: Batch:  6/31	Total Loss 4.3664 (4.4682)
2022-11-03 00:55:23,042:INFO: Batch:  7/31	Total Loss 4.2080 (4.4343)
2022-11-03 00:55:23,592:INFO: Batch:  8/31	Total Loss 4.6009 (4.4549)
2022-11-03 00:55:24,066:INFO: Batch:  9/31	Total Loss 4.4568 (4.4551)
2022-11-03 00:55:24,537:INFO: Batch: 10/31	Total Loss 5.1954 (4.5217)
2022-11-03 00:55:25,012:INFO: Batch: 11/31	Total Loss 4.9889 (4.5624)
2022-11-03 00:55:25,489:INFO: Batch: 12/31	Total Loss 4.6177 (4.5666)
2022-11-03 00:55:25,966:INFO: Batch: 13/31	Total Loss 4.9915 (4.5950)
2022-11-03 00:55:26,442:INFO: Batch: 14/31	Total Loss 4.1826 (4.5681)
2022-11-03 00:55:26,920:INFO: Batch: 15/31	Total Loss 4.0568 (4.5357)
2022-11-03 00:55:27,396:INFO: Batch: 16/31	Total Loss 4.3552 (4.5261)
2022-11-03 00:55:27,871:INFO: Batch: 17/31	Total Loss 4.9591 (4.5538)
2022-11-03 00:55:28,347:INFO: Batch: 18/31	Total Loss 4.9649 (4.5759)
2022-11-03 00:55:28,822:INFO: Batch: 19/31	Total Loss 4.3261 (4.5627)
2022-11-03 00:55:29,296:INFO: Batch: 20/31	Total Loss 4.3706 (4.5536)
2022-11-03 00:55:29,770:INFO: Batch: 21/31	Total Loss 6.0588 (4.6181)
2022-11-03 00:55:30,250:INFO: Batch: 22/31	Total Loss 4.2312 (4.6012)
2022-11-03 00:55:30,727:INFO: Batch: 23/31	Total Loss 4.4383 (4.5952)
2022-11-03 00:55:31,199:INFO: Batch: 24/31	Total Loss 4.2507 (4.5828)
2022-11-03 00:55:31,674:INFO: Batch: 25/31	Total Loss 5.5349 (4.6197)
2022-11-03 00:55:32,147:INFO: Batch: 26/31	Total Loss 4.7692 (4.6254)
2022-11-03 00:55:32,620:INFO: Batch: 27/31	Total Loss 4.6261 (4.6254)
2022-11-03 00:55:33,098:INFO: Batch: 28/31	Total Loss 4.7931 (4.6318)
2022-11-03 00:55:33,572:INFO: Batch: 29/31	Total Loss 4.7311 (4.6353)
2022-11-03 00:55:33,965:INFO: Batch: 30/31	Total Loss 1.7514 (4.6058)
2022-11-03 00:55:34,113:INFO: - Computing ADE (validation o)
2022-11-03 00:55:34,691:INFO: 		 ADE on eth                       dataset:	 1.0030111074447632
2022-11-03 00:55:34,691:INFO: Average validation o:	ADE  1.0030	FDE  1.9327
2022-11-03 00:55:34,692:INFO: - Computing ADE (validation)
2022-11-03 00:55:34,941:INFO: 		 ADE on hotel                     dataset:	 0.5337474942207336
2022-11-03 00:55:35,236:INFO: 		 ADE on univ                      dataset:	 0.6036432385444641
2022-11-03 00:55:35,498:INFO: 		 ADE on zara1                     dataset:	 0.5363401174545288
2022-11-03 00:55:35,850:INFO: 		 ADE on zara2                     dataset:	 0.49859344959259033
2022-11-03 00:55:35,851:INFO: Average validation:	ADE  0.5574	FDE  1.1819
2022-11-03 00:55:35,852:INFO: - Computing ADE (training)
2022-11-03 00:55:36,294:INFO: 		 ADE on hotel                     dataset:	 0.571656346321106
2022-11-03 00:55:36,982:INFO: 		 ADE on univ                      dataset:	 0.5998986959457397
2022-11-03 00:55:37,558:INFO: 		 ADE on zara1                     dataset:	 0.5640000700950623
2022-11-03 00:55:38,300:INFO: 		 ADE on zara2                     dataset:	 0.5079441070556641
2022-11-03 00:55:38,300:INFO: Average training:	ADE  0.5782	FDE  1.2322
2022-11-03 00:55:38,308:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_444.pth.tar
2022-11-03 00:55:38,308:INFO: 
===> EPOCH: 445 (P3)
2022-11-03 00:55:38,309:INFO: - Computing loss (training)
2022-11-03 00:55:39,385:INFO: Batch:  0/31	Total Loss 4.3336 (4.3336)
2022-11-03 00:55:39,862:INFO: Batch:  1/31	Total Loss 5.0633 (4.6795)
2022-11-03 00:55:40,337:INFO: Batch:  2/31	Total Loss 5.8425 (5.0567)
2022-11-03 00:55:40,812:INFO: Batch:  3/31	Total Loss 5.2935 (5.1065)
2022-11-03 00:55:41,281:INFO: Batch:  4/31	Total Loss 4.0729 (4.8765)
2022-11-03 00:55:41,754:INFO: Batch:  5/31	Total Loss 4.6470 (4.8389)
2022-11-03 00:55:42,223:INFO: Batch:  6/31	Total Loss 5.4710 (4.9233)
2022-11-03 00:55:42,691:INFO: Batch:  7/31	Total Loss 4.3794 (4.8571)
2022-11-03 00:55:43,160:INFO: Batch:  8/31	Total Loss 5.1482 (4.8850)
2022-11-03 00:55:43,630:INFO: Batch:  9/31	Total Loss 5.4554 (4.9409)
2022-11-03 00:55:44,101:INFO: Batch: 10/31	Total Loss 4.3797 (4.8901)
2022-11-03 00:55:44,575:INFO: Batch: 11/31	Total Loss 4.4986 (4.8588)
2022-11-03 00:55:45,050:INFO: Batch: 12/31	Total Loss 5.1464 (4.8788)
2022-11-03 00:55:45,523:INFO: Batch: 13/31	Total Loss 4.3144 (4.8388)
2022-11-03 00:55:45,998:INFO: Batch: 14/31	Total Loss 4.6394 (4.8253)
2022-11-03 00:55:46,472:INFO: Batch: 15/31	Total Loss 4.9425 (4.8325)
2022-11-03 00:55:46,948:INFO: Batch: 16/31	Total Loss 4.4093 (4.8064)
2022-11-03 00:55:47,423:INFO: Batch: 17/31	Total Loss 4.1398 (4.7739)
2022-11-03 00:55:47,898:INFO: Batch: 18/31	Total Loss 4.4267 (4.7556)
2022-11-03 00:55:48,371:INFO: Batch: 19/31	Total Loss 5.6163 (4.7905)
2022-11-03 00:55:48,846:INFO: Batch: 20/31	Total Loss 4.0599 (4.7564)
2022-11-03 00:55:49,320:INFO: Batch: 21/31	Total Loss 3.8960 (4.7187)
2022-11-03 00:55:49,793:INFO: Batch: 22/31	Total Loss 4.9178 (4.7261)
2022-11-03 00:55:50,272:INFO: Batch: 23/31	Total Loss 4.3531 (4.7113)
2022-11-03 00:55:50,746:INFO: Batch: 24/31	Total Loss 4.3305 (4.6969)
2022-11-03 00:55:51,217:INFO: Batch: 25/31	Total Loss 4.6495 (4.6949)
2022-11-03 00:55:51,689:INFO: Batch: 26/31	Total Loss 4.3208 (4.6812)
2022-11-03 00:55:52,160:INFO: Batch: 27/31	Total Loss 4.3757 (4.6708)
2022-11-03 00:55:52,633:INFO: Batch: 28/31	Total Loss 4.1008 (4.6508)
2022-11-03 00:55:53,107:INFO: Batch: 29/31	Total Loss 4.4171 (4.6427)
2022-11-03 00:55:53,495:INFO: Batch: 30/31	Total Loss 1.7185 (4.6172)
2022-11-03 00:55:53,642:INFO: - Computing ADE (validation o)
2022-11-03 00:55:54,227:INFO: 		 ADE on eth                       dataset:	 0.9682573676109314
2022-11-03 00:55:54,228:INFO: Average validation o:	ADE  0.9683	FDE  1.8372
2022-11-03 00:55:54,228:INFO: - Computing ADE (validation)
2022-11-03 00:55:54,491:INFO: 		 ADE on hotel                     dataset:	 0.4600815773010254
2022-11-03 00:55:54,793:INFO: 		 ADE on univ                      dataset:	 0.5589985847473145
2022-11-03 00:55:55,048:INFO: 		 ADE on zara1                     dataset:	 0.45575544238090515
2022-11-03 00:55:55,390:INFO: 		 ADE on zara2                     dataset:	 0.4265397787094116
2022-11-03 00:55:55,390:INFO: Average validation:	ADE  0.4990	FDE  1.0185
2022-11-03 00:55:55,391:INFO: - Computing ADE (training)
2022-11-03 00:55:55,828:INFO: 		 ADE on hotel                     dataset:	 0.49020206928253174
2022-11-03 00:55:56,499:INFO: 		 ADE on univ                      dataset:	 0.5483083724975586
2022-11-03 00:55:57,039:INFO: 		 ADE on zara1                     dataset:	 0.520408570766449
2022-11-03 00:55:57,826:INFO: 		 ADE on zara2                     dataset:	 0.43647149205207825
2022-11-03 00:55:57,826:INFO: Average training:	ADE  0.5224	FDE  1.0744
2022-11-03 00:55:57,834:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_445.pth.tar
2022-11-03 00:55:57,834:INFO: 
===> EPOCH: 446 (P3)
2022-11-03 00:55:57,835:INFO: - Computing loss (training)
2022-11-03 00:55:58,927:INFO: Batch:  0/31	Total Loss 4.1019 (4.1019)
2022-11-03 00:55:59,410:INFO: Batch:  1/31	Total Loss 4.3366 (4.2207)
2022-11-03 00:55:59,883:INFO: Batch:  2/31	Total Loss 4.0280 (4.1587)
2022-11-03 00:56:00,364:INFO: Batch:  3/31	Total Loss 4.0030 (4.1209)
2022-11-03 00:56:00,840:INFO: Batch:  4/31	Total Loss 4.3942 (4.1714)
2022-11-03 00:56:01,314:INFO: Batch:  5/31	Total Loss 3.9623 (4.1398)
2022-11-03 00:56:01,786:INFO: Batch:  6/31	Total Loss 4.4454 (4.1821)
2022-11-03 00:56:02,255:INFO: Batch:  7/31	Total Loss 4.2780 (4.1942)
2022-11-03 00:56:02,722:INFO: Batch:  8/31	Total Loss 4.3153 (4.2069)
2022-11-03 00:56:03,193:INFO: Batch:  9/31	Total Loss 3.8212 (4.1681)
2022-11-03 00:56:03,664:INFO: Batch: 10/31	Total Loss 4.0400 (4.1569)
2022-11-03 00:56:04,133:INFO: Batch: 11/31	Total Loss 5.4254 (4.2544)
2022-11-03 00:56:04,606:INFO: Batch: 12/31	Total Loss 4.9193 (4.2999)
2022-11-03 00:56:05,080:INFO: Batch: 13/31	Total Loss 4.5358 (4.3174)
2022-11-03 00:56:05,553:INFO: Batch: 14/31	Total Loss 3.8140 (4.2827)
2022-11-03 00:56:06,027:INFO: Batch: 15/31	Total Loss 4.5884 (4.2993)
2022-11-03 00:56:06,501:INFO: Batch: 16/31	Total Loss 4.1718 (4.2918)
2022-11-03 00:56:06,977:INFO: Batch: 17/31	Total Loss 4.3200 (4.2934)
2022-11-03 00:56:07,451:INFO: Batch: 18/31	Total Loss 5.0044 (4.3312)
2022-11-03 00:56:07,924:INFO: Batch: 19/31	Total Loss 4.5381 (4.3417)
2022-11-03 00:56:08,398:INFO: Batch: 20/31	Total Loss 4.7576 (4.3612)
2022-11-03 00:56:08,871:INFO: Batch: 21/31	Total Loss 4.3828 (4.3622)
2022-11-03 00:56:09,343:INFO: Batch: 22/31	Total Loss 4.7721 (4.3808)
2022-11-03 00:56:09,814:INFO: Batch: 23/31	Total Loss 4.0268 (4.3655)
2022-11-03 00:56:10,286:INFO: Batch: 24/31	Total Loss 4.2377 (4.3598)
2022-11-03 00:56:10,757:INFO: Batch: 25/31	Total Loss 4.0266 (4.3471)
2022-11-03 00:56:11,228:INFO: Batch: 26/31	Total Loss 5.3347 (4.3858)
2022-11-03 00:56:11,700:INFO: Batch: 27/31	Total Loss 4.8451 (4.4024)
2022-11-03 00:56:12,170:INFO: Batch: 28/31	Total Loss 3.9680 (4.3892)
2022-11-03 00:56:12,640:INFO: Batch: 29/31	Total Loss 4.6583 (4.3977)
2022-11-03 00:56:13,028:INFO: Batch: 30/31	Total Loss 1.4803 (4.3681)
2022-11-03 00:56:13,180:INFO: - Computing ADE (validation o)
2022-11-03 00:56:13,754:INFO: 		 ADE on eth                       dataset:	 0.9897972941398621
2022-11-03 00:56:13,754:INFO: Average validation o:	ADE  0.9898	FDE  1.8398
2022-11-03 00:56:13,755:INFO: - Computing ADE (validation)
2022-11-03 00:56:14,070:INFO: 		 ADE on hotel                     dataset:	 0.5039145946502686
2022-11-03 00:56:14,374:INFO: 		 ADE on univ                      dataset:	 0.5862880945205688
2022-11-03 00:56:14,622:INFO: 		 ADE on zara1                     dataset:	 0.45813894271850586
2022-11-03 00:56:14,980:INFO: 		 ADE on zara2                     dataset:	 0.4616124927997589
2022-11-03 00:56:14,980:INFO: Average validation:	ADE  0.5286	FDE  1.0940
2022-11-03 00:56:14,980:INFO: - Computing ADE (training)
2022-11-03 00:56:15,418:INFO: 		 ADE on hotel                     dataset:	 0.538178026676178
2022-11-03 00:56:16,129:INFO: 		 ADE on univ                      dataset:	 0.5651718378067017
2022-11-03 00:56:16,653:INFO: 		 ADE on zara1                     dataset:	 0.5596501231193542
2022-11-03 00:56:17,375:INFO: 		 ADE on zara2                     dataset:	 0.4815255403518677
2022-11-03 00:56:17,375:INFO: Average training:	ADE  0.5472	FDE  1.1346
2022-11-03 00:56:17,383:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_446.pth.tar
2022-11-03 00:56:17,383:INFO: 
===> EPOCH: 447 (P3)
2022-11-03 00:56:17,384:INFO: - Computing loss (training)
2022-11-03 00:56:18,563:INFO: Batch:  0/31	Total Loss 4.3970 (4.3970)
2022-11-03 00:56:19,039:INFO: Batch:  1/31	Total Loss 4.6598 (4.5378)
2022-11-03 00:56:19,510:INFO: Batch:  2/31	Total Loss 4.0521 (4.3835)
2022-11-03 00:56:19,980:INFO: Batch:  3/31	Total Loss 4.5786 (4.4351)
2022-11-03 00:56:20,451:INFO: Batch:  4/31	Total Loss 4.7273 (4.4929)
2022-11-03 00:56:20,926:INFO: Batch:  5/31	Total Loss 3.8504 (4.3793)
2022-11-03 00:56:21,394:INFO: Batch:  6/31	Total Loss 3.7724 (4.2906)
2022-11-03 00:56:21,859:INFO: Batch:  7/31	Total Loss 4.5207 (4.3174)
2022-11-03 00:56:22,330:INFO: Batch:  8/31	Total Loss 4.8525 (4.3803)
2022-11-03 00:56:22,799:INFO: Batch:  9/31	Total Loss 4.5757 (4.3991)
2022-11-03 00:56:23,270:INFO: Batch: 10/31	Total Loss 4.2462 (4.3862)
2022-11-03 00:56:23,741:INFO: Batch: 11/31	Total Loss 4.6388 (4.4081)
2022-11-03 00:56:24,214:INFO: Batch: 12/31	Total Loss 3.8887 (4.3693)
2022-11-03 00:56:24,686:INFO: Batch: 13/31	Total Loss 4.2814 (4.3633)
2022-11-03 00:56:25,160:INFO: Batch: 14/31	Total Loss 4.9781 (4.3978)
2022-11-03 00:56:25,634:INFO: Batch: 15/31	Total Loss 4.4477 (4.4010)
2022-11-03 00:56:26,110:INFO: Batch: 16/31	Total Loss 4.1397 (4.3846)
2022-11-03 00:56:26,585:INFO: Batch: 17/31	Total Loss 5.1871 (4.4299)
2022-11-03 00:56:27,061:INFO: Batch: 18/31	Total Loss 4.3070 (4.4232)
2022-11-03 00:56:27,535:INFO: Batch: 19/31	Total Loss 4.5285 (4.4285)
2022-11-03 00:56:28,006:INFO: Batch: 20/31	Total Loss 4.4245 (4.4283)
2022-11-03 00:56:28,483:INFO: Batch: 21/31	Total Loss 5.0599 (4.4565)
2022-11-03 00:56:28,962:INFO: Batch: 22/31	Total Loss 4.0702 (4.4385)
2022-11-03 00:56:29,443:INFO: Batch: 23/31	Total Loss 4.5239 (4.4424)
2022-11-03 00:56:29,920:INFO: Batch: 24/31	Total Loss 4.8689 (4.4594)
2022-11-03 00:56:30,412:INFO: Batch: 25/31	Total Loss 5.1881 (4.4899)
2022-11-03 00:56:31,015:INFO: Batch: 26/31	Total Loss 4.7939 (4.5023)
2022-11-03 00:56:31,676:INFO: Batch: 27/31	Total Loss 4.4960 (4.5021)
2022-11-03 00:56:32,187:INFO: Batch: 28/31	Total Loss 4.7667 (4.5126)
2022-11-03 00:56:32,776:INFO: Batch: 29/31	Total Loss 4.8336 (4.5237)
2022-11-03 00:56:33,194:INFO: Batch: 30/31	Total Loss 1.9498 (4.4953)
2022-11-03 00:56:33,353:INFO: - Computing ADE (validation o)
2022-11-03 00:56:33,911:INFO: 		 ADE on eth                       dataset:	 1.0529195070266724
2022-11-03 00:56:33,911:INFO: Average validation o:	ADE  1.0529	FDE  2.0609
2022-11-03 00:56:33,912:INFO: - Computing ADE (validation)
2022-11-03 00:56:34,189:INFO: 		 ADE on hotel                     dataset:	 0.5751376152038574
2022-11-03 00:56:34,484:INFO: 		 ADE on univ                      dataset:	 0.6231922507286072
2022-11-03 00:56:34,760:INFO: 		 ADE on zara1                     dataset:	 0.5839656591415405
2022-11-03 00:56:35,136:INFO: 		 ADE on zara2                     dataset:	 0.559100866317749
2022-11-03 00:56:35,136:INFO: Average validation:	ADE  0.5948	FDE  1.2809
2022-11-03 00:56:35,137:INFO: - Computing ADE (training)
2022-11-03 00:56:35,640:INFO: 		 ADE on hotel                     dataset:	 0.5918096899986267
2022-11-03 00:56:36,346:INFO: 		 ADE on univ                      dataset:	 0.6366519331932068
2022-11-03 00:56:36,944:INFO: 		 ADE on zara1                     dataset:	 0.6115889549255371
2022-11-03 00:56:37,710:INFO: 		 ADE on zara2                     dataset:	 0.565230131149292
2022-11-03 00:56:37,710:INFO: Average training:	ADE  0.6194	FDE  1.3421
2022-11-03 00:56:37,719:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_447.pth.tar
2022-11-03 00:56:37,719:INFO: 
===> EPOCH: 448 (P3)
2022-11-03 00:56:37,719:INFO: - Computing loss (training)
2022-11-03 00:56:38,856:INFO: Batch:  0/31	Total Loss 5.1164 (5.1164)
2022-11-03 00:56:39,361:INFO: Batch:  1/31	Total Loss 4.7827 (4.9537)
2022-11-03 00:56:39,843:INFO: Batch:  2/31	Total Loss 4.3331 (4.7679)
2022-11-03 00:56:40,349:INFO: Batch:  3/31	Total Loss 4.6227 (4.7316)
2022-11-03 00:56:40,881:INFO: Batch:  4/31	Total Loss 4.4775 (4.6840)
2022-11-03 00:56:41,382:INFO: Batch:  5/31	Total Loss 5.2549 (4.7888)
2022-11-03 00:56:41,892:INFO: Batch:  6/31	Total Loss 4.0968 (4.6881)
2022-11-03 00:56:42,386:INFO: Batch:  7/31	Total Loss 4.8791 (4.7134)
2022-11-03 00:56:42,863:INFO: Batch:  8/31	Total Loss 4.5805 (4.6999)
2022-11-03 00:56:43,340:INFO: Batch:  9/31	Total Loss 3.9770 (4.6294)
2022-11-03 00:56:43,830:INFO: Batch: 10/31	Total Loss 4.0169 (4.5722)
2022-11-03 00:56:44,309:INFO: Batch: 11/31	Total Loss 4.7126 (4.5833)
2022-11-03 00:56:44,800:INFO: Batch: 12/31	Total Loss 4.5864 (4.5836)
2022-11-03 00:56:45,321:INFO: Batch: 13/31	Total Loss 4.0894 (4.5456)
2022-11-03 00:56:45,815:INFO: Batch: 14/31	Total Loss 4.2863 (4.5292)
2022-11-03 00:56:46,331:INFO: Batch: 15/31	Total Loss 4.7265 (4.5403)
2022-11-03 00:56:46,886:INFO: Batch: 16/31	Total Loss 3.8260 (4.5002)
2022-11-03 00:56:47,384:INFO: Batch: 17/31	Total Loss 4.4677 (4.4984)
2022-11-03 00:56:47,896:INFO: Batch: 18/31	Total Loss 4.4989 (4.4985)
2022-11-03 00:56:48,424:INFO: Batch: 19/31	Total Loss 5.3236 (4.5367)
2022-11-03 00:56:48,932:INFO: Batch: 20/31	Total Loss 5.2645 (4.5690)
2022-11-03 00:56:49,420:INFO: Batch: 21/31	Total Loss 4.1379 (4.5477)
2022-11-03 00:56:49,957:INFO: Batch: 22/31	Total Loss 4.3559 (4.5390)
2022-11-03 00:56:50,467:INFO: Batch: 23/31	Total Loss 4.3450 (4.5319)
2022-11-03 00:56:50,958:INFO: Batch: 24/31	Total Loss 4.0688 (4.5126)
2022-11-03 00:56:51,447:INFO: Batch: 25/31	Total Loss 5.3508 (4.5432)
2022-11-03 00:56:51,946:INFO: Batch: 26/31	Total Loss 4.4362 (4.5393)
2022-11-03 00:56:52,438:INFO: Batch: 27/31	Total Loss 6.4003 (4.6050)
2022-11-03 00:56:52,926:INFO: Batch: 28/31	Total Loss 5.4284 (4.6314)
2022-11-03 00:56:53,410:INFO: Batch: 29/31	Total Loss 4.4520 (4.6259)
2022-11-03 00:56:53,801:INFO: Batch: 30/31	Total Loss 2.3108 (4.6025)
2022-11-03 00:56:53,953:INFO: - Computing ADE (validation o)
2022-11-03 00:56:54,536:INFO: 		 ADE on eth                       dataset:	 1.0040321350097656
2022-11-03 00:56:54,537:INFO: Average validation o:	ADE  1.0040	FDE  1.9046
2022-11-03 00:56:54,546:INFO: - Computing ADE (validation)
2022-11-03 00:56:54,841:INFO: 		 ADE on hotel                     dataset:	 0.5075258612632751
2022-11-03 00:56:55,144:INFO: 		 ADE on univ                      dataset:	 0.5893961191177368
2022-11-03 00:56:55,407:INFO: 		 ADE on zara1                     dataset:	 0.5575332641601562
2022-11-03 00:56:55,755:INFO: 		 ADE on zara2                     dataset:	 0.47450128197669983
2022-11-03 00:56:55,756:INFO: Average validation:	ADE  0.5409	FDE  1.1314
2022-11-03 00:56:55,757:INFO: - Computing ADE (training)
2022-11-03 00:56:56,216:INFO: 		 ADE on hotel                     dataset:	 0.547199010848999
2022-11-03 00:56:56,884:INFO: 		 ADE on univ                      dataset:	 0.5778042078018188
2022-11-03 00:56:57,414:INFO: 		 ADE on zara1                     dataset:	 0.5782017111778259
2022-11-03 00:56:58,151:INFO: 		 ADE on zara2                     dataset:	 0.4921782910823822
2022-11-03 00:56:58,151:INFO: Average training:	ADE  0.5597	FDE  1.1735
2022-11-03 00:56:58,160:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_448.pth.tar
2022-11-03 00:56:58,160:INFO: 
===> EPOCH: 449 (P3)
2022-11-03 00:56:58,161:INFO: - Computing loss (training)
2022-11-03 00:56:59,236:INFO: Batch:  0/31	Total Loss 4.6847 (4.6847)
2022-11-03 00:56:59,708:INFO: Batch:  1/31	Total Loss 4.7491 (4.7144)
2022-11-03 00:57:00,184:INFO: Batch:  2/31	Total Loss 4.2449 (4.5524)
2022-11-03 00:57:00,660:INFO: Batch:  3/31	Total Loss 4.6473 (4.5758)
2022-11-03 00:57:01,145:INFO: Batch:  4/31	Total Loss 4.6955 (4.6000)
2022-11-03 00:57:01,624:INFO: Batch:  5/31	Total Loss 4.5296 (4.5879)
2022-11-03 00:57:02,100:INFO: Batch:  6/31	Total Loss 5.0265 (4.6542)
2022-11-03 00:57:02,575:INFO: Batch:  7/31	Total Loss 4.4015 (4.6234)
2022-11-03 00:57:03,047:INFO: Batch:  8/31	Total Loss 5.4509 (4.7016)
2022-11-03 00:57:03,525:INFO: Batch:  9/31	Total Loss 5.0981 (4.7377)
2022-11-03 00:57:04,003:INFO: Batch: 10/31	Total Loss 4.9471 (4.7587)
2022-11-03 00:57:04,476:INFO: Batch: 11/31	Total Loss 4.9644 (4.7763)
2022-11-03 00:57:04,958:INFO: Batch: 12/31	Total Loss 5.6724 (4.8531)
2022-11-03 00:57:05,435:INFO: Batch: 13/31	Total Loss 4.6939 (4.8411)
2022-11-03 00:57:05,911:INFO: Batch: 14/31	Total Loss 5.6558 (4.8905)
2022-11-03 00:57:06,389:INFO: Batch: 15/31	Total Loss 3.8658 (4.8224)
2022-11-03 00:57:06,866:INFO: Batch: 16/31	Total Loss 4.1302 (4.7770)
2022-11-03 00:57:07,343:INFO: Batch: 17/31	Total Loss 4.0166 (4.7341)
2022-11-03 00:57:07,820:INFO: Batch: 18/31	Total Loss 4.0725 (4.6989)
2022-11-03 00:57:08,297:INFO: Batch: 19/31	Total Loss 4.8842 (4.7070)
2022-11-03 00:57:08,774:INFO: Batch: 20/31	Total Loss 4.5577 (4.7003)
2022-11-03 00:57:09,326:INFO: Batch: 21/31	Total Loss 4.4835 (4.6898)
2022-11-03 00:57:09,801:INFO: Batch: 22/31	Total Loss 4.6161 (4.6866)
2022-11-03 00:57:10,279:INFO: Batch: 23/31	Total Loss 4.3670 (4.6733)
2022-11-03 00:57:10,759:INFO: Batch: 24/31	Total Loss 4.3229 (4.6586)
2022-11-03 00:57:11,236:INFO: Batch: 25/31	Total Loss 4.0200 (4.6326)
2022-11-03 00:57:11,714:INFO: Batch: 26/31	Total Loss 4.8565 (4.6408)
2022-11-03 00:57:12,191:INFO: Batch: 27/31	Total Loss 4.5878 (4.6388)
2022-11-03 00:57:12,667:INFO: Batch: 28/31	Total Loss 3.7557 (4.6076)
2022-11-03 00:57:13,141:INFO: Batch: 29/31	Total Loss 4.1934 (4.5926)
2022-11-03 00:57:13,532:INFO: Batch: 30/31	Total Loss 1.8874 (4.5648)
2022-11-03 00:57:13,689:INFO: - Computing ADE (validation o)
2022-11-03 00:57:14,276:INFO: 		 ADE on eth                       dataset:	 0.9604625105857849
2022-11-03 00:57:14,276:INFO: Average validation o:	ADE  0.9605	FDE  1.7903
2022-11-03 00:57:14,277:INFO: - Computing ADE (validation)
2022-11-03 00:57:14,546:INFO: 		 ADE on hotel                     dataset:	 0.4707774817943573
2022-11-03 00:57:14,841:INFO: 		 ADE on univ                      dataset:	 0.5616315007209778
2022-11-03 00:57:15,084:INFO: 		 ADE on zara1                     dataset:	 0.4344496428966522
2022-11-03 00:57:15,426:INFO: 		 ADE on zara2                     dataset:	 0.418659508228302
2022-11-03 00:57:15,426:INFO: Average validation:	ADE  0.4968	FDE  1.0152
2022-11-03 00:57:15,427:INFO: - Computing ADE (training)
2022-11-03 00:57:15,875:INFO: 		 ADE on hotel                     dataset:	 0.49659815430641174
2022-11-03 00:57:16,550:INFO: 		 ADE on univ                      dataset:	 0.5488570332527161
2022-11-03 00:57:17,070:INFO: 		 ADE on zara1                     dataset:	 0.5090397596359253
2022-11-03 00:57:17,798:INFO: 		 ADE on zara2                     dataset:	 0.42356985807418823
2022-11-03 00:57:17,798:INFO: Average training:	ADE  0.5196	FDE  1.0684
2022-11-03 00:57:17,816:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_449.pth.tar
2022-11-03 00:57:17,816:INFO: 
===> EPOCH: 450 (P3)
2022-11-03 00:57:17,816:INFO: - Computing loss (training)
2022-11-03 00:57:18,941:INFO: Batch:  0/31	Total Loss 5.0687 (5.0687)
2022-11-03 00:57:19,425:INFO: Batch:  1/31	Total Loss 4.5137 (4.7759)
2022-11-03 00:57:19,900:INFO: Batch:  2/31	Total Loss 3.7930 (4.4771)
2022-11-03 00:57:20,369:INFO: Batch:  3/31	Total Loss 4.3754 (4.4497)
2022-11-03 00:57:20,838:INFO: Batch:  4/31	Total Loss 4.2516 (4.4043)
2022-11-03 00:57:21,311:INFO: Batch:  5/31	Total Loss 4.7327 (4.4560)
2022-11-03 00:57:21,781:INFO: Batch:  6/31	Total Loss 4.6553 (4.4872)
2022-11-03 00:57:22,250:INFO: Batch:  7/31	Total Loss 4.1186 (4.4379)
2022-11-03 00:57:22,717:INFO: Batch:  8/31	Total Loss 4.5131 (4.4454)
2022-11-03 00:57:23,183:INFO: Batch:  9/31	Total Loss 3.8560 (4.3820)
2022-11-03 00:57:23,653:INFO: Batch: 10/31	Total Loss 3.7573 (4.3208)
2022-11-03 00:57:24,122:INFO: Batch: 11/31	Total Loss 3.9342 (4.2908)
2022-11-03 00:57:24,593:INFO: Batch: 12/31	Total Loss 4.4326 (4.3018)
2022-11-03 00:57:25,069:INFO: Batch: 13/31	Total Loss 4.4381 (4.3112)
2022-11-03 00:57:25,544:INFO: Batch: 14/31	Total Loss 4.1663 (4.3020)
2022-11-03 00:57:26,018:INFO: Batch: 15/31	Total Loss 5.0779 (4.3522)
2022-11-03 00:57:26,490:INFO: Batch: 16/31	Total Loss 4.4449 (4.3575)
2022-11-03 00:57:26,962:INFO: Batch: 17/31	Total Loss 4.0461 (4.3417)
2022-11-03 00:57:27,435:INFO: Batch: 18/31	Total Loss 4.2234 (4.3357)
2022-11-03 00:57:27,905:INFO: Batch: 19/31	Total Loss 4.5801 (4.3471)
2022-11-03 00:57:28,375:INFO: Batch: 20/31	Total Loss 4.0253 (4.3318)
2022-11-03 00:57:28,847:INFO: Batch: 21/31	Total Loss 5.6182 (4.3920)
2022-11-03 00:57:29,320:INFO: Batch: 22/31	Total Loss 4.2828 (4.3872)
2022-11-03 00:57:29,789:INFO: Batch: 23/31	Total Loss 3.9434 (4.3680)
2022-11-03 00:57:30,259:INFO: Batch: 24/31	Total Loss 4.1415 (4.3591)
2022-11-03 00:57:30,729:INFO: Batch: 25/31	Total Loss 4.5224 (4.3650)
2022-11-03 00:57:31,198:INFO: Batch: 26/31	Total Loss 4.5912 (4.3727)
2022-11-03 00:57:31,669:INFO: Batch: 27/31	Total Loss 3.9122 (4.3553)
2022-11-03 00:57:32,141:INFO: Batch: 28/31	Total Loss 4.4294 (4.3578)
2022-11-03 00:57:32,611:INFO: Batch: 29/31	Total Loss 4.0951 (4.3490)
2022-11-03 00:57:33,000:INFO: Batch: 30/31	Total Loss 1.6627 (4.3233)
2022-11-03 00:57:33,152:INFO: - Computing ADE (validation o)
2022-11-03 00:57:33,747:INFO: 		 ADE on eth                       dataset:	 0.9686461091041565
2022-11-03 00:57:33,747:INFO: Average validation o:	ADE  0.9686	FDE  1.8373
2022-11-03 00:57:33,748:INFO: - Computing ADE (validation)
2022-11-03 00:57:34,005:INFO: 		 ADE on hotel                     dataset:	 0.43950268626213074
2022-11-03 00:57:34,291:INFO: 		 ADE on univ                      dataset:	 0.5560773611068726
2022-11-03 00:57:34,546:INFO: 		 ADE on zara1                     dataset:	 0.45986485481262207
2022-11-03 00:57:34,908:INFO: 		 ADE on zara2                     dataset:	 0.41633090376853943
2022-11-03 00:57:34,908:INFO: Average validation:	ADE  0.4928	FDE  1.0059
2022-11-03 00:57:34,909:INFO: - Computing ADE (training)
2022-11-03 00:57:35,360:INFO: 		 ADE on hotel                     dataset:	 0.46790555119514465
2022-11-03 00:57:36,050:INFO: 		 ADE on univ                      dataset:	 0.5414059162139893
2022-11-03 00:57:36,588:INFO: 		 ADE on zara1                     dataset:	 0.5227290987968445
2022-11-03 00:57:37,367:INFO: 		 ADE on zara2                     dataset:	 0.43090227246284485
2022-11-03 00:57:37,368:INFO: Average training:	ADE  0.5159	FDE  1.0603
2022-11-03 00:57:37,377:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_450.pth.tar
2022-11-03 00:57:37,377:INFO: 
===> EPOCH: 451 (P3)
2022-11-03 00:57:37,378:INFO: - Computing loss (training)
2022-11-03 00:57:38,483:INFO: Batch:  0/31	Total Loss 4.5429 (4.5429)
2022-11-03 00:57:38,964:INFO: Batch:  1/31	Total Loss 3.8494 (4.1557)
2022-11-03 00:57:39,448:INFO: Batch:  2/31	Total Loss 3.7086 (4.0057)
2022-11-03 00:57:39,923:INFO: Batch:  3/31	Total Loss 4.3403 (4.0843)
2022-11-03 00:57:40,400:INFO: Batch:  4/31	Total Loss 4.7671 (4.2295)
2022-11-03 00:57:40,883:INFO: Batch:  5/31	Total Loss 4.3284 (4.2462)
2022-11-03 00:57:41,358:INFO: Batch:  6/31	Total Loss 4.8587 (4.3330)
2022-11-03 00:57:41,832:INFO: Batch:  7/31	Total Loss 4.4808 (4.3530)
2022-11-03 00:57:42,307:INFO: Batch:  8/31	Total Loss 4.0244 (4.3182)
2022-11-03 00:57:42,784:INFO: Batch:  9/31	Total Loss 4.0023 (4.2932)
2022-11-03 00:57:43,258:INFO: Batch: 10/31	Total Loss 4.4857 (4.3099)
2022-11-03 00:57:43,732:INFO: Batch: 11/31	Total Loss 4.0326 (4.2873)
2022-11-03 00:57:44,210:INFO: Batch: 12/31	Total Loss 4.3026 (4.2885)
2022-11-03 00:57:44,688:INFO: Batch: 13/31	Total Loss 4.2645 (4.2868)
2022-11-03 00:57:45,168:INFO: Batch: 14/31	Total Loss 4.5153 (4.3028)
2022-11-03 00:57:45,646:INFO: Batch: 15/31	Total Loss 5.0514 (4.3521)
2022-11-03 00:57:46,122:INFO: Batch: 16/31	Total Loss 4.7414 (4.3695)
2022-11-03 00:57:46,601:INFO: Batch: 17/31	Total Loss 4.1552 (4.3575)
2022-11-03 00:57:47,080:INFO: Batch: 18/31	Total Loss 4.3786 (4.3586)
2022-11-03 00:57:47,557:INFO: Batch: 19/31	Total Loss 4.6584 (4.3738)
2022-11-03 00:57:48,035:INFO: Batch: 20/31	Total Loss 5.6034 (4.4351)
2022-11-03 00:57:48,512:INFO: Batch: 21/31	Total Loss 4.0559 (4.4174)
2022-11-03 00:57:48,995:INFO: Batch: 22/31	Total Loss 3.9585 (4.3973)
2022-11-03 00:57:49,472:INFO: Batch: 23/31	Total Loss 4.1409 (4.3863)
2022-11-03 00:57:49,950:INFO: Batch: 24/31	Total Loss 4.4123 (4.3874)
2022-11-03 00:57:50,461:INFO: Batch: 25/31	Total Loss 5.1190 (4.4144)
2022-11-03 00:57:50,960:INFO: Batch: 26/31	Total Loss 4.5761 (4.4205)
2022-11-03 00:57:51,436:INFO: Batch: 27/31	Total Loss 4.3976 (4.4197)
2022-11-03 00:57:51,914:INFO: Batch: 28/31	Total Loss 3.7771 (4.3965)
2022-11-03 00:57:52,387:INFO: Batch: 29/31	Total Loss 4.4614 (4.3988)
2022-11-03 00:57:52,799:INFO: Batch: 30/31	Total Loss 1.7675 (4.3702)
2022-11-03 00:57:52,965:INFO: - Computing ADE (validation o)
2022-11-03 00:57:53,559:INFO: 		 ADE on eth                       dataset:	 0.9720218181610107
2022-11-03 00:57:53,559:INFO: Average validation o:	ADE  0.9720	FDE  1.8423
2022-11-03 00:57:53,560:INFO: - Computing ADE (validation)
2022-11-03 00:57:53,878:INFO: 		 ADE on hotel                     dataset:	 0.4748988747596741
2022-11-03 00:57:54,170:INFO: 		 ADE on univ                      dataset:	 0.575351893901825
2022-11-03 00:57:54,461:INFO: 		 ADE on zara1                     dataset:	 0.4883787930011749
2022-11-03 00:57:54,815:INFO: 		 ADE on zara2                     dataset:	 0.4320380687713623
2022-11-03 00:57:54,815:INFO: Average validation:	ADE  0.5122	FDE  1.0525
2022-11-03 00:57:54,816:INFO: - Computing ADE (training)
2022-11-03 00:57:55,276:INFO: 		 ADE on hotel                     dataset:	 0.522914707660675
2022-11-03 00:57:55,956:INFO: 		 ADE on univ                      dataset:	 0.5550998449325562
2022-11-03 00:57:56,502:INFO: 		 ADE on zara1                     dataset:	 0.539350688457489
2022-11-03 00:57:57,257:INFO: 		 ADE on zara2                     dataset:	 0.44689419865608215
2022-11-03 00:57:57,258:INFO: Average training:	ADE  0.5313	FDE  1.0961
2022-11-03 00:57:57,266:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_451.pth.tar
2022-11-03 00:57:57,266:INFO: 
===> EPOCH: 452 (P3)
2022-11-03 00:57:57,266:INFO: - Computing loss (training)
2022-11-03 00:57:58,360:INFO: Batch:  0/31	Total Loss 4.2678 (4.2678)
2022-11-03 00:57:58,842:INFO: Batch:  1/31	Total Loss 4.2112 (4.2379)
2022-11-03 00:57:59,316:INFO: Batch:  2/31	Total Loss 3.8612 (4.1089)
2022-11-03 00:57:59,789:INFO: Batch:  3/31	Total Loss 4.7041 (4.2466)
2022-11-03 00:58:00,269:INFO: Batch:  4/31	Total Loss 4.5950 (4.3220)
2022-11-03 00:58:00,740:INFO: Batch:  5/31	Total Loss 4.5141 (4.3542)
2022-11-03 00:58:01,215:INFO: Batch:  6/31	Total Loss 4.3681 (4.3561)
2022-11-03 00:58:01,684:INFO: Batch:  7/31	Total Loss 3.9226 (4.2986)
2022-11-03 00:58:02,152:INFO: Batch:  8/31	Total Loss 3.8893 (4.2561)
2022-11-03 00:58:02,619:INFO: Batch:  9/31	Total Loss 4.4358 (4.2722)
2022-11-03 00:58:03,166:INFO: Batch: 10/31	Total Loss 4.4094 (4.2839)
2022-11-03 00:58:03,639:INFO: Batch: 11/31	Total Loss 4.5634 (4.3095)
2022-11-03 00:58:04,118:INFO: Batch: 12/31	Total Loss 5.0062 (4.3621)
2022-11-03 00:58:04,589:INFO: Batch: 13/31	Total Loss 5.4272 (4.4453)
2022-11-03 00:58:05,065:INFO: Batch: 14/31	Total Loss 4.1723 (4.4277)
2022-11-03 00:58:05,538:INFO: Batch: 15/31	Total Loss 3.7204 (4.3839)
2022-11-03 00:58:06,010:INFO: Batch: 16/31	Total Loss 4.6382 (4.3976)
2022-11-03 00:58:06,482:INFO: Batch: 17/31	Total Loss 4.8231 (4.4213)
2022-11-03 00:58:06,953:INFO: Batch: 18/31	Total Loss 4.0526 (4.4009)
2022-11-03 00:58:07,426:INFO: Batch: 19/31	Total Loss 4.2304 (4.3925)
2022-11-03 00:58:07,895:INFO: Batch: 20/31	Total Loss 4.4384 (4.3947)
2022-11-03 00:58:08,366:INFO: Batch: 21/31	Total Loss 5.0418 (4.4210)
2022-11-03 00:58:08,836:INFO: Batch: 22/31	Total Loss 4.4317 (4.4214)
2022-11-03 00:58:09,311:INFO: Batch: 23/31	Total Loss 4.3745 (4.4196)
2022-11-03 00:58:09,780:INFO: Batch: 24/31	Total Loss 4.2298 (4.4127)
2022-11-03 00:58:10,251:INFO: Batch: 25/31	Total Loss 4.1904 (4.4043)
2022-11-03 00:58:10,721:INFO: Batch: 26/31	Total Loss 3.9756 (4.3878)
2022-11-03 00:58:11,254:INFO: Batch: 27/31	Total Loss 4.6553 (4.3971)
2022-11-03 00:58:11,765:INFO: Batch: 28/31	Total Loss 5.0128 (4.4173)
2022-11-03 00:58:12,248:INFO: Batch: 29/31	Total Loss 4.3432 (4.4148)
2022-11-03 00:58:12,644:INFO: Batch: 30/31	Total Loss 1.8237 (4.3933)
2022-11-03 00:58:12,804:INFO: - Computing ADE (validation o)
2022-11-03 00:58:13,447:INFO: 		 ADE on eth                       dataset:	 0.9867386221885681
2022-11-03 00:58:13,447:INFO: Average validation o:	ADE  0.9867	FDE  1.8640
2022-11-03 00:58:13,448:INFO: - Computing ADE (validation)
2022-11-03 00:58:13,766:INFO: 		 ADE on hotel                     dataset:	 0.44574305415153503
2022-11-03 00:58:14,123:INFO: 		 ADE on univ                      dataset:	 0.5566043853759766
2022-11-03 00:58:14,393:INFO: 		 ADE on zara1                     dataset:	 0.47636887431144714
2022-11-03 00:58:14,761:INFO: 		 ADE on zara2                     dataset:	 0.4237721562385559
2022-11-03 00:58:14,761:INFO: Average validation:	ADE  0.4971	FDE  1.0082
2022-11-03 00:58:14,762:INFO: - Computing ADE (training)
2022-11-03 00:58:15,276:INFO: 		 ADE on hotel                     dataset:	 0.4817660450935364
2022-11-03 00:58:16,006:INFO: 		 ADE on univ                      dataset:	 0.5441058874130249
2022-11-03 00:58:16,610:INFO: 		 ADE on zara1                     dataset:	 0.5425997376441956
2022-11-03 00:58:17,397:INFO: 		 ADE on zara2                     dataset:	 0.44385668635368347
2022-11-03 00:58:17,397:INFO: Average training:	ADE  0.5221	FDE  1.0682
2022-11-03 00:58:17,406:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_452.pth.tar
2022-11-03 00:58:17,406:INFO: 
===> EPOCH: 453 (P3)
2022-11-03 00:58:17,407:INFO: - Computing loss (training)
2022-11-03 00:58:18,568:INFO: Batch:  0/31	Total Loss 4.4479 (4.4479)
2022-11-03 00:58:19,064:INFO: Batch:  1/31	Total Loss 4.6243 (4.5368)
2022-11-03 00:58:19,535:INFO: Batch:  2/31	Total Loss 4.5933 (4.5554)
2022-11-03 00:58:20,029:INFO: Batch:  3/31	Total Loss 4.3696 (4.5087)
2022-11-03 00:58:20,508:INFO: Batch:  4/31	Total Loss 4.1156 (4.4286)
2022-11-03 00:58:20,989:INFO: Batch:  5/31	Total Loss 4.4251 (4.4281)
2022-11-03 00:58:21,500:INFO: Batch:  6/31	Total Loss 4.0750 (4.3776)
2022-11-03 00:58:22,049:INFO: Batch:  7/31	Total Loss 4.7118 (4.4193)
2022-11-03 00:58:22,529:INFO: Batch:  8/31	Total Loss 4.7431 (4.4556)
2022-11-03 00:58:23,000:INFO: Batch:  9/31	Total Loss 6.5725 (4.6553)
2022-11-03 00:58:23,489:INFO: Batch: 10/31	Total Loss 4.3665 (4.6309)
2022-11-03 00:58:24,007:INFO: Batch: 11/31	Total Loss 4.1583 (4.5925)
2022-11-03 00:58:24,526:INFO: Batch: 12/31	Total Loss 4.6481 (4.5971)
2022-11-03 00:58:25,025:INFO: Batch: 13/31	Total Loss 4.1542 (4.5690)
2022-11-03 00:58:25,529:INFO: Batch: 14/31	Total Loss 5.1002 (4.6068)
2022-11-03 00:58:26,067:INFO: Batch: 15/31	Total Loss 5.2039 (4.6484)
2022-11-03 00:58:26,626:INFO: Batch: 16/31	Total Loss 4.8930 (4.6628)
2022-11-03 00:58:27,190:INFO: Batch: 17/31	Total Loss 4.8893 (4.6753)
2022-11-03 00:58:27,753:INFO: Batch: 18/31	Total Loss 4.6770 (4.6754)
2022-11-03 00:58:28,241:INFO: Batch: 19/31	Total Loss 4.5223 (4.6675)
2022-11-03 00:58:28,736:INFO: Batch: 20/31	Total Loss 4.3799 (4.6524)
2022-11-03 00:58:29,231:INFO: Batch: 21/31	Total Loss 4.4150 (4.6413)
2022-11-03 00:58:29,766:INFO: Batch: 22/31	Total Loss 4.1998 (4.6207)
2022-11-03 00:58:30,321:INFO: Batch: 23/31	Total Loss 4.5906 (4.6195)
2022-11-03 00:58:30,870:INFO: Batch: 24/31	Total Loss 4.3268 (4.6081)
2022-11-03 00:58:31,402:INFO: Batch: 25/31	Total Loss 4.2607 (4.5944)
2022-11-03 00:58:31,939:INFO: Batch: 26/31	Total Loss 4.5973 (4.5945)
2022-11-03 00:58:32,461:INFO: Batch: 27/31	Total Loss 4.3312 (4.5850)
2022-11-03 00:58:32,995:INFO: Batch: 28/31	Total Loss 4.2638 (4.5743)
2022-11-03 00:58:33,514:INFO: Batch: 29/31	Total Loss 3.9065 (4.5509)
2022-11-03 00:58:33,906:INFO: Batch: 30/31	Total Loss 1.5888 (4.5177)
2022-11-03 00:58:34,063:INFO: - Computing ADE (validation o)
2022-11-03 00:58:34,728:INFO: 		 ADE on eth                       dataset:	 0.9671348929405212
2022-11-03 00:58:34,728:INFO: Average validation o:	ADE  0.9671	FDE  1.8150
2022-11-03 00:58:34,729:INFO: - Computing ADE (validation)
2022-11-03 00:58:35,006:INFO: 		 ADE on hotel                     dataset:	 0.47701534628868103
2022-11-03 00:58:35,296:INFO: 		 ADE on univ                      dataset:	 0.5628325343132019
2022-11-03 00:58:35,547:INFO: 		 ADE on zara1                     dataset:	 0.4381701946258545
2022-11-03 00:58:35,917:INFO: 		 ADE on zara2                     dataset:	 0.41413038969039917
2022-11-03 00:58:35,918:INFO: Average validation:	ADE  0.4963	FDE  1.0089
2022-11-03 00:58:35,919:INFO: - Computing ADE (training)
2022-11-03 00:58:36,402:INFO: 		 ADE on hotel                     dataset:	 0.5108751058578491
2022-11-03 00:58:37,315:INFO: 		 ADE on univ                      dataset:	 0.5455309152603149
2022-11-03 00:58:37,991:INFO: 		 ADE on zara1                     dataset:	 0.5168501138687134
2022-11-03 00:58:38,741:INFO: 		 ADE on zara2                     dataset:	 0.42638450860977173
2022-11-03 00:58:38,742:INFO: Average training:	ADE  0.5186	FDE  1.0586
2022-11-03 00:58:38,750:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_453.pth.tar
2022-11-03 00:58:38,750:INFO: 
===> EPOCH: 454 (P3)
2022-11-03 00:58:38,751:INFO: - Computing loss (training)
2022-11-03 00:58:39,855:INFO: Batch:  0/31	Total Loss 4.8428 (4.8428)
2022-11-03 00:58:40,331:INFO: Batch:  1/31	Total Loss 5.2702 (5.0366)
2022-11-03 00:58:40,811:INFO: Batch:  2/31	Total Loss 4.4362 (4.8336)
2022-11-03 00:58:41,284:INFO: Batch:  3/31	Total Loss 4.1241 (4.6511)
2022-11-03 00:58:41,759:INFO: Batch:  4/31	Total Loss 3.8750 (4.4833)
2022-11-03 00:58:42,233:INFO: Batch:  5/31	Total Loss 4.8777 (4.5471)
2022-11-03 00:58:42,708:INFO: Batch:  6/31	Total Loss 4.4764 (4.5374)
2022-11-03 00:58:43,177:INFO: Batch:  7/31	Total Loss 4.6246 (4.5478)
2022-11-03 00:58:43,649:INFO: Batch:  8/31	Total Loss 3.9383 (4.4825)
2022-11-03 00:58:44,120:INFO: Batch:  9/31	Total Loss 4.2709 (4.4605)
2022-11-03 00:58:44,594:INFO: Batch: 10/31	Total Loss 4.2219 (4.4380)
2022-11-03 00:58:45,068:INFO: Batch: 11/31	Total Loss 4.3672 (4.4319)
2022-11-03 00:58:45,545:INFO: Batch: 12/31	Total Loss 4.5037 (4.4367)
2022-11-03 00:58:46,018:INFO: Batch: 13/31	Total Loss 5.0182 (4.4767)
2022-11-03 00:58:46,490:INFO: Batch: 14/31	Total Loss 4.6801 (4.4901)
2022-11-03 00:58:46,965:INFO: Batch: 15/31	Total Loss 4.7041 (4.5036)
2022-11-03 00:58:47,435:INFO: Batch: 16/31	Total Loss 4.5817 (4.5084)
2022-11-03 00:58:47,907:INFO: Batch: 17/31	Total Loss 4.5655 (4.5121)
2022-11-03 00:58:48,379:INFO: Batch: 18/31	Total Loss 4.1206 (4.4898)
2022-11-03 00:58:48,851:INFO: Batch: 19/31	Total Loss 3.9360 (4.4623)
2022-11-03 00:58:49,322:INFO: Batch: 20/31	Total Loss 4.3888 (4.4584)
2022-11-03 00:58:49,797:INFO: Batch: 21/31	Total Loss 3.8891 (4.4337)
2022-11-03 00:58:50,271:INFO: Batch: 22/31	Total Loss 3.9913 (4.4142)
2022-11-03 00:58:50,742:INFO: Batch: 23/31	Total Loss 4.2097 (4.4042)
2022-11-03 00:58:51,212:INFO: Batch: 24/31	Total Loss 5.5005 (4.4500)
2022-11-03 00:58:51,684:INFO: Batch: 25/31	Total Loss 4.9081 (4.4671)
2022-11-03 00:58:52,156:INFO: Batch: 26/31	Total Loss 4.3137 (4.4617)
2022-11-03 00:58:52,629:INFO: Batch: 27/31	Total Loss 4.3394 (4.4578)
2022-11-03 00:58:53,101:INFO: Batch: 28/31	Total Loss 4.4180 (4.4565)
2022-11-03 00:58:53,571:INFO: Batch: 29/31	Total Loss 5.1990 (4.4809)
2022-11-03 00:58:54,036:INFO: Batch: 30/31	Total Loss 2.1574 (4.4610)
2022-11-03 00:58:54,185:INFO: - Computing ADE (validation o)
2022-11-03 00:58:54,754:INFO: 		 ADE on eth                       dataset:	 1.0049837827682495
2022-11-03 00:58:54,755:INFO: Average validation o:	ADE  1.0050	FDE  1.9411
2022-11-03 00:58:54,755:INFO: - Computing ADE (validation)
2022-11-03 00:58:55,018:INFO: 		 ADE on hotel                     dataset:	 0.47224387526512146
2022-11-03 00:58:55,326:INFO: 		 ADE on univ                      dataset:	 0.5706363916397095
2022-11-03 00:58:55,587:INFO: 		 ADE on zara1                     dataset:	 0.5150071978569031
2022-11-03 00:58:55,925:INFO: 		 ADE on zara2                     dataset:	 0.470723420381546
2022-11-03 00:58:55,925:INFO: Average validation:	ADE  0.5254	FDE  1.0951
2022-11-03 00:58:55,925:INFO: - Computing ADE (training)
2022-11-03 00:58:56,386:INFO: 		 ADE on hotel                     dataset:	 0.491812139749527
2022-11-03 00:58:57,129:INFO: 		 ADE on univ                      dataset:	 0.5709585547447205
2022-11-03 00:58:57,663:INFO: 		 ADE on zara1                     dataset:	 0.5575275421142578
2022-11-03 00:58:58,397:INFO: 		 ADE on zara2                     dataset:	 0.4850602447986603
2022-11-03 00:58:58,397:INFO: Average training:	ADE  0.5507	FDE  1.1569
2022-11-03 00:58:58,406:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_454.pth.tar
2022-11-03 00:58:58,406:INFO: 
===> EPOCH: 455 (P3)
2022-11-03 00:58:58,406:INFO: - Computing loss (training)
2022-11-03 00:58:59,492:INFO: Batch:  0/31	Total Loss 4.6610 (4.6610)
2022-11-03 00:58:59,969:INFO: Batch:  1/31	Total Loss 4.3674 (4.5169)
2022-11-03 00:59:00,444:INFO: Batch:  2/31	Total Loss 4.6693 (4.5665)
2022-11-03 00:59:00,911:INFO: Batch:  3/31	Total Loss 4.1003 (4.4475)
2022-11-03 00:59:01,383:INFO: Batch:  4/31	Total Loss 4.2211 (4.4015)
2022-11-03 00:59:01,858:INFO: Batch:  5/31	Total Loss 3.9677 (4.3308)
2022-11-03 00:59:02,329:INFO: Batch:  6/31	Total Loss 5.0393 (4.4431)
2022-11-03 00:59:02,798:INFO: Batch:  7/31	Total Loss 4.7597 (4.4844)
2022-11-03 00:59:03,266:INFO: Batch:  8/31	Total Loss 4.3283 (4.4661)
2022-11-03 00:59:03,736:INFO: Batch:  9/31	Total Loss 4.8388 (4.5002)
2022-11-03 00:59:04,207:INFO: Batch: 10/31	Total Loss 4.3574 (4.4881)
2022-11-03 00:59:04,678:INFO: Batch: 11/31	Total Loss 4.3403 (4.4760)
2022-11-03 00:59:05,153:INFO: Batch: 12/31	Total Loss 4.7614 (4.4985)
2022-11-03 00:59:05,627:INFO: Batch: 13/31	Total Loss 4.5033 (4.4988)
2022-11-03 00:59:06,101:INFO: Batch: 14/31	Total Loss 4.7556 (4.5158)
2022-11-03 00:59:06,577:INFO: Batch: 15/31	Total Loss 3.9529 (4.4773)
2022-11-03 00:59:07,052:INFO: Batch: 16/31	Total Loss 4.4665 (4.4766)
2022-11-03 00:59:07,526:INFO: Batch: 17/31	Total Loss 4.9079 (4.4991)
2022-11-03 00:59:08,004:INFO: Batch: 18/31	Total Loss 4.1884 (4.4821)
2022-11-03 00:59:08,475:INFO: Batch: 19/31	Total Loss 4.1653 (4.4649)
2022-11-03 00:59:08,946:INFO: Batch: 20/31	Total Loss 3.9307 (4.4398)
2022-11-03 00:59:09,429:INFO: Batch: 21/31	Total Loss 4.9976 (4.4631)
2022-11-03 00:59:09,899:INFO: Batch: 22/31	Total Loss 4.5315 (4.4658)
2022-11-03 00:59:10,376:INFO: Batch: 23/31	Total Loss 4.1626 (4.4526)
2022-11-03 00:59:10,847:INFO: Batch: 24/31	Total Loss 4.1630 (4.4409)
2022-11-03 00:59:11,318:INFO: Batch: 25/31	Total Loss 4.5235 (4.4442)
2022-11-03 00:59:11,790:INFO: Batch: 26/31	Total Loss 4.6021 (4.4506)
2022-11-03 00:59:12,261:INFO: Batch: 27/31	Total Loss 4.8235 (4.4645)
2022-11-03 00:59:12,734:INFO: Batch: 28/31	Total Loss 4.2140 (4.4555)
2022-11-03 00:59:13,207:INFO: Batch: 29/31	Total Loss 3.7675 (4.4321)
2022-11-03 00:59:13,599:INFO: Batch: 30/31	Total Loss 2.1911 (4.4104)
2022-11-03 00:59:13,740:INFO: - Computing ADE (validation o)
2022-11-03 00:59:14,326:INFO: 		 ADE on eth                       dataset:	 0.9670640826225281
2022-11-03 00:59:14,326:INFO: Average validation o:	ADE  0.9671	FDE  1.8090
2022-11-03 00:59:14,327:INFO: - Computing ADE (validation)
2022-11-03 00:59:14,619:INFO: 		 ADE on hotel                     dataset:	 0.45767393708229065
2022-11-03 00:59:14,916:INFO: 		 ADE on univ                      dataset:	 0.5664586424827576
2022-11-03 00:59:15,172:INFO: 		 ADE on zara1                     dataset:	 0.470662921667099
2022-11-03 00:59:15,506:INFO: 		 ADE on zara2                     dataset:	 0.4262089729309082
2022-11-03 00:59:15,506:INFO: Average validation:	ADE  0.5035	FDE  1.0313
2022-11-03 00:59:15,516:INFO: - Computing ADE (training)
2022-11-03 00:59:15,971:INFO: 		 ADE on hotel                     dataset:	 0.4918665289878845
2022-11-03 00:59:16,634:INFO: 		 ADE on univ                      dataset:	 0.5467401146888733
2022-11-03 00:59:17,179:INFO: 		 ADE on zara1                     dataset:	 0.5333219766616821
2022-11-03 00:59:17,979:INFO: 		 ADE on zara2                     dataset:	 0.44369998574256897
2022-11-03 00:59:17,979:INFO: Average training:	ADE  0.5236	FDE  1.0763
2022-11-03 00:59:17,989:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_455.pth.tar
2022-11-03 00:59:17,989:INFO: 
===> EPOCH: 456 (P3)
2022-11-03 00:59:17,989:INFO: - Computing loss (training)
2022-11-03 00:59:19,095:INFO: Batch:  0/31	Total Loss 4.4748 (4.4748)
2022-11-03 00:59:19,581:INFO: Batch:  1/31	Total Loss 4.0751 (4.2698)
2022-11-03 00:59:20,059:INFO: Batch:  2/31	Total Loss 4.2611 (4.2670)
2022-11-03 00:59:20,535:INFO: Batch:  3/31	Total Loss 4.0973 (4.2261)
2022-11-03 00:59:21,007:INFO: Batch:  4/31	Total Loss 4.0822 (4.1970)
2022-11-03 00:59:21,484:INFO: Batch:  5/31	Total Loss 4.4502 (4.2379)
2022-11-03 00:59:21,954:INFO: Batch:  6/31	Total Loss 4.4806 (4.2709)
2022-11-03 00:59:22,424:INFO: Batch:  7/31	Total Loss 4.2543 (4.2688)
2022-11-03 00:59:22,896:INFO: Batch:  8/31	Total Loss 4.1176 (4.2519)
2022-11-03 00:59:23,366:INFO: Batch:  9/31	Total Loss 4.6544 (4.2953)
2022-11-03 00:59:23,839:INFO: Batch: 10/31	Total Loss 4.2235 (4.2888)
2022-11-03 00:59:24,322:INFO: Batch: 11/31	Total Loss 4.2463 (4.2852)
2022-11-03 00:59:24,814:INFO: Batch: 12/31	Total Loss 4.0960 (4.2693)
2022-11-03 00:59:25,291:INFO: Batch: 13/31	Total Loss 4.3361 (4.2747)
2022-11-03 00:59:25,778:INFO: Batch: 14/31	Total Loss 3.9279 (4.2529)
2022-11-03 00:59:26,277:INFO: Batch: 15/31	Total Loss 4.1396 (4.2463)
2022-11-03 00:59:26,764:INFO: Batch: 16/31	Total Loss 4.6394 (4.2699)
2022-11-03 00:59:27,256:INFO: Batch: 17/31	Total Loss 3.5792 (4.2325)
2022-11-03 00:59:27,794:INFO: Batch: 18/31	Total Loss 4.3061 (4.2366)
2022-11-03 00:59:28,371:INFO: Batch: 19/31	Total Loss 4.6563 (4.2583)
2022-11-03 00:59:28,866:INFO: Batch: 20/31	Total Loss 4.1932 (4.2553)
2022-11-03 00:59:29,379:INFO: Batch: 21/31	Total Loss 3.4225 (4.2138)
2022-11-03 00:59:29,949:INFO: Batch: 22/31	Total Loss 4.1715 (4.2119)
2022-11-03 00:59:30,460:INFO: Batch: 23/31	Total Loss 3.9330 (4.1989)
2022-11-03 00:59:31,013:INFO: Batch: 24/31	Total Loss 4.2649 (4.2014)
2022-11-03 00:59:31,532:INFO: Batch: 25/31	Total Loss 4.3001 (4.2053)
2022-11-03 00:59:32,068:INFO: Batch: 26/31	Total Loss 4.5865 (4.2179)
2022-11-03 00:59:32,614:INFO: Batch: 27/31	Total Loss 4.4618 (4.2265)
2022-11-03 00:59:33,140:INFO: Batch: 28/31	Total Loss 4.9504 (4.2483)
2022-11-03 00:59:33,661:INFO: Batch: 29/31	Total Loss 4.8370 (4.2661)
2022-11-03 00:59:34,109:INFO: Batch: 30/31	Total Loss 1.5514 (4.2440)
2022-11-03 00:59:34,271:INFO: - Computing ADE (validation o)
2022-11-03 00:59:34,978:INFO: 		 ADE on eth                       dataset:	 0.9729579091072083
2022-11-03 00:59:34,979:INFO: Average validation o:	ADE  0.9730	FDE  1.8614
2022-11-03 00:59:34,980:INFO: - Computing ADE (validation)
2022-11-03 00:59:35,265:INFO: 		 ADE on hotel                     dataset:	 0.4546188414096832
2022-11-03 00:59:35,570:INFO: 		 ADE on univ                      dataset:	 0.5638702511787415
2022-11-03 00:59:35,835:INFO: 		 ADE on zara1                     dataset:	 0.4831845164299011
2022-11-03 00:59:36,177:INFO: 		 ADE on zara2                     dataset:	 0.42780137062072754
2022-11-03 00:59:36,177:INFO: Average validation:	ADE  0.5033	FDE  1.0409
2022-11-03 00:59:36,178:INFO: - Computing ADE (training)
2022-11-03 00:59:36,655:INFO: 		 ADE on hotel                     dataset:	 0.48853304982185364
2022-11-03 00:59:37,378:INFO: 		 ADE on univ                      dataset:	 0.5501070618629456
2022-11-03 00:59:38,006:INFO: 		 ADE on zara1                     dataset:	 0.5291588306427002
2022-11-03 00:59:38,854:INFO: 		 ADE on zara2                     dataset:	 0.44194215536117554
2022-11-03 00:59:38,854:INFO: Average training:	ADE  0.5253	FDE  1.0923
2022-11-03 00:59:38,863:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_456.pth.tar
2022-11-03 00:59:38,863:INFO: 
===> EPOCH: 457 (P3)
2022-11-03 00:59:38,864:INFO: - Computing loss (training)
2022-11-03 00:59:40,004:INFO: Batch:  0/31	Total Loss 4.0086 (4.0086)
2022-11-03 00:59:40,540:INFO: Batch:  1/31	Total Loss 4.8449 (4.3811)
2022-11-03 00:59:41,075:INFO: Batch:  2/31	Total Loss 4.6028 (4.4568)
2022-11-03 00:59:41,599:INFO: Batch:  3/31	Total Loss 3.5829 (4.2241)
2022-11-03 00:59:42,113:INFO: Batch:  4/31	Total Loss 4.5814 (4.2979)
2022-11-03 00:59:42,625:INFO: Batch:  5/31	Total Loss 4.7766 (4.3801)
2022-11-03 00:59:43,098:INFO: Batch:  6/31	Total Loss 4.1620 (4.3467)
2022-11-03 00:59:43,599:INFO: Batch:  7/31	Total Loss 4.2102 (4.3290)
2022-11-03 00:59:44,099:INFO: Batch:  8/31	Total Loss 4.2179 (4.3163)
2022-11-03 00:59:44,579:INFO: Batch:  9/31	Total Loss 4.2857 (4.3134)
2022-11-03 00:59:45,070:INFO: Batch: 10/31	Total Loss 4.7121 (4.3494)
2022-11-03 00:59:45,603:INFO: Batch: 11/31	Total Loss 4.5176 (4.3639)
2022-11-03 00:59:46,094:INFO: Batch: 12/31	Total Loss 4.3375 (4.3619)
2022-11-03 00:59:46,612:INFO: Batch: 13/31	Total Loss 4.3350 (4.3600)
2022-11-03 00:59:47,117:INFO: Batch: 14/31	Total Loss 4.2472 (4.3522)
2022-11-03 00:59:47,611:INFO: Batch: 15/31	Total Loss 4.4127 (4.3562)
2022-11-03 00:59:48,092:INFO: Batch: 16/31	Total Loss 4.6030 (4.3703)
2022-11-03 00:59:48,591:INFO: Batch: 17/31	Total Loss 4.2157 (4.3617)
2022-11-03 00:59:49,088:INFO: Batch: 18/31	Total Loss 4.1295 (4.3508)
2022-11-03 00:59:49,716:INFO: Batch: 19/31	Total Loss 4.4842 (4.3576)
2022-11-03 00:59:50,228:INFO: Batch: 20/31	Total Loss 3.9864 (4.3366)
2022-11-03 00:59:50,762:INFO: Batch: 21/31	Total Loss 4.2931 (4.3347)
2022-11-03 00:59:51,277:INFO: Batch: 22/31	Total Loss 3.9687 (4.3189)
2022-11-03 00:59:51,752:INFO: Batch: 23/31	Total Loss 3.9253 (4.3030)
2022-11-03 00:59:52,225:INFO: Batch: 24/31	Total Loss 4.6367 (4.3157)
2022-11-03 00:59:52,757:INFO: Batch: 25/31	Total Loss 3.9787 (4.3022)
2022-11-03 00:59:53,338:INFO: Batch: 26/31	Total Loss 4.2100 (4.2988)
2022-11-03 00:59:53,884:INFO: Batch: 27/31	Total Loss 4.4955 (4.3053)
2022-11-03 00:59:54,405:INFO: Batch: 28/31	Total Loss 4.4828 (4.3108)
2022-11-03 00:59:54,941:INFO: Batch: 29/31	Total Loss 4.4648 (4.3154)
2022-11-03 00:59:55,361:INFO: Batch: 30/31	Total Loss 1.5267 (4.2929)
2022-11-03 00:59:55,510:INFO: - Computing ADE (validation o)
2022-11-03 00:59:56,136:INFO: 		 ADE on eth                       dataset:	 0.9670634865760803
2022-11-03 00:59:56,137:INFO: Average validation o:	ADE  0.9671	FDE  1.8886
2022-11-03 00:59:56,137:INFO: - Computing ADE (validation)
2022-11-03 00:59:56,454:INFO: 		 ADE on hotel                     dataset:	 0.46952879428863525
2022-11-03 00:59:56,782:INFO: 		 ADE on univ                      dataset:	 0.5581569671630859
2022-11-03 00:59:57,070:INFO: 		 ADE on zara1                     dataset:	 0.41900309920310974
2022-11-03 00:59:57,589:INFO: 		 ADE on zara2                     dataset:	 0.4287799894809723
2022-11-03 00:59:57,590:INFO: Average validation:	ADE  0.4978	FDE  1.0229
2022-11-03 00:59:57,591:INFO: - Computing ADE (training)
2022-11-03 00:59:58,092:INFO: 		 ADE on hotel                     dataset:	 0.49698829650878906
2022-11-03 00:59:58,756:INFO: 		 ADE on univ                      dataset:	 0.5546584725379944
2022-11-03 00:59:59,318:INFO: 		 ADE on zara1                     dataset:	 0.4930264353752136
2022-11-03 01:00:00,108:INFO: 		 ADE on zara2                     dataset:	 0.4313056468963623
2022-11-03 01:00:00,109:INFO: Average training:	ADE  0.5242	FDE  1.0856
2022-11-03 01:00:00,117:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_457.pth.tar
2022-11-03 01:00:00,118:INFO: 
===> EPOCH: 458 (P3)
2022-11-03 01:00:00,118:INFO: - Computing loss (training)
2022-11-03 01:00:01,234:INFO: Batch:  0/31	Total Loss 4.8260 (4.8260)
2022-11-03 01:00:01,717:INFO: Batch:  1/31	Total Loss 4.8017 (4.8131)
2022-11-03 01:00:02,206:INFO: Batch:  2/31	Total Loss 4.4061 (4.6700)
2022-11-03 01:00:02,689:INFO: Batch:  3/31	Total Loss 4.3157 (4.5872)
2022-11-03 01:00:03,167:INFO: Batch:  4/31	Total Loss 4.1819 (4.5159)
2022-11-03 01:00:03,642:INFO: Batch:  5/31	Total Loss 3.8915 (4.4168)
2022-11-03 01:00:04,115:INFO: Batch:  6/31	Total Loss 4.6330 (4.4468)
2022-11-03 01:00:04,582:INFO: Batch:  7/31	Total Loss 4.4795 (4.4510)
2022-11-03 01:00:05,052:INFO: Batch:  8/31	Total Loss 4.2819 (4.4334)
2022-11-03 01:00:05,520:INFO: Batch:  9/31	Total Loss 4.2612 (4.4166)
2022-11-03 01:00:06,007:INFO: Batch: 10/31	Total Loss 4.6806 (4.4407)
2022-11-03 01:00:06,480:INFO: Batch: 11/31	Total Loss 4.3945 (4.4368)
2022-11-03 01:00:06,959:INFO: Batch: 12/31	Total Loss 4.9984 (4.4823)
2022-11-03 01:00:07,436:INFO: Batch: 13/31	Total Loss 4.8133 (4.5063)
2022-11-03 01:00:07,917:INFO: Batch: 14/31	Total Loss 4.3704 (4.4973)
2022-11-03 01:00:08,401:INFO: Batch: 15/31	Total Loss 4.3679 (4.4893)
2022-11-03 01:00:08,879:INFO: Batch: 16/31	Total Loss 4.5276 (4.4916)
2022-11-03 01:00:09,360:INFO: Batch: 17/31	Total Loss 4.0693 (4.4673)
2022-11-03 01:00:09,840:INFO: Batch: 18/31	Total Loss 4.6054 (4.4755)
2022-11-03 01:00:10,320:INFO: Batch: 19/31	Total Loss 5.4017 (4.5182)
2022-11-03 01:00:10,797:INFO: Batch: 20/31	Total Loss 4.5740 (4.5207)
2022-11-03 01:00:11,272:INFO: Batch: 21/31	Total Loss 4.6472 (4.5263)
2022-11-03 01:00:11,748:INFO: Batch: 22/31	Total Loss 4.7409 (4.5343)
2022-11-03 01:00:12,223:INFO: Batch: 23/31	Total Loss 5.6801 (4.5782)
2022-11-03 01:00:12,700:INFO: Batch: 24/31	Total Loss 4.1458 (4.5610)
2022-11-03 01:00:13,177:INFO: Batch: 25/31	Total Loss 4.8561 (4.5719)
2022-11-03 01:00:13,666:INFO: Batch: 26/31	Total Loss 4.0398 (4.5532)
2022-11-03 01:00:14,143:INFO: Batch: 27/31	Total Loss 4.0791 (4.5351)
2022-11-03 01:00:14,621:INFO: Batch: 28/31	Total Loss 3.9575 (4.5158)
2022-11-03 01:00:15,099:INFO: Batch: 29/31	Total Loss 3.9563 (4.4950)
2022-11-03 01:00:15,489:INFO: Batch: 30/31	Total Loss 1.6026 (4.4753)
2022-11-03 01:00:15,645:INFO: - Computing ADE (validation o)
2022-11-03 01:00:16,250:INFO: 		 ADE on eth                       dataset:	 1.00121009349823
2022-11-03 01:00:16,250:INFO: Average validation o:	ADE  1.0012	FDE  1.9176
2022-11-03 01:00:16,251:INFO: - Computing ADE (validation)
2022-11-03 01:00:16,530:INFO: 		 ADE on hotel                     dataset:	 0.4848967492580414
2022-11-03 01:00:16,815:INFO: 		 ADE on univ                      dataset:	 0.5632060766220093
2022-11-03 01:00:17,094:INFO: 		 ADE on zara1                     dataset:	 0.43316543102264404
2022-11-03 01:00:17,439:INFO: 		 ADE on zara2                     dataset:	 0.4560747444629669
2022-11-03 01:00:17,439:INFO: Average validation:	ADE  0.5121	FDE  1.0593
2022-11-03 01:00:17,440:INFO: - Computing ADE (training)
2022-11-03 01:00:17,898:INFO: 		 ADE on hotel                     dataset:	 0.5023255944252014
2022-11-03 01:00:18,577:INFO: 		 ADE on univ                      dataset:	 0.5602126121520996
2022-11-03 01:00:19,106:INFO: 		 ADE on zara1                     dataset:	 0.5218473076820374
2022-11-03 01:00:19,894:INFO: 		 ADE on zara2                     dataset:	 0.46512386202812195
2022-11-03 01:00:19,894:INFO: Average training:	ADE  0.5370	FDE  1.1177
2022-11-03 01:00:19,902:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_458.pth.tar
2022-11-03 01:00:19,902:INFO: 
===> EPOCH: 459 (P3)
2022-11-03 01:00:19,903:INFO: - Computing loss (training)
2022-11-03 01:00:20,981:INFO: Batch:  0/31	Total Loss 4.5272 (4.5272)
2022-11-03 01:00:21,459:INFO: Batch:  1/31	Total Loss 4.8537 (4.6859)
2022-11-03 01:00:21,930:INFO: Batch:  2/31	Total Loss 4.3234 (4.5802)
2022-11-03 01:00:22,410:INFO: Batch:  3/31	Total Loss 3.6248 (4.3330)
2022-11-03 01:00:22,878:INFO: Batch:  4/31	Total Loss 4.5319 (4.3759)
2022-11-03 01:00:23,347:INFO: Batch:  5/31	Total Loss 5.3858 (4.5473)
2022-11-03 01:00:23,813:INFO: Batch:  6/31	Total Loss 4.5995 (4.5546)
2022-11-03 01:00:24,279:INFO: Batch:  7/31	Total Loss 4.5437 (4.5532)
2022-11-03 01:00:24,742:INFO: Batch:  8/31	Total Loss 4.3267 (4.5282)
2022-11-03 01:00:25,209:INFO: Batch:  9/31	Total Loss 4.1930 (4.4939)
2022-11-03 01:00:25,677:INFO: Batch: 10/31	Total Loss 4.5103 (4.4954)
2022-11-03 01:00:26,148:INFO: Batch: 11/31	Total Loss 4.7073 (4.5128)
2022-11-03 01:00:26,624:INFO: Batch: 12/31	Total Loss 4.2867 (4.4942)
2022-11-03 01:00:27,103:INFO: Batch: 13/31	Total Loss 4.3069 (4.4796)
2022-11-03 01:00:27,582:INFO: Batch: 14/31	Total Loss 5.0064 (4.5126)
2022-11-03 01:00:28,060:INFO: Batch: 15/31	Total Loss 4.4505 (4.5084)
2022-11-03 01:00:28,536:INFO: Batch: 16/31	Total Loss 3.9568 (4.4748)
2022-11-03 01:00:29,014:INFO: Batch: 17/31	Total Loss 4.3172 (4.4654)
2022-11-03 01:00:29,491:INFO: Batch: 18/31	Total Loss 4.3225 (4.4584)
2022-11-03 01:00:29,967:INFO: Batch: 19/31	Total Loss 4.3534 (4.4528)
2022-11-03 01:00:30,447:INFO: Batch: 20/31	Total Loss 4.8024 (4.4697)
2022-11-03 01:00:30,922:INFO: Batch: 21/31	Total Loss 4.6709 (4.4773)
2022-11-03 01:00:31,401:INFO: Batch: 22/31	Total Loss 4.2468 (4.4664)
2022-11-03 01:00:31,878:INFO: Batch: 23/31	Total Loss 4.3252 (4.4611)
2022-11-03 01:00:32,355:INFO: Batch: 24/31	Total Loss 4.3754 (4.4579)
2022-11-03 01:00:32,832:INFO: Batch: 25/31	Total Loss 4.0316 (4.4407)
2022-11-03 01:00:33,307:INFO: Batch: 26/31	Total Loss 4.2297 (4.4329)
2022-11-03 01:00:33,784:INFO: Batch: 27/31	Total Loss 4.1324 (4.4207)
2022-11-03 01:00:34,262:INFO: Batch: 28/31	Total Loss 4.4936 (4.4234)
2022-11-03 01:00:34,740:INFO: Batch: 29/31	Total Loss 4.5177 (4.4267)
2022-11-03 01:00:35,134:INFO: Batch: 30/31	Total Loss 2.0165 (4.4038)
2022-11-03 01:00:35,281:INFO: - Computing ADE (validation o)
2022-11-03 01:00:35,870:INFO: 		 ADE on eth                       dataset:	 0.958985447883606
2022-11-03 01:00:35,870:INFO: Average validation o:	ADE  0.9590	FDE  1.8122
2022-11-03 01:00:35,871:INFO: - Computing ADE (validation)
2022-11-03 01:00:36,139:INFO: 		 ADE on hotel                     dataset:	 0.46173733472824097
2022-11-03 01:00:36,430:INFO: 		 ADE on univ                      dataset:	 0.558927595615387
2022-11-03 01:00:36,666:INFO: 		 ADE on zara1                     dataset:	 0.4417315423488617
2022-11-03 01:00:37,007:INFO: 		 ADE on zara2                     dataset:	 0.4047171175479889
2022-11-03 01:00:37,007:INFO: Average validation:	ADE  0.4902	FDE  0.9958
2022-11-03 01:00:37,008:INFO: - Computing ADE (training)
2022-11-03 01:00:37,444:INFO: 		 ADE on hotel                     dataset:	 0.5051052570343018
2022-11-03 01:00:38,123:INFO: 		 ADE on univ                      dataset:	 0.5415075421333313
2022-11-03 01:00:38,653:INFO: 		 ADE on zara1                     dataset:	 0.5129445791244507
2022-11-03 01:00:39,402:INFO: 		 ADE on zara2                     dataset:	 0.4181768000125885
2022-11-03 01:00:39,402:INFO: Average training:	ADE  0.5137	FDE  1.0496
2022-11-03 01:00:39,410:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_459.pth.tar
2022-11-03 01:00:39,411:INFO: 
===> EPOCH: 460 (P3)
2022-11-03 01:00:39,411:INFO: - Computing loss (training)
2022-11-03 01:00:40,508:INFO: Batch:  0/31	Total Loss 4.5019 (4.5019)
2022-11-03 01:00:40,982:INFO: Batch:  1/31	Total Loss 4.3904 (4.4495)
2022-11-03 01:00:41,456:INFO: Batch:  2/31	Total Loss 4.6220 (4.5057)
2022-11-03 01:00:41,934:INFO: Batch:  3/31	Total Loss 4.2435 (4.4406)
2022-11-03 01:00:42,413:INFO: Batch:  4/31	Total Loss 4.4245 (4.4377)
2022-11-03 01:00:42,887:INFO: Batch:  5/31	Total Loss 3.8902 (4.3498)
2022-11-03 01:00:43,361:INFO: Batch:  6/31	Total Loss 4.8233 (4.4261)
2022-11-03 01:00:43,836:INFO: Batch:  7/31	Total Loss 4.0791 (4.3831)
2022-11-03 01:00:44,386:INFO: Batch:  8/31	Total Loss 4.4772 (4.3941)
2022-11-03 01:00:44,858:INFO: Batch:  9/31	Total Loss 5.0070 (4.4544)
2022-11-03 01:00:45,332:INFO: Batch: 10/31	Total Loss 4.1866 (4.4283)
2022-11-03 01:00:45,797:INFO: Batch: 11/31	Total Loss 4.0516 (4.3940)
2022-11-03 01:00:46,267:INFO: Batch: 12/31	Total Loss 4.3101 (4.3872)
2022-11-03 01:00:46,739:INFO: Batch: 13/31	Total Loss 4.2830 (4.3798)
2022-11-03 01:00:47,210:INFO: Batch: 14/31	Total Loss 4.3992 (4.3812)
2022-11-03 01:00:47,682:INFO: Batch: 15/31	Total Loss 4.2541 (4.3730)
2022-11-03 01:00:48,151:INFO: Batch: 16/31	Total Loss 4.7704 (4.3967)
2022-11-03 01:00:48,621:INFO: Batch: 17/31	Total Loss 4.0571 (4.3772)
2022-11-03 01:00:49,094:INFO: Batch: 18/31	Total Loss 4.3006 (4.3733)
2022-11-03 01:00:49,563:INFO: Batch: 19/31	Total Loss 4.3790 (4.3736)
2022-11-03 01:00:50,032:INFO: Batch: 20/31	Total Loss 4.1639 (4.3625)
2022-11-03 01:00:50,503:INFO: Batch: 21/31	Total Loss 4.7770 (4.3808)
2022-11-03 01:00:50,971:INFO: Batch: 22/31	Total Loss 4.2757 (4.3762)
2022-11-03 01:00:51,444:INFO: Batch: 23/31	Total Loss 4.9656 (4.3972)
2022-11-03 01:00:51,913:INFO: Batch: 24/31	Total Loss 4.6591 (4.4094)
2022-11-03 01:00:52,382:INFO: Batch: 25/31	Total Loss 4.0328 (4.3966)
2022-11-03 01:00:52,852:INFO: Batch: 26/31	Total Loss 3.7419 (4.3693)
2022-11-03 01:00:53,322:INFO: Batch: 27/31	Total Loss 4.3990 (4.3703)
2022-11-03 01:00:53,792:INFO: Batch: 28/31	Total Loss 4.2687 (4.3671)
2022-11-03 01:00:54,263:INFO: Batch: 29/31	Total Loss 4.2076 (4.3615)
2022-11-03 01:00:54,650:INFO: Batch: 30/31	Total Loss 1.4432 (4.3334)
2022-11-03 01:00:54,803:INFO: - Computing ADE (validation o)
2022-11-03 01:00:55,374:INFO: 		 ADE on eth                       dataset:	 0.9604849815368652
2022-11-03 01:00:55,374:INFO: Average validation o:	ADE  0.9605	FDE  1.8401
2022-11-03 01:00:55,375:INFO: - Computing ADE (validation)
2022-11-03 01:00:55,644:INFO: 		 ADE on hotel                     dataset:	 0.4528396427631378
2022-11-03 01:00:55,947:INFO: 		 ADE on univ                      dataset:	 0.5521810054779053
2022-11-03 01:00:56,186:INFO: 		 ADE on zara1                     dataset:	 0.4323013722896576
2022-11-03 01:00:56,544:INFO: 		 ADE on zara2                     dataset:	 0.41090941429138184
2022-11-03 01:00:56,545:INFO: Average validation:	ADE  0.4880	FDE  0.9997
2022-11-03 01:00:56,545:INFO: - Computing ADE (training)
2022-11-03 01:00:57,028:INFO: 		 ADE on hotel                     dataset:	 0.4794367551803589
2022-11-03 01:00:57,680:INFO: 		 ADE on univ                      dataset:	 0.5437083840370178
2022-11-03 01:00:58,208:INFO: 		 ADE on zara1                     dataset:	 0.48742377758026123
2022-11-03 01:00:58,958:INFO: 		 ADE on zara2                     dataset:	 0.41559329628944397
2022-11-03 01:00:58,958:INFO: Average training:	ADE  0.5125	FDE  1.0572
2022-11-03 01:00:58,967:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_460.pth.tar
2022-11-03 01:00:58,968:INFO: 
===> EPOCH: 461 (P3)
2022-11-03 01:00:58,968:INFO: - Computing loss (training)
2022-11-03 01:01:00,067:INFO: Batch:  0/31	Total Loss 4.3717 (4.3717)
2022-11-03 01:01:00,539:INFO: Batch:  1/31	Total Loss 5.3859 (4.8425)
2022-11-03 01:01:01,012:INFO: Batch:  2/31	Total Loss 4.0841 (4.5887)
2022-11-03 01:01:01,480:INFO: Batch:  3/31	Total Loss 4.2155 (4.4890)
2022-11-03 01:01:01,949:INFO: Batch:  4/31	Total Loss 3.9966 (4.3835)
2022-11-03 01:01:02,424:INFO: Batch:  5/31	Total Loss 4.4382 (4.3929)
2022-11-03 01:01:02,894:INFO: Batch:  6/31	Total Loss 5.1357 (4.5059)
2022-11-03 01:01:03,358:INFO: Batch:  7/31	Total Loss 4.2971 (4.4778)
2022-11-03 01:01:03,824:INFO: Batch:  8/31	Total Loss 3.9125 (4.4131)
2022-11-03 01:01:04,291:INFO: Batch:  9/31	Total Loss 4.1248 (4.3826)
2022-11-03 01:01:04,758:INFO: Batch: 10/31	Total Loss 4.5955 (4.4040)
2022-11-03 01:01:05,227:INFO: Batch: 11/31	Total Loss 4.0866 (4.3791)
2022-11-03 01:01:05,698:INFO: Batch: 12/31	Total Loss 4.5473 (4.3922)
2022-11-03 01:01:06,170:INFO: Batch: 13/31	Total Loss 3.9850 (4.3652)
2022-11-03 01:01:06,642:INFO: Batch: 14/31	Total Loss 4.0675 (4.3460)
2022-11-03 01:01:07,114:INFO: Batch: 15/31	Total Loss 3.8409 (4.3122)
2022-11-03 01:01:07,586:INFO: Batch: 16/31	Total Loss 4.7058 (4.3325)
2022-11-03 01:01:08,063:INFO: Batch: 17/31	Total Loss 4.0545 (4.3168)
2022-11-03 01:01:08,540:INFO: Batch: 18/31	Total Loss 4.2432 (4.3131)
2022-11-03 01:01:09,012:INFO: Batch: 19/31	Total Loss 4.6909 (4.3300)
2022-11-03 01:01:09,483:INFO: Batch: 20/31	Total Loss 4.4704 (4.3366)
2022-11-03 01:01:09,959:INFO: Batch: 21/31	Total Loss 4.5222 (4.3460)
2022-11-03 01:01:10,434:INFO: Batch: 22/31	Total Loss 3.7285 (4.3205)
2022-11-03 01:01:10,905:INFO: Batch: 23/31	Total Loss 4.1903 (4.3154)
2022-11-03 01:01:11,375:INFO: Batch: 24/31	Total Loss 3.9440 (4.2985)
2022-11-03 01:01:11,845:INFO: Batch: 25/31	Total Loss 4.1055 (4.2913)
2022-11-03 01:01:12,314:INFO: Batch: 26/31	Total Loss 4.0750 (4.2833)
2022-11-03 01:01:12,783:INFO: Batch: 27/31	Total Loss 4.3925 (4.2873)
2022-11-03 01:01:13,252:INFO: Batch: 28/31	Total Loss 4.4172 (4.2919)
2022-11-03 01:01:13,723:INFO: Batch: 29/31	Total Loss 4.8440 (4.3113)
2022-11-03 01:01:14,111:INFO: Batch: 30/31	Total Loss 1.5760 (4.2900)
2022-11-03 01:01:14,261:INFO: - Computing ADE (validation o)
2022-11-03 01:01:14,837:INFO: 		 ADE on eth                       dataset:	 0.9661322832107544
2022-11-03 01:01:14,837:INFO: Average validation o:	ADE  0.9661	FDE  1.8884
2022-11-03 01:01:14,837:INFO: - Computing ADE (validation)
2022-11-03 01:01:15,112:INFO: 		 ADE on hotel                     dataset:	 0.48779186606407166
2022-11-03 01:01:15,414:INFO: 		 ADE on univ                      dataset:	 0.5730876922607422
2022-11-03 01:01:15,663:INFO: 		 ADE on zara1                     dataset:	 0.4715616703033447
2022-11-03 01:01:16,004:INFO: 		 ADE on zara2                     dataset:	 0.44910693168640137
2022-11-03 01:01:16,004:INFO: Average validation:	ADE  0.5170	FDE  1.0800
2022-11-03 01:01:16,005:INFO: - Computing ADE (training)
2022-11-03 01:01:16,442:INFO: 		 ADE on hotel                     dataset:	 0.5165559649467468
2022-11-03 01:01:17,130:INFO: 		 ADE on univ                      dataset:	 0.5691022872924805
2022-11-03 01:01:17,688:INFO: 		 ADE on zara1                     dataset:	 0.5235862135887146
2022-11-03 01:01:18,433:INFO: 		 ADE on zara2                     dataset:	 0.45860251784324646
2022-11-03 01:01:18,434:INFO: Average training:	ADE  0.5424	FDE  1.1407
2022-11-03 01:01:18,442:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_461.pth.tar
2022-11-03 01:01:18,442:INFO: 
===> EPOCH: 462 (P3)
2022-11-03 01:01:18,443:INFO: - Computing loss (training)
2022-11-03 01:01:19,533:INFO: Batch:  0/31	Total Loss 4.1670 (4.1670)
2022-11-03 01:01:20,010:INFO: Batch:  1/31	Total Loss 4.7486 (4.4594)
2022-11-03 01:01:20,484:INFO: Batch:  2/31	Total Loss 4.8919 (4.6039)
2022-11-03 01:01:20,966:INFO: Batch:  3/31	Total Loss 4.1416 (4.4783)
2022-11-03 01:01:21,442:INFO: Batch:  4/31	Total Loss 4.2892 (4.4390)
2022-11-03 01:01:21,917:INFO: Batch:  5/31	Total Loss 4.6775 (4.4768)
2022-11-03 01:01:22,390:INFO: Batch:  6/31	Total Loss 4.6174 (4.4973)
2022-11-03 01:01:22,857:INFO: Batch:  7/31	Total Loss 4.4731 (4.4947)
2022-11-03 01:01:23,326:INFO: Batch:  8/31	Total Loss 4.2308 (4.4652)
2022-11-03 01:01:23,796:INFO: Batch:  9/31	Total Loss 4.1869 (4.4350)
2022-11-03 01:01:24,268:INFO: Batch: 10/31	Total Loss 4.2842 (4.4196)
2022-11-03 01:01:24,737:INFO: Batch: 11/31	Total Loss 4.3505 (4.4142)
2022-11-03 01:01:25,214:INFO: Batch: 12/31	Total Loss 3.9342 (4.3760)
2022-11-03 01:01:25,687:INFO: Batch: 13/31	Total Loss 4.2399 (4.3670)
2022-11-03 01:01:26,165:INFO: Batch: 14/31	Total Loss 4.5862 (4.3836)
2022-11-03 01:01:26,638:INFO: Batch: 15/31	Total Loss 4.1733 (4.3711)
2022-11-03 01:01:27,115:INFO: Batch: 16/31	Total Loss 4.5496 (4.3815)
2022-11-03 01:01:27,589:INFO: Batch: 17/31	Total Loss 5.0168 (4.4165)
2022-11-03 01:01:28,064:INFO: Batch: 18/31	Total Loss 3.8605 (4.3880)
2022-11-03 01:01:28,539:INFO: Batch: 19/31	Total Loss 4.4522 (4.3911)
2022-11-03 01:01:29,014:INFO: Batch: 20/31	Total Loss 4.2564 (4.3843)
2022-11-03 01:01:29,484:INFO: Batch: 21/31	Total Loss 3.8943 (4.3624)
2022-11-03 01:01:29,954:INFO: Batch: 22/31	Total Loss 4.5746 (4.3713)
2022-11-03 01:01:30,426:INFO: Batch: 23/31	Total Loss 3.9664 (4.3551)
2022-11-03 01:01:30,897:INFO: Batch: 24/31	Total Loss 4.2684 (4.3521)
2022-11-03 01:01:31,367:INFO: Batch: 25/31	Total Loss 4.0366 (4.3403)
2022-11-03 01:01:31,838:INFO: Batch: 26/31	Total Loss 3.7854 (4.3180)
2022-11-03 01:01:32,307:INFO: Batch: 27/31	Total Loss 4.1940 (4.3137)
2022-11-03 01:01:32,779:INFO: Batch: 28/31	Total Loss 4.4621 (4.3182)
2022-11-03 01:01:33,249:INFO: Batch: 29/31	Total Loss 4.7236 (4.3324)
2022-11-03 01:01:33,636:INFO: Batch: 30/31	Total Loss 1.6908 (4.3121)
2022-11-03 01:01:33,788:INFO: - Computing ADE (validation o)
2022-11-03 01:01:34,376:INFO: 		 ADE on eth                       dataset:	 0.9699211120605469
2022-11-03 01:01:34,376:INFO: Average validation o:	ADE  0.9699	FDE  1.8698
2022-11-03 01:01:34,377:INFO: - Computing ADE (validation)
2022-11-03 01:01:34,659:INFO: 		 ADE on hotel                     dataset:	 0.44828590750694275
2022-11-03 01:01:34,946:INFO: 		 ADE on univ                      dataset:	 0.5497612953186035
2022-11-03 01:01:35,204:INFO: 		 ADE on zara1                     dataset:	 0.4357713460922241
2022-11-03 01:01:35,564:INFO: 		 ADE on zara2                     dataset:	 0.41618961095809937
2022-11-03 01:01:35,564:INFO: Average validation:	ADE  0.4886	FDE  0.9970
2022-11-03 01:01:35,565:INFO: - Computing ADE (training)
2022-11-03 01:01:36,018:INFO: 		 ADE on hotel                     dataset:	 0.4741283655166626
2022-11-03 01:01:36,698:INFO: 		 ADE on univ                      dataset:	 0.542955219745636
2022-11-03 01:01:37,220:INFO: 		 ADE on zara1                     dataset:	 0.5053547024726868
2022-11-03 01:01:37,964:INFO: 		 ADE on zara2                     dataset:	 0.42837682366371155
2022-11-03 01:01:37,965:INFO: Average training:	ADE  0.5156	FDE  1.0615
2022-11-03 01:01:37,973:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_462.pth.tar
2022-11-03 01:01:37,973:INFO: 
===> EPOCH: 463 (P3)
2022-11-03 01:01:37,974:INFO: - Computing loss (training)
2022-11-03 01:01:39,093:INFO: Batch:  0/31	Total Loss 4.0686 (4.0686)
2022-11-03 01:01:39,570:INFO: Batch:  1/31	Total Loss 5.0307 (4.5447)
2022-11-03 01:01:40,127:INFO: Batch:  2/31	Total Loss 4.3812 (4.4914)
2022-11-03 01:01:40,605:INFO: Batch:  3/31	Total Loss 3.9747 (4.3650)
2022-11-03 01:01:41,081:INFO: Batch:  4/31	Total Loss 4.0768 (4.3041)
2022-11-03 01:01:41,556:INFO: Batch:  5/31	Total Loss 4.4461 (4.3279)
2022-11-03 01:01:42,035:INFO: Batch:  6/31	Total Loss 4.4881 (4.3489)
2022-11-03 01:01:42,510:INFO: Batch:  7/31	Total Loss 3.7952 (4.2726)
2022-11-03 01:01:42,984:INFO: Batch:  8/31	Total Loss 4.3211 (4.2781)
2022-11-03 01:01:43,456:INFO: Batch:  9/31	Total Loss 4.2991 (4.2802)
2022-11-03 01:01:43,927:INFO: Batch: 10/31	Total Loss 4.0073 (4.2569)
2022-11-03 01:01:44,400:INFO: Batch: 11/31	Total Loss 4.0351 (4.2385)
2022-11-03 01:01:44,876:INFO: Batch: 12/31	Total Loss 4.4358 (4.2530)
2022-11-03 01:01:45,351:INFO: Batch: 13/31	Total Loss 4.8268 (4.2917)
2022-11-03 01:01:45,827:INFO: Batch: 14/31	Total Loss 3.9856 (4.2686)
2022-11-03 01:01:46,304:INFO: Batch: 15/31	Total Loss 4.7916 (4.3013)
2022-11-03 01:01:46,782:INFO: Batch: 16/31	Total Loss 4.0781 (4.2877)
2022-11-03 01:01:47,258:INFO: Batch: 17/31	Total Loss 3.8777 (4.2648)
2022-11-03 01:01:47,733:INFO: Batch: 18/31	Total Loss 4.6592 (4.2852)
2022-11-03 01:01:48,208:INFO: Batch: 19/31	Total Loss 4.3783 (4.2894)
2022-11-03 01:01:48,683:INFO: Batch: 20/31	Total Loss 4.4489 (4.2968)
2022-11-03 01:01:49,162:INFO: Batch: 21/31	Total Loss 5.8328 (4.3660)
2022-11-03 01:01:49,638:INFO: Batch: 22/31	Total Loss 4.8492 (4.3818)
2022-11-03 01:01:50,117:INFO: Batch: 23/31	Total Loss 4.8110 (4.3997)
2022-11-03 01:01:50,585:INFO: Batch: 24/31	Total Loss 4.0771 (4.3881)
2022-11-03 01:01:51,054:INFO: Batch: 25/31	Total Loss 4.2777 (4.3837)
2022-11-03 01:01:51,521:INFO: Batch: 26/31	Total Loss 4.0896 (4.3736)
2022-11-03 01:01:51,990:INFO: Batch: 27/31	Total Loss 4.3408 (4.3725)
2022-11-03 01:01:52,461:INFO: Batch: 28/31	Total Loss 4.4229 (4.3738)
2022-11-03 01:01:52,930:INFO: Batch: 29/31	Total Loss 4.3438 (4.3727)
2022-11-03 01:01:53,316:INFO: Batch: 30/31	Total Loss 1.4847 (4.3441)
2022-11-03 01:01:53,467:INFO: - Computing ADE (validation o)
2022-11-03 01:01:54,063:INFO: 		 ADE on eth                       dataset:	 0.9729885458946228
2022-11-03 01:01:54,063:INFO: Average validation o:	ADE  0.9730	FDE  1.8876
2022-11-03 01:01:54,064:INFO: - Computing ADE (validation)
2022-11-03 01:01:54,328:INFO: 		 ADE on hotel                     dataset:	 0.4727269113063812
2022-11-03 01:01:54,614:INFO: 		 ADE on univ                      dataset:	 0.5596780776977539
2022-11-03 01:01:54,860:INFO: 		 ADE on zara1                     dataset:	 0.4478336274623871
2022-11-03 01:01:55,194:INFO: 		 ADE on zara2                     dataset:	 0.4469393491744995
2022-11-03 01:01:55,195:INFO: Average validation:	ADE  0.5071	FDE  1.0509
2022-11-03 01:01:55,195:INFO: - Computing ADE (training)
2022-11-03 01:01:55,652:INFO: 		 ADE on hotel                     dataset:	 0.4993412494659424
2022-11-03 01:01:56,338:INFO: 		 ADE on univ                      dataset:	 0.5608060359954834
2022-11-03 01:01:56,890:INFO: 		 ADE on zara1                     dataset:	 0.5074032545089722
2022-11-03 01:01:57,643:INFO: 		 ADE on zara2                     dataset:	 0.4494921565055847
2022-11-03 01:01:57,643:INFO: Average training:	ADE  0.5333	FDE  1.1139
2022-11-03 01:01:57,651:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_463.pth.tar
2022-11-03 01:01:57,651:INFO: 
===> EPOCH: 464 (P3)
2022-11-03 01:01:57,652:INFO: - Computing loss (training)
2022-11-03 01:01:58,760:INFO: Batch:  0/31	Total Loss 4.3490 (4.3490)
2022-11-03 01:01:59,236:INFO: Batch:  1/31	Total Loss 4.2242 (4.2849)
2022-11-03 01:01:59,709:INFO: Batch:  2/31	Total Loss 4.6521 (4.4091)
2022-11-03 01:02:00,178:INFO: Batch:  3/31	Total Loss 4.4006 (4.4068)
2022-11-03 01:02:00,653:INFO: Batch:  4/31	Total Loss 4.4838 (4.4205)
2022-11-03 01:02:01,129:INFO: Batch:  5/31	Total Loss 4.1934 (4.3851)
2022-11-03 01:02:01,601:INFO: Batch:  6/31	Total Loss 4.0002 (4.3248)
2022-11-03 01:02:02,070:INFO: Batch:  7/31	Total Loss 4.6356 (4.3655)
2022-11-03 01:02:02,540:INFO: Batch:  8/31	Total Loss 3.9112 (4.3151)
2022-11-03 01:02:03,010:INFO: Batch:  9/31	Total Loss 3.9819 (4.2798)
2022-11-03 01:02:03,481:INFO: Batch: 10/31	Total Loss 4.3092 (4.2824)
2022-11-03 01:02:03,949:INFO: Batch: 11/31	Total Loss 4.3083 (4.2843)
2022-11-03 01:02:04,423:INFO: Batch: 12/31	Total Loss 4.8667 (4.3291)
2022-11-03 01:02:04,896:INFO: Batch: 13/31	Total Loss 3.6553 (4.2786)
2022-11-03 01:02:05,370:INFO: Batch: 14/31	Total Loss 4.3886 (4.2864)
2022-11-03 01:02:05,843:INFO: Batch: 15/31	Total Loss 4.4441 (4.2965)
2022-11-03 01:02:06,315:INFO: Batch: 16/31	Total Loss 4.0350 (4.2805)
2022-11-03 01:02:06,788:INFO: Batch: 17/31	Total Loss 3.6632 (4.2456)
2022-11-03 01:02:07,261:INFO: Batch: 18/31	Total Loss 4.8105 (4.2741)
2022-11-03 01:02:07,733:INFO: Batch: 19/31	Total Loss 3.6544 (4.2437)
2022-11-03 01:02:08,206:INFO: Batch: 20/31	Total Loss 3.7846 (4.2209)
2022-11-03 01:02:08,678:INFO: Batch: 21/31	Total Loss 4.3512 (4.2270)
2022-11-03 01:02:09,150:INFO: Batch: 22/31	Total Loss 4.9754 (4.2558)
2022-11-03 01:02:09,620:INFO: Batch: 23/31	Total Loss 4.1459 (4.2511)
2022-11-03 01:02:10,095:INFO: Batch: 24/31	Total Loss 4.3333 (4.2542)
2022-11-03 01:02:10,564:INFO: Batch: 25/31	Total Loss 4.6786 (4.2701)
2022-11-03 01:02:11,035:INFO: Batch: 26/31	Total Loss 4.2885 (4.2707)
2022-11-03 01:02:11,507:INFO: Batch: 27/31	Total Loss 3.7860 (4.2526)
2022-11-03 01:02:11,978:INFO: Batch: 28/31	Total Loss 4.7326 (4.2695)
2022-11-03 01:02:12,470:INFO: Batch: 29/31	Total Loss 4.2524 (4.2690)
2022-11-03 01:02:12,864:INFO: Batch: 30/31	Total Loss 2.1784 (4.2554)
2022-11-03 01:02:13,019:INFO: - Computing ADE (validation o)
2022-11-03 01:02:13,609:INFO: 		 ADE on eth                       dataset:	 0.9496631622314453
2022-11-03 01:02:13,610:INFO: Average validation o:	ADE  0.9497	FDE  1.8035
2022-11-03 01:02:13,611:INFO: - Computing ADE (validation)
2022-11-03 01:02:13,886:INFO: 		 ADE on hotel                     dataset:	 0.45579439401626587
2022-11-03 01:02:14,181:INFO: 		 ADE on univ                      dataset:	 0.5548278093338013
2022-11-03 01:02:14,427:INFO: 		 ADE on zara1                     dataset:	 0.4309665262699127
2022-11-03 01:02:14,789:INFO: 		 ADE on zara2                     dataset:	 0.4104975461959839
2022-11-03 01:02:14,790:INFO: Average validation:	ADE  0.4893	FDE  1.0014
2022-11-03 01:02:14,791:INFO: - Computing ADE (training)
2022-11-03 01:02:15,236:INFO: 		 ADE on hotel                     dataset:	 0.4854508936405182
2022-11-03 01:02:15,949:INFO: 		 ADE on univ                      dataset:	 0.541358232498169
2022-11-03 01:02:16,486:INFO: 		 ADE on zara1                     dataset:	 0.5057104229927063
2022-11-03 01:02:17,238:INFO: 		 ADE on zara2                     dataset:	 0.4227689802646637
2022-11-03 01:02:17,238:INFO: Average training:	ADE  0.5136	FDE  1.0575
2022-11-03 01:02:17,247:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_464.pth.tar
2022-11-03 01:02:17,248:INFO: 
===> EPOCH: 465 (P3)
2022-11-03 01:02:17,248:INFO: - Computing loss (training)
2022-11-03 01:02:18,345:INFO: Batch:  0/31	Total Loss 4.9813 (4.9813)
2022-11-03 01:02:18,816:INFO: Batch:  1/31	Total Loss 3.9694 (4.4202)
2022-11-03 01:02:19,287:INFO: Batch:  2/31	Total Loss 4.2475 (4.3650)
2022-11-03 01:02:19,754:INFO: Batch:  3/31	Total Loss 3.8730 (4.2404)
2022-11-03 01:02:20,224:INFO: Batch:  4/31	Total Loss 4.4796 (4.2850)
2022-11-03 01:02:20,700:INFO: Batch:  5/31	Total Loss 5.0632 (4.4178)
2022-11-03 01:02:21,168:INFO: Batch:  6/31	Total Loss 4.6962 (4.4561)
2022-11-03 01:02:21,633:INFO: Batch:  7/31	Total Loss 4.2458 (4.4258)
2022-11-03 01:02:22,103:INFO: Batch:  8/31	Total Loss 4.3622 (4.4184)
2022-11-03 01:02:22,570:INFO: Batch:  9/31	Total Loss 4.5362 (4.4296)
2022-11-03 01:02:23,041:INFO: Batch: 10/31	Total Loss 4.0229 (4.3916)
2022-11-03 01:02:23,508:INFO: Batch: 11/31	Total Loss 3.9698 (4.3566)
2022-11-03 01:02:23,978:INFO: Batch: 12/31	Total Loss 4.5005 (4.3679)
2022-11-03 01:02:24,450:INFO: Batch: 13/31	Total Loss 4.3582 (4.3671)
2022-11-03 01:02:24,921:INFO: Batch: 14/31	Total Loss 4.1187 (4.3494)
2022-11-03 01:02:25,392:INFO: Batch: 15/31	Total Loss 4.5711 (4.3636)
2022-11-03 01:02:25,867:INFO: Batch: 16/31	Total Loss 4.6074 (4.3785)
2022-11-03 01:02:26,338:INFO: Batch: 17/31	Total Loss 3.7535 (4.3409)
2022-11-03 01:02:26,807:INFO: Batch: 18/31	Total Loss 4.5431 (4.3514)
2022-11-03 01:02:27,275:INFO: Batch: 19/31	Total Loss 3.9639 (4.3326)
2022-11-03 01:02:27,744:INFO: Batch: 20/31	Total Loss 4.7119 (4.3488)
2022-11-03 01:02:28,214:INFO: Batch: 21/31	Total Loss 4.4275 (4.3524)
2022-11-03 01:02:28,684:INFO: Batch: 22/31	Total Loss 3.7554 (4.3258)
2022-11-03 01:02:29,153:INFO: Batch: 23/31	Total Loss 4.3407 (4.3264)
2022-11-03 01:02:29,622:INFO: Batch: 24/31	Total Loss 4.0339 (4.3148)
2022-11-03 01:02:30,091:INFO: Batch: 25/31	Total Loss 4.1570 (4.3094)
2022-11-03 01:02:30,559:INFO: Batch: 26/31	Total Loss 4.7809 (4.3260)
2022-11-03 01:02:31,107:INFO: Batch: 27/31	Total Loss 4.3102 (4.3254)
2022-11-03 01:02:31,575:INFO: Batch: 28/31	Total Loss 4.3460 (4.3262)
2022-11-03 01:02:32,043:INFO: Batch: 29/31	Total Loss 3.9637 (4.3142)
2022-11-03 01:02:32,427:INFO: Batch: 30/31	Total Loss 1.3386 (4.2846)
2022-11-03 01:02:32,578:INFO: - Computing ADE (validation o)
2022-11-03 01:02:33,160:INFO: 		 ADE on eth                       dataset:	 0.9640212655067444
2022-11-03 01:02:33,160:INFO: Average validation o:	ADE  0.9640	FDE  1.8450
2022-11-03 01:02:33,161:INFO: - Computing ADE (validation)
2022-11-03 01:02:33,431:INFO: 		 ADE on hotel                     dataset:	 0.4331100583076477
2022-11-03 01:02:33,727:INFO: 		 ADE on univ                      dataset:	 0.5456004738807678
2022-11-03 01:02:33,982:INFO: 		 ADE on zara1                     dataset:	 0.43874508142471313
2022-11-03 01:02:34,336:INFO: 		 ADE on zara2                     dataset:	 0.41558587551116943
2022-11-03 01:02:34,336:INFO: Average validation:	ADE  0.4855	FDE  0.9911
2022-11-03 01:02:34,337:INFO: - Computing ADE (training)
2022-11-03 01:02:34,811:INFO: 		 ADE on hotel                     dataset:	 0.45123082399368286
2022-11-03 01:02:35,482:INFO: 		 ADE on univ                      dataset:	 0.5384833216667175
2022-11-03 01:02:36,016:INFO: 		 ADE on zara1                     dataset:	 0.5066515803337097
2022-11-03 01:02:36,752:INFO: 		 ADE on zara2                     dataset:	 0.42650339007377625
2022-11-03 01:02:36,752:INFO: Average training:	ADE  0.5115	FDE  1.0532
2022-11-03 01:02:36,761:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_465.pth.tar
2022-11-03 01:02:36,761:INFO: 
===> EPOCH: 466 (P3)
2022-11-03 01:02:36,761:INFO: - Computing loss (training)
2022-11-03 01:02:37,840:INFO: Batch:  0/31	Total Loss 4.6898 (4.6898)
2022-11-03 01:02:38,313:INFO: Batch:  1/31	Total Loss 4.2991 (4.4985)
2022-11-03 01:02:38,784:INFO: Batch:  2/31	Total Loss 3.7622 (4.2674)
2022-11-03 01:02:39,247:INFO: Batch:  3/31	Total Loss 4.2252 (4.2564)
2022-11-03 01:02:39,716:INFO: Batch:  4/31	Total Loss 4.3051 (4.2673)
2022-11-03 01:02:40,186:INFO: Batch:  5/31	Total Loss 4.5888 (4.3156)
2022-11-03 01:02:40,653:INFO: Batch:  6/31	Total Loss 3.9816 (4.2703)
2022-11-03 01:02:41,119:INFO: Batch:  7/31	Total Loss 4.3288 (4.2779)
2022-11-03 01:02:41,584:INFO: Batch:  8/31	Total Loss 4.3394 (4.2843)
2022-11-03 01:02:42,049:INFO: Batch:  9/31	Total Loss 4.4119 (4.2970)
2022-11-03 01:02:42,518:INFO: Batch: 10/31	Total Loss 4.3043 (4.2976)
2022-11-03 01:02:42,983:INFO: Batch: 11/31	Total Loss 3.7411 (4.2463)
2022-11-03 01:02:43,452:INFO: Batch: 12/31	Total Loss 4.2940 (4.2505)
2022-11-03 01:02:43,923:INFO: Batch: 13/31	Total Loss 4.1103 (4.2404)
2022-11-03 01:02:44,391:INFO: Batch: 14/31	Total Loss 4.4425 (4.2534)
2022-11-03 01:02:44,861:INFO: Batch: 15/31	Total Loss 4.4263 (4.2656)
2022-11-03 01:02:45,329:INFO: Batch: 16/31	Total Loss 4.1689 (4.2597)
2022-11-03 01:02:45,797:INFO: Batch: 17/31	Total Loss 4.1669 (4.2545)
2022-11-03 01:02:46,267:INFO: Batch: 18/31	Total Loss 4.2815 (4.2559)
2022-11-03 01:02:46,736:INFO: Batch: 19/31	Total Loss 4.4989 (4.2686)
2022-11-03 01:02:47,207:INFO: Batch: 20/31	Total Loss 3.8184 (4.2468)
2022-11-03 01:02:47,681:INFO: Batch: 21/31	Total Loss 3.8319 (4.2300)
2022-11-03 01:02:48,158:INFO: Batch: 22/31	Total Loss 4.0729 (4.2228)
2022-11-03 01:02:48,633:INFO: Batch: 23/31	Total Loss 3.9483 (4.2126)
2022-11-03 01:02:49,110:INFO: Batch: 24/31	Total Loss 4.1226 (4.2093)
2022-11-03 01:02:49,586:INFO: Batch: 25/31	Total Loss 4.2622 (4.2113)
2022-11-03 01:02:50,065:INFO: Batch: 26/31	Total Loss 4.3780 (4.2169)
2022-11-03 01:02:50,540:INFO: Batch: 27/31	Total Loss 3.6908 (4.1978)
2022-11-03 01:02:51,015:INFO: Batch: 28/31	Total Loss 4.4856 (4.2078)
2022-11-03 01:02:51,490:INFO: Batch: 29/31	Total Loss 4.0472 (4.2021)
2022-11-03 01:02:51,882:INFO: Batch: 30/31	Total Loss 1.7402 (4.1739)
2022-11-03 01:02:52,036:INFO: - Computing ADE (validation o)
2022-11-03 01:02:52,640:INFO: 		 ADE on eth                       dataset:	 0.9554440975189209
2022-11-03 01:02:52,640:INFO: Average validation o:	ADE  0.9554	FDE  1.8541
2022-11-03 01:02:52,641:INFO: - Computing ADE (validation)
2022-11-03 01:02:52,910:INFO: 		 ADE on hotel                     dataset:	 0.4505256712436676
2022-11-03 01:02:53,195:INFO: 		 ADE on univ                      dataset:	 0.5524404644966125
2022-11-03 01:02:53,431:INFO: 		 ADE on zara1                     dataset:	 0.4322907626628876
2022-11-03 01:02:53,781:INFO: 		 ADE on zara2                     dataset:	 0.4003995656967163
2022-11-03 01:02:53,781:INFO: Average validation:	ADE  0.4841	FDE  0.9864
2022-11-03 01:02:53,782:INFO: - Computing ADE (training)
2022-11-03 01:02:54,244:INFO: 		 ADE on hotel                     dataset:	 0.4762991666793823
2022-11-03 01:02:54,958:INFO: 		 ADE on univ                      dataset:	 0.5390331745147705
2022-11-03 01:02:55,488:INFO: 		 ADE on zara1                     dataset:	 0.4944191575050354
2022-11-03 01:02:56,228:INFO: 		 ADE on zara2                     dataset:	 0.4111466109752655
2022-11-03 01:02:56,228:INFO: Average training:	ADE  0.5086	FDE  1.0440
2022-11-03 01:02:56,236:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_466.pth.tar
2022-11-03 01:02:56,236:INFO: 
===> EPOCH: 467 (P3)
2022-11-03 01:02:56,237:INFO: - Computing loss (training)
2022-11-03 01:02:57,353:INFO: Batch:  0/31	Total Loss 3.7636 (3.7636)
2022-11-03 01:02:57,828:INFO: Batch:  1/31	Total Loss 4.6634 (4.2135)
2022-11-03 01:02:58,301:INFO: Batch:  2/31	Total Loss 4.4196 (4.2810)
2022-11-03 01:02:58,778:INFO: Batch:  3/31	Total Loss 4.0927 (4.2330)
2022-11-03 01:02:59,248:INFO: Batch:  4/31	Total Loss 4.2295 (4.2322)
2022-11-03 01:02:59,723:INFO: Batch:  5/31	Total Loss 4.3525 (4.2515)
2022-11-03 01:03:00,195:INFO: Batch:  6/31	Total Loss 3.6724 (4.1692)
2022-11-03 01:03:00,667:INFO: Batch:  7/31	Total Loss 4.1268 (4.1637)
2022-11-03 01:03:01,138:INFO: Batch:  8/31	Total Loss 4.1774 (4.1651)
2022-11-03 01:03:01,614:INFO: Batch:  9/31	Total Loss 4.5432 (4.1993)
2022-11-03 01:03:02,085:INFO: Batch: 10/31	Total Loss 3.9600 (4.1760)
2022-11-03 01:03:02,558:INFO: Batch: 11/31	Total Loss 4.2762 (4.1843)
2022-11-03 01:03:03,033:INFO: Batch: 12/31	Total Loss 4.4674 (4.2058)
2022-11-03 01:03:03,509:INFO: Batch: 13/31	Total Loss 3.7613 (4.1774)
2022-11-03 01:03:03,985:INFO: Batch: 14/31	Total Loss 4.5616 (4.2019)
2022-11-03 01:03:04,461:INFO: Batch: 15/31	Total Loss 4.4896 (4.2194)
2022-11-03 01:03:04,935:INFO: Batch: 16/31	Total Loss 4.3059 (4.2246)
2022-11-03 01:03:05,409:INFO: Batch: 17/31	Total Loss 4.1015 (4.2169)
2022-11-03 01:03:05,885:INFO: Batch: 18/31	Total Loss 4.3813 (4.2257)
2022-11-03 01:03:06,360:INFO: Batch: 19/31	Total Loss 4.4673 (4.2386)
2022-11-03 01:03:06,834:INFO: Batch: 20/31	Total Loss 4.6055 (4.2556)
2022-11-03 01:03:07,307:INFO: Batch: 21/31	Total Loss 3.8267 (4.2374)
2022-11-03 01:03:07,782:INFO: Batch: 22/31	Total Loss 3.8130 (4.2197)
2022-11-03 01:03:08,256:INFO: Batch: 23/31	Total Loss 4.2180 (4.2196)
2022-11-03 01:03:08,734:INFO: Batch: 24/31	Total Loss 4.6354 (4.2358)
2022-11-03 01:03:09,221:INFO: Batch: 25/31	Total Loss 4.4395 (4.2440)
2022-11-03 01:03:09,713:INFO: Batch: 26/31	Total Loss 4.3498 (4.2482)
2022-11-03 01:03:10,206:INFO: Batch: 27/31	Total Loss 4.2114 (4.2468)
2022-11-03 01:03:10,677:INFO: Batch: 28/31	Total Loss 4.2566 (4.2471)
2022-11-03 01:03:11,151:INFO: Batch: 29/31	Total Loss 4.0439 (4.2408)
2022-11-03 01:03:11,537:INFO: Batch: 30/31	Total Loss 1.3918 (4.2176)
2022-11-03 01:03:11,690:INFO: - Computing ADE (validation o)
2022-11-03 01:03:12,261:INFO: 		 ADE on eth                       dataset:	 0.9446841478347778
2022-11-03 01:03:12,262:INFO: Average validation o:	ADE  0.9447	FDE  1.8456
2022-11-03 01:03:12,262:INFO: - Computing ADE (validation)
2022-11-03 01:03:12,520:INFO: 		 ADE on hotel                     dataset:	 0.43734636902809143
2022-11-03 01:03:12,819:INFO: 		 ADE on univ                      dataset:	 0.5497443675994873
2022-11-03 01:03:13,089:INFO: 		 ADE on zara1                     dataset:	 0.42800259590148926
2022-11-03 01:03:13,436:INFO: 		 ADE on zara2                     dataset:	 0.4028393030166626
2022-11-03 01:03:13,436:INFO: Average validation:	ADE  0.4826	FDE  0.9909
2022-11-03 01:03:13,437:INFO: - Computing ADE (training)
2022-11-03 01:03:13,902:INFO: 		 ADE on hotel                     dataset:	 0.45967167615890503
2022-11-03 01:03:14,592:INFO: 		 ADE on univ                      dataset:	 0.5407806038856506
2022-11-03 01:03:15,136:INFO: 		 ADE on zara1                     dataset:	 0.47457367181777954
2022-11-03 01:03:15,880:INFO: 		 ADE on zara2                     dataset:	 0.40483662486076355
2022-11-03 01:03:15,881:INFO: Average training:	ADE  0.5069	FDE  1.0482
2022-11-03 01:03:15,891:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_467.pth.tar
2022-11-03 01:03:15,891:INFO: 
===> EPOCH: 468 (P3)
2022-11-03 01:03:15,891:INFO: - Computing loss (training)
2022-11-03 01:03:16,969:INFO: Batch:  0/31	Total Loss 3.6885 (3.6885)
2022-11-03 01:03:17,440:INFO: Batch:  1/31	Total Loss 4.6675 (4.1734)
2022-11-03 01:03:17,910:INFO: Batch:  2/31	Total Loss 3.9462 (4.0871)
2022-11-03 01:03:18,381:INFO: Batch:  3/31	Total Loss 4.0001 (4.0654)
2022-11-03 01:03:18,857:INFO: Batch:  4/31	Total Loss 3.7885 (4.0049)
2022-11-03 01:03:19,336:INFO: Batch:  5/31	Total Loss 3.8417 (3.9789)
2022-11-03 01:03:19,814:INFO: Batch:  6/31	Total Loss 3.6958 (3.9338)
2022-11-03 01:03:20,294:INFO: Batch:  7/31	Total Loss 4.2925 (3.9773)
2022-11-03 01:03:20,775:INFO: Batch:  8/31	Total Loss 4.8658 (4.0721)
2022-11-03 01:03:21,255:INFO: Batch:  9/31	Total Loss 4.8220 (4.1394)
2022-11-03 01:03:21,732:INFO: Batch: 10/31	Total Loss 4.5208 (4.1738)
2022-11-03 01:03:22,211:INFO: Batch: 11/31	Total Loss 4.8918 (4.2327)
2022-11-03 01:03:22,693:INFO: Batch: 12/31	Total Loss 4.5110 (4.2546)
2022-11-03 01:03:23,175:INFO: Batch: 13/31	Total Loss 4.2023 (4.2507)
2022-11-03 01:03:23,655:INFO: Batch: 14/31	Total Loss 4.3430 (4.2567)
2022-11-03 01:03:24,135:INFO: Batch: 15/31	Total Loss 4.1455 (4.2495)
2022-11-03 01:03:24,615:INFO: Batch: 16/31	Total Loss 4.7213 (4.2741)
2022-11-03 01:03:25,176:INFO: Batch: 17/31	Total Loss 4.3814 (4.2802)
2022-11-03 01:03:25,657:INFO: Batch: 18/31	Total Loss 3.9165 (4.2618)
2022-11-03 01:03:26,139:INFO: Batch: 19/31	Total Loss 4.4918 (4.2738)
2022-11-03 01:03:26,620:INFO: Batch: 20/31	Total Loss 4.1608 (4.2686)
2022-11-03 01:03:27,099:INFO: Batch: 21/31	Total Loss 4.2432 (4.2675)
2022-11-03 01:03:27,576:INFO: Batch: 22/31	Total Loss 4.7702 (4.2884)
2022-11-03 01:03:28,055:INFO: Batch: 23/31	Total Loss 4.2698 (4.2877)
2022-11-03 01:03:28,535:INFO: Batch: 24/31	Total Loss 3.6609 (4.2633)
2022-11-03 01:03:29,015:INFO: Batch: 25/31	Total Loss 4.6648 (4.2790)
2022-11-03 01:03:29,494:INFO: Batch: 26/31	Total Loss 4.4736 (4.2870)
2022-11-03 01:03:29,973:INFO: Batch: 27/31	Total Loss 4.0143 (4.2784)
2022-11-03 01:03:30,452:INFO: Batch: 28/31	Total Loss 4.6573 (4.2909)
2022-11-03 01:03:30,932:INFO: Batch: 29/31	Total Loss 4.5723 (4.3003)
2022-11-03 01:03:31,324:INFO: Batch: 30/31	Total Loss 1.6011 (4.2744)
2022-11-03 01:03:31,478:INFO: - Computing ADE (validation o)
2022-11-03 01:03:32,064:INFO: 		 ADE on eth                       dataset:	 0.9840887188911438
2022-11-03 01:03:32,065:INFO: Average validation o:	ADE  0.9841	FDE  1.9787
2022-11-03 01:03:32,065:INFO: - Computing ADE (validation)
2022-11-03 01:03:32,322:INFO: 		 ADE on hotel                     dataset:	 0.48803573846817017
2022-11-03 01:03:32,622:INFO: 		 ADE on univ                      dataset:	 0.5835461020469666
2022-11-03 01:03:32,871:INFO: 		 ADE on zara1                     dataset:	 0.4863959848880768
2022-11-03 01:03:33,222:INFO: 		 ADE on zara2                     dataset:	 0.4773865044116974
2022-11-03 01:03:33,222:INFO: Average validation:	ADE  0.5337	FDE  1.1388
2022-11-03 01:03:33,222:INFO: - Computing ADE (training)
2022-11-03 01:03:33,691:INFO: 		 ADE on hotel                     dataset:	 0.5075631737709045
2022-11-03 01:03:34,364:INFO: 		 ADE on univ                      dataset:	 0.5860728621482849
2022-11-03 01:03:34,870:INFO: 		 ADE on zara1                     dataset:	 0.5131617784500122
2022-11-03 01:03:35,627:INFO: 		 ADE on zara2                     dataset:	 0.4786485731601715
2022-11-03 01:03:35,627:INFO: Average training:	ADE  0.5576	FDE  1.1969
2022-11-03 01:03:35,637:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_468.pth.tar
2022-11-03 01:03:35,637:INFO: 
===> EPOCH: 469 (P3)
2022-11-03 01:03:35,637:INFO: - Computing loss (training)
2022-11-03 01:03:36,771:INFO: Batch:  0/31	Total Loss 5.5667 (5.5667)
2022-11-03 01:03:37,260:INFO: Batch:  1/31	Total Loss 4.6068 (5.0770)
2022-11-03 01:03:37,745:INFO: Batch:  2/31	Total Loss 4.3496 (4.8214)
2022-11-03 01:03:38,231:INFO: Batch:  3/31	Total Loss 4.2563 (4.6868)
2022-11-03 01:03:38,718:INFO: Batch:  4/31	Total Loss 4.4425 (4.6330)
2022-11-03 01:03:39,206:INFO: Batch:  5/31	Total Loss 4.6093 (4.6294)
2022-11-03 01:03:39,694:INFO: Batch:  6/31	Total Loss 4.7405 (4.6454)
2022-11-03 01:03:40,183:INFO: Batch:  7/31	Total Loss 4.5595 (4.6339)
2022-11-03 01:03:40,671:INFO: Batch:  8/31	Total Loss 5.2162 (4.7002)
2022-11-03 01:03:41,157:INFO: Batch:  9/31	Total Loss 5.1192 (4.7437)
2022-11-03 01:03:41,643:INFO: Batch: 10/31	Total Loss 4.2840 (4.7017)
2022-11-03 01:03:42,130:INFO: Batch: 11/31	Total Loss 3.9130 (4.6297)
2022-11-03 01:03:42,619:INFO: Batch: 12/31	Total Loss 4.1862 (4.5983)
2022-11-03 01:03:43,109:INFO: Batch: 13/31	Total Loss 5.5672 (4.6675)
2022-11-03 01:03:43,596:INFO: Batch: 14/31	Total Loss 3.9418 (4.6197)
2022-11-03 01:03:44,084:INFO: Batch: 15/31	Total Loss 4.0018 (4.5807)
2022-11-03 01:03:44,566:INFO: Batch: 16/31	Total Loss 3.9483 (4.5450)
2022-11-03 01:03:45,038:INFO: Batch: 17/31	Total Loss 3.9800 (4.5139)
2022-11-03 01:03:45,509:INFO: Batch: 18/31	Total Loss 4.4587 (4.5110)
2022-11-03 01:03:45,980:INFO: Batch: 19/31	Total Loss 4.7230 (4.5216)
2022-11-03 01:03:46,452:INFO: Batch: 20/31	Total Loss 3.8946 (4.4922)
2022-11-03 01:03:46,923:INFO: Batch: 21/31	Total Loss 4.3064 (4.4844)
2022-11-03 01:03:47,394:INFO: Batch: 22/31	Total Loss 5.4368 (4.5236)
2022-11-03 01:03:47,863:INFO: Batch: 23/31	Total Loss 4.8048 (4.5341)
2022-11-03 01:03:48,335:INFO: Batch: 24/31	Total Loss 4.5727 (4.5356)
2022-11-03 01:03:48,807:INFO: Batch: 25/31	Total Loss 4.1692 (4.5214)
2022-11-03 01:03:49,279:INFO: Batch: 26/31	Total Loss 3.9053 (4.4994)
2022-11-03 01:03:49,749:INFO: Batch: 27/31	Total Loss 3.8311 (4.4775)
2022-11-03 01:03:50,221:INFO: Batch: 28/31	Total Loss 4.7127 (4.4858)
2022-11-03 01:03:50,694:INFO: Batch: 29/31	Total Loss 3.8247 (4.4640)
2022-11-03 01:03:51,081:INFO: Batch: 30/31	Total Loss 1.4957 (4.4342)
2022-11-03 01:03:51,238:INFO: - Computing ADE (validation o)
2022-11-03 01:03:51,823:INFO: 		 ADE on eth                       dataset:	 0.9599347710609436
2022-11-03 01:03:51,823:INFO: Average validation o:	ADE  0.9599	FDE  1.8950
2022-11-03 01:03:51,824:INFO: - Computing ADE (validation)
2022-11-03 01:03:52,110:INFO: 		 ADE on hotel                     dataset:	 0.4470903277397156
2022-11-03 01:03:52,398:INFO: 		 ADE on univ                      dataset:	 0.5554561018943787
2022-11-03 01:03:52,643:INFO: 		 ADE on zara1                     dataset:	 0.4431036114692688
2022-11-03 01:03:52,995:INFO: 		 ADE on zara2                     dataset:	 0.4287482500076294
2022-11-03 01:03:52,995:INFO: Average validation:	ADE  0.4965	FDE  1.0317
2022-11-03 01:03:52,996:INFO: - Computing ADE (training)
2022-11-03 01:03:53,467:INFO: 		 ADE on hotel                     dataset:	 0.4730226695537567
2022-11-03 01:03:54,146:INFO: 		 ADE on univ                      dataset:	 0.5524023175239563
2022-11-03 01:03:54,675:INFO: 		 ADE on zara1                     dataset:	 0.49242353439331055
2022-11-03 01:03:55,403:INFO: 		 ADE on zara2                     dataset:	 0.43205419182777405
2022-11-03 01:03:55,403:INFO: Average training:	ADE  0.5221	FDE  1.0936
2022-11-03 01:03:55,412:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_469.pth.tar
2022-11-03 01:03:55,412:INFO: 
===> EPOCH: 470 (P3)
2022-11-03 01:03:55,412:INFO: - Computing loss (training)
2022-11-03 01:03:56,494:INFO: Batch:  0/31	Total Loss 4.5930 (4.5930)
2022-11-03 01:03:56,966:INFO: Batch:  1/31	Total Loss 4.0472 (4.3241)
2022-11-03 01:03:57,443:INFO: Batch:  2/31	Total Loss 3.2546 (3.9679)
2022-11-03 01:03:57,915:INFO: Batch:  3/31	Total Loss 4.6423 (4.1524)
2022-11-03 01:03:58,386:INFO: Batch:  4/31	Total Loss 4.3936 (4.2004)
2022-11-03 01:03:58,859:INFO: Batch:  5/31	Total Loss 3.9338 (4.1529)
2022-11-03 01:03:59,329:INFO: Batch:  6/31	Total Loss 4.4986 (4.1972)
2022-11-03 01:03:59,797:INFO: Batch:  7/31	Total Loss 4.4691 (4.2312)
2022-11-03 01:04:00,271:INFO: Batch:  8/31	Total Loss 4.2318 (4.2313)
2022-11-03 01:04:00,741:INFO: Batch:  9/31	Total Loss 5.0255 (4.3049)
2022-11-03 01:04:01,217:INFO: Batch: 10/31	Total Loss 3.9684 (4.2728)
2022-11-03 01:04:01,688:INFO: Batch: 11/31	Total Loss 4.6707 (4.3081)
2022-11-03 01:04:02,163:INFO: Batch: 12/31	Total Loss 4.4207 (4.3159)
2022-11-03 01:04:02,638:INFO: Batch: 13/31	Total Loss 4.3425 (4.3177)
2022-11-03 01:04:03,112:INFO: Batch: 14/31	Total Loss 4.1838 (4.3087)
2022-11-03 01:04:03,587:INFO: Batch: 15/31	Total Loss 4.7250 (4.3369)
2022-11-03 01:04:04,067:INFO: Batch: 16/31	Total Loss 4.6161 (4.3535)
2022-11-03 01:04:04,544:INFO: Batch: 17/31	Total Loss 4.8799 (4.3812)
2022-11-03 01:04:05,021:INFO: Batch: 18/31	Total Loss 4.0140 (4.3609)
2022-11-03 01:04:05,496:INFO: Batch: 19/31	Total Loss 4.3953 (4.3624)
2022-11-03 01:04:05,974:INFO: Batch: 20/31	Total Loss 4.3063 (4.3594)
2022-11-03 01:04:06,450:INFO: Batch: 21/31	Total Loss 4.2662 (4.3552)
2022-11-03 01:04:06,925:INFO: Batch: 22/31	Total Loss 4.3503 (4.3550)
2022-11-03 01:04:07,400:INFO: Batch: 23/31	Total Loss 4.2922 (4.3527)
2022-11-03 01:04:07,876:INFO: Batch: 24/31	Total Loss 4.3270 (4.3516)
2022-11-03 01:04:08,352:INFO: Batch: 25/31	Total Loss 4.3371 (4.3510)
2022-11-03 01:04:08,829:INFO: Batch: 26/31	Total Loss 3.9275 (4.3356)
2022-11-03 01:04:09,305:INFO: Batch: 27/31	Total Loss 4.1955 (4.3302)
2022-11-03 01:04:09,781:INFO: Batch: 28/31	Total Loss 4.2481 (4.3276)
2022-11-03 01:04:10,261:INFO: Batch: 29/31	Total Loss 4.4676 (4.3321)
2022-11-03 01:04:10,653:INFO: Batch: 30/31	Total Loss 1.5794 (4.3052)
2022-11-03 01:04:10,800:INFO: - Computing ADE (validation o)
2022-11-03 01:04:11,396:INFO: 		 ADE on eth                       dataset:	 0.9537472724914551
2022-11-03 01:04:11,397:INFO: Average validation o:	ADE  0.9537	FDE  1.8357
2022-11-03 01:04:11,397:INFO: - Computing ADE (validation)
2022-11-03 01:04:11,698:INFO: 		 ADE on hotel                     dataset:	 0.44013503193855286
2022-11-03 01:04:12,005:INFO: 		 ADE on univ                      dataset:	 0.5541004538536072
2022-11-03 01:04:12,251:INFO: 		 ADE on zara1                     dataset:	 0.4451991021633148
2022-11-03 01:04:12,607:INFO: 		 ADE on zara2                     dataset:	 0.4136866331100464
2022-11-03 01:04:12,607:INFO: Average validation:	ADE  0.4900	FDE  1.0117
2022-11-03 01:04:12,608:INFO: - Computing ADE (training)
2022-11-03 01:04:13,041:INFO: 		 ADE on hotel                     dataset:	 0.4682139754295349
2022-11-03 01:04:13,725:INFO: 		 ADE on univ                      dataset:	 0.5422535538673401
2022-11-03 01:04:14,259:INFO: 		 ADE on zara1                     dataset:	 0.49858546257019043
2022-11-03 01:04:15,012:INFO: 		 ADE on zara2                     dataset:	 0.420356810092926
2022-11-03 01:04:15,012:INFO: Average training:	ADE  0.5129	FDE  1.0648
2022-11-03 01:04:15,021:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_470.pth.tar
2022-11-03 01:04:15,022:INFO: 
===> EPOCH: 471 (P3)
2022-11-03 01:04:15,022:INFO: - Computing loss (training)
2022-11-03 01:04:16,121:INFO: Batch:  0/31	Total Loss 4.3221 (4.3221)
2022-11-03 01:04:16,597:INFO: Batch:  1/31	Total Loss 4.1683 (4.2390)
2022-11-03 01:04:17,071:INFO: Batch:  2/31	Total Loss 3.9843 (4.1626)
2022-11-03 01:04:17,618:INFO: Batch:  3/31	Total Loss 3.9521 (4.1125)
2022-11-03 01:04:18,086:INFO: Batch:  4/31	Total Loss 4.6098 (4.2169)
2022-11-03 01:04:18,563:INFO: Batch:  5/31	Total Loss 3.9817 (4.1788)
2022-11-03 01:04:19,029:INFO: Batch:  6/31	Total Loss 4.7676 (4.2533)
2022-11-03 01:04:19,503:INFO: Batch:  7/31	Total Loss 4.7497 (4.3127)
2022-11-03 01:04:19,971:INFO: Batch:  8/31	Total Loss 4.1396 (4.2946)
2022-11-03 01:04:20,444:INFO: Batch:  9/31	Total Loss 5.0282 (4.3701)
2022-11-03 01:04:20,912:INFO: Batch: 10/31	Total Loss 3.8497 (4.3276)
2022-11-03 01:04:21,382:INFO: Batch: 11/31	Total Loss 5.2853 (4.4029)
2022-11-03 01:04:21,855:INFO: Batch: 12/31	Total Loss 4.2924 (4.3953)
2022-11-03 01:04:22,328:INFO: Batch: 13/31	Total Loss 4.1483 (4.3775)
2022-11-03 01:04:22,801:INFO: Batch: 14/31	Total Loss 4.2176 (4.3677)
2022-11-03 01:04:23,274:INFO: Batch: 15/31	Total Loss 4.2347 (4.3597)
2022-11-03 01:04:23,747:INFO: Batch: 16/31	Total Loss 3.9316 (4.3339)
2022-11-03 01:04:24,223:INFO: Batch: 17/31	Total Loss 4.2643 (4.3304)
2022-11-03 01:04:24,696:INFO: Batch: 18/31	Total Loss 4.5662 (4.3428)
2022-11-03 01:04:25,173:INFO: Batch: 19/31	Total Loss 3.9576 (4.3218)
2022-11-03 01:04:25,645:INFO: Batch: 20/31	Total Loss 3.9815 (4.3063)
2022-11-03 01:04:26,117:INFO: Batch: 21/31	Total Loss 3.7318 (4.2834)
2022-11-03 01:04:26,589:INFO: Batch: 22/31	Total Loss 4.5904 (4.2961)
2022-11-03 01:04:27,063:INFO: Batch: 23/31	Total Loss 4.5210 (4.3048)
2022-11-03 01:04:27,535:INFO: Batch: 24/31	Total Loss 4.3617 (4.3074)
2022-11-03 01:04:28,007:INFO: Batch: 25/31	Total Loss 4.3141 (4.3077)
2022-11-03 01:04:28,478:INFO: Batch: 26/31	Total Loss 3.9923 (4.2946)
2022-11-03 01:04:28,949:INFO: Batch: 27/31	Total Loss 4.8162 (4.3123)
2022-11-03 01:04:29,422:INFO: Batch: 28/31	Total Loss 4.0349 (4.3023)
2022-11-03 01:04:29,894:INFO: Batch: 29/31	Total Loss 4.3448 (4.3036)
2022-11-03 01:04:30,281:INFO: Batch: 30/31	Total Loss 1.5070 (4.2782)
2022-11-03 01:04:30,429:INFO: - Computing ADE (validation o)
2022-11-03 01:04:31,003:INFO: 		 ADE on eth                       dataset:	 0.9251500964164734
2022-11-03 01:04:31,003:INFO: Average validation o:	ADE  0.9252	FDE  1.7797
2022-11-03 01:04:31,004:INFO: - Computing ADE (validation)
2022-11-03 01:04:31,263:INFO: 		 ADE on hotel                     dataset:	 0.43752914667129517
2022-11-03 01:04:31,560:INFO: 		 ADE on univ                      dataset:	 0.5516582727432251
2022-11-03 01:04:31,801:INFO: 		 ADE on zara1                     dataset:	 0.4301006495952606
2022-11-03 01:04:32,151:INFO: 		 ADE on zara2                     dataset:	 0.40437552332878113
2022-11-03 01:04:32,151:INFO: Average validation:	ADE  0.4843	FDE  1.0081
2022-11-03 01:04:32,152:INFO: - Computing ADE (training)
2022-11-03 01:04:32,616:INFO: 		 ADE on hotel                     dataset:	 0.45694631338119507
2022-11-03 01:04:33,290:INFO: 		 ADE on univ                      dataset:	 0.5428510308265686
2022-11-03 01:04:33,848:INFO: 		 ADE on zara1                     dataset:	 0.4744645953178406
2022-11-03 01:04:34,579:INFO: 		 ADE on zara2                     dataset:	 0.4039607048034668
2022-11-03 01:04:34,579:INFO: Average training:	ADE  0.5081	FDE  1.0631
2022-11-03 01:04:34,588:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_471.pth.tar
2022-11-03 01:04:34,588:INFO: 
===> EPOCH: 472 (P3)
2022-11-03 01:04:34,589:INFO: - Computing loss (training)
2022-11-03 01:04:35,678:INFO: Batch:  0/31	Total Loss 4.5266 (4.5266)
2022-11-03 01:04:36,145:INFO: Batch:  1/31	Total Loss 4.5786 (4.5534)
2022-11-03 01:04:36,615:INFO: Batch:  2/31	Total Loss 4.0798 (4.4159)
2022-11-03 01:04:37,081:INFO: Batch:  3/31	Total Loss 4.3831 (4.4081)
2022-11-03 01:04:37,554:INFO: Batch:  4/31	Total Loss 4.3161 (4.3894)
2022-11-03 01:04:38,025:INFO: Batch:  5/31	Total Loss 4.7461 (4.4541)
2022-11-03 01:04:38,495:INFO: Batch:  6/31	Total Loss 4.3913 (4.4469)
2022-11-03 01:04:38,964:INFO: Batch:  7/31	Total Loss 4.2947 (4.4282)
2022-11-03 01:04:39,431:INFO: Batch:  8/31	Total Loss 5.0575 (4.4948)
2022-11-03 01:04:39,902:INFO: Batch:  9/31	Total Loss 4.0768 (4.4506)
2022-11-03 01:04:40,374:INFO: Batch: 10/31	Total Loss 4.6825 (4.4689)
2022-11-03 01:04:40,844:INFO: Batch: 11/31	Total Loss 4.4907 (4.4708)
2022-11-03 01:04:41,317:INFO: Batch: 12/31	Total Loss 4.0407 (4.4391)
2022-11-03 01:04:41,792:INFO: Batch: 13/31	Total Loss 4.4536 (4.4401)
2022-11-03 01:04:42,265:INFO: Batch: 14/31	Total Loss 4.1742 (4.4229)
2022-11-03 01:04:42,740:INFO: Batch: 15/31	Total Loss 5.8066 (4.5044)
2022-11-03 01:04:43,213:INFO: Batch: 16/31	Total Loss 3.8205 (4.4629)
2022-11-03 01:04:43,687:INFO: Batch: 17/31	Total Loss 3.8756 (4.4290)
2022-11-03 01:04:44,160:INFO: Batch: 18/31	Total Loss 4.5884 (4.4385)
2022-11-03 01:04:44,633:INFO: Batch: 19/31	Total Loss 4.0181 (4.4172)
2022-11-03 01:04:45,103:INFO: Batch: 20/31	Total Loss 4.6570 (4.4277)
2022-11-03 01:04:45,575:INFO: Batch: 21/31	Total Loss 4.5854 (4.4348)
2022-11-03 01:04:46,044:INFO: Batch: 22/31	Total Loss 3.5341 (4.3970)
2022-11-03 01:04:46,512:INFO: Batch: 23/31	Total Loss 4.4352 (4.3985)
2022-11-03 01:04:46,981:INFO: Batch: 24/31	Total Loss 4.3827 (4.3978)
2022-11-03 01:04:47,452:INFO: Batch: 25/31	Total Loss 4.5862 (4.4055)
2022-11-03 01:04:47,921:INFO: Batch: 26/31	Total Loss 4.4367 (4.4067)
2022-11-03 01:04:48,390:INFO: Batch: 27/31	Total Loss 3.8804 (4.3855)
2022-11-03 01:04:48,857:INFO: Batch: 28/31	Total Loss 4.4464 (4.3875)
2022-11-03 01:04:49,325:INFO: Batch: 29/31	Total Loss 4.4317 (4.3888)
2022-11-03 01:04:49,711:INFO: Batch: 30/31	Total Loss 1.5799 (4.3598)
2022-11-03 01:04:49,862:INFO: - Computing ADE (validation o)
2022-11-03 01:04:50,452:INFO: 		 ADE on eth                       dataset:	 0.9473198056221008
2022-11-03 01:04:50,452:INFO: Average validation o:	ADE  0.9473	FDE  1.8294
2022-11-03 01:04:50,453:INFO: - Computing ADE (validation)
2022-11-03 01:04:50,723:INFO: 		 ADE on hotel                     dataset:	 0.45120951533317566
2022-11-03 01:04:51,010:INFO: 		 ADE on univ                      dataset:	 0.548750638961792
2022-11-03 01:04:51,263:INFO: 		 ADE on zara1                     dataset:	 0.4186983108520508
2022-11-03 01:04:51,609:INFO: 		 ADE on zara2                     dataset:	 0.4088915288448334
2022-11-03 01:04:51,610:INFO: Average validation:	ADE  0.4845	FDE  0.9950
2022-11-03 01:04:51,610:INFO: - Computing ADE (training)
2022-11-03 01:04:52,051:INFO: 		 ADE on hotel                     dataset:	 0.47818100452423096
2022-11-03 01:04:52,719:INFO: 		 ADE on univ                      dataset:	 0.5419381260871887
2022-11-03 01:04:53,254:INFO: 		 ADE on zara1                     dataset:	 0.49074143171310425
2022-11-03 01:04:53,994:INFO: 		 ADE on zara2                     dataset:	 0.4151151478290558
2022-11-03 01:04:53,994:INFO: Average training:	ADE  0.5113	FDE  1.0575
2022-11-03 01:04:54,003:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_472.pth.tar
2022-11-03 01:04:54,003:INFO: 
===> EPOCH: 473 (P3)
2022-11-03 01:04:54,003:INFO: - Computing loss (training)
2022-11-03 01:04:55,090:INFO: Batch:  0/31	Total Loss 4.4447 (4.4447)
2022-11-03 01:04:55,564:INFO: Batch:  1/31	Total Loss 4.1731 (4.2986)
2022-11-03 01:04:56,041:INFO: Batch:  2/31	Total Loss 3.8242 (4.1324)
2022-11-03 01:04:56,513:INFO: Batch:  3/31	Total Loss 4.2009 (4.1486)
2022-11-03 01:04:56,988:INFO: Batch:  4/31	Total Loss 3.9976 (4.1155)
2022-11-03 01:04:57,459:INFO: Batch:  5/31	Total Loss 4.4103 (4.1632)
2022-11-03 01:04:57,933:INFO: Batch:  6/31	Total Loss 4.5199 (4.2165)
2022-11-03 01:04:58,404:INFO: Batch:  7/31	Total Loss 4.3059 (4.2264)
2022-11-03 01:04:58,877:INFO: Batch:  8/31	Total Loss 4.5000 (4.2619)
2022-11-03 01:04:59,351:INFO: Batch:  9/31	Total Loss 4.0575 (4.2400)
2022-11-03 01:04:59,826:INFO: Batch: 10/31	Total Loss 4.1836 (4.2347)
2022-11-03 01:05:00,302:INFO: Batch: 11/31	Total Loss 4.4166 (4.2502)
2022-11-03 01:05:00,782:INFO: Batch: 12/31	Total Loss 4.2555 (4.2506)
2022-11-03 01:05:01,261:INFO: Batch: 13/31	Total Loss 4.4080 (4.2624)
2022-11-03 01:05:01,738:INFO: Batch: 14/31	Total Loss 4.2147 (4.2594)
2022-11-03 01:05:02,216:INFO: Batch: 15/31	Total Loss 4.2305 (4.2574)
2022-11-03 01:05:02,717:INFO: Batch: 16/31	Total Loss 3.7994 (4.2299)
2022-11-03 01:05:03,191:INFO: Batch: 17/31	Total Loss 4.8306 (4.2683)
2022-11-03 01:05:03,666:INFO: Batch: 18/31	Total Loss 3.9025 (4.2490)
2022-11-03 01:05:04,140:INFO: Batch: 19/31	Total Loss 4.7144 (4.2736)
2022-11-03 01:05:04,616:INFO: Batch: 20/31	Total Loss 4.3172 (4.2756)
2022-11-03 01:05:05,088:INFO: Batch: 21/31	Total Loss 3.8365 (4.2547)
2022-11-03 01:05:05,561:INFO: Batch: 22/31	Total Loss 4.2597 (4.2549)
2022-11-03 01:05:06,033:INFO: Batch: 23/31	Total Loss 4.4846 (4.2634)
2022-11-03 01:05:06,503:INFO: Batch: 24/31	Total Loss 4.0505 (4.2548)
2022-11-03 01:05:06,977:INFO: Batch: 25/31	Total Loss 3.9246 (4.2415)
2022-11-03 01:05:07,450:INFO: Batch: 26/31	Total Loss 4.3651 (4.2456)
2022-11-03 01:05:07,922:INFO: Batch: 27/31	Total Loss 6.1497 (4.3137)
2022-11-03 01:05:08,392:INFO: Batch: 28/31	Total Loss 3.3690 (4.2798)
2022-11-03 01:05:08,865:INFO: Batch: 29/31	Total Loss 4.6450 (4.2916)
2022-11-03 01:05:09,251:INFO: Batch: 30/31	Total Loss 1.3341 (4.2639)
2022-11-03 01:05:09,403:INFO: - Computing ADE (validation o)
2022-11-03 01:05:10,010:INFO: 		 ADE on eth                       dataset:	 1.0079293251037598
2022-11-03 01:05:10,011:INFO: Average validation o:	ADE  1.0079	FDE  1.9818
2022-11-03 01:05:10,011:INFO: - Computing ADE (validation)
2022-11-03 01:05:10,283:INFO: 		 ADE on hotel                     dataset:	 0.4909469783306122
2022-11-03 01:05:10,561:INFO: 		 ADE on univ                      dataset:	 0.5867127776145935
2022-11-03 01:05:10,803:INFO: 		 ADE on zara1                     dataset:	 0.539068341255188
2022-11-03 01:05:11,152:INFO: 		 ADE on zara2                     dataset:	 0.49512434005737305
2022-11-03 01:05:11,152:INFO: Average validation:	ADE  0.5451	FDE  1.1533
2022-11-03 01:05:11,153:INFO: - Computing ADE (training)
2022-11-03 01:05:11,605:INFO: 		 ADE on hotel                     dataset:	 0.5145544409751892
2022-11-03 01:05:12,263:INFO: 		 ADE on univ                      dataset:	 0.5890942811965942
2022-11-03 01:05:12,784:INFO: 		 ADE on zara1                     dataset:	 0.5779337882995605
2022-11-03 01:05:13,553:INFO: 		 ADE on zara2                     dataset:	 0.5072623491287231
2022-11-03 01:05:13,553:INFO: Average training:	ADE  0.5699	FDE  1.2146
2022-11-03 01:05:13,562:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_473.pth.tar
2022-11-03 01:05:13,562:INFO: 
===> EPOCH: 474 (P3)
2022-11-03 01:05:13,562:INFO: - Computing loss (training)
2022-11-03 01:05:14,751:INFO: Batch:  0/31	Total Loss 4.3758 (4.3758)
2022-11-03 01:05:15,225:INFO: Batch:  1/31	Total Loss 4.6017 (4.4784)
2022-11-03 01:05:15,707:INFO: Batch:  2/31	Total Loss 5.2251 (4.7342)
2022-11-03 01:05:16,180:INFO: Batch:  3/31	Total Loss 4.4779 (4.6694)
2022-11-03 01:05:16,657:INFO: Batch:  4/31	Total Loss 4.2557 (4.5871)
2022-11-03 01:05:17,136:INFO: Batch:  5/31	Total Loss 3.6984 (4.4415)
2022-11-03 01:05:17,608:INFO: Batch:  6/31	Total Loss 4.8173 (4.4854)
2022-11-03 01:05:18,082:INFO: Batch:  7/31	Total Loss 5.2704 (4.5776)
2022-11-03 01:05:18,554:INFO: Batch:  8/31	Total Loss 4.4248 (4.5612)
2022-11-03 01:05:19,028:INFO: Batch:  9/31	Total Loss 3.5452 (4.4597)
2022-11-03 01:05:19,504:INFO: Batch: 10/31	Total Loss 4.7564 (4.4879)
2022-11-03 01:05:19,978:INFO: Batch: 11/31	Total Loss 4.2857 (4.4731)
2022-11-03 01:05:20,459:INFO: Batch: 12/31	Total Loss 4.0546 (4.4397)
2022-11-03 01:05:20,938:INFO: Batch: 13/31	Total Loss 4.3226 (4.4313)
2022-11-03 01:05:21,417:INFO: Batch: 14/31	Total Loss 3.9555 (4.3979)
2022-11-03 01:05:21,889:INFO: Batch: 15/31	Total Loss 4.0938 (4.3799)
2022-11-03 01:05:22,362:INFO: Batch: 16/31	Total Loss 4.7168 (4.4024)
2022-11-03 01:05:22,840:INFO: Batch: 17/31	Total Loss 4.2747 (4.3952)
2022-11-03 01:05:23,316:INFO: Batch: 18/31	Total Loss 4.6335 (4.4081)
2022-11-03 01:05:23,793:INFO: Batch: 19/31	Total Loss 4.4169 (4.4085)
2022-11-03 01:05:24,268:INFO: Batch: 20/31	Total Loss 5.3410 (4.4535)
2022-11-03 01:05:24,746:INFO: Batch: 21/31	Total Loss 4.1263 (4.4381)
2022-11-03 01:05:25,222:INFO: Batch: 22/31	Total Loss 4.3101 (4.4325)
2022-11-03 01:05:25,701:INFO: Batch: 23/31	Total Loss 4.4287 (4.4323)
2022-11-03 01:05:26,177:INFO: Batch: 24/31	Total Loss 3.8992 (4.4107)
2022-11-03 01:05:26,652:INFO: Batch: 25/31	Total Loss 4.2691 (4.4048)
2022-11-03 01:05:27,127:INFO: Batch: 26/31	Total Loss 3.8247 (4.3812)
2022-11-03 01:05:27,601:INFO: Batch: 27/31	Total Loss 3.7626 (4.3590)
2022-11-03 01:05:28,074:INFO: Batch: 28/31	Total Loss 4.4930 (4.3632)
2022-11-03 01:05:28,547:INFO: Batch: 29/31	Total Loss 5.0114 (4.3851)
2022-11-03 01:05:28,935:INFO: Batch: 30/31	Total Loss 1.8114 (4.3599)
2022-11-03 01:05:29,088:INFO: - Computing ADE (validation o)
2022-11-03 01:05:29,701:INFO: 		 ADE on eth                       dataset:	 0.9907490611076355
2022-11-03 01:05:29,702:INFO: Average validation o:	ADE  0.9907	FDE  1.9217
2022-11-03 01:05:29,702:INFO: - Computing ADE (validation)
2022-11-03 01:05:29,984:INFO: 		 ADE on hotel                     dataset:	 0.4423684775829315
2022-11-03 01:05:30,288:INFO: 		 ADE on univ                      dataset:	 0.5503786206245422
2022-11-03 01:05:30,526:INFO: 		 ADE on zara1                     dataset:	 0.4668372869491577
2022-11-03 01:05:30,868:INFO: 		 ADE on zara2                     dataset:	 0.4331790804862976
2022-11-03 01:05:30,869:INFO: Average validation:	ADE  0.4966	FDE  1.0198
2022-11-03 01:05:30,869:INFO: - Computing ADE (training)
2022-11-03 01:05:31,347:INFO: 		 ADE on hotel                     dataset:	 0.4636167585849762
2022-11-03 01:05:32,016:INFO: 		 ADE on univ                      dataset:	 0.5454463958740234
2022-11-03 01:05:32,549:INFO: 		 ADE on zara1                     dataset:	 0.5326313376426697
2022-11-03 01:05:33,296:INFO: 		 ADE on zara2                     dataset:	 0.45055678486824036
2022-11-03 01:05:33,297:INFO: Average training:	ADE  0.5233	FDE  1.0838
2022-11-03 01:05:33,306:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_474.pth.tar
2022-11-03 01:05:33,306:INFO: 
===> EPOCH: 475 (P3)
2022-11-03 01:05:33,306:INFO: - Computing loss (training)
2022-11-03 01:05:34,429:INFO: Batch:  0/31	Total Loss 4.8579 (4.8579)
2022-11-03 01:05:34,913:INFO: Batch:  1/31	Total Loss 4.6867 (4.7743)
2022-11-03 01:05:35,404:INFO: Batch:  2/31	Total Loss 4.5054 (4.6751)
2022-11-03 01:05:36,071:INFO: Batch:  3/31	Total Loss 4.2206 (4.5680)
2022-11-03 01:05:36,696:INFO: Batch:  4/31	Total Loss 3.9409 (4.4346)
2022-11-03 01:05:37,273:INFO: Batch:  5/31	Total Loss 3.9500 (4.3484)
2022-11-03 01:05:37,825:INFO: Batch:  6/31	Total Loss 3.9997 (4.2969)
2022-11-03 01:05:38,343:INFO: Batch:  7/31	Total Loss 4.2584 (4.2917)
2022-11-03 01:05:38,828:INFO: Batch:  8/31	Total Loss 5.1244 (4.3690)
2022-11-03 01:05:39,329:INFO: Batch:  9/31	Total Loss 4.2284 (4.3550)
2022-11-03 01:05:39,885:INFO: Batch: 10/31	Total Loss 4.0191 (4.3243)
2022-11-03 01:05:40,412:INFO: Batch: 11/31	Total Loss 4.0100 (4.2980)
2022-11-03 01:05:40,916:INFO: Batch: 12/31	Total Loss 5.0636 (4.3470)
2022-11-03 01:05:41,438:INFO: Batch: 13/31	Total Loss 4.4796 (4.3562)
2022-11-03 01:05:41,953:INFO: Batch: 14/31	Total Loss 4.7539 (4.3864)
2022-11-03 01:05:42,451:INFO: Batch: 15/31	Total Loss 4.5424 (4.3957)
2022-11-03 01:05:42,949:INFO: Batch: 16/31	Total Loss 5.0570 (4.4330)
2022-11-03 01:05:43,469:INFO: Batch: 17/31	Total Loss 4.7040 (4.4469)
2022-11-03 01:05:43,985:INFO: Batch: 18/31	Total Loss 4.7444 (4.4625)
2022-11-03 01:05:44,490:INFO: Batch: 19/31	Total Loss 3.7714 (4.4262)
2022-11-03 01:05:45,040:INFO: Batch: 20/31	Total Loss 4.2615 (4.4179)
2022-11-03 01:05:45,592:INFO: Batch: 21/31	Total Loss 4.1385 (4.4047)
2022-11-03 01:05:46,103:INFO: Batch: 22/31	Total Loss 4.7263 (4.4201)
2022-11-03 01:05:46,625:INFO: Batch: 23/31	Total Loss 4.2180 (4.4120)
2022-11-03 01:05:47,173:INFO: Batch: 24/31	Total Loss 4.8595 (4.4311)
2022-11-03 01:05:47,690:INFO: Batch: 25/31	Total Loss 3.7214 (4.4015)
2022-11-03 01:05:48,169:INFO: Batch: 26/31	Total Loss 4.1780 (4.3929)
2022-11-03 01:05:48,685:INFO: Batch: 27/31	Total Loss 4.2603 (4.3883)
2022-11-03 01:05:49,201:INFO: Batch: 28/31	Total Loss 4.1532 (4.3793)
2022-11-03 01:05:49,727:INFO: Batch: 29/31	Total Loss 3.9347 (4.3643)
2022-11-03 01:05:50,144:INFO: Batch: 30/31	Total Loss 1.4754 (4.3416)
2022-11-03 01:05:50,305:INFO: - Computing ADE (validation o)
2022-11-03 01:05:50,957:INFO: 		 ADE on eth                       dataset:	 0.9699402451515198
2022-11-03 01:05:50,958:INFO: Average validation o:	ADE  0.9699	FDE  1.8872
2022-11-03 01:05:50,958:INFO: - Computing ADE (validation)
2022-11-03 01:05:51,259:INFO: 		 ADE on hotel                     dataset:	 0.43398240208625793
2022-11-03 01:05:51,585:INFO: 		 ADE on univ                      dataset:	 0.5500509142875671
2022-11-03 01:05:51,839:INFO: 		 ADE on zara1                     dataset:	 0.45009365677833557
2022-11-03 01:05:52,211:INFO: 		 ADE on zara2                     dataset:	 0.418405681848526
2022-11-03 01:05:52,212:INFO: Average validation:	ADE  0.4896	FDE  1.0085
2022-11-03 01:05:52,212:INFO: - Computing ADE (training)
2022-11-03 01:05:52,707:INFO: 		 ADE on hotel                     dataset:	 0.45727819204330444
2022-11-03 01:05:53,444:INFO: 		 ADE on univ                      dataset:	 0.5428693890571594
2022-11-03 01:05:54,047:INFO: 		 ADE on zara1                     dataset:	 0.5125641226768494
2022-11-03 01:05:55,066:INFO: 		 ADE on zara2                     dataset:	 0.43042781949043274
2022-11-03 01:05:55,066:INFO: Average training:	ADE  0.5159	FDE  1.0714
2022-11-03 01:05:55,076:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_475.pth.tar
2022-11-03 01:05:55,076:INFO: 
===> EPOCH: 476 (P3)
2022-11-03 01:05:55,076:INFO: - Computing loss (training)
2022-11-03 01:05:56,229:INFO: Batch:  0/31	Total Loss 4.7400 (4.7400)
2022-11-03 01:05:56,714:INFO: Batch:  1/31	Total Loss 4.2527 (4.4929)
2022-11-03 01:05:57,193:INFO: Batch:  2/31	Total Loss 4.7879 (4.5980)
2022-11-03 01:05:57,671:INFO: Batch:  3/31	Total Loss 4.1871 (4.4944)
2022-11-03 01:05:58,149:INFO: Batch:  4/31	Total Loss 4.1848 (4.4345)
2022-11-03 01:05:58,631:INFO: Batch:  5/31	Total Loss 4.3693 (4.4241)
2022-11-03 01:05:59,116:INFO: Batch:  6/31	Total Loss 3.8630 (4.3312)
2022-11-03 01:05:59,595:INFO: Batch:  7/31	Total Loss 4.5748 (4.3635)
2022-11-03 01:06:00,080:INFO: Batch:  8/31	Total Loss 4.9798 (4.4268)
2022-11-03 01:06:00,562:INFO: Batch:  9/31	Total Loss 4.7423 (4.4556)
2022-11-03 01:06:01,043:INFO: Batch: 10/31	Total Loss 4.2896 (4.4407)
2022-11-03 01:06:01,519:INFO: Batch: 11/31	Total Loss 3.8105 (4.3829)
2022-11-03 01:06:01,993:INFO: Batch: 12/31	Total Loss 5.0211 (4.4280)
2022-11-03 01:06:02,466:INFO: Batch: 13/31	Total Loss 4.6758 (4.4487)
2022-11-03 01:06:02,957:INFO: Batch: 14/31	Total Loss 4.4033 (4.4454)
2022-11-03 01:06:03,430:INFO: Batch: 15/31	Total Loss 3.9979 (4.4187)
2022-11-03 01:06:03,910:INFO: Batch: 16/31	Total Loss 4.6835 (4.4325)
2022-11-03 01:06:04,392:INFO: Batch: 17/31	Total Loss 4.1459 (4.4168)
2022-11-03 01:06:04,870:INFO: Batch: 18/31	Total Loss 4.1804 (4.4053)
2022-11-03 01:06:05,353:INFO: Batch: 19/31	Total Loss 3.7636 (4.3718)
2022-11-03 01:06:05,837:INFO: Batch: 20/31	Total Loss 4.3178 (4.3693)
2022-11-03 01:06:06,323:INFO: Batch: 21/31	Total Loss 4.2553 (4.3634)
2022-11-03 01:06:06,900:INFO: Batch: 22/31	Total Loss 4.3888 (4.3646)
2022-11-03 01:06:07,386:INFO: Batch: 23/31	Total Loss 4.2717 (4.3605)
2022-11-03 01:06:07,873:INFO: Batch: 24/31	Total Loss 3.9305 (4.3421)
2022-11-03 01:06:08,358:INFO: Batch: 25/31	Total Loss 4.1144 (4.3326)
2022-11-03 01:06:08,842:INFO: Batch: 26/31	Total Loss 4.5378 (4.3406)
2022-11-03 01:06:09,325:INFO: Batch: 27/31	Total Loss 4.1572 (4.3341)
2022-11-03 01:06:09,810:INFO: Batch: 28/31	Total Loss 3.6198 (4.3108)
2022-11-03 01:06:10,293:INFO: Batch: 29/31	Total Loss 3.9153 (4.2981)
2022-11-03 01:06:10,690:INFO: Batch: 30/31	Total Loss 1.5293 (4.2757)
2022-11-03 01:06:10,854:INFO: - Computing ADE (validation o)
2022-11-03 01:06:11,455:INFO: 		 ADE on eth                       dataset:	 0.9524307250976562
2022-11-03 01:06:11,455:INFO: Average validation o:	ADE  0.9524	FDE  1.8438
2022-11-03 01:06:11,456:INFO: - Computing ADE (validation)
2022-11-03 01:06:11,713:INFO: 		 ADE on hotel                     dataset:	 0.41404345631599426
2022-11-03 01:06:11,999:INFO: 		 ADE on univ                      dataset:	 0.5438379645347595
2022-11-03 01:06:12,236:INFO: 		 ADE on zara1                     dataset:	 0.4293631315231323
2022-11-03 01:06:12,576:INFO: 		 ADE on zara2                     dataset:	 0.39852267503738403
2022-11-03 01:06:12,576:INFO: Average validation:	ADE  0.4768	FDE  0.9765
2022-11-03 01:06:12,577:INFO: - Computing ADE (training)
2022-11-03 01:06:13,032:INFO: 		 ADE on hotel                     dataset:	 0.43168047070503235
2022-11-03 01:06:13,707:INFO: 		 ADE on univ                      dataset:	 0.5330162048339844
2022-11-03 01:06:14,264:INFO: 		 ADE on zara1                     dataset:	 0.48928651213645935
2022-11-03 01:06:15,001:INFO: 		 ADE on zara2                     dataset:	 0.4064786434173584
2022-11-03 01:06:15,001:INFO: Average training:	ADE  0.5020	FDE  1.0366
2022-11-03 01:06:15,010:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_476.pth.tar
2022-11-03 01:06:15,010:INFO: 
===> EPOCH: 477 (P3)
2022-11-03 01:06:15,010:INFO: - Computing loss (training)
2022-11-03 01:06:16,101:INFO: Batch:  0/31	Total Loss 4.1198 (4.1198)
2022-11-03 01:06:16,579:INFO: Batch:  1/31	Total Loss 4.5984 (4.3627)
2022-11-03 01:06:17,051:INFO: Batch:  2/31	Total Loss 4.0661 (4.2616)
2022-11-03 01:06:17,519:INFO: Batch:  3/31	Total Loss 4.1989 (4.2455)
2022-11-03 01:06:17,988:INFO: Batch:  4/31	Total Loss 3.9351 (4.1796)
2022-11-03 01:06:18,467:INFO: Batch:  5/31	Total Loss 4.0267 (4.1549)
2022-11-03 01:06:18,939:INFO: Batch:  6/31	Total Loss 4.3856 (4.1855)
2022-11-03 01:06:19,414:INFO: Batch:  7/31	Total Loss 4.9266 (4.2683)
2022-11-03 01:06:19,886:INFO: Batch:  8/31	Total Loss 4.0777 (4.2442)
2022-11-03 01:06:20,357:INFO: Batch:  9/31	Total Loss 4.1627 (4.2349)
2022-11-03 01:06:20,821:INFO: Batch: 10/31	Total Loss 3.6200 (4.1750)
2022-11-03 01:06:21,299:INFO: Batch: 11/31	Total Loss 3.8571 (4.1462)
2022-11-03 01:06:21,771:INFO: Batch: 12/31	Total Loss 4.5553 (4.1759)
2022-11-03 01:06:22,242:INFO: Batch: 13/31	Total Loss 4.6845 (4.2128)
2022-11-03 01:06:22,713:INFO: Batch: 14/31	Total Loss 4.6620 (4.2430)
2022-11-03 01:06:23,187:INFO: Batch: 15/31	Total Loss 4.2613 (4.2442)
2022-11-03 01:06:23,660:INFO: Batch: 16/31	Total Loss 4.6710 (4.2704)
2022-11-03 01:06:24,135:INFO: Batch: 17/31	Total Loss 3.6056 (4.2287)
2022-11-03 01:06:24,610:INFO: Batch: 18/31	Total Loss 4.3742 (4.2362)
2022-11-03 01:06:25,079:INFO: Batch: 19/31	Total Loss 4.7543 (4.2627)
2022-11-03 01:06:25,548:INFO: Batch: 20/31	Total Loss 3.8913 (4.2440)
2022-11-03 01:06:26,019:INFO: Batch: 21/31	Total Loss 4.4085 (4.2511)
2022-11-03 01:06:26,487:INFO: Batch: 22/31	Total Loss 4.3833 (4.2565)
2022-11-03 01:06:26,960:INFO: Batch: 23/31	Total Loss 3.7827 (4.2367)
2022-11-03 01:06:27,429:INFO: Batch: 24/31	Total Loss 4.0060 (4.2276)
2022-11-03 01:06:27,900:INFO: Batch: 25/31	Total Loss 4.2756 (4.2295)
2022-11-03 01:06:28,367:INFO: Batch: 26/31	Total Loss 4.5259 (4.2396)
2022-11-03 01:06:28,836:INFO: Batch: 27/31	Total Loss 3.9583 (4.2292)
2022-11-03 01:06:29,306:INFO: Batch: 28/31	Total Loss 4.2001 (4.2282)
2022-11-03 01:06:29,778:INFO: Batch: 29/31	Total Loss 4.0090 (4.2202)
2022-11-03 01:06:30,162:INFO: Batch: 30/31	Total Loss 1.4064 (4.1851)
2022-11-03 01:06:30,307:INFO: - Computing ADE (validation o)
2022-11-03 01:06:30,932:INFO: 		 ADE on eth                       dataset:	 0.9410310387611389
2022-11-03 01:06:30,932:INFO: Average validation o:	ADE  0.9410	FDE  1.8521
2022-11-03 01:06:30,933:INFO: - Computing ADE (validation)
2022-11-03 01:06:31,214:INFO: 		 ADE on hotel                     dataset:	 0.42845582962036133
2022-11-03 01:06:31,502:INFO: 		 ADE on univ                      dataset:	 0.5483851432800293
2022-11-03 01:06:31,759:INFO: 		 ADE on zara1                     dataset:	 0.40806686878204346
2022-11-03 01:06:32,092:INFO: 		 ADE on zara2                     dataset:	 0.3988904654979706
2022-11-03 01:06:32,092:INFO: Average validation:	ADE  0.4788	FDE  0.9858
2022-11-03 01:06:32,093:INFO: - Computing ADE (training)
2022-11-03 01:06:32,530:INFO: 		 ADE on hotel                     dataset:	 0.4450956881046295
2022-11-03 01:06:33,264:INFO: 		 ADE on univ                      dataset:	 0.5403761267662048
2022-11-03 01:06:33,786:INFO: 		 ADE on zara1                     dataset:	 0.47032663226127625
2022-11-03 01:06:34,543:INFO: 		 ADE on zara2                     dataset:	 0.39940589666366577
2022-11-03 01:06:34,543:INFO: Average training:	ADE  0.5049	FDE  1.0475
2022-11-03 01:06:34,552:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_477.pth.tar
2022-11-03 01:06:34,552:INFO: 
===> EPOCH: 478 (P3)
2022-11-03 01:06:34,552:INFO: - Computing loss (training)
2022-11-03 01:06:35,661:INFO: Batch:  0/31	Total Loss 5.3609 (5.3609)
2022-11-03 01:06:36,149:INFO: Batch:  1/31	Total Loss 3.8409 (4.6489)
2022-11-03 01:06:36,626:INFO: Batch:  2/31	Total Loss 4.0744 (4.4718)
2022-11-03 01:06:37,100:INFO: Batch:  3/31	Total Loss 4.5660 (4.4949)
2022-11-03 01:06:37,571:INFO: Batch:  4/31	Total Loss 4.0951 (4.4341)
2022-11-03 01:06:38,052:INFO: Batch:  5/31	Total Loss 4.3602 (4.4218)
2022-11-03 01:06:38,531:INFO: Batch:  6/31	Total Loss 4.3303 (4.4092)
2022-11-03 01:06:39,007:INFO: Batch:  7/31	Total Loss 4.4583 (4.4157)
2022-11-03 01:06:39,482:INFO: Batch:  8/31	Total Loss 4.1199 (4.3818)
2022-11-03 01:06:39,957:INFO: Batch:  9/31	Total Loss 4.1845 (4.3641)
2022-11-03 01:06:40,438:INFO: Batch: 10/31	Total Loss 4.2183 (4.3501)
2022-11-03 01:06:40,915:INFO: Batch: 11/31	Total Loss 3.7573 (4.3051)
2022-11-03 01:06:41,397:INFO: Batch: 12/31	Total Loss 4.5335 (4.3214)
2022-11-03 01:06:41,879:INFO: Batch: 13/31	Total Loss 4.0075 (4.2982)
2022-11-03 01:06:42,361:INFO: Batch: 14/31	Total Loss 4.1180 (4.2864)
2022-11-03 01:06:42,850:INFO: Batch: 15/31	Total Loss 4.1835 (4.2799)
2022-11-03 01:06:43,324:INFO: Batch: 16/31	Total Loss 5.3383 (4.3462)
2022-11-03 01:06:43,799:INFO: Batch: 17/31	Total Loss 4.6339 (4.3644)
2022-11-03 01:06:44,274:INFO: Batch: 18/31	Total Loss 4.2263 (4.3570)
2022-11-03 01:06:44,747:INFO: Batch: 19/31	Total Loss 4.0039 (4.3398)
2022-11-03 01:06:45,221:INFO: Batch: 20/31	Total Loss 4.0787 (4.3279)
2022-11-03 01:06:45,694:INFO: Batch: 21/31	Total Loss 4.2578 (4.3246)
2022-11-03 01:06:46,168:INFO: Batch: 22/31	Total Loss 4.5886 (4.3366)
2022-11-03 01:06:46,640:INFO: Batch: 23/31	Total Loss 4.8052 (4.3573)
2022-11-03 01:06:47,114:INFO: Batch: 24/31	Total Loss 5.3793 (4.3990)
2022-11-03 01:06:47,586:INFO: Batch: 25/31	Total Loss 4.3965 (4.3989)
2022-11-03 01:06:48,058:INFO: Batch: 26/31	Total Loss 3.8459 (4.3791)
2022-11-03 01:06:48,530:INFO: Batch: 27/31	Total Loss 4.5514 (4.3854)
2022-11-03 01:06:49,002:INFO: Batch: 28/31	Total Loss 4.5939 (4.3915)
2022-11-03 01:06:49,476:INFO: Batch: 29/31	Total Loss 4.2069 (4.3852)
2022-11-03 01:06:49,867:INFO: Batch: 30/31	Total Loss 1.8539 (4.3584)
2022-11-03 01:06:50,013:INFO: - Computing ADE (validation o)
2022-11-03 01:06:50,615:INFO: 		 ADE on eth                       dataset:	 1.0084980726242065
2022-11-03 01:06:50,615:INFO: Average validation o:	ADE  1.0085	FDE  2.0190
2022-11-03 01:06:50,616:INFO: - Computing ADE (validation)
2022-11-03 01:06:50,867:INFO: 		 ADE on hotel                     dataset:	 0.5189293026924133
2022-11-03 01:06:51,147:INFO: 		 ADE on univ                      dataset:	 0.5819135904312134
2022-11-03 01:06:51,390:INFO: 		 ADE on zara1                     dataset:	 0.42976653575897217
2022-11-03 01:06:51,743:INFO: 		 ADE on zara2                     dataset:	 0.49500787258148193
2022-11-03 01:06:51,743:INFO: Average validation:	ADE  0.5377	FDE  1.1414
2022-11-03 01:06:51,744:INFO: - Computing ADE (training)
2022-11-03 01:06:52,202:INFO: 		 ADE on hotel                     dataset:	 0.5216598510742188
2022-11-03 01:06:52,877:INFO: 		 ADE on univ                      dataset:	 0.5924801826477051
2022-11-03 01:06:53,437:INFO: 		 ADE on zara1                     dataset:	 0.5378236770629883
2022-11-03 01:06:54,180:INFO: 		 ADE on zara2                     dataset:	 0.49858683347702026
2022-11-03 01:06:54,181:INFO: Average training:	ADE  0.5681	FDE  1.2141
2022-11-03 01:06:54,189:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_478.pth.tar
2022-11-03 01:06:54,189:INFO: 
===> EPOCH: 479 (P3)
2022-11-03 01:06:54,190:INFO: - Computing loss (training)
2022-11-03 01:06:55,286:INFO: Batch:  0/31	Total Loss 3.7598 (3.7598)
2022-11-03 01:06:55,762:INFO: Batch:  1/31	Total Loss 4.6769 (4.2260)
2022-11-03 01:06:56,251:INFO: Batch:  2/31	Total Loss 4.4782 (4.3080)
2022-11-03 01:06:56,725:INFO: Batch:  3/31	Total Loss 3.9207 (4.2107)
2022-11-03 01:06:57,205:INFO: Batch:  4/31	Total Loss 4.2759 (4.2241)
2022-11-03 01:06:57,683:INFO: Batch:  5/31	Total Loss 3.9983 (4.1848)
2022-11-03 01:06:58,159:INFO: Batch:  6/31	Total Loss 4.2144 (4.1890)
2022-11-03 01:06:58,634:INFO: Batch:  7/31	Total Loss 3.9168 (4.1564)
2022-11-03 01:06:59,184:INFO: Batch:  8/31	Total Loss 4.5769 (4.1993)
2022-11-03 01:06:59,657:INFO: Batch:  9/31	Total Loss 4.4662 (4.2291)
2022-11-03 01:07:00,134:INFO: Batch: 10/31	Total Loss 4.2030 (4.2267)
2022-11-03 01:07:00,609:INFO: Batch: 11/31	Total Loss 3.9981 (4.2086)
2022-11-03 01:07:01,087:INFO: Batch: 12/31	Total Loss 4.0739 (4.1990)
2022-11-03 01:07:01,568:INFO: Batch: 13/31	Total Loss 4.3166 (4.2084)
2022-11-03 01:07:02,046:INFO: Batch: 14/31	Total Loss 4.1504 (4.2046)
2022-11-03 01:07:02,525:INFO: Batch: 15/31	Total Loss 4.0772 (4.1973)
2022-11-03 01:07:03,001:INFO: Batch: 16/31	Total Loss 4.2896 (4.2026)
2022-11-03 01:07:03,478:INFO: Batch: 17/31	Total Loss 4.7106 (4.2303)
2022-11-03 01:07:03,955:INFO: Batch: 18/31	Total Loss 4.1149 (4.2244)
2022-11-03 01:07:04,432:INFO: Batch: 19/31	Total Loss 4.5685 (4.2414)
2022-11-03 01:07:04,909:INFO: Batch: 20/31	Total Loss 4.6316 (4.2600)
2022-11-03 01:07:05,388:INFO: Batch: 21/31	Total Loss 4.5377 (4.2725)
2022-11-03 01:07:05,867:INFO: Batch: 22/31	Total Loss 3.8587 (4.2546)
2022-11-03 01:07:06,344:INFO: Batch: 23/31	Total Loss 4.7237 (4.2736)
2022-11-03 01:07:06,829:INFO: Batch: 24/31	Total Loss 4.3133 (4.2753)
2022-11-03 01:07:07,310:INFO: Batch: 25/31	Total Loss 4.5945 (4.2875)
2022-11-03 01:07:07,790:INFO: Batch: 26/31	Total Loss 5.2589 (4.3201)
2022-11-03 01:07:08,268:INFO: Batch: 27/31	Total Loss 4.3911 (4.3226)
2022-11-03 01:07:08,757:INFO: Batch: 28/31	Total Loss 4.0960 (4.3150)
2022-11-03 01:07:09,236:INFO: Batch: 29/31	Total Loss 4.3763 (4.3170)
2022-11-03 01:07:09,628:INFO: Batch: 30/31	Total Loss 1.6546 (4.2955)
2022-11-03 01:07:09,793:INFO: - Computing ADE (validation o)
2022-11-03 01:07:10,383:INFO: 		 ADE on eth                       dataset:	 0.9523239731788635
2022-11-03 01:07:10,384:INFO: Average validation o:	ADE  0.9523	FDE  1.8170
2022-11-03 01:07:10,384:INFO: - Computing ADE (validation)
2022-11-03 01:07:10,679:INFO: 		 ADE on hotel                     dataset:	 0.4447212517261505
2022-11-03 01:07:10,972:INFO: 		 ADE on univ                      dataset:	 0.5522563457489014
2022-11-03 01:07:11,232:INFO: 		 ADE on zara1                     dataset:	 0.42367538809776306
2022-11-03 01:07:11,580:INFO: 		 ADE on zara2                     dataset:	 0.40668046474456787
2022-11-03 01:07:11,580:INFO: Average validation:	ADE  0.4855	FDE  0.9915
2022-11-03 01:07:11,581:INFO: - Computing ADE (training)
2022-11-03 01:07:12,050:INFO: 		 ADE on hotel                     dataset:	 0.48027125000953674
2022-11-03 01:07:12,754:INFO: 		 ADE on univ                      dataset:	 0.5407538414001465
2022-11-03 01:07:13,284:INFO: 		 ADE on zara1                     dataset:	 0.5034759044647217
2022-11-03 01:07:14,047:INFO: 		 ADE on zara2                     dataset:	 0.4179457128047943
2022-11-03 01:07:14,047:INFO: Average training:	ADE  0.5119	FDE  1.0531
2022-11-03 01:07:14,056:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_479.pth.tar
2022-11-03 01:07:14,056:INFO: 
===> EPOCH: 480 (P3)
2022-11-03 01:07:14,056:INFO: - Computing loss (training)
2022-11-03 01:07:15,163:INFO: Batch:  0/31	Total Loss 4.1515 (4.1515)
2022-11-03 01:07:15,637:INFO: Batch:  1/31	Total Loss 3.5906 (3.8651)
2022-11-03 01:07:16,112:INFO: Batch:  2/31	Total Loss 4.9096 (4.2177)
2022-11-03 01:07:16,586:INFO: Batch:  3/31	Total Loss 4.2909 (4.2363)
2022-11-03 01:07:17,059:INFO: Batch:  4/31	Total Loss 4.2844 (4.2461)
2022-11-03 01:07:17,536:INFO: Batch:  5/31	Total Loss 3.9863 (4.1987)
2022-11-03 01:07:18,007:INFO: Batch:  6/31	Total Loss 3.8295 (4.1468)
2022-11-03 01:07:18,474:INFO: Batch:  7/31	Total Loss 4.9573 (4.2379)
2022-11-03 01:07:18,940:INFO: Batch:  8/31	Total Loss 4.2851 (4.2430)
2022-11-03 01:07:19,407:INFO: Batch:  9/31	Total Loss 4.2297 (4.2415)
2022-11-03 01:07:19,875:INFO: Batch: 10/31	Total Loss 4.4760 (4.2644)
2022-11-03 01:07:20,347:INFO: Batch: 11/31	Total Loss 4.1323 (4.2522)
2022-11-03 01:07:20,819:INFO: Batch: 12/31	Total Loss 4.3554 (4.2593)
2022-11-03 01:07:21,292:INFO: Batch: 13/31	Total Loss 5.0670 (4.3088)
2022-11-03 01:07:21,765:INFO: Batch: 14/31	Total Loss 4.6658 (4.3338)
2022-11-03 01:07:22,239:INFO: Batch: 15/31	Total Loss 4.4835 (4.3429)
2022-11-03 01:07:22,714:INFO: Batch: 16/31	Total Loss 4.7460 (4.3659)
2022-11-03 01:07:23,187:INFO: Batch: 17/31	Total Loss 4.2267 (4.3578)
2022-11-03 01:07:23,660:INFO: Batch: 18/31	Total Loss 3.6906 (4.3257)
2022-11-03 01:07:24,132:INFO: Batch: 19/31	Total Loss 4.7010 (4.3438)
2022-11-03 01:07:24,602:INFO: Batch: 20/31	Total Loss 4.3036 (4.3419)
2022-11-03 01:07:25,073:INFO: Batch: 21/31	Total Loss 3.6740 (4.3121)
2022-11-03 01:07:25,545:INFO: Batch: 22/31	Total Loss 4.0185 (4.3009)
2022-11-03 01:07:26,021:INFO: Batch: 23/31	Total Loss 4.1532 (4.2951)
2022-11-03 01:07:26,492:INFO: Batch: 24/31	Total Loss 4.6844 (4.3101)
2022-11-03 01:07:26,963:INFO: Batch: 25/31	Total Loss 4.2117 (4.3064)
2022-11-03 01:07:27,435:INFO: Batch: 26/31	Total Loss 3.9790 (4.2940)
2022-11-03 01:07:27,908:INFO: Batch: 27/31	Total Loss 5.0223 (4.3201)
2022-11-03 01:07:28,379:INFO: Batch: 28/31	Total Loss 4.1968 (4.3158)
2022-11-03 01:07:28,852:INFO: Batch: 29/31	Total Loss 4.3079 (4.3155)
2022-11-03 01:07:29,242:INFO: Batch: 30/31	Total Loss 1.9620 (4.2943)
2022-11-03 01:07:29,397:INFO: - Computing ADE (validation o)
2022-11-03 01:07:29,983:INFO: 		 ADE on eth                       dataset:	 0.9475678205490112
2022-11-03 01:07:29,983:INFO: Average validation o:	ADE  0.9476	FDE  1.8185
2022-11-03 01:07:29,984:INFO: - Computing ADE (validation)
2022-11-03 01:07:30,266:INFO: 		 ADE on hotel                     dataset:	 0.43637821078300476
2022-11-03 01:07:30,560:INFO: 		 ADE on univ                      dataset:	 0.5537052154541016
2022-11-03 01:07:30,803:INFO: 		 ADE on zara1                     dataset:	 0.4473358690738678
2022-11-03 01:07:31,168:INFO: 		 ADE on zara2                     dataset:	 0.4125002920627594
2022-11-03 01:07:31,168:INFO: Average validation:	ADE  0.4893	FDE  1.0111
2022-11-03 01:07:31,169:INFO: - Computing ADE (training)
2022-11-03 01:07:31,666:INFO: 		 ADE on hotel                     dataset:	 0.46610280871391296
2022-11-03 01:07:32,402:INFO: 		 ADE on univ                      dataset:	 0.5406179428100586
2022-11-03 01:07:32,944:INFO: 		 ADE on zara1                     dataset:	 0.5029647350311279
2022-11-03 01:07:33,690:INFO: 		 ADE on zara2                     dataset:	 0.4197840988636017
2022-11-03 01:07:33,691:INFO: Average training:	ADE  0.5118	FDE  1.0623
2022-11-03 01:07:33,700:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_480.pth.tar
2022-11-03 01:07:33,700:INFO: 
===> EPOCH: 481 (P3)
2022-11-03 01:07:33,700:INFO: - Computing loss (training)
2022-11-03 01:07:34,825:INFO: Batch:  0/31	Total Loss 3.8732 (3.8732)
2022-11-03 01:07:35,309:INFO: Batch:  1/31	Total Loss 4.1350 (4.0148)
2022-11-03 01:07:35,796:INFO: Batch:  2/31	Total Loss 3.7581 (3.9253)
2022-11-03 01:07:36,266:INFO: Batch:  3/31	Total Loss 4.1915 (3.9923)
2022-11-03 01:07:36,734:INFO: Batch:  4/31	Total Loss 4.2689 (4.0442)
2022-11-03 01:07:37,209:INFO: Batch:  5/31	Total Loss 4.1501 (4.0595)
2022-11-03 01:07:37,684:INFO: Batch:  6/31	Total Loss 4.6119 (4.1421)
2022-11-03 01:07:38,156:INFO: Batch:  7/31	Total Loss 3.7508 (4.0909)
2022-11-03 01:07:38,621:INFO: Batch:  8/31	Total Loss 3.9089 (4.0709)
2022-11-03 01:07:39,087:INFO: Batch:  9/31	Total Loss 4.5409 (4.1220)
2022-11-03 01:07:39,556:INFO: Batch: 10/31	Total Loss 3.9850 (4.1099)
2022-11-03 01:07:40,026:INFO: Batch: 11/31	Total Loss 4.2719 (4.1226)
2022-11-03 01:07:40,503:INFO: Batch: 12/31	Total Loss 4.8552 (4.1747)
2022-11-03 01:07:40,975:INFO: Batch: 13/31	Total Loss 4.3553 (4.1881)
2022-11-03 01:07:41,451:INFO: Batch: 14/31	Total Loss 4.5395 (4.2124)
2022-11-03 01:07:41,924:INFO: Batch: 15/31	Total Loss 4.4307 (4.2247)
2022-11-03 01:07:42,397:INFO: Batch: 16/31	Total Loss 4.8356 (4.2640)
2022-11-03 01:07:42,868:INFO: Batch: 17/31	Total Loss 4.1663 (4.2592)
2022-11-03 01:07:43,340:INFO: Batch: 18/31	Total Loss 4.1364 (4.2518)
2022-11-03 01:07:43,812:INFO: Batch: 19/31	Total Loss 4.5317 (4.2648)
2022-11-03 01:07:44,284:INFO: Batch: 20/31	Total Loss 4.5547 (4.2794)
2022-11-03 01:07:44,756:INFO: Batch: 21/31	Total Loss 4.6963 (4.2969)
2022-11-03 01:07:45,228:INFO: Batch: 22/31	Total Loss 3.9848 (4.2835)
2022-11-03 01:07:45,706:INFO: Batch: 23/31	Total Loss 4.4818 (4.2911)
2022-11-03 01:07:46,184:INFO: Batch: 24/31	Total Loss 4.3134 (4.2919)
2022-11-03 01:07:46,654:INFO: Batch: 25/31	Total Loss 4.6535 (4.3051)
2022-11-03 01:07:47,125:INFO: Batch: 26/31	Total Loss 4.5684 (4.3143)
2022-11-03 01:07:47,595:INFO: Batch: 27/31	Total Loss 3.8533 (4.2968)
2022-11-03 01:07:48,065:INFO: Batch: 28/31	Total Loss 4.2025 (4.2934)
2022-11-03 01:07:48,535:INFO: Batch: 29/31	Total Loss 4.1609 (4.2894)
2022-11-03 01:07:48,922:INFO: Batch: 30/31	Total Loss 1.5376 (4.2692)
2022-11-03 01:07:49,078:INFO: - Computing ADE (validation o)
2022-11-03 01:07:49,662:INFO: 		 ADE on eth                       dataset:	 0.9368814826011658
2022-11-03 01:07:49,662:INFO: Average validation o:	ADE  0.9369	FDE  1.8073
2022-11-03 01:07:49,662:INFO: - Computing ADE (validation)
2022-11-03 01:07:49,963:INFO: 		 ADE on hotel                     dataset:	 0.44482627511024475
2022-11-03 01:07:50,243:INFO: 		 ADE on univ                      dataset:	 0.5559386610984802
2022-11-03 01:07:50,489:INFO: 		 ADE on zara1                     dataset:	 0.4167364239692688
2022-11-03 01:07:50,846:INFO: 		 ADE on zara2                     dataset:	 0.4056876301765442
2022-11-03 01:07:50,846:INFO: Average validation:	ADE  0.4866	FDE  1.0094
2022-11-03 01:07:50,847:INFO: - Computing ADE (training)
2022-11-03 01:07:51,306:INFO: 		 ADE on hotel                     dataset:	 0.46665477752685547
2022-11-03 01:07:51,984:INFO: 		 ADE on univ                      dataset:	 0.5435322523117065
2022-11-03 01:07:52,544:INFO: 		 ADE on zara1                     dataset:	 0.4787415862083435
2022-11-03 01:07:53,302:INFO: 		 ADE on zara2                     dataset:	 0.40812352299690247
2022-11-03 01:07:53,302:INFO: Average training:	ADE  0.5100	FDE  1.0616
2022-11-03 01:07:53,310:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_481.pth.tar
2022-11-03 01:07:53,311:INFO: 
===> EPOCH: 482 (P3)
2022-11-03 01:07:53,311:INFO: - Computing loss (training)
2022-11-03 01:07:54,422:INFO: Batch:  0/31	Total Loss 4.4517 (4.4517)
2022-11-03 01:07:54,974:INFO: Batch:  1/31	Total Loss 3.7409 (4.0866)
2022-11-03 01:07:55,448:INFO: Batch:  2/31	Total Loss 4.1938 (4.1180)
2022-11-03 01:07:55,926:INFO: Batch:  3/31	Total Loss 4.0624 (4.1038)
2022-11-03 01:07:56,403:INFO: Batch:  4/31	Total Loss 4.0757 (4.0978)
2022-11-03 01:07:56,883:INFO: Batch:  5/31	Total Loss 4.4144 (4.1498)
2022-11-03 01:07:57,354:INFO: Batch:  6/31	Total Loss 3.8210 (4.1017)
2022-11-03 01:07:57,826:INFO: Batch:  7/31	Total Loss 4.2851 (4.1244)
2022-11-03 01:07:58,293:INFO: Batch:  8/31	Total Loss 4.0566 (4.1171)
2022-11-03 01:07:58,762:INFO: Batch:  9/31	Total Loss 3.9603 (4.1010)
2022-11-03 01:07:59,230:INFO: Batch: 10/31	Total Loss 4.5213 (4.1380)
2022-11-03 01:07:59,699:INFO: Batch: 11/31	Total Loss 4.6787 (4.1774)
2022-11-03 01:08:00,174:INFO: Batch: 12/31	Total Loss 4.4119 (4.1935)
2022-11-03 01:08:00,652:INFO: Batch: 13/31	Total Loss 4.1054 (4.1871)
2022-11-03 01:08:01,124:INFO: Batch: 14/31	Total Loss 3.7914 (4.1601)
2022-11-03 01:08:01,598:INFO: Batch: 15/31	Total Loss 4.8542 (4.2043)
2022-11-03 01:08:02,071:INFO: Batch: 16/31	Total Loss 4.3008 (4.2098)
2022-11-03 01:08:02,542:INFO: Batch: 17/31	Total Loss 5.1932 (4.2683)
2022-11-03 01:08:03,012:INFO: Batch: 18/31	Total Loss 4.1955 (4.2644)
2022-11-03 01:08:03,483:INFO: Batch: 19/31	Total Loss 4.2572 (4.2640)
2022-11-03 01:08:03,953:INFO: Batch: 20/31	Total Loss 4.1615 (4.2589)
2022-11-03 01:08:04,424:INFO: Batch: 21/31	Total Loss 4.6967 (4.2802)
2022-11-03 01:08:04,896:INFO: Batch: 22/31	Total Loss 4.4198 (4.2858)
2022-11-03 01:08:05,369:INFO: Batch: 23/31	Total Loss 4.6605 (4.3023)
2022-11-03 01:08:05,841:INFO: Batch: 24/31	Total Loss 4.0973 (4.2932)
2022-11-03 01:08:06,316:INFO: Batch: 25/31	Total Loss 4.5821 (4.3054)
2022-11-03 01:08:06,789:INFO: Batch: 26/31	Total Loss 4.4339 (4.3101)
2022-11-03 01:08:07,261:INFO: Batch: 27/31	Total Loss 4.0200 (4.2998)
2022-11-03 01:08:07,739:INFO: Batch: 28/31	Total Loss 4.1800 (4.2958)
2022-11-03 01:08:08,212:INFO: Batch: 29/31	Total Loss 4.0188 (4.2871)
2022-11-03 01:08:08,599:INFO: Batch: 30/31	Total Loss 1.7583 (4.2664)
2022-11-03 01:08:08,743:INFO: - Computing ADE (validation o)
2022-11-03 01:08:09,321:INFO: 		 ADE on eth                       dataset:	 0.9374496340751648
2022-11-03 01:08:09,322:INFO: Average validation o:	ADE  0.9374	FDE  1.8394
2022-11-03 01:08:09,322:INFO: - Computing ADE (validation)
2022-11-03 01:08:09,632:INFO: 		 ADE on hotel                     dataset:	 0.44202175736427307
2022-11-03 01:08:09,923:INFO: 		 ADE on univ                      dataset:	 0.5589489936828613
2022-11-03 01:08:10,171:INFO: 		 ADE on zara1                     dataset:	 0.43980270624160767
2022-11-03 01:08:10,512:INFO: 		 ADE on zara2                     dataset:	 0.41489648818969727
2022-11-03 01:08:10,512:INFO: Average validation:	ADE  0.4928	FDE  1.0297
2022-11-03 01:08:10,513:INFO: - Computing ADE (training)
2022-11-03 01:08:10,993:INFO: 		 ADE on hotel                     dataset:	 0.46369925141334534
2022-11-03 01:08:11,670:INFO: 		 ADE on univ                      dataset:	 0.5476208329200745
2022-11-03 01:08:12,196:INFO: 		 ADE on zara1                     dataset:	 0.4777488708496094
2022-11-03 01:08:13,008:INFO: 		 ADE on zara2                     dataset:	 0.4170812964439392
2022-11-03 01:08:13,008:INFO: Average training:	ADE  0.5145	FDE  1.0794
2022-11-03 01:08:13,017:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_482.pth.tar
2022-11-03 01:08:13,017:INFO: 
===> EPOCH: 483 (P3)
2022-11-03 01:08:13,017:INFO: - Computing loss (training)
2022-11-03 01:08:14,111:INFO: Batch:  0/31	Total Loss 4.0965 (4.0965)
2022-11-03 01:08:14,595:INFO: Batch:  1/31	Total Loss 5.0284 (4.5518)
2022-11-03 01:08:15,072:INFO: Batch:  2/31	Total Loss 4.0186 (4.3726)
2022-11-03 01:08:15,542:INFO: Batch:  3/31	Total Loss 4.2830 (4.3509)
2022-11-03 01:08:16,015:INFO: Batch:  4/31	Total Loss 4.0504 (4.2861)
2022-11-03 01:08:16,497:INFO: Batch:  5/31	Total Loss 3.9903 (4.2385)
2022-11-03 01:08:16,973:INFO: Batch:  6/31	Total Loss 4.3147 (4.2499)
2022-11-03 01:08:17,447:INFO: Batch:  7/31	Total Loss 4.2537 (4.2505)
2022-11-03 01:08:17,921:INFO: Batch:  8/31	Total Loss 4.7534 (4.3082)
2022-11-03 01:08:18,395:INFO: Batch:  9/31	Total Loss 4.4694 (4.3239)
2022-11-03 01:08:18,867:INFO: Batch: 10/31	Total Loss 4.2380 (4.3163)
2022-11-03 01:08:19,343:INFO: Batch: 11/31	Total Loss 5.0640 (4.3864)
2022-11-03 01:08:19,824:INFO: Batch: 12/31	Total Loss 4.4076 (4.3879)
2022-11-03 01:08:20,307:INFO: Batch: 13/31	Total Loss 4.2814 (4.3798)
2022-11-03 01:08:20,792:INFO: Batch: 14/31	Total Loss 4.2542 (4.3720)
2022-11-03 01:08:21,272:INFO: Batch: 15/31	Total Loss 7.2892 (4.5494)
2022-11-03 01:08:21,756:INFO: Batch: 16/31	Total Loss 4.0830 (4.5200)
2022-11-03 01:08:22,237:INFO: Batch: 17/31	Total Loss 4.0834 (4.4944)
2022-11-03 01:08:22,719:INFO: Batch: 18/31	Total Loss 4.2597 (4.4824)
2022-11-03 01:08:23,200:INFO: Batch: 19/31	Total Loss 4.4228 (4.4791)
2022-11-03 01:08:23,681:INFO: Batch: 20/31	Total Loss 4.3905 (4.4752)
2022-11-03 01:08:24,162:INFO: Batch: 21/31	Total Loss 4.2273 (4.4636)
2022-11-03 01:08:24,640:INFO: Batch: 22/31	Total Loss 4.4904 (4.4648)
2022-11-03 01:08:25,121:INFO: Batch: 23/31	Total Loss 3.8919 (4.4412)
2022-11-03 01:08:25,601:INFO: Batch: 24/31	Total Loss 4.0512 (4.4264)
2022-11-03 01:08:26,081:INFO: Batch: 25/31	Total Loss 4.2408 (4.4197)
2022-11-03 01:08:26,561:INFO: Batch: 26/31	Total Loss 3.9960 (4.4027)
2022-11-03 01:08:27,041:INFO: Batch: 27/31	Total Loss 4.6637 (4.4121)
2022-11-03 01:08:27,521:INFO: Batch: 28/31	Total Loss 3.9051 (4.3951)
2022-11-03 01:08:28,000:INFO: Batch: 29/31	Total Loss 4.2808 (4.3915)
2022-11-03 01:08:28,394:INFO: Batch: 30/31	Total Loss 1.7122 (4.3616)
2022-11-03 01:08:28,548:INFO: - Computing ADE (validation o)
2022-11-03 01:08:29,127:INFO: 		 ADE on eth                       dataset:	 0.9877265095710754
2022-11-03 01:08:29,128:INFO: Average validation o:	ADE  0.9877	FDE  1.9429
2022-11-03 01:08:29,128:INFO: - Computing ADE (validation)
2022-11-03 01:08:29,419:INFO: 		 ADE on hotel                     dataset:	 0.5516700148582458
2022-11-03 01:08:29,716:INFO: 		 ADE on univ                      dataset:	 0.6261892914772034
2022-11-03 01:08:29,967:INFO: 		 ADE on zara1                     dataset:	 0.46811985969543457
2022-11-03 01:08:30,326:INFO: 		 ADE on zara2                     dataset:	 0.5033866763114929
2022-11-03 01:08:30,326:INFO: Average validation:	ADE  0.5679	FDE  1.2434
2022-11-03 01:08:30,327:INFO: - Computing ADE (training)
2022-11-03 01:08:30,792:INFO: 		 ADE on hotel                     dataset:	 0.5741373300552368
2022-11-03 01:08:31,475:INFO: 		 ADE on univ                      dataset:	 0.6035194993019104
2022-11-03 01:08:32,052:INFO: 		 ADE on zara1                     dataset:	 0.5485848784446716
2022-11-03 01:08:32,795:INFO: 		 ADE on zara2                     dataset:	 0.5074077844619751
2022-11-03 01:08:32,795:INFO: Average training:	ADE  0.5798	FDE  1.2633
2022-11-03 01:08:32,804:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_483.pth.tar
2022-11-03 01:08:32,804:INFO: 
===> EPOCH: 484 (P3)
2022-11-03 01:08:32,804:INFO: - Computing loss (training)
2022-11-03 01:08:33,911:INFO: Batch:  0/31	Total Loss 5.3830 (5.3830)
2022-11-03 01:08:34,383:INFO: Batch:  1/31	Total Loss 4.1919 (4.8356)
2022-11-03 01:08:34,858:INFO: Batch:  2/31	Total Loss 4.3520 (4.6751)
2022-11-03 01:08:35,323:INFO: Batch:  3/31	Total Loss 4.4439 (4.6168)
2022-11-03 01:08:35,799:INFO: Batch:  4/31	Total Loss 4.4129 (4.5771)
2022-11-03 01:08:36,275:INFO: Batch:  5/31	Total Loss 4.2693 (4.5224)
2022-11-03 01:08:36,742:INFO: Batch:  6/31	Total Loss 4.4189 (4.5069)
2022-11-03 01:08:37,206:INFO: Batch:  7/31	Total Loss 5.1850 (4.5915)
2022-11-03 01:08:37,675:INFO: Batch:  8/31	Total Loss 4.3308 (4.5610)
2022-11-03 01:08:38,140:INFO: Batch:  9/31	Total Loss 4.5227 (4.5573)
2022-11-03 01:08:38,607:INFO: Batch: 10/31	Total Loss 4.3397 (4.5387)
2022-11-03 01:08:39,071:INFO: Batch: 11/31	Total Loss 4.5835 (4.5423)
2022-11-03 01:08:39,541:INFO: Batch: 12/31	Total Loss 4.2922 (4.5223)
2022-11-03 01:08:40,010:INFO: Batch: 13/31	Total Loss 4.0638 (4.4876)
2022-11-03 01:08:40,485:INFO: Batch: 14/31	Total Loss 4.6107 (4.4959)
2022-11-03 01:08:40,963:INFO: Batch: 15/31	Total Loss 4.4613 (4.4936)
2022-11-03 01:08:41,442:INFO: Batch: 16/31	Total Loss 3.7139 (4.4457)
2022-11-03 01:08:41,923:INFO: Batch: 17/31	Total Loss 4.4101 (4.4435)
2022-11-03 01:08:42,401:INFO: Batch: 18/31	Total Loss 4.6113 (4.4524)
2022-11-03 01:08:42,879:INFO: Batch: 19/31	Total Loss 3.8172 (4.4176)
2022-11-03 01:08:43,356:INFO: Batch: 20/31	Total Loss 3.9140 (4.3932)
2022-11-03 01:08:43,834:INFO: Batch: 21/31	Total Loss 4.2360 (4.3863)
2022-11-03 01:08:44,313:INFO: Batch: 22/31	Total Loss 4.1651 (4.3752)
2022-11-03 01:08:44,790:INFO: Batch: 23/31	Total Loss 5.1785 (4.4089)
2022-11-03 01:08:45,268:INFO: Batch: 24/31	Total Loss 4.0585 (4.3944)
2022-11-03 01:08:45,748:INFO: Batch: 25/31	Total Loss 4.1998 (4.3865)
2022-11-03 01:08:46,303:INFO: Batch: 26/31	Total Loss 3.7791 (4.3641)
2022-11-03 01:08:46,781:INFO: Batch: 27/31	Total Loss 4.1369 (4.3560)
2022-11-03 01:08:47,260:INFO: Batch: 28/31	Total Loss 4.5941 (4.3641)
2022-11-03 01:08:47,740:INFO: Batch: 29/31	Total Loss 5.0750 (4.3867)
2022-11-03 01:08:48,132:INFO: Batch: 30/31	Total Loss 1.5478 (4.3547)
2022-11-03 01:08:48,285:INFO: - Computing ADE (validation o)
2022-11-03 01:08:48,859:INFO: 		 ADE on eth                       dataset:	 0.9874594211578369
2022-11-03 01:08:48,860:INFO: Average validation o:	ADE  0.9875	FDE  1.8943
2022-11-03 01:08:48,860:INFO: - Computing ADE (validation)
2022-11-03 01:08:49,130:INFO: 		 ADE on hotel                     dataset:	 0.49559497833251953
2022-11-03 01:08:49,418:INFO: 		 ADE on univ                      dataset:	 0.5914369225502014
2022-11-03 01:08:49,725:INFO: 		 ADE on zara1                     dataset:	 0.44483646750450134
2022-11-03 01:08:50,078:INFO: 		 ADE on zara2                     dataset:	 0.47156503796577454
2022-11-03 01:08:50,078:INFO: Average validation:	ADE  0.5337	FDE  1.1338
2022-11-03 01:08:50,079:INFO: - Computing ADE (training)
2022-11-03 01:08:50,536:INFO: 		 ADE on hotel                     dataset:	 0.5171899795532227
2022-11-03 01:08:51,216:INFO: 		 ADE on univ                      dataset:	 0.5706578493118286
2022-11-03 01:08:51,762:INFO: 		 ADE on zara1                     dataset:	 0.5505533218383789
2022-11-03 01:08:52,502:INFO: 		 ADE on zara2                     dataset:	 0.4869549572467804
2022-11-03 01:08:52,502:INFO: Average training:	ADE  0.5510	FDE  1.1702
2022-11-03 01:08:52,511:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_484.pth.tar
2022-11-03 01:08:52,511:INFO: 
===> EPOCH: 485 (P3)
2022-11-03 01:08:52,512:INFO: - Computing loss (training)
2022-11-03 01:08:53,605:INFO: Batch:  0/31	Total Loss 4.2980 (4.2980)
2022-11-03 01:08:54,083:INFO: Batch:  1/31	Total Loss 4.4895 (4.3965)
2022-11-03 01:08:54,560:INFO: Batch:  2/31	Total Loss 4.4311 (4.4089)
2022-11-03 01:08:55,034:INFO: Batch:  3/31	Total Loss 4.2194 (4.3611)
2022-11-03 01:08:55,505:INFO: Batch:  4/31	Total Loss 3.8540 (4.2619)
2022-11-03 01:08:55,982:INFO: Batch:  5/31	Total Loss 3.9150 (4.2021)
2022-11-03 01:08:56,455:INFO: Batch:  6/31	Total Loss 4.7729 (4.2824)
2022-11-03 01:08:56,930:INFO: Batch:  7/31	Total Loss 3.7216 (4.2152)
2022-11-03 01:08:57,402:INFO: Batch:  8/31	Total Loss 5.1452 (4.3183)
2022-11-03 01:08:57,875:INFO: Batch:  9/31	Total Loss 4.3418 (4.3204)
2022-11-03 01:08:58,348:INFO: Batch: 10/31	Total Loss 3.9723 (4.2862)
2022-11-03 01:08:58,822:INFO: Batch: 11/31	Total Loss 4.0976 (4.2708)
2022-11-03 01:08:59,301:INFO: Batch: 12/31	Total Loss 4.1215 (4.2592)
2022-11-03 01:08:59,779:INFO: Batch: 13/31	Total Loss 3.9707 (4.2387)
2022-11-03 01:09:00,259:INFO: Batch: 14/31	Total Loss 4.0527 (4.2256)
2022-11-03 01:09:00,736:INFO: Batch: 15/31	Total Loss 4.3552 (4.2339)
2022-11-03 01:09:01,216:INFO: Batch: 16/31	Total Loss 4.1473 (4.2291)
2022-11-03 01:09:01,692:INFO: Batch: 17/31	Total Loss 4.5746 (4.2493)
2022-11-03 01:09:02,170:INFO: Batch: 18/31	Total Loss 4.3266 (4.2531)
2022-11-03 01:09:02,647:INFO: Batch: 19/31	Total Loss 4.2005 (4.2506)
2022-11-03 01:09:03,122:INFO: Batch: 20/31	Total Loss 4.5751 (4.2659)
2022-11-03 01:09:03,598:INFO: Batch: 21/31	Total Loss 4.2263 (4.2643)
2022-11-03 01:09:04,074:INFO: Batch: 22/31	Total Loss 4.2008 (4.2614)
2022-11-03 01:09:04,549:INFO: Batch: 23/31	Total Loss 5.0630 (4.2954)
2022-11-03 01:09:05,025:INFO: Batch: 24/31	Total Loss 3.9949 (4.2839)
2022-11-03 01:09:05,501:INFO: Batch: 25/31	Total Loss 4.3480 (4.2864)
2022-11-03 01:09:05,977:INFO: Batch: 26/31	Total Loss 4.1588 (4.2818)
2022-11-03 01:09:06,452:INFO: Batch: 27/31	Total Loss 4.8100 (4.3005)
2022-11-03 01:09:06,930:INFO: Batch: 28/31	Total Loss 5.6730 (4.3449)
2022-11-03 01:09:07,405:INFO: Batch: 29/31	Total Loss 4.4891 (4.3499)
2022-11-03 01:09:07,800:INFO: Batch: 30/31	Total Loss 1.5284 (4.3257)
2022-11-03 01:09:07,947:INFO: - Computing ADE (validation o)
2022-11-03 01:09:08,552:INFO: 		 ADE on eth                       dataset:	 0.9646943807601929
2022-11-03 01:09:08,552:INFO: Average validation o:	ADE  0.9647	FDE  1.8590
2022-11-03 01:09:08,553:INFO: - Computing ADE (validation)
2022-11-03 01:09:08,818:INFO: 		 ADE on hotel                     dataset:	 0.447893887758255
2022-11-03 01:09:09,113:INFO: 		 ADE on univ                      dataset:	 0.5515275597572327
2022-11-03 01:09:09,368:INFO: 		 ADE on zara1                     dataset:	 0.4157693088054657
2022-11-03 01:09:09,727:INFO: 		 ADE on zara2                     dataset:	 0.4370323419570923
2022-11-03 01:09:09,727:INFO: Average validation:	ADE  0.4960	FDE  1.0254
2022-11-03 01:09:09,728:INFO: - Computing ADE (training)
2022-11-03 01:09:10,202:INFO: 		 ADE on hotel                     dataset:	 0.4621286690235138
2022-11-03 01:09:10,906:INFO: 		 ADE on univ                      dataset:	 0.5529623627662659
2022-11-03 01:09:11,431:INFO: 		 ADE on zara1                     dataset:	 0.5048922896385193
2022-11-03 01:09:12,183:INFO: 		 ADE on zara2                     dataset:	 0.4423086643218994
2022-11-03 01:09:12,184:INFO: Average training:	ADE  0.5251	FDE  1.0951
2022-11-03 01:09:12,192:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_485.pth.tar
2022-11-03 01:09:12,192:INFO: 
===> EPOCH: 486 (P3)
2022-11-03 01:09:12,193:INFO: - Computing loss (training)
2022-11-03 01:09:13,299:INFO: Batch:  0/31	Total Loss 4.1321 (4.1321)
2022-11-03 01:09:13,773:INFO: Batch:  1/31	Total Loss 4.1894 (4.1615)
2022-11-03 01:09:14,253:INFO: Batch:  2/31	Total Loss 4.2957 (4.2053)
2022-11-03 01:09:14,724:INFO: Batch:  3/31	Total Loss 4.5954 (4.2952)
2022-11-03 01:09:15,201:INFO: Batch:  4/31	Total Loss 4.1769 (4.2684)
2022-11-03 01:09:15,681:INFO: Batch:  5/31	Total Loss 4.0176 (4.2264)
2022-11-03 01:09:16,157:INFO: Batch:  6/31	Total Loss 4.0951 (4.2072)
2022-11-03 01:09:16,630:INFO: Batch:  7/31	Total Loss 4.1600 (4.2015)
2022-11-03 01:09:17,102:INFO: Batch:  8/31	Total Loss 4.1382 (4.1945)
2022-11-03 01:09:17,574:INFO: Batch:  9/31	Total Loss 4.3213 (4.2074)
2022-11-03 01:09:18,045:INFO: Batch: 10/31	Total Loss 4.0857 (4.1962)
2022-11-03 01:09:18,525:INFO: Batch: 11/31	Total Loss 4.1222 (4.1901)
2022-11-03 01:09:19,002:INFO: Batch: 12/31	Total Loss 4.6192 (4.2239)
2022-11-03 01:09:19,486:INFO: Batch: 13/31	Total Loss 4.1861 (4.2213)
2022-11-03 01:09:19,966:INFO: Batch: 14/31	Total Loss 4.7100 (4.2541)
2022-11-03 01:09:20,449:INFO: Batch: 15/31	Total Loss 4.1312 (4.2465)
2022-11-03 01:09:20,929:INFO: Batch: 16/31	Total Loss 5.6877 (4.3386)
2022-11-03 01:09:21,407:INFO: Batch: 17/31	Total Loss 4.3458 (4.3390)
2022-11-03 01:09:21,885:INFO: Batch: 18/31	Total Loss 4.4886 (4.3456)
2022-11-03 01:09:22,363:INFO: Batch: 19/31	Total Loss 4.3345 (4.3450)
2022-11-03 01:09:22,844:INFO: Batch: 20/31	Total Loss 4.4447 (4.3496)
2022-11-03 01:09:23,321:INFO: Batch: 21/31	Total Loss 4.0993 (4.3384)
2022-11-03 01:09:23,799:INFO: Batch: 22/31	Total Loss 4.2246 (4.3338)
2022-11-03 01:09:24,277:INFO: Batch: 23/31	Total Loss 4.1080 (4.3235)
2022-11-03 01:09:24,757:INFO: Batch: 24/31	Total Loss 4.0947 (4.3136)
2022-11-03 01:09:25,232:INFO: Batch: 25/31	Total Loss 3.7243 (4.2883)
2022-11-03 01:09:25,708:INFO: Batch: 26/31	Total Loss 3.9969 (4.2774)
2022-11-03 01:09:26,186:INFO: Batch: 27/31	Total Loss 3.6150 (4.2532)
2022-11-03 01:09:26,660:INFO: Batch: 28/31	Total Loss 5.1897 (4.2845)
2022-11-03 01:09:27,135:INFO: Batch: 29/31	Total Loss 4.1756 (4.2812)
2022-11-03 01:09:27,523:INFO: Batch: 30/31	Total Loss 1.5764 (4.2521)
2022-11-03 01:09:27,666:INFO: - Computing ADE (validation o)
2022-11-03 01:09:28,231:INFO: 		 ADE on eth                       dataset:	 0.9661957621574402
2022-11-03 01:09:28,232:INFO: Average validation o:	ADE  0.9662	FDE  1.8747
2022-11-03 01:09:28,232:INFO: - Computing ADE (validation)
2022-11-03 01:09:28,506:INFO: 		 ADE on hotel                     dataset:	 0.42466169595718384
2022-11-03 01:09:28,798:INFO: 		 ADE on univ                      dataset:	 0.5589615106582642
2022-11-03 01:09:29,047:INFO: 		 ADE on zara1                     dataset:	 0.47323402762413025
2022-11-03 01:09:29,401:INFO: 		 ADE on zara2                     dataset:	 0.42290937900543213
2022-11-03 01:09:29,401:INFO: Average validation:	ADE  0.4967	FDE  1.0331
2022-11-03 01:09:29,402:INFO: - Computing ADE (training)
2022-11-03 01:09:29,843:INFO: 		 ADE on hotel                     dataset:	 0.45330992341041565
2022-11-03 01:09:30,578:INFO: 		 ADE on univ                      dataset:	 0.544903039932251
2022-11-03 01:09:31,117:INFO: 		 ADE on zara1                     dataset:	 0.5254232883453369
2022-11-03 01:09:31,900:INFO: 		 ADE on zara2                     dataset:	 0.4378088712692261
2022-11-03 01:09:31,901:INFO: Average training:	ADE  0.5196	FDE  1.0858
2022-11-03 01:09:31,909:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_486.pth.tar
2022-11-03 01:09:31,909:INFO: 
===> EPOCH: 487 (P3)
2022-11-03 01:09:31,909:INFO: - Computing loss (training)
2022-11-03 01:09:32,988:INFO: Batch:  0/31	Total Loss 3.9015 (3.9015)
2022-11-03 01:09:33,464:INFO: Batch:  1/31	Total Loss 4.4470 (4.1554)
2022-11-03 01:09:33,943:INFO: Batch:  2/31	Total Loss 4.4695 (4.2640)
2022-11-03 01:09:34,422:INFO: Batch:  3/31	Total Loss 4.6589 (4.3541)
2022-11-03 01:09:34,900:INFO: Batch:  4/31	Total Loss 4.4253 (4.3669)
2022-11-03 01:09:35,375:INFO: Batch:  5/31	Total Loss 4.3505 (4.3642)
2022-11-03 01:09:35,849:INFO: Batch:  6/31	Total Loss 3.7014 (4.2659)
2022-11-03 01:09:36,320:INFO: Batch:  7/31	Total Loss 4.4692 (4.2907)
2022-11-03 01:09:36,792:INFO: Batch:  8/31	Total Loss 3.6893 (4.2238)
2022-11-03 01:09:37,266:INFO: Batch:  9/31	Total Loss 4.1080 (4.2122)
2022-11-03 01:09:37,739:INFO: Batch: 10/31	Total Loss 6.1828 (4.3793)
2022-11-03 01:09:38,218:INFO: Batch: 11/31	Total Loss 4.0507 (4.3483)
2022-11-03 01:09:38,697:INFO: Batch: 12/31	Total Loss 3.9173 (4.3143)
2022-11-03 01:09:39,176:INFO: Batch: 13/31	Total Loss 4.1906 (4.3045)
2022-11-03 01:09:39,653:INFO: Batch: 14/31	Total Loss 3.9146 (4.2766)
2022-11-03 01:09:40,130:INFO: Batch: 15/31	Total Loss 4.5855 (4.2923)
2022-11-03 01:09:40,687:INFO: Batch: 16/31	Total Loss 5.1258 (4.3363)
2022-11-03 01:09:41,163:INFO: Batch: 17/31	Total Loss 4.3271 (4.3358)
2022-11-03 01:09:41,641:INFO: Batch: 18/31	Total Loss 4.4264 (4.3404)
2022-11-03 01:09:42,119:INFO: Batch: 19/31	Total Loss 3.8671 (4.3139)
2022-11-03 01:09:42,596:INFO: Batch: 20/31	Total Loss 3.8031 (4.2893)
2022-11-03 01:09:43,080:INFO: Batch: 21/31	Total Loss 3.9508 (4.2760)
2022-11-03 01:09:43,555:INFO: Batch: 22/31	Total Loss 4.2498 (4.2748)
2022-11-03 01:09:44,030:INFO: Batch: 23/31	Total Loss 5.0427 (4.3080)
2022-11-03 01:09:44,517:INFO: Batch: 24/31	Total Loss 4.1305 (4.2999)
2022-11-03 01:09:44,993:INFO: Batch: 25/31	Total Loss 4.3017 (4.3000)
2022-11-03 01:09:45,470:INFO: Batch: 26/31	Total Loss 4.6431 (4.3127)
2022-11-03 01:09:45,947:INFO: Batch: 27/31	Total Loss 4.2607 (4.3109)
2022-11-03 01:09:46,425:INFO: Batch: 28/31	Total Loss 4.2271 (4.3080)
2022-11-03 01:09:46,903:INFO: Batch: 29/31	Total Loss 4.5026 (4.3143)
2022-11-03 01:09:47,297:INFO: Batch: 30/31	Total Loss 1.5309 (4.2869)
2022-11-03 01:09:47,464:INFO: - Computing ADE (validation o)
2022-11-03 01:09:48,082:INFO: 		 ADE on eth                       dataset:	 0.958746612071991
2022-11-03 01:09:48,082:INFO: Average validation o:	ADE  0.9587	FDE  1.8881
2022-11-03 01:09:48,091:INFO: - Computing ADE (validation)
2022-11-03 01:09:48,349:INFO: 		 ADE on hotel                     dataset:	 0.4375647306442261
2022-11-03 01:09:48,642:INFO: 		 ADE on univ                      dataset:	 0.5560473203659058
2022-11-03 01:09:48,895:INFO: 		 ADE on zara1                     dataset:	 0.44294223189353943
2022-11-03 01:09:49,231:INFO: 		 ADE on zara2                     dataset:	 0.43697312474250793
2022-11-03 01:09:49,231:INFO: Average validation:	ADE  0.4993	FDE  1.0415
2022-11-03 01:09:49,232:INFO: - Computing ADE (training)
2022-11-03 01:09:49,660:INFO: 		 ADE on hotel                     dataset:	 0.4620096683502197
2022-11-03 01:09:50,360:INFO: 		 ADE on univ                      dataset:	 0.5550832152366638
2022-11-03 01:09:50,902:INFO: 		 ADE on zara1                     dataset:	 0.49696117639541626
2022-11-03 01:09:51,676:INFO: 		 ADE on zara2                     dataset:	 0.4386231005191803
2022-11-03 01:09:51,676:INFO: Average training:	ADE  0.5254	FDE  1.1045
2022-11-03 01:09:51,685:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_487.pth.tar
2022-11-03 01:09:51,685:INFO: 
===> EPOCH: 488 (P3)
2022-11-03 01:09:51,685:INFO: - Computing loss (training)
2022-11-03 01:09:52,776:INFO: Batch:  0/31	Total Loss 3.7952 (3.7952)
2022-11-03 01:09:53,253:INFO: Batch:  1/31	Total Loss 4.1108 (3.9412)
2022-11-03 01:09:53,727:INFO: Batch:  2/31	Total Loss 4.3580 (4.0819)
2022-11-03 01:09:54,203:INFO: Batch:  3/31	Total Loss 4.1703 (4.1032)
2022-11-03 01:09:54,672:INFO: Batch:  4/31	Total Loss 4.1307 (4.1082)
2022-11-03 01:09:55,148:INFO: Batch:  5/31	Total Loss 4.0376 (4.0962)
2022-11-03 01:09:55,620:INFO: Batch:  6/31	Total Loss 4.3089 (4.1263)
2022-11-03 01:09:56,089:INFO: Batch:  7/31	Total Loss 4.3272 (4.1541)
2022-11-03 01:09:56,560:INFO: Batch:  8/31	Total Loss 4.5132 (4.1967)
2022-11-03 01:09:57,032:INFO: Batch:  9/31	Total Loss 4.9700 (4.2705)
2022-11-03 01:09:57,504:INFO: Batch: 10/31	Total Loss 3.9314 (4.2414)
2022-11-03 01:09:57,977:INFO: Batch: 11/31	Total Loss 4.1365 (4.2334)
2022-11-03 01:09:58,454:INFO: Batch: 12/31	Total Loss 3.8625 (4.2047)
2022-11-03 01:09:58,930:INFO: Batch: 13/31	Total Loss 4.1924 (4.2039)
2022-11-03 01:09:59,406:INFO: Batch: 14/31	Total Loss 4.7656 (4.2395)
2022-11-03 01:09:59,883:INFO: Batch: 15/31	Total Loss 3.4815 (4.1957)
2022-11-03 01:10:00,363:INFO: Batch: 16/31	Total Loss 4.2183 (4.1970)
2022-11-03 01:10:00,843:INFO: Batch: 17/31	Total Loss 3.9153 (4.1822)
2022-11-03 01:10:01,324:INFO: Batch: 18/31	Total Loss 4.0305 (4.1739)
2022-11-03 01:10:01,801:INFO: Batch: 19/31	Total Loss 4.1232 (4.1717)
2022-11-03 01:10:02,277:INFO: Batch: 20/31	Total Loss 4.2248 (4.1743)
2022-11-03 01:10:02,753:INFO: Batch: 21/31	Total Loss 4.6695 (4.1952)
2022-11-03 01:10:03,229:INFO: Batch: 22/31	Total Loss 3.7084 (4.1781)
2022-11-03 01:10:03,704:INFO: Batch: 23/31	Total Loss 4.2721 (4.1817)
2022-11-03 01:10:04,179:INFO: Batch: 24/31	Total Loss 4.2658 (4.1849)
2022-11-03 01:10:04,655:INFO: Batch: 25/31	Total Loss 4.0585 (4.1799)
2022-11-03 01:10:05,129:INFO: Batch: 26/31	Total Loss 5.1813 (4.2109)
2022-11-03 01:10:05,603:INFO: Batch: 27/31	Total Loss 4.2933 (4.2136)
2022-11-03 01:10:06,076:INFO: Batch: 28/31	Total Loss 4.1388 (4.2113)
2022-11-03 01:10:06,551:INFO: Batch: 29/31	Total Loss 5.6082 (4.2578)
2022-11-03 01:10:06,940:INFO: Batch: 30/31	Total Loss 1.2480 (4.2264)
2022-11-03 01:10:07,087:INFO: - Computing ADE (validation o)
2022-11-03 01:10:07,683:INFO: 		 ADE on eth                       dataset:	 0.9550361037254333
2022-11-03 01:10:07,683:INFO: Average validation o:	ADE  0.9550	FDE  1.8663
2022-11-03 01:10:07,684:INFO: - Computing ADE (validation)
2022-11-03 01:10:07,963:INFO: 		 ADE on hotel                     dataset:	 0.4131461977958679
2022-11-03 01:10:08,251:INFO: 		 ADE on univ                      dataset:	 0.5453956127166748
2022-11-03 01:10:08,502:INFO: 		 ADE on zara1                     dataset:	 0.4247005581855774
2022-11-03 01:10:08,845:INFO: 		 ADE on zara2                     dataset:	 0.40617766976356506
2022-11-03 01:10:08,845:INFO: Average validation:	ADE  0.4801	FDE  0.9869
2022-11-03 01:10:08,846:INFO: - Computing ADE (training)
2022-11-03 01:10:09,319:INFO: 		 ADE on hotel                     dataset:	 0.433626264333725
2022-11-03 01:10:09,995:INFO: 		 ADE on univ                      dataset:	 0.5381101965904236
2022-11-03 01:10:10,535:INFO: 		 ADE on zara1                     dataset:	 0.4932899475097656
2022-11-03 01:10:11,258:INFO: 		 ADE on zara2                     dataset:	 0.41523364186286926
2022-11-03 01:10:11,259:INFO: Average training:	ADE  0.5077	FDE  1.0533
2022-11-03 01:10:11,267:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_488.pth.tar
2022-11-03 01:10:11,267:INFO: 
===> EPOCH: 489 (P3)
2022-11-03 01:10:11,267:INFO: - Computing loss (training)
2022-11-03 01:10:12,362:INFO: Batch:  0/31	Total Loss 4.8114 (4.8114)
2022-11-03 01:10:12,839:INFO: Batch:  1/31	Total Loss 4.0938 (4.4563)
2022-11-03 01:10:13,321:INFO: Batch:  2/31	Total Loss 4.8165 (4.5709)
2022-11-03 01:10:13,799:INFO: Batch:  3/31	Total Loss 4.6807 (4.5986)
2022-11-03 01:10:14,274:INFO: Batch:  4/31	Total Loss 4.8404 (4.6431)
2022-11-03 01:10:14,744:INFO: Batch:  5/31	Total Loss 4.7234 (4.6573)
2022-11-03 01:10:15,212:INFO: Batch:  6/31	Total Loss 4.7493 (4.6682)
2022-11-03 01:10:15,676:INFO: Batch:  7/31	Total Loss 3.9534 (4.5723)
2022-11-03 01:10:16,146:INFO: Batch:  8/31	Total Loss 5.5511 (4.6836)
2022-11-03 01:10:16,614:INFO: Batch:  9/31	Total Loss 4.0028 (4.6211)
2022-11-03 01:10:17,081:INFO: Batch: 10/31	Total Loss 4.3010 (4.5929)
2022-11-03 01:10:17,550:INFO: Batch: 11/31	Total Loss 4.0333 (4.5440)
2022-11-03 01:10:18,021:INFO: Batch: 12/31	Total Loss 3.9804 (4.4981)
2022-11-03 01:10:18,493:INFO: Batch: 13/31	Total Loss 4.6780 (4.5103)
2022-11-03 01:10:18,965:INFO: Batch: 14/31	Total Loss 4.5695 (4.5138)
2022-11-03 01:10:19,437:INFO: Batch: 15/31	Total Loss 4.4765 (4.5115)
2022-11-03 01:10:19,907:INFO: Batch: 16/31	Total Loss 4.4911 (4.5102)
2022-11-03 01:10:20,382:INFO: Batch: 17/31	Total Loss 4.2422 (4.4955)
2022-11-03 01:10:20,855:INFO: Batch: 18/31	Total Loss 4.1388 (4.4754)
2022-11-03 01:10:21,324:INFO: Batch: 19/31	Total Loss 4.3501 (4.4687)
2022-11-03 01:10:21,795:INFO: Batch: 20/31	Total Loss 3.6975 (4.4240)
2022-11-03 01:10:22,266:INFO: Batch: 21/31	Total Loss 3.9493 (4.4037)
2022-11-03 01:10:22,738:INFO: Batch: 22/31	Total Loss 4.5938 (4.4110)
2022-11-03 01:10:23,208:INFO: Batch: 23/31	Total Loss 5.2456 (4.4466)
2022-11-03 01:10:23,678:INFO: Batch: 24/31	Total Loss 4.2949 (4.4404)
2022-11-03 01:10:24,149:INFO: Batch: 25/31	Total Loss 3.7275 (4.4136)
2022-11-03 01:10:24,618:INFO: Batch: 26/31	Total Loss 4.4753 (4.4159)
2022-11-03 01:10:25,088:INFO: Batch: 27/31	Total Loss 4.5698 (4.4213)
2022-11-03 01:10:25,559:INFO: Batch: 28/31	Total Loss 4.4809 (4.4235)
2022-11-03 01:10:26,028:INFO: Batch: 29/31	Total Loss 4.2018 (4.4165)
2022-11-03 01:10:26,416:INFO: Batch: 30/31	Total Loss 1.5075 (4.3884)
2022-11-03 01:10:26,564:INFO: - Computing ADE (validation o)
2022-11-03 01:10:27,175:INFO: 		 ADE on eth                       dataset:	 0.947708010673523
2022-11-03 01:10:27,175:INFO: Average validation o:	ADE  0.9477	FDE  1.8355
2022-11-03 01:10:27,176:INFO: - Computing ADE (validation)
2022-11-03 01:10:27,446:INFO: 		 ADE on hotel                     dataset:	 0.4229649603366852
2022-11-03 01:10:27,747:INFO: 		 ADE on univ                      dataset:	 0.5463576316833496
2022-11-03 01:10:27,984:INFO: 		 ADE on zara1                     dataset:	 0.4133458137512207
2022-11-03 01:10:28,336:INFO: 		 ADE on zara2                     dataset:	 0.4103359580039978
2022-11-03 01:10:28,336:INFO: Average validation:	ADE  0.4820	FDE  0.9926
2022-11-03 01:10:28,337:INFO: - Computing ADE (training)
2022-11-03 01:10:28,803:INFO: 		 ADE on hotel                     dataset:	 0.44551658630371094
2022-11-03 01:10:29,509:INFO: 		 ADE on univ                      dataset:	 0.5403997898101807
2022-11-03 01:10:30,066:INFO: 		 ADE on zara1                     dataset:	 0.48569825291633606
2022-11-03 01:10:30,807:INFO: 		 ADE on zara2                     dataset:	 0.4134417176246643
2022-11-03 01:10:30,807:INFO: Average training:	ADE  0.5087	FDE  1.0565
2022-11-03 01:10:30,816:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_489.pth.tar
2022-11-03 01:10:30,816:INFO: 
===> EPOCH: 490 (P3)
2022-11-03 01:10:30,817:INFO: - Computing loss (training)
2022-11-03 01:10:31,897:INFO: Batch:  0/31	Total Loss 3.7840 (3.7840)
2022-11-03 01:10:32,373:INFO: Batch:  1/31	Total Loss 4.1031 (3.9522)
2022-11-03 01:10:32,853:INFO: Batch:  2/31	Total Loss 4.2585 (4.0604)
2022-11-03 01:10:33,326:INFO: Batch:  3/31	Total Loss 4.1209 (4.0751)
2022-11-03 01:10:33,799:INFO: Batch:  4/31	Total Loss 4.4747 (4.1559)
2022-11-03 01:10:34,354:INFO: Batch:  5/31	Total Loss 3.8400 (4.1024)
2022-11-03 01:10:34,830:INFO: Batch:  6/31	Total Loss 4.3515 (4.1395)
2022-11-03 01:10:35,303:INFO: Batch:  7/31	Total Loss 4.3878 (4.1721)
2022-11-03 01:10:35,776:INFO: Batch:  8/31	Total Loss 4.2248 (4.1784)
2022-11-03 01:10:36,247:INFO: Batch:  9/31	Total Loss 3.5701 (4.1152)
2022-11-03 01:10:36,721:INFO: Batch: 10/31	Total Loss 4.5047 (4.1545)
2022-11-03 01:10:37,197:INFO: Batch: 11/31	Total Loss 4.3158 (4.1674)
2022-11-03 01:10:37,676:INFO: Batch: 12/31	Total Loss 4.3342 (4.1793)
2022-11-03 01:10:38,153:INFO: Batch: 13/31	Total Loss 3.9121 (4.1608)
2022-11-03 01:10:38,629:INFO: Batch: 14/31	Total Loss 4.5447 (4.1871)
2022-11-03 01:10:39,106:INFO: Batch: 15/31	Total Loss 4.0423 (4.1776)
2022-11-03 01:10:39,581:INFO: Batch: 16/31	Total Loss 3.7263 (4.1482)
2022-11-03 01:10:40,057:INFO: Batch: 17/31	Total Loss 4.1206 (4.1466)
2022-11-03 01:10:40,540:INFO: Batch: 18/31	Total Loss 4.1496 (4.1467)
2022-11-03 01:10:41,017:INFO: Batch: 19/31	Total Loss 4.4728 (4.1649)
2022-11-03 01:10:41,495:INFO: Batch: 20/31	Total Loss 4.4784 (4.1803)
2022-11-03 01:10:41,973:INFO: Batch: 21/31	Total Loss 4.3657 (4.1888)
2022-11-03 01:10:42,448:INFO: Batch: 22/31	Total Loss 3.9819 (4.1804)
2022-11-03 01:10:42,926:INFO: Batch: 23/31	Total Loss 3.9665 (4.1705)
2022-11-03 01:10:43,401:INFO: Batch: 24/31	Total Loss 4.4020 (4.1791)
2022-11-03 01:10:43,878:INFO: Batch: 25/31	Total Loss 4.5880 (4.1927)
2022-11-03 01:10:44,356:INFO: Batch: 26/31	Total Loss 3.0556 (4.1500)
2022-11-03 01:10:44,834:INFO: Batch: 27/31	Total Loss 3.6853 (4.1317)
2022-11-03 01:10:45,310:INFO: Batch: 28/31	Total Loss 4.6123 (4.1459)
2022-11-03 01:10:45,784:INFO: Batch: 29/31	Total Loss 4.6015 (4.1581)
2022-11-03 01:10:46,173:INFO: Batch: 30/31	Total Loss 1.6806 (4.1355)
2022-11-03 01:10:46,319:INFO: - Computing ADE (validation o)
2022-11-03 01:10:46,932:INFO: 		 ADE on eth                       dataset:	 0.9357680082321167
2022-11-03 01:10:46,933:INFO: Average validation o:	ADE  0.9358	FDE  1.8411
2022-11-03 01:10:46,933:INFO: - Computing ADE (validation)
2022-11-03 01:10:47,233:INFO: 		 ADE on hotel                     dataset:	 0.4400927722454071
2022-11-03 01:10:47,540:INFO: 		 ADE on univ                      dataset:	 0.5642057657241821
2022-11-03 01:10:47,819:INFO: 		 ADE on zara1                     dataset:	 0.44927629828453064
2022-11-03 01:10:48,202:INFO: 		 ADE on zara2                     dataset:	 0.4185173213481903
2022-11-03 01:10:48,202:INFO: Average validation:	ADE  0.4973	FDE  1.0495
2022-11-03 01:10:48,203:INFO: - Computing ADE (training)
2022-11-03 01:10:48,659:INFO: 		 ADE on hotel                     dataset:	 0.45445942878723145
2022-11-03 01:10:49,354:INFO: 		 ADE on univ                      dataset:	 0.5485413670539856
2022-11-03 01:10:49,941:INFO: 		 ADE on zara1                     dataset:	 0.4833660125732422
2022-11-03 01:10:50,756:INFO: 		 ADE on zara2                     dataset:	 0.4216345250606537
2022-11-03 01:10:50,756:INFO: Average training:	ADE  0.5162	FDE  1.0913
2022-11-03 01:10:50,765:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_490.pth.tar
2022-11-03 01:10:50,765:INFO: 
===> EPOCH: 491 (P3)
2022-11-03 01:10:50,765:INFO: - Computing loss (training)
2022-11-03 01:10:51,870:INFO: Batch:  0/31	Total Loss 4.8256 (4.8256)
2022-11-03 01:10:52,339:INFO: Batch:  1/31	Total Loss 4.5072 (4.6564)
2022-11-03 01:10:52,822:INFO: Batch:  2/31	Total Loss 4.5043 (4.6110)
2022-11-03 01:10:53,291:INFO: Batch:  3/31	Total Loss 4.4729 (4.5717)
2022-11-03 01:10:53,764:INFO: Batch:  4/31	Total Loss 4.3528 (4.5283)
2022-11-03 01:10:54,237:INFO: Batch:  5/31	Total Loss 4.4266 (4.5090)
2022-11-03 01:10:54,706:INFO: Batch:  6/31	Total Loss 4.5519 (4.5149)
2022-11-03 01:10:55,176:INFO: Batch:  7/31	Total Loss 4.2357 (4.4761)
2022-11-03 01:10:55,646:INFO: Batch:  8/31	Total Loss 4.1750 (4.4440)
2022-11-03 01:10:56,113:INFO: Batch:  9/31	Total Loss 4.5739 (4.4571)
2022-11-03 01:10:56,586:INFO: Batch: 10/31	Total Loss 4.1439 (4.4253)
2022-11-03 01:10:57,058:INFO: Batch: 11/31	Total Loss 4.5482 (4.4362)
2022-11-03 01:10:57,533:INFO: Batch: 12/31	Total Loss 4.3099 (4.4279)
2022-11-03 01:10:58,007:INFO: Batch: 13/31	Total Loss 5.5494 (4.5133)
2022-11-03 01:10:58,483:INFO: Batch: 14/31	Total Loss 4.4239 (4.5069)
2022-11-03 01:10:58,958:INFO: Batch: 15/31	Total Loss 4.6691 (4.5172)
2022-11-03 01:10:59,434:INFO: Batch: 16/31	Total Loss 4.3842 (4.5091)
2022-11-03 01:10:59,909:INFO: Batch: 17/31	Total Loss 4.5400 (4.5107)
2022-11-03 01:11:00,393:INFO: Batch: 18/31	Total Loss 4.2163 (4.4955)
2022-11-03 01:11:00,870:INFO: Batch: 19/31	Total Loss 4.3018 (4.4847)
2022-11-03 01:11:01,345:INFO: Batch: 20/31	Total Loss 4.2479 (4.4740)
2022-11-03 01:11:01,824:INFO: Batch: 21/31	Total Loss 4.6335 (4.4814)
2022-11-03 01:11:02,298:INFO: Batch: 22/31	Total Loss 3.9619 (4.4555)
2022-11-03 01:11:02,773:INFO: Batch: 23/31	Total Loss 4.4070 (4.4535)
2022-11-03 01:11:03,247:INFO: Batch: 24/31	Total Loss 4.7189 (4.4643)
2022-11-03 01:11:03,720:INFO: Batch: 25/31	Total Loss 4.2238 (4.4543)
2022-11-03 01:11:04,194:INFO: Batch: 26/31	Total Loss 4.2815 (4.4483)
2022-11-03 01:11:04,667:INFO: Batch: 27/31	Total Loss 4.2072 (4.4395)
2022-11-03 01:11:05,141:INFO: Batch: 28/31	Total Loss 4.6367 (4.4467)
2022-11-03 01:11:05,615:INFO: Batch: 29/31	Total Loss 4.1360 (4.4355)
2022-11-03 01:11:06,004:INFO: Batch: 30/31	Total Loss 1.5620 (4.4024)
2022-11-03 01:11:06,159:INFO: - Computing ADE (validation o)
2022-11-03 01:11:06,756:INFO: 		 ADE on eth                       dataset:	 0.9676783084869385
2022-11-03 01:11:06,756:INFO: Average validation o:	ADE  0.9677	FDE  1.9183
2022-11-03 01:11:06,757:INFO: - Computing ADE (validation)
2022-11-03 01:11:07,026:INFO: 		 ADE on hotel                     dataset:	 0.48005419969558716
2022-11-03 01:11:07,310:INFO: 		 ADE on univ                      dataset:	 0.5618302822113037
2022-11-03 01:11:07,569:INFO: 		 ADE on zara1                     dataset:	 0.41437360644340515
2022-11-03 01:11:07,915:INFO: 		 ADE on zara2                     dataset:	 0.4474755823612213
2022-11-03 01:11:07,915:INFO: Average validation:	ADE  0.5068	FDE  1.0548
2022-11-03 01:11:07,916:INFO: - Computing ADE (training)
2022-11-03 01:11:08,345:INFO: 		 ADE on hotel                     dataset:	 0.49752077460289
2022-11-03 01:11:09,028:INFO: 		 ADE on univ                      dataset:	 0.5644963979721069
2022-11-03 01:11:09,576:INFO: 		 ADE on zara1                     dataset:	 0.49578365683555603
2022-11-03 01:11:10,332:INFO: 		 ADE on zara2                     dataset:	 0.44703221321105957
2022-11-03 01:11:10,332:INFO: Average training:	ADE  0.5346	FDE  1.1201
2022-11-03 01:11:10,341:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_491.pth.tar
2022-11-03 01:11:10,341:INFO: 
===> EPOCH: 492 (P3)
2022-11-03 01:11:10,342:INFO: - Computing loss (training)
2022-11-03 01:11:11,436:INFO: Batch:  0/31	Total Loss 3.7238 (3.7238)
2022-11-03 01:11:11,913:INFO: Batch:  1/31	Total Loss 4.0331 (3.8919)
2022-11-03 01:11:12,393:INFO: Batch:  2/31	Total Loss 4.4140 (4.0580)
2022-11-03 01:11:12,864:INFO: Batch:  3/31	Total Loss 4.6055 (4.1953)
2022-11-03 01:11:13,333:INFO: Batch:  4/31	Total Loss 3.9739 (4.1548)
2022-11-03 01:11:13,806:INFO: Batch:  5/31	Total Loss 4.5201 (4.2201)
2022-11-03 01:11:14,279:INFO: Batch:  6/31	Total Loss 4.4500 (4.2526)
2022-11-03 01:11:14,752:INFO: Batch:  7/31	Total Loss 4.3153 (4.2600)
2022-11-03 01:11:15,225:INFO: Batch:  8/31	Total Loss 4.1860 (4.2521)
2022-11-03 01:11:15,694:INFO: Batch:  9/31	Total Loss 4.2886 (4.2562)
2022-11-03 01:11:16,167:INFO: Batch: 10/31	Total Loss 4.2115 (4.2520)
2022-11-03 01:11:16,639:INFO: Batch: 11/31	Total Loss 3.9856 (4.2321)
2022-11-03 01:11:17,114:INFO: Batch: 12/31	Total Loss 3.9452 (4.2073)
2022-11-03 01:11:17,588:INFO: Batch: 13/31	Total Loss 4.6551 (4.2363)
2022-11-03 01:11:18,064:INFO: Batch: 14/31	Total Loss 4.2531 (4.2375)
2022-11-03 01:11:18,540:INFO: Batch: 15/31	Total Loss 4.3647 (4.2458)
2022-11-03 01:11:19,015:INFO: Batch: 16/31	Total Loss 3.5409 (4.2073)
2022-11-03 01:11:19,491:INFO: Batch: 17/31	Total Loss 4.2994 (4.2127)
2022-11-03 01:11:19,966:INFO: Batch: 18/31	Total Loss 4.1553 (4.2097)
2022-11-03 01:11:20,444:INFO: Batch: 19/31	Total Loss 4.1142 (4.2047)
2022-11-03 01:11:20,922:INFO: Batch: 20/31	Total Loss 4.1318 (4.2011)
2022-11-03 01:11:21,402:INFO: Batch: 21/31	Total Loss 4.6048 (4.2179)
2022-11-03 01:11:21,877:INFO: Batch: 22/31	Total Loss 3.9351 (4.2044)
2022-11-03 01:11:22,350:INFO: Batch: 23/31	Total Loss 3.9823 (4.1952)
2022-11-03 01:11:22,901:INFO: Batch: 24/31	Total Loss 4.0091 (4.1875)
2022-11-03 01:11:23,375:INFO: Batch: 25/31	Total Loss 4.2586 (4.1903)
2022-11-03 01:11:23,851:INFO: Batch: 26/31	Total Loss 4.3504 (4.1963)
2022-11-03 01:11:24,326:INFO: Batch: 27/31	Total Loss 4.0461 (4.1908)
2022-11-03 01:11:24,800:INFO: Batch: 28/31	Total Loss 3.8721 (4.1815)
2022-11-03 01:11:25,274:INFO: Batch: 29/31	Total Loss 4.1851 (4.1816)
2022-11-03 01:11:25,664:INFO: Batch: 30/31	Total Loss 1.6565 (4.1583)
2022-11-03 01:11:25,815:INFO: - Computing ADE (validation o)
2022-11-03 01:11:26,407:INFO: 		 ADE on eth                       dataset:	 0.9600513577461243
2022-11-03 01:11:26,407:INFO: Average validation o:	ADE  0.9601	FDE  1.8955
2022-11-03 01:11:26,408:INFO: - Computing ADE (validation)
2022-11-03 01:11:26,666:INFO: 		 ADE on hotel                     dataset:	 0.43377870321273804
2022-11-03 01:11:26,967:INFO: 		 ADE on univ                      dataset:	 0.5554984211921692
2022-11-03 01:11:27,219:INFO: 		 ADE on zara1                     dataset:	 0.4535588026046753
2022-11-03 01:11:27,565:INFO: 		 ADE on zara2                     dataset:	 0.43839624524116516
2022-11-03 01:11:27,565:INFO: Average validation:	ADE  0.5000	FDE  1.0515
2022-11-03 01:11:27,566:INFO: - Computing ADE (training)
2022-11-03 01:11:28,076:INFO: 		 ADE on hotel                     dataset:	 0.44944846630096436
2022-11-03 01:11:28,761:INFO: 		 ADE on univ                      dataset:	 0.5553268790245056
2022-11-03 01:11:29,306:INFO: 		 ADE on zara1                     dataset:	 0.49681735038757324
2022-11-03 01:11:30,068:INFO: 		 ADE on zara2                     dataset:	 0.4420711398124695
2022-11-03 01:11:30,069:INFO: Average training:	ADE  0.5259	FDE  1.1142
2022-11-03 01:11:30,078:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_492.pth.tar
2022-11-03 01:11:30,078:INFO: 
===> EPOCH: 493 (P3)
2022-11-03 01:11:30,079:INFO: - Computing loss (training)
2022-11-03 01:11:31,189:INFO: Batch:  0/31	Total Loss 4.8331 (4.8331)
2022-11-03 01:11:31,656:INFO: Batch:  1/31	Total Loss 4.1152 (4.4367)
2022-11-03 01:11:32,127:INFO: Batch:  2/31	Total Loss 4.1608 (4.3533)
2022-11-03 01:11:32,600:INFO: Batch:  3/31	Total Loss 4.4707 (4.3849)
2022-11-03 01:11:33,071:INFO: Batch:  4/31	Total Loss 4.1565 (4.3328)
2022-11-03 01:11:33,537:INFO: Batch:  5/31	Total Loss 4.3643 (4.3378)
2022-11-03 01:11:34,003:INFO: Batch:  6/31	Total Loss 4.1503 (4.3109)
2022-11-03 01:11:34,473:INFO: Batch:  7/31	Total Loss 3.7128 (4.2257)
2022-11-03 01:11:34,942:INFO: Batch:  8/31	Total Loss 4.5163 (4.2572)
2022-11-03 01:11:35,411:INFO: Batch:  9/31	Total Loss 4.3289 (4.2642)
2022-11-03 01:11:35,883:INFO: Batch: 10/31	Total Loss 4.1832 (4.2566)
2022-11-03 01:11:36,349:INFO: Batch: 11/31	Total Loss 4.1424 (4.2465)
2022-11-03 01:11:36,821:INFO: Batch: 12/31	Total Loss 3.9854 (4.2255)
2022-11-03 01:11:37,292:INFO: Batch: 13/31	Total Loss 5.0014 (4.2787)
2022-11-03 01:11:37,766:INFO: Batch: 14/31	Total Loss 3.8760 (4.2518)
2022-11-03 01:11:38,238:INFO: Batch: 15/31	Total Loss 4.8475 (4.2873)
2022-11-03 01:11:38,709:INFO: Batch: 16/31	Total Loss 4.2460 (4.2850)
2022-11-03 01:11:39,181:INFO: Batch: 17/31	Total Loss 4.5031 (4.2979)
2022-11-03 01:11:39,653:INFO: Batch: 18/31	Total Loss 3.9415 (4.2791)
2022-11-03 01:11:40,123:INFO: Batch: 19/31	Total Loss 4.5956 (4.2944)
2022-11-03 01:11:40,598:INFO: Batch: 20/31	Total Loss 4.2784 (4.2937)
2022-11-03 01:11:41,068:INFO: Batch: 21/31	Total Loss 4.5937 (4.3077)
2022-11-03 01:11:41,540:INFO: Batch: 22/31	Total Loss 5.4667 (4.3614)
2022-11-03 01:11:42,014:INFO: Batch: 23/31	Total Loss 3.8418 (4.3393)
2022-11-03 01:11:42,485:INFO: Batch: 24/31	Total Loss 4.9309 (4.3627)
2022-11-03 01:11:42,955:INFO: Batch: 25/31	Total Loss 3.5371 (4.3287)
2022-11-03 01:11:43,426:INFO: Batch: 26/31	Total Loss 4.3694 (4.3302)
2022-11-03 01:11:43,899:INFO: Batch: 27/31	Total Loss 4.2858 (4.3287)
2022-11-03 01:11:44,369:INFO: Batch: 28/31	Total Loss 5.0093 (4.3542)
2022-11-03 01:11:44,840:INFO: Batch: 29/31	Total Loss 5.2417 (4.3879)
2022-11-03 01:11:45,227:INFO: Batch: 30/31	Total Loss 1.9869 (4.3669)
2022-11-03 01:11:45,388:INFO: - Computing ADE (validation o)
2022-11-03 01:11:45,975:INFO: 		 ADE on eth                       dataset:	 1.0136793851852417
2022-11-03 01:11:45,976:INFO: Average validation o:	ADE  1.0137	FDE  2.0312
2022-11-03 01:11:45,976:INFO: - Computing ADE (validation)
2022-11-03 01:11:46,277:INFO: 		 ADE on hotel                     dataset:	 0.48355913162231445
2022-11-03 01:11:46,584:INFO: 		 ADE on univ                      dataset:	 0.5865257382392883
2022-11-03 01:11:46,836:INFO: 		 ADE on zara1                     dataset:	 0.521509051322937
2022-11-03 01:11:47,172:INFO: 		 ADE on zara2                     dataset:	 0.49914953112602234
2022-11-03 01:11:47,172:INFO: Average validation:	ADE  0.5451	FDE  1.1599
2022-11-03 01:11:47,173:INFO: - Computing ADE (training)
2022-11-03 01:11:47,618:INFO: 		 ADE on hotel                     dataset:	 0.5037540793418884
2022-11-03 01:11:48,325:INFO: 		 ADE on univ                      dataset:	 0.5944040417671204
2022-11-03 01:11:48,895:INFO: 		 ADE on zara1                     dataset:	 0.5620710849761963
2022-11-03 01:11:49,640:INFO: 		 ADE on zara2                     dataset:	 0.5076504945755005
2022-11-03 01:11:49,640:INFO: Average training:	ADE  0.5724	FDE  1.2275
2022-11-03 01:11:49,649:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_493.pth.tar
2022-11-03 01:11:49,649:INFO: 
===> EPOCH: 494 (P3)
2022-11-03 01:11:49,649:INFO: - Computing loss (training)
2022-11-03 01:11:50,735:INFO: Batch:  0/31	Total Loss 4.3858 (4.3858)
2022-11-03 01:11:51,213:INFO: Batch:  1/31	Total Loss 4.3008 (4.3455)
2022-11-03 01:11:51,683:INFO: Batch:  2/31	Total Loss 4.3080 (4.3329)
2022-11-03 01:11:52,162:INFO: Batch:  3/31	Total Loss 4.4332 (4.3571)
2022-11-03 01:11:52,626:INFO: Batch:  4/31	Total Loss 4.1605 (4.3182)
2022-11-03 01:11:53,096:INFO: Batch:  5/31	Total Loss 3.8235 (4.2339)
2022-11-03 01:11:53,566:INFO: Batch:  6/31	Total Loss 4.5756 (4.2798)
2022-11-03 01:11:54,030:INFO: Batch:  7/31	Total Loss 5.1056 (4.3953)
2022-11-03 01:11:54,496:INFO: Batch:  8/31	Total Loss 4.0481 (4.3596)
2022-11-03 01:11:54,962:INFO: Batch:  9/31	Total Loss 4.8182 (4.4048)
2022-11-03 01:11:55,426:INFO: Batch: 10/31	Total Loss 3.7775 (4.3465)
2022-11-03 01:11:55,895:INFO: Batch: 11/31	Total Loss 4.1738 (4.3334)
2022-11-03 01:11:56,367:INFO: Batch: 12/31	Total Loss 3.8752 (4.2991)
2022-11-03 01:11:56,839:INFO: Batch: 13/31	Total Loss 4.3352 (4.3017)
2022-11-03 01:11:57,310:INFO: Batch: 14/31	Total Loss 3.6898 (4.2564)
2022-11-03 01:11:57,779:INFO: Batch: 15/31	Total Loss 3.9532 (4.2369)
2022-11-03 01:11:58,250:INFO: Batch: 16/31	Total Loss 3.2381 (4.1724)
2022-11-03 01:11:58,717:INFO: Batch: 17/31	Total Loss 5.0455 (4.2145)
2022-11-03 01:11:59,187:INFO: Batch: 18/31	Total Loss 4.0458 (4.2055)
2022-11-03 01:11:59,656:INFO: Batch: 19/31	Total Loss 4.2136 (4.2060)
2022-11-03 01:12:00,127:INFO: Batch: 20/31	Total Loss 4.4008 (4.2160)
2022-11-03 01:12:00,596:INFO: Batch: 21/31	Total Loss 4.2792 (4.2192)
2022-11-03 01:12:01,069:INFO: Batch: 22/31	Total Loss 3.9886 (4.2094)
2022-11-03 01:12:01,540:INFO: Batch: 23/31	Total Loss 3.8762 (4.1952)
2022-11-03 01:12:02,011:INFO: Batch: 24/31	Total Loss 4.6767 (4.2124)
2022-11-03 01:12:02,481:INFO: Batch: 25/31	Total Loss 4.1786 (4.2111)
2022-11-03 01:12:02,952:INFO: Batch: 26/31	Total Loss 4.6613 (4.2303)
2022-11-03 01:12:03,420:INFO: Batch: 27/31	Total Loss 4.2639 (4.2315)
2022-11-03 01:12:03,889:INFO: Batch: 28/31	Total Loss 4.3201 (4.2342)
2022-11-03 01:12:04,358:INFO: Batch: 29/31	Total Loss 4.0743 (4.2294)
2022-11-03 01:12:04,745:INFO: Batch: 30/31	Total Loss 1.5849 (4.2026)
2022-11-03 01:12:04,903:INFO: - Computing ADE (validation o)
2022-11-03 01:12:05,482:INFO: 		 ADE on eth                       dataset:	 0.9649183750152588
2022-11-03 01:12:05,482:INFO: Average validation o:	ADE  0.9649	FDE  1.9136
2022-11-03 01:12:05,483:INFO: - Computing ADE (validation)
2022-11-03 01:12:05,752:INFO: 		 ADE on hotel                     dataset:	 0.4470745325088501
2022-11-03 01:12:06,052:INFO: 		 ADE on univ                      dataset:	 0.5544901490211487
2022-11-03 01:12:06,302:INFO: 		 ADE on zara1                     dataset:	 0.4270118474960327
2022-11-03 01:12:06,663:INFO: 		 ADE on zara2                     dataset:	 0.43899163603782654
2022-11-03 01:12:06,663:INFO: Average validation:	ADE  0.4988	FDE  1.0428
2022-11-03 01:12:06,664:INFO: - Computing ADE (training)
2022-11-03 01:12:07,099:INFO: 		 ADE on hotel                     dataset:	 0.4624658524990082
2022-11-03 01:12:07,788:INFO: 		 ADE on univ                      dataset:	 0.5570785999298096
2022-11-03 01:12:08,336:INFO: 		 ADE on zara1                     dataset:	 0.4959772229194641
2022-11-03 01:12:09,066:INFO: 		 ADE on zara2                     dataset:	 0.44246265292167664
2022-11-03 01:12:09,066:INFO: Average training:	ADE  0.5275	FDE  1.1121
2022-11-03 01:12:09,074:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_494.pth.tar
2022-11-03 01:12:09,074:INFO: 
===> EPOCH: 495 (P3)
2022-11-03 01:12:09,075:INFO: - Computing loss (training)
2022-11-03 01:12:10,184:INFO: Batch:  0/31	Total Loss 4.0890 (4.0890)
2022-11-03 01:12:10,653:INFO: Batch:  1/31	Total Loss 4.9205 (4.5280)
2022-11-03 01:12:11,131:INFO: Batch:  2/31	Total Loss 4.2622 (4.4411)
2022-11-03 01:12:11,600:INFO: Batch:  3/31	Total Loss 4.3592 (4.4211)
2022-11-03 01:12:12,066:INFO: Batch:  4/31	Total Loss 3.9441 (4.3226)
2022-11-03 01:12:12,533:INFO: Batch:  5/31	Total Loss 3.9623 (4.2668)
2022-11-03 01:12:12,999:INFO: Batch:  6/31	Total Loss 4.1343 (4.2462)
2022-11-03 01:12:13,466:INFO: Batch:  7/31	Total Loss 3.8409 (4.1892)
2022-11-03 01:12:13,934:INFO: Batch:  8/31	Total Loss 3.8130 (4.1449)
2022-11-03 01:12:14,402:INFO: Batch:  9/31	Total Loss 4.3783 (4.1684)
2022-11-03 01:12:14,871:INFO: Batch: 10/31	Total Loss 3.9991 (4.1534)
2022-11-03 01:12:15,338:INFO: Batch: 11/31	Total Loss 4.0785 (4.1461)
2022-11-03 01:12:15,811:INFO: Batch: 12/31	Total Loss 4.5452 (4.1755)
2022-11-03 01:12:16,358:INFO: Batch: 13/31	Total Loss 4.1983 (4.1773)
2022-11-03 01:12:16,829:INFO: Batch: 14/31	Total Loss 4.6050 (4.2060)
2022-11-03 01:12:17,301:INFO: Batch: 15/31	Total Loss 3.9075 (4.1884)
2022-11-03 01:12:17,771:INFO: Batch: 16/31	Total Loss 4.2258 (4.1904)
2022-11-03 01:12:18,242:INFO: Batch: 17/31	Total Loss 4.3613 (4.1992)
2022-11-03 01:12:18,713:INFO: Batch: 18/31	Total Loss 3.9052 (4.1829)
2022-11-03 01:12:19,183:INFO: Batch: 19/31	Total Loss 4.6271 (4.2045)
2022-11-03 01:12:19,651:INFO: Batch: 20/31	Total Loss 3.5756 (4.1765)
2022-11-03 01:12:20,120:INFO: Batch: 21/31	Total Loss 4.1718 (4.1763)
2022-11-03 01:12:20,595:INFO: Batch: 22/31	Total Loss 4.4665 (4.1906)
2022-11-03 01:12:21,064:INFO: Batch: 23/31	Total Loss 3.9024 (4.1777)
2022-11-03 01:12:21,534:INFO: Batch: 24/31	Total Loss 4.4639 (4.1881)
2022-11-03 01:12:22,005:INFO: Batch: 25/31	Total Loss 4.3440 (4.1932)
2022-11-03 01:12:22,474:INFO: Batch: 26/31	Total Loss 4.2888 (4.1974)
2022-11-03 01:12:22,947:INFO: Batch: 27/31	Total Loss 4.0325 (4.1905)
2022-11-03 01:12:23,415:INFO: Batch: 28/31	Total Loss 4.3612 (4.1968)
2022-11-03 01:12:23,887:INFO: Batch: 29/31	Total Loss 4.2849 (4.1996)
2022-11-03 01:12:24,273:INFO: Batch: 30/31	Total Loss 1.4694 (4.1700)
2022-11-03 01:12:24,427:INFO: - Computing ADE (validation o)
2022-11-03 01:12:25,054:INFO: 		 ADE on eth                       dataset:	 0.9410005211830139
2022-11-03 01:12:25,054:INFO: Average validation o:	ADE  0.9410	FDE  1.8422
2022-11-03 01:12:25,055:INFO: - Computing ADE (validation)
2022-11-03 01:12:25,335:INFO: 		 ADE on hotel                     dataset:	 0.44523948431015015
2022-11-03 01:12:25,622:INFO: 		 ADE on univ                      dataset:	 0.5718725323677063
2022-11-03 01:12:25,880:INFO: 		 ADE on zara1                     dataset:	 0.4640837013721466
2022-11-03 01:12:26,245:INFO: 		 ADE on zara2                     dataset:	 0.4198945164680481
2022-11-03 01:12:26,245:INFO: Average validation:	ADE  0.5029	FDE  1.0611
2022-11-03 01:12:26,246:INFO: - Computing ADE (training)
2022-11-03 01:12:26,730:INFO: 		 ADE on hotel                     dataset:	 0.4794358015060425
2022-11-03 01:12:27,421:INFO: 		 ADE on univ                      dataset:	 0.5509228706359863
2022-11-03 01:12:27,943:INFO: 		 ADE on zara1                     dataset:	 0.4965786635875702
2022-11-03 01:12:28,723:INFO: 		 ADE on zara2                     dataset:	 0.42677512764930725
2022-11-03 01:12:28,723:INFO: Average training:	ADE  0.5204	FDE  1.0974
2022-11-03 01:12:28,732:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_495.pth.tar
2022-11-03 01:12:28,732:INFO: 
===> EPOCH: 496 (P3)
2022-11-03 01:12:28,732:INFO: - Computing loss (training)
2022-11-03 01:12:29,814:INFO: Batch:  0/31	Total Loss 4.9381 (4.9381)
2022-11-03 01:12:30,296:INFO: Batch:  1/31	Total Loss 4.1348 (4.5473)
2022-11-03 01:12:30,772:INFO: Batch:  2/31	Total Loss 4.8191 (4.6410)
2022-11-03 01:12:31,246:INFO: Batch:  3/31	Total Loss 4.4035 (4.5837)
2022-11-03 01:12:31,718:INFO: Batch:  4/31	Total Loss 4.0390 (4.4638)
2022-11-03 01:12:32,190:INFO: Batch:  5/31	Total Loss 3.9951 (4.3836)
2022-11-03 01:12:32,662:INFO: Batch:  6/31	Total Loss 4.6103 (4.4158)
2022-11-03 01:12:33,132:INFO: Batch:  7/31	Total Loss 3.8067 (4.3386)
2022-11-03 01:12:33,602:INFO: Batch:  8/31	Total Loss 3.9088 (4.2829)
2022-11-03 01:12:34,072:INFO: Batch:  9/31	Total Loss 4.2386 (4.2789)
2022-11-03 01:12:34,547:INFO: Batch: 10/31	Total Loss 4.7108 (4.3180)
2022-11-03 01:12:35,018:INFO: Batch: 11/31	Total Loss 4.2406 (4.3112)
2022-11-03 01:12:35,494:INFO: Batch: 12/31	Total Loss 3.8954 (4.2824)
2022-11-03 01:12:35,968:INFO: Batch: 13/31	Total Loss 4.2632 (4.2811)
2022-11-03 01:12:36,442:INFO: Batch: 14/31	Total Loss 4.1549 (4.2729)
2022-11-03 01:12:36,917:INFO: Batch: 15/31	Total Loss 4.5624 (4.2935)
2022-11-03 01:12:37,393:INFO: Batch: 16/31	Total Loss 4.4650 (4.3049)
2022-11-03 01:12:37,870:INFO: Batch: 17/31	Total Loss 3.9518 (4.2844)
2022-11-03 01:12:38,346:INFO: Batch: 18/31	Total Loss 4.3537 (4.2879)
2022-11-03 01:12:38,821:INFO: Batch: 19/31	Total Loss 4.3633 (4.2917)
2022-11-03 01:12:39,296:INFO: Batch: 20/31	Total Loss 3.9839 (4.2779)
2022-11-03 01:12:39,769:INFO: Batch: 21/31	Total Loss 4.3740 (4.2821)
2022-11-03 01:12:40,243:INFO: Batch: 22/31	Total Loss 4.9203 (4.3096)
2022-11-03 01:12:40,718:INFO: Batch: 23/31	Total Loss 3.8435 (4.2902)
2022-11-03 01:12:41,191:INFO: Batch: 24/31	Total Loss 4.4225 (4.2956)
2022-11-03 01:12:41,663:INFO: Batch: 25/31	Total Loss 4.1376 (4.2896)
2022-11-03 01:12:42,138:INFO: Batch: 26/31	Total Loss 4.6391 (4.3026)
2022-11-03 01:12:42,611:INFO: Batch: 27/31	Total Loss 3.9800 (4.2904)
2022-11-03 01:12:43,084:INFO: Batch: 28/31	Total Loss 4.3388 (4.2921)
2022-11-03 01:12:43,559:INFO: Batch: 29/31	Total Loss 3.9877 (4.2808)
2022-11-03 01:12:43,949:INFO: Batch: 30/31	Total Loss 1.7326 (4.2568)
2022-11-03 01:12:44,092:INFO: - Computing ADE (validation o)
2022-11-03 01:12:44,674:INFO: 		 ADE on eth                       dataset:	 0.9498776197433472
2022-11-03 01:12:44,675:INFO: Average validation o:	ADE  0.9499	FDE  1.8379
2022-11-03 01:12:44,675:INFO: - Computing ADE (validation)
2022-11-03 01:12:44,943:INFO: 		 ADE on hotel                     dataset:	 0.43699222803115845
2022-11-03 01:12:45,241:INFO: 		 ADE on univ                      dataset:	 0.5509587526321411
2022-11-03 01:12:45,499:INFO: 		 ADE on zara1                     dataset:	 0.40453070402145386
2022-11-03 01:12:45,859:INFO: 		 ADE on zara2                     dataset:	 0.4196368157863617
2022-11-03 01:12:45,859:INFO: Average validation:	ADE  0.4880	FDE  1.0149
2022-11-03 01:12:45,860:INFO: - Computing ADE (training)
2022-11-03 01:12:46,299:INFO: 		 ADE on hotel                     dataset:	 0.458797425031662
2022-11-03 01:12:47,012:INFO: 		 ADE on univ                      dataset:	 0.5449289679527283
2022-11-03 01:12:47,538:INFO: 		 ADE on zara1                     dataset:	 0.4895900785923004
2022-11-03 01:12:48,268:INFO: 		 ADE on zara2                     dataset:	 0.42421892285346985
2022-11-03 01:12:48,268:INFO: Average training:	ADE  0.5147	FDE  1.0765
2022-11-03 01:12:48,276:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_496.pth.tar
2022-11-03 01:12:48,276:INFO: 
===> EPOCH: 497 (P3)
2022-11-03 01:12:48,277:INFO: - Computing loss (training)
2022-11-03 01:12:49,376:INFO: Batch:  0/31	Total Loss 5.1458 (5.1458)
2022-11-03 01:12:49,850:INFO: Batch:  1/31	Total Loss 4.5869 (4.8954)
2022-11-03 01:12:50,325:INFO: Batch:  2/31	Total Loss 4.2045 (4.6717)
2022-11-03 01:12:50,800:INFO: Batch:  3/31	Total Loss 4.2814 (4.5701)
2022-11-03 01:12:51,270:INFO: Batch:  4/31	Total Loss 3.7089 (4.3995)
2022-11-03 01:12:51,748:INFO: Batch:  5/31	Total Loss 4.1952 (4.3665)
2022-11-03 01:12:52,227:INFO: Batch:  6/31	Total Loss 4.1891 (4.3406)
2022-11-03 01:12:52,703:INFO: Batch:  7/31	Total Loss 4.1330 (4.3108)
2022-11-03 01:12:53,176:INFO: Batch:  8/31	Total Loss 4.4363 (4.3258)
2022-11-03 01:12:53,649:INFO: Batch:  9/31	Total Loss 3.9853 (4.2917)
2022-11-03 01:12:54,126:INFO: Batch: 10/31	Total Loss 4.4594 (4.3063)
2022-11-03 01:12:54,600:INFO: Batch: 11/31	Total Loss 4.3313 (4.3082)
2022-11-03 01:12:55,077:INFO: Batch: 12/31	Total Loss 3.7900 (4.2668)
2022-11-03 01:12:55,553:INFO: Batch: 13/31	Total Loss 4.2502 (4.2656)
2022-11-03 01:12:56,030:INFO: Batch: 14/31	Total Loss 4.2212 (4.2627)
2022-11-03 01:12:56,509:INFO: Batch: 15/31	Total Loss 3.9155 (4.2410)
2022-11-03 01:12:56,988:INFO: Batch: 16/31	Total Loss 3.9692 (4.2265)
2022-11-03 01:12:57,465:INFO: Batch: 17/31	Total Loss 4.4032 (4.2365)
2022-11-03 01:12:57,942:INFO: Batch: 18/31	Total Loss 4.1938 (4.2343)
2022-11-03 01:12:58,420:INFO: Batch: 19/31	Total Loss 3.9555 (4.2195)
2022-11-03 01:12:58,897:INFO: Batch: 20/31	Total Loss 4.1891 (4.2180)
2022-11-03 01:12:59,373:INFO: Batch: 21/31	Total Loss 4.2348 (4.2188)
2022-11-03 01:12:59,849:INFO: Batch: 22/31	Total Loss 4.9237 (4.2483)
2022-11-03 01:13:00,326:INFO: Batch: 23/31	Total Loss 3.9650 (4.2348)
2022-11-03 01:13:00,803:INFO: Batch: 24/31	Total Loss 4.0079 (4.2265)
2022-11-03 01:13:01,282:INFO: Batch: 25/31	Total Loss 4.3732 (4.2326)
2022-11-03 01:13:01,756:INFO: Batch: 26/31	Total Loss 4.6912 (4.2502)
2022-11-03 01:13:02,233:INFO: Batch: 27/31	Total Loss 4.1057 (4.2444)
2022-11-03 01:13:02,707:INFO: Batch: 28/31	Total Loss 4.0153 (4.2360)
2022-11-03 01:13:03,182:INFO: Batch: 29/31	Total Loss 3.6903 (4.2165)
2022-11-03 01:13:03,573:INFO: Batch: 30/31	Total Loss 1.5069 (4.1858)
2022-11-03 01:13:03,725:INFO: - Computing ADE (validation o)
2022-11-03 01:13:04,296:INFO: 		 ADE on eth                       dataset:	 0.926593542098999
2022-11-03 01:13:04,296:INFO: Average validation o:	ADE  0.9266	FDE  1.8255
2022-11-03 01:13:04,296:INFO: - Computing ADE (validation)
2022-11-03 01:13:04,560:INFO: 		 ADE on hotel                     dataset:	 0.43697503209114075
2022-11-03 01:13:04,855:INFO: 		 ADE on univ                      dataset:	 0.5597152709960938
2022-11-03 01:13:05,115:INFO: 		 ADE on zara1                     dataset:	 0.4110727906227112
2022-11-03 01:13:05,475:INFO: 		 ADE on zara2                     dataset:	 0.39383557438850403
2022-11-03 01:13:05,475:INFO: Average validation:	ADE  0.4835	FDE  1.0079
2022-11-03 01:13:05,476:INFO: - Computing ADE (training)
2022-11-03 01:13:05,967:INFO: 		 ADE on hotel                     dataset:	 0.4666883945465088
2022-11-03 01:13:06,659:INFO: 		 ADE on univ                      dataset:	 0.5432862043380737
2022-11-03 01:13:07,220:INFO: 		 ADE on zara1                     dataset:	 0.46628281474113464
2022-11-03 01:13:07,993:INFO: 		 ADE on zara2                     dataset:	 0.394433856010437
2022-11-03 01:13:07,994:INFO: Average training:	ADE  0.5062	FDE  1.0582
2022-11-03 01:13:08,002:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_497.pth.tar
2022-11-03 01:13:08,002:INFO: 
===> EPOCH: 498 (P3)
2022-11-03 01:13:08,002:INFO: - Computing loss (training)
2022-11-03 01:13:09,112:INFO: Batch:  0/31	Total Loss 5.2875 (5.2875)
2022-11-03 01:13:09,581:INFO: Batch:  1/31	Total Loss 3.8857 (4.5873)
2022-11-03 01:13:10,055:INFO: Batch:  2/31	Total Loss 4.0580 (4.4123)
2022-11-03 01:13:10,529:INFO: Batch:  3/31	Total Loss 4.1732 (4.3538)
2022-11-03 01:13:10,999:INFO: Batch:  4/31	Total Loss 4.2124 (4.3233)
2022-11-03 01:13:11,472:INFO: Batch:  5/31	Total Loss 3.9746 (4.2676)
2022-11-03 01:13:12,020:INFO: Batch:  6/31	Total Loss 4.0325 (4.2331)
2022-11-03 01:13:12,492:INFO: Batch:  7/31	Total Loss 4.6379 (4.2793)
2022-11-03 01:13:12,961:INFO: Batch:  8/31	Total Loss 4.1112 (4.2575)
2022-11-03 01:13:13,434:INFO: Batch:  9/31	Total Loss 4.2771 (4.2597)
2022-11-03 01:13:13,905:INFO: Batch: 10/31	Total Loss 4.2414 (4.2581)
2022-11-03 01:13:14,374:INFO: Batch: 11/31	Total Loss 3.7423 (4.2178)
2022-11-03 01:13:14,852:INFO: Batch: 12/31	Total Loss 4.8103 (4.2604)
2022-11-03 01:13:15,330:INFO: Batch: 13/31	Total Loss 4.4993 (4.2792)
2022-11-03 01:13:15,804:INFO: Batch: 14/31	Total Loss 3.9716 (4.2564)
2022-11-03 01:13:16,281:INFO: Batch: 15/31	Total Loss 4.3303 (4.2608)
2022-11-03 01:13:16,753:INFO: Batch: 16/31	Total Loss 3.8334 (4.2372)
2022-11-03 01:13:17,227:INFO: Batch: 17/31	Total Loss 4.2609 (4.2386)
2022-11-03 01:13:17,700:INFO: Batch: 18/31	Total Loss 4.3648 (4.2449)
2022-11-03 01:13:18,173:INFO: Batch: 19/31	Total Loss 4.4192 (4.2544)
2022-11-03 01:13:18,645:INFO: Batch: 20/31	Total Loss 4.1376 (4.2481)
2022-11-03 01:13:19,116:INFO: Batch: 21/31	Total Loss 4.4282 (4.2551)
2022-11-03 01:13:19,588:INFO: Batch: 22/31	Total Loss 4.1219 (4.2487)
2022-11-03 01:13:20,061:INFO: Batch: 23/31	Total Loss 3.9826 (4.2377)
2022-11-03 01:13:20,532:INFO: Batch: 24/31	Total Loss 4.5499 (4.2500)
2022-11-03 01:13:21,007:INFO: Batch: 25/31	Total Loss 4.1485 (4.2456)
2022-11-03 01:13:21,479:INFO: Batch: 26/31	Total Loss 3.9394 (4.2328)
2022-11-03 01:13:21,952:INFO: Batch: 27/31	Total Loss 4.6645 (4.2501)
2022-11-03 01:13:22,424:INFO: Batch: 28/31	Total Loss 3.7531 (4.2303)
2022-11-03 01:13:22,898:INFO: Batch: 29/31	Total Loss 3.9502 (4.2210)
2022-11-03 01:13:23,286:INFO: Batch: 30/31	Total Loss 1.5482 (4.1936)
2022-11-03 01:13:23,435:INFO: - Computing ADE (validation o)
2022-11-03 01:13:24,027:INFO: 		 ADE on eth                       dataset:	 0.9407409429550171
2022-11-03 01:13:24,027:INFO: Average validation o:	ADE  0.9407	FDE  1.8329
2022-11-03 01:13:24,028:INFO: - Computing ADE (validation)
2022-11-03 01:13:24,313:INFO: 		 ADE on hotel                     dataset:	 0.42125505208969116
2022-11-03 01:13:24,600:INFO: 		 ADE on univ                      dataset:	 0.5471776127815247
2022-11-03 01:13:24,847:INFO: 		 ADE on zara1                     dataset:	 0.4130757749080658
2022-11-03 01:13:25,199:INFO: 		 ADE on zara2                     dataset:	 0.4002864360809326
2022-11-03 01:13:25,199:INFO: Average validation:	ADE  0.4786	FDE  0.9920
2022-11-03 01:13:25,200:INFO: - Computing ADE (training)
2022-11-03 01:13:25,639:INFO: 		 ADE on hotel                     dataset:	 0.4430006444454193
2022-11-03 01:13:26,314:INFO: 		 ADE on univ                      dataset:	 0.5352687835693359
2022-11-03 01:13:26,847:INFO: 		 ADE on zara1                     dataset:	 0.48368552327156067
2022-11-03 01:13:27,575:INFO: 		 ADE on zara2                     dataset:	 0.4087386429309845
2022-11-03 01:13:27,576:INFO: Average training:	ADE  0.5040	FDE  1.0502
2022-11-03 01:13:27,584:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_498.pth.tar
2022-11-03 01:13:27,584:INFO: 
===> EPOCH: 499 (P3)
2022-11-03 01:13:27,584:INFO: - Computing loss (training)
2022-11-03 01:13:28,691:INFO: Batch:  0/31	Total Loss 4.4187 (4.4187)
2022-11-03 01:13:29,160:INFO: Batch:  1/31	Total Loss 3.8742 (4.1177)
2022-11-03 01:13:29,634:INFO: Batch:  2/31	Total Loss 5.1901 (4.4906)
2022-11-03 01:13:30,103:INFO: Batch:  3/31	Total Loss 4.3141 (4.4467)
2022-11-03 01:13:30,572:INFO: Batch:  4/31	Total Loss 3.8075 (4.3217)
2022-11-03 01:13:31,038:INFO: Batch:  5/31	Total Loss 3.9785 (4.2654)
2022-11-03 01:13:31,505:INFO: Batch:  6/31	Total Loss 4.0586 (4.2346)
2022-11-03 01:13:31,969:INFO: Batch:  7/31	Total Loss 4.3825 (4.2524)
2022-11-03 01:13:32,435:INFO: Batch:  8/31	Total Loss 4.3940 (4.2675)
2022-11-03 01:13:32,904:INFO: Batch:  9/31	Total Loss 4.6552 (4.3031)
2022-11-03 01:13:33,368:INFO: Batch: 10/31	Total Loss 4.1461 (4.2886)
2022-11-03 01:13:33,834:INFO: Batch: 11/31	Total Loss 4.4279 (4.2992)
2022-11-03 01:13:34,304:INFO: Batch: 12/31	Total Loss 4.3228 (4.3008)
2022-11-03 01:13:34,773:INFO: Batch: 13/31	Total Loss 4.1289 (4.2875)
2022-11-03 01:13:35,242:INFO: Batch: 14/31	Total Loss 4.4271 (4.2963)
2022-11-03 01:13:35,709:INFO: Batch: 15/31	Total Loss 3.8879 (4.2705)
2022-11-03 01:13:36,180:INFO: Batch: 16/31	Total Loss 4.5923 (4.2904)
2022-11-03 01:13:36,648:INFO: Batch: 17/31	Total Loss 3.9117 (4.2687)
2022-11-03 01:13:37,116:INFO: Batch: 18/31	Total Loss 4.0233 (4.2549)
2022-11-03 01:13:37,587:INFO: Batch: 19/31	Total Loss 4.1807 (4.2512)
2022-11-03 01:13:38,058:INFO: Batch: 20/31	Total Loss 4.5297 (4.2645)
2022-11-03 01:13:38,527:INFO: Batch: 21/31	Total Loss 3.9278 (4.2480)
2022-11-03 01:13:38,995:INFO: Batch: 22/31	Total Loss 4.5274 (4.2583)
2022-11-03 01:13:39,462:INFO: Batch: 23/31	Total Loss 4.1667 (4.2545)
2022-11-03 01:13:39,939:INFO: Batch: 24/31	Total Loss 4.5802 (4.2675)
2022-11-03 01:13:40,414:INFO: Batch: 25/31	Total Loss 3.7935 (4.2508)
2022-11-03 01:13:40,891:INFO: Batch: 26/31	Total Loss 3.9931 (4.2400)
2022-11-03 01:13:41,365:INFO: Batch: 27/31	Total Loss 4.3047 (4.2423)
2022-11-03 01:13:41,840:INFO: Batch: 28/31	Total Loss 4.1331 (4.2385)
2022-11-03 01:13:42,315:INFO: Batch: 29/31	Total Loss 3.6722 (4.2189)
2022-11-03 01:13:42,704:INFO: Batch: 30/31	Total Loss 1.5597 (4.1974)
2022-11-03 01:13:42,852:INFO: - Computing ADE (validation o)
2022-11-03 01:13:43,441:INFO: 		 ADE on eth                       dataset:	 0.9299092292785645
2022-11-03 01:13:43,441:INFO: Average validation o:	ADE  0.9299	FDE  1.8188
2022-11-03 01:13:43,442:INFO: - Computing ADE (validation)
2022-11-03 01:13:43,700:INFO: 		 ADE on hotel                     dataset:	 0.4120311141014099
2022-11-03 01:13:44,004:INFO: 		 ADE on univ                      dataset:	 0.5415796637535095
2022-11-03 01:13:44,244:INFO: 		 ADE on zara1                     dataset:	 0.4045712947845459
2022-11-03 01:13:44,575:INFO: 		 ADE on zara2                     dataset:	 0.39653050899505615
2022-11-03 01:13:44,575:INFO: Average validation:	ADE  0.4733	FDE  0.9768
2022-11-03 01:13:44,576:INFO: - Computing ADE (training)
2022-11-03 01:13:45,016:INFO: 		 ADE on hotel                     dataset:	 0.42844676971435547
2022-11-03 01:13:45,722:INFO: 		 ADE on univ                      dataset:	 0.5356308817863464
2022-11-03 01:13:46,237:INFO: 		 ADE on zara1                     dataset:	 0.4654771387577057
2022-11-03 01:13:46,994:INFO: 		 ADE on zara2                     dataset:	 0.39659565687179565
2022-11-03 01:13:46,994:INFO: Average training:	ADE  0.5002	FDE  1.0398
2022-11-03 01:13:47,003:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_499.pth.tar
2022-11-03 01:13:47,003:INFO: 
===> EPOCH: 500 (P3)
2022-11-03 01:13:47,004:INFO: - Computing loss (training)
2022-11-03 01:13:48,105:INFO: Batch:  0/31	Total Loss 4.7069 (4.7069)
2022-11-03 01:13:48,580:INFO: Batch:  1/31	Total Loss 3.7596 (4.1970)
2022-11-03 01:13:49,055:INFO: Batch:  2/31	Total Loss 4.0293 (4.1391)
2022-11-03 01:13:49,522:INFO: Batch:  3/31	Total Loss 3.6213 (4.0231)
2022-11-03 01:13:49,992:INFO: Batch:  4/31	Total Loss 4.5001 (4.1186)
2022-11-03 01:13:50,466:INFO: Batch:  5/31	Total Loss 4.0960 (4.1144)
2022-11-03 01:13:50,937:INFO: Batch:  6/31	Total Loss 4.3431 (4.1462)
2022-11-03 01:13:51,409:INFO: Batch:  7/31	Total Loss 4.0350 (4.1315)
2022-11-03 01:13:51,876:INFO: Batch:  8/31	Total Loss 3.6539 (4.0767)
2022-11-03 01:13:52,346:INFO: Batch:  9/31	Total Loss 3.9112 (4.0579)
2022-11-03 01:13:52,819:INFO: Batch: 10/31	Total Loss 4.1035 (4.0619)
2022-11-03 01:13:53,289:INFO: Batch: 11/31	Total Loss 4.4252 (4.0918)
2022-11-03 01:13:53,762:INFO: Batch: 12/31	Total Loss 4.4360 (4.1187)
2022-11-03 01:13:54,235:INFO: Batch: 13/31	Total Loss 4.6976 (4.1545)
2022-11-03 01:13:54,708:INFO: Batch: 14/31	Total Loss 4.0026 (4.1455)
2022-11-03 01:13:55,180:INFO: Batch: 15/31	Total Loss 3.7002 (4.1157)
2022-11-03 01:13:55,653:INFO: Batch: 16/31	Total Loss 4.4603 (4.1334)
2022-11-03 01:13:56,128:INFO: Batch: 17/31	Total Loss 4.3768 (4.1474)
2022-11-03 01:13:56,604:INFO: Batch: 18/31	Total Loss 3.9519 (4.1358)
2022-11-03 01:13:57,076:INFO: Batch: 19/31	Total Loss 5.0842 (4.1858)
2022-11-03 01:13:57,548:INFO: Batch: 20/31	Total Loss 4.3355 (4.1927)
2022-11-03 01:13:58,021:INFO: Batch: 21/31	Total Loss 4.3626 (4.2006)
2022-11-03 01:13:58,496:INFO: Batch: 22/31	Total Loss 4.2981 (4.2048)
2022-11-03 01:13:58,969:INFO: Batch: 23/31	Total Loss 3.8003 (4.1891)
2022-11-03 01:13:59,442:INFO: Batch: 24/31	Total Loss 4.7755 (4.2095)
2022-11-03 01:13:59,915:INFO: Batch: 25/31	Total Loss 4.1025 (4.2054)
2022-11-03 01:14:00,387:INFO: Batch: 26/31	Total Loss 4.2250 (4.2061)
2022-11-03 01:14:00,863:INFO: Batch: 27/31	Total Loss 4.3400 (4.2111)
2022-11-03 01:14:01,340:INFO: Batch: 28/31	Total Loss 4.5995 (4.2241)
2022-11-03 01:14:01,814:INFO: Batch: 29/31	Total Loss 5.2791 (4.2586)
2022-11-03 01:14:02,202:INFO: Batch: 30/31	Total Loss 1.6647 (4.2362)
2022-11-03 01:14:02,351:INFO: - Computing ADE (validation o)
2022-11-03 01:14:02,943:INFO: 		 ADE on eth                       dataset:	 0.9900436401367188
2022-11-03 01:14:02,944:INFO: Average validation o:	ADE  0.9900	FDE  1.9675
2022-11-03 01:14:02,944:INFO: - Computing ADE (validation)
2022-11-03 01:14:03,260:INFO: 		 ADE on hotel                     dataset:	 0.4996756315231323
2022-11-03 01:14:03,551:INFO: 		 ADE on univ                      dataset:	 0.5799812078475952
2022-11-03 01:14:03,799:INFO: 		 ADE on zara1                     dataset:	 0.469225138425827
2022-11-03 01:14:04,148:INFO: 		 ADE on zara2                     dataset:	 0.48407989740371704
2022-11-03 01:14:04,148:INFO: Average validation:	ADE  0.5340	FDE  1.1362
2022-11-03 01:14:04,149:INFO: - Computing ADE (training)
2022-11-03 01:14:04,627:INFO: 		 ADE on hotel                     dataset:	 0.5161511898040771
2022-11-03 01:14:05,344:INFO: 		 ADE on univ                      dataset:	 0.5888939499855042
2022-11-03 01:14:05,856:INFO: 		 ADE on zara1                     dataset:	 0.5311256051063538
2022-11-03 01:14:06,678:INFO: 		 ADE on zara2                     dataset:	 0.4854111075401306
2022-11-03 01:14:06,678:INFO: Average training:	ADE  0.5624	FDE  1.2060
2022-11-03 01:14:06,688:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_500.pth.tar
2022-11-03 01:14:06,688:INFO: 
===> EPOCH: 501 (P3)
2022-11-03 01:14:06,688:INFO: - Computing loss (training)
2022-11-03 01:14:07,857:INFO: Batch:  0/31	Total Loss 4.6989 (4.6989)
2022-11-03 01:14:08,333:INFO: Batch:  1/31	Total Loss 4.4672 (4.5781)
2022-11-03 01:14:08,812:INFO: Batch:  2/31	Total Loss 4.5331 (4.5620)
2022-11-03 01:14:09,286:INFO: Batch:  3/31	Total Loss 4.4566 (4.5353)
2022-11-03 01:14:09,755:INFO: Batch:  4/31	Total Loss 4.7502 (4.5809)
2022-11-03 01:14:10,234:INFO: Batch:  5/31	Total Loss 4.4795 (4.5641)
2022-11-03 01:14:10,711:INFO: Batch:  6/31	Total Loss 4.3989 (4.5426)
2022-11-03 01:14:11,190:INFO: Batch:  7/31	Total Loss 4.0673 (4.4787)
2022-11-03 01:14:11,665:INFO: Batch:  8/31	Total Loss 4.5218 (4.4833)
2022-11-03 01:14:12,140:INFO: Batch:  9/31	Total Loss 4.3542 (4.4717)
2022-11-03 01:14:12,615:INFO: Batch: 10/31	Total Loss 3.9272 (4.4203)
2022-11-03 01:14:13,092:INFO: Batch: 11/31	Total Loss 4.0749 (4.3940)
2022-11-03 01:14:13,572:INFO: Batch: 12/31	Total Loss 5.4803 (4.4759)
2022-11-03 01:14:14,052:INFO: Batch: 13/31	Total Loss 4.3205 (4.4652)
2022-11-03 01:14:14,534:INFO: Batch: 14/31	Total Loss 4.0065 (4.4368)
2022-11-03 01:14:15,016:INFO: Batch: 15/31	Total Loss 4.1684 (4.4207)
2022-11-03 01:14:15,497:INFO: Batch: 16/31	Total Loss 3.8867 (4.3887)
2022-11-03 01:14:15,978:INFO: Batch: 17/31	Total Loss 4.3441 (4.3861)
2022-11-03 01:14:16,460:INFO: Batch: 18/31	Total Loss 4.2990 (4.3817)
2022-11-03 01:14:16,940:INFO: Batch: 19/31	Total Loss 4.2266 (4.3750)
2022-11-03 01:14:17,418:INFO: Batch: 20/31	Total Loss 3.9252 (4.3551)
2022-11-03 01:14:17,898:INFO: Batch: 21/31	Total Loss 4.3579 (4.3552)
2022-11-03 01:14:18,384:INFO: Batch: 22/31	Total Loss 4.2631 (4.3508)
2022-11-03 01:14:18,864:INFO: Batch: 23/31	Total Loss 4.0989 (4.3415)
2022-11-03 01:14:19,353:INFO: Batch: 24/31	Total Loss 4.4182 (4.3446)
2022-11-03 01:14:19,832:INFO: Batch: 25/31	Total Loss 4.2727 (4.3417)
2022-11-03 01:14:20,313:INFO: Batch: 26/31	Total Loss 4.7030 (4.3568)
2022-11-03 01:14:20,792:INFO: Batch: 27/31	Total Loss 4.2988 (4.3548)
2022-11-03 01:14:21,271:INFO: Batch: 28/31	Total Loss 4.2764 (4.3520)
2022-11-03 01:14:21,749:INFO: Batch: 29/31	Total Loss 4.4935 (4.3569)
2022-11-03 01:14:22,142:INFO: Batch: 30/31	Total Loss 1.4454 (4.3301)
2022-11-03 01:14:22,297:INFO: - Computing ADE (validation o)
2022-11-03 01:14:22,903:INFO: 		 ADE on eth                       dataset:	 0.9711427092552185
2022-11-03 01:14:22,903:INFO: Average validation o:	ADE  0.9711	FDE  1.9129
2022-11-03 01:14:22,904:INFO: - Computing ADE (validation)
2022-11-03 01:14:23,168:INFO: 		 ADE on hotel                     dataset:	 0.4204331338405609
2022-11-03 01:14:23,458:INFO: 		 ADE on univ                      dataset:	 0.5517983436584473
2022-11-03 01:14:23,694:INFO: 		 ADE on zara1                     dataset:	 0.47191357612609863
2022-11-03 01:14:24,039:INFO: 		 ADE on zara2                     dataset:	 0.4299161732196808
2022-11-03 01:14:24,039:INFO: Average validation:	ADE  0.4953	FDE  1.0321
2022-11-03 01:14:24,040:INFO: - Computing ADE (training)
2022-11-03 01:14:24,482:INFO: 		 ADE on hotel                     dataset:	 0.438539981842041
2022-11-03 01:14:25,221:INFO: 		 ADE on univ                      dataset:	 0.5460103750228882
2022-11-03 01:14:25,751:INFO: 		 ADE on zara1                     dataset:	 0.5250413417816162
2022-11-03 01:14:26,491:INFO: 		 ADE on zara2                     dataset:	 0.44334059953689575
2022-11-03 01:14:26,491:INFO: Average training:	ADE  0.5211	FDE  1.0943
2022-11-03 01:14:26,500:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_501.pth.tar
2022-11-03 01:14:26,500:INFO: 
===> EPOCH: 502 (P3)
2022-11-03 01:14:26,501:INFO: - Computing loss (training)
2022-11-03 01:14:27,589:INFO: Batch:  0/31	Total Loss 4.8773 (4.8773)
2022-11-03 01:14:28,057:INFO: Batch:  1/31	Total Loss 3.9719 (4.4301)
2022-11-03 01:14:28,528:INFO: Batch:  2/31	Total Loss 5.1531 (4.6266)
2022-11-03 01:14:28,997:INFO: Batch:  3/31	Total Loss 4.7112 (4.6477)
2022-11-03 01:14:29,468:INFO: Batch:  4/31	Total Loss 3.9138 (4.5111)
2022-11-03 01:14:29,938:INFO: Batch:  5/31	Total Loss 4.4500 (4.5016)
2022-11-03 01:14:30,408:INFO: Batch:  6/31	Total Loss 4.2337 (4.4640)
2022-11-03 01:14:30,877:INFO: Batch:  7/31	Total Loss 4.9232 (4.5229)
2022-11-03 01:14:31,342:INFO: Batch:  8/31	Total Loss 4.6301 (4.5346)
2022-11-03 01:14:31,809:INFO: Batch:  9/31	Total Loss 4.0770 (4.4918)
2022-11-03 01:14:32,278:INFO: Batch: 10/31	Total Loss 3.8763 (4.4373)
2022-11-03 01:14:32,748:INFO: Batch: 11/31	Total Loss 4.3077 (4.4271)
2022-11-03 01:14:33,218:INFO: Batch: 12/31	Total Loss 4.1844 (4.4105)
2022-11-03 01:14:33,688:INFO: Batch: 13/31	Total Loss 4.1928 (4.3959)
2022-11-03 01:14:34,158:INFO: Batch: 14/31	Total Loss 4.5313 (4.4043)
2022-11-03 01:14:34,628:INFO: Batch: 15/31	Total Loss 4.6849 (4.4207)
2022-11-03 01:14:35,099:INFO: Batch: 16/31	Total Loss 4.6978 (4.4370)
2022-11-03 01:14:35,569:INFO: Batch: 17/31	Total Loss 5.0033 (4.4677)
2022-11-03 01:14:36,040:INFO: Batch: 18/31	Total Loss 3.9496 (4.4400)
2022-11-03 01:14:36,508:INFO: Batch: 19/31	Total Loss 4.5412 (4.4448)
2022-11-03 01:14:36,976:INFO: Batch: 20/31	Total Loss 4.5500 (4.4501)
2022-11-03 01:14:37,446:INFO: Batch: 21/31	Total Loss 4.3447 (4.4450)
2022-11-03 01:14:37,926:INFO: Batch: 22/31	Total Loss 4.9087 (4.4667)
2022-11-03 01:14:38,409:INFO: Batch: 23/31	Total Loss 3.8562 (4.4399)
2022-11-03 01:14:38,887:INFO: Batch: 24/31	Total Loss 4.6332 (4.4472)
2022-11-03 01:14:39,368:INFO: Batch: 25/31	Total Loss 4.3934 (4.4453)
2022-11-03 01:14:39,846:INFO: Batch: 26/31	Total Loss 5.0284 (4.4676)
2022-11-03 01:14:40,325:INFO: Batch: 27/31	Total Loss 3.8939 (4.4437)
2022-11-03 01:14:40,803:INFO: Batch: 28/31	Total Loss 4.2316 (4.4363)
2022-11-03 01:14:41,281:INFO: Batch: 29/31	Total Loss 4.7522 (4.4462)
2022-11-03 01:14:41,677:INFO: Batch: 30/31	Total Loss 1.3830 (4.4116)
2022-11-03 01:14:41,836:INFO: - Computing ADE (validation o)
2022-11-03 01:14:42,419:INFO: 		 ADE on eth                       dataset:	 0.9701201915740967
2022-11-03 01:14:42,419:INFO: Average validation o:	ADE  0.9701	FDE  1.8831
2022-11-03 01:14:42,420:INFO: - Computing ADE (validation)
2022-11-03 01:14:42,699:INFO: 		 ADE on hotel                     dataset:	 0.48127421736717224
2022-11-03 01:14:42,983:INFO: 		 ADE on univ                      dataset:	 0.5806301236152649
2022-11-03 01:14:43,228:INFO: 		 ADE on zara1                     dataset:	 0.42413678765296936
2022-11-03 01:14:43,589:INFO: 		 ADE on zara2                     dataset:	 0.45822733640670776
2022-11-03 01:14:43,589:INFO: Average validation:	ADE  0.5212	FDE  1.1098
2022-11-03 01:14:43,590:INFO: - Computing ADE (training)
2022-11-03 01:14:44,054:INFO: 		 ADE on hotel                     dataset:	 0.4976733922958374
2022-11-03 01:14:44,770:INFO: 		 ADE on univ                      dataset:	 0.5671287178993225
2022-11-03 01:14:45,342:INFO: 		 ADE on zara1                     dataset:	 0.5265628099441528
2022-11-03 01:14:46,073:INFO: 		 ADE on zara2                     dataset:	 0.4672863185405731
2022-11-03 01:14:46,074:INFO: Average training:	ADE  0.5425	FDE  1.1555
2022-11-03 01:14:46,083:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_502.pth.tar
2022-11-03 01:14:46,083:INFO: 
===> EPOCH: 503 (P3)
2022-11-03 01:14:46,083:INFO: - Computing loss (training)
2022-11-03 01:14:47,215:INFO: Batch:  0/31	Total Loss 4.6333 (4.6333)
2022-11-03 01:14:47,698:INFO: Batch:  1/31	Total Loss 4.2011 (4.4354)
2022-11-03 01:14:48,186:INFO: Batch:  2/31	Total Loss 4.1684 (4.3430)
2022-11-03 01:14:48,665:INFO: Batch:  3/31	Total Loss 3.8408 (4.2139)
2022-11-03 01:14:49,142:INFO: Batch:  4/31	Total Loss 4.3656 (4.2438)
2022-11-03 01:14:49,627:INFO: Batch:  5/31	Total Loss 3.7015 (4.1630)
2022-11-03 01:14:50,102:INFO: Batch:  6/31	Total Loss 4.4223 (4.2025)
2022-11-03 01:14:50,573:INFO: Batch:  7/31	Total Loss 4.1911 (4.2013)
2022-11-03 01:14:51,040:INFO: Batch:  8/31	Total Loss 4.4971 (4.2349)
2022-11-03 01:14:51,508:INFO: Batch:  9/31	Total Loss 3.8123 (4.1908)
2022-11-03 01:14:51,976:INFO: Batch: 10/31	Total Loss 3.9930 (4.1713)
2022-11-03 01:14:52,447:INFO: Batch: 11/31	Total Loss 4.4106 (4.1945)
2022-11-03 01:14:52,923:INFO: Batch: 12/31	Total Loss 4.3934 (4.2115)
2022-11-03 01:14:53,397:INFO: Batch: 13/31	Total Loss 4.4083 (4.2246)
2022-11-03 01:14:53,872:INFO: Batch: 14/31	Total Loss 5.3881 (4.2989)
2022-11-03 01:14:54,346:INFO: Batch: 15/31	Total Loss 3.5644 (4.2503)
2022-11-03 01:14:54,820:INFO: Batch: 16/31	Total Loss 4.7112 (4.2758)
2022-11-03 01:14:55,292:INFO: Batch: 17/31	Total Loss 4.2597 (4.2749)
2022-11-03 01:14:55,764:INFO: Batch: 18/31	Total Loss 4.6446 (4.2920)
2022-11-03 01:14:56,237:INFO: Batch: 19/31	Total Loss 4.2531 (4.2897)
2022-11-03 01:14:56,708:INFO: Batch: 20/31	Total Loss 5.5944 (4.3536)
2022-11-03 01:14:57,180:INFO: Batch: 21/31	Total Loss 3.9965 (4.3368)
2022-11-03 01:14:57,654:INFO: Batch: 22/31	Total Loss 4.1493 (4.3281)
2022-11-03 01:14:58,126:INFO: Batch: 23/31	Total Loss 3.8276 (4.3051)
2022-11-03 01:14:58,676:INFO: Batch: 24/31	Total Loss 5.2128 (4.3401)
2022-11-03 01:14:59,150:INFO: Batch: 25/31	Total Loss 4.0180 (4.3274)
2022-11-03 01:14:59,625:INFO: Batch: 26/31	Total Loss 4.9153 (4.3499)
2022-11-03 01:15:00,098:INFO: Batch: 27/31	Total Loss 3.9488 (4.3354)
2022-11-03 01:15:00,571:INFO: Batch: 28/31	Total Loss 4.0231 (4.3244)
2022-11-03 01:15:01,046:INFO: Batch: 29/31	Total Loss 4.0639 (4.3164)
2022-11-03 01:15:01,459:INFO: Batch: 30/31	Total Loss 1.6516 (4.2884)
2022-11-03 01:15:01,621:INFO: - Computing ADE (validation o)
2022-11-03 01:15:02,210:INFO: 		 ADE on eth                       dataset:	 0.9761741757392883
2022-11-03 01:15:02,211:INFO: Average validation o:	ADE  0.9762	FDE  1.8824
2022-11-03 01:15:02,211:INFO: - Computing ADE (validation)
2022-11-03 01:15:02,488:INFO: 		 ADE on hotel                     dataset:	 0.4836427569389343
2022-11-03 01:15:02,791:INFO: 		 ADE on univ                      dataset:	 0.5772358179092407
2022-11-03 01:15:03,060:INFO: 		 ADE on zara1                     dataset:	 0.42442572116851807
2022-11-03 01:15:03,420:INFO: 		 ADE on zara2                     dataset:	 0.4587196409702301
2022-11-03 01:15:03,420:INFO: Average validation:	ADE  0.5198	FDE  1.1004
2022-11-03 01:15:03,421:INFO: - Computing ADE (training)
2022-11-03 01:15:03,873:INFO: 		 ADE on hotel                     dataset:	 0.503084123134613
2022-11-03 01:15:04,568:INFO: 		 ADE on univ                      dataset:	 0.5664315819740295
2022-11-03 01:15:05,101:INFO: 		 ADE on zara1                     dataset:	 0.5326928496360779
2022-11-03 01:15:05,854:INFO: 		 ADE on zara2                     dataset:	 0.4695560336112976
2022-11-03 01:15:05,854:INFO: Average training:	ADE  0.5430	FDE  1.1523
2022-11-03 01:15:05,871:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_503.pth.tar
2022-11-03 01:15:05,871:INFO: 
===> EPOCH: 504 (P3)
2022-11-03 01:15:05,871:INFO: - Computing loss (training)
2022-11-03 01:15:06,976:INFO: Batch:  0/31	Total Loss 5.1243 (5.1243)
2022-11-03 01:15:07,449:INFO: Batch:  1/31	Total Loss 4.3692 (4.7559)
2022-11-03 01:15:07,926:INFO: Batch:  2/31	Total Loss 4.5919 (4.7034)
2022-11-03 01:15:08,395:INFO: Batch:  3/31	Total Loss 4.2751 (4.6025)
2022-11-03 01:15:08,864:INFO: Batch:  4/31	Total Loss 3.8119 (4.4314)
2022-11-03 01:15:09,336:INFO: Batch:  5/31	Total Loss 4.2994 (4.4087)
2022-11-03 01:15:09,805:INFO: Batch:  6/31	Total Loss 4.9274 (4.4822)
2022-11-03 01:15:10,272:INFO: Batch:  7/31	Total Loss 4.2765 (4.4532)
2022-11-03 01:15:10,741:INFO: Batch:  8/31	Total Loss 4.5341 (4.4622)
2022-11-03 01:15:11,204:INFO: Batch:  9/31	Total Loss 4.0398 (4.4249)
2022-11-03 01:15:11,672:INFO: Batch: 10/31	Total Loss 4.4824 (4.4307)
2022-11-03 01:15:12,142:INFO: Batch: 11/31	Total Loss 3.7996 (4.3782)
2022-11-03 01:15:12,615:INFO: Batch: 12/31	Total Loss 4.0494 (4.3501)
2022-11-03 01:15:13,086:INFO: Batch: 13/31	Total Loss 4.0511 (4.3266)
2022-11-03 01:15:13,557:INFO: Batch: 14/31	Total Loss 4.0271 (4.3080)
2022-11-03 01:15:14,028:INFO: Batch: 15/31	Total Loss 4.2027 (4.3014)
2022-11-03 01:15:14,498:INFO: Batch: 16/31	Total Loss 4.7726 (4.3257)
2022-11-03 01:15:14,972:INFO: Batch: 17/31	Total Loss 4.3755 (4.3285)
2022-11-03 01:15:15,442:INFO: Batch: 18/31	Total Loss 3.8767 (4.3045)
2022-11-03 01:15:15,914:INFO: Batch: 19/31	Total Loss 4.2242 (4.3004)
2022-11-03 01:15:16,384:INFO: Batch: 20/31	Total Loss 4.5239 (4.3094)
2022-11-03 01:15:16,861:INFO: Batch: 21/31	Total Loss 4.0007 (4.2960)
2022-11-03 01:15:17,357:INFO: Batch: 22/31	Total Loss 3.9544 (4.2794)
2022-11-03 01:15:17,866:INFO: Batch: 23/31	Total Loss 3.9450 (4.2656)
2022-11-03 01:15:18,346:INFO: Batch: 24/31	Total Loss 4.5815 (4.2787)
2022-11-03 01:15:18,815:INFO: Batch: 25/31	Total Loss 3.8413 (4.2616)
2022-11-03 01:15:19,292:INFO: Batch: 26/31	Total Loss 5.3786 (4.3017)
2022-11-03 01:15:19,762:INFO: Batch: 27/31	Total Loss 3.8747 (4.2865)
2022-11-03 01:15:20,234:INFO: Batch: 28/31	Total Loss 4.4676 (4.2937)
2022-11-03 01:15:20,702:INFO: Batch: 29/31	Total Loss 4.7152 (4.3077)
2022-11-03 01:15:21,093:INFO: Batch: 30/31	Total Loss 1.8177 (4.2818)
2022-11-03 01:15:21,247:INFO: - Computing ADE (validation o)
2022-11-03 01:15:21,816:INFO: 		 ADE on eth                       dataset:	 0.9783530235290527
2022-11-03 01:15:21,817:INFO: Average validation o:	ADE  0.9784	FDE  1.9134
2022-11-03 01:15:21,817:INFO: - Computing ADE (validation)
2022-11-03 01:15:22,094:INFO: 		 ADE on hotel                     dataset:	 0.3991726338863373
2022-11-03 01:15:22,391:INFO: 		 ADE on univ                      dataset:	 0.5475909113883972
2022-11-03 01:15:22,648:INFO: 		 ADE on zara1                     dataset:	 0.45201238989830017
2022-11-03 01:15:22,995:INFO: 		 ADE on zara2                     dataset:	 0.4341520667076111
2022-11-03 01:15:22,996:INFO: Average validation:	ADE  0.4923	FDE  1.0257
2022-11-03 01:15:22,996:INFO: - Computing ADE (training)
2022-11-03 01:15:23,437:INFO: 		 ADE on hotel                     dataset:	 0.41578730940818787
2022-11-03 01:15:24,127:INFO: 		 ADE on univ                      dataset:	 0.5443946719169617
2022-11-03 01:15:24,675:INFO: 		 ADE on zara1                     dataset:	 0.5382445454597473
2022-11-03 01:15:25,411:INFO: 		 ADE on zara2                     dataset:	 0.4514598846435547
2022-11-03 01:15:25,412:INFO: Average training:	ADE  0.5219	FDE  1.0970
2022-11-03 01:15:25,420:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_504.pth.tar
2022-11-03 01:15:25,420:INFO: 
===> EPOCH: 505 (P3)
2022-11-03 01:15:25,421:INFO: - Computing loss (training)
2022-11-03 01:15:26,513:INFO: Batch:  0/31	Total Loss 4.6691 (4.6691)
2022-11-03 01:15:26,987:INFO: Batch:  1/31	Total Loss 3.9123 (4.2771)
2022-11-03 01:15:27,464:INFO: Batch:  2/31	Total Loss 4.3804 (4.3087)
2022-11-03 01:15:27,933:INFO: Batch:  3/31	Total Loss 4.3245 (4.3128)
2022-11-03 01:15:28,402:INFO: Batch:  4/31	Total Loss 4.1664 (4.2873)
2022-11-03 01:15:28,874:INFO: Batch:  5/31	Total Loss 4.3641 (4.2994)
2022-11-03 01:15:29,348:INFO: Batch:  6/31	Total Loss 3.7033 (4.2222)
2022-11-03 01:15:29,816:INFO: Batch:  7/31	Total Loss 4.5147 (4.2610)
2022-11-03 01:15:30,287:INFO: Batch:  8/31	Total Loss 4.1920 (4.2536)
2022-11-03 01:15:30,759:INFO: Batch:  9/31	Total Loss 4.7313 (4.3040)
2022-11-03 01:15:31,226:INFO: Batch: 10/31	Total Loss 4.2392 (4.2978)
2022-11-03 01:15:31,695:INFO: Batch: 11/31	Total Loss 3.4946 (4.2266)
2022-11-03 01:15:32,169:INFO: Batch: 12/31	Total Loss 3.8519 (4.1943)
2022-11-03 01:15:32,645:INFO: Batch: 13/31	Total Loss 4.4543 (4.2135)
2022-11-03 01:15:33,126:INFO: Batch: 14/31	Total Loss 4.0158 (4.2003)
2022-11-03 01:15:33,599:INFO: Batch: 15/31	Total Loss 4.8995 (4.2408)
2022-11-03 01:15:34,081:INFO: Batch: 16/31	Total Loss 4.4760 (4.2551)
2022-11-03 01:15:34,554:INFO: Batch: 17/31	Total Loss 4.1633 (4.2504)
2022-11-03 01:15:35,027:INFO: Batch: 18/31	Total Loss 5.8014 (4.3241)
2022-11-03 01:15:35,499:INFO: Batch: 19/31	Total Loss 4.4639 (4.3312)
2022-11-03 01:15:35,973:INFO: Batch: 20/31	Total Loss 3.5963 (4.2931)
2022-11-03 01:15:36,444:INFO: Batch: 21/31	Total Loss 5.0351 (4.3316)
2022-11-03 01:15:36,914:INFO: Batch: 22/31	Total Loss 4.0517 (4.3201)
2022-11-03 01:15:37,382:INFO: Batch: 23/31	Total Loss 4.3955 (4.3234)
2022-11-03 01:15:37,860:INFO: Batch: 24/31	Total Loss 4.4168 (4.3270)
2022-11-03 01:15:38,335:INFO: Batch: 25/31	Total Loss 4.1123 (4.3181)
2022-11-03 01:15:38,809:INFO: Batch: 26/31	Total Loss 4.6731 (4.3320)
2022-11-03 01:15:39,288:INFO: Batch: 27/31	Total Loss 4.2490 (4.3288)
2022-11-03 01:15:39,762:INFO: Batch: 28/31	Total Loss 3.5686 (4.3038)
2022-11-03 01:15:40,237:INFO: Batch: 29/31	Total Loss 4.4817 (4.3104)
2022-11-03 01:15:40,636:INFO: Batch: 30/31	Total Loss 1.6804 (4.2888)
2022-11-03 01:15:40,789:INFO: - Computing ADE (validation o)
2022-11-03 01:15:41,414:INFO: 		 ADE on eth                       dataset:	 0.9350175857543945
2022-11-03 01:15:41,414:INFO: Average validation o:	ADE  0.9350	FDE  1.7915
2022-11-03 01:15:41,415:INFO: - Computing ADE (validation)
2022-11-03 01:15:41,683:INFO: 		 ADE on hotel                     dataset:	 0.4260251224040985
2022-11-03 01:15:41,993:INFO: 		 ADE on univ                      dataset:	 0.5590496063232422
2022-11-03 01:15:42,250:INFO: 		 ADE on zara1                     dataset:	 0.4325716495513916
2022-11-03 01:15:42,602:INFO: 		 ADE on zara2                     dataset:	 0.4109885096549988
2022-11-03 01:15:42,602:INFO: Average validation:	ADE  0.4901	FDE  1.0314
2022-11-03 01:15:42,603:INFO: - Computing ADE (training)
2022-11-03 01:15:43,052:INFO: 		 ADE on hotel                     dataset:	 0.4537617862224579
2022-11-03 01:15:43,747:INFO: 		 ADE on univ                      dataset:	 0.5403279662132263
2022-11-03 01:15:44,286:INFO: 		 ADE on zara1                     dataset:	 0.49573493003845215
2022-11-03 01:15:45,025:INFO: 		 ADE on zara2                     dataset:	 0.4191243648529053
2022-11-03 01:15:45,026:INFO: Average training:	ADE  0.5107	FDE  1.0752
2022-11-03 01:15:45,034:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_505.pth.tar
2022-11-03 01:15:45,034:INFO: 
===> EPOCH: 506 (P3)
2022-11-03 01:15:45,035:INFO: - Computing loss (training)
2022-11-03 01:15:46,134:INFO: Batch:  0/31	Total Loss 3.9349 (3.9349)
2022-11-03 01:15:46,614:INFO: Batch:  1/31	Total Loss 4.3697 (4.1628)
2022-11-03 01:15:47,102:INFO: Batch:  2/31	Total Loss 3.9848 (4.1044)
2022-11-03 01:15:47,580:INFO: Batch:  3/31	Total Loss 3.6229 (3.9813)
2022-11-03 01:15:48,061:INFO: Batch:  4/31	Total Loss 4.0332 (3.9920)
2022-11-03 01:15:48,539:INFO: Batch:  5/31	Total Loss 4.4351 (4.0741)
2022-11-03 01:15:49,017:INFO: Batch:  6/31	Total Loss 4.1956 (4.0891)
2022-11-03 01:15:49,488:INFO: Batch:  7/31	Total Loss 3.7815 (4.0438)
2022-11-03 01:15:49,960:INFO: Batch:  8/31	Total Loss 4.0764 (4.0478)
2022-11-03 01:15:50,435:INFO: Batch:  9/31	Total Loss 4.3645 (4.0761)
2022-11-03 01:15:50,910:INFO: Batch: 10/31	Total Loss 4.4547 (4.1088)
2022-11-03 01:15:51,382:INFO: Batch: 11/31	Total Loss 4.7750 (4.1681)
2022-11-03 01:15:51,857:INFO: Batch: 12/31	Total Loss 3.7919 (4.1403)
2022-11-03 01:15:52,334:INFO: Batch: 13/31	Total Loss 4.2304 (4.1470)
2022-11-03 01:15:52,809:INFO: Batch: 14/31	Total Loss 3.7614 (4.1237)
2022-11-03 01:15:53,285:INFO: Batch: 15/31	Total Loss 4.2135 (4.1290)
2022-11-03 01:15:53,836:INFO: Batch: 16/31	Total Loss 4.1738 (4.1314)
2022-11-03 01:15:54,313:INFO: Batch: 17/31	Total Loss 3.9941 (4.1238)
2022-11-03 01:15:54,788:INFO: Batch: 18/31	Total Loss 4.5574 (4.1447)
2022-11-03 01:15:55,263:INFO: Batch: 19/31	Total Loss 3.6351 (4.1173)
2022-11-03 01:15:55,738:INFO: Batch: 20/31	Total Loss 3.6985 (4.0980)
2022-11-03 01:15:56,214:INFO: Batch: 21/31	Total Loss 4.5480 (4.1182)
2022-11-03 01:15:56,688:INFO: Batch: 22/31	Total Loss 4.9291 (4.1593)
2022-11-03 01:15:57,164:INFO: Batch: 23/31	Total Loss 3.9775 (4.1513)
2022-11-03 01:15:57,639:INFO: Batch: 24/31	Total Loss 4.3408 (4.1585)
2022-11-03 01:15:58,114:INFO: Batch: 25/31	Total Loss 5.3719 (4.2094)
2022-11-03 01:15:58,590:INFO: Batch: 26/31	Total Loss 4.5063 (4.2208)
2022-11-03 01:15:59,065:INFO: Batch: 27/31	Total Loss 4.8476 (4.2433)
2022-11-03 01:15:59,542:INFO: Batch: 28/31	Total Loss 4.5976 (4.2535)
2022-11-03 01:16:00,018:INFO: Batch: 29/31	Total Loss 4.1516 (4.2503)
2022-11-03 01:16:00,409:INFO: Batch: 30/31	Total Loss 1.7743 (4.2327)
2022-11-03 01:16:00,561:INFO: - Computing ADE (validation o)
2022-11-03 01:16:01,149:INFO: 		 ADE on eth                       dataset:	 0.9437201619148254
2022-11-03 01:16:01,149:INFO: Average validation o:	ADE  0.9437	FDE  1.8359
2022-11-03 01:16:01,149:INFO: - Computing ADE (validation)
2022-11-03 01:16:01,437:INFO: 		 ADE on hotel                     dataset:	 0.4552716910839081
2022-11-03 01:16:01,752:INFO: 		 ADE on univ                      dataset:	 0.5597292184829712
2022-11-03 01:16:01,999:INFO: 		 ADE on zara1                     dataset:	 0.40719637274742126
2022-11-03 01:16:02,353:INFO: 		 ADE on zara2                     dataset:	 0.4289291799068451
2022-11-03 01:16:02,354:INFO: Average validation:	ADE  0.4972	FDE  1.0457
2022-11-03 01:16:02,354:INFO: - Computing ADE (training)
2022-11-03 01:16:02,796:INFO: 		 ADE on hotel                     dataset:	 0.4714088439941406
2022-11-03 01:16:03,472:INFO: 		 ADE on univ                      dataset:	 0.5531831383705139
2022-11-03 01:16:04,023:INFO: 		 ADE on zara1                     dataset:	 0.4891451299190521
2022-11-03 01:16:04,772:INFO: 		 ADE on zara2                     dataset:	 0.4329656660556793
2022-11-03 01:16:04,772:INFO: Average training:	ADE  0.5226	FDE  1.1037
2022-11-03 01:16:04,780:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_506.pth.tar
2022-11-03 01:16:04,780:INFO: 
===> EPOCH: 507 (P3)
2022-11-03 01:16:04,780:INFO: - Computing loss (training)
2022-11-03 01:16:05,857:INFO: Batch:  0/31	Total Loss 4.2295 (4.2295)
2022-11-03 01:16:06,345:INFO: Batch:  1/31	Total Loss 3.7728 (3.9748)
2022-11-03 01:16:06,827:INFO: Batch:  2/31	Total Loss 4.6336 (4.1914)
2022-11-03 01:16:07,306:INFO: Batch:  3/31	Total Loss 4.0890 (4.1681)
2022-11-03 01:16:07,784:INFO: Batch:  4/31	Total Loss 4.4189 (4.2196)
2022-11-03 01:16:08,268:INFO: Batch:  5/31	Total Loss 4.1815 (4.2133)
2022-11-03 01:16:08,746:INFO: Batch:  6/31	Total Loss 5.2723 (4.3593)
2022-11-03 01:16:09,227:INFO: Batch:  7/31	Total Loss 4.2383 (4.3453)
2022-11-03 01:16:09,704:INFO: Batch:  8/31	Total Loss 4.0374 (4.3158)
2022-11-03 01:16:10,182:INFO: Batch:  9/31	Total Loss 3.4804 (4.2337)
2022-11-03 01:16:10,664:INFO: Batch: 10/31	Total Loss 4.3952 (4.2464)
2022-11-03 01:16:11,143:INFO: Batch: 11/31	Total Loss 4.1402 (4.2383)
2022-11-03 01:16:11,628:INFO: Batch: 12/31	Total Loss 5.9904 (4.3874)
2022-11-03 01:16:12,115:INFO: Batch: 13/31	Total Loss 4.1838 (4.3723)
2022-11-03 01:16:12,600:INFO: Batch: 14/31	Total Loss 3.6802 (4.3222)
2022-11-03 01:16:13,084:INFO: Batch: 15/31	Total Loss 3.9746 (4.3014)
2022-11-03 01:16:13,571:INFO: Batch: 16/31	Total Loss 3.5382 (4.2600)
2022-11-03 01:16:14,055:INFO: Batch: 17/31	Total Loss 4.2362 (4.2585)
2022-11-03 01:16:14,540:INFO: Batch: 18/31	Total Loss 4.6863 (4.2800)
2022-11-03 01:16:15,027:INFO: Batch: 19/31	Total Loss 4.2235 (4.2771)
2022-11-03 01:16:15,510:INFO: Batch: 20/31	Total Loss 3.7447 (4.2525)
2022-11-03 01:16:15,996:INFO: Batch: 21/31	Total Loss 3.7327 (4.2287)
2022-11-03 01:16:16,479:INFO: Batch: 22/31	Total Loss 4.1769 (4.2264)
2022-11-03 01:16:16,962:INFO: Batch: 23/31	Total Loss 4.3409 (4.2312)
2022-11-03 01:16:17,444:INFO: Batch: 24/31	Total Loss 4.3585 (4.2368)
2022-11-03 01:16:17,929:INFO: Batch: 25/31	Total Loss 3.7882 (4.2199)
2022-11-03 01:16:18,412:INFO: Batch: 26/31	Total Loss 4.2092 (4.2195)
2022-11-03 01:16:18,894:INFO: Batch: 27/31	Total Loss 4.2243 (4.2197)
2022-11-03 01:16:19,377:INFO: Batch: 28/31	Total Loss 3.8918 (4.2084)
2022-11-03 01:16:19,859:INFO: Batch: 29/31	Total Loss 4.0473 (4.2026)
2022-11-03 01:16:20,257:INFO: Batch: 30/31	Total Loss 1.5081 (4.1716)
2022-11-03 01:16:20,412:INFO: - Computing ADE (validation o)
2022-11-03 01:16:21,012:INFO: 		 ADE on eth                       dataset:	 0.9372403621673584
2022-11-03 01:16:21,012:INFO: Average validation o:	ADE  0.9372	FDE  1.8623
2022-11-03 01:16:21,013:INFO: - Computing ADE (validation)
2022-11-03 01:16:21,300:INFO: 		 ADE on hotel                     dataset:	 0.4133760929107666
2022-11-03 01:16:21,607:INFO: 		 ADE on univ                      dataset:	 0.5483778715133667
2022-11-03 01:16:21,847:INFO: 		 ADE on zara1                     dataset:	 0.4128280580043793
2022-11-03 01:16:22,211:INFO: 		 ADE on zara2                     dataset:	 0.39410072565078735
2022-11-03 01:16:22,211:INFO: Average validation:	ADE  0.4765	FDE  0.9869
2022-11-03 01:16:22,212:INFO: - Computing ADE (training)
2022-11-03 01:16:22,687:INFO: 		 ADE on hotel                     dataset:	 0.43777456879615784
2022-11-03 01:16:23,411:INFO: 		 ADE on univ                      dataset:	 0.5389674305915833
2022-11-03 01:16:23,945:INFO: 		 ADE on zara1                     dataset:	 0.4640158414840698
2022-11-03 01:16:24,686:INFO: 		 ADE on zara2                     dataset:	 0.39608287811279297
2022-11-03 01:16:24,686:INFO: Average training:	ADE  0.5026	FDE  1.0477
2022-11-03 01:16:24,696:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_507.pth.tar
2022-11-03 01:16:24,696:INFO: 
===> EPOCH: 508 (P3)
2022-11-03 01:16:24,696:INFO: - Computing loss (training)
2022-11-03 01:16:25,815:INFO: Batch:  0/31	Total Loss 4.0392 (4.0392)
2022-11-03 01:16:26,302:INFO: Batch:  1/31	Total Loss 3.8361 (3.9485)
2022-11-03 01:16:26,791:INFO: Batch:  2/31	Total Loss 4.6399 (4.1768)
2022-11-03 01:16:27,268:INFO: Batch:  3/31	Total Loss 4.0246 (4.1382)
2022-11-03 01:16:27,747:INFO: Batch:  4/31	Total Loss 4.0650 (4.1216)
2022-11-03 01:16:28,229:INFO: Batch:  5/31	Total Loss 4.4006 (4.1694)
2022-11-03 01:16:28,709:INFO: Batch:  6/31	Total Loss 4.0111 (4.1451)
2022-11-03 01:16:29,186:INFO: Batch:  7/31	Total Loss 4.3071 (4.1625)
2022-11-03 01:16:29,669:INFO: Batch:  8/31	Total Loss 5.2558 (4.2806)
2022-11-03 01:16:30,148:INFO: Batch:  9/31	Total Loss 3.6948 (4.2169)
2022-11-03 01:16:30,630:INFO: Batch: 10/31	Total Loss 4.2876 (4.2241)
2022-11-03 01:16:31,108:INFO: Batch: 11/31	Total Loss 4.9427 (4.2818)
2022-11-03 01:16:31,587:INFO: Batch: 12/31	Total Loss 4.2311 (4.2780)
2022-11-03 01:16:32,066:INFO: Batch: 13/31	Total Loss 4.1225 (4.2664)
2022-11-03 01:16:32,542:INFO: Batch: 14/31	Total Loss 4.1966 (4.2619)
2022-11-03 01:16:33,021:INFO: Batch: 15/31	Total Loss 4.3608 (4.2674)
2022-11-03 01:16:33,497:INFO: Batch: 16/31	Total Loss 3.9724 (4.2490)
2022-11-03 01:16:33,974:INFO: Batch: 17/31	Total Loss 4.3312 (4.2529)
2022-11-03 01:16:34,453:INFO: Batch: 18/31	Total Loss 4.5767 (4.2707)
2022-11-03 01:16:34,930:INFO: Batch: 19/31	Total Loss 5.0004 (4.3008)
2022-11-03 01:16:35,406:INFO: Batch: 20/31	Total Loss 4.2171 (4.2968)
2022-11-03 01:16:35,881:INFO: Batch: 21/31	Total Loss 4.2165 (4.2932)
2022-11-03 01:16:36,358:INFO: Batch: 22/31	Total Loss 4.5616 (4.3040)
2022-11-03 01:16:36,834:INFO: Batch: 23/31	Total Loss 4.5713 (4.3165)
2022-11-03 01:16:37,309:INFO: Batch: 24/31	Total Loss 4.2333 (4.3130)
2022-11-03 01:16:37,786:INFO: Batch: 25/31	Total Loss 4.5867 (4.3227)
2022-11-03 01:16:38,262:INFO: Batch: 26/31	Total Loss 4.1214 (4.3157)
2022-11-03 01:16:38,737:INFO: Batch: 27/31	Total Loss 4.2631 (4.3139)
2022-11-03 01:16:39,213:INFO: Batch: 28/31	Total Loss 4.4655 (4.3192)
2022-11-03 01:16:39,690:INFO: Batch: 29/31	Total Loss 4.1259 (4.3130)
2022-11-03 01:16:40,084:INFO: Batch: 30/31	Total Loss 1.5595 (4.2859)
2022-11-03 01:16:40,231:INFO: - Computing ADE (validation o)
2022-11-03 01:16:40,815:INFO: 		 ADE on eth                       dataset:	 0.9621945023536682
2022-11-03 01:16:40,815:INFO: Average validation o:	ADE  0.9622	FDE  1.9156
2022-11-03 01:16:40,816:INFO: - Computing ADE (validation)
2022-11-03 01:16:41,081:INFO: 		 ADE on hotel                     dataset:	 0.45878949761390686
2022-11-03 01:16:41,364:INFO: 		 ADE on univ                      dataset:	 0.5712745785713196
2022-11-03 01:16:41,612:INFO: 		 ADE on zara1                     dataset:	 0.46180444955825806
2022-11-03 01:16:41,963:INFO: 		 ADE on zara2                     dataset:	 0.45178961753845215
2022-11-03 01:16:41,963:INFO: Average validation:	ADE  0.5149	FDE  1.0963
2022-11-03 01:16:41,964:INFO: - Computing ADE (training)
2022-11-03 01:16:42,415:INFO: 		 ADE on hotel                     dataset:	 0.48646512627601624
2022-11-03 01:16:43,091:INFO: 		 ADE on univ                      dataset:	 0.5699241757392883
2022-11-03 01:16:43,639:INFO: 		 ADE on zara1                     dataset:	 0.5016887784004211
2022-11-03 01:16:44,442:INFO: 		 ADE on zara2                     dataset:	 0.4530583322048187
2022-11-03 01:16:44,443:INFO: Average training:	ADE  0.5397	FDE  1.1544
2022-11-03 01:16:44,452:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_508.pth.tar
2022-11-03 01:16:44,452:INFO: 
===> EPOCH: 509 (P3)
2022-11-03 01:16:44,452:INFO: - Computing loss (training)
2022-11-03 01:16:45,549:INFO: Batch:  0/31	Total Loss 4.2972 (4.2972)
2022-11-03 01:16:46,022:INFO: Batch:  1/31	Total Loss 4.1679 (4.2319)
2022-11-03 01:16:46,492:INFO: Batch:  2/31	Total Loss 4.1545 (4.2078)
2022-11-03 01:16:46,963:INFO: Batch:  3/31	Total Loss 4.3140 (4.2338)
2022-11-03 01:16:47,429:INFO: Batch:  4/31	Total Loss 3.7277 (4.1314)
2022-11-03 01:16:47,900:INFO: Batch:  5/31	Total Loss 4.4660 (4.1902)
2022-11-03 01:16:48,367:INFO: Batch:  6/31	Total Loss 3.7103 (4.1174)
2022-11-03 01:16:48,909:INFO: Batch:  7/31	Total Loss 3.9237 (4.0918)
2022-11-03 01:16:49,377:INFO: Batch:  8/31	Total Loss 4.2243 (4.1070)
2022-11-03 01:16:49,843:INFO: Batch:  9/31	Total Loss 4.1156 (4.1078)
2022-11-03 01:16:50,311:INFO: Batch: 10/31	Total Loss 4.5202 (4.1469)
2022-11-03 01:16:50,779:INFO: Batch: 11/31	Total Loss 3.6101 (4.1032)
2022-11-03 01:16:51,249:INFO: Batch: 12/31	Total Loss 3.8591 (4.0878)
2022-11-03 01:16:51,718:INFO: Batch: 13/31	Total Loss 3.8090 (4.0689)
2022-11-03 01:16:52,189:INFO: Batch: 14/31	Total Loss 4.5803 (4.1019)
2022-11-03 01:16:52,663:INFO: Batch: 15/31	Total Loss 4.5399 (4.1276)
2022-11-03 01:16:53,135:INFO: Batch: 16/31	Total Loss 4.5332 (4.1506)
2022-11-03 01:16:53,605:INFO: Batch: 17/31	Total Loss 3.7861 (4.1291)
2022-11-03 01:16:54,076:INFO: Batch: 18/31	Total Loss 4.2737 (4.1364)
2022-11-03 01:16:54,547:INFO: Batch: 19/31	Total Loss 4.5906 (4.1585)
2022-11-03 01:16:55,019:INFO: Batch: 20/31	Total Loss 3.8658 (4.1461)
2022-11-03 01:16:55,486:INFO: Batch: 21/31	Total Loss 4.0924 (4.1437)
2022-11-03 01:16:55,960:INFO: Batch: 22/31	Total Loss 4.1000 (4.1416)
2022-11-03 01:16:56,430:INFO: Batch: 23/31	Total Loss 4.5912 (4.1589)
2022-11-03 01:16:56,907:INFO: Batch: 24/31	Total Loss 3.7137 (4.1418)
2022-11-03 01:16:57,375:INFO: Batch: 25/31	Total Loss 4.4965 (4.1539)
2022-11-03 01:16:57,853:INFO: Batch: 26/31	Total Loss 3.8540 (4.1433)
2022-11-03 01:16:58,323:INFO: Batch: 27/31	Total Loss 4.8546 (4.1703)
2022-11-03 01:16:58,792:INFO: Batch: 28/31	Total Loss 3.4334 (4.1450)
2022-11-03 01:16:59,261:INFO: Batch: 29/31	Total Loss 4.5793 (4.1599)
2022-11-03 01:16:59,645:INFO: Batch: 30/31	Total Loss 1.5231 (4.1315)
2022-11-03 01:16:59,796:INFO: - Computing ADE (validation o)
2022-11-03 01:17:00,405:INFO: 		 ADE on eth                       dataset:	 0.9743038415908813
2022-11-03 01:17:00,405:INFO: Average validation o:	ADE  0.9743	FDE  1.9732
2022-11-03 01:17:00,406:INFO: - Computing ADE (validation)
2022-11-03 01:17:00,685:INFO: 		 ADE on hotel                     dataset:	 0.47503066062927246
2022-11-03 01:17:00,970:INFO: 		 ADE on univ                      dataset:	 0.5983490943908691
2022-11-03 01:17:01,242:INFO: 		 ADE on zara1                     dataset:	 0.5098734498023987
2022-11-03 01:17:01,590:INFO: 		 ADE on zara2                     dataset:	 0.48916688561439514
2022-11-03 01:17:01,590:INFO: Average validation:	ADE  0.5464	FDE  1.1875
2022-11-03 01:17:01,591:INFO: - Computing ADE (training)
2022-11-03 01:17:02,047:INFO: 		 ADE on hotel                     dataset:	 0.4953061640262604
2022-11-03 01:17:02,739:INFO: 		 ADE on univ                      dataset:	 0.5957425236701965
2022-11-03 01:17:03,256:INFO: 		 ADE on zara1                     dataset:	 0.5271889567375183
2022-11-03 01:17:04,010:INFO: 		 ADE on zara2                     dataset:	 0.49078384041786194
2022-11-03 01:17:04,010:INFO: Average training:	ADE  0.5675	FDE  1.2382
2022-11-03 01:17:04,018:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_509.pth.tar
2022-11-03 01:17:04,018:INFO: 
===> EPOCH: 510 (P3)
2022-11-03 01:17:04,019:INFO: - Computing loss (training)
2022-11-03 01:17:05,086:INFO: Batch:  0/31	Total Loss 4.2374 (4.2374)
2022-11-03 01:17:05,553:INFO: Batch:  1/31	Total Loss 4.2353 (4.2364)
2022-11-03 01:17:06,030:INFO: Batch:  2/31	Total Loss 3.9570 (4.1462)
2022-11-03 01:17:06,493:INFO: Batch:  3/31	Total Loss 3.9695 (4.0986)
2022-11-03 01:17:06,963:INFO: Batch:  4/31	Total Loss 4.4965 (4.1753)
2022-11-03 01:17:07,433:INFO: Batch:  5/31	Total Loss 3.7726 (4.1073)
2022-11-03 01:17:07,902:INFO: Batch:  6/31	Total Loss 4.4455 (4.1577)
2022-11-03 01:17:08,368:INFO: Batch:  7/31	Total Loss 4.1769 (4.1596)
2022-11-03 01:17:08,833:INFO: Batch:  8/31	Total Loss 4.4163 (4.1867)
2022-11-03 01:17:09,297:INFO: Batch:  9/31	Total Loss 4.1395 (4.1824)
2022-11-03 01:17:09,764:INFO: Batch: 10/31	Total Loss 4.0646 (4.1720)
2022-11-03 01:17:10,230:INFO: Batch: 11/31	Total Loss 3.8480 (4.1438)
2022-11-03 01:17:10,705:INFO: Batch: 12/31	Total Loss 4.0695 (4.1384)
2022-11-03 01:17:11,177:INFO: Batch: 13/31	Total Loss 4.6711 (4.1731)
2022-11-03 01:17:11,650:INFO: Batch: 14/31	Total Loss 3.8871 (4.1544)
2022-11-03 01:17:12,122:INFO: Batch: 15/31	Total Loss 4.4789 (4.1765)
2022-11-03 01:17:12,593:INFO: Batch: 16/31	Total Loss 3.9795 (4.1639)
2022-11-03 01:17:13,063:INFO: Batch: 17/31	Total Loss 4.2726 (4.1695)
2022-11-03 01:17:13,532:INFO: Batch: 18/31	Total Loss 4.1997 (4.1708)
2022-11-03 01:17:14,004:INFO: Batch: 19/31	Total Loss 3.6888 (4.1447)
2022-11-03 01:17:14,473:INFO: Batch: 20/31	Total Loss 3.6697 (4.1237)
2022-11-03 01:17:14,946:INFO: Batch: 21/31	Total Loss 4.3262 (4.1325)
2022-11-03 01:17:15,416:INFO: Batch: 22/31	Total Loss 4.4088 (4.1451)
2022-11-03 01:17:15,887:INFO: Batch: 23/31	Total Loss 4.4649 (4.1576)
2022-11-03 01:17:16,356:INFO: Batch: 24/31	Total Loss 3.8719 (4.1454)
2022-11-03 01:17:16,824:INFO: Batch: 25/31	Total Loss 4.2783 (4.1508)
2022-11-03 01:17:17,293:INFO: Batch: 26/31	Total Loss 4.1991 (4.1523)
2022-11-03 01:17:17,762:INFO: Batch: 27/31	Total Loss 4.0028 (4.1470)
2022-11-03 01:17:18,232:INFO: Batch: 28/31	Total Loss 3.9418 (4.1402)
2022-11-03 01:17:18,703:INFO: Batch: 29/31	Total Loss 4.1012 (4.1390)
2022-11-03 01:17:19,088:INFO: Batch: 30/31	Total Loss 1.3946 (4.1101)
2022-11-03 01:17:19,241:INFO: - Computing ADE (validation o)
2022-11-03 01:17:19,827:INFO: 		 ADE on eth                       dataset:	 0.9221903085708618
2022-11-03 01:17:19,828:INFO: Average validation o:	ADE  0.9222	FDE  1.8154
2022-11-03 01:17:19,828:INFO: - Computing ADE (validation)
2022-11-03 01:17:20,087:INFO: 		 ADE on hotel                     dataset:	 0.4138249456882477
2022-11-03 01:17:20,396:INFO: 		 ADE on univ                      dataset:	 0.5469568967819214
2022-11-03 01:17:20,642:INFO: 		 ADE on zara1                     dataset:	 0.4052005112171173
2022-11-03 01:17:20,999:INFO: 		 ADE on zara2                     dataset:	 0.3933972716331482
2022-11-03 01:17:20,999:INFO: Average validation:	ADE  0.4751	FDE  0.9872
2022-11-03 01:17:21,000:INFO: - Computing ADE (training)
2022-11-03 01:17:21,432:INFO: 		 ADE on hotel                     dataset:	 0.4295197129249573
2022-11-03 01:17:22,115:INFO: 		 ADE on univ                      dataset:	 0.5382266044616699
2022-11-03 01:17:22,690:INFO: 		 ADE on zara1                     dataset:	 0.45479679107666016
2022-11-03 01:17:23,443:INFO: 		 ADE on zara2                     dataset:	 0.3903011977672577
2022-11-03 01:17:23,443:INFO: Average training:	ADE  0.5001	FDE  1.0445
2022-11-03 01:17:23,452:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_510.pth.tar
2022-11-03 01:17:23,452:INFO: 
===> EPOCH: 511 (P3)
2022-11-03 01:17:23,452:INFO: - Computing loss (training)
2022-11-03 01:17:24,574:INFO: Batch:  0/31	Total Loss 4.4297 (4.4297)
2022-11-03 01:17:25,053:INFO: Batch:  1/31	Total Loss 4.2000 (4.3273)
2022-11-03 01:17:25,534:INFO: Batch:  2/31	Total Loss 4.1320 (4.2557)
2022-11-03 01:17:26,002:INFO: Batch:  3/31	Total Loss 4.4977 (4.3203)
2022-11-03 01:17:26,469:INFO: Batch:  4/31	Total Loss 4.2502 (4.3059)
2022-11-03 01:17:26,942:INFO: Batch:  5/31	Total Loss 4.0190 (4.2591)
2022-11-03 01:17:27,412:INFO: Batch:  6/31	Total Loss 4.4779 (4.2886)
2022-11-03 01:17:27,877:INFO: Batch:  7/31	Total Loss 4.2014 (4.2771)
2022-11-03 01:17:28,345:INFO: Batch:  8/31	Total Loss 4.0479 (4.2491)
2022-11-03 01:17:28,808:INFO: Batch:  9/31	Total Loss 3.9982 (4.2238)
2022-11-03 01:17:29,279:INFO: Batch: 10/31	Total Loss 3.9588 (4.1997)
2022-11-03 01:17:29,746:INFO: Batch: 11/31	Total Loss 3.8488 (4.1681)
2022-11-03 01:17:30,217:INFO: Batch: 12/31	Total Loss 3.5927 (4.1241)
2022-11-03 01:17:30,690:INFO: Batch: 13/31	Total Loss 4.5152 (4.1527)
2022-11-03 01:17:31,161:INFO: Batch: 14/31	Total Loss 3.7702 (4.1267)
2022-11-03 01:17:31,631:INFO: Batch: 15/31	Total Loss 4.1451 (4.1277)
2022-11-03 01:17:32,102:INFO: Batch: 16/31	Total Loss 4.8089 (4.1649)
2022-11-03 01:17:32,571:INFO: Batch: 17/31	Total Loss 3.8291 (4.1467)
2022-11-03 01:17:33,041:INFO: Batch: 18/31	Total Loss 3.9522 (4.1373)
2022-11-03 01:17:33,509:INFO: Batch: 19/31	Total Loss 4.3855 (4.1486)
2022-11-03 01:17:33,977:INFO: Batch: 20/31	Total Loss 4.0515 (4.1436)
2022-11-03 01:17:34,446:INFO: Batch: 21/31	Total Loss 4.6593 (4.1668)
2022-11-03 01:17:34,915:INFO: Batch: 22/31	Total Loss 4.6536 (4.1880)
2022-11-03 01:17:35,383:INFO: Batch: 23/31	Total Loss 4.6728 (4.2070)
2022-11-03 01:17:35,851:INFO: Batch: 24/31	Total Loss 3.7591 (4.1891)
2022-11-03 01:17:36,319:INFO: Batch: 25/31	Total Loss 4.1216 (4.1863)
2022-11-03 01:17:36,786:INFO: Batch: 26/31	Total Loss 4.0038 (4.1795)
2022-11-03 01:17:37,254:INFO: Batch: 27/31	Total Loss 4.4126 (4.1877)
2022-11-03 01:17:37,726:INFO: Batch: 28/31	Total Loss 4.0546 (4.1830)
2022-11-03 01:17:38,211:INFO: Batch: 29/31	Total Loss 3.9207 (4.1735)
2022-11-03 01:17:38,610:INFO: Batch: 30/31	Total Loss 1.5229 (4.1471)
2022-11-03 01:17:38,751:INFO: - Computing ADE (validation o)
2022-11-03 01:17:39,323:INFO: 		 ADE on eth                       dataset:	 0.9308068156242371
2022-11-03 01:17:39,323:INFO: Average validation o:	ADE  0.9308	FDE  1.8237
2022-11-03 01:17:39,324:INFO: - Computing ADE (validation)
2022-11-03 01:17:39,588:INFO: 		 ADE on hotel                     dataset:	 0.40604257583618164
2022-11-03 01:17:39,898:INFO: 		 ADE on univ                      dataset:	 0.5480523109436035
2022-11-03 01:17:40,161:INFO: 		 ADE on zara1                     dataset:	 0.4160676598548889
2022-11-03 01:17:40,496:INFO: 		 ADE on zara2                     dataset:	 0.39764025807380676
2022-11-03 01:17:40,496:INFO: Average validation:	ADE  0.4774	FDE  1.0000
2022-11-03 01:17:40,497:INFO: - Computing ADE (training)
2022-11-03 01:17:40,966:INFO: 		 ADE on hotel                     dataset:	 0.4226706027984619
2022-11-03 01:17:41,656:INFO: 		 ADE on univ                      dataset:	 0.5335730910301208
2022-11-03 01:17:42,184:INFO: 		 ADE on zara1                     dataset:	 0.4724613130092621
2022-11-03 01:17:43,028:INFO: 		 ADE on zara2                     dataset:	 0.39975664019584656
2022-11-03 01:17:43,028:INFO: Average training:	ADE  0.4997	FDE  1.0502
2022-11-03 01:17:43,045:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_511.pth.tar
2022-11-03 01:17:43,045:INFO: 
===> EPOCH: 512 (P3)
2022-11-03 01:17:43,045:INFO: - Computing loss (training)
2022-11-03 01:17:44,157:INFO: Batch:  0/31	Total Loss 3.8708 (3.8708)
2022-11-03 01:17:44,626:INFO: Batch:  1/31	Total Loss 3.9976 (3.9343)
2022-11-03 01:17:45,099:INFO: Batch:  2/31	Total Loss 4.1574 (4.0057)
2022-11-03 01:17:45,566:INFO: Batch:  3/31	Total Loss 4.8891 (4.2151)
2022-11-03 01:17:46,035:INFO: Batch:  4/31	Total Loss 4.2866 (4.2304)
2022-11-03 01:17:46,509:INFO: Batch:  5/31	Total Loss 4.0276 (4.2000)
2022-11-03 01:17:46,979:INFO: Batch:  6/31	Total Loss 4.1995 (4.2000)
2022-11-03 01:17:47,450:INFO: Batch:  7/31	Total Loss 4.2739 (4.2096)
2022-11-03 01:17:47,921:INFO: Batch:  8/31	Total Loss 3.9635 (4.1833)
2022-11-03 01:17:48,392:INFO: Batch:  9/31	Total Loss 3.8123 (4.1440)
2022-11-03 01:17:48,863:INFO: Batch: 10/31	Total Loss 4.1054 (4.1403)
2022-11-03 01:17:49,332:INFO: Batch: 11/31	Total Loss 4.1435 (4.1406)
2022-11-03 01:17:49,805:INFO: Batch: 12/31	Total Loss 3.6889 (4.1050)
2022-11-03 01:17:50,280:INFO: Batch: 13/31	Total Loss 3.9390 (4.0941)
2022-11-03 01:17:50,756:INFO: Batch: 14/31	Total Loss 4.3448 (4.1107)
2022-11-03 01:17:51,234:INFO: Batch: 15/31	Total Loss 3.8657 (4.0945)
2022-11-03 01:17:51,708:INFO: Batch: 16/31	Total Loss 4.5104 (4.1185)
2022-11-03 01:17:52,183:INFO: Batch: 17/31	Total Loss 4.3669 (4.1330)
2022-11-03 01:17:52,663:INFO: Batch: 18/31	Total Loss 4.3814 (4.1458)
2022-11-03 01:17:53,138:INFO: Batch: 19/31	Total Loss 3.8281 (4.1285)
2022-11-03 01:17:53,616:INFO: Batch: 20/31	Total Loss 4.5774 (4.1515)
2022-11-03 01:17:54,091:INFO: Batch: 21/31	Total Loss 3.9222 (4.1398)
2022-11-03 01:17:54,567:INFO: Batch: 22/31	Total Loss 4.1618 (4.1408)
2022-11-03 01:17:55,043:INFO: Batch: 23/31	Total Loss 4.6438 (4.1601)
2022-11-03 01:17:55,517:INFO: Batch: 24/31	Total Loss 4.5326 (4.1749)
2022-11-03 01:17:55,991:INFO: Batch: 25/31	Total Loss 4.0461 (4.1697)
2022-11-03 01:17:56,465:INFO: Batch: 26/31	Total Loss 4.2965 (4.1746)
2022-11-03 01:17:56,940:INFO: Batch: 27/31	Total Loss 4.2285 (4.1764)
2022-11-03 01:17:57,414:INFO: Batch: 28/31	Total Loss 4.1316 (4.1749)
2022-11-03 01:17:57,888:INFO: Batch: 29/31	Total Loss 3.7644 (4.1609)
2022-11-03 01:17:58,277:INFO: Batch: 30/31	Total Loss 1.4876 (4.1444)
2022-11-03 01:17:58,430:INFO: - Computing ADE (validation o)
2022-11-03 01:17:59,006:INFO: 		 ADE on eth                       dataset:	 0.955830454826355
2022-11-03 01:17:59,007:INFO: Average validation o:	ADE  0.9558	FDE  1.9258
2022-11-03 01:17:59,007:INFO: - Computing ADE (validation)
2022-11-03 01:17:59,276:INFO: 		 ADE on hotel                     dataset:	 0.47379544377326965
2022-11-03 01:17:59,557:INFO: 		 ADE on univ                      dataset:	 0.5781851410865784
2022-11-03 01:17:59,811:INFO: 		 ADE on zara1                     dataset:	 0.4502095878124237
2022-11-03 01:18:00,159:INFO: 		 ADE on zara2                     dataset:	 0.45152097940444946
2022-11-03 01:18:00,159:INFO: Average validation:	ADE  0.5186	FDE  1.1115
2022-11-03 01:18:00,160:INFO: - Computing ADE (training)
2022-11-03 01:18:00,614:INFO: 		 ADE on hotel                     dataset:	 0.5070245862007141
2022-11-03 01:18:01,304:INFO: 		 ADE on univ                      dataset:	 0.5754610896110535
2022-11-03 01:18:01,845:INFO: 		 ADE on zara1                     dataset:	 0.4828944802284241
2022-11-03 01:18:02,584:INFO: 		 ADE on zara2                     dataset:	 0.44757217168807983
2022-11-03 01:18:02,584:INFO: Average training:	ADE  0.5419	FDE  1.1659
2022-11-03 01:18:02,593:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_512.pth.tar
2022-11-03 01:18:02,594:INFO: 
===> EPOCH: 513 (P3)
2022-11-03 01:18:02,594:INFO: - Computing loss (training)
2022-11-03 01:18:03,692:INFO: Batch:  0/31	Total Loss 4.9188 (4.9188)
2022-11-03 01:18:04,167:INFO: Batch:  1/31	Total Loss 4.3325 (4.6240)
2022-11-03 01:18:04,641:INFO: Batch:  2/31	Total Loss 3.8304 (4.3627)
2022-11-03 01:18:05,111:INFO: Batch:  3/31	Total Loss 4.0631 (4.2779)
2022-11-03 01:18:05,583:INFO: Batch:  4/31	Total Loss 4.2689 (4.2758)
2022-11-03 01:18:06,059:INFO: Batch:  5/31	Total Loss 4.2142 (4.2647)
2022-11-03 01:18:06,532:INFO: Batch:  6/31	Total Loss 4.6564 (4.3232)
2022-11-03 01:18:07,004:INFO: Batch:  7/31	Total Loss 3.9416 (4.2763)
2022-11-03 01:18:07,474:INFO: Batch:  8/31	Total Loss 4.4403 (4.2958)
2022-11-03 01:18:07,946:INFO: Batch:  9/31	Total Loss 3.7622 (4.2410)
2022-11-03 01:18:08,420:INFO: Batch: 10/31	Total Loss 4.1839 (4.2356)
2022-11-03 01:18:08,914:INFO: Batch: 11/31	Total Loss 4.3516 (4.2451)
2022-11-03 01:18:09,455:INFO: Batch: 12/31	Total Loss 4.8005 (4.2840)
2022-11-03 01:18:09,943:INFO: Batch: 13/31	Total Loss 4.6822 (4.3137)
2022-11-03 01:18:10,425:INFO: Batch: 14/31	Total Loss 4.8182 (4.3473)
2022-11-03 01:18:10,903:INFO: Batch: 15/31	Total Loss 4.5842 (4.3612)
2022-11-03 01:18:11,377:INFO: Batch: 16/31	Total Loss 4.1995 (4.3529)
2022-11-03 01:18:11,851:INFO: Batch: 17/31	Total Loss 4.0422 (4.3351)
2022-11-03 01:18:12,322:INFO: Batch: 18/31	Total Loss 3.9331 (4.3156)
2022-11-03 01:18:12,793:INFO: Batch: 19/31	Total Loss 4.5031 (4.3257)
2022-11-03 01:18:13,268:INFO: Batch: 20/31	Total Loss 5.2638 (4.3739)
2022-11-03 01:18:13,739:INFO: Batch: 21/31	Total Loss 4.1444 (4.3633)
2022-11-03 01:18:14,210:INFO: Batch: 22/31	Total Loss 4.0523 (4.3482)
2022-11-03 01:18:14,682:INFO: Batch: 23/31	Total Loss 4.3731 (4.3492)
2022-11-03 01:18:15,158:INFO: Batch: 24/31	Total Loss 4.8931 (4.3689)
2022-11-03 01:18:15,631:INFO: Batch: 25/31	Total Loss 4.6143 (4.3788)
2022-11-03 01:18:16,105:INFO: Batch: 26/31	Total Loss 4.7176 (4.3906)
2022-11-03 01:18:16,579:INFO: Batch: 27/31	Total Loss 4.8063 (4.4073)
2022-11-03 01:18:17,052:INFO: Batch: 28/31	Total Loss 4.5687 (4.4132)
2022-11-03 01:18:17,524:INFO: Batch: 29/31	Total Loss 3.9417 (4.3978)
2022-11-03 01:18:17,913:INFO: Batch: 30/31	Total Loss 1.4853 (4.3694)
2022-11-03 01:18:18,066:INFO: - Computing ADE (validation o)
2022-11-03 01:18:18,662:INFO: 		 ADE on eth                       dataset:	 0.9399062991142273
2022-11-03 01:18:18,662:INFO: Average validation o:	ADE  0.9399	FDE  1.8098
2022-11-03 01:18:18,663:INFO: - Computing ADE (validation)
2022-11-03 01:18:18,924:INFO: 		 ADE on hotel                     dataset:	 0.41860002279281616
2022-11-03 01:18:19,208:INFO: 		 ADE on univ                      dataset:	 0.5534487962722778
2022-11-03 01:18:19,465:INFO: 		 ADE on zara1                     dataset:	 0.4255809783935547
2022-11-03 01:18:19,805:INFO: 		 ADE on zara2                     dataset:	 0.4116376042366028
2022-11-03 01:18:19,805:INFO: Average validation:	ADE  0.4866	FDE  1.0217
2022-11-03 01:18:19,806:INFO: - Computing ADE (training)
2022-11-03 01:18:20,252:INFO: 		 ADE on hotel                     dataset:	 0.4432651400566101
2022-11-03 01:18:20,972:INFO: 		 ADE on univ                      dataset:	 0.5392175912857056
2022-11-03 01:18:21,516:INFO: 		 ADE on zara1                     dataset:	 0.49536028504371643
2022-11-03 01:18:22,277:INFO: 		 ADE on zara2                     dataset:	 0.41992655396461487
2022-11-03 01:18:22,277:INFO: Average training:	ADE  0.5098	FDE  1.0727
2022-11-03 01:18:22,286:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_513.pth.tar
2022-11-03 01:18:22,287:INFO: 
===> EPOCH: 514 (P3)
2022-11-03 01:18:22,287:INFO: - Computing loss (training)
2022-11-03 01:18:23,408:INFO: Batch:  0/31	Total Loss 4.0596 (4.0596)
2022-11-03 01:18:23,884:INFO: Batch:  1/31	Total Loss 3.9478 (4.0036)
2022-11-03 01:18:24,354:INFO: Batch:  2/31	Total Loss 4.6488 (4.1905)
2022-11-03 01:18:24,825:INFO: Batch:  3/31	Total Loss 4.9198 (4.3742)
2022-11-03 01:18:25,298:INFO: Batch:  4/31	Total Loss 4.3806 (4.3755)
2022-11-03 01:18:25,772:INFO: Batch:  5/31	Total Loss 3.9498 (4.3020)
2022-11-03 01:18:26,245:INFO: Batch:  6/31	Total Loss 4.3236 (4.3055)
2022-11-03 01:18:26,716:INFO: Batch:  7/31	Total Loss 4.0356 (4.2694)
2022-11-03 01:18:27,188:INFO: Batch:  8/31	Total Loss 4.4317 (4.2880)
2022-11-03 01:18:27,657:INFO: Batch:  9/31	Total Loss 4.3060 (4.2896)
2022-11-03 01:18:28,129:INFO: Batch: 10/31	Total Loss 3.8933 (4.2520)
2022-11-03 01:18:28,598:INFO: Batch: 11/31	Total Loss 4.6089 (4.2811)
2022-11-03 01:18:29,073:INFO: Batch: 12/31	Total Loss 3.6821 (4.2362)
2022-11-03 01:18:29,551:INFO: Batch: 13/31	Total Loss 3.9085 (4.2130)
2022-11-03 01:18:30,026:INFO: Batch: 14/31	Total Loss 3.9437 (4.1954)
2022-11-03 01:18:30,503:INFO: Batch: 15/31	Total Loss 4.2409 (4.1978)
2022-11-03 01:18:31,055:INFO: Batch: 16/31	Total Loss 5.2348 (4.2563)
2022-11-03 01:18:31,529:INFO: Batch: 17/31	Total Loss 3.6743 (4.2263)
2022-11-03 01:18:32,002:INFO: Batch: 18/31	Total Loss 4.3586 (4.2322)
2022-11-03 01:18:32,474:INFO: Batch: 19/31	Total Loss 4.4505 (4.2430)
2022-11-03 01:18:32,950:INFO: Batch: 20/31	Total Loss 4.1322 (4.2374)
2022-11-03 01:18:33,424:INFO: Batch: 21/31	Total Loss 4.2791 (4.2393)
2022-11-03 01:18:33,897:INFO: Batch: 22/31	Total Loss 3.7815 (4.2176)
2022-11-03 01:18:34,370:INFO: Batch: 23/31	Total Loss 3.9416 (4.2063)
2022-11-03 01:18:34,843:INFO: Batch: 24/31	Total Loss 4.2404 (4.2078)
2022-11-03 01:18:35,315:INFO: Batch: 25/31	Total Loss 3.5422 (4.1838)
2022-11-03 01:18:35,786:INFO: Batch: 26/31	Total Loss 4.2036 (4.1845)
2022-11-03 01:18:36,259:INFO: Batch: 27/31	Total Loss 5.0749 (4.2139)
2022-11-03 01:18:36,733:INFO: Batch: 28/31	Total Loss 4.0608 (4.2089)
2022-11-03 01:18:37,207:INFO: Batch: 29/31	Total Loss 4.0657 (4.2043)
2022-11-03 01:18:37,598:INFO: Batch: 30/31	Total Loss 1.4670 (4.1727)
2022-11-03 01:18:37,761:INFO: - Computing ADE (validation o)
2022-11-03 01:18:38,387:INFO: 		 ADE on eth                       dataset:	 0.9265773296356201
2022-11-03 01:18:38,387:INFO: Average validation o:	ADE  0.9266	FDE  1.8206
2022-11-03 01:18:38,388:INFO: - Computing ADE (validation)
2022-11-03 01:18:38,657:INFO: 		 ADE on hotel                     dataset:	 0.4165116846561432
2022-11-03 01:18:38,938:INFO: 		 ADE on univ                      dataset:	 0.544910728931427
2022-11-03 01:18:39,193:INFO: 		 ADE on zara1                     dataset:	 0.4019037187099457
2022-11-03 01:18:39,549:INFO: 		 ADE on zara2                     dataset:	 0.3946186900138855
2022-11-03 01:18:39,550:INFO: Average validation:	ADE  0.4744	FDE  0.9823
2022-11-03 01:18:39,550:INFO: - Computing ADE (training)
2022-11-03 01:18:39,993:INFO: 		 ADE on hotel                     dataset:	 0.43891507387161255
2022-11-03 01:18:40,699:INFO: 		 ADE on univ                      dataset:	 0.5368709564208984
2022-11-03 01:18:41,268:INFO: 		 ADE on zara1                     dataset:	 0.46557241678237915
2022-11-03 01:18:42,036:INFO: 		 ADE on zara2                     dataset:	 0.3953791856765747
2022-11-03 01:18:42,037:INFO: Average training:	ADE  0.5011	FDE  1.0451
2022-11-03 01:18:42,045:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_514.pth.tar
2022-11-03 01:18:42,045:INFO: 
===> EPOCH: 515 (P3)
2022-11-03 01:18:42,046:INFO: - Computing loss (training)
2022-11-03 01:18:43,155:INFO: Batch:  0/31	Total Loss 4.2417 (4.2417)
2022-11-03 01:18:43,624:INFO: Batch:  1/31	Total Loss 3.8815 (4.0575)
2022-11-03 01:18:44,095:INFO: Batch:  2/31	Total Loss 5.4234 (4.5134)
2022-11-03 01:18:44,560:INFO: Batch:  3/31	Total Loss 5.1658 (4.6670)
2022-11-03 01:18:45,026:INFO: Batch:  4/31	Total Loss 3.6620 (4.4572)
2022-11-03 01:18:45,494:INFO: Batch:  5/31	Total Loss 4.8033 (4.5101)
2022-11-03 01:18:45,964:INFO: Batch:  6/31	Total Loss 4.3675 (4.4865)
2022-11-03 01:18:46,431:INFO: Batch:  7/31	Total Loss 3.9762 (4.4275)
2022-11-03 01:18:46,905:INFO: Batch:  8/31	Total Loss 4.3991 (4.4243)
2022-11-03 01:18:47,371:INFO: Batch:  9/31	Total Loss 4.2831 (4.4103)
2022-11-03 01:18:47,839:INFO: Batch: 10/31	Total Loss 3.8520 (4.3538)
2022-11-03 01:18:48,307:INFO: Batch: 11/31	Total Loss 3.4775 (4.2868)
2022-11-03 01:18:48,778:INFO: Batch: 12/31	Total Loss 4.0569 (4.2678)
2022-11-03 01:18:49,250:INFO: Batch: 13/31	Total Loss 4.0943 (4.2556)
2022-11-03 01:18:49,721:INFO: Batch: 14/31	Total Loss 4.4129 (4.2647)
2022-11-03 01:18:50,193:INFO: Batch: 15/31	Total Loss 4.1774 (4.2593)
2022-11-03 01:18:50,667:INFO: Batch: 16/31	Total Loss 4.0170 (4.2440)
2022-11-03 01:18:51,140:INFO: Batch: 17/31	Total Loss 4.3053 (4.2473)
2022-11-03 01:18:51,611:INFO: Batch: 18/31	Total Loss 3.6600 (4.2143)
2022-11-03 01:18:52,082:INFO: Batch: 19/31	Total Loss 3.9863 (4.2031)
2022-11-03 01:18:52,553:INFO: Batch: 20/31	Total Loss 4.4714 (4.2155)
2022-11-03 01:18:53,022:INFO: Batch: 21/31	Total Loss 4.5581 (4.2286)
2022-11-03 01:18:53,491:INFO: Batch: 22/31	Total Loss 4.3593 (4.2334)
2022-11-03 01:18:53,960:INFO: Batch: 23/31	Total Loss 3.9022 (4.2198)
2022-11-03 01:18:54,428:INFO: Batch: 24/31	Total Loss 3.8484 (4.2043)
2022-11-03 01:18:54,898:INFO: Batch: 25/31	Total Loss 4.7419 (4.2252)
2022-11-03 01:18:55,366:INFO: Batch: 26/31	Total Loss 4.5162 (4.2344)
2022-11-03 01:18:55,834:INFO: Batch: 27/31	Total Loss 3.8618 (4.2214)
2022-11-03 01:18:56,303:INFO: Batch: 28/31	Total Loss 3.8758 (4.2104)
2022-11-03 01:18:56,771:INFO: Batch: 29/31	Total Loss 4.3217 (4.2139)
2022-11-03 01:18:57,158:INFO: Batch: 30/31	Total Loss 1.3435 (4.1943)
2022-11-03 01:18:57,316:INFO: - Computing ADE (validation o)
2022-11-03 01:18:57,917:INFO: 		 ADE on eth                       dataset:	 0.9511973857879639
2022-11-03 01:18:57,917:INFO: Average validation o:	ADE  0.9512	FDE  1.8867
2022-11-03 01:18:57,918:INFO: - Computing ADE (validation)
2022-11-03 01:18:58,211:INFO: 		 ADE on hotel                     dataset:	 0.43314364552497864
2022-11-03 01:18:58,496:INFO: 		 ADE on univ                      dataset:	 0.549818217754364
2022-11-03 01:18:58,750:INFO: 		 ADE on zara1                     dataset:	 0.412690132856369
2022-11-03 01:18:59,086:INFO: 		 ADE on zara2                     dataset:	 0.4284760355949402
2022-11-03 01:18:59,086:INFO: Average validation:	ADE  0.4909	FDE  1.0264
2022-11-03 01:18:59,087:INFO: - Computing ADE (training)
2022-11-03 01:18:59,538:INFO: 		 ADE on hotel                     dataset:	 0.4500281810760498
2022-11-03 01:19:00,231:INFO: 		 ADE on univ                      dataset:	 0.5513651967048645
2022-11-03 01:19:00,794:INFO: 		 ADE on zara1                     dataset:	 0.48916444182395935
2022-11-03 01:19:01,546:INFO: 		 ADE on zara2                     dataset:	 0.43180549144744873
2022-11-03 01:19:01,546:INFO: Average training:	ADE  0.5206	FDE  1.0979
2022-11-03 01:19:01,555:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_515.pth.tar
2022-11-03 01:19:01,555:INFO: 
===> EPOCH: 516 (P3)
2022-11-03 01:19:01,556:INFO: - Computing loss (training)
2022-11-03 01:19:02,662:INFO: Batch:  0/31	Total Loss 3.9494 (3.9494)
2022-11-03 01:19:03,141:INFO: Batch:  1/31	Total Loss 4.4677 (4.2109)
2022-11-03 01:19:03,619:INFO: Batch:  2/31	Total Loss 4.0639 (4.1584)
2022-11-03 01:19:04,092:INFO: Batch:  3/31	Total Loss 4.3076 (4.1955)
2022-11-03 01:19:04,567:INFO: Batch:  4/31	Total Loss 3.9633 (4.1504)
2022-11-03 01:19:05,038:INFO: Batch:  5/31	Total Loss 5.1031 (4.3144)
2022-11-03 01:19:05,506:INFO: Batch:  6/31	Total Loss 3.7457 (4.2361)
2022-11-03 01:19:05,975:INFO: Batch:  7/31	Total Loss 4.4794 (4.2667)
2022-11-03 01:19:06,441:INFO: Batch:  8/31	Total Loss 3.8788 (4.2205)
2022-11-03 01:19:06,908:INFO: Batch:  9/31	Total Loss 4.3549 (4.2331)
2022-11-03 01:19:07,375:INFO: Batch: 10/31	Total Loss 4.0022 (4.2144)
2022-11-03 01:19:07,845:INFO: Batch: 11/31	Total Loss 3.6285 (4.1662)
2022-11-03 01:19:08,315:INFO: Batch: 12/31	Total Loss 4.3611 (4.1816)
2022-11-03 01:19:08,785:INFO: Batch: 13/31	Total Loss 3.8918 (4.1602)
2022-11-03 01:19:09,258:INFO: Batch: 14/31	Total Loss 4.7161 (4.1972)
2022-11-03 01:19:09,729:INFO: Batch: 15/31	Total Loss 4.7600 (4.2313)
2022-11-03 01:19:10,199:INFO: Batch: 16/31	Total Loss 3.5774 (4.1934)
2022-11-03 01:19:10,672:INFO: Batch: 17/31	Total Loss 4.2611 (4.1972)
2022-11-03 01:19:11,143:INFO: Batch: 18/31	Total Loss 3.9881 (4.1857)
2022-11-03 01:19:11,615:INFO: Batch: 19/31	Total Loss 4.2488 (4.1887)
2022-11-03 01:19:12,087:INFO: Batch: 20/31	Total Loss 4.7034 (4.2110)
2022-11-03 01:19:12,555:INFO: Batch: 21/31	Total Loss 3.9975 (4.2005)
2022-11-03 01:19:13,026:INFO: Batch: 22/31	Total Loss 4.4842 (4.2135)
2022-11-03 01:19:13,497:INFO: Batch: 23/31	Total Loss 4.0446 (4.2060)
2022-11-03 01:19:13,968:INFO: Batch: 24/31	Total Loss 3.7431 (4.1875)
2022-11-03 01:19:14,439:INFO: Batch: 25/31	Total Loss 4.1043 (4.1844)
2022-11-03 01:19:14,911:INFO: Batch: 26/31	Total Loss 4.0166 (4.1778)
2022-11-03 01:19:15,382:INFO: Batch: 27/31	Total Loss 4.1788 (4.1779)
2022-11-03 01:19:15,852:INFO: Batch: 28/31	Total Loss 3.5788 (4.1578)
2022-11-03 01:19:16,322:INFO: Batch: 29/31	Total Loss 4.4003 (4.1649)
2022-11-03 01:19:16,709:INFO: Batch: 30/31	Total Loss 1.4337 (4.1343)
2022-11-03 01:19:16,866:INFO: - Computing ADE (validation o)
2022-11-03 01:19:17,449:INFO: 		 ADE on eth                       dataset:	 0.9323756098747253
2022-11-03 01:19:17,450:INFO: Average validation o:	ADE  0.9324	FDE  1.8207
2022-11-03 01:19:17,459:INFO: - Computing ADE (validation)
2022-11-03 01:19:17,739:INFO: 		 ADE on hotel                     dataset:	 0.4139639139175415
2022-11-03 01:19:18,027:INFO: 		 ADE on univ                      dataset:	 0.5498941540718079
2022-11-03 01:19:18,266:INFO: 		 ADE on zara1                     dataset:	 0.43289199471473694
2022-11-03 01:19:18,624:INFO: 		 ADE on zara2                     dataset:	 0.3959948420524597
2022-11-03 01:19:18,625:INFO: Average validation:	ADE  0.4792	FDE  0.9999
2022-11-03 01:19:18,626:INFO: - Computing ADE (training)
2022-11-03 01:19:19,087:INFO: 		 ADE on hotel                     dataset:	 0.44232791662216187
2022-11-03 01:19:19,819:INFO: 		 ADE on univ                      dataset:	 0.5330663919448853
2022-11-03 01:19:20,369:INFO: 		 ADE on zara1                     dataset:	 0.48626694083213806
2022-11-03 01:19:21,139:INFO: 		 ADE on zara2                     dataset:	 0.40676814317703247
2022-11-03 01:19:21,139:INFO: Average training:	ADE  0.5021	FDE  1.0506
2022-11-03 01:19:21,148:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_516.pth.tar
2022-11-03 01:19:21,148:INFO: 
===> EPOCH: 517 (P3)
2022-11-03 01:19:21,148:INFO: - Computing loss (training)
2022-11-03 01:19:22,229:INFO: Batch:  0/31	Total Loss 4.6732 (4.6732)
2022-11-03 01:19:22,709:INFO: Batch:  1/31	Total Loss 4.0180 (4.3306)
2022-11-03 01:19:23,189:INFO: Batch:  2/31	Total Loss 3.8026 (4.1544)
2022-11-03 01:19:23,662:INFO: Batch:  3/31	Total Loss 3.6621 (4.0170)
2022-11-03 01:19:24,136:INFO: Batch:  4/31	Total Loss 3.6819 (3.9443)
2022-11-03 01:19:24,687:INFO: Batch:  5/31	Total Loss 3.8486 (3.9288)
2022-11-03 01:19:25,161:INFO: Batch:  6/31	Total Loss 4.7358 (4.0386)
2022-11-03 01:19:25,637:INFO: Batch:  7/31	Total Loss 4.4076 (4.0874)
2022-11-03 01:19:26,114:INFO: Batch:  8/31	Total Loss 3.9733 (4.0748)
2022-11-03 01:19:26,587:INFO: Batch:  9/31	Total Loss 4.3162 (4.0978)
2022-11-03 01:19:27,062:INFO: Batch: 10/31	Total Loss 4.7024 (4.1467)
2022-11-03 01:19:27,536:INFO: Batch: 11/31	Total Loss 4.5656 (4.1775)
2022-11-03 01:19:28,013:INFO: Batch: 12/31	Total Loss 4.3371 (4.1897)
2022-11-03 01:19:28,490:INFO: Batch: 13/31	Total Loss 3.7052 (4.1533)
2022-11-03 01:19:28,967:INFO: Batch: 14/31	Total Loss 4.0322 (4.1448)
2022-11-03 01:19:29,449:INFO: Batch: 15/31	Total Loss 4.1987 (4.1481)
2022-11-03 01:19:29,929:INFO: Batch: 16/31	Total Loss 4.6184 (4.1760)
2022-11-03 01:19:30,412:INFO: Batch: 17/31	Total Loss 4.4371 (4.1910)
2022-11-03 01:19:30,888:INFO: Batch: 18/31	Total Loss 4.0548 (4.1832)
2022-11-03 01:19:31,363:INFO: Batch: 19/31	Total Loss 3.9855 (4.1734)
2022-11-03 01:19:31,839:INFO: Batch: 20/31	Total Loss 4.7323 (4.2019)
2022-11-03 01:19:32,318:INFO: Batch: 21/31	Total Loss 3.8767 (4.1851)
2022-11-03 01:19:32,796:INFO: Batch: 22/31	Total Loss 4.0146 (4.1771)
2022-11-03 01:19:33,272:INFO: Batch: 23/31	Total Loss 3.8518 (4.1634)
2022-11-03 01:19:33,750:INFO: Batch: 24/31	Total Loss 3.9272 (4.1540)
2022-11-03 01:19:34,226:INFO: Batch: 25/31	Total Loss 3.8669 (4.1425)
2022-11-03 01:19:34,704:INFO: Batch: 26/31	Total Loss 4.4628 (4.1542)
2022-11-03 01:19:35,180:INFO: Batch: 27/31	Total Loss 4.0096 (4.1495)
2022-11-03 01:19:35,657:INFO: Batch: 28/31	Total Loss 4.5011 (4.1620)
2022-11-03 01:19:36,133:INFO: Batch: 29/31	Total Loss 3.8604 (4.1517)
2022-11-03 01:19:36,524:INFO: Batch: 30/31	Total Loss 1.5487 (4.1227)
2022-11-03 01:19:36,680:INFO: - Computing ADE (validation o)
2022-11-03 01:19:37,242:INFO: 		 ADE on eth                       dataset:	 0.9459923505783081
2022-11-03 01:19:37,242:INFO: Average validation o:	ADE  0.9460	FDE  1.8778
2022-11-03 01:19:37,243:INFO: - Computing ADE (validation)
2022-11-03 01:19:37,516:INFO: 		 ADE on hotel                     dataset:	 0.4263900816440582
2022-11-03 01:19:37,816:INFO: 		 ADE on univ                      dataset:	 0.5537247061729431
2022-11-03 01:19:38,065:INFO: 		 ADE on zara1                     dataset:	 0.44391438364982605
2022-11-03 01:19:38,423:INFO: 		 ADE on zara2                     dataset:	 0.41837888956069946
2022-11-03 01:19:38,424:INFO: Average validation:	ADE  0.4907	FDE  1.0278
2022-11-03 01:19:38,424:INFO: - Computing ADE (training)
2022-11-03 01:19:38,912:INFO: 		 ADE on hotel                     dataset:	 0.4573565423488617
2022-11-03 01:19:39,587:INFO: 		 ADE on univ                      dataset:	 0.5468262434005737
2022-11-03 01:19:40,099:INFO: 		 ADE on zara1                     dataset:	 0.494209885597229
2022-11-03 01:19:40,896:INFO: 		 ADE on zara2                     dataset:	 0.42396390438079834
2022-11-03 01:19:40,896:INFO: Average training:	ADE  0.5163	FDE  1.0876
2022-11-03 01:19:40,905:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_517.pth.tar
2022-11-03 01:19:40,905:INFO: 
===> EPOCH: 518 (P3)
2022-11-03 01:19:40,905:INFO: - Computing loss (training)
2022-11-03 01:19:42,038:INFO: Batch:  0/31	Total Loss 4.0918 (4.0918)
2022-11-03 01:19:42,521:INFO: Batch:  1/31	Total Loss 4.1602 (4.1257)
2022-11-03 01:19:43,008:INFO: Batch:  2/31	Total Loss 4.6886 (4.3237)
2022-11-03 01:19:43,483:INFO: Batch:  3/31	Total Loss 4.0666 (4.2627)
2022-11-03 01:19:43,958:INFO: Batch:  4/31	Total Loss 4.7518 (4.3483)
2022-11-03 01:19:44,438:INFO: Batch:  5/31	Total Loss 3.5270 (4.2037)
2022-11-03 01:19:44,916:INFO: Batch:  6/31	Total Loss 4.0152 (4.1764)
2022-11-03 01:19:45,394:INFO: Batch:  7/31	Total Loss 4.7335 (4.2450)
2022-11-03 01:19:45,870:INFO: Batch:  8/31	Total Loss 5.4521 (4.3872)
2022-11-03 01:19:46,348:INFO: Batch:  9/31	Total Loss 4.1484 (4.3648)
2022-11-03 01:19:46,824:INFO: Batch: 10/31	Total Loss 4.0496 (4.3352)
2022-11-03 01:19:47,303:INFO: Batch: 11/31	Total Loss 4.1534 (4.3181)
2022-11-03 01:19:47,784:INFO: Batch: 12/31	Total Loss 4.0698 (4.2986)
2022-11-03 01:19:48,267:INFO: Batch: 13/31	Total Loss 4.3153 (4.2998)
2022-11-03 01:19:48,748:INFO: Batch: 14/31	Total Loss 3.7526 (4.2617)
2022-11-03 01:19:49,230:INFO: Batch: 15/31	Total Loss 4.1114 (4.2519)
2022-11-03 01:19:49,712:INFO: Batch: 16/31	Total Loss 3.9005 (4.2318)
2022-11-03 01:19:50,196:INFO: Batch: 17/31	Total Loss 4.8170 (4.2661)
2022-11-03 01:19:50,679:INFO: Batch: 18/31	Total Loss 4.0272 (4.2523)
2022-11-03 01:19:51,161:INFO: Batch: 19/31	Total Loss 4.1579 (4.2476)
2022-11-03 01:19:51,644:INFO: Batch: 20/31	Total Loss 5.0755 (4.2864)
2022-11-03 01:19:52,127:INFO: Batch: 21/31	Total Loss 3.9902 (4.2732)
2022-11-03 01:19:52,606:INFO: Batch: 22/31	Total Loss 4.1082 (4.2656)
2022-11-03 01:19:53,085:INFO: Batch: 23/31	Total Loss 4.0827 (4.2581)
2022-11-03 01:19:53,562:INFO: Batch: 24/31	Total Loss 4.5094 (4.2678)
2022-11-03 01:19:54,041:INFO: Batch: 25/31	Total Loss 3.9621 (4.2543)
2022-11-03 01:19:54,520:INFO: Batch: 26/31	Total Loss 3.9558 (4.2422)
2022-11-03 01:19:54,998:INFO: Batch: 27/31	Total Loss 4.2721 (4.2432)
2022-11-03 01:19:55,475:INFO: Batch: 28/31	Total Loss 3.9600 (4.2338)
2022-11-03 01:19:55,951:INFO: Batch: 29/31	Total Loss 3.8947 (4.2228)
2022-11-03 01:19:56,344:INFO: Batch: 30/31	Total Loss 1.5468 (4.2016)
2022-11-03 01:19:56,488:INFO: - Computing ADE (validation o)
2022-11-03 01:19:57,113:INFO: 		 ADE on eth                       dataset:	 0.9335205554962158
2022-11-03 01:19:57,114:INFO: Average validation o:	ADE  0.9335	FDE  1.8781
2022-11-03 01:19:57,114:INFO: - Computing ADE (validation)
2022-11-03 01:19:57,388:INFO: 		 ADE on hotel                     dataset:	 0.4034052789211273
2022-11-03 01:19:57,669:INFO: 		 ADE on univ                      dataset:	 0.5429831147193909
2022-11-03 01:19:57,925:INFO: 		 ADE on zara1                     dataset:	 0.4130258858203888
2022-11-03 01:19:58,263:INFO: 		 ADE on zara2                     dataset:	 0.39990565180778503
2022-11-03 01:19:58,263:INFO: Average validation:	ADE  0.4753	FDE  0.9915
2022-11-03 01:19:58,264:INFO: - Computing ADE (training)
2022-11-03 01:19:58,719:INFO: 		 ADE on hotel                     dataset:	 0.41752275824546814
2022-11-03 01:19:59,390:INFO: 		 ADE on univ                      dataset:	 0.5382581353187561
2022-11-03 01:19:59,907:INFO: 		 ADE on zara1                     dataset:	 0.4600646495819092
2022-11-03 01:20:00,703:INFO: 		 ADE on zara2                     dataset:	 0.40027204155921936
2022-11-03 01:20:00,703:INFO: Average training:	ADE  0.5022	FDE  1.0548
2022-11-03 01:20:00,712:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_518.pth.tar
2022-11-03 01:20:00,712:INFO: 
===> EPOCH: 519 (P3)
2022-11-03 01:20:00,712:INFO: - Computing loss (training)
2022-11-03 01:20:01,819:INFO: Batch:  0/31	Total Loss 4.7717 (4.7717)
2022-11-03 01:20:02,293:INFO: Batch:  1/31	Total Loss 4.0700 (4.4372)
2022-11-03 01:20:02,770:INFO: Batch:  2/31	Total Loss 3.4866 (4.1530)
2022-11-03 01:20:03,245:INFO: Batch:  3/31	Total Loss 4.0060 (4.1132)
2022-11-03 01:20:03,717:INFO: Batch:  4/31	Total Loss 3.8683 (4.0624)
2022-11-03 01:20:04,197:INFO: Batch:  5/31	Total Loss 5.8073 (4.3607)
2022-11-03 01:20:04,670:INFO: Batch:  6/31	Total Loss 4.5174 (4.3825)
2022-11-03 01:20:05,142:INFO: Batch:  7/31	Total Loss 3.9539 (4.3230)
2022-11-03 01:20:05,625:INFO: Batch:  8/31	Total Loss 3.9962 (4.2860)
2022-11-03 01:20:06,097:INFO: Batch:  9/31	Total Loss 3.8886 (4.2495)
2022-11-03 01:20:06,572:INFO: Batch: 10/31	Total Loss 4.0718 (4.2334)
2022-11-03 01:20:07,044:INFO: Batch: 11/31	Total Loss 4.2639 (4.2358)
2022-11-03 01:20:07,522:INFO: Batch: 12/31	Total Loss 4.2534 (4.2373)
2022-11-03 01:20:07,999:INFO: Batch: 13/31	Total Loss 4.5893 (4.2649)
2022-11-03 01:20:08,478:INFO: Batch: 14/31	Total Loss 4.0855 (4.2509)
2022-11-03 01:20:08,955:INFO: Batch: 15/31	Total Loss 4.1030 (4.2412)
2022-11-03 01:20:09,432:INFO: Batch: 16/31	Total Loss 4.2134 (4.2395)
2022-11-03 01:20:09,909:INFO: Batch: 17/31	Total Loss 4.1768 (4.2362)
2022-11-03 01:20:10,388:INFO: Batch: 18/31	Total Loss 5.1711 (4.2867)
2022-11-03 01:20:10,867:INFO: Batch: 19/31	Total Loss 5.5643 (4.3447)
2022-11-03 01:20:11,342:INFO: Batch: 20/31	Total Loss 4.2072 (4.3381)
2022-11-03 01:20:11,816:INFO: Batch: 21/31	Total Loss 3.8293 (4.3141)
2022-11-03 01:20:12,295:INFO: Batch: 22/31	Total Loss 4.0361 (4.3025)
2022-11-03 01:20:12,778:INFO: Batch: 23/31	Total Loss 4.1333 (4.2954)
2022-11-03 01:20:13,262:INFO: Batch: 24/31	Total Loss 5.1207 (4.3308)
2022-11-03 01:20:13,747:INFO: Batch: 25/31	Total Loss 4.0804 (4.3208)
2022-11-03 01:20:14,232:INFO: Batch: 26/31	Total Loss 4.6297 (4.3334)
2022-11-03 01:20:14,794:INFO: Batch: 27/31	Total Loss 4.4508 (4.3375)
2022-11-03 01:20:15,281:INFO: Batch: 28/31	Total Loss 4.2578 (4.3344)
2022-11-03 01:20:15,766:INFO: Batch: 29/31	Total Loss 4.1663 (4.3286)
2022-11-03 01:20:16,167:INFO: Batch: 30/31	Total Loss 1.6640 (4.3000)
2022-11-03 01:20:16,324:INFO: - Computing ADE (validation o)
2022-11-03 01:20:16,934:INFO: 		 ADE on eth                       dataset:	 0.9487951397895813
2022-11-03 01:20:16,934:INFO: Average validation o:	ADE  0.9488	FDE  1.8703
2022-11-03 01:20:16,935:INFO: - Computing ADE (validation)
2022-11-03 01:20:17,198:INFO: 		 ADE on hotel                     dataset:	 0.5310708284378052
2022-11-03 01:20:17,477:INFO: 		 ADE on univ                      dataset:	 0.6276630759239197
2022-11-03 01:20:17,714:INFO: 		 ADE on zara1                     dataset:	 0.5167980790138245
2022-11-03 01:20:18,051:INFO: 		 ADE on zara2                     dataset:	 0.48631659150123596
2022-11-03 01:20:18,051:INFO: Average validation:	ADE  0.5641	FDE  1.2336
2022-11-03 01:20:18,052:INFO: - Computing ADE (training)
2022-11-03 01:20:18,533:INFO: 		 ADE on hotel                     dataset:	 0.5622754693031311
2022-11-03 01:20:19,210:INFO: 		 ADE on univ                      dataset:	 0.5985032916069031
2022-11-03 01:20:19,736:INFO: 		 ADE on zara1                     dataset:	 0.5299258828163147
2022-11-03 01:20:20,495:INFO: 		 ADE on zara2                     dataset:	 0.48491013050079346
2022-11-03 01:20:20,496:INFO: Average training:	ADE  0.5702	FDE  1.2408
2022-11-03 01:20:20,505:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_519.pth.tar
2022-11-03 01:20:20,505:INFO: 
===> EPOCH: 520 (P3)
2022-11-03 01:20:20,506:INFO: - Computing loss (training)
2022-11-03 01:20:21,596:INFO: Batch:  0/31	Total Loss 5.0783 (5.0783)
2022-11-03 01:20:22,072:INFO: Batch:  1/31	Total Loss 4.9320 (5.0011)
2022-11-03 01:20:22,555:INFO: Batch:  2/31	Total Loss 3.8901 (4.6327)
2022-11-03 01:20:23,031:INFO: Batch:  3/31	Total Loss 4.5404 (4.6096)
2022-11-03 01:20:23,510:INFO: Batch:  4/31	Total Loss 3.9536 (4.4690)
2022-11-03 01:20:23,993:INFO: Batch:  5/31	Total Loss 4.1557 (4.4173)
2022-11-03 01:20:24,471:INFO: Batch:  6/31	Total Loss 3.5569 (4.2986)
2022-11-03 01:20:24,945:INFO: Batch:  7/31	Total Loss 3.9629 (4.2539)
2022-11-03 01:20:25,420:INFO: Batch:  8/31	Total Loss 4.7936 (4.3099)
2022-11-03 01:20:25,894:INFO: Batch:  9/31	Total Loss 4.4886 (4.3255)
2022-11-03 01:20:26,367:INFO: Batch: 10/31	Total Loss 3.7949 (4.2729)
2022-11-03 01:20:26,842:INFO: Batch: 11/31	Total Loss 4.4276 (4.2849)
2022-11-03 01:20:27,318:INFO: Batch: 12/31	Total Loss 4.2519 (4.2824)
2022-11-03 01:20:27,795:INFO: Batch: 13/31	Total Loss 4.0351 (4.2640)
2022-11-03 01:20:28,274:INFO: Batch: 14/31	Total Loss 5.5650 (4.3482)
2022-11-03 01:20:28,750:INFO: Batch: 15/31	Total Loss 4.0266 (4.3267)
2022-11-03 01:20:29,228:INFO: Batch: 16/31	Total Loss 3.9015 (4.3022)
2022-11-03 01:20:29,703:INFO: Batch: 17/31	Total Loss 4.1336 (4.2923)
2022-11-03 01:20:30,181:INFO: Batch: 18/31	Total Loss 4.4393 (4.3010)
2022-11-03 01:20:30,660:INFO: Batch: 19/31	Total Loss 4.0723 (4.2899)
2022-11-03 01:20:31,137:INFO: Batch: 20/31	Total Loss 4.2567 (4.2884)
2022-11-03 01:20:31,613:INFO: Batch: 21/31	Total Loss 4.6336 (4.3043)
2022-11-03 01:20:32,090:INFO: Batch: 22/31	Total Loss 4.1958 (4.2997)
2022-11-03 01:20:32,564:INFO: Batch: 23/31	Total Loss 3.8172 (4.2799)
2022-11-03 01:20:33,041:INFO: Batch: 24/31	Total Loss 4.1250 (4.2734)
2022-11-03 01:20:33,516:INFO: Batch: 25/31	Total Loss 4.3086 (4.2747)
2022-11-03 01:20:33,991:INFO: Batch: 26/31	Total Loss 4.0231 (4.2661)
2022-11-03 01:20:34,468:INFO: Batch: 27/31	Total Loss 4.4070 (4.2719)
2022-11-03 01:20:34,942:INFO: Batch: 28/31	Total Loss 4.5358 (4.2809)
2022-11-03 01:20:35,416:INFO: Batch: 29/31	Total Loss 4.4046 (4.2845)
2022-11-03 01:20:35,806:INFO: Batch: 30/31	Total Loss 1.5744 (4.2600)
2022-11-03 01:20:35,963:INFO: - Computing ADE (validation o)
2022-11-03 01:20:36,562:INFO: 		 ADE on eth                       dataset:	 0.9198033213615417
2022-11-03 01:20:36,562:INFO: Average validation o:	ADE  0.9198	FDE  1.8063
2022-11-03 01:20:36,563:INFO: - Computing ADE (validation)
2022-11-03 01:20:36,834:INFO: 		 ADE on hotel                     dataset:	 0.408702552318573
2022-11-03 01:20:37,128:INFO: 		 ADE on univ                      dataset:	 0.5521543025970459
2022-11-03 01:20:37,374:INFO: 		 ADE on zara1                     dataset:	 0.41064953804016113
2022-11-03 01:20:37,722:INFO: 		 ADE on zara2                     dataset:	 0.3935708999633789
2022-11-03 01:20:37,723:INFO: Average validation:	ADE  0.4779	FDE  1.0006
2022-11-03 01:20:37,723:INFO: - Computing ADE (training)
2022-11-03 01:20:38,181:INFO: 		 ADE on hotel                     dataset:	 0.4321172833442688
2022-11-03 01:20:38,880:INFO: 		 ADE on univ                      dataset:	 0.536612868309021
2022-11-03 01:20:39,429:INFO: 		 ADE on zara1                     dataset:	 0.47346481680870056
2022-11-03 01:20:40,178:INFO: 		 ADE on zara2                     dataset:	 0.39725345373153687
2022-11-03 01:20:40,178:INFO: Average training:	ADE  0.5017	FDE  1.0524
2022-11-03 01:20:40,187:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_520.pth.tar
2022-11-03 01:20:40,187:INFO: 
===> EPOCH: 521 (P3)
2022-11-03 01:20:40,187:INFO: - Computing loss (training)
2022-11-03 01:20:41,264:INFO: Batch:  0/31	Total Loss 4.8820 (4.8820)
2022-11-03 01:20:41,736:INFO: Batch:  1/31	Total Loss 4.0880 (4.4933)
2022-11-03 01:20:42,208:INFO: Batch:  2/31	Total Loss 3.8316 (4.2503)
2022-11-03 01:20:42,673:INFO: Batch:  3/31	Total Loss 4.7684 (4.3815)
2022-11-03 01:20:43,138:INFO: Batch:  4/31	Total Loss 4.8290 (4.4799)
2022-11-03 01:20:43,605:INFO: Batch:  5/31	Total Loss 4.1848 (4.4274)
2022-11-03 01:20:44,069:INFO: Batch:  6/31	Total Loss 4.3622 (4.4181)
2022-11-03 01:20:44,532:INFO: Batch:  7/31	Total Loss 3.6660 (4.3307)
2022-11-03 01:20:44,995:INFO: Batch:  8/31	Total Loss 4.0094 (4.2948)
2022-11-03 01:20:45,459:INFO: Batch:  9/31	Total Loss 3.5828 (4.2171)
2022-11-03 01:20:45,921:INFO: Batch: 10/31	Total Loss 4.3677 (4.2305)
2022-11-03 01:20:46,388:INFO: Batch: 11/31	Total Loss 3.9683 (4.2096)
2022-11-03 01:20:46,856:INFO: Batch: 12/31	Total Loss 4.3057 (4.2178)
2022-11-03 01:20:47,323:INFO: Batch: 13/31	Total Loss 4.2251 (4.2183)
2022-11-03 01:20:47,788:INFO: Batch: 14/31	Total Loss 3.8894 (4.1961)
2022-11-03 01:20:48,256:INFO: Batch: 15/31	Total Loss 4.8077 (4.2331)
2022-11-03 01:20:48,724:INFO: Batch: 16/31	Total Loss 3.9379 (4.2163)
2022-11-03 01:20:49,192:INFO: Batch: 17/31	Total Loss 4.5892 (4.2369)
2022-11-03 01:20:49,660:INFO: Batch: 18/31	Total Loss 4.9820 (4.2719)
2022-11-03 01:20:50,127:INFO: Batch: 19/31	Total Loss 4.4197 (4.2784)
2022-11-03 01:20:50,599:INFO: Batch: 20/31	Total Loss 4.8093 (4.3023)
2022-11-03 01:20:51,086:INFO: Batch: 21/31	Total Loss 3.9365 (4.2846)
2022-11-03 01:20:51,569:INFO: Batch: 22/31	Total Loss 3.4683 (4.2486)
2022-11-03 01:20:52,053:INFO: Batch: 23/31	Total Loss 4.0976 (4.2426)
2022-11-03 01:20:52,540:INFO: Batch: 24/31	Total Loss 3.9172 (4.2290)
2022-11-03 01:20:53,024:INFO: Batch: 25/31	Total Loss 4.4308 (4.2360)
2022-11-03 01:20:53,510:INFO: Batch: 26/31	Total Loss 3.8389 (4.2198)
2022-11-03 01:20:53,994:INFO: Batch: 27/31	Total Loss 3.7149 (4.2009)
2022-11-03 01:20:54,480:INFO: Batch: 28/31	Total Loss 3.8840 (4.1901)
2022-11-03 01:20:54,963:INFO: Batch: 29/31	Total Loss 4.4945 (4.1996)
2022-11-03 01:20:55,361:INFO: Batch: 30/31	Total Loss 1.5366 (4.1740)
2022-11-03 01:20:55,517:INFO: - Computing ADE (validation o)
2022-11-03 01:20:56,115:INFO: 		 ADE on eth                       dataset:	 0.9449755549430847
2022-11-03 01:20:56,115:INFO: Average validation o:	ADE  0.9450	FDE  1.8689
2022-11-03 01:20:56,116:INFO: - Computing ADE (validation)
2022-11-03 01:20:56,387:INFO: 		 ADE on hotel                     dataset:	 0.40679407119750977
2022-11-03 01:20:56,664:INFO: 		 ADE on univ                      dataset:	 0.5430487990379333
2022-11-03 01:20:56,934:INFO: 		 ADE on zara1                     dataset:	 0.41997864842414856
2022-11-03 01:20:57,297:INFO: 		 ADE on zara2                     dataset:	 0.4128855764865875
2022-11-03 01:20:57,297:INFO: Average validation:	ADE  0.4807	FDE  0.9992
2022-11-03 01:20:57,298:INFO: - Computing ADE (training)
2022-11-03 01:20:57,759:INFO: 		 ADE on hotel                     dataset:	 0.42170608043670654
2022-11-03 01:20:58,428:INFO: 		 ADE on univ                      dataset:	 0.5390480160713196
2022-11-03 01:20:58,954:INFO: 		 ADE on zara1                     dataset:	 0.4909321367740631
2022-11-03 01:20:59,694:INFO: 		 ADE on zara2                     dataset:	 0.42003512382507324
2022-11-03 01:20:59,694:INFO: Average training:	ADE  0.5088	FDE  1.0670
2022-11-03 01:20:59,704:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_521.pth.tar
2022-11-03 01:20:59,704:INFO: 
===> EPOCH: 522 (P3)
2022-11-03 01:20:59,704:INFO: - Computing loss (training)
2022-11-03 01:21:00,814:INFO: Batch:  0/31	Total Loss 4.7647 (4.7647)
2022-11-03 01:21:01,321:INFO: Batch:  1/31	Total Loss 4.2318 (4.5056)
2022-11-03 01:21:01,799:INFO: Batch:  2/31	Total Loss 4.3955 (4.4706)
2022-11-03 01:21:02,274:INFO: Batch:  3/31	Total Loss 4.2695 (4.4228)
2022-11-03 01:21:02,750:INFO: Batch:  4/31	Total Loss 3.9461 (4.3288)
2022-11-03 01:21:03,226:INFO: Batch:  5/31	Total Loss 4.4211 (4.3437)
2022-11-03 01:21:03,701:INFO: Batch:  6/31	Total Loss 4.0416 (4.2995)
2022-11-03 01:21:04,176:INFO: Batch:  7/31	Total Loss 4.1522 (4.2808)
2022-11-03 01:21:04,651:INFO: Batch:  8/31	Total Loss 4.3169 (4.2850)
2022-11-03 01:21:05,126:INFO: Batch:  9/31	Total Loss 4.3143 (4.2881)
2022-11-03 01:21:05,601:INFO: Batch: 10/31	Total Loss 4.5887 (4.3149)
2022-11-03 01:21:06,078:INFO: Batch: 11/31	Total Loss 4.3346 (4.3165)
2022-11-03 01:21:06,555:INFO: Batch: 12/31	Total Loss 4.1529 (4.3047)
2022-11-03 01:21:07,033:INFO: Batch: 13/31	Total Loss 4.0220 (4.2831)
2022-11-03 01:21:07,508:INFO: Batch: 14/31	Total Loss 4.9468 (4.3274)
2022-11-03 01:21:07,986:INFO: Batch: 15/31	Total Loss 4.0422 (4.3112)
2022-11-03 01:21:08,463:INFO: Batch: 16/31	Total Loss 3.9744 (4.2925)
2022-11-03 01:21:08,940:INFO: Batch: 17/31	Total Loss 3.9376 (4.2723)
2022-11-03 01:21:09,494:INFO: Batch: 18/31	Total Loss 4.6933 (4.2968)
2022-11-03 01:21:09,970:INFO: Batch: 19/31	Total Loss 4.7977 (4.3219)
2022-11-03 01:21:10,449:INFO: Batch: 20/31	Total Loss 3.6875 (4.2898)
2022-11-03 01:21:10,923:INFO: Batch: 21/31	Total Loss 4.4951 (4.2998)
2022-11-03 01:21:11,400:INFO: Batch: 22/31	Total Loss 3.9328 (4.2817)
2022-11-03 01:21:11,875:INFO: Batch: 23/31	Total Loss 4.2180 (4.2788)
2022-11-03 01:21:12,349:INFO: Batch: 24/31	Total Loss 4.5219 (4.2877)
2022-11-03 01:21:12,827:INFO: Batch: 25/31	Total Loss 4.2815 (4.2875)
2022-11-03 01:21:13,304:INFO: Batch: 26/31	Total Loss 4.4269 (4.2930)
2022-11-03 01:21:13,780:INFO: Batch: 27/31	Total Loss 4.2117 (4.2904)
2022-11-03 01:21:14,257:INFO: Batch: 28/31	Total Loss 3.7416 (4.2692)
2022-11-03 01:21:14,736:INFO: Batch: 29/31	Total Loss 4.2469 (4.2685)
2022-11-03 01:21:15,129:INFO: Batch: 30/31	Total Loss 1.5327 (4.2470)
2022-11-03 01:21:15,279:INFO: - Computing ADE (validation o)
2022-11-03 01:21:15,873:INFO: 		 ADE on eth                       dataset:	 0.9400818347930908
2022-11-03 01:21:15,874:INFO: Average validation o:	ADE  0.9401	FDE  1.8949
2022-11-03 01:21:15,874:INFO: - Computing ADE (validation)
2022-11-03 01:21:16,133:INFO: 		 ADE on hotel                     dataset:	 0.44318994879722595
2022-11-03 01:21:16,419:INFO: 		 ADE on univ                      dataset:	 0.5626997351646423
2022-11-03 01:21:16,676:INFO: 		 ADE on zara1                     dataset:	 0.4243011474609375
2022-11-03 01:21:17,028:INFO: 		 ADE on zara2                     dataset:	 0.42281219363212585
2022-11-03 01:21:17,029:INFO: Average validation:	ADE  0.4968	FDE  1.0562
2022-11-03 01:21:17,029:INFO: - Computing ADE (training)
2022-11-03 01:21:17,464:INFO: 		 ADE on hotel                     dataset:	 0.4711369574069977
2022-11-03 01:21:18,151:INFO: 		 ADE on univ                      dataset:	 0.5574439764022827
2022-11-03 01:21:18,707:INFO: 		 ADE on zara1                     dataset:	 0.466130793094635
2022-11-03 01:21:19,479:INFO: 		 ADE on zara2                     dataset:	 0.42072972655296326
2022-11-03 01:21:19,480:INFO: Average training:	ADE  0.5217	FDE  1.1136
2022-11-03 01:21:19,489:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_522.pth.tar
2022-11-03 01:21:19,489:INFO: 
===> EPOCH: 523 (P3)
2022-11-03 01:21:19,489:INFO: - Computing loss (training)
2022-11-03 01:21:20,604:INFO: Batch:  0/31	Total Loss 4.0750 (4.0750)
2022-11-03 01:21:21,090:INFO: Batch:  1/31	Total Loss 4.6243 (4.3236)
2022-11-03 01:21:21,581:INFO: Batch:  2/31	Total Loss 4.2458 (4.2988)
2022-11-03 01:21:22,066:INFO: Batch:  3/31	Total Loss 4.3711 (4.3163)
2022-11-03 01:21:22,557:INFO: Batch:  4/31	Total Loss 4.2639 (4.3057)
2022-11-03 01:21:23,039:INFO: Batch:  5/31	Total Loss 4.8523 (4.3905)
2022-11-03 01:21:23,520:INFO: Batch:  6/31	Total Loss 4.5633 (4.4157)
2022-11-03 01:21:23,998:INFO: Batch:  7/31	Total Loss 4.2187 (4.3926)
2022-11-03 01:21:24,467:INFO: Batch:  8/31	Total Loss 4.0418 (4.3519)
2022-11-03 01:21:24,932:INFO: Batch:  9/31	Total Loss 4.0666 (4.3243)
2022-11-03 01:21:25,402:INFO: Batch: 10/31	Total Loss 5.1084 (4.3919)
2022-11-03 01:21:25,867:INFO: Batch: 11/31	Total Loss 4.2879 (4.3830)
2022-11-03 01:21:26,339:INFO: Batch: 12/31	Total Loss 4.2664 (4.3747)
2022-11-03 01:21:26,811:INFO: Batch: 13/31	Total Loss 4.6277 (4.3948)
2022-11-03 01:21:27,283:INFO: Batch: 14/31	Total Loss 4.4652 (4.3985)
2022-11-03 01:21:27,755:INFO: Batch: 15/31	Total Loss 4.1866 (4.3840)
2022-11-03 01:21:28,226:INFO: Batch: 16/31	Total Loss 4.2523 (4.3761)
2022-11-03 01:21:28,696:INFO: Batch: 17/31	Total Loss 4.5642 (4.3859)
2022-11-03 01:21:29,167:INFO: Batch: 18/31	Total Loss 4.3465 (4.3841)
2022-11-03 01:21:29,636:INFO: Batch: 19/31	Total Loss 4.5389 (4.3909)
2022-11-03 01:21:30,107:INFO: Batch: 20/31	Total Loss 4.3011 (4.3864)
2022-11-03 01:21:30,580:INFO: Batch: 21/31	Total Loss 4.0372 (4.3710)
2022-11-03 01:21:31,052:INFO: Batch: 22/31	Total Loss 3.9626 (4.3539)
2022-11-03 01:21:31,520:INFO: Batch: 23/31	Total Loss 4.4823 (4.3589)
2022-11-03 01:21:31,988:INFO: Batch: 24/31	Total Loss 4.3427 (4.3583)
2022-11-03 01:21:32,455:INFO: Batch: 25/31	Total Loss 4.3661 (4.3586)
2022-11-03 01:21:32,924:INFO: Batch: 26/31	Total Loss 4.3619 (4.3587)
2022-11-03 01:21:33,394:INFO: Batch: 27/31	Total Loss 4.4632 (4.3626)
2022-11-03 01:21:33,861:INFO: Batch: 28/31	Total Loss 3.5307 (4.3317)
2022-11-03 01:21:34,329:INFO: Batch: 29/31	Total Loss 3.9437 (4.3189)
2022-11-03 01:21:34,713:INFO: Batch: 30/31	Total Loss 1.5982 (4.2831)
2022-11-03 01:21:34,868:INFO: - Computing ADE (validation o)
2022-11-03 01:21:35,471:INFO: 		 ADE on eth                       dataset:	 0.9538829922676086
2022-11-03 01:21:35,471:INFO: Average validation o:	ADE  0.9539	FDE  1.9032
2022-11-03 01:21:35,472:INFO: - Computing ADE (validation)
2022-11-03 01:21:35,735:INFO: 		 ADE on hotel                     dataset:	 0.4593595266342163
2022-11-03 01:21:36,027:INFO: 		 ADE on univ                      dataset:	 0.5675489902496338
2022-11-03 01:21:36,275:INFO: 		 ADE on zara1                     dataset:	 0.43095719814300537
2022-11-03 01:21:36,623:INFO: 		 ADE on zara2                     dataset:	 0.4506283402442932
2022-11-03 01:21:36,623:INFO: Average validation:	ADE  0.5108	FDE  1.0916
2022-11-03 01:21:36,624:INFO: - Computing ADE (training)
2022-11-03 01:21:37,082:INFO: 		 ADE on hotel                     dataset:	 0.4832603931427002
2022-11-03 01:21:37,765:INFO: 		 ADE on univ                      dataset:	 0.5717609524726868
2022-11-03 01:21:38,292:INFO: 		 ADE on zara1                     dataset:	 0.48214760422706604
2022-11-03 01:21:39,059:INFO: 		 ADE on zara2                     dataset:	 0.44720208644866943
2022-11-03 01:21:39,059:INFO: Average training:	ADE  0.5385	FDE  1.1574
2022-11-03 01:21:39,068:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_523.pth.tar
2022-11-03 01:21:39,068:INFO: 
===> EPOCH: 524 (P3)
2022-11-03 01:21:39,068:INFO: - Computing loss (training)
2022-11-03 01:21:40,169:INFO: Batch:  0/31	Total Loss 3.9769 (3.9769)
2022-11-03 01:21:40,655:INFO: Batch:  1/31	Total Loss 4.2448 (4.1050)
2022-11-03 01:21:41,127:INFO: Batch:  2/31	Total Loss 3.9404 (4.0561)
2022-11-03 01:21:41,593:INFO: Batch:  3/31	Total Loss 3.8704 (4.0084)
2022-11-03 01:21:42,062:INFO: Batch:  4/31	Total Loss 4.2462 (4.0561)
2022-11-03 01:21:42,529:INFO: Batch:  5/31	Total Loss 3.9708 (4.0413)
2022-11-03 01:21:42,993:INFO: Batch:  6/31	Total Loss 3.4974 (3.9610)
2022-11-03 01:21:43,457:INFO: Batch:  7/31	Total Loss 3.7974 (3.9417)
2022-11-03 01:21:43,927:INFO: Batch:  8/31	Total Loss 4.1729 (3.9713)
2022-11-03 01:21:44,400:INFO: Batch:  9/31	Total Loss 4.3063 (3.9988)
2022-11-03 01:21:44,877:INFO: Batch: 10/31	Total Loss 4.0390 (4.0028)
2022-11-03 01:21:45,354:INFO: Batch: 11/31	Total Loss 4.1463 (4.0141)
2022-11-03 01:21:45,822:INFO: Batch: 12/31	Total Loss 3.9308 (4.0078)
2022-11-03 01:21:46,291:INFO: Batch: 13/31	Total Loss 4.3265 (4.0305)
2022-11-03 01:21:46,760:INFO: Batch: 14/31	Total Loss 3.6747 (4.0073)
2022-11-03 01:21:47,230:INFO: Batch: 15/31	Total Loss 4.4857 (4.0392)
2022-11-03 01:21:47,699:INFO: Batch: 16/31	Total Loss 4.6683 (4.0756)
2022-11-03 01:21:48,169:INFO: Batch: 17/31	Total Loss 3.4489 (4.0374)
2022-11-03 01:21:48,637:INFO: Batch: 18/31	Total Loss 4.6260 (4.0664)
2022-11-03 01:21:49,106:INFO: Batch: 19/31	Total Loss 4.7456 (4.1005)
2022-11-03 01:21:49,575:INFO: Batch: 20/31	Total Loss 4.8388 (4.1341)
2022-11-03 01:21:50,045:INFO: Batch: 21/31	Total Loss 5.1924 (4.1788)
2022-11-03 01:21:50,515:INFO: Batch: 22/31	Total Loss 4.6182 (4.1959)
2022-11-03 01:21:50,990:INFO: Batch: 23/31	Total Loss 4.4030 (4.2044)
2022-11-03 01:21:51,458:INFO: Batch: 24/31	Total Loss 4.3794 (4.2112)
2022-11-03 01:21:51,926:INFO: Batch: 25/31	Total Loss 4.0971 (4.2067)
2022-11-03 01:21:52,396:INFO: Batch: 26/31	Total Loss 4.3354 (4.2112)
2022-11-03 01:21:52,867:INFO: Batch: 27/31	Total Loss 5.2572 (4.2492)
2022-11-03 01:21:53,335:INFO: Batch: 28/31	Total Loss 4.4555 (4.2562)
2022-11-03 01:21:53,802:INFO: Batch: 29/31	Total Loss 4.0856 (4.2504)
2022-11-03 01:21:54,185:INFO: Batch: 30/31	Total Loss 1.8778 (4.2292)
2022-11-03 01:21:54,337:INFO: - Computing ADE (validation o)
2022-11-03 01:21:54,927:INFO: 		 ADE on eth                       dataset:	 0.9539157748222351
2022-11-03 01:21:54,927:INFO: Average validation o:	ADE  0.9539	FDE  1.9101
2022-11-03 01:21:54,928:INFO: - Computing ADE (validation)
2022-11-03 01:21:55,196:INFO: 		 ADE on hotel                     dataset:	 0.4424773156642914
2022-11-03 01:21:55,498:INFO: 		 ADE on univ                      dataset:	 0.569612443447113
2022-11-03 01:21:55,759:INFO: 		 ADE on zara1                     dataset:	 0.43985018134117126
2022-11-03 01:21:56,108:INFO: 		 ADE on zara2                     dataset:	 0.4444030523300171
2022-11-03 01:21:56,108:INFO: Average validation:	ADE  0.5092	FDE  1.0874
2022-11-03 01:21:56,109:INFO: - Computing ADE (training)
2022-11-03 01:21:56,586:INFO: 		 ADE on hotel                     dataset:	 0.46251046657562256
2022-11-03 01:21:57,288:INFO: 		 ADE on univ                      dataset:	 0.5667498111724854
2022-11-03 01:21:57,823:INFO: 		 ADE on zara1                     dataset:	 0.4859863519668579
2022-11-03 01:21:58,567:INFO: 		 ADE on zara2                     dataset:	 0.44194701313972473
2022-11-03 01:21:58,567:INFO: Average training:	ADE  0.5336	FDE  1.1445
2022-11-03 01:21:58,577:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_524.pth.tar
2022-11-03 01:21:58,577:INFO: 
===> EPOCH: 525 (P3)
2022-11-03 01:21:58,577:INFO: - Computing loss (training)
2022-11-03 01:21:59,656:INFO: Batch:  0/31	Total Loss 3.7722 (3.7722)
2022-11-03 01:22:00,122:INFO: Batch:  1/31	Total Loss 4.0267 (3.8963)
2022-11-03 01:22:00,596:INFO: Batch:  2/31	Total Loss 4.8156 (4.1964)
2022-11-03 01:22:01,058:INFO: Batch:  3/31	Total Loss 4.0953 (4.1691)
2022-11-03 01:22:01,527:INFO: Batch:  4/31	Total Loss 4.6257 (4.2544)
2022-11-03 01:22:02,000:INFO: Batch:  5/31	Total Loss 4.1026 (4.2300)
2022-11-03 01:22:02,465:INFO: Batch:  6/31	Total Loss 3.9933 (4.1979)
2022-11-03 01:22:02,929:INFO: Batch:  7/31	Total Loss 3.6556 (4.1357)
2022-11-03 01:22:03,394:INFO: Batch:  8/31	Total Loss 4.0575 (4.1270)
2022-11-03 01:22:03,857:INFO: Batch:  9/31	Total Loss 3.7442 (4.0914)
2022-11-03 01:22:04,323:INFO: Batch: 10/31	Total Loss 3.9836 (4.0827)
2022-11-03 01:22:04,788:INFO: Batch: 11/31	Total Loss 4.7520 (4.1336)
2022-11-03 01:22:05,257:INFO: Batch: 12/31	Total Loss 4.0865 (4.1300)
2022-11-03 01:22:05,727:INFO: Batch: 13/31	Total Loss 4.0923 (4.1273)
2022-11-03 01:22:06,274:INFO: Batch: 14/31	Total Loss 4.9105 (4.1867)
2022-11-03 01:22:06,745:INFO: Batch: 15/31	Total Loss 3.8457 (4.1662)
2022-11-03 01:22:07,214:INFO: Batch: 16/31	Total Loss 3.9913 (4.1549)
2022-11-03 01:22:07,687:INFO: Batch: 17/31	Total Loss 4.1093 (4.1526)
2022-11-03 01:22:08,157:INFO: Batch: 18/31	Total Loss 4.3881 (4.1666)
2022-11-03 01:22:08,624:INFO: Batch: 19/31	Total Loss 3.9103 (4.1530)
2022-11-03 01:22:09,093:INFO: Batch: 20/31	Total Loss 3.9760 (4.1449)
2022-11-03 01:22:09,561:INFO: Batch: 21/31	Total Loss 4.2282 (4.1487)
2022-11-03 01:22:10,029:INFO: Batch: 22/31	Total Loss 5.4441 (4.1989)
2022-11-03 01:22:10,501:INFO: Batch: 23/31	Total Loss 4.4018 (4.2064)
2022-11-03 01:22:10,968:INFO: Batch: 24/31	Total Loss 3.8805 (4.1932)
2022-11-03 01:22:11,435:INFO: Batch: 25/31	Total Loss 3.5368 (4.1687)
2022-11-03 01:22:11,902:INFO: Batch: 26/31	Total Loss 4.0023 (4.1627)
2022-11-03 01:22:12,371:INFO: Batch: 27/31	Total Loss 4.1219 (4.1613)
2022-11-03 01:22:12,838:INFO: Batch: 28/31	Total Loss 4.6094 (4.1765)
2022-11-03 01:22:13,307:INFO: Batch: 29/31	Total Loss 4.1208 (4.1745)
2022-11-03 01:22:13,691:INFO: Batch: 30/31	Total Loss 1.4433 (4.1490)
2022-11-03 01:22:13,834:INFO: - Computing ADE (validation o)
2022-11-03 01:22:14,442:INFO: 		 ADE on eth                       dataset:	 0.9508159160614014
2022-11-03 01:22:14,443:INFO: Average validation o:	ADE  0.9508	FDE  1.8859
2022-11-03 01:22:14,443:INFO: - Computing ADE (validation)
2022-11-03 01:22:14,713:INFO: 		 ADE on hotel                     dataset:	 0.40058037638664246
2022-11-03 01:22:15,016:INFO: 		 ADE on univ                      dataset:	 0.5455929636955261
2022-11-03 01:22:15,288:INFO: 		 ADE on zara1                     dataset:	 0.42693987488746643
2022-11-03 01:22:15,630:INFO: 		 ADE on zara2                     dataset:	 0.4176832139492035
2022-11-03 01:22:15,631:INFO: Average validation:	ADE  0.4838	FDE  1.0169
2022-11-03 01:22:15,631:INFO: - Computing ADE (training)
2022-11-03 01:22:16,080:INFO: 		 ADE on hotel                     dataset:	 0.4224787652492523
2022-11-03 01:22:16,786:INFO: 		 ADE on univ                      dataset:	 0.5446505546569824
2022-11-03 01:22:17,337:INFO: 		 ADE on zara1                     dataset:	 0.47938719391822815
2022-11-03 01:22:18,072:INFO: 		 ADE on zara2                     dataset:	 0.4198055863380432
2022-11-03 01:22:18,072:INFO: Average training:	ADE  0.5120	FDE  1.0839
2022-11-03 01:22:18,089:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_525.pth.tar
2022-11-03 01:22:18,089:INFO: 
===> EPOCH: 526 (P3)
2022-11-03 01:22:18,090:INFO: - Computing loss (training)
2022-11-03 01:22:19,190:INFO: Batch:  0/31	Total Loss 4.0999 (4.0999)
2022-11-03 01:22:19,660:INFO: Batch:  1/31	Total Loss 4.3016 (4.2010)
2022-11-03 01:22:20,129:INFO: Batch:  2/31	Total Loss 4.0453 (4.1488)
2022-11-03 01:22:20,602:INFO: Batch:  3/31	Total Loss 4.2805 (4.1800)
2022-11-03 01:22:21,065:INFO: Batch:  4/31	Total Loss 4.5900 (4.2673)
2022-11-03 01:22:21,537:INFO: Batch:  5/31	Total Loss 3.8252 (4.1913)
2022-11-03 01:22:22,004:INFO: Batch:  6/31	Total Loss 4.2037 (4.1932)
2022-11-03 01:22:22,471:INFO: Batch:  7/31	Total Loss 3.8482 (4.1461)
2022-11-03 01:22:22,940:INFO: Batch:  8/31	Total Loss 4.1235 (4.1441)
2022-11-03 01:22:23,405:INFO: Batch:  9/31	Total Loss 4.2331 (4.1534)
2022-11-03 01:22:23,870:INFO: Batch: 10/31	Total Loss 4.4014 (4.1760)
2022-11-03 01:22:24,337:INFO: Batch: 11/31	Total Loss 4.1503 (4.1738)
2022-11-03 01:22:24,808:INFO: Batch: 12/31	Total Loss 4.3486 (4.1875)
2022-11-03 01:22:25,276:INFO: Batch: 13/31	Total Loss 3.7379 (4.1541)
2022-11-03 01:22:25,747:INFO: Batch: 14/31	Total Loss 4.2153 (4.1579)
2022-11-03 01:22:26,218:INFO: Batch: 15/31	Total Loss 4.2625 (4.1651)
2022-11-03 01:22:26,687:INFO: Batch: 16/31	Total Loss 3.5799 (4.1271)
2022-11-03 01:22:27,162:INFO: Batch: 17/31	Total Loss 4.6067 (4.1545)
2022-11-03 01:22:27,632:INFO: Batch: 18/31	Total Loss 4.1989 (4.1567)
2022-11-03 01:22:28,102:INFO: Batch: 19/31	Total Loss 3.9083 (4.1444)
2022-11-03 01:22:28,571:INFO: Batch: 20/31	Total Loss 3.8258 (4.1275)
2022-11-03 01:22:29,039:INFO: Batch: 21/31	Total Loss 4.8624 (4.1575)
2022-11-03 01:22:29,509:INFO: Batch: 22/31	Total Loss 4.0087 (4.1515)
2022-11-03 01:22:29,979:INFO: Batch: 23/31	Total Loss 4.1531 (4.1515)
2022-11-03 01:22:30,448:INFO: Batch: 24/31	Total Loss 4.1164 (4.1503)
2022-11-03 01:22:30,917:INFO: Batch: 25/31	Total Loss 3.7146 (4.1341)
2022-11-03 01:22:31,385:INFO: Batch: 26/31	Total Loss 4.5978 (4.1505)
2022-11-03 01:22:31,851:INFO: Batch: 27/31	Total Loss 3.8563 (4.1405)
2022-11-03 01:22:32,319:INFO: Batch: 28/31	Total Loss 4.0835 (4.1386)
2022-11-03 01:22:32,789:INFO: Batch: 29/31	Total Loss 3.9880 (4.1327)
2022-11-03 01:22:33,173:INFO: Batch: 30/31	Total Loss 1.6171 (4.1071)
2022-11-03 01:22:33,315:INFO: - Computing ADE (validation o)
2022-11-03 01:22:33,924:INFO: 		 ADE on eth                       dataset:	 0.9440975785255432
2022-11-03 01:22:33,925:INFO: Average validation o:	ADE  0.9441	FDE  1.8710
2022-11-03 01:22:33,925:INFO: - Computing ADE (validation)
2022-11-03 01:22:34,195:INFO: 		 ADE on hotel                     dataset:	 0.4335511028766632
2022-11-03 01:22:34,486:INFO: 		 ADE on univ                      dataset:	 0.5499813556671143
2022-11-03 01:22:34,749:INFO: 		 ADE on zara1                     dataset:	 0.4008956253528595
2022-11-03 01:22:35,105:INFO: 		 ADE on zara2                     dataset:	 0.4304436147212982
2022-11-03 01:22:35,106:INFO: Average validation:	ADE  0.4911	FDE  1.0282
2022-11-03 01:22:35,106:INFO: - Computing ADE (training)
2022-11-03 01:22:35,573:INFO: 		 ADE on hotel                     dataset:	 0.44607263803482056
2022-11-03 01:22:36,253:INFO: 		 ADE on univ                      dataset:	 0.5523008108139038
2022-11-03 01:22:36,802:INFO: 		 ADE on zara1                     dataset:	 0.48836779594421387
2022-11-03 01:22:37,570:INFO: 		 ADE on zara2                     dataset:	 0.4329986274242401
2022-11-03 01:22:37,570:INFO: Average training:	ADE  0.5213	FDE  1.0996
2022-11-03 01:22:37,579:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_526.pth.tar
2022-11-03 01:22:37,579:INFO: 
===> EPOCH: 527 (P3)
2022-11-03 01:22:37,580:INFO: - Computing loss (training)
2022-11-03 01:22:38,686:INFO: Batch:  0/31	Total Loss 4.0954 (4.0954)
2022-11-03 01:22:39,174:INFO: Batch:  1/31	Total Loss 4.2333 (4.1624)
2022-11-03 01:22:39,662:INFO: Batch:  2/31	Total Loss 3.9362 (4.0815)
2022-11-03 01:22:40,146:INFO: Batch:  3/31	Total Loss 4.2352 (4.1152)
2022-11-03 01:22:40,629:INFO: Batch:  4/31	Total Loss 4.0227 (4.0971)
2022-11-03 01:22:41,117:INFO: Batch:  5/31	Total Loss 3.8653 (4.0546)
2022-11-03 01:22:41,598:INFO: Batch:  6/31	Total Loss 3.9236 (4.0350)
2022-11-03 01:22:42,080:INFO: Batch:  7/31	Total Loss 4.4408 (4.0867)
2022-11-03 01:22:42,560:INFO: Batch:  8/31	Total Loss 3.6334 (4.0321)
2022-11-03 01:22:43,041:INFO: Batch:  9/31	Total Loss 3.8932 (4.0185)
2022-11-03 01:22:43,522:INFO: Batch: 10/31	Total Loss 3.9673 (4.0140)
2022-11-03 01:22:44,003:INFO: Batch: 11/31	Total Loss 4.0181 (4.0144)
2022-11-03 01:22:44,488:INFO: Batch: 12/31	Total Loss 3.8270 (3.9989)
2022-11-03 01:22:44,974:INFO: Batch: 13/31	Total Loss 3.8858 (3.9904)
2022-11-03 01:22:45,458:INFO: Batch: 14/31	Total Loss 4.7627 (4.0370)
2022-11-03 01:22:45,943:INFO: Batch: 15/31	Total Loss 4.2670 (4.0525)
2022-11-03 01:22:46,432:INFO: Batch: 16/31	Total Loss 4.2215 (4.0622)
2022-11-03 01:22:46,916:INFO: Batch: 17/31	Total Loss 4.1455 (4.0664)
2022-11-03 01:22:47,407:INFO: Batch: 18/31	Total Loss 4.1054 (4.0684)
2022-11-03 01:22:47,889:INFO: Batch: 19/31	Total Loss 3.6754 (4.0490)
2022-11-03 01:22:48,370:INFO: Batch: 20/31	Total Loss 5.1038 (4.0967)
2022-11-03 01:22:48,850:INFO: Batch: 21/31	Total Loss 4.3526 (4.1071)
2022-11-03 01:22:49,333:INFO: Batch: 22/31	Total Loss 3.9024 (4.0979)
2022-11-03 01:22:49,814:INFO: Batch: 23/31	Total Loss 3.6019 (4.0784)
2022-11-03 01:22:50,295:INFO: Batch: 24/31	Total Loss 3.7594 (4.0653)
2022-11-03 01:22:50,779:INFO: Batch: 25/31	Total Loss 4.7291 (4.0895)
2022-11-03 01:22:51,260:INFO: Batch: 26/31	Total Loss 3.7915 (4.0772)
2022-11-03 01:22:51,741:INFO: Batch: 27/31	Total Loss 4.2805 (4.0844)
2022-11-03 01:22:52,221:INFO: Batch: 28/31	Total Loss 4.1758 (4.0876)
2022-11-03 01:22:52,704:INFO: Batch: 29/31	Total Loss 3.9391 (4.0831)
2022-11-03 01:22:53,098:INFO: Batch: 30/31	Total Loss 1.4082 (4.0609)
2022-11-03 01:22:53,245:INFO: - Computing ADE (validation o)
2022-11-03 01:22:53,829:INFO: 		 ADE on eth                       dataset:	 0.9140312671661377
2022-11-03 01:22:53,830:INFO: Average validation o:	ADE  0.9140	FDE  1.8107
2022-11-03 01:22:53,830:INFO: - Computing ADE (validation)
2022-11-03 01:22:54,114:INFO: 		 ADE on hotel                     dataset:	 0.39311325550079346
2022-11-03 01:22:54,410:INFO: 		 ADE on univ                      dataset:	 0.538917064666748
2022-11-03 01:22:54,676:INFO: 		 ADE on zara1                     dataset:	 0.41643664240837097
2022-11-03 01:22:55,015:INFO: 		 ADE on zara2                     dataset:	 0.3873153626918793
2022-11-03 01:22:55,015:INFO: Average validation:	ADE  0.4682	FDE  0.9760
2022-11-03 01:22:55,016:INFO: - Computing ADE (training)
2022-11-03 01:22:55,459:INFO: 		 ADE on hotel                     dataset:	 0.41080084443092346
2022-11-03 01:22:56,149:INFO: 		 ADE on univ                      dataset:	 0.5312830805778503
2022-11-03 01:22:56,675:INFO: 		 ADE on zara1                     dataset:	 0.45531463623046875
2022-11-03 01:22:57,459:INFO: 		 ADE on zara2                     dataset:	 0.38695308566093445
2022-11-03 01:22:57,459:INFO: Average training:	ADE  0.4941	FDE  1.0354
2022-11-03 01:22:57,477:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_527.pth.tar
2022-11-03 01:22:57,477:INFO: 
===> EPOCH: 528 (P3)
2022-11-03 01:22:57,477:INFO: - Computing loss (training)
2022-11-03 01:22:58,600:INFO: Batch:  0/31	Total Loss 4.4819 (4.4819)
2022-11-03 01:22:59,068:INFO: Batch:  1/31	Total Loss 3.5624 (4.0262)
2022-11-03 01:22:59,545:INFO: Batch:  2/31	Total Loss 3.8095 (3.9521)
2022-11-03 01:23:00,012:INFO: Batch:  3/31	Total Loss 3.9001 (3.9388)
2022-11-03 01:23:00,555:INFO: Batch:  4/31	Total Loss 4.2696 (4.0068)
2022-11-03 01:23:01,023:INFO: Batch:  5/31	Total Loss 4.0668 (4.0162)
2022-11-03 01:23:01,494:INFO: Batch:  6/31	Total Loss 3.9242 (4.0030)
2022-11-03 01:23:01,962:INFO: Batch:  7/31	Total Loss 4.3170 (4.0444)
2022-11-03 01:23:02,428:INFO: Batch:  8/31	Total Loss 3.8032 (4.0157)
2022-11-03 01:23:02,894:INFO: Batch:  9/31	Total Loss 4.0440 (4.0186)
2022-11-03 01:23:03,361:INFO: Batch: 10/31	Total Loss 3.9830 (4.0155)
2022-11-03 01:23:03,826:INFO: Batch: 11/31	Total Loss 4.6163 (4.0710)
2022-11-03 01:23:04,296:INFO: Batch: 12/31	Total Loss 4.0190 (4.0670)
2022-11-03 01:23:04,766:INFO: Batch: 13/31	Total Loss 4.9343 (4.1333)
2022-11-03 01:23:05,236:INFO: Batch: 14/31	Total Loss 4.0747 (4.1294)
2022-11-03 01:23:05,705:INFO: Batch: 15/31	Total Loss 4.8503 (4.1767)
2022-11-03 01:23:06,175:INFO: Batch: 16/31	Total Loss 3.8008 (4.1546)
2022-11-03 01:23:06,645:INFO: Batch: 17/31	Total Loss 4.2129 (4.1581)
2022-11-03 01:23:07,113:INFO: Batch: 18/31	Total Loss 4.5121 (4.1787)
2022-11-03 01:23:07,585:INFO: Batch: 19/31	Total Loss 4.8207 (4.2105)
2022-11-03 01:23:08,054:INFO: Batch: 20/31	Total Loss 4.7122 (4.2367)
2022-11-03 01:23:08,521:INFO: Batch: 21/31	Total Loss 4.3994 (4.2441)
2022-11-03 01:23:08,991:INFO: Batch: 22/31	Total Loss 4.2344 (4.2437)
2022-11-03 01:23:09,459:INFO: Batch: 23/31	Total Loss 4.0238 (4.2352)
2022-11-03 01:23:09,928:INFO: Batch: 24/31	Total Loss 3.7068 (4.2134)
2022-11-03 01:23:10,397:INFO: Batch: 25/31	Total Loss 5.2804 (4.2530)
2022-11-03 01:23:10,868:INFO: Batch: 26/31	Total Loss 3.8085 (4.2375)
2022-11-03 01:23:11,335:INFO: Batch: 27/31	Total Loss 4.4027 (4.2441)
2022-11-03 01:23:11,802:INFO: Batch: 28/31	Total Loss 4.1410 (4.2401)
2022-11-03 01:23:12,270:INFO: Batch: 29/31	Total Loss 4.7507 (4.2570)
2022-11-03 01:23:12,654:INFO: Batch: 30/31	Total Loss 1.5524 (4.2342)
2022-11-03 01:23:12,805:INFO: - Computing ADE (validation o)
2022-11-03 01:23:13,396:INFO: 		 ADE on eth                       dataset:	 0.949783444404602
2022-11-03 01:23:13,396:INFO: Average validation o:	ADE  0.9498	FDE  1.8888
2022-11-03 01:23:13,397:INFO: - Computing ADE (validation)
2022-11-03 01:23:13,668:INFO: 		 ADE on hotel                     dataset:	 0.4147312641143799
2022-11-03 01:23:13,951:INFO: 		 ADE on univ                      dataset:	 0.5505338311195374
2022-11-03 01:23:14,208:INFO: 		 ADE on zara1                     dataset:	 0.43321356177330017
2022-11-03 01:23:14,554:INFO: 		 ADE on zara2                     dataset:	 0.4264736771583557
2022-11-03 01:23:14,554:INFO: Average validation:	ADE  0.4908	FDE  1.0298
2022-11-03 01:23:14,555:INFO: - Computing ADE (training)
2022-11-03 01:23:14,999:INFO: 		 ADE on hotel                     dataset:	 0.4404873847961426
2022-11-03 01:23:15,727:INFO: 		 ADE on univ                      dataset:	 0.548414409160614
2022-11-03 01:23:16,287:INFO: 		 ADE on zara1                     dataset:	 0.494630366563797
2022-11-03 01:23:17,024:INFO: 		 ADE on zara2                     dataset:	 0.4312981963157654
2022-11-03 01:23:17,024:INFO: Average training:	ADE  0.5185	FDE  1.0962
2022-11-03 01:23:17,032:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_528.pth.tar
2022-11-03 01:23:17,033:INFO: 
===> EPOCH: 529 (P3)
2022-11-03 01:23:17,033:INFO: - Computing loss (training)
2022-11-03 01:23:18,145:INFO: Batch:  0/31	Total Loss 4.2143 (4.2143)
2022-11-03 01:23:18,618:INFO: Batch:  1/31	Total Loss 3.8093 (3.9968)
2022-11-03 01:23:19,094:INFO: Batch:  2/31	Total Loss 4.6696 (4.2238)
2022-11-03 01:23:19,567:INFO: Batch:  3/31	Total Loss 4.4042 (4.2701)
2022-11-03 01:23:20,042:INFO: Batch:  4/31	Total Loss 3.8698 (4.1860)
2022-11-03 01:23:20,517:INFO: Batch:  5/31	Total Loss 4.0799 (4.1682)
2022-11-03 01:23:20,990:INFO: Batch:  6/31	Total Loss 4.5155 (4.2199)
2022-11-03 01:23:21,462:INFO: Batch:  7/31	Total Loss 3.7983 (4.1677)
2022-11-03 01:23:21,935:INFO: Batch:  8/31	Total Loss 4.2130 (4.1722)
2022-11-03 01:23:22,407:INFO: Batch:  9/31	Total Loss 3.6928 (4.1188)
2022-11-03 01:23:22,879:INFO: Batch: 10/31	Total Loss 5.4433 (4.2358)
2022-11-03 01:23:23,349:INFO: Batch: 11/31	Total Loss 4.1047 (4.2257)
2022-11-03 01:23:23,822:INFO: Batch: 12/31	Total Loss 3.9575 (4.2045)
2022-11-03 01:23:24,297:INFO: Batch: 13/31	Total Loss 3.5543 (4.1556)
2022-11-03 01:23:24,770:INFO: Batch: 14/31	Total Loss 4.1360 (4.1542)
2022-11-03 01:23:25,245:INFO: Batch: 15/31	Total Loss 4.1536 (4.1542)
2022-11-03 01:23:25,719:INFO: Batch: 16/31	Total Loss 4.0582 (4.1486)
2022-11-03 01:23:26,192:INFO: Batch: 17/31	Total Loss 4.1731 (4.1502)
2022-11-03 01:23:26,666:INFO: Batch: 18/31	Total Loss 4.2304 (4.1541)
2022-11-03 01:23:27,140:INFO: Batch: 19/31	Total Loss 3.7526 (4.1333)
2022-11-03 01:23:27,614:INFO: Batch: 20/31	Total Loss 4.5989 (4.1556)
2022-11-03 01:23:28,087:INFO: Batch: 21/31	Total Loss 3.9774 (4.1475)
2022-11-03 01:23:28,561:INFO: Batch: 22/31	Total Loss 4.3163 (4.1552)
2022-11-03 01:23:29,034:INFO: Batch: 23/31	Total Loss 4.4484 (4.1691)
2022-11-03 01:23:29,506:INFO: Batch: 24/31	Total Loss 3.9523 (4.1604)
2022-11-03 01:23:29,979:INFO: Batch: 25/31	Total Loss 4.0317 (4.1554)
2022-11-03 01:23:30,453:INFO: Batch: 26/31	Total Loss 4.0433 (4.1514)
2022-11-03 01:23:30,925:INFO: Batch: 27/31	Total Loss 4.2044 (4.1532)
2022-11-03 01:23:31,398:INFO: Batch: 28/31	Total Loss 4.0519 (4.1494)
2022-11-03 01:23:31,870:INFO: Batch: 29/31	Total Loss 3.9137 (4.1405)
2022-11-03 01:23:32,258:INFO: Batch: 30/31	Total Loss 1.5173 (4.1162)
2022-11-03 01:23:32,407:INFO: - Computing ADE (validation o)
2022-11-03 01:23:32,993:INFO: 		 ADE on eth                       dataset:	 0.9217705130577087
2022-11-03 01:23:32,993:INFO: Average validation o:	ADE  0.9218	FDE  1.8210
2022-11-03 01:23:32,994:INFO: - Computing ADE (validation)
2022-11-03 01:23:33,256:INFO: 		 ADE on hotel                     dataset:	 0.40270471572875977
2022-11-03 01:23:33,555:INFO: 		 ADE on univ                      dataset:	 0.5457903742790222
2022-11-03 01:23:33,804:INFO: 		 ADE on zara1                     dataset:	 0.4061359167098999
2022-11-03 01:23:34,162:INFO: 		 ADE on zara2                     dataset:	 0.38855186104774475
2022-11-03 01:23:34,162:INFO: Average validation:	ADE  0.4722	FDE  0.9850
2022-11-03 01:23:34,163:INFO: - Computing ADE (training)
2022-11-03 01:23:34,615:INFO: 		 ADE on hotel                     dataset:	 0.4309103488922119
2022-11-03 01:23:35,302:INFO: 		 ADE on univ                      dataset:	 0.5354081392288208
2022-11-03 01:23:35,846:INFO: 		 ADE on zara1                     dataset:	 0.45545119047164917
2022-11-03 01:23:36,623:INFO: 		 ADE on zara2                     dataset:	 0.3880853056907654
2022-11-03 01:23:36,623:INFO: Average training:	ADE  0.4978	FDE  1.0417
2022-11-03 01:23:36,632:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_529.pth.tar
2022-11-03 01:23:36,632:INFO: 
===> EPOCH: 530 (P3)
2022-11-03 01:23:36,632:INFO: - Computing loss (training)
2022-11-03 01:23:37,746:INFO: Batch:  0/31	Total Loss 3.9130 (3.9130)
2022-11-03 01:23:38,222:INFO: Batch:  1/31	Total Loss 3.9460 (3.9296)
2022-11-03 01:23:38,708:INFO: Batch:  2/31	Total Loss 4.1926 (4.0068)
2022-11-03 01:23:39,183:INFO: Batch:  3/31	Total Loss 6.2879 (4.5498)
2022-11-03 01:23:39,662:INFO: Batch:  4/31	Total Loss 3.9742 (4.4326)
2022-11-03 01:23:40,140:INFO: Batch:  5/31	Total Loss 3.8865 (4.3360)
2022-11-03 01:23:40,618:INFO: Batch:  6/31	Total Loss 4.3507 (4.3380)
2022-11-03 01:23:41,093:INFO: Batch:  7/31	Total Loss 4.4893 (4.3560)
2022-11-03 01:23:41,567:INFO: Batch:  8/31	Total Loss 4.3991 (4.3606)
2022-11-03 01:23:42,031:INFO: Batch:  9/31	Total Loss 3.9085 (4.3111)
2022-11-03 01:23:42,499:INFO: Batch: 10/31	Total Loss 4.3606 (4.3157)
2022-11-03 01:23:42,976:INFO: Batch: 11/31	Total Loss 3.9226 (4.2802)
2022-11-03 01:23:43,457:INFO: Batch: 12/31	Total Loss 4.5868 (4.3028)
2022-11-03 01:23:43,936:INFO: Batch: 13/31	Total Loss 4.0019 (4.2821)
2022-11-03 01:23:44,418:INFO: Batch: 14/31	Total Loss 4.1946 (4.2764)
2022-11-03 01:23:44,898:INFO: Batch: 15/31	Total Loss 4.0588 (4.2622)
2022-11-03 01:23:45,379:INFO: Batch: 16/31	Total Loss 3.7972 (4.2341)
2022-11-03 01:23:45,861:INFO: Batch: 17/31	Total Loss 3.7164 (4.2089)
2022-11-03 01:23:46,342:INFO: Batch: 18/31	Total Loss 5.1220 (4.2491)
2022-11-03 01:23:46,811:INFO: Batch: 19/31	Total Loss 4.3600 (4.2543)
2022-11-03 01:23:47,280:INFO: Batch: 20/31	Total Loss 3.9110 (4.2373)
2022-11-03 01:23:47,750:INFO: Batch: 21/31	Total Loss 3.9639 (4.2251)
2022-11-03 01:23:48,219:INFO: Batch: 22/31	Total Loss 4.7412 (4.2469)
2022-11-03 01:23:48,687:INFO: Batch: 23/31	Total Loss 4.2472 (4.2469)
2022-11-03 01:23:49,156:INFO: Batch: 24/31	Total Loss 4.2329 (4.2464)
2022-11-03 01:23:49,625:INFO: Batch: 25/31	Total Loss 3.6440 (4.2217)
2022-11-03 01:23:50,169:INFO: Batch: 26/31	Total Loss 5.0477 (4.2512)
2022-11-03 01:23:50,637:INFO: Batch: 27/31	Total Loss 4.2651 (4.2517)
2022-11-03 01:23:51,104:INFO: Batch: 28/31	Total Loss 3.6100 (4.2301)
2022-11-03 01:23:51,572:INFO: Batch: 29/31	Total Loss 4.2533 (4.2310)
2022-11-03 01:23:51,958:INFO: Batch: 30/31	Total Loss 1.7298 (4.2114)
2022-11-03 01:23:52,108:INFO: - Computing ADE (validation o)
2022-11-03 01:23:52,743:INFO: 		 ADE on eth                       dataset:	 0.9452807307243347
2022-11-03 01:23:52,743:INFO: Average validation o:	ADE  0.9453	FDE  1.8569
2022-11-03 01:23:52,744:INFO: - Computing ADE (validation)
2022-11-03 01:23:53,028:INFO: 		 ADE on hotel                     dataset:	 0.42625707387924194
2022-11-03 01:23:53,334:INFO: 		 ADE on univ                      dataset:	 0.5570030212402344
2022-11-03 01:23:53,633:INFO: 		 ADE on zara1                     dataset:	 0.435298889875412
2022-11-03 01:23:53,982:INFO: 		 ADE on zara2                     dataset:	 0.42953193187713623
2022-11-03 01:23:53,983:INFO: Average validation:	ADE  0.4960	FDE  1.0461
2022-11-03 01:23:53,992:INFO: - Computing ADE (training)
2022-11-03 01:23:54,433:INFO: 		 ADE on hotel                     dataset:	 0.45442306995391846
2022-11-03 01:23:55,121:INFO: 		 ADE on univ                      dataset:	 0.553286075592041
2022-11-03 01:23:55,655:INFO: 		 ADE on zara1                     dataset:	 0.4948602318763733
2022-11-03 01:23:56,381:INFO: 		 ADE on zara2                     dataset:	 0.4340616464614868
2022-11-03 01:23:56,381:INFO: Average training:	ADE  0.5229	FDE  1.1096
2022-11-03 01:23:56,389:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_530.pth.tar
2022-11-03 01:23:56,390:INFO: 
===> EPOCH: 531 (P3)
2022-11-03 01:23:56,390:INFO: - Computing loss (training)
2022-11-03 01:23:57,486:INFO: Batch:  0/31	Total Loss 4.0342 (4.0342)
2022-11-03 01:23:57,959:INFO: Batch:  1/31	Total Loss 4.3852 (4.2212)
2022-11-03 01:23:58,433:INFO: Batch:  2/31	Total Loss 4.0216 (4.1534)
2022-11-03 01:23:58,903:INFO: Batch:  3/31	Total Loss 4.0446 (4.1222)
2022-11-03 01:23:59,371:INFO: Batch:  4/31	Total Loss 4.3070 (4.1586)
2022-11-03 01:23:59,847:INFO: Batch:  5/31	Total Loss 3.9452 (4.1262)
2022-11-03 01:24:00,318:INFO: Batch:  6/31	Total Loss 3.9131 (4.0946)
2022-11-03 01:24:00,788:INFO: Batch:  7/31	Total Loss 4.3730 (4.1285)
2022-11-03 01:24:01,262:INFO: Batch:  8/31	Total Loss 3.8116 (4.0941)
2022-11-03 01:24:01,732:INFO: Batch:  9/31	Total Loss 4.7800 (4.1652)
2022-11-03 01:24:02,202:INFO: Batch: 10/31	Total Loss 4.0624 (4.1549)
2022-11-03 01:24:02,673:INFO: Batch: 11/31	Total Loss 3.9717 (4.1373)
2022-11-03 01:24:03,145:INFO: Batch: 12/31	Total Loss 4.5486 (4.1691)
2022-11-03 01:24:03,620:INFO: Batch: 13/31	Total Loss 2.9217 (4.0814)
2022-11-03 01:24:04,095:INFO: Batch: 14/31	Total Loss 4.4174 (4.1021)
2022-11-03 01:24:04,571:INFO: Batch: 15/31	Total Loss 4.0030 (4.0954)
2022-11-03 01:24:05,045:INFO: Batch: 16/31	Total Loss 4.2952 (4.1076)
2022-11-03 01:24:05,518:INFO: Batch: 17/31	Total Loss 4.1908 (4.1123)
2022-11-03 01:24:05,991:INFO: Batch: 18/31	Total Loss 4.0650 (4.1096)
2022-11-03 01:24:06,464:INFO: Batch: 19/31	Total Loss 3.8995 (4.0989)
2022-11-03 01:24:06,936:INFO: Batch: 20/31	Total Loss 4.2378 (4.1060)
2022-11-03 01:24:07,410:INFO: Batch: 21/31	Total Loss 4.4622 (4.1216)
2022-11-03 01:24:07,884:INFO: Batch: 22/31	Total Loss 4.5591 (4.1411)
2022-11-03 01:24:08,359:INFO: Batch: 23/31	Total Loss 4.0785 (4.1386)
2022-11-03 01:24:08,829:INFO: Batch: 24/31	Total Loss 3.8998 (4.1281)
2022-11-03 01:24:09,301:INFO: Batch: 25/31	Total Loss 4.4684 (4.1405)
2022-11-03 01:24:09,773:INFO: Batch: 26/31	Total Loss 4.1447 (4.1406)
2022-11-03 01:24:10,246:INFO: Batch: 27/31	Total Loss 4.1885 (4.1423)
2022-11-03 01:24:10,721:INFO: Batch: 28/31	Total Loss 3.7412 (4.1292)
2022-11-03 01:24:11,200:INFO: Batch: 29/31	Total Loss 4.6783 (4.1474)
2022-11-03 01:24:11,589:INFO: Batch: 30/31	Total Loss 1.7817 (4.1303)
2022-11-03 01:24:11,740:INFO: - Computing ADE (validation o)
2022-11-03 01:24:12,333:INFO: 		 ADE on eth                       dataset:	 0.9436337947845459
2022-11-03 01:24:12,333:INFO: Average validation o:	ADE  0.9436	FDE  1.8649
2022-11-03 01:24:12,334:INFO: - Computing ADE (validation)
2022-11-03 01:24:12,632:INFO: 		 ADE on hotel                     dataset:	 0.44297289848327637
2022-11-03 01:24:12,923:INFO: 		 ADE on univ                      dataset:	 0.5534626245498657
2022-11-03 01:24:13,164:INFO: 		 ADE on zara1                     dataset:	 0.41512858867645264
2022-11-03 01:24:13,504:INFO: 		 ADE on zara2                     dataset:	 0.4336160719394684
2022-11-03 01:24:13,504:INFO: Average validation:	ADE  0.4954	FDE  1.0429
2022-11-03 01:24:13,505:INFO: - Computing ADE (training)
2022-11-03 01:24:13,995:INFO: 		 ADE on hotel                     dataset:	 0.45994460582733154
2022-11-03 01:24:14,672:INFO: 		 ADE on univ                      dataset:	 0.5560256838798523
2022-11-03 01:24:15,219:INFO: 		 ADE on zara1                     dataset:	 0.49253132939338684
2022-11-03 01:24:16,002:INFO: 		 ADE on zara2                     dataset:	 0.436266154050827
2022-11-03 01:24:16,002:INFO: Average training:	ADE  0.5252	FDE  1.1145
2022-11-03 01:24:16,011:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_531.pth.tar
2022-11-03 01:24:16,011:INFO: 
===> EPOCH: 532 (P3)
2022-11-03 01:24:16,012:INFO: - Computing loss (training)
2022-11-03 01:24:17,102:INFO: Batch:  0/31	Total Loss 4.2511 (4.2511)
2022-11-03 01:24:17,572:INFO: Batch:  1/31	Total Loss 4.0027 (4.1291)
2022-11-03 01:24:18,042:INFO: Batch:  2/31	Total Loss 4.1184 (4.1258)
2022-11-03 01:24:18,510:INFO: Batch:  3/31	Total Loss 3.9384 (4.0754)
2022-11-03 01:24:18,974:INFO: Batch:  4/31	Total Loss 3.6715 (3.9890)
2022-11-03 01:24:19,450:INFO: Batch:  5/31	Total Loss 3.5471 (3.9171)
2022-11-03 01:24:19,914:INFO: Batch:  6/31	Total Loss 3.8338 (3.9043)
2022-11-03 01:24:20,382:INFO: Batch:  7/31	Total Loss 4.6002 (3.9901)
2022-11-03 01:24:20,854:INFO: Batch:  8/31	Total Loss 3.9327 (3.9831)
2022-11-03 01:24:21,321:INFO: Batch:  9/31	Total Loss 4.0344 (3.9884)
2022-11-03 01:24:21,784:INFO: Batch: 10/31	Total Loss 4.0609 (3.9942)
2022-11-03 01:24:22,251:INFO: Batch: 11/31	Total Loss 4.1668 (4.0085)
2022-11-03 01:24:22,725:INFO: Batch: 12/31	Total Loss 4.5906 (4.0577)
2022-11-03 01:24:23,195:INFO: Batch: 13/31	Total Loss 4.0535 (4.0574)
2022-11-03 01:24:23,666:INFO: Batch: 14/31	Total Loss 3.9390 (4.0495)
2022-11-03 01:24:24,137:INFO: Batch: 15/31	Total Loss 4.3407 (4.0706)
2022-11-03 01:24:24,607:INFO: Batch: 16/31	Total Loss 3.8550 (4.0591)
2022-11-03 01:24:25,079:INFO: Batch: 17/31	Total Loss 4.3499 (4.0750)
2022-11-03 01:24:25,550:INFO: Batch: 18/31	Total Loss 3.6283 (4.0498)
2022-11-03 01:24:26,020:INFO: Batch: 19/31	Total Loss 4.1162 (4.0537)
2022-11-03 01:24:26,490:INFO: Batch: 20/31	Total Loss 4.2315 (4.0621)
2022-11-03 01:24:26,958:INFO: Batch: 21/31	Total Loss 3.8972 (4.0548)
2022-11-03 01:24:27,428:INFO: Batch: 22/31	Total Loss 4.1880 (4.0602)
2022-11-03 01:24:27,896:INFO: Batch: 23/31	Total Loss 5.3183 (4.1121)
2022-11-03 01:24:28,372:INFO: Batch: 24/31	Total Loss 4.2783 (4.1192)
2022-11-03 01:24:28,847:INFO: Batch: 25/31	Total Loss 4.0167 (4.1148)
2022-11-03 01:24:29,322:INFO: Batch: 26/31	Total Loss 4.3353 (4.1223)
2022-11-03 01:24:29,798:INFO: Batch: 27/31	Total Loss 3.8796 (4.1140)
2022-11-03 01:24:30,276:INFO: Batch: 28/31	Total Loss 4.0286 (4.1113)
2022-11-03 01:24:30,752:INFO: Batch: 29/31	Total Loss 4.4120 (4.1211)
2022-11-03 01:24:31,143:INFO: Batch: 30/31	Total Loss 1.3663 (4.0918)
2022-11-03 01:24:31,305:INFO: - Computing ADE (validation o)
2022-11-03 01:24:31,923:INFO: 		 ADE on eth                       dataset:	 0.922309935092926
2022-11-03 01:24:31,924:INFO: Average validation o:	ADE  0.9223	FDE  1.8441
2022-11-03 01:24:31,924:INFO: - Computing ADE (validation)
2022-11-03 01:24:32,197:INFO: 		 ADE on hotel                     dataset:	 0.41120925545692444
2022-11-03 01:24:32,498:INFO: 		 ADE on univ                      dataset:	 0.5507317781448364
2022-11-03 01:24:32,766:INFO: 		 ADE on zara1                     dataset:	 0.40359511971473694
2022-11-03 01:24:33,128:INFO: 		 ADE on zara2                     dataset:	 0.3936517834663391
2022-11-03 01:24:33,128:INFO: Average validation:	ADE  0.4769	FDE  1.0028
2022-11-03 01:24:33,129:INFO: - Computing ADE (training)
2022-11-03 01:24:33,590:INFO: 		 ADE on hotel                     dataset:	 0.43849441409111023
2022-11-03 01:24:34,251:INFO: 		 ADE on univ                      dataset:	 0.5392129421234131
2022-11-03 01:24:34,767:INFO: 		 ADE on zara1                     dataset:	 0.4566991329193115
2022-11-03 01:24:35,494:INFO: 		 ADE on zara2                     dataset:	 0.3917507231235504
2022-11-03 01:24:35,495:INFO: Average training:	ADE  0.5015	FDE  1.0584
2022-11-03 01:24:35,503:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_532.pth.tar
2022-11-03 01:24:35,503:INFO: 
===> EPOCH: 533 (P3)
2022-11-03 01:24:35,503:INFO: - Computing loss (training)
2022-11-03 01:24:36,606:INFO: Batch:  0/31	Total Loss 3.9023 (3.9023)
2022-11-03 01:24:37,097:INFO: Batch:  1/31	Total Loss 4.0468 (3.9673)
2022-11-03 01:24:37,586:INFO: Batch:  2/31	Total Loss 4.1848 (4.0472)
2022-11-03 01:24:38,070:INFO: Batch:  3/31	Total Loss 3.9249 (4.0160)
2022-11-03 01:24:38,558:INFO: Batch:  4/31	Total Loss 4.0660 (4.0267)
2022-11-03 01:24:39,047:INFO: Batch:  5/31	Total Loss 4.3472 (4.0783)
2022-11-03 01:24:39,532:INFO: Batch:  6/31	Total Loss 3.9369 (4.0599)
2022-11-03 01:24:40,005:INFO: Batch:  7/31	Total Loss 4.4443 (4.1122)
2022-11-03 01:24:40,481:INFO: Batch:  8/31	Total Loss 4.0415 (4.1044)
2022-11-03 01:24:40,953:INFO: Batch:  9/31	Total Loss 4.5680 (4.1551)
2022-11-03 01:24:41,427:INFO: Batch: 10/31	Total Loss 4.9474 (4.2305)
2022-11-03 01:24:41,904:INFO: Batch: 11/31	Total Loss 4.8985 (4.2838)
2022-11-03 01:24:42,384:INFO: Batch: 12/31	Total Loss 4.4106 (4.2937)
2022-11-03 01:24:42,945:INFO: Batch: 13/31	Total Loss 3.9467 (4.2702)
2022-11-03 01:24:43,425:INFO: Batch: 14/31	Total Loss 3.9209 (4.2485)
2022-11-03 01:24:43,904:INFO: Batch: 15/31	Total Loss 3.8142 (4.2219)
2022-11-03 01:24:44,382:INFO: Batch: 16/31	Total Loss 3.9145 (4.2049)
2022-11-03 01:24:44,862:INFO: Batch: 17/31	Total Loss 5.9130 (4.3057)
2022-11-03 01:24:45,342:INFO: Batch: 18/31	Total Loss 4.3126 (4.3061)
2022-11-03 01:24:45,821:INFO: Batch: 19/31	Total Loss 4.1044 (4.2964)
2022-11-03 01:24:46,301:INFO: Batch: 20/31	Total Loss 4.4928 (4.3058)
2022-11-03 01:24:46,780:INFO: Batch: 21/31	Total Loss 4.1187 (4.2970)
2022-11-03 01:24:47,259:INFO: Batch: 22/31	Total Loss 4.7387 (4.3154)
2022-11-03 01:24:47,737:INFO: Batch: 23/31	Total Loss 4.4790 (4.3227)
2022-11-03 01:24:48,216:INFO: Batch: 24/31	Total Loss 4.4174 (4.3265)
2022-11-03 01:24:48,700:INFO: Batch: 25/31	Total Loss 4.8653 (4.3444)
2022-11-03 01:24:49,187:INFO: Batch: 26/31	Total Loss 4.5166 (4.3508)
2022-11-03 01:24:49,676:INFO: Batch: 27/31	Total Loss 4.5354 (4.3572)
2022-11-03 01:24:50,164:INFO: Batch: 28/31	Total Loss 4.2332 (4.3530)
2022-11-03 01:24:50,652:INFO: Batch: 29/31	Total Loss 3.9036 (4.3376)
2022-11-03 01:24:51,054:INFO: Batch: 30/31	Total Loss 1.4973 (4.3105)
2022-11-03 01:24:51,204:INFO: - Computing ADE (validation o)
2022-11-03 01:24:51,813:INFO: 		 ADE on eth                       dataset:	 0.9203182458877563
2022-11-03 01:24:51,813:INFO: Average validation o:	ADE  0.9203	FDE  1.8442
2022-11-03 01:24:51,813:INFO: - Computing ADE (validation)
2022-11-03 01:24:52,082:INFO: 		 ADE on hotel                     dataset:	 0.41501253843307495
2022-11-03 01:24:52,388:INFO: 		 ADE on univ                      dataset:	 0.555083692073822
2022-11-03 01:24:52,638:INFO: 		 ADE on zara1                     dataset:	 0.40820005536079407
2022-11-03 01:24:52,987:INFO: 		 ADE on zara2                     dataset:	 0.3960624933242798
2022-11-03 01:24:52,987:INFO: Average validation:	ADE  0.4805	FDE  1.0153
2022-11-03 01:24:52,988:INFO: - Computing ADE (training)
2022-11-03 01:24:53,432:INFO: 		 ADE on hotel                     dataset:	 0.4348714351654053
2022-11-03 01:24:54,126:INFO: 		 ADE on univ                      dataset:	 0.5424827933311462
2022-11-03 01:24:54,695:INFO: 		 ADE on zara1                     dataset:	 0.45030540227890015
2022-11-03 01:24:55,423:INFO: 		 ADE on zara2                     dataset:	 0.38919728994369507
2022-11-03 01:24:55,423:INFO: Average training:	ADE  0.5028	FDE  1.0642
2022-11-03 01:24:55,431:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_533.pth.tar
2022-11-03 01:24:55,432:INFO: 
===> EPOCH: 534 (P3)
2022-11-03 01:24:55,432:INFO: - Computing loss (training)
2022-11-03 01:24:56,538:INFO: Batch:  0/31	Total Loss 5.5173 (5.5173)
2022-11-03 01:24:57,024:INFO: Batch:  1/31	Total Loss 4.2351 (4.7738)
2022-11-03 01:24:57,507:INFO: Batch:  2/31	Total Loss 3.9874 (4.5293)
2022-11-03 01:24:57,988:INFO: Batch:  3/31	Total Loss 3.6186 (4.3074)
2022-11-03 01:24:58,476:INFO: Batch:  4/31	Total Loss 4.0255 (4.2405)
2022-11-03 01:24:58,961:INFO: Batch:  5/31	Total Loss 6.0471 (4.5236)
2022-11-03 01:24:59,443:INFO: Batch:  6/31	Total Loss 4.1987 (4.4749)
2022-11-03 01:24:59,923:INFO: Batch:  7/31	Total Loss 5.0261 (4.5408)
2022-11-03 01:25:00,410:INFO: Batch:  8/31	Total Loss 4.4454 (4.5293)
2022-11-03 01:25:00,894:INFO: Batch:  9/31	Total Loss 4.0531 (4.4788)
2022-11-03 01:25:01,378:INFO: Batch: 10/31	Total Loss 4.1064 (4.4463)
2022-11-03 01:25:01,860:INFO: Batch: 11/31	Total Loss 4.7661 (4.4748)
2022-11-03 01:25:02,391:INFO: Batch: 12/31	Total Loss 4.0815 (4.4416)
2022-11-03 01:25:02,873:INFO: Batch: 13/31	Total Loss 5.1545 (4.4950)
2022-11-03 01:25:03,353:INFO: Batch: 14/31	Total Loss 3.7113 (4.4453)
2022-11-03 01:25:03,832:INFO: Batch: 15/31	Total Loss 4.5487 (4.4512)
2022-11-03 01:25:04,311:INFO: Batch: 16/31	Total Loss 4.1341 (4.4333)
2022-11-03 01:25:04,788:INFO: Batch: 17/31	Total Loss 4.5341 (4.4383)
2022-11-03 01:25:05,264:INFO: Batch: 18/31	Total Loss 4.2330 (4.4266)
2022-11-03 01:25:05,741:INFO: Batch: 19/31	Total Loss 5.0986 (4.4608)
2022-11-03 01:25:06,218:INFO: Batch: 20/31	Total Loss 4.6212 (4.4679)
2022-11-03 01:25:06,693:INFO: Batch: 21/31	Total Loss 4.1123 (4.4517)
2022-11-03 01:25:07,170:INFO: Batch: 22/31	Total Loss 4.0478 (4.4333)
2022-11-03 01:25:07,650:INFO: Batch: 23/31	Total Loss 4.4598 (4.4345)
2022-11-03 01:25:08,126:INFO: Batch: 24/31	Total Loss 3.9404 (4.4137)
2022-11-03 01:25:08,606:INFO: Batch: 25/31	Total Loss 3.9019 (4.3953)
2022-11-03 01:25:09,083:INFO: Batch: 26/31	Total Loss 4.3717 (4.3944)
2022-11-03 01:25:09,558:INFO: Batch: 27/31	Total Loss 4.3283 (4.3920)
2022-11-03 01:25:10,034:INFO: Batch: 28/31	Total Loss 4.3177 (4.3894)
2022-11-03 01:25:10,511:INFO: Batch: 29/31	Total Loss 3.7038 (4.3661)
2022-11-03 01:25:10,903:INFO: Batch: 30/31	Total Loss 1.4394 (4.3345)
2022-11-03 01:25:11,060:INFO: - Computing ADE (validation o)
2022-11-03 01:25:11,667:INFO: 		 ADE on eth                       dataset:	 0.9423108696937561
2022-11-03 01:25:11,668:INFO: Average validation o:	ADE  0.9423	FDE  1.8858
2022-11-03 01:25:11,669:INFO: - Computing ADE (validation)
2022-11-03 01:25:11,946:INFO: 		 ADE on hotel                     dataset:	 0.4230124056339264
2022-11-03 01:25:12,238:INFO: 		 ADE on univ                      dataset:	 0.547924816608429
2022-11-03 01:25:12,489:INFO: 		 ADE on zara1                     dataset:	 0.40404391288757324
2022-11-03 01:25:12,831:INFO: 		 ADE on zara2                     dataset:	 0.41577404737472534
2022-11-03 01:25:12,831:INFO: Average validation:	ADE  0.4842	FDE  1.0141
2022-11-03 01:25:12,832:INFO: - Computing ADE (training)
2022-11-03 01:25:13,284:INFO: 		 ADE on hotel                     dataset:	 0.4452875256538391
2022-11-03 01:25:14,000:INFO: 		 ADE on univ                      dataset:	 0.547020435333252
2022-11-03 01:25:14,539:INFO: 		 ADE on zara1                     dataset:	 0.46971482038497925
2022-11-03 01:25:15,289:INFO: 		 ADE on zara2                     dataset:	 0.41521403193473816
2022-11-03 01:25:15,290:INFO: Average training:	ADE  0.5128	FDE  1.0815
2022-11-03 01:25:15,299:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_534.pth.tar
2022-11-03 01:25:15,299:INFO: 
===> EPOCH: 535 (P3)
2022-11-03 01:25:15,299:INFO: - Computing loss (training)
2022-11-03 01:25:16,403:INFO: Batch:  0/31	Total Loss 4.6124 (4.6124)
2022-11-03 01:25:16,873:INFO: Batch:  1/31	Total Loss 4.5224 (4.5706)
2022-11-03 01:25:17,349:INFO: Batch:  2/31	Total Loss 3.3295 (4.1235)
2022-11-03 01:25:17,818:INFO: Batch:  3/31	Total Loss 4.8507 (4.2994)
2022-11-03 01:25:18,289:INFO: Batch:  4/31	Total Loss 4.0833 (4.2549)
2022-11-03 01:25:18,763:INFO: Batch:  5/31	Total Loss 4.4542 (4.2889)
2022-11-03 01:25:19,231:INFO: Batch:  6/31	Total Loss 4.2327 (4.2812)
2022-11-03 01:25:19,703:INFO: Batch:  7/31	Total Loss 4.2431 (4.2766)
2022-11-03 01:25:20,170:INFO: Batch:  8/31	Total Loss 4.3631 (4.2852)
2022-11-03 01:25:20,639:INFO: Batch:  9/31	Total Loss 4.3718 (4.2940)
2022-11-03 01:25:21,106:INFO: Batch: 10/31	Total Loss 4.2654 (4.2914)
2022-11-03 01:25:21,574:INFO: Batch: 11/31	Total Loss 4.1185 (4.2771)
2022-11-03 01:25:22,046:INFO: Batch: 12/31	Total Loss 4.3853 (4.2857)
2022-11-03 01:25:22,517:INFO: Batch: 13/31	Total Loss 3.6980 (4.2446)
2022-11-03 01:25:22,991:INFO: Batch: 14/31	Total Loss 4.1801 (4.2405)
2022-11-03 01:25:23,461:INFO: Batch: 15/31	Total Loss 4.6191 (4.2611)
2022-11-03 01:25:23,931:INFO: Batch: 16/31	Total Loss 4.4431 (4.2715)
2022-11-03 01:25:24,402:INFO: Batch: 17/31	Total Loss 4.1180 (4.2634)
2022-11-03 01:25:24,873:INFO: Batch: 18/31	Total Loss 4.0034 (4.2499)
2022-11-03 01:25:25,348:INFO: Batch: 19/31	Total Loss 4.1234 (4.2441)
2022-11-03 01:25:25,823:INFO: Batch: 20/31	Total Loss 3.7062 (4.2155)
2022-11-03 01:25:26,299:INFO: Batch: 21/31	Total Loss 3.7931 (4.1955)
2022-11-03 01:25:26,775:INFO: Batch: 22/31	Total Loss 4.3038 (4.2006)
2022-11-03 01:25:27,251:INFO: Batch: 23/31	Total Loss 3.5135 (4.1731)
2022-11-03 01:25:27,727:INFO: Batch: 24/31	Total Loss 3.9469 (4.1642)
2022-11-03 01:25:28,202:INFO: Batch: 25/31	Total Loss 4.0795 (4.1609)
2022-11-03 01:25:28,679:INFO: Batch: 26/31	Total Loss 3.7590 (4.1460)
2022-11-03 01:25:29,153:INFO: Batch: 27/31	Total Loss 4.1943 (4.1476)
2022-11-03 01:25:29,628:INFO: Batch: 28/31	Total Loss 3.5243 (4.1281)
2022-11-03 01:25:30,103:INFO: Batch: 29/31	Total Loss 4.0441 (4.1256)
2022-11-03 01:25:30,489:INFO: Batch: 30/31	Total Loss 1.4447 (4.1000)
2022-11-03 01:25:30,641:INFO: - Computing ADE (validation o)
2022-11-03 01:25:31,220:INFO: 		 ADE on eth                       dataset:	 0.926578938961029
2022-11-03 01:25:31,220:INFO: Average validation o:	ADE  0.9266	FDE  1.8318
2022-11-03 01:25:31,230:INFO: - Computing ADE (validation)
2022-11-03 01:25:31,504:INFO: 		 ADE on hotel                     dataset:	 0.4119321405887604
2022-11-03 01:25:31,814:INFO: 		 ADE on univ                      dataset:	 0.5476613640785217
2022-11-03 01:25:32,062:INFO: 		 ADE on zara1                     dataset:	 0.4182971119880676
2022-11-03 01:25:32,403:INFO: 		 ADE on zara2                     dataset:	 0.3925320506095886
2022-11-03 01:25:32,403:INFO: Average validation:	ADE  0.4758	FDE  0.9983
2022-11-03 01:25:32,404:INFO: - Computing ADE (training)
2022-11-03 01:25:32,863:INFO: 		 ADE on hotel                     dataset:	 0.4399857819080353
2022-11-03 01:25:33,589:INFO: 		 ADE on univ                      dataset:	 0.5365781188011169
2022-11-03 01:25:34,126:INFO: 		 ADE on zara1                     dataset:	 0.45193737745285034
2022-11-03 01:25:34,866:INFO: 		 ADE on zara2                     dataset:	 0.3908328711986542
2022-11-03 01:25:34,867:INFO: Average training:	ADE  0.4992	FDE  1.0498
2022-11-03 01:25:34,875:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_535.pth.tar
2022-11-03 01:25:34,875:INFO: 
===> EPOCH: 536 (P3)
2022-11-03 01:25:34,876:INFO: - Computing loss (training)
2022-11-03 01:25:35,945:INFO: Batch:  0/31	Total Loss 5.1156 (5.1156)
2022-11-03 01:25:36,496:INFO: Batch:  1/31	Total Loss 4.2774 (4.6848)
2022-11-03 01:25:36,965:INFO: Batch:  2/31	Total Loss 3.8448 (4.4038)
2022-11-03 01:25:37,433:INFO: Batch:  3/31	Total Loss 4.2553 (4.3626)
2022-11-03 01:25:37,899:INFO: Batch:  4/31	Total Loss 4.5596 (4.4030)
2022-11-03 01:25:38,370:INFO: Batch:  5/31	Total Loss 4.5151 (4.4214)
2022-11-03 01:25:38,836:INFO: Batch:  6/31	Total Loss 3.8313 (4.3345)
2022-11-03 01:25:39,302:INFO: Batch:  7/31	Total Loss 3.7841 (4.2688)
2022-11-03 01:25:39,769:INFO: Batch:  8/31	Total Loss 3.9616 (4.2344)
2022-11-03 01:25:40,237:INFO: Batch:  9/31	Total Loss 3.8356 (4.1988)
2022-11-03 01:25:40,706:INFO: Batch: 10/31	Total Loss 4.1179 (4.1916)
2022-11-03 01:25:41,173:INFO: Batch: 11/31	Total Loss 4.7317 (4.2389)
2022-11-03 01:25:41,643:INFO: Batch: 12/31	Total Loss 4.2656 (4.2409)
2022-11-03 01:25:42,113:INFO: Batch: 13/31	Total Loss 3.8066 (4.2063)
2022-11-03 01:25:42,583:INFO: Batch: 14/31	Total Loss 3.8851 (4.1852)
2022-11-03 01:25:43,056:INFO: Batch: 15/31	Total Loss 4.2479 (4.1895)
2022-11-03 01:25:43,526:INFO: Batch: 16/31	Total Loss 4.3623 (4.1991)
2022-11-03 01:25:43,996:INFO: Batch: 17/31	Total Loss 3.8530 (4.1782)
2022-11-03 01:25:44,466:INFO: Batch: 18/31	Total Loss 3.4915 (4.1414)
2022-11-03 01:25:44,937:INFO: Batch: 19/31	Total Loss 3.9249 (4.1305)
2022-11-03 01:25:45,407:INFO: Batch: 20/31	Total Loss 4.0558 (4.1268)
2022-11-03 01:25:45,876:INFO: Batch: 21/31	Total Loss 3.6422 (4.1033)
2022-11-03 01:25:46,346:INFO: Batch: 22/31	Total Loss 4.2680 (4.1105)
2022-11-03 01:25:46,816:INFO: Batch: 23/31	Total Loss 4.1417 (4.1120)
2022-11-03 01:25:47,289:INFO: Batch: 24/31	Total Loss 4.3886 (4.1220)
2022-11-03 01:25:47,760:INFO: Batch: 25/31	Total Loss 4.4261 (4.1343)
2022-11-03 01:25:48,231:INFO: Batch: 26/31	Total Loss 4.0461 (4.1309)
2022-11-03 01:25:48,700:INFO: Batch: 27/31	Total Loss 4.3560 (4.1387)
2022-11-03 01:25:49,169:INFO: Batch: 28/31	Total Loss 4.5488 (4.1517)
2022-11-03 01:25:49,639:INFO: Batch: 29/31	Total Loss 4.0755 (4.1493)
2022-11-03 01:25:50,025:INFO: Batch: 30/31	Total Loss 1.4772 (4.1246)
2022-11-03 01:25:50,175:INFO: - Computing ADE (validation o)
2022-11-03 01:25:50,746:INFO: 		 ADE on eth                       dataset:	 0.9392278790473938
2022-11-03 01:25:50,746:INFO: Average validation o:	ADE  0.9392	FDE  1.8650
2022-11-03 01:25:50,747:INFO: - Computing ADE (validation)
2022-11-03 01:25:51,032:INFO: 		 ADE on hotel                     dataset:	 0.3887065052986145
2022-11-03 01:25:51,332:INFO: 		 ADE on univ                      dataset:	 0.5404201745986938
2022-11-03 01:25:51,597:INFO: 		 ADE on zara1                     dataset:	 0.43209534883499146
2022-11-03 01:25:51,951:INFO: 		 ADE on zara2                     dataset:	 0.4038584232330322
2022-11-03 01:25:51,951:INFO: Average validation:	ADE  0.4757	FDE  0.9968
2022-11-03 01:25:51,951:INFO: - Computing ADE (training)
2022-11-03 01:25:52,414:INFO: 		 ADE on hotel                     dataset:	 0.4089844822883606
2022-11-03 01:25:53,107:INFO: 		 ADE on univ                      dataset:	 0.5338223576545715
2022-11-03 01:25:53,632:INFO: 		 ADE on zara1                     dataset:	 0.48503416776657104
2022-11-03 01:25:54,380:INFO: 		 ADE on zara2                     dataset:	 0.41047075390815735
2022-11-03 01:25:54,381:INFO: Average training:	ADE  0.5025	FDE  1.0594
2022-11-03 01:25:54,389:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_536.pth.tar
2022-11-03 01:25:54,389:INFO: 
===> EPOCH: 537 (P3)
2022-11-03 01:25:54,390:INFO: - Computing loss (training)
2022-11-03 01:25:55,464:INFO: Batch:  0/31	Total Loss 4.0371 (4.0371)
2022-11-03 01:25:55,932:INFO: Batch:  1/31	Total Loss 4.1271 (4.0832)
2022-11-03 01:25:56,405:INFO: Batch:  2/31	Total Loss 3.7668 (3.9671)
2022-11-03 01:25:56,876:INFO: Batch:  3/31	Total Loss 3.8525 (3.9368)
2022-11-03 01:25:57,346:INFO: Batch:  4/31	Total Loss 4.6765 (4.0689)
2022-11-03 01:25:57,823:INFO: Batch:  5/31	Total Loss 3.8170 (4.0287)
2022-11-03 01:25:58,295:INFO: Batch:  6/31	Total Loss 3.9871 (4.0231)
2022-11-03 01:25:58,763:INFO: Batch:  7/31	Total Loss 3.9287 (4.0094)
2022-11-03 01:25:59,231:INFO: Batch:  8/31	Total Loss 4.0311 (4.0117)
2022-11-03 01:25:59,700:INFO: Batch:  9/31	Total Loss 4.4576 (4.0538)
2022-11-03 01:26:00,171:INFO: Batch: 10/31	Total Loss 3.8707 (4.0394)
2022-11-03 01:26:00,642:INFO: Batch: 11/31	Total Loss 3.7941 (4.0177)
2022-11-03 01:26:01,114:INFO: Batch: 12/31	Total Loss 5.1380 (4.1034)
2022-11-03 01:26:01,587:INFO: Batch: 13/31	Total Loss 3.6653 (4.0707)
2022-11-03 01:26:02,060:INFO: Batch: 14/31	Total Loss 5.1503 (4.1293)
2022-11-03 01:26:02,531:INFO: Batch: 15/31	Total Loss 4.1511 (4.1308)
2022-11-03 01:26:03,002:INFO: Batch: 16/31	Total Loss 4.1460 (4.1317)
2022-11-03 01:26:03,477:INFO: Batch: 17/31	Total Loss 4.4423 (4.1510)
2022-11-03 01:26:03,948:INFO: Batch: 18/31	Total Loss 4.1538 (4.1511)
2022-11-03 01:26:04,420:INFO: Batch: 19/31	Total Loss 4.0437 (4.1449)
2022-11-03 01:26:04,891:INFO: Batch: 20/31	Total Loss 4.2047 (4.1476)
2022-11-03 01:26:05,363:INFO: Batch: 21/31	Total Loss 4.0571 (4.1432)
2022-11-03 01:26:05,834:INFO: Batch: 22/31	Total Loss 4.4521 (4.1577)
2022-11-03 01:26:06,305:INFO: Batch: 23/31	Total Loss 3.7100 (4.1384)
2022-11-03 01:26:06,777:INFO: Batch: 24/31	Total Loss 4.7484 (4.1624)
2022-11-03 01:26:07,248:INFO: Batch: 25/31	Total Loss 3.7440 (4.1458)
2022-11-03 01:26:07,721:INFO: Batch: 26/31	Total Loss 4.2735 (4.1508)
2022-11-03 01:26:08,193:INFO: Batch: 27/31	Total Loss 3.4735 (4.1255)
2022-11-03 01:26:08,663:INFO: Batch: 28/31	Total Loss 4.4224 (4.1350)
2022-11-03 01:26:09,134:INFO: Batch: 29/31	Total Loss 4.2340 (4.1384)
2022-11-03 01:26:09,520:INFO: Batch: 30/31	Total Loss 1.6914 (4.1175)
2022-11-03 01:26:09,670:INFO: - Computing ADE (validation o)
2022-11-03 01:26:10,238:INFO: 		 ADE on eth                       dataset:	 0.93852698802948
2022-11-03 01:26:10,238:INFO: Average validation o:	ADE  0.9385	FDE  1.8347
2022-11-03 01:26:10,239:INFO: - Computing ADE (validation)
2022-11-03 01:26:10,515:INFO: 		 ADE on hotel                     dataset:	 0.3939206600189209
2022-11-03 01:26:10,810:INFO: 		 ADE on univ                      dataset:	 0.5422266721725464
2022-11-03 01:26:11,064:INFO: 		 ADE on zara1                     dataset:	 0.4320948123931885
2022-11-03 01:26:11,412:INFO: 		 ADE on zara2                     dataset:	 0.38934841752052307
2022-11-03 01:26:11,412:INFO: Average validation:	ADE  0.4716	FDE  0.9853
2022-11-03 01:26:11,413:INFO: - Computing ADE (training)
2022-11-03 01:26:11,854:INFO: 		 ADE on hotel                     dataset:	 0.42087385058403015
2022-11-03 01:26:12,524:INFO: 		 ADE on univ                      dataset:	 0.5276119709014893
2022-11-03 01:26:13,084:INFO: 		 ADE on zara1                     dataset:	 0.4908108115196228
2022-11-03 01:26:13,818:INFO: 		 ADE on zara2                     dataset:	 0.40185537934303284
2022-11-03 01:26:13,818:INFO: Average training:	ADE  0.4970	FDE  1.0418
2022-11-03 01:26:13,827:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_537.pth.tar
2022-11-03 01:26:13,827:INFO: 
===> EPOCH: 538 (P3)
2022-11-03 01:26:13,827:INFO: - Computing loss (training)
2022-11-03 01:26:14,917:INFO: Batch:  0/31	Total Loss 4.2153 (4.2153)
2022-11-03 01:26:15,402:INFO: Batch:  1/31	Total Loss 4.5431 (4.3749)
2022-11-03 01:26:15,877:INFO: Batch:  2/31	Total Loss 4.3053 (4.3533)
2022-11-03 01:26:16,350:INFO: Batch:  3/31	Total Loss 4.5040 (4.3937)
2022-11-03 01:26:16,818:INFO: Batch:  4/31	Total Loss 4.1300 (4.3376)
2022-11-03 01:26:17,290:INFO: Batch:  5/31	Total Loss 3.9085 (4.2640)
2022-11-03 01:26:17,759:INFO: Batch:  6/31	Total Loss 4.2247 (4.2587)
2022-11-03 01:26:18,227:INFO: Batch:  7/31	Total Loss 3.8864 (4.2092)
2022-11-03 01:26:18,694:INFO: Batch:  8/31	Total Loss 3.5948 (4.1455)
2022-11-03 01:26:19,165:INFO: Batch:  9/31	Total Loss 4.6887 (4.1991)
2022-11-03 01:26:19,638:INFO: Batch: 10/31	Total Loss 3.4471 (4.1291)
2022-11-03 01:26:20,105:INFO: Batch: 11/31	Total Loss 3.7462 (4.0977)
2022-11-03 01:26:20,581:INFO: Batch: 12/31	Total Loss 3.7686 (4.0720)
2022-11-03 01:26:21,059:INFO: Batch: 13/31	Total Loss 4.1558 (4.0781)
2022-11-03 01:26:21,531:INFO: Batch: 14/31	Total Loss 4.4341 (4.1012)
2022-11-03 01:26:22,005:INFO: Batch: 15/31	Total Loss 4.0437 (4.0981)
2022-11-03 01:26:22,478:INFO: Batch: 16/31	Total Loss 4.4675 (4.1170)
2022-11-03 01:26:22,954:INFO: Batch: 17/31	Total Loss 4.0259 (4.1118)
2022-11-03 01:26:23,427:INFO: Batch: 18/31	Total Loss 3.9952 (4.1051)
2022-11-03 01:26:23,898:INFO: Batch: 19/31	Total Loss 4.0607 (4.1030)
2022-11-03 01:26:24,372:INFO: Batch: 20/31	Total Loss 3.7980 (4.0890)
2022-11-03 01:26:24,843:INFO: Batch: 21/31	Total Loss 3.9132 (4.0815)
2022-11-03 01:26:25,314:INFO: Batch: 22/31	Total Loss 4.4729 (4.0969)
2022-11-03 01:26:25,784:INFO: Batch: 23/31	Total Loss 5.9084 (4.1673)
2022-11-03 01:26:26,255:INFO: Batch: 24/31	Total Loss 3.8325 (4.1529)
2022-11-03 01:26:26,725:INFO: Batch: 25/31	Total Loss 4.1936 (4.1542)
2022-11-03 01:26:27,195:INFO: Batch: 26/31	Total Loss 3.7484 (4.1391)
2022-11-03 01:26:27,664:INFO: Batch: 27/31	Total Loss 3.9593 (4.1331)
2022-11-03 01:26:28,209:INFO: Batch: 28/31	Total Loss 4.5340 (4.1483)
2022-11-03 01:26:28,679:INFO: Batch: 29/31	Total Loss 4.3187 (4.1539)
2022-11-03 01:26:29,064:INFO: Batch: 30/31	Total Loss 1.5429 (4.1229)
2022-11-03 01:26:29,214:INFO: - Computing ADE (validation o)
2022-11-03 01:26:29,801:INFO: 		 ADE on eth                       dataset:	 0.9430091977119446
2022-11-03 01:26:29,802:INFO: Average validation o:	ADE  0.9430	FDE  1.9017
2022-11-03 01:26:29,802:INFO: - Computing ADE (validation)
2022-11-03 01:26:30,098:INFO: 		 ADE on hotel                     dataset:	 0.43160808086395264
2022-11-03 01:26:30,388:INFO: 		 ADE on univ                      dataset:	 0.5736749172210693
2022-11-03 01:26:30,663:INFO: 		 ADE on zara1                     dataset:	 0.4531523585319519
2022-11-03 01:26:31,023:INFO: 		 ADE on zara2                     dataset:	 0.4300772547721863
2022-11-03 01:26:31,023:INFO: Average validation:	ADE  0.5062	FDE  1.0857
2022-11-03 01:26:31,024:INFO: - Computing ADE (training)
2022-11-03 01:26:31,505:INFO: 		 ADE on hotel                     dataset:	 0.4592377543449402
2022-11-03 01:26:32,180:INFO: 		 ADE on univ                      dataset:	 0.557813286781311
2022-11-03 01:26:32,710:INFO: 		 ADE on zara1                     dataset:	 0.48652148246765137
2022-11-03 01:26:33,468:INFO: 		 ADE on zara2                     dataset:	 0.43165504932403564
2022-11-03 01:26:33,468:INFO: Average training:	ADE  0.5252	FDE  1.1267
2022-11-03 01:26:33,477:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_538.pth.tar
2022-11-03 01:26:33,477:INFO: 
===> EPOCH: 539 (P3)
2022-11-03 01:26:33,478:INFO: - Computing loss (training)
2022-11-03 01:26:34,562:INFO: Batch:  0/31	Total Loss 4.4562 (4.4562)
2022-11-03 01:26:35,045:INFO: Batch:  1/31	Total Loss 3.5562 (3.9835)
2022-11-03 01:26:35,518:INFO: Batch:  2/31	Total Loss 4.3494 (4.0976)
2022-11-03 01:26:35,992:INFO: Batch:  3/31	Total Loss 4.3683 (4.1734)
2022-11-03 01:26:36,463:INFO: Batch:  4/31	Total Loss 4.1398 (4.1661)
2022-11-03 01:26:36,940:INFO: Batch:  5/31	Total Loss 4.3269 (4.1921)
2022-11-03 01:26:37,413:INFO: Batch:  6/31	Total Loss 4.0761 (4.1747)
2022-11-03 01:26:37,885:INFO: Batch:  7/31	Total Loss 4.3729 (4.1996)
2022-11-03 01:26:38,357:INFO: Batch:  8/31	Total Loss 5.0161 (4.2835)
2022-11-03 01:26:38,831:INFO: Batch:  9/31	Total Loss 4.2682 (4.2820)
2022-11-03 01:26:39,304:INFO: Batch: 10/31	Total Loss 4.3105 (4.2843)
2022-11-03 01:26:39,778:INFO: Batch: 11/31	Total Loss 4.2377 (4.2800)
2022-11-03 01:26:40,254:INFO: Batch: 12/31	Total Loss 4.0627 (4.2653)
2022-11-03 01:26:40,731:INFO: Batch: 13/31	Total Loss 4.0457 (4.2510)
2022-11-03 01:26:41,207:INFO: Batch: 14/31	Total Loss 3.8022 (4.2188)
2022-11-03 01:26:41,684:INFO: Batch: 15/31	Total Loss 3.8479 (4.1959)
2022-11-03 01:26:42,161:INFO: Batch: 16/31	Total Loss 4.1741 (4.1945)
2022-11-03 01:26:42,638:INFO: Batch: 17/31	Total Loss 3.9831 (4.1810)
2022-11-03 01:26:43,113:INFO: Batch: 18/31	Total Loss 4.1837 (4.1811)
2022-11-03 01:26:43,588:INFO: Batch: 19/31	Total Loss 3.6276 (4.1516)
2022-11-03 01:26:44,064:INFO: Batch: 20/31	Total Loss 4.2706 (4.1578)
2022-11-03 01:26:44,537:INFO: Batch: 21/31	Total Loss 3.8954 (4.1469)
2022-11-03 01:26:45,012:INFO: Batch: 22/31	Total Loss 4.1923 (4.1484)
2022-11-03 01:26:45,487:INFO: Batch: 23/31	Total Loss 4.5255 (4.1636)
2022-11-03 01:26:45,962:INFO: Batch: 24/31	Total Loss 4.2311 (4.1666)
2022-11-03 01:26:46,438:INFO: Batch: 25/31	Total Loss 4.0910 (4.1636)
2022-11-03 01:26:46,914:INFO: Batch: 26/31	Total Loss 3.5741 (4.1413)
2022-11-03 01:26:47,390:INFO: Batch: 27/31	Total Loss 3.9702 (4.1347)
2022-11-03 01:26:47,866:INFO: Batch: 28/31	Total Loss 4.5702 (4.1492)
2022-11-03 01:26:48,342:INFO: Batch: 29/31	Total Loss 3.7383 (4.1352)
2022-11-03 01:26:48,734:INFO: Batch: 30/31	Total Loss 1.7172 (4.1137)
2022-11-03 01:26:48,877:INFO: - Computing ADE (validation o)
2022-11-03 01:26:49,468:INFO: 		 ADE on eth                       dataset:	 0.9396088123321533
2022-11-03 01:26:49,469:INFO: Average validation o:	ADE  0.9396	FDE  1.8835
2022-11-03 01:26:49,469:INFO: - Computing ADE (validation)
2022-11-03 01:26:49,750:INFO: 		 ADE on hotel                     dataset:	 0.4167887270450592
2022-11-03 01:26:50,053:INFO: 		 ADE on univ                      dataset:	 0.5543832778930664
2022-11-03 01:26:50,318:INFO: 		 ADE on zara1                     dataset:	 0.4364977777004242
2022-11-03 01:26:50,653:INFO: 		 ADE on zara2                     dataset:	 0.42100387811660767
2022-11-03 01:26:50,653:INFO: Average validation:	ADE  0.4911	FDE  1.0396
2022-11-03 01:26:50,654:INFO: - Computing ADE (training)
2022-11-03 01:26:51,116:INFO: 		 ADE on hotel                     dataset:	 0.4399510324001312
2022-11-03 01:26:51,791:INFO: 		 ADE on univ                      dataset:	 0.5488020181655884
2022-11-03 01:26:52,344:INFO: 		 ADE on zara1                     dataset:	 0.4834755063056946
2022-11-03 01:26:53,158:INFO: 		 ADE on zara2                     dataset:	 0.424160361289978
2022-11-03 01:26:53,158:INFO: Average training:	ADE  0.5166	FDE  1.0992
2022-11-03 01:26:53,167:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_539.pth.tar
2022-11-03 01:26:53,167:INFO: 
===> EPOCH: 540 (P3)
2022-11-03 01:26:53,167:INFO: - Computing loss (training)
2022-11-03 01:26:54,267:INFO: Batch:  0/31	Total Loss 3.8000 (3.8000)
2022-11-03 01:26:54,750:INFO: Batch:  1/31	Total Loss 4.6799 (4.2433)
2022-11-03 01:26:55,226:INFO: Batch:  2/31	Total Loss 4.0080 (4.1662)
2022-11-03 01:26:55,721:INFO: Batch:  3/31	Total Loss 3.8569 (4.0922)
2022-11-03 01:26:56,196:INFO: Batch:  4/31	Total Loss 4.0745 (4.0885)
2022-11-03 01:26:56,671:INFO: Batch:  5/31	Total Loss 3.9033 (4.0577)
2022-11-03 01:26:57,155:INFO: Batch:  6/31	Total Loss 3.7173 (4.0047)
2022-11-03 01:26:57,632:INFO: Batch:  7/31	Total Loss 3.9929 (4.0031)
2022-11-03 01:26:58,116:INFO: Batch:  8/31	Total Loss 3.8663 (3.9889)
2022-11-03 01:26:58,593:INFO: Batch:  9/31	Total Loss 3.8887 (3.9803)
2022-11-03 01:26:59,070:INFO: Batch: 10/31	Total Loss 4.8566 (4.0665)
2022-11-03 01:26:59,542:INFO: Batch: 11/31	Total Loss 4.2676 (4.0834)
2022-11-03 01:27:00,023:INFO: Batch: 12/31	Total Loss 4.3745 (4.1058)
2022-11-03 01:27:00,505:INFO: Batch: 13/31	Total Loss 3.6983 (4.0764)
2022-11-03 01:27:00,984:INFO: Batch: 14/31	Total Loss 3.9949 (4.0703)
2022-11-03 01:27:01,465:INFO: Batch: 15/31	Total Loss 3.6559 (4.0472)
2022-11-03 01:27:01,945:INFO: Batch: 16/31	Total Loss 4.1837 (4.0560)
2022-11-03 01:27:02,425:INFO: Batch: 17/31	Total Loss 4.2008 (4.0635)
2022-11-03 01:27:02,905:INFO: Batch: 18/31	Total Loss 4.1477 (4.0682)
2022-11-03 01:27:03,383:INFO: Batch: 19/31	Total Loss 4.4185 (4.0848)
2022-11-03 01:27:03,861:INFO: Batch: 20/31	Total Loss 4.1658 (4.0890)
2022-11-03 01:27:04,338:INFO: Batch: 21/31	Total Loss 3.9888 (4.0842)
2022-11-03 01:27:04,816:INFO: Batch: 22/31	Total Loss 4.2243 (4.0901)
2022-11-03 01:27:05,294:INFO: Batch: 23/31	Total Loss 3.9609 (4.0847)
2022-11-03 01:27:05,772:INFO: Batch: 24/31	Total Loss 4.6552 (4.1040)
2022-11-03 01:27:06,250:INFO: Batch: 25/31	Total Loss 3.6618 (4.0873)
2022-11-03 01:27:06,731:INFO: Batch: 26/31	Total Loss 4.4675 (4.0997)
2022-11-03 01:27:07,209:INFO: Batch: 27/31	Total Loss 4.0417 (4.0975)
2022-11-03 01:27:07,691:INFO: Batch: 28/31	Total Loss 5.1856 (4.1335)
2022-11-03 01:27:08,169:INFO: Batch: 29/31	Total Loss 4.1529 (4.1342)
2022-11-03 01:27:08,563:INFO: Batch: 30/31	Total Loss 1.3544 (4.1014)
2022-11-03 01:27:08,724:INFO: - Computing ADE (validation o)
2022-11-03 01:27:09,306:INFO: 		 ADE on eth                       dataset:	 0.9262706637382507
2022-11-03 01:27:09,306:INFO: Average validation o:	ADE  0.9263	FDE  1.8321
2022-11-03 01:27:09,307:INFO: - Computing ADE (validation)
2022-11-03 01:27:09,578:INFO: 		 ADE on hotel                     dataset:	 0.3970467746257782
2022-11-03 01:27:09,874:INFO: 		 ADE on univ                      dataset:	 0.5394797325134277
2022-11-03 01:27:10,135:INFO: 		 ADE on zara1                     dataset:	 0.39807525277137756
2022-11-03 01:27:10,478:INFO: 		 ADE on zara2                     dataset:	 0.3869194984436035
2022-11-03 01:27:10,479:INFO: Average validation:	ADE  0.4675	FDE  0.9706
2022-11-03 01:27:10,479:INFO: - Computing ADE (training)
2022-11-03 01:27:10,943:INFO: 		 ADE on hotel                     dataset:	 0.4160686731338501
2022-11-03 01:27:11,632:INFO: 		 ADE on univ                      dataset:	 0.5315471291542053
2022-11-03 01:27:12,185:INFO: 		 ADE on zara1                     dataset:	 0.45446857810020447
2022-11-03 01:27:12,923:INFO: 		 ADE on zara2                     dataset:	 0.3865591585636139
2022-11-03 01:27:12,923:INFO: Average training:	ADE  0.4943	FDE  1.0330
2022-11-03 01:27:12,940:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_540.pth.tar
2022-11-03 01:27:12,940:INFO: 
===> EPOCH: 541 (P3)
2022-11-03 01:27:12,940:INFO: - Computing loss (training)
2022-11-03 01:27:14,046:INFO: Batch:  0/31	Total Loss 4.0326 (4.0326)
2022-11-03 01:27:14,523:INFO: Batch:  1/31	Total Loss 4.4124 (4.2144)
2022-11-03 01:27:15,002:INFO: Batch:  2/31	Total Loss 4.0281 (4.1534)
2022-11-03 01:27:15,480:INFO: Batch:  3/31	Total Loss 3.7587 (4.0572)
2022-11-03 01:27:15,955:INFO: Batch:  4/31	Total Loss 4.1929 (4.0800)
2022-11-03 01:27:16,439:INFO: Batch:  5/31	Total Loss 4.3264 (4.1195)
2022-11-03 01:27:16,916:INFO: Batch:  6/31	Total Loss 4.1091 (4.1180)
2022-11-03 01:27:17,393:INFO: Batch:  7/31	Total Loss 4.5333 (4.1638)
2022-11-03 01:27:17,869:INFO: Batch:  8/31	Total Loss 4.2490 (4.1734)
2022-11-03 01:27:18,345:INFO: Batch:  9/31	Total Loss 3.7148 (4.1224)
2022-11-03 01:27:18,822:INFO: Batch: 10/31	Total Loss 4.1042 (4.1208)
2022-11-03 01:27:19,300:INFO: Batch: 11/31	Total Loss 4.6342 (4.1636)
2022-11-03 01:27:19,781:INFO: Batch: 12/31	Total Loss 4.3727 (4.1774)
2022-11-03 01:27:20,260:INFO: Batch: 13/31	Total Loss 3.8745 (4.1561)
2022-11-03 01:27:20,731:INFO: Batch: 14/31	Total Loss 4.0492 (4.1479)
2022-11-03 01:27:21,200:INFO: Batch: 15/31	Total Loss 3.9812 (4.1365)
2022-11-03 01:27:21,679:INFO: Batch: 16/31	Total Loss 4.2844 (4.1463)
2022-11-03 01:27:22,235:INFO: Batch: 17/31	Total Loss 3.7099 (4.1211)
2022-11-03 01:27:22,714:INFO: Batch: 18/31	Total Loss 3.9909 (4.1143)
2022-11-03 01:27:23,189:INFO: Batch: 19/31	Total Loss 5.2616 (4.1703)
2022-11-03 01:27:23,664:INFO: Batch: 20/31	Total Loss 3.9752 (4.1601)
2022-11-03 01:27:24,140:INFO: Batch: 21/31	Total Loss 4.6224 (4.1790)
2022-11-03 01:27:24,616:INFO: Batch: 22/31	Total Loss 4.3417 (4.1861)
2022-11-03 01:27:25,091:INFO: Batch: 23/31	Total Loss 3.9777 (4.1778)
2022-11-03 01:27:25,565:INFO: Batch: 24/31	Total Loss 4.0531 (4.1729)
2022-11-03 01:27:26,040:INFO: Batch: 25/31	Total Loss 4.3851 (4.1809)
2022-11-03 01:27:26,518:INFO: Batch: 26/31	Total Loss 4.0631 (4.1763)
2022-11-03 01:27:26,994:INFO: Batch: 27/31	Total Loss 4.6996 (4.1961)
2022-11-03 01:27:27,472:INFO: Batch: 28/31	Total Loss 3.9102 (4.1863)
2022-11-03 01:27:27,947:INFO: Batch: 29/31	Total Loss 4.3107 (4.1907)
2022-11-03 01:27:28,338:INFO: Batch: 30/31	Total Loss 1.4796 (4.1637)
2022-11-03 01:27:28,497:INFO: - Computing ADE (validation o)
2022-11-03 01:27:29,072:INFO: 		 ADE on eth                       dataset:	 0.9381886124610901
2022-11-03 01:27:29,073:INFO: Average validation o:	ADE  0.9382	FDE  1.8452
2022-11-03 01:27:29,073:INFO: - Computing ADE (validation)
2022-11-03 01:27:29,362:INFO: 		 ADE on hotel                     dataset:	 0.4295181930065155
2022-11-03 01:27:29,650:INFO: 		 ADE on univ                      dataset:	 0.5517531037330627
2022-11-03 01:27:29,894:INFO: 		 ADE on zara1                     dataset:	 0.404768168926239
2022-11-03 01:27:30,243:INFO: 		 ADE on zara2                     dataset:	 0.4152469038963318
2022-11-03 01:27:30,243:INFO: Average validation:	ADE  0.4864	FDE  1.0247
2022-11-03 01:27:30,244:INFO: - Computing ADE (training)
2022-11-03 01:27:30,690:INFO: 		 ADE on hotel                     dataset:	 0.45161688327789307
2022-11-03 01:27:31,351:INFO: 		 ADE on univ                      dataset:	 0.5444968938827515
2022-11-03 01:27:31,871:INFO: 		 ADE on zara1                     dataset:	 0.4775225520133972
2022-11-03 01:27:32,620:INFO: 		 ADE on zara2                     dataset:	 0.4190179705619812
2022-11-03 01:27:32,620:INFO: Average training:	ADE  0.5124	FDE  1.0828
2022-11-03 01:27:32,629:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_541.pth.tar
2022-11-03 01:27:32,629:INFO: 
===> EPOCH: 542 (P3)
2022-11-03 01:27:32,629:INFO: - Computing loss (training)
2022-11-03 01:27:33,725:INFO: Batch:  0/31	Total Loss 4.4415 (4.4415)
2022-11-03 01:27:34,207:INFO: Batch:  1/31	Total Loss 4.3592 (4.4005)
2022-11-03 01:27:34,690:INFO: Batch:  2/31	Total Loss 4.3269 (4.3769)
2022-11-03 01:27:35,171:INFO: Batch:  3/31	Total Loss 3.8795 (4.2443)
2022-11-03 01:27:35,651:INFO: Batch:  4/31	Total Loss 3.9994 (4.1871)
2022-11-03 01:27:36,136:INFO: Batch:  5/31	Total Loss 4.4135 (4.2282)
2022-11-03 01:27:36,618:INFO: Batch:  6/31	Total Loss 4.2035 (4.2248)
2022-11-03 01:27:37,100:INFO: Batch:  7/31	Total Loss 4.1328 (4.2138)
2022-11-03 01:27:37,582:INFO: Batch:  8/31	Total Loss 4.6813 (4.2646)
2022-11-03 01:27:38,061:INFO: Batch:  9/31	Total Loss 3.8707 (4.2255)
2022-11-03 01:27:38,542:INFO: Batch: 10/31	Total Loss 3.9789 (4.2036)
2022-11-03 01:27:39,023:INFO: Batch: 11/31	Total Loss 4.2763 (4.2095)
2022-11-03 01:27:39,509:INFO: Batch: 12/31	Total Loss 4.1420 (4.2044)
2022-11-03 01:27:39,994:INFO: Batch: 13/31	Total Loss 3.9756 (4.1888)
2022-11-03 01:27:40,480:INFO: Batch: 14/31	Total Loss 3.8560 (4.1689)
2022-11-03 01:27:40,967:INFO: Batch: 15/31	Total Loss 3.8305 (4.1502)
2022-11-03 01:27:41,451:INFO: Batch: 16/31	Total Loss 4.2044 (4.1538)
2022-11-03 01:27:41,937:INFO: Batch: 17/31	Total Loss 4.4365 (4.1690)
2022-11-03 01:27:42,423:INFO: Batch: 18/31	Total Loss 4.5697 (4.1916)
2022-11-03 01:27:42,909:INFO: Batch: 19/31	Total Loss 3.9563 (4.1811)
2022-11-03 01:27:43,395:INFO: Batch: 20/31	Total Loss 4.2589 (4.1848)
2022-11-03 01:27:43,880:INFO: Batch: 21/31	Total Loss 3.9109 (4.1731)
2022-11-03 01:27:44,367:INFO: Batch: 22/31	Total Loss 4.6164 (4.1903)
2022-11-03 01:27:44,850:INFO: Batch: 23/31	Total Loss 4.3736 (4.1970)
2022-11-03 01:27:45,332:INFO: Batch: 24/31	Total Loss 4.1437 (4.1951)
2022-11-03 01:27:45,817:INFO: Batch: 25/31	Total Loss 4.1359 (4.1929)
2022-11-03 01:27:46,300:INFO: Batch: 26/31	Total Loss 4.9111 (4.2182)
2022-11-03 01:27:46,783:INFO: Batch: 27/31	Total Loss 4.1690 (4.2165)
2022-11-03 01:27:47,269:INFO: Batch: 28/31	Total Loss 4.1037 (4.2126)
2022-11-03 01:27:47,755:INFO: Batch: 29/31	Total Loss 4.0213 (4.2060)
2022-11-03 01:27:48,149:INFO: Batch: 30/31	Total Loss 1.5173 (4.1817)
2022-11-03 01:27:48,298:INFO: - Computing ADE (validation o)
2022-11-03 01:27:48,932:INFO: 		 ADE on eth                       dataset:	 0.9244080781936646
2022-11-03 01:27:48,932:INFO: Average validation o:	ADE  0.9244	FDE  1.8255
2022-11-03 01:27:48,933:INFO: - Computing ADE (validation)
2022-11-03 01:27:49,217:INFO: 		 ADE on hotel                     dataset:	 0.4468637704849243
2022-11-03 01:27:49,527:INFO: 		 ADE on univ                      dataset:	 0.572662889957428
2022-11-03 01:27:49,781:INFO: 		 ADE on zara1                     dataset:	 0.43649300932884216
2022-11-03 01:27:50,139:INFO: 		 ADE on zara2                     dataset:	 0.4334556460380554
2022-11-03 01:27:50,139:INFO: Average validation:	ADE  0.5068	FDE  1.0918
2022-11-03 01:27:50,140:INFO: - Computing ADE (training)
2022-11-03 01:27:50,623:INFO: 		 ADE on hotel                     dataset:	 0.46198493242263794
2022-11-03 01:27:51,300:INFO: 		 ADE on univ                      dataset:	 0.5591421723365784
2022-11-03 01:27:51,835:INFO: 		 ADE on zara1                     dataset:	 0.4865220785140991
2022-11-03 01:27:52,583:INFO: 		 ADE on zara2                     dataset:	 0.4289378523826599
2022-11-03 01:27:52,583:INFO: Average training:	ADE  0.5256	FDE  1.1305
2022-11-03 01:27:52,591:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_542.pth.tar
2022-11-03 01:27:52,592:INFO: 
===> EPOCH: 543 (P3)
2022-11-03 01:27:52,592:INFO: - Computing loss (training)
2022-11-03 01:27:53,692:INFO: Batch:  0/31	Total Loss 3.9906 (3.9906)
2022-11-03 01:27:54,159:INFO: Batch:  1/31	Total Loss 4.1684 (4.0735)
2022-11-03 01:27:54,627:INFO: Batch:  2/31	Total Loss 4.1047 (4.0829)
2022-11-03 01:27:55,097:INFO: Batch:  3/31	Total Loss 3.7991 (4.0104)
2022-11-03 01:27:55,562:INFO: Batch:  4/31	Total Loss 4.1471 (4.0372)
2022-11-03 01:27:56,029:INFO: Batch:  5/31	Total Loss 4.0773 (4.0439)
2022-11-03 01:27:56,495:INFO: Batch:  6/31	Total Loss 4.1953 (4.0651)
2022-11-03 01:27:56,960:INFO: Batch:  7/31	Total Loss 3.9263 (4.0487)
2022-11-03 01:27:57,423:INFO: Batch:  8/31	Total Loss 4.4836 (4.0938)
2022-11-03 01:27:57,887:INFO: Batch:  9/31	Total Loss 4.7120 (4.1517)
2022-11-03 01:27:58,352:INFO: Batch: 10/31	Total Loss 3.9486 (4.1340)
2022-11-03 01:27:58,815:INFO: Batch: 11/31	Total Loss 4.1015 (4.1313)
2022-11-03 01:27:59,283:INFO: Batch: 12/31	Total Loss 4.3363 (4.1464)
2022-11-03 01:27:59,753:INFO: Batch: 13/31	Total Loss 3.9004 (4.1295)
2022-11-03 01:28:00,221:INFO: Batch: 14/31	Total Loss 5.7352 (4.2377)
2022-11-03 01:28:00,691:INFO: Batch: 15/31	Total Loss 3.9464 (4.2219)
2022-11-03 01:28:01,162:INFO: Batch: 16/31	Total Loss 4.9687 (4.2660)
2022-11-03 01:28:01,632:INFO: Batch: 17/31	Total Loss 4.6520 (4.2861)
2022-11-03 01:28:02,101:INFO: Batch: 18/31	Total Loss 4.6699 (4.3070)
2022-11-03 01:28:02,569:INFO: Batch: 19/31	Total Loss 3.7336 (4.2776)
2022-11-03 01:28:03,036:INFO: Batch: 20/31	Total Loss 4.0013 (4.2650)
2022-11-03 01:28:03,506:INFO: Batch: 21/31	Total Loss 3.8897 (4.2482)
2022-11-03 01:28:03,973:INFO: Batch: 22/31	Total Loss 4.4409 (4.2565)
2022-11-03 01:28:04,442:INFO: Batch: 23/31	Total Loss 4.4644 (4.2645)
2022-11-03 01:28:04,912:INFO: Batch: 24/31	Total Loss 3.9073 (4.2509)
2022-11-03 01:28:05,381:INFO: Batch: 25/31	Total Loss 4.0008 (4.2412)
2022-11-03 01:28:05,850:INFO: Batch: 26/31	Total Loss 3.8447 (4.2253)
2022-11-03 01:28:06,318:INFO: Batch: 27/31	Total Loss 4.8271 (4.2466)
2022-11-03 01:28:06,787:INFO: Batch: 28/31	Total Loss 3.8723 (4.2333)
2022-11-03 01:28:07,255:INFO: Batch: 29/31	Total Loss 4.2654 (4.2344)
2022-11-03 01:28:07,643:INFO: Batch: 30/31	Total Loss 1.1932 (4.2040)
2022-11-03 01:28:07,805:INFO: - Computing ADE (validation o)
2022-11-03 01:28:08,396:INFO: 		 ADE on eth                       dataset:	 0.9446921348571777
2022-11-03 01:28:08,397:INFO: Average validation o:	ADE  0.9447	FDE  1.9013
2022-11-03 01:28:08,397:INFO: - Computing ADE (validation)
2022-11-03 01:28:08,665:INFO: 		 ADE on hotel                     dataset:	 0.44998255372047424
2022-11-03 01:28:08,947:INFO: 		 ADE on univ                      dataset:	 0.575015127658844
2022-11-03 01:28:09,200:INFO: 		 ADE on zara1                     dataset:	 0.45397448539733887
2022-11-03 01:28:09,553:INFO: 		 ADE on zara2                     dataset:	 0.4370989203453064
2022-11-03 01:28:09,553:INFO: Average validation:	ADE  0.5105	FDE  1.0960
2022-11-03 01:28:09,554:INFO: - Computing ADE (training)
2022-11-03 01:28:10,012:INFO: 		 ADE on hotel                     dataset:	 0.4819033443927765
2022-11-03 01:28:10,712:INFO: 		 ADE on univ                      dataset:	 0.5643908977508545
2022-11-03 01:28:11,287:INFO: 		 ADE on zara1                     dataset:	 0.4800553321838379
2022-11-03 01:28:12,003:INFO: 		 ADE on zara2                     dataset:	 0.43523508310317993
2022-11-03 01:28:12,004:INFO: Average training:	ADE  0.5307	FDE  1.1404
2022-11-03 01:28:12,012:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_543.pth.tar
2022-11-03 01:28:12,012:INFO: 
===> EPOCH: 544 (P3)
2022-11-03 01:28:12,013:INFO: - Computing loss (training)
2022-11-03 01:28:13,131:INFO: Batch:  0/31	Total Loss 4.0476 (4.0476)
2022-11-03 01:28:13,614:INFO: Batch:  1/31	Total Loss 4.3484 (4.1953)
2022-11-03 01:28:14,099:INFO: Batch:  2/31	Total Loss 4.2461 (4.2116)
2022-11-03 01:28:14,658:INFO: Batch:  3/31	Total Loss 4.5391 (4.2933)
2022-11-03 01:28:15,142:INFO: Batch:  4/31	Total Loss 3.9746 (4.2260)
2022-11-03 01:28:15,624:INFO: Batch:  5/31	Total Loss 3.9329 (4.1779)
2022-11-03 01:28:16,109:INFO: Batch:  6/31	Total Loss 4.2514 (4.1880)
2022-11-03 01:28:16,590:INFO: Batch:  7/31	Total Loss 3.7061 (4.1272)
2022-11-03 01:28:17,071:INFO: Batch:  8/31	Total Loss 3.9177 (4.1024)
2022-11-03 01:28:17,549:INFO: Batch:  9/31	Total Loss 3.9348 (4.0853)
2022-11-03 01:28:18,033:INFO: Batch: 10/31	Total Loss 4.4485 (4.1177)
2022-11-03 01:28:18,516:INFO: Batch: 11/31	Total Loss 4.3336 (4.1355)
2022-11-03 01:28:19,001:INFO: Batch: 12/31	Total Loss 3.6523 (4.0998)
2022-11-03 01:28:19,489:INFO: Batch: 13/31	Total Loss 3.9801 (4.0919)
2022-11-03 01:28:19,977:INFO: Batch: 14/31	Total Loss 4.5708 (4.1270)
2022-11-03 01:28:20,466:INFO: Batch: 15/31	Total Loss 3.5209 (4.0856)
2022-11-03 01:28:20,952:INFO: Batch: 16/31	Total Loss 4.2624 (4.0959)
2022-11-03 01:28:21,438:INFO: Batch: 17/31	Total Loss 4.5151 (4.1189)
2022-11-03 01:28:21,923:INFO: Batch: 18/31	Total Loss 3.9378 (4.1089)
2022-11-03 01:28:22,410:INFO: Batch: 19/31	Total Loss 3.9996 (4.1034)
2022-11-03 01:28:22,895:INFO: Batch: 20/31	Total Loss 4.0175 (4.0997)
2022-11-03 01:28:23,381:INFO: Batch: 21/31	Total Loss 4.0319 (4.0963)
2022-11-03 01:28:23,865:INFO: Batch: 22/31	Total Loss 3.9131 (4.0879)
2022-11-03 01:28:24,349:INFO: Batch: 23/31	Total Loss 4.1649 (4.0914)
2022-11-03 01:28:24,834:INFO: Batch: 24/31	Total Loss 4.9204 (4.1232)
2022-11-03 01:28:25,317:INFO: Batch: 25/31	Total Loss 4.3150 (4.1303)
2022-11-03 01:28:25,796:INFO: Batch: 26/31	Total Loss 3.8123 (4.1181)
2022-11-03 01:28:26,276:INFO: Batch: 27/31	Total Loss 3.8391 (4.1091)
2022-11-03 01:28:26,755:INFO: Batch: 28/31	Total Loss 3.4942 (4.0914)
2022-11-03 01:28:27,234:INFO: Batch: 29/31	Total Loss 4.0779 (4.0909)
2022-11-03 01:28:27,628:INFO: Batch: 30/31	Total Loss 1.5101 (4.0609)
2022-11-03 01:28:27,773:INFO: - Computing ADE (validation o)
2022-11-03 01:28:28,368:INFO: 		 ADE on eth                       dataset:	 0.9276012778282166
2022-11-03 01:28:28,368:INFO: Average validation o:	ADE  0.9276	FDE  1.8463
2022-11-03 01:28:28,369:INFO: - Computing ADE (validation)
2022-11-03 01:28:28,638:INFO: 		 ADE on hotel                     dataset:	 0.39605361223220825
2022-11-03 01:28:28,933:INFO: 		 ADE on univ                      dataset:	 0.5378087162971497
2022-11-03 01:28:29,186:INFO: 		 ADE on zara1                     dataset:	 0.39194726943969727
2022-11-03 01:28:29,528:INFO: 		 ADE on zara2                     dataset:	 0.3871717154979706
2022-11-03 01:28:29,528:INFO: Average validation:	ADE  0.4663	FDE  0.9715
2022-11-03 01:28:29,529:INFO: - Computing ADE (training)
2022-11-03 01:28:30,023:INFO: 		 ADE on hotel                     dataset:	 0.4083442986011505
2022-11-03 01:28:30,699:INFO: 		 ADE on univ                      dataset:	 0.5317856073379517
2022-11-03 01:28:31,231:INFO: 		 ADE on zara1                     dataset:	 0.4557766616344452
2022-11-03 01:28:31,966:INFO: 		 ADE on zara2                     dataset:	 0.38784340023994446
2022-11-03 01:28:31,966:INFO: Average training:	ADE  0.4946	FDE  1.0378
2022-11-03 01:28:31,975:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_544.pth.tar
2022-11-03 01:28:31,975:INFO: 
===> EPOCH: 545 (P3)
2022-11-03 01:28:31,975:INFO: - Computing loss (training)
2022-11-03 01:28:33,081:INFO: Batch:  0/31	Total Loss 4.2577 (4.2577)
2022-11-03 01:28:33,568:INFO: Batch:  1/31	Total Loss 3.7929 (4.0137)
2022-11-03 01:28:34,052:INFO: Batch:  2/31	Total Loss 3.9944 (4.0076)
2022-11-03 01:28:34,528:INFO: Batch:  3/31	Total Loss 3.5507 (3.8812)
2022-11-03 01:28:35,004:INFO: Batch:  4/31	Total Loss 3.7216 (3.8483)
2022-11-03 01:28:35,481:INFO: Batch:  5/31	Total Loss 4.2342 (3.9128)
2022-11-03 01:28:35,958:INFO: Batch:  6/31	Total Loss 3.9396 (3.9165)
2022-11-03 01:28:36,437:INFO: Batch:  7/31	Total Loss 3.7931 (3.9006)
2022-11-03 01:28:36,904:INFO: Batch:  8/31	Total Loss 3.9088 (3.9016)
2022-11-03 01:28:37,372:INFO: Batch:  9/31	Total Loss 3.8618 (3.8980)
2022-11-03 01:28:37,842:INFO: Batch: 10/31	Total Loss 3.9426 (3.9021)
2022-11-03 01:28:38,312:INFO: Batch: 11/31	Total Loss 5.0354 (3.9909)
2022-11-03 01:28:38,788:INFO: Batch: 12/31	Total Loss 4.4671 (4.0284)
2022-11-03 01:28:39,261:INFO: Batch: 13/31	Total Loss 4.3967 (4.0548)
2022-11-03 01:28:39,736:INFO: Batch: 14/31	Total Loss 3.8352 (4.0396)
2022-11-03 01:28:40,210:INFO: Batch: 15/31	Total Loss 4.6730 (4.0749)
2022-11-03 01:28:40,685:INFO: Batch: 16/31	Total Loss 4.1559 (4.0794)
2022-11-03 01:28:41,158:INFO: Batch: 17/31	Total Loss 4.0988 (4.0804)
2022-11-03 01:28:41,632:INFO: Batch: 18/31	Total Loss 3.5759 (4.0514)
2022-11-03 01:28:42,105:INFO: Batch: 19/31	Total Loss 5.0601 (4.1015)
2022-11-03 01:28:42,578:INFO: Batch: 20/31	Total Loss 4.8902 (4.1393)
2022-11-03 01:28:43,051:INFO: Batch: 21/31	Total Loss 3.8177 (4.1243)
2022-11-03 01:28:43,524:INFO: Batch: 22/31	Total Loss 4.2844 (4.1313)
2022-11-03 01:28:43,998:INFO: Batch: 23/31	Total Loss 3.6187 (4.1104)
2022-11-03 01:28:44,471:INFO: Batch: 24/31	Total Loss 4.4857 (4.1252)
2022-11-03 01:28:44,943:INFO: Batch: 25/31	Total Loss 4.2362 (4.1289)
2022-11-03 01:28:45,416:INFO: Batch: 26/31	Total Loss 4.2050 (4.1316)
2022-11-03 01:28:45,888:INFO: Batch: 27/31	Total Loss 3.9180 (4.1240)
2022-11-03 01:28:46,363:INFO: Batch: 28/31	Total Loss 3.7840 (4.1126)
2022-11-03 01:28:46,837:INFO: Batch: 29/31	Total Loss 4.3739 (4.1212)
2022-11-03 01:28:47,227:INFO: Batch: 30/31	Total Loss 1.6881 (4.0979)
2022-11-03 01:28:47,383:INFO: - Computing ADE (validation o)
2022-11-03 01:28:47,987:INFO: 		 ADE on eth                       dataset:	 0.9313063025474548
2022-11-03 01:28:47,987:INFO: Average validation o:	ADE  0.9313	FDE  1.8915
2022-11-03 01:28:47,988:INFO: - Computing ADE (validation)
2022-11-03 01:28:48,263:INFO: 		 ADE on hotel                     dataset:	 0.3948848843574524
2022-11-03 01:28:48,549:INFO: 		 ADE on univ                      dataset:	 0.5426359176635742
2022-11-03 01:28:48,804:INFO: 		 ADE on zara1                     dataset:	 0.40357309579849243
2022-11-03 01:28:49,152:INFO: 		 ADE on zara2                     dataset:	 0.4007730484008789
2022-11-03 01:28:49,152:INFO: Average validation:	ADE  0.4744	FDE  1.0030
2022-11-03 01:28:49,153:INFO: - Computing ADE (training)
2022-11-03 01:28:49,610:INFO: 		 ADE on hotel                     dataset:	 0.40394866466522217
2022-11-03 01:28:50,326:INFO: 		 ADE on univ                      dataset:	 0.5392601490020752
2022-11-03 01:28:50,860:INFO: 		 ADE on zara1                     dataset:	 0.4458681344985962
2022-11-03 01:28:51,609:INFO: 		 ADE on zara2                     dataset:	 0.39518576860427856
2022-11-03 01:28:51,610:INFO: Average training:	ADE  0.5006	FDE  1.0631
2022-11-03 01:28:51,618:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_545.pth.tar
2022-11-03 01:28:51,618:INFO: 
===> EPOCH: 546 (P3)
2022-11-03 01:28:51,619:INFO: - Computing loss (training)
2022-11-03 01:28:52,756:INFO: Batch:  0/31	Total Loss 3.6860 (3.6860)
2022-11-03 01:28:53,240:INFO: Batch:  1/31	Total Loss 4.3624 (4.0235)
2022-11-03 01:28:53,722:INFO: Batch:  2/31	Total Loss 3.9297 (3.9907)
2022-11-03 01:28:54,191:INFO: Batch:  3/31	Total Loss 4.6015 (4.1483)
2022-11-03 01:28:54,658:INFO: Batch:  4/31	Total Loss 4.0942 (4.1376)
2022-11-03 01:28:55,128:INFO: Batch:  5/31	Total Loss 3.9580 (4.1068)
2022-11-03 01:28:55,598:INFO: Batch:  6/31	Total Loss 4.3643 (4.1447)
2022-11-03 01:28:56,063:INFO: Batch:  7/31	Total Loss 4.5968 (4.2001)
2022-11-03 01:28:56,529:INFO: Batch:  8/31	Total Loss 4.7125 (4.2607)
2022-11-03 01:28:56,995:INFO: Batch:  9/31	Total Loss 4.2664 (4.2614)
2022-11-03 01:28:57,461:INFO: Batch: 10/31	Total Loss 4.3756 (4.2701)
2022-11-03 01:28:57,928:INFO: Batch: 11/31	Total Loss 4.4775 (4.2880)
2022-11-03 01:28:58,401:INFO: Batch: 12/31	Total Loss 5.1734 (4.3594)
2022-11-03 01:28:58,869:INFO: Batch: 13/31	Total Loss 4.6024 (4.3776)
2022-11-03 01:28:59,339:INFO: Batch: 14/31	Total Loss 4.3526 (4.3758)
2022-11-03 01:28:59,811:INFO: Batch: 15/31	Total Loss 4.5889 (4.3899)
2022-11-03 01:29:00,281:INFO: Batch: 16/31	Total Loss 4.4001 (4.3905)
2022-11-03 01:29:00,755:INFO: Batch: 17/31	Total Loss 4.4957 (4.3952)
2022-11-03 01:29:01,232:INFO: Batch: 18/31	Total Loss 4.4109 (4.3961)
2022-11-03 01:29:01,702:INFO: Batch: 19/31	Total Loss 4.8274 (4.4187)
2022-11-03 01:29:02,171:INFO: Batch: 20/31	Total Loss 4.5687 (4.4262)
2022-11-03 01:29:02,641:INFO: Batch: 21/31	Total Loss 3.6409 (4.3896)
2022-11-03 01:29:03,110:INFO: Batch: 22/31	Total Loss 4.3849 (4.3894)
2022-11-03 01:29:03,580:INFO: Batch: 23/31	Total Loss 4.0622 (4.3766)
2022-11-03 01:29:04,049:INFO: Batch: 24/31	Total Loss 4.2055 (4.3708)
2022-11-03 01:29:04,519:INFO: Batch: 25/31	Total Loss 3.7033 (4.3447)
2022-11-03 01:29:05,064:INFO: Batch: 26/31	Total Loss 4.0751 (4.3335)
2022-11-03 01:29:05,535:INFO: Batch: 27/31	Total Loss 3.7714 (4.3120)
2022-11-03 01:29:06,003:INFO: Batch: 28/31	Total Loss 3.8033 (4.2948)
2022-11-03 01:29:06,473:INFO: Batch: 29/31	Total Loss 3.8720 (4.2818)
2022-11-03 01:29:06,859:INFO: Batch: 30/31	Total Loss 1.5217 (4.2574)
2022-11-03 01:29:07,016:INFO: - Computing ADE (validation o)
2022-11-03 01:29:07,610:INFO: 		 ADE on eth                       dataset:	 0.9417142271995544
2022-11-03 01:29:07,610:INFO: Average validation o:	ADE  0.9417	FDE  1.8919
2022-11-03 01:29:07,611:INFO: - Computing ADE (validation)
2022-11-03 01:29:07,891:INFO: 		 ADE on hotel                     dataset:	 0.4307139217853546
2022-11-03 01:29:08,193:INFO: 		 ADE on univ                      dataset:	 0.5491349697113037
2022-11-03 01:29:08,464:INFO: 		 ADE on zara1                     dataset:	 0.3937985599040985
2022-11-03 01:29:08,804:INFO: 		 ADE on zara2                     dataset:	 0.42500782012939453
2022-11-03 01:29:08,804:INFO: Average validation:	ADE  0.4881	FDE  1.0270
2022-11-03 01:29:08,805:INFO: - Computing ADE (training)
2022-11-03 01:29:09,257:INFO: 		 ADE on hotel                     dataset:	 0.43942633271217346
2022-11-03 01:29:09,936:INFO: 		 ADE on univ                      dataset:	 0.5511242747306824
2022-11-03 01:29:10,451:INFO: 		 ADE on zara1                     dataset:	 0.46218305826187134
2022-11-03 01:29:11,184:INFO: 		 ADE on zara2                     dataset:	 0.4205179512500763
2022-11-03 01:29:11,184:INFO: Average training:	ADE  0.5161	FDE  1.0938
2022-11-03 01:29:11,193:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_546.pth.tar
2022-11-03 01:29:11,193:INFO: 
===> EPOCH: 547 (P3)
2022-11-03 01:29:11,193:INFO: - Computing loss (training)
2022-11-03 01:29:12,294:INFO: Batch:  0/31	Total Loss 3.7763 (3.7763)
2022-11-03 01:29:12,772:INFO: Batch:  1/31	Total Loss 4.0221 (3.9012)
2022-11-03 01:29:13,248:INFO: Batch:  2/31	Total Loss 4.2654 (4.0246)
2022-11-03 01:29:13,723:INFO: Batch:  3/31	Total Loss 4.0693 (4.0356)
2022-11-03 01:29:14,194:INFO: Batch:  4/31	Total Loss 3.7701 (3.9804)
2022-11-03 01:29:14,669:INFO: Batch:  5/31	Total Loss 3.9219 (3.9706)
2022-11-03 01:29:15,142:INFO: Batch:  6/31	Total Loss 4.0381 (3.9791)
2022-11-03 01:29:15,612:INFO: Batch:  7/31	Total Loss 4.6185 (4.0614)
2022-11-03 01:29:16,084:INFO: Batch:  8/31	Total Loss 4.6615 (4.1242)
2022-11-03 01:29:16,556:INFO: Batch:  9/31	Total Loss 4.1418 (4.1256)
2022-11-03 01:29:17,030:INFO: Batch: 10/31	Total Loss 4.5063 (4.1550)
2022-11-03 01:29:17,504:INFO: Batch: 11/31	Total Loss 4.3323 (4.1711)
2022-11-03 01:29:17,979:INFO: Batch: 12/31	Total Loss 3.9185 (4.1536)
2022-11-03 01:29:18,463:INFO: Batch: 13/31	Total Loss 3.8467 (4.1298)
2022-11-03 01:29:18,940:INFO: Batch: 14/31	Total Loss 3.8716 (4.1135)
2022-11-03 01:29:19,430:INFO: Batch: 15/31	Total Loss 4.7480 (4.1542)
2022-11-03 01:29:19,907:INFO: Batch: 16/31	Total Loss 5.7060 (4.2582)
2022-11-03 01:29:20,386:INFO: Batch: 17/31	Total Loss 4.2589 (4.2582)
2022-11-03 01:29:20,863:INFO: Batch: 18/31	Total Loss 3.8176 (4.2348)
2022-11-03 01:29:21,339:INFO: Batch: 19/31	Total Loss 4.3298 (4.2397)
2022-11-03 01:29:21,813:INFO: Batch: 20/31	Total Loss 4.9225 (4.2693)
2022-11-03 01:29:22,289:INFO: Batch: 21/31	Total Loss 5.0141 (4.3056)
2022-11-03 01:29:22,766:INFO: Batch: 22/31	Total Loss 3.7511 (4.2804)
2022-11-03 01:29:23,241:INFO: Batch: 23/31	Total Loss 4.0487 (4.2698)
2022-11-03 01:29:23,718:INFO: Batch: 24/31	Total Loss 4.1244 (4.2642)
2022-11-03 01:29:24,195:INFO: Batch: 25/31	Total Loss 4.5397 (4.2742)
2022-11-03 01:29:24,676:INFO: Batch: 26/31	Total Loss 4.1885 (4.2710)
2022-11-03 01:29:25,158:INFO: Batch: 27/31	Total Loss 4.1004 (4.2648)
2022-11-03 01:29:25,637:INFO: Batch: 28/31	Total Loss 4.4352 (4.2704)
2022-11-03 01:29:26,117:INFO: Batch: 29/31	Total Loss 4.0919 (4.2645)
2022-11-03 01:29:26,511:INFO: Batch: 30/31	Total Loss 1.6367 (4.2439)
2022-11-03 01:29:26,669:INFO: - Computing ADE (validation o)
2022-11-03 01:29:27,264:INFO: 		 ADE on eth                       dataset:	 0.9312214851379395
2022-11-03 01:29:27,264:INFO: Average validation o:	ADE  0.9312	FDE  1.8762
2022-11-03 01:29:27,265:INFO: - Computing ADE (validation)
2022-11-03 01:29:27,528:INFO: 		 ADE on hotel                     dataset:	 0.46855220198631287
2022-11-03 01:29:27,842:INFO: 		 ADE on univ                      dataset:	 0.575369656085968
2022-11-03 01:29:28,082:INFO: 		 ADE on zara1                     dataset:	 0.44227296113967896
2022-11-03 01:29:28,443:INFO: 		 ADE on zara2                     dataset:	 0.4393922984600067
2022-11-03 01:29:28,443:INFO: Average validation:	ADE  0.5119	FDE  1.0965
2022-11-03 01:29:28,444:INFO: - Computing ADE (training)
2022-11-03 01:29:28,895:INFO: 		 ADE on hotel                     dataset:	 0.5022058486938477
2022-11-03 01:29:29,569:INFO: 		 ADE on univ                      dataset:	 0.5714677572250366
2022-11-03 01:29:30,108:INFO: 		 ADE on zara1                     dataset:	 0.45955535769462585
2022-11-03 01:29:30,862:INFO: 		 ADE on zara2                     dataset:	 0.43039312958717346
2022-11-03 01:29:30,862:INFO: Average training:	ADE  0.5339	FDE  1.1464
2022-11-03 01:29:30,870:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_547.pth.tar
2022-11-03 01:29:30,871:INFO: 
===> EPOCH: 548 (P3)
2022-11-03 01:29:30,871:INFO: - Computing loss (training)
2022-11-03 01:29:31,968:INFO: Batch:  0/31	Total Loss 4.2291 (4.2291)
2022-11-03 01:29:32,447:INFO: Batch:  1/31	Total Loss 4.1820 (4.2057)
2022-11-03 01:29:32,917:INFO: Batch:  2/31	Total Loss 4.0100 (4.1426)
2022-11-03 01:29:33,388:INFO: Batch:  3/31	Total Loss 4.1643 (4.1475)
2022-11-03 01:29:33,858:INFO: Batch:  4/31	Total Loss 4.6961 (4.2462)
2022-11-03 01:29:34,325:INFO: Batch:  5/31	Total Loss 4.3807 (4.2657)
2022-11-03 01:29:34,792:INFO: Batch:  6/31	Total Loss 4.9996 (4.3550)
2022-11-03 01:29:35,260:INFO: Batch:  7/31	Total Loss 4.2366 (4.3422)
2022-11-03 01:29:35,726:INFO: Batch:  8/31	Total Loss 4.1917 (4.3234)
2022-11-03 01:29:36,193:INFO: Batch:  9/31	Total Loss 4.4139 (4.3325)
2022-11-03 01:29:36,662:INFO: Batch: 10/31	Total Loss 3.8544 (4.2842)
2022-11-03 01:29:37,128:INFO: Batch: 11/31	Total Loss 4.3424 (4.2893)
2022-11-03 01:29:37,602:INFO: Batch: 12/31	Total Loss 4.2180 (4.2842)
2022-11-03 01:29:38,074:INFO: Batch: 13/31	Total Loss 3.9362 (4.2591)
2022-11-03 01:29:38,545:INFO: Batch: 14/31	Total Loss 4.0214 (4.2421)
2022-11-03 01:29:39,021:INFO: Batch: 15/31	Total Loss 4.1074 (4.2349)
2022-11-03 01:29:39,493:INFO: Batch: 16/31	Total Loss 5.0086 (4.2893)
2022-11-03 01:29:39,966:INFO: Batch: 17/31	Total Loss 4.2986 (4.2898)
2022-11-03 01:29:40,440:INFO: Batch: 18/31	Total Loss 3.7672 (4.2628)
2022-11-03 01:29:40,915:INFO: Batch: 19/31	Total Loss 4.2420 (4.2617)
2022-11-03 01:29:41,387:INFO: Batch: 20/31	Total Loss 4.1365 (4.2559)
2022-11-03 01:29:41,857:INFO: Batch: 21/31	Total Loss 4.0413 (4.2456)
2022-11-03 01:29:42,327:INFO: Batch: 22/31	Total Loss 4.0096 (4.2353)
2022-11-03 01:29:42,799:INFO: Batch: 23/31	Total Loss 3.9736 (4.2244)
2022-11-03 01:29:43,269:INFO: Batch: 24/31	Total Loss 3.9096 (4.2123)
2022-11-03 01:29:43,740:INFO: Batch: 25/31	Total Loss 3.9410 (4.2027)
2022-11-03 01:29:44,211:INFO: Batch: 26/31	Total Loss 3.8358 (4.1890)
2022-11-03 01:29:44,683:INFO: Batch: 27/31	Total Loss 4.0916 (4.1859)
2022-11-03 01:29:45,154:INFO: Batch: 28/31	Total Loss 3.6126 (4.1661)
2022-11-03 01:29:45,626:INFO: Batch: 29/31	Total Loss 3.3737 (4.1395)
2022-11-03 01:29:46,013:INFO: Batch: 30/31	Total Loss 1.5011 (4.1092)
2022-11-03 01:29:46,167:INFO: - Computing ADE (validation o)
2022-11-03 01:29:46,734:INFO: 		 ADE on eth                       dataset:	 0.9256862998008728
2022-11-03 01:29:46,734:INFO: Average validation o:	ADE  0.9257	FDE  1.8174
2022-11-03 01:29:46,735:INFO: - Computing ADE (validation)
2022-11-03 01:29:46,996:INFO: 		 ADE on hotel                     dataset:	 0.3889440894126892
2022-11-03 01:29:47,314:INFO: 		 ADE on univ                      dataset:	 0.5408674478530884
2022-11-03 01:29:47,559:INFO: 		 ADE on zara1                     dataset:	 0.4049731492996216
2022-11-03 01:29:47,904:INFO: 		 ADE on zara2                     dataset:	 0.3888051211833954
2022-11-03 01:29:47,904:INFO: Average validation:	ADE  0.4689	FDE  0.9823
2022-11-03 01:29:47,905:INFO: - Computing ADE (training)
2022-11-03 01:29:48,354:INFO: 		 ADE on hotel                     dataset:	 0.4088481664657593
2022-11-03 01:29:49,062:INFO: 		 ADE on univ                      dataset:	 0.5298512578010559
2022-11-03 01:29:49,623:INFO: 		 ADE on zara1                     dataset:	 0.46971380710601807
2022-11-03 01:29:50,394:INFO: 		 ADE on zara2                     dataset:	 0.3930671811103821
2022-11-03 01:29:50,394:INFO: Average training:	ADE  0.4952	FDE  1.0418
2022-11-03 01:29:50,403:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_548.pth.tar
2022-11-03 01:29:50,403:INFO: 
===> EPOCH: 549 (P3)
2022-11-03 01:29:50,403:INFO: - Computing loss (training)
2022-11-03 01:29:51,509:INFO: Batch:  0/31	Total Loss 4.0865 (4.0865)
2022-11-03 01:29:51,977:INFO: Batch:  1/31	Total Loss 3.9383 (4.0129)
2022-11-03 01:29:52,445:INFO: Batch:  2/31	Total Loss 3.7863 (3.9310)
2022-11-03 01:29:52,913:INFO: Batch:  3/31	Total Loss 4.4582 (4.0700)
2022-11-03 01:29:53,382:INFO: Batch:  4/31	Total Loss 4.5366 (4.1556)
2022-11-03 01:29:53,850:INFO: Batch:  5/31	Total Loss 4.0763 (4.1415)
2022-11-03 01:29:54,321:INFO: Batch:  6/31	Total Loss 4.4510 (4.1861)
2022-11-03 01:29:54,793:INFO: Batch:  7/31	Total Loss 3.7845 (4.1370)
2022-11-03 01:29:55,261:INFO: Batch:  8/31	Total Loss 4.1029 (4.1333)
2022-11-03 01:29:55,729:INFO: Batch:  9/31	Total Loss 4.2874 (4.1492)
2022-11-03 01:29:56,199:INFO: Batch: 10/31	Total Loss 3.3635 (4.0684)
2022-11-03 01:29:56,666:INFO: Batch: 11/31	Total Loss 4.4279 (4.0963)
2022-11-03 01:29:57,138:INFO: Batch: 12/31	Total Loss 4.0821 (4.0952)
2022-11-03 01:29:57,613:INFO: Batch: 13/31	Total Loss 4.0376 (4.0913)
2022-11-03 01:29:58,088:INFO: Batch: 14/31	Total Loss 3.7376 (4.0657)
2022-11-03 01:29:58,562:INFO: Batch: 15/31	Total Loss 4.0807 (4.0666)
2022-11-03 01:29:59,038:INFO: Batch: 16/31	Total Loss 3.9821 (4.0623)
2022-11-03 01:29:59,515:INFO: Batch: 17/31	Total Loss 4.2787 (4.0754)
2022-11-03 01:30:00,069:INFO: Batch: 18/31	Total Loss 3.8591 (4.0652)
2022-11-03 01:30:00,549:INFO: Batch: 19/31	Total Loss 3.7893 (4.0508)
2022-11-03 01:30:01,026:INFO: Batch: 20/31	Total Loss 3.6461 (4.0306)
2022-11-03 01:30:01,516:INFO: Batch: 21/31	Total Loss 4.0490 (4.0315)
2022-11-03 01:30:01,991:INFO: Batch: 22/31	Total Loss 3.9056 (4.0264)
2022-11-03 01:30:02,468:INFO: Batch: 23/31	Total Loss 4.0478 (4.0274)
2022-11-03 01:30:02,944:INFO: Batch: 24/31	Total Loss 4.8135 (4.0619)
2022-11-03 01:30:03,421:INFO: Batch: 25/31	Total Loss 4.6536 (4.0833)
2022-11-03 01:30:03,897:INFO: Batch: 26/31	Total Loss 4.4302 (4.0959)
2022-11-03 01:30:04,372:INFO: Batch: 27/31	Total Loss 4.1301 (4.0970)
2022-11-03 01:30:04,848:INFO: Batch: 28/31	Total Loss 4.4879 (4.1093)
2022-11-03 01:30:05,323:INFO: Batch: 29/31	Total Loss 4.4192 (4.1208)
2022-11-03 01:30:05,713:INFO: Batch: 30/31	Total Loss 1.7515 (4.0974)
2022-11-03 01:30:05,866:INFO: - Computing ADE (validation o)
2022-11-03 01:30:06,478:INFO: 		 ADE on eth                       dataset:	 0.9348684549331665
2022-11-03 01:30:06,479:INFO: Average validation o:	ADE  0.9349	FDE  1.8441
2022-11-03 01:30:06,479:INFO: - Computing ADE (validation)
2022-11-03 01:30:06,759:INFO: 		 ADE on hotel                     dataset:	 0.3837476670742035
2022-11-03 01:30:07,046:INFO: 		 ADE on univ                      dataset:	 0.5400199890136719
2022-11-03 01:30:07,278:INFO: 		 ADE on zara1                     dataset:	 0.41342490911483765
2022-11-03 01:30:07,638:INFO: 		 ADE on zara2                     dataset:	 0.3853173553943634
2022-11-03 01:30:07,638:INFO: Average validation:	ADE  0.4674	FDE  0.9784
2022-11-03 01:30:07,639:INFO: - Computing ADE (training)
2022-11-03 01:30:08,118:INFO: 		 ADE on hotel                     dataset:	 0.40490326285362244
2022-11-03 01:30:08,782:INFO: 		 ADE on univ                      dataset:	 0.5276033878326416
2022-11-03 01:30:09,306:INFO: 		 ADE on zara1                     dataset:	 0.4701116681098938
2022-11-03 01:30:10,062:INFO: 		 ADE on zara2                     dataset:	 0.39049747586250305
2022-11-03 01:30:10,062:INFO: Average training:	ADE  0.4930	FDE  1.0374
2022-11-03 01:30:10,071:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_549.pth.tar
2022-11-03 01:30:10,071:INFO: 
===> EPOCH: 550 (P3)
2022-11-03 01:30:10,072:INFO: - Computing loss (training)
2022-11-03 01:30:11,187:INFO: Batch:  0/31	Total Loss 3.8950 (3.8950)
2022-11-03 01:30:11,670:INFO: Batch:  1/31	Total Loss 4.6087 (4.2879)
2022-11-03 01:30:12,155:INFO: Batch:  2/31	Total Loss 3.7309 (4.0928)
2022-11-03 01:30:12,637:INFO: Batch:  3/31	Total Loss 4.0926 (4.0928)
2022-11-03 01:30:13,113:INFO: Batch:  4/31	Total Loss 4.5130 (4.1662)
2022-11-03 01:30:13,597:INFO: Batch:  5/31	Total Loss 4.5365 (4.2319)
2022-11-03 01:30:14,079:INFO: Batch:  6/31	Total Loss 4.0341 (4.2012)
2022-11-03 01:30:14,561:INFO: Batch:  7/31	Total Loss 3.7248 (4.1358)
2022-11-03 01:30:15,042:INFO: Batch:  8/31	Total Loss 4.0468 (4.1261)
2022-11-03 01:30:15,525:INFO: Batch:  9/31	Total Loss 3.9709 (4.1087)
2022-11-03 01:30:16,008:INFO: Batch: 10/31	Total Loss 4.1660 (4.1140)
2022-11-03 01:30:16,492:INFO: Batch: 11/31	Total Loss 3.9117 (4.0943)
2022-11-03 01:30:16,977:INFO: Batch: 12/31	Total Loss 4.5120 (4.1244)
2022-11-03 01:30:17,466:INFO: Batch: 13/31	Total Loss 4.0563 (4.1195)
2022-11-03 01:30:17,950:INFO: Batch: 14/31	Total Loss 3.7763 (4.0949)
2022-11-03 01:30:18,433:INFO: Batch: 15/31	Total Loss 4.2039 (4.1022)
2022-11-03 01:30:18,917:INFO: Batch: 16/31	Total Loss 3.7685 (4.0817)
2022-11-03 01:30:19,388:INFO: Batch: 17/31	Total Loss 4.0493 (4.0797)
2022-11-03 01:30:19,858:INFO: Batch: 18/31	Total Loss 4.3610 (4.0953)
2022-11-03 01:30:20,327:INFO: Batch: 19/31	Total Loss 3.7965 (4.0812)
2022-11-03 01:30:20,801:INFO: Batch: 20/31	Total Loss 4.3826 (4.0954)
2022-11-03 01:30:21,270:INFO: Batch: 21/31	Total Loss 3.7984 (4.0823)
2022-11-03 01:30:21,739:INFO: Batch: 22/31	Total Loss 4.6194 (4.1073)
2022-11-03 01:30:22,209:INFO: Batch: 23/31	Total Loss 4.6339 (4.1273)
2022-11-03 01:30:22,681:INFO: Batch: 24/31	Total Loss 3.9571 (4.1203)
2022-11-03 01:30:23,150:INFO: Batch: 25/31	Total Loss 3.8961 (4.1115)
2022-11-03 01:30:23,619:INFO: Batch: 26/31	Total Loss 4.0762 (4.1102)
2022-11-03 01:30:24,086:INFO: Batch: 27/31	Total Loss 3.7478 (4.0967)
2022-11-03 01:30:24,555:INFO: Batch: 28/31	Total Loss 3.9862 (4.0928)
2022-11-03 01:30:25,025:INFO: Batch: 29/31	Total Loss 4.2354 (4.0979)
2022-11-03 01:30:25,411:INFO: Batch: 30/31	Total Loss 1.6557 (4.0765)
2022-11-03 01:30:25,567:INFO: - Computing ADE (validation o)
2022-11-03 01:30:26,167:INFO: 		 ADE on eth                       dataset:	 0.9231707453727722
2022-11-03 01:30:26,167:INFO: Average validation o:	ADE  0.9232	FDE  1.8612
2022-11-03 01:30:26,168:INFO: - Computing ADE (validation)
2022-11-03 01:30:26,450:INFO: 		 ADE on hotel                     dataset:	 0.4134449362754822
2022-11-03 01:30:26,752:INFO: 		 ADE on univ                      dataset:	 0.5566809177398682
2022-11-03 01:30:26,992:INFO: 		 ADE on zara1                     dataset:	 0.4267614781856537
2022-11-03 01:30:27,339:INFO: 		 ADE on zara2                     dataset:	 0.40208524465560913
2022-11-03 01:30:27,339:INFO: Average validation:	ADE  0.4846	FDE  1.0272
2022-11-03 01:30:27,340:INFO: - Computing ADE (training)
2022-11-03 01:30:27,800:INFO: 		 ADE on hotel                     dataset:	 0.43571045994758606
2022-11-03 01:30:28,483:INFO: 		 ADE on univ                      dataset:	 0.5422439575195312
2022-11-03 01:30:29,015:INFO: 		 ADE on zara1                     dataset:	 0.4626886546611786
2022-11-03 01:30:29,790:INFO: 		 ADE on zara2                     dataset:	 0.40223321318626404
2022-11-03 01:30:29,791:INFO: Average training:	ADE  0.5061	FDE  1.0742
2022-11-03 01:30:29,799:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P3/CRMF_epoch_550.pth.tar
2022-11-03 01:30:29,799:INFO: 
===> EPOCH: 551 (P4)
2022-11-03 01:30:29,800:INFO: - Computing loss (training)
2022-11-03 01:30:30,925:INFO: Batch:  0/31	Total Loss 105.6264 (105.6264)
2022-11-03 01:30:31,427:INFO: Batch:  1/31	Total Loss 104.6834 (105.1542)
2022-11-03 01:30:31,932:INFO: Batch:  2/31	Total Loss 99.1912 (103.3225)
2022-11-03 01:30:32,432:INFO: Batch:  3/31	Total Loss 91.7207 (100.3431)
2022-11-03 01:30:32,930:INFO: Batch:  4/31	Total Loss 90.2628 (98.3703)
2022-11-03 01:30:33,430:INFO: Batch:  5/31	Total Loss 84.6938 (96.1398)
2022-11-03 01:30:33,935:INFO: Batch:  6/31	Total Loss 80.5023 (93.6129)
2022-11-03 01:30:34,433:INFO: Batch:  7/31	Total Loss 80.1311 (91.8212)
2022-11-03 01:30:34,932:INFO: Batch:  8/31	Total Loss 76.5300 (89.9479)
2022-11-03 01:30:35,432:INFO: Batch:  9/31	Total Loss 76.0959 (88.5025)
2022-11-03 01:30:35,929:INFO: Batch: 10/31	Total Loss 74.5497 (87.2495)
2022-11-03 01:30:36,428:INFO: Batch: 11/31	Total Loss 70.4485 (85.8509)
2022-11-03 01:30:36,932:INFO: Batch: 12/31	Total Loss 72.3071 (84.6998)
2022-11-03 01:30:37,434:INFO: Batch: 13/31	Total Loss 70.1311 (83.6314)
2022-11-03 01:30:37,935:INFO: Batch: 14/31	Total Loss 69.7304 (82.7544)
2022-11-03 01:30:38,437:INFO: Batch: 15/31	Total Loss 71.3072 (82.1295)
2022-11-03 01:30:38,939:INFO: Batch: 16/31	Total Loss 68.7657 (81.3736)
2022-11-03 01:30:39,440:INFO: Batch: 17/31	Total Loss 67.0352 (80.5847)
2022-11-03 01:30:39,942:INFO: Batch: 18/31	Total Loss 65.4651 (79.7978)
2022-11-03 01:30:40,446:INFO: Batch: 19/31	Total Loss 66.5849 (79.1121)
2022-11-03 01:30:40,946:INFO: Batch: 20/31	Total Loss 65.2336 (78.4994)
2022-11-03 01:30:41,447:INFO: Batch: 21/31	Total Loss 65.6064 (77.9237)
2022-11-03 01:30:41,947:INFO: Batch: 22/31	Total Loss 66.1893 (77.4765)
2022-11-03 01:30:42,449:INFO: Batch: 23/31	Total Loss 64.4024 (76.9752)
2022-11-03 01:30:42,950:INFO: Batch: 24/31	Total Loss 64.9868 (76.4871)
2022-11-03 01:30:43,451:INFO: Batch: 25/31	Total Loss 62.2032 (75.9219)
2022-11-03 01:30:43,951:INFO: Batch: 26/31	Total Loss 60.7885 (75.3322)
2022-11-03 01:30:44,452:INFO: Batch: 27/31	Total Loss 63.1248 (74.9323)
2022-11-03 01:30:44,953:INFO: Batch: 28/31	Total Loss 64.6451 (74.6073)
2022-11-03 01:30:45,454:INFO: Batch: 29/31	Total Loss 61.0591 (74.1586)
2022-11-03 01:30:45,850:INFO: Batch: 30/31	Total Loss -20.2847 (73.4185)
2022-11-03 01:30:45,997:INFO: - Computing ADE (validation o)
2022-11-03 01:30:46,703:INFO: 		 ADE on eth                       dataset:	 2.825202226638794
2022-11-03 01:30:46,703:INFO: Average validation o:	ADE  2.8252	FDE  4.7997
2022-11-03 01:30:46,704:INFO: - Computing ADE (validation)
2022-11-03 01:30:47,022:INFO: 		 ADE on hotel                     dataset:	 0.9062922596931458
2022-11-03 01:30:47,400:INFO: 		 ADE on univ                      dataset:	 1.4834734201431274
2022-11-03 01:30:47,700:INFO: 		 ADE on zara1                     dataset:	 2.513833522796631
2022-11-03 01:30:48,171:INFO: 		 ADE on zara2                     dataset:	 1.3886536359786987
2022-11-03 01:30:48,172:INFO: Average validation:	ADE  1.4770	FDE  2.6951
2022-11-03 01:30:48,172:INFO: - Computing ADE (training)
2022-11-03 01:30:48,738:INFO: 		 ADE on hotel                     dataset:	 1.2713580131530762
2022-11-03 01:30:49,758:INFO: 		 ADE on univ                      dataset:	 1.3702034950256348
2022-11-03 01:30:50,528:INFO: 		 ADE on zara1                     dataset:	 2.454709768295288
2022-11-03 01:30:51,685:INFO: 		 ADE on zara2                     dataset:	 1.66350257396698
2022-11-03 01:30:51,686:INFO: Average training:	ADE  1.4963	FDE  2.7344
2022-11-03 01:30:51,698:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_551.pth.tar
2022-11-03 01:30:51,699:INFO: 
===> EPOCH: 552 (P4)
2022-11-03 01:30:51,699:INFO: - Computing loss (training)
2022-11-03 01:30:52,823:INFO: Batch:  0/31	Total Loss 58.0769 (58.0769)
2022-11-03 01:30:53,318:INFO: Batch:  1/31	Total Loss 59.8060 (58.8803)
2022-11-03 01:30:53,812:INFO: Batch:  2/31	Total Loss 57.3692 (58.3879)
2022-11-03 01:30:54,307:INFO: Batch:  3/31	Total Loss 57.6294 (58.1962)
2022-11-03 01:30:54,798:INFO: Batch:  4/31	Total Loss 60.3055 (58.6181)
2022-11-03 01:30:55,294:INFO: Batch:  5/31	Total Loss 59.9673 (58.8227)
2022-11-03 01:30:55,789:INFO: Batch:  6/31	Total Loss 61.4565 (59.1707)
2022-11-03 01:30:56,359:INFO: Batch:  7/31	Total Loss 57.4482 (58.9618)
2022-11-03 01:30:56,849:INFO: Batch:  8/31	Total Loss 59.6011 (59.0227)
2022-11-03 01:30:57,343:INFO: Batch:  9/31	Total Loss 56.3580 (58.7555)
2022-11-03 01:30:57,837:INFO: Batch: 10/31	Total Loss 51.4756 (58.0325)
2022-11-03 01:30:58,330:INFO: Batch: 11/31	Total Loss 54.8634 (57.7928)
2022-11-03 01:30:58,825:INFO: Batch: 12/31	Total Loss 55.9439 (57.6518)
2022-11-03 01:30:59,322:INFO: Batch: 13/31	Total Loss 56.4530 (57.5642)
2022-11-03 01:30:59,820:INFO: Batch: 14/31	Total Loss 54.0718 (57.3357)
2022-11-03 01:31:00,316:INFO: Batch: 15/31	Total Loss 53.1881 (57.0577)
2022-11-03 01:31:00,817:INFO: Batch: 16/31	Total Loss 56.5295 (57.0286)
2022-11-03 01:31:01,317:INFO: Batch: 17/31	Total Loss 53.8151 (56.8573)
2022-11-03 01:31:01,814:INFO: Batch: 18/31	Total Loss 53.2039 (56.6481)
2022-11-03 01:31:02,311:INFO: Batch: 19/31	Total Loss 50.3884 (56.3052)
2022-11-03 01:31:02,805:INFO: Batch: 20/31	Total Loss 54.9932 (56.2445)
2022-11-03 01:31:03,300:INFO: Batch: 21/31	Total Loss 52.8736 (56.0846)
2022-11-03 01:31:03,795:INFO: Batch: 22/31	Total Loss 53.0205 (55.9488)
2022-11-03 01:31:04,291:INFO: Batch: 23/31	Total Loss 53.8260 (55.8645)
2022-11-03 01:31:04,785:INFO: Batch: 24/31	Total Loss 51.7848 (55.7043)
2022-11-03 01:31:05,280:INFO: Batch: 25/31	Total Loss 50.2174 (55.4773)
2022-11-03 01:31:05,774:INFO: Batch: 26/31	Total Loss 54.4213 (55.4382)
2022-11-03 01:31:06,270:INFO: Batch: 27/31	Total Loss 49.4627 (55.2223)
2022-11-03 01:31:06,765:INFO: Batch: 28/31	Total Loss 50.8176 (55.0830)
2022-11-03 01:31:07,260:INFO: Batch: 29/31	Total Loss 52.2309 (54.9979)
2022-11-03 01:31:07,653:INFO: Batch: 30/31	Total Loss -25.9596 (54.3175)
2022-11-03 01:31:07,804:INFO: - Computing ADE (validation o)
2022-11-03 01:31:08,496:INFO: 		 ADE on eth                       dataset:	 2.7935469150543213
2022-11-03 01:31:08,496:INFO: Average validation o:	ADE  2.7935	FDE  4.7744
2022-11-03 01:31:08,497:INFO: - Computing ADE (validation)
2022-11-03 01:31:08,809:INFO: 		 ADE on hotel                     dataset:	 0.9228165149688721
2022-11-03 01:31:09,176:INFO: 		 ADE on univ                      dataset:	 1.4653074741363525
2022-11-03 01:31:09,452:INFO: 		 ADE on zara1                     dataset:	 2.4231879711151123
2022-11-03 01:31:09,917:INFO: 		 ADE on zara2                     dataset:	 1.370186686515808
2022-11-03 01:31:09,918:INFO: Average validation:	ADE  1.4564	FDE  2.6697
2022-11-03 01:31:09,918:INFO: - Computing ADE (training)
2022-11-03 01:31:10,515:INFO: 		 ADE on hotel                     dataset:	 1.2828543186187744
2022-11-03 01:31:11,560:INFO: 		 ADE on univ                      dataset:	 1.350659728050232
2022-11-03 01:31:12,280:INFO: 		 ADE on zara1                     dataset:	 2.410848379135132
2022-11-03 01:31:13,444:INFO: 		 ADE on zara2                     dataset:	 1.6494064331054688
2022-11-03 01:31:13,444:INFO: Average training:	ADE  1.4771	FDE  2.7125
2022-11-03 01:31:13,456:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_552.pth.tar
2022-11-03 01:31:13,456:INFO: 
===> EPOCH: 553 (P4)
2022-11-03 01:31:13,456:INFO: - Computing loss (training)
2022-11-03 01:31:14,553:INFO: Batch:  0/31	Total Loss 48.7491 (48.7491)
2022-11-03 01:31:15,044:INFO: Batch:  1/31	Total Loss 50.6870 (49.7468)
2022-11-03 01:31:15,538:INFO: Batch:  2/31	Total Loss 52.4616 (50.5982)
2022-11-03 01:31:16,031:INFO: Batch:  3/31	Total Loss 50.8778 (50.6636)
2022-11-03 01:31:16,522:INFO: Batch:  4/31	Total Loss 47.6280 (50.0320)
2022-11-03 01:31:17,015:INFO: Batch:  5/31	Total Loss 47.1707 (49.5498)
2022-11-03 01:31:17,506:INFO: Batch:  6/31	Total Loss 47.9943 (49.3296)
2022-11-03 01:31:17,995:INFO: Batch:  7/31	Total Loss 45.8412 (48.8615)
2022-11-03 01:31:18,484:INFO: Batch:  8/31	Total Loss 48.6243 (48.8334)
2022-11-03 01:31:18,974:INFO: Batch:  9/31	Total Loss 46.2139 (48.5585)
2022-11-03 01:31:19,464:INFO: Batch: 10/31	Total Loss 47.4319 (48.4540)
2022-11-03 01:31:19,955:INFO: Batch: 11/31	Total Loss 47.9694 (48.4152)
2022-11-03 01:31:20,450:INFO: Batch: 12/31	Total Loss 45.2036 (48.1737)
2022-11-03 01:31:20,947:INFO: Batch: 13/31	Total Loss 48.8447 (48.2208)
2022-11-03 01:31:21,444:INFO: Batch: 14/31	Total Loss 45.3444 (48.0281)
2022-11-03 01:31:21,936:INFO: Batch: 15/31	Total Loss 45.2957 (47.8509)
2022-11-03 01:31:22,431:INFO: Batch: 16/31	Total Loss 41.8514 (47.5110)
2022-11-03 01:31:22,924:INFO: Batch: 17/31	Total Loss 45.6867 (47.4106)
2022-11-03 01:31:23,416:INFO: Batch: 18/31	Total Loss 47.9822 (47.4435)
2022-11-03 01:31:23,907:INFO: Batch: 19/31	Total Loss 43.1604 (47.2435)
2022-11-03 01:31:24,400:INFO: Batch: 20/31	Total Loss 39.6990 (46.8242)
2022-11-03 01:31:24,893:INFO: Batch: 21/31	Total Loss 49.2998 (46.9198)
2022-11-03 01:31:25,384:INFO: Batch: 22/31	Total Loss 47.7137 (46.9528)
2022-11-03 01:31:25,875:INFO: Batch: 23/31	Total Loss 45.8126 (46.9025)
2022-11-03 01:31:26,367:INFO: Batch: 24/31	Total Loss 42.8860 (46.7466)
2022-11-03 01:31:26,859:INFO: Batch: 25/31	Total Loss 42.4570 (46.5993)
2022-11-03 01:31:27,350:INFO: Batch: 26/31	Total Loss 42.0605 (46.4384)
2022-11-03 01:31:27,841:INFO: Batch: 27/31	Total Loss 43.5203 (46.3324)
2022-11-03 01:31:28,332:INFO: Batch: 28/31	Total Loss 43.7439 (46.2478)
2022-11-03 01:31:28,824:INFO: Batch: 29/31	Total Loss 47.7954 (46.2920)
2022-11-03 01:31:29,212:INFO: Batch: 30/31	Total Loss -28.9822 (45.4159)
2022-11-03 01:31:29,360:INFO: - Computing ADE (validation o)
2022-11-03 01:31:30,046:INFO: 		 ADE on eth                       dataset:	 2.619384765625
2022-11-03 01:31:30,046:INFO: Average validation o:	ADE  2.6194	FDE  4.4813
2022-11-03 01:31:30,047:INFO: - Computing ADE (validation)
2022-11-03 01:31:30,337:INFO: 		 ADE on hotel                     dataset:	 0.9477907419204712
2022-11-03 01:31:30,711:INFO: 		 ADE on univ                      dataset:	 1.3808460235595703
2022-11-03 01:31:30,984:INFO: 		 ADE on zara1                     dataset:	 2.252021074295044
2022-11-03 01:31:31,461:INFO: 		 ADE on zara2                     dataset:	 1.3200567960739136
2022-11-03 01:31:31,461:INFO: Average validation:	ADE  1.3855	FDE  2.5530
2022-11-03 01:31:31,461:INFO: - Computing ADE (training)
2022-11-03 01:31:32,056:INFO: 		 ADE on hotel                     dataset:	 1.2731419801712036
2022-11-03 01:31:33,113:INFO: 		 ADE on univ                      dataset:	 1.2888950109481812
2022-11-03 01:31:33,875:INFO: 		 ADE on zara1                     dataset:	 2.243708610534668
2022-11-03 01:31:35,035:INFO: 		 ADE on zara2                     dataset:	 1.5606839656829834
2022-11-03 01:31:35,035:INFO: Average training:	ADE  1.4045	FDE  2.5910
2022-11-03 01:31:35,046:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_553.pth.tar
2022-11-03 01:31:35,046:INFO: 
===> EPOCH: 554 (P4)
2022-11-03 01:31:35,047:INFO: - Computing loss (training)
2022-11-03 01:31:36,164:INFO: Batch:  0/31	Total Loss 44.4278 (44.4278)
2022-11-03 01:31:36,658:INFO: Batch:  1/31	Total Loss 43.1573 (43.7960)
2022-11-03 01:31:37,151:INFO: Batch:  2/31	Total Loss 40.4833 (42.5865)
2022-11-03 01:31:37,642:INFO: Batch:  3/31	Total Loss 44.4528 (43.0554)
2022-11-03 01:31:38,134:INFO: Batch:  4/31	Total Loss 37.5911 (41.8250)
2022-11-03 01:31:38,626:INFO: Batch:  5/31	Total Loss 40.5742 (41.6048)
2022-11-03 01:31:39,117:INFO: Batch:  6/31	Total Loss 39.6814 (41.3295)
2022-11-03 01:31:39,609:INFO: Batch:  7/31	Total Loss 42.3647 (41.4465)
2022-11-03 01:31:40,097:INFO: Batch:  8/31	Total Loss 38.8788 (41.1683)
2022-11-03 01:31:40,588:INFO: Batch:  9/31	Total Loss 39.4133 (40.9979)
2022-11-03 01:31:41,078:INFO: Batch: 10/31	Total Loss 41.7934 (41.0616)
2022-11-03 01:31:41,569:INFO: Batch: 11/31	Total Loss 40.0910 (40.9827)
2022-11-03 01:31:42,062:INFO: Batch: 12/31	Total Loss 37.5412 (40.7346)
2022-11-03 01:31:42,555:INFO: Batch: 13/31	Total Loss 37.4811 (40.4854)
2022-11-03 01:31:43,049:INFO: Batch: 14/31	Total Loss 34.8868 (40.0949)
2022-11-03 01:31:43,545:INFO: Batch: 15/31	Total Loss 38.4890 (40.0010)
2022-11-03 01:31:44,037:INFO: Batch: 16/31	Total Loss 37.2692 (39.8335)
2022-11-03 01:31:44,532:INFO: Batch: 17/31	Total Loss 32.6598 (39.3920)
2022-11-03 01:31:45,026:INFO: Batch: 18/31	Total Loss 33.5732 (39.0937)
2022-11-03 01:31:45,519:INFO: Batch: 19/31	Total Loss 31.3261 (38.6843)
2022-11-03 01:31:46,014:INFO: Batch: 20/31	Total Loss 35.8884 (38.5604)
2022-11-03 01:31:46,507:INFO: Batch: 21/31	Total Loss 35.3147 (38.4122)
2022-11-03 01:31:46,999:INFO: Batch: 22/31	Total Loss 36.4197 (38.3260)
2022-11-03 01:31:47,494:INFO: Batch: 23/31	Total Loss 38.3894 (38.3288)
2022-11-03 01:31:47,987:INFO: Batch: 24/31	Total Loss 33.5149 (38.1155)
2022-11-03 01:31:48,480:INFO: Batch: 25/31	Total Loss 36.1201 (38.0407)
2022-11-03 01:31:48,973:INFO: Batch: 26/31	Total Loss 31.2526 (37.7884)
2022-11-03 01:31:49,466:INFO: Batch: 27/31	Total Loss 36.7831 (37.7552)
2022-11-03 01:31:49,959:INFO: Batch: 28/31	Total Loss 31.9618 (37.5293)
2022-11-03 01:31:50,453:INFO: Batch: 29/31	Total Loss 28.7896 (37.2392)
2022-11-03 01:31:50,918:INFO: Batch: 30/31	Total Loss -31.2205 (36.5809)
2022-11-03 01:31:51,061:INFO: - Computing ADE (validation o)
2022-11-03 01:31:51,794:INFO: 		 ADE on eth                       dataset:	 2.042903184890747
2022-11-03 01:31:51,795:INFO: Average validation o:	ADE  2.0429	FDE  3.3995
2022-11-03 01:31:51,795:INFO: - Computing ADE (validation)
2022-11-03 01:31:52,098:INFO: 		 ADE on hotel                     dataset:	 0.9906141757965088
2022-11-03 01:31:52,472:INFO: 		 ADE on univ                      dataset:	 1.0966053009033203
2022-11-03 01:31:52,753:INFO: 		 ADE on zara1                     dataset:	 1.428371787071228
2022-11-03 01:31:53,212:INFO: 		 ADE on zara2                     dataset:	 0.9896592497825623
2022-11-03 01:31:53,212:INFO: Average validation:	ADE  1.0709	FDE  1.9379
2022-11-03 01:31:53,212:INFO: - Computing ADE (training)
2022-11-03 01:31:53,779:INFO: 		 ADE on hotel                     dataset:	 1.2489182949066162
2022-11-03 01:31:54,831:INFO: 		 ADE on univ                      dataset:	 1.0435465574264526
2022-11-03 01:31:55,598:INFO: 		 ADE on zara1                     dataset:	 1.5615689754486084
2022-11-03 01:31:56,785:INFO: 		 ADE on zara2                     dataset:	 1.136769413948059
2022-11-03 01:31:56,786:INFO: Average training:	ADE  1.1007	FDE  1.9953
2022-11-03 01:31:56,797:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_554.pth.tar
2022-11-03 01:31:56,797:INFO: 
===> EPOCH: 555 (P4)
2022-11-03 01:31:56,797:INFO: - Computing loss (training)
2022-11-03 01:31:57,918:INFO: Batch:  0/31	Total Loss 33.3993 (33.3993)
2022-11-03 01:31:58,421:INFO: Batch:  1/31	Total Loss 30.4412 (31.8026)
2022-11-03 01:31:58,920:INFO: Batch:  2/31	Total Loss 30.7661 (31.4747)
2022-11-03 01:31:59,416:INFO: Batch:  3/31	Total Loss 31.3452 (31.4436)
2022-11-03 01:31:59,907:INFO: Batch:  4/31	Total Loss 31.6618 (31.4885)
2022-11-03 01:32:00,404:INFO: Batch:  5/31	Total Loss 34.7345 (32.0217)
2022-11-03 01:32:00,897:INFO: Batch:  6/31	Total Loss 32.7511 (32.1305)
2022-11-03 01:32:01,390:INFO: Batch:  7/31	Total Loss 31.6646 (32.0774)
2022-11-03 01:32:01,881:INFO: Batch:  8/31	Total Loss 28.1475 (31.6157)
2022-11-03 01:32:02,374:INFO: Batch:  9/31	Total Loss 28.9253 (31.3534)
2022-11-03 01:32:02,865:INFO: Batch: 10/31	Total Loss 31.6982 (31.3809)
2022-11-03 01:32:03,360:INFO: Batch: 11/31	Total Loss 30.2701 (31.2906)
2022-11-03 01:32:03,854:INFO: Batch: 12/31	Total Loss 28.7562 (31.0855)
2022-11-03 01:32:04,348:INFO: Batch: 13/31	Total Loss 29.0202 (30.9299)
2022-11-03 01:32:04,842:INFO: Batch: 14/31	Total Loss 27.8765 (30.7109)
2022-11-03 01:32:05,336:INFO: Batch: 15/31	Total Loss 28.5300 (30.5798)
2022-11-03 01:32:05,829:INFO: Batch: 16/31	Total Loss 32.7594 (30.7019)
2022-11-03 01:32:06,326:INFO: Batch: 17/31	Total Loss 26.2321 (30.4173)
2022-11-03 01:32:06,819:INFO: Batch: 18/31	Total Loss 25.7953 (30.1585)
2022-11-03 01:32:07,312:INFO: Batch: 19/31	Total Loss 27.8074 (30.0496)
2022-11-03 01:32:07,807:INFO: Batch: 20/31	Total Loss 24.8607 (29.7691)
2022-11-03 01:32:08,299:INFO: Batch: 21/31	Total Loss 32.7508 (29.8826)
2022-11-03 01:32:08,792:INFO: Batch: 22/31	Total Loss 28.4056 (29.8221)
2022-11-03 01:32:09,285:INFO: Batch: 23/31	Total Loss 23.6917 (29.5632)
2022-11-03 01:32:09,779:INFO: Batch: 24/31	Total Loss 27.9893 (29.4948)
2022-11-03 01:32:10,271:INFO: Batch: 25/31	Total Loss 27.7905 (29.4301)
2022-11-03 01:32:10,766:INFO: Batch: 26/31	Total Loss 26.1635 (29.2953)
2022-11-03 01:32:11,258:INFO: Batch: 27/31	Total Loss 25.3516 (29.1539)
2022-11-03 01:32:11,750:INFO: Batch: 28/31	Total Loss 28.0967 (29.1189)
2022-11-03 01:32:12,243:INFO: Batch: 29/31	Total Loss 22.8099 (28.8930)
2022-11-03 01:32:12,631:INFO: Batch: 30/31	Total Loss -32.9361 (28.2008)
2022-11-03 01:32:12,779:INFO: - Computing ADE (validation o)
2022-11-03 01:32:13,440:INFO: 		 ADE on eth                       dataset:	 1.6517109870910645
2022-11-03 01:32:13,440:INFO: Average validation o:	ADE  1.6517	FDE  2.5757
2022-11-03 01:32:13,441:INFO: - Computing ADE (validation)
2022-11-03 01:32:13,752:INFO: 		 ADE on hotel                     dataset:	 1.0222644805908203
2022-11-03 01:32:14,142:INFO: 		 ADE on univ                      dataset:	 1.017816185951233
2022-11-03 01:32:14,428:INFO: 		 ADE on zara1                     dataset:	 1.120385766029358
2022-11-03 01:32:14,898:INFO: 		 ADE on zara2                     dataset:	 0.8049321174621582
2022-11-03 01:32:14,898:INFO: Average validation:	ADE  0.9459	FDE  1.6250
2022-11-03 01:32:14,899:INFO: - Computing ADE (training)
2022-11-03 01:32:15,456:INFO: 		 ADE on hotel                     dataset:	 1.3334540128707886
2022-11-03 01:32:16,511:INFO: 		 ADE on univ                      dataset:	 0.9558430910110474
2022-11-03 01:32:17,242:INFO: 		 ADE on zara1                     dataset:	 1.2562350034713745
2022-11-03 01:32:18,426:INFO: 		 ADE on zara2                     dataset:	 0.9215001463890076
2022-11-03 01:32:18,426:INFO: Average training:	ADE  0.9776	FDE  1.6832
2022-11-03 01:32:18,437:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_555.pth.tar
2022-11-03 01:32:18,437:INFO: 
===> EPOCH: 556 (P4)
2022-11-03 01:32:18,438:INFO: - Computing loss (training)
2022-11-03 01:32:19,545:INFO: Batch:  0/31	Total Loss 22.4477 (22.4477)
2022-11-03 01:32:20,050:INFO: Batch:  1/31	Total Loss 28.1506 (25.1342)
2022-11-03 01:32:20,558:INFO: Batch:  2/31	Total Loss 23.0382 (24.4241)
2022-11-03 01:32:21,055:INFO: Batch:  3/31	Total Loss 23.5289 (24.1845)
2022-11-03 01:32:21,557:INFO: Batch:  4/31	Total Loss 21.7344 (23.6669)
2022-11-03 01:32:22,060:INFO: Batch:  5/31	Total Loss 19.6001 (22.9839)
2022-11-03 01:32:22,564:INFO: Batch:  6/31	Total Loss 22.7545 (22.9512)
2022-11-03 01:32:23,064:INFO: Batch:  7/31	Total Loss 22.7190 (22.9228)
2022-11-03 01:32:23,562:INFO: Batch:  8/31	Total Loss 21.4048 (22.7462)
2022-11-03 01:32:24,062:INFO: Batch:  9/31	Total Loss 19.5180 (22.4438)
2022-11-03 01:32:24,562:INFO: Batch: 10/31	Total Loss 21.6330 (22.3671)
2022-11-03 01:32:25,064:INFO: Batch: 11/31	Total Loss 22.1350 (22.3483)
2022-11-03 01:32:25,567:INFO: Batch: 12/31	Total Loss 28.1475 (22.7375)
2022-11-03 01:32:26,070:INFO: Batch: 13/31	Total Loss 22.6236 (22.7293)
2022-11-03 01:32:26,573:INFO: Batch: 14/31	Total Loss 18.3164 (22.4235)
2022-11-03 01:32:27,076:INFO: Batch: 15/31	Total Loss 21.2814 (22.3475)
2022-11-03 01:32:27,577:INFO: Batch: 16/31	Total Loss 22.3669 (22.3486)
2022-11-03 01:32:28,076:INFO: Batch: 17/31	Total Loss 27.0838 (22.5706)
2022-11-03 01:32:28,574:INFO: Batch: 18/31	Total Loss 17.2269 (22.2763)
2022-11-03 01:32:29,071:INFO: Batch: 19/31	Total Loss 22.2629 (22.2756)
2022-11-03 01:32:29,571:INFO: Batch: 20/31	Total Loss 25.6222 (22.4066)
2022-11-03 01:32:30,067:INFO: Batch: 21/31	Total Loss 21.7159 (22.3777)
2022-11-03 01:32:30,567:INFO: Batch: 22/31	Total Loss 22.7118 (22.3927)
2022-11-03 01:32:31,064:INFO: Batch: 23/31	Total Loss 21.0538 (22.3368)
2022-11-03 01:32:31,559:INFO: Batch: 24/31	Total Loss 23.3336 (22.3712)
2022-11-03 01:32:32,057:INFO: Batch: 25/31	Total Loss 28.7936 (22.5938)
2022-11-03 01:32:32,555:INFO: Batch: 26/31	Total Loss 19.6310 (22.4744)
2022-11-03 01:32:33,054:INFO: Batch: 27/31	Total Loss 26.8862 (22.6194)
2022-11-03 01:32:33,550:INFO: Batch: 28/31	Total Loss 17.9828 (22.4557)
2022-11-03 01:32:34,047:INFO: Batch: 29/31	Total Loss 20.9620 (22.4039)
2022-11-03 01:32:34,439:INFO: Batch: 30/31	Total Loss -39.3468 (21.8824)
2022-11-03 01:32:34,588:INFO: - Computing ADE (validation o)
2022-11-03 01:32:35,271:INFO: 		 ADE on eth                       dataset:	 1.4989277124404907
2022-11-03 01:32:35,271:INFO: Average validation o:	ADE  1.4989	FDE  2.3360
2022-11-03 01:32:35,272:INFO: - Computing ADE (validation)
2022-11-03 01:32:35,572:INFO: 		 ADE on hotel                     dataset:	 1.0340983867645264
2022-11-03 01:32:35,952:INFO: 		 ADE on univ                      dataset:	 0.9897912740707397
2022-11-03 01:32:36,243:INFO: 		 ADE on zara1                     dataset:	 1.0773932933807373
2022-11-03 01:32:36,713:INFO: 		 ADE on zara2                     dataset:	 0.7516870498657227
2022-11-03 01:32:36,713:INFO: Average validation:	ADE  0.9100	FDE  1.5719
2022-11-03 01:32:36,714:INFO: - Computing ADE (training)
2022-11-03 01:32:37,338:INFO: 		 ADE on hotel                     dataset:	 1.3436676263809204
2022-11-03 01:32:38,386:INFO: 		 ADE on univ                      dataset:	 0.932687520980835
2022-11-03 01:32:39,099:INFO: 		 ADE on zara1                     dataset:	 1.1488851308822632
2022-11-03 01:32:40,260:INFO: 		 ADE on zara2                     dataset:	 0.8425653576850891
2022-11-03 01:32:40,260:INFO: Average training:	ADE  0.9386	FDE  1.6248
2022-11-03 01:32:40,271:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_556.pth.tar
2022-11-03 01:32:40,271:INFO: 
===> EPOCH: 557 (P4)
2022-11-03 01:32:40,272:INFO: - Computing loss (training)
2022-11-03 01:32:41,392:INFO: Batch:  0/31	Total Loss 20.7742 (20.7742)
2022-11-03 01:32:41,902:INFO: Batch:  1/31	Total Loss 23.9426 (22.3447)
2022-11-03 01:32:42,411:INFO: Batch:  2/31	Total Loss 21.9783 (22.2312)
2022-11-03 01:32:42,916:INFO: Batch:  3/31	Total Loss 16.4489 (20.7378)
2022-11-03 01:32:43,420:INFO: Batch:  4/31	Total Loss 16.2818 (19.8393)
2022-11-03 01:32:43,917:INFO: Batch:  5/31	Total Loss 23.0026 (20.3628)
2022-11-03 01:32:44,412:INFO: Batch:  6/31	Total Loss 17.4945 (19.9219)
2022-11-03 01:32:44,906:INFO: Batch:  7/31	Total Loss 18.5899 (19.7546)
2022-11-03 01:32:45,403:INFO: Batch:  8/31	Total Loss 18.3594 (19.5952)
2022-11-03 01:32:45,900:INFO: Batch:  9/31	Total Loss 27.3386 (20.3708)
2022-11-03 01:32:46,398:INFO: Batch: 10/31	Total Loss 20.0633 (20.3418)
2022-11-03 01:32:46,894:INFO: Batch: 11/31	Total Loss 19.8852 (20.3006)
2022-11-03 01:32:47,392:INFO: Batch: 12/31	Total Loss 18.6297 (20.1846)
2022-11-03 01:32:47,892:INFO: Batch: 13/31	Total Loss 19.3260 (20.1266)
2022-11-03 01:32:48,467:INFO: Batch: 14/31	Total Loss 17.2951 (19.9383)
2022-11-03 01:32:48,968:INFO: Batch: 15/31	Total Loss 15.4668 (19.6474)
2022-11-03 01:32:49,468:INFO: Batch: 16/31	Total Loss 15.0369 (19.3543)
2022-11-03 01:32:49,967:INFO: Batch: 17/31	Total Loss 15.7719 (19.1716)
2022-11-03 01:32:50,471:INFO: Batch: 18/31	Total Loss 13.2021 (18.8179)
2022-11-03 01:32:50,974:INFO: Batch: 19/31	Total Loss 24.7468 (19.0858)
2022-11-03 01:32:51,477:INFO: Batch: 20/31	Total Loss 17.7912 (19.0228)
2022-11-03 01:32:51,976:INFO: Batch: 21/31	Total Loss 18.1715 (18.9840)
2022-11-03 01:32:52,474:INFO: Batch: 22/31	Total Loss 16.6956 (18.8902)
2022-11-03 01:32:52,975:INFO: Batch: 23/31	Total Loss 15.4837 (18.7478)
2022-11-03 01:32:53,475:INFO: Batch: 24/31	Total Loss 13.5430 (18.5258)
2022-11-03 01:32:53,973:INFO: Batch: 25/31	Total Loss 20.4014 (18.5969)
2022-11-03 01:32:54,471:INFO: Batch: 26/31	Total Loss 14.9277 (18.4572)
2022-11-03 01:32:54,969:INFO: Batch: 27/31	Total Loss 14.8692 (18.3320)
2022-11-03 01:32:55,467:INFO: Batch: 28/31	Total Loss 10.3863 (18.0248)
2022-11-03 01:32:55,966:INFO: Batch: 29/31	Total Loss 15.0363 (17.9328)
2022-11-03 01:32:56,358:INFO: Batch: 30/31	Total Loss -38.1303 (17.3956)
2022-11-03 01:32:56,507:INFO: - Computing ADE (validation o)
2022-11-03 01:32:57,203:INFO: 		 ADE on eth                       dataset:	 1.4191434383392334
2022-11-03 01:32:57,203:INFO: Average validation o:	ADE  1.4191	FDE  2.1994
2022-11-03 01:32:57,204:INFO: - Computing ADE (validation)
2022-11-03 01:32:57,514:INFO: 		 ADE on hotel                     dataset:	 1.0030198097229004
2022-11-03 01:32:57,888:INFO: 		 ADE on univ                      dataset:	 0.9629395008087158
2022-11-03 01:32:58,185:INFO: 		 ADE on zara1                     dataset:	 0.9631006717681885
2022-11-03 01:32:58,668:INFO: 		 ADE on zara2                     dataset:	 0.6926841139793396
2022-11-03 01:32:58,669:INFO: Average validation:	ADE  0.8660	FDE  1.4830
2022-11-03 01:32:58,669:INFO: - Computing ADE (training)
2022-11-03 01:32:59,246:INFO: 		 ADE on hotel                     dataset:	 1.3207533359527588
2022-11-03 01:33:00,287:INFO: 		 ADE on univ                      dataset:	 0.8944705128669739
2022-11-03 01:33:01,097:INFO: 		 ADE on zara1                     dataset:	 1.071982741355896
2022-11-03 01:33:02,255:INFO: 		 ADE on zara2                     dataset:	 0.7819352149963379
2022-11-03 01:33:02,255:INFO: Average training:	ADE  0.8938	FDE  1.5306
2022-11-03 01:33:02,267:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_557.pth.tar
2022-11-03 01:33:02,267:INFO: 
===> EPOCH: 558 (P4)
2022-11-03 01:33:02,267:INFO: - Computing loss (training)
2022-11-03 01:33:03,371:INFO: Batch:  0/31	Total Loss 10.6346 (10.6346)
2022-11-03 01:33:03,863:INFO: Batch:  1/31	Total Loss 13.2022 (11.9779)
2022-11-03 01:33:04,355:INFO: Batch:  2/31	Total Loss 14.6560 (12.8569)
2022-11-03 01:33:04,845:INFO: Batch:  3/31	Total Loss 16.8178 (13.8325)
2022-11-03 01:33:05,333:INFO: Batch:  4/31	Total Loss 17.3825 (14.4703)
2022-11-03 01:33:05,824:INFO: Batch:  5/31	Total Loss 16.1739 (14.7636)
2022-11-03 01:33:06,315:INFO: Batch:  6/31	Total Loss 17.6309 (15.1848)
2022-11-03 01:33:06,806:INFO: Batch:  7/31	Total Loss 16.3154 (15.3324)
2022-11-03 01:33:07,295:INFO: Batch:  8/31	Total Loss 14.5885 (15.2457)
2022-11-03 01:33:07,784:INFO: Batch:  9/31	Total Loss 11.4761 (14.8300)
2022-11-03 01:33:08,272:INFO: Batch: 10/31	Total Loss 12.4029 (14.6096)
2022-11-03 01:33:08,761:INFO: Batch: 11/31	Total Loss 13.3749 (14.5041)
2022-11-03 01:33:09,255:INFO: Batch: 12/31	Total Loss 19.3110 (14.8838)
2022-11-03 01:33:09,749:INFO: Batch: 13/31	Total Loss 13.1219 (14.7600)
2022-11-03 01:33:10,243:INFO: Batch: 14/31	Total Loss 9.3136 (14.3496)
2022-11-03 01:33:10,740:INFO: Batch: 15/31	Total Loss 12.5830 (14.2512)
2022-11-03 01:33:11,233:INFO: Batch: 16/31	Total Loss 18.7184 (14.4883)
2022-11-03 01:33:11,725:INFO: Batch: 17/31	Total Loss 14.4397 (14.4858)
2022-11-03 01:33:12,218:INFO: Batch: 18/31	Total Loss 10.4448 (14.2490)
2022-11-03 01:33:12,710:INFO: Batch: 19/31	Total Loss 14.6572 (14.2696)
2022-11-03 01:33:13,201:INFO: Batch: 20/31	Total Loss 11.6733 (14.1481)
2022-11-03 01:33:13,693:INFO: Batch: 21/31	Total Loss 15.2957 (14.1996)
2022-11-03 01:33:14,182:INFO: Batch: 22/31	Total Loss 13.9136 (14.1878)
2022-11-03 01:33:14,673:INFO: Batch: 23/31	Total Loss 12.9963 (14.1416)
2022-11-03 01:33:15,168:INFO: Batch: 24/31	Total Loss 13.4683 (14.1157)
2022-11-03 01:33:15,660:INFO: Batch: 25/31	Total Loss 15.9027 (14.1772)
2022-11-03 01:33:16,153:INFO: Batch: 26/31	Total Loss 5.3440 (13.7948)
2022-11-03 01:33:16,646:INFO: Batch: 27/31	Total Loss 13.0136 (13.7619)
2022-11-03 01:33:17,136:INFO: Batch: 28/31	Total Loss 11.7155 (13.6912)
2022-11-03 01:33:17,628:INFO: Batch: 29/31	Total Loss 13.4680 (13.6838)
2022-11-03 01:33:18,016:INFO: Batch: 30/31	Total Loss -40.1581 (13.1426)
2022-11-03 01:33:18,165:INFO: - Computing ADE (validation o)
2022-11-03 01:33:18,856:INFO: 		 ADE on eth                       dataset:	 1.3635458946228027
2022-11-03 01:33:18,856:INFO: Average validation o:	ADE  1.3635	FDE  2.1301
2022-11-03 01:33:18,857:INFO: - Computing ADE (validation)
2022-11-03 01:33:19,158:INFO: 		 ADE on hotel                     dataset:	 0.9848468899726868
2022-11-03 01:33:19,539:INFO: 		 ADE on univ                      dataset:	 0.9478432536125183
2022-11-03 01:33:19,834:INFO: 		 ADE on zara1                     dataset:	 0.9526016712188721
2022-11-03 01:33:20,314:INFO: 		 ADE on zara2                     dataset:	 0.6687714457511902
2022-11-03 01:33:20,314:INFO: Average validation:	ADE  0.8478	FDE  1.4559
2022-11-03 01:33:20,315:INFO: - Computing ADE (training)
2022-11-03 01:33:20,864:INFO: 		 ADE on hotel                     dataset:	 1.3061286211013794
2022-11-03 01:33:21,912:INFO: 		 ADE on univ                      dataset:	 0.8811143636703491
2022-11-03 01:33:22,697:INFO: 		 ADE on zara1                     dataset:	 1.0424339771270752
2022-11-03 01:33:23,931:INFO: 		 ADE on zara2                     dataset:	 0.7556793093681335
2022-11-03 01:33:23,932:INFO: Average training:	ADE  0.8767	FDE  1.5064
2022-11-03 01:33:23,943:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_558.pth.tar
2022-11-03 01:33:23,944:INFO: 
===> EPOCH: 559 (P4)
2022-11-03 01:33:23,944:INFO: - Computing loss (training)
2022-11-03 01:33:25,043:INFO: Batch:  0/31	Total Loss 13.7098 (13.7098)
2022-11-03 01:33:25,546:INFO: Batch:  1/31	Total Loss 9.9610 (11.7301)
2022-11-03 01:33:26,040:INFO: Batch:  2/31	Total Loss 2.8204 (8.3897)
2022-11-03 01:33:26,529:INFO: Batch:  3/31	Total Loss 12.9926 (9.4857)
2022-11-03 01:33:27,018:INFO: Batch:  4/31	Total Loss 9.3547 (9.4592)
2022-11-03 01:33:27,514:INFO: Batch:  5/31	Total Loss 9.8960 (9.5197)
2022-11-03 01:33:28,005:INFO: Batch:  6/31	Total Loss 17.0844 (10.5699)
2022-11-03 01:33:28,498:INFO: Batch:  7/31	Total Loss 9.3934 (10.4185)
2022-11-03 01:33:28,989:INFO: Batch:  8/31	Total Loss 26.9605 (12.0479)
2022-11-03 01:33:29,482:INFO: Batch:  9/31	Total Loss 4.3712 (11.2021)
2022-11-03 01:33:29,974:INFO: Batch: 10/31	Total Loss 7.3137 (10.8652)
2022-11-03 01:33:30,467:INFO: Batch: 11/31	Total Loss 16.1453 (11.2651)
2022-11-03 01:33:30,964:INFO: Batch: 12/31	Total Loss 7.2865 (10.9419)
2022-11-03 01:33:31,459:INFO: Batch: 13/31	Total Loss 16.1768 (11.2906)
2022-11-03 01:33:31,953:INFO: Batch: 14/31	Total Loss -0.2210 (10.4289)
2022-11-03 01:33:32,447:INFO: Batch: 15/31	Total Loss 10.8463 (10.4572)
2022-11-03 01:33:32,942:INFO: Batch: 16/31	Total Loss 9.0275 (10.3775)
2022-11-03 01:33:33,434:INFO: Batch: 17/31	Total Loss 13.5576 (10.5497)
2022-11-03 01:33:33,927:INFO: Batch: 18/31	Total Loss 18.4426 (10.8949)
2022-11-03 01:33:34,421:INFO: Batch: 19/31	Total Loss 11.5293 (10.9238)
2022-11-03 01:33:34,914:INFO: Batch: 20/31	Total Loss 10.9553 (10.9252)
2022-11-03 01:33:35,406:INFO: Batch: 21/31	Total Loss 6.4086 (10.7174)
2022-11-03 01:33:35,899:INFO: Batch: 22/31	Total Loss 7.0589 (10.5547)
2022-11-03 01:33:36,391:INFO: Batch: 23/31	Total Loss 16.2748 (10.7687)
2022-11-03 01:33:36,883:INFO: Batch: 24/31	Total Loss 16.4632 (10.9876)
2022-11-03 01:33:37,375:INFO: Batch: 25/31	Total Loss 13.3644 (11.0805)
2022-11-03 01:33:37,870:INFO: Batch: 26/31	Total Loss 6.7399 (10.9355)
2022-11-03 01:33:38,362:INFO: Batch: 27/31	Total Loss 7.1876 (10.8016)
2022-11-03 01:33:38,854:INFO: Batch: 28/31	Total Loss 8.7182 (10.7337)
2022-11-03 01:33:39,345:INFO: Batch: 29/31	Total Loss 11.6288 (10.7633)
2022-11-03 01:33:39,733:INFO: Batch: 30/31	Total Loss -43.9599 (10.2056)
2022-11-03 01:33:39,877:INFO: - Computing ADE (validation o)
2022-11-03 01:33:40,589:INFO: 		 ADE on eth                       dataset:	 1.32650887966156
2022-11-03 01:33:40,589:INFO: Average validation o:	ADE  1.3265	FDE  2.0685
2022-11-03 01:33:40,590:INFO: - Computing ADE (validation)
2022-11-03 01:33:40,902:INFO: 		 ADE on hotel                     dataset:	 0.9752305150032043
2022-11-03 01:33:41,262:INFO: 		 ADE on univ                      dataset:	 0.9355524182319641
2022-11-03 01:33:41,547:INFO: 		 ADE on zara1                     dataset:	 0.8703835010528564
2022-11-03 01:33:42,016:INFO: 		 ADE on zara2                     dataset:	 0.6349763870239258
2022-11-03 01:33:42,016:INFO: Average validation:	ADE  0.8237	FDE  1.4174
2022-11-03 01:33:42,017:INFO: - Computing ADE (training)
2022-11-03 01:33:42,599:INFO: 		 ADE on hotel                     dataset:	 1.2968471050262451
2022-11-03 01:33:43,650:INFO: 		 ADE on univ                      dataset:	 0.862078845500946
2022-11-03 01:33:44,390:INFO: 		 ADE on zara1                     dataset:	 0.9956283569335938
2022-11-03 01:33:45,565:INFO: 		 ADE on zara2                     dataset:	 0.7231382131576538
2022-11-03 01:33:45,565:INFO: Average training:	ADE  0.8535	FDE  1.4670
2022-11-03 01:33:45,576:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_559.pth.tar
2022-11-03 01:33:45,576:INFO: 
===> EPOCH: 560 (P4)
2022-11-03 01:33:45,577:INFO: - Computing loss (training)
2022-11-03 01:33:46,686:INFO: Batch:  0/31	Total Loss 3.8271 (3.8271)
2022-11-03 01:33:47,178:INFO: Batch:  1/31	Total Loss 1.7315 (2.8196)
2022-11-03 01:33:47,670:INFO: Batch:  2/31	Total Loss 7.4601 (4.3023)
2022-11-03 01:33:48,235:INFO: Batch:  3/31	Total Loss 2.4183 (3.8444)
2022-11-03 01:33:48,724:INFO: Batch:  4/31	Total Loss 11.5311 (5.3330)
2022-11-03 01:33:49,218:INFO: Batch:  5/31	Total Loss 11.0248 (6.2827)
2022-11-03 01:33:49,710:INFO: Batch:  6/31	Total Loss 11.2329 (7.0005)
2022-11-03 01:33:50,204:INFO: Batch:  7/31	Total Loss 3.5480 (6.5534)
2022-11-03 01:33:50,695:INFO: Batch:  8/31	Total Loss 6.9053 (6.5905)
2022-11-03 01:33:51,184:INFO: Batch:  9/31	Total Loss 5.7051 (6.5059)
2022-11-03 01:33:51,673:INFO: Batch: 10/31	Total Loss 5.9616 (6.4647)
2022-11-03 01:33:52,163:INFO: Batch: 11/31	Total Loss 7.5266 (6.5449)
2022-11-03 01:33:52,664:INFO: Batch: 12/31	Total Loss 9.3751 (6.7489)
2022-11-03 01:33:53,157:INFO: Batch: 13/31	Total Loss 5.0343 (6.6211)
2022-11-03 01:33:53,651:INFO: Batch: 14/31	Total Loss 5.4417 (6.5452)
2022-11-03 01:33:54,143:INFO: Batch: 15/31	Total Loss 3.8821 (6.3973)
2022-11-03 01:33:54,636:INFO: Batch: 16/31	Total Loss 3.0114 (6.1946)
2022-11-03 01:33:55,131:INFO: Batch: 17/31	Total Loss 3.4722 (6.0409)
2022-11-03 01:33:55,623:INFO: Batch: 18/31	Total Loss 7.1863 (6.0951)
2022-11-03 01:33:56,114:INFO: Batch: 19/31	Total Loss 8.2912 (6.2076)
2022-11-03 01:33:56,606:INFO: Batch: 20/31	Total Loss 5.5408 (6.1751)
2022-11-03 01:33:57,098:INFO: Batch: 21/31	Total Loss 5.5665 (6.1479)
2022-11-03 01:33:57,588:INFO: Batch: 22/31	Total Loss 10.6459 (6.3229)
2022-11-03 01:33:58,079:INFO: Batch: 23/31	Total Loss -5.9222 (5.7864)
2022-11-03 01:33:58,572:INFO: Batch: 24/31	Total Loss 2.3798 (5.6519)
2022-11-03 01:33:59,064:INFO: Batch: 25/31	Total Loss 8.0009 (5.7387)
2022-11-03 01:33:59,555:INFO: Batch: 26/31	Total Loss 4.8861 (5.7053)
2022-11-03 01:34:00,048:INFO: Batch: 27/31	Total Loss 8.9300 (5.8229)
2022-11-03 01:34:00,539:INFO: Batch: 28/31	Total Loss 10.8183 (5.9786)
2022-11-03 01:34:01,029:INFO: Batch: 29/31	Total Loss 3.0831 (5.8780)
2022-11-03 01:34:01,418:INFO: Batch: 30/31	Total Loss -42.9468 (5.4148)
2022-11-03 01:34:01,569:INFO: - Computing ADE (validation o)
2022-11-03 01:34:02,272:INFO: 		 ADE on eth                       dataset:	 1.3048094511032104
2022-11-03 01:34:02,272:INFO: Average validation o:	ADE  1.3048	FDE  2.0614
2022-11-03 01:34:02,273:INFO: - Computing ADE (validation)
2022-11-03 01:34:02,583:INFO: 		 ADE on hotel                     dataset:	 0.9769192934036255
2022-11-03 01:34:02,960:INFO: 		 ADE on univ                      dataset:	 0.931449830532074
2022-11-03 01:34:03,248:INFO: 		 ADE on zara1                     dataset:	 0.9028725624084473
2022-11-03 01:34:03,725:INFO: 		 ADE on zara2                     dataset:	 0.634301483631134
2022-11-03 01:34:03,725:INFO: Average validation:	ADE  0.8233	FDE  1.4273
2022-11-03 01:34:03,726:INFO: - Computing ADE (training)
2022-11-03 01:34:04,291:INFO: 		 ADE on hotel                     dataset:	 1.2927958965301514
2022-11-03 01:34:05,419:INFO: 		 ADE on univ                      dataset:	 0.862882137298584
2022-11-03 01:34:06,150:INFO: 		 ADE on zara1                     dataset:	 0.9850502014160156
2022-11-03 01:34:07,316:INFO: 		 ADE on zara2                     dataset:	 0.7167558670043945
2022-11-03 01:34:07,317:INFO: Average training:	ADE  0.8519	FDE  1.4760
2022-11-03 01:34:07,328:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_560.pth.tar
2022-11-03 01:34:07,328:INFO: 
===> EPOCH: 561 (P4)
2022-11-03 01:34:07,328:INFO: - Computing loss (training)
2022-11-03 01:34:08,453:INFO: Batch:  0/31	Total Loss 12.9762 (12.9762)
2022-11-03 01:34:08,953:INFO: Batch:  1/31	Total Loss 4.4964 (8.9376)
2022-11-03 01:34:09,456:INFO: Batch:  2/31	Total Loss 4.7783 (7.5238)
2022-11-03 01:34:09,962:INFO: Batch:  3/31	Total Loss 2.1181 (6.1219)
2022-11-03 01:34:10,465:INFO: Batch:  4/31	Total Loss 5.3992 (5.9716)
2022-11-03 01:34:10,969:INFO: Batch:  5/31	Total Loss 7.4490 (6.2168)
2022-11-03 01:34:11,472:INFO: Batch:  6/31	Total Loss 4.0537 (5.8957)
2022-11-03 01:34:11,968:INFO: Batch:  7/31	Total Loss 0.3171 (5.1946)
2022-11-03 01:34:12,465:INFO: Batch:  8/31	Total Loss 12.9587 (5.9549)
2022-11-03 01:34:12,961:INFO: Batch:  9/31	Total Loss 5.9739 (5.9567)
2022-11-03 01:34:13,460:INFO: Batch: 10/31	Total Loss 0.8567 (5.4829)
2022-11-03 01:34:13,959:INFO: Batch: 11/31	Total Loss -2.1844 (4.8667)
2022-11-03 01:34:14,462:INFO: Batch: 12/31	Total Loss 1.5444 (4.6234)
2022-11-03 01:34:14,966:INFO: Batch: 13/31	Total Loss 0.2471 (4.3259)
2022-11-03 01:34:15,471:INFO: Batch: 14/31	Total Loss -2.7906 (3.8468)
2022-11-03 01:34:15,974:INFO: Batch: 15/31	Total Loss 3.9164 (3.8512)
2022-11-03 01:34:16,479:INFO: Batch: 16/31	Total Loss 0.5147 (3.6701)
2022-11-03 01:34:16,981:INFO: Batch: 17/31	Total Loss 0.2969 (3.4731)
2022-11-03 01:34:17,483:INFO: Batch: 18/31	Total Loss 0.0911 (3.2947)
2022-11-03 01:34:17,984:INFO: Batch: 19/31	Total Loss 11.4323 (3.6740)
2022-11-03 01:34:18,493:INFO: Batch: 20/31	Total Loss -4.5855 (3.2465)
2022-11-03 01:34:18,994:INFO: Batch: 21/31	Total Loss 1.3451 (3.1593)
2022-11-03 01:34:19,503:INFO: Batch: 22/31	Total Loss -4.0532 (2.8132)
2022-11-03 01:34:20,008:INFO: Batch: 23/31	Total Loss -3.8575 (2.5160)
2022-11-03 01:34:20,511:INFO: Batch: 24/31	Total Loss 0.9734 (2.4510)
2022-11-03 01:34:21,013:INFO: Batch: 25/31	Total Loss 4.2644 (2.5195)
2022-11-03 01:34:21,515:INFO: Batch: 26/31	Total Loss -1.8129 (2.3520)
2022-11-03 01:34:22,018:INFO: Batch: 27/31	Total Loss -3.3599 (2.1744)
2022-11-03 01:34:22,520:INFO: Batch: 28/31	Total Loss 1.8289 (2.1636)
2022-11-03 01:34:23,023:INFO: Batch: 29/31	Total Loss 10.7040 (2.4222)
2022-11-03 01:34:23,418:INFO: Batch: 30/31	Total Loss -44.9461 (1.9651)
2022-11-03 01:34:23,575:INFO: - Computing ADE (validation o)
2022-11-03 01:34:24,262:INFO: 		 ADE on eth                       dataset:	 1.2550104856491089
2022-11-03 01:34:24,262:INFO: Average validation o:	ADE  1.2550	FDE  1.9926
2022-11-03 01:34:24,263:INFO: - Computing ADE (validation)
2022-11-03 01:34:24,555:INFO: 		 ADE on hotel                     dataset:	 0.9681594371795654
2022-11-03 01:34:24,938:INFO: 		 ADE on univ                      dataset:	 0.9095240235328674
2022-11-03 01:34:25,214:INFO: 		 ADE on zara1                     dataset:	 0.8152625560760498
2022-11-03 01:34:25,682:INFO: 		 ADE on zara2                     dataset:	 0.5958880186080933
2022-11-03 01:34:25,682:INFO: Average validation:	ADE  0.7922	FDE  1.3742
2022-11-03 01:34:25,683:INFO: - Computing ADE (training)
2022-11-03 01:34:26,264:INFO: 		 ADE on hotel                     dataset:	 1.2844306230545044
2022-11-03 01:34:27,318:INFO: 		 ADE on univ                      dataset:	 0.8419736623764038
2022-11-03 01:34:28,066:INFO: 		 ADE on zara1                     dataset:	 0.9240800738334656
2022-11-03 01:34:29,309:INFO: 		 ADE on zara2                     dataset:	 0.6715234518051147
2022-11-03 01:34:29,310:INFO: Average training:	ADE  0.8239	FDE  1.4299
2022-11-03 01:34:29,321:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_561.pth.tar
2022-11-03 01:34:29,321:INFO: 
===> EPOCH: 562 (P4)
2022-11-03 01:34:29,322:INFO: - Computing loss (training)
2022-11-03 01:34:30,455:INFO: Batch:  0/31	Total Loss 7.9558 (7.9558)
2022-11-03 01:34:30,951:INFO: Batch:  1/31	Total Loss -3.5498 (1.8265)
2022-11-03 01:34:31,453:INFO: Batch:  2/31	Total Loss 4.3372 (2.6697)
2022-11-03 01:34:31,943:INFO: Batch:  3/31	Total Loss 1.2701 (2.2928)
2022-11-03 01:34:32,435:INFO: Batch:  4/31	Total Loss -2.5555 (1.3065)
2022-11-03 01:34:32,928:INFO: Batch:  5/31	Total Loss 2.1157 (1.4487)
2022-11-03 01:34:33,419:INFO: Batch:  6/31	Total Loss 11.1614 (2.6410)
2022-11-03 01:34:33,908:INFO: Batch:  7/31	Total Loss 4.3382 (2.8512)
2022-11-03 01:34:34,400:INFO: Batch:  8/31	Total Loss -9.4907 (1.3443)
2022-11-03 01:34:34,892:INFO: Batch:  9/31	Total Loss 1.1775 (1.3268)
2022-11-03 01:34:35,384:INFO: Batch: 10/31	Total Loss 0.2041 (1.2190)
2022-11-03 01:34:35,872:INFO: Batch: 11/31	Total Loss 3.3050 (1.3911)
2022-11-03 01:34:36,365:INFO: Batch: 12/31	Total Loss -6.5165 (0.7282)
2022-11-03 01:34:36,859:INFO: Batch: 13/31	Total Loss -3.3235 (0.4203)
2022-11-03 01:34:37,353:INFO: Batch: 14/31	Total Loss -7.7810 (-0.1501)
2022-11-03 01:34:37,848:INFO: Batch: 15/31	Total Loss -10.9863 (-0.9283)
2022-11-03 01:34:38,342:INFO: Batch: 16/31	Total Loss -1.2952 (-0.9498)
2022-11-03 01:34:38,836:INFO: Batch: 17/31	Total Loss 5.0893 (-0.6429)
2022-11-03 01:34:39,333:INFO: Batch: 18/31	Total Loss -3.3871 (-0.7729)
2022-11-03 01:34:39,826:INFO: Batch: 19/31	Total Loss -2.0771 (-0.8365)
2022-11-03 01:34:40,320:INFO: Batch: 20/31	Total Loss 1.8056 (-0.7103)
2022-11-03 01:34:40,890:INFO: Batch: 21/31	Total Loss 3.0358 (-0.5366)
2022-11-03 01:34:41,384:INFO: Batch: 22/31	Total Loss -13.7749 (-1.1685)
2022-11-03 01:34:41,876:INFO: Batch: 23/31	Total Loss 0.2407 (-1.1144)
2022-11-03 01:34:42,368:INFO: Batch: 24/31	Total Loss -4.3188 (-1.2425)
2022-11-03 01:34:42,860:INFO: Batch: 25/31	Total Loss 3.7360 (-1.0309)
2022-11-03 01:34:43,353:INFO: Batch: 26/31	Total Loss -7.0230 (-1.2458)
2022-11-03 01:34:43,845:INFO: Batch: 27/31	Total Loss 4.4069 (-1.0656)
2022-11-03 01:34:44,339:INFO: Batch: 28/31	Total Loss -11.9577 (-1.4425)
2022-11-03 01:34:44,833:INFO: Batch: 29/31	Total Loss -2.9360 (-1.4937)
2022-11-03 01:34:45,223:INFO: Batch: 30/31	Total Loss -47.2758 (-1.9970)
2022-11-03 01:34:45,380:INFO: - Computing ADE (validation o)
2022-11-03 01:34:46,051:INFO: 		 ADE on eth                       dataset:	 1.238094687461853
2022-11-03 01:34:46,052:INFO: Average validation o:	ADE  1.2381	FDE  2.0004
2022-11-03 01:34:46,052:INFO: - Computing ADE (validation)
2022-11-03 01:34:46,359:INFO: 		 ADE on hotel                     dataset:	 0.9643751382827759
2022-11-03 01:34:46,733:INFO: 		 ADE on univ                      dataset:	 0.9058658480644226
2022-11-03 01:34:47,015:INFO: 		 ADE on zara1                     dataset:	 0.8239883184432983
2022-11-03 01:34:47,494:INFO: 		 ADE on zara2                     dataset:	 0.5984182953834534
2022-11-03 01:34:47,495:INFO: Average validation:	ADE  0.7915	FDE  1.3891
2022-11-03 01:34:47,495:INFO: - Computing ADE (training)
2022-11-03 01:34:48,077:INFO: 		 ADE on hotel                     dataset:	 1.2834972143173218
2022-11-03 01:34:49,105:INFO: 		 ADE on univ                      dataset:	 0.839959979057312
2022-11-03 01:34:49,860:INFO: 		 ADE on zara1                     dataset:	 0.922160804271698
2022-11-03 01:34:51,062:INFO: 		 ADE on zara2                     dataset:	 0.6707134246826172
2022-11-03 01:34:51,062:INFO: Average training:	ADE  0.8221	FDE  1.4435
2022-11-03 01:34:51,073:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_562.pth.tar
2022-11-03 01:34:51,073:INFO: 
===> EPOCH: 563 (P4)
2022-11-03 01:34:51,074:INFO: - Computing loss (training)
2022-11-03 01:34:52,188:INFO: Batch:  0/31	Total Loss -6.7139 (-6.7139)
2022-11-03 01:34:52,689:INFO: Batch:  1/31	Total Loss -4.3393 (-5.5675)
2022-11-03 01:34:53,181:INFO: Batch:  2/31	Total Loss -2.7911 (-4.6186)
2022-11-03 01:34:53,672:INFO: Batch:  3/31	Total Loss -10.3512 (-5.9955)
2022-11-03 01:34:54,164:INFO: Batch:  4/31	Total Loss -7.5395 (-6.2943)
2022-11-03 01:34:54,657:INFO: Batch:  5/31	Total Loss 3.8528 (-4.6606)
2022-11-03 01:34:55,148:INFO: Batch:  6/31	Total Loss 4.0343 (-3.4625)
2022-11-03 01:34:55,637:INFO: Batch:  7/31	Total Loss -1.0763 (-3.1638)
2022-11-03 01:34:56,125:INFO: Batch:  8/31	Total Loss -16.9130 (-4.8571)
2022-11-03 01:34:56,615:INFO: Batch:  9/31	Total Loss -8.3593 (-5.1919)
2022-11-03 01:34:57,104:INFO: Batch: 10/31	Total Loss -1.1012 (-4.8230)
2022-11-03 01:34:57,595:INFO: Batch: 11/31	Total Loss -4.9153 (-4.8303)
2022-11-03 01:34:58,087:INFO: Batch: 12/31	Total Loss -5.3210 (-4.8681)
2022-11-03 01:34:58,581:INFO: Batch: 13/31	Total Loss -4.5578 (-4.8455)
2022-11-03 01:34:59,074:INFO: Batch: 14/31	Total Loss -3.6858 (-4.7709)
2022-11-03 01:34:59,568:INFO: Batch: 15/31	Total Loss -7.3365 (-4.9326)
2022-11-03 01:35:00,063:INFO: Batch: 16/31	Total Loss -7.9089 (-5.1194)
2022-11-03 01:35:00,560:INFO: Batch: 17/31	Total Loss -9.6701 (-5.4033)
2022-11-03 01:35:01,054:INFO: Batch: 18/31	Total Loss -3.5193 (-5.3076)
2022-11-03 01:35:01,548:INFO: Batch: 19/31	Total Loss -5.5454 (-5.3191)
2022-11-03 01:35:02,041:INFO: Batch: 20/31	Total Loss -4.3543 (-5.2707)
2022-11-03 01:35:02,535:INFO: Batch: 21/31	Total Loss -2.1915 (-5.1483)
2022-11-03 01:35:03,026:INFO: Batch: 22/31	Total Loss -4.7700 (-5.1326)
2022-11-03 01:35:03,518:INFO: Batch: 23/31	Total Loss -12.7931 (-5.4912)
2022-11-03 01:35:04,009:INFO: Batch: 24/31	Total Loss -6.3519 (-5.5293)
2022-11-03 01:35:04,502:INFO: Batch: 25/31	Total Loss -3.9215 (-5.4685)
2022-11-03 01:35:04,994:INFO: Batch: 26/31	Total Loss -3.1259 (-5.3841)
2022-11-03 01:35:05,485:INFO: Batch: 27/31	Total Loss -5.8201 (-5.3986)
2022-11-03 01:35:05,977:INFO: Batch: 28/31	Total Loss 1.9984 (-5.1766)
2022-11-03 01:35:06,470:INFO: Batch: 29/31	Total Loss -0.7589 (-5.0491)
2022-11-03 01:35:06,858:INFO: Batch: 30/31	Total Loss -46.8704 (-5.4218)
2022-11-03 01:35:07,006:INFO: - Computing ADE (validation o)
2022-11-03 01:35:07,751:INFO: 		 ADE on eth                       dataset:	 1.222009301185608
2022-11-03 01:35:07,752:INFO: Average validation o:	ADE  1.2220	FDE  1.9754
2022-11-03 01:35:07,752:INFO: - Computing ADE (validation)
2022-11-03 01:35:08,066:INFO: 		 ADE on hotel                     dataset:	 0.9645167589187622
2022-11-03 01:35:08,435:INFO: 		 ADE on univ                      dataset:	 0.9039039611816406
2022-11-03 01:35:08,730:INFO: 		 ADE on zara1                     dataset:	 0.7943171262741089
2022-11-03 01:35:09,215:INFO: 		 ADE on zara2                     dataset:	 0.5888757705688477
2022-11-03 01:35:09,216:INFO: Average validation:	ADE  0.7853	FDE  1.3938
2022-11-03 01:35:09,216:INFO: - Computing ADE (training)
2022-11-03 01:35:09,793:INFO: 		 ADE on hotel                     dataset:	 1.278806209564209
2022-11-03 01:35:10,834:INFO: 		 ADE on univ                      dataset:	 0.8345553278923035
2022-11-03 01:35:11,582:INFO: 		 ADE on zara1                     dataset:	 0.9178745150566101
2022-11-03 01:35:12,793:INFO: 		 ADE on zara2                     dataset:	 0.6683980822563171
2022-11-03 01:35:12,793:INFO: Average training:	ADE  0.8174	FDE  1.4487
2022-11-03 01:35:12,804:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_563.pth.tar
2022-11-03 01:35:12,805:INFO: 
===> EPOCH: 564 (P4)
2022-11-03 01:35:12,805:INFO: - Computing loss (training)
2022-11-03 01:35:13,936:INFO: Batch:  0/31	Total Loss -9.5393 (-9.5393)
2022-11-03 01:35:14,436:INFO: Batch:  1/31	Total Loss -10.0141 (-9.7740)
2022-11-03 01:35:14,926:INFO: Batch:  2/31	Total Loss -7.0731 (-8.9262)
2022-11-03 01:35:15,417:INFO: Batch:  3/31	Total Loss -7.9401 (-8.6817)
2022-11-03 01:35:15,906:INFO: Batch:  4/31	Total Loss -18.3125 (-10.5951)
2022-11-03 01:35:16,402:INFO: Batch:  5/31	Total Loss -9.8199 (-10.4810)
2022-11-03 01:35:16,891:INFO: Batch:  6/31	Total Loss 2.6791 (-8.7451)
2022-11-03 01:35:17,381:INFO: Batch:  7/31	Total Loss -3.4767 (-8.1673)
2022-11-03 01:35:17,871:INFO: Batch:  8/31	Total Loss -5.0703 (-7.8628)
2022-11-03 01:35:18,360:INFO: Batch:  9/31	Total Loss -3.3624 (-7.4050)
2022-11-03 01:35:18,850:INFO: Batch: 10/31	Total Loss -13.3350 (-7.9668)
2022-11-03 01:35:19,341:INFO: Batch: 11/31	Total Loss -7.8520 (-7.9573)
2022-11-03 01:35:19,839:INFO: Batch: 12/31	Total Loss -8.0007 (-7.9608)
2022-11-03 01:35:20,333:INFO: Batch: 13/31	Total Loss -3.7727 (-7.6731)
2022-11-03 01:35:20,828:INFO: Batch: 14/31	Total Loss -10.2684 (-7.8363)
2022-11-03 01:35:21,322:INFO: Batch: 15/31	Total Loss -8.6312 (-7.8819)
2022-11-03 01:35:21,817:INFO: Batch: 16/31	Total Loss -14.7010 (-8.3116)
2022-11-03 01:35:22,311:INFO: Batch: 17/31	Total Loss -3.2277 (-8.0586)
2022-11-03 01:35:22,806:INFO: Batch: 18/31	Total Loss -9.5315 (-8.1382)
2022-11-03 01:35:23,300:INFO: Batch: 19/31	Total Loss -11.8410 (-8.3092)
2022-11-03 01:35:23,792:INFO: Batch: 20/31	Total Loss 0.4472 (-7.9170)
2022-11-03 01:35:24,287:INFO: Batch: 21/31	Total Loss -17.2634 (-8.3648)
2022-11-03 01:35:24,780:INFO: Batch: 22/31	Total Loss -11.5909 (-8.5072)
2022-11-03 01:35:25,273:INFO: Batch: 23/31	Total Loss -1.8905 (-8.2511)
2022-11-03 01:35:25,764:INFO: Batch: 24/31	Total Loss -19.8243 (-8.7386)
2022-11-03 01:35:26,257:INFO: Batch: 25/31	Total Loss -4.6859 (-8.5857)
2022-11-03 01:35:26,749:INFO: Batch: 26/31	Total Loss 3.1243 (-8.1986)
2022-11-03 01:35:27,240:INFO: Batch: 27/31	Total Loss -15.5472 (-8.4699)
2022-11-03 01:35:27,731:INFO: Batch: 28/31	Total Loss -15.3517 (-8.7408)
2022-11-03 01:35:28,225:INFO: Batch: 29/31	Total Loss -13.2725 (-8.9135)
2022-11-03 01:35:28,613:INFO: Batch: 30/31	Total Loss -49.5407 (-9.3193)
2022-11-03 01:35:28,769:INFO: - Computing ADE (validation o)
2022-11-03 01:35:29,464:INFO: 		 ADE on eth                       dataset:	 1.1975129842758179
2022-11-03 01:35:29,465:INFO: Average validation o:	ADE  1.1975	FDE  1.9669
2022-11-03 01:35:29,465:INFO: - Computing ADE (validation)
2022-11-03 01:35:29,772:INFO: 		 ADE on hotel                     dataset:	 0.9822597503662109
2022-11-03 01:35:30,163:INFO: 		 ADE on univ                      dataset:	 0.8982825875282288
2022-11-03 01:35:30,466:INFO: 		 ADE on zara1                     dataset:	 0.7035501599311829
2022-11-03 01:35:30,956:INFO: 		 ADE on zara2                     dataset:	 0.571358323097229
2022-11-03 01:35:30,956:INFO: Average validation:	ADE  0.7716	FDE  1.3946
2022-11-03 01:35:30,957:INFO: - Computing ADE (training)
2022-11-03 01:35:31,556:INFO: 		 ADE on hotel                     dataset:	 1.2919228076934814
2022-11-03 01:35:32,575:INFO: 		 ADE on univ                      dataset:	 0.8264995217323303
2022-11-03 01:35:33,336:INFO: 		 ADE on zara1                     dataset:	 0.8536014556884766
2022-11-03 01:35:34,558:INFO: 		 ADE on zara2                     dataset:	 0.6409273147583008
2022-11-03 01:35:34,558:INFO: Average training:	ADE  0.8024	FDE  1.4449
2022-11-03 01:35:34,570:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_564.pth.tar
2022-11-03 01:35:34,570:INFO: 
===> EPOCH: 565 (P4)
2022-11-03 01:35:34,570:INFO: - Computing loss (training)
2022-11-03 01:35:35,677:INFO: Batch:  0/31	Total Loss -5.5012 (-5.5012)
2022-11-03 01:35:36,177:INFO: Batch:  1/31	Total Loss -8.6314 (-7.0577)
2022-11-03 01:35:36,676:INFO: Batch:  2/31	Total Loss -9.4453 (-7.8813)
2022-11-03 01:35:37,170:INFO: Batch:  3/31	Total Loss -19.4033 (-10.7399)
2022-11-03 01:35:37,670:INFO: Batch:  4/31	Total Loss -13.6448 (-11.2976)
2022-11-03 01:35:38,172:INFO: Batch:  5/31	Total Loss -2.5583 (-10.0188)
2022-11-03 01:35:38,747:INFO: Batch:  6/31	Total Loss -12.0863 (-10.3114)
2022-11-03 01:35:39,243:INFO: Batch:  7/31	Total Loss -8.8036 (-10.1470)
2022-11-03 01:35:39,741:INFO: Batch:  8/31	Total Loss -13.4705 (-10.5457)
2022-11-03 01:35:40,236:INFO: Batch:  9/31	Total Loss -10.5403 (-10.5451)
2022-11-03 01:35:40,734:INFO: Batch: 10/31	Total Loss -7.9910 (-10.2954)
2022-11-03 01:35:41,232:INFO: Batch: 11/31	Total Loss 5.9029 (-9.0789)
2022-11-03 01:35:41,735:INFO: Batch: 12/31	Total Loss -14.7031 (-9.5267)
2022-11-03 01:35:42,237:INFO: Batch: 13/31	Total Loss -13.5162 (-9.8078)
2022-11-03 01:35:42,737:INFO: Batch: 14/31	Total Loss -10.7641 (-9.8744)
2022-11-03 01:35:43,238:INFO: Batch: 15/31	Total Loss -9.5007 (-9.8508)
2022-11-03 01:35:43,739:INFO: Batch: 16/31	Total Loss -8.7658 (-9.7825)
2022-11-03 01:35:44,237:INFO: Batch: 17/31	Total Loss -1.6426 (-9.3193)
2022-11-03 01:35:44,736:INFO: Batch: 18/31	Total Loss -7.0401 (-9.2029)
2022-11-03 01:35:45,235:INFO: Batch: 19/31	Total Loss -11.7332 (-9.3244)
2022-11-03 01:35:45,733:INFO: Batch: 20/31	Total Loss -19.9303 (-9.8463)
2022-11-03 01:35:46,233:INFO: Batch: 21/31	Total Loss -9.7444 (-9.8416)
2022-11-03 01:35:46,732:INFO: Batch: 22/31	Total Loss -9.4181 (-9.8242)
2022-11-03 01:35:47,231:INFO: Batch: 23/31	Total Loss -7.2242 (-9.7184)
2022-11-03 01:35:47,731:INFO: Batch: 24/31	Total Loss -3.0607 (-9.4799)
2022-11-03 01:35:48,231:INFO: Batch: 25/31	Total Loss -12.5341 (-9.5959)
2022-11-03 01:35:48,731:INFO: Batch: 26/31	Total Loss -8.2910 (-9.5483)
2022-11-03 01:35:49,228:INFO: Batch: 27/31	Total Loss -13.2202 (-9.6837)
2022-11-03 01:35:49,727:INFO: Batch: 28/31	Total Loss -8.5021 (-9.6403)
2022-11-03 01:35:50,225:INFO: Batch: 29/31	Total Loss -8.1328 (-9.5919)
2022-11-03 01:35:50,618:INFO: Batch: 30/31	Total Loss -48.3717 (-9.9870)
2022-11-03 01:35:50,784:INFO: - Computing ADE (validation o)
2022-11-03 01:35:51,486:INFO: 		 ADE on eth                       dataset:	 1.1603631973266602
2022-11-03 01:35:51,487:INFO: Average validation o:	ADE  1.1604	FDE  1.9330
2022-11-03 01:35:51,487:INFO: - Computing ADE (validation)
2022-11-03 01:35:51,786:INFO: 		 ADE on hotel                     dataset:	 0.9645246863365173
2022-11-03 01:35:52,159:INFO: 		 ADE on univ                      dataset:	 0.8783404231071472
2022-11-03 01:35:52,451:INFO: 		 ADE on zara1                     dataset:	 0.6740682125091553
2022-11-03 01:35:52,916:INFO: 		 ADE on zara2                     dataset:	 0.5391380786895752
2022-11-03 01:35:52,917:INFO: Average validation:	ADE  0.7468	FDE  1.3510
2022-11-03 01:35:52,917:INFO: - Computing ADE (training)
2022-11-03 01:35:53,499:INFO: 		 ADE on hotel                     dataset:	 1.270541787147522
2022-11-03 01:35:54,566:INFO: 		 ADE on univ                      dataset:	 0.8089290857315063
2022-11-03 01:35:55,327:INFO: 		 ADE on zara1                     dataset:	 0.8167988657951355
2022-11-03 01:35:56,535:INFO: 		 ADE on zara2                     dataset:	 0.6031321287155151
2022-11-03 01:35:56,536:INFO: Average training:	ADE  0.7794	FDE  1.4070
2022-11-03 01:35:56,548:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_565.pth.tar
2022-11-03 01:35:56,548:INFO: 
===> EPOCH: 566 (P4)
2022-11-03 01:35:56,548:INFO: - Computing loss (training)
2022-11-03 01:35:57,690:INFO: Batch:  0/31	Total Loss -9.2407 (-9.2407)
2022-11-03 01:35:58,191:INFO: Batch:  1/31	Total Loss -19.8424 (-14.6799)
2022-11-03 01:35:58,690:INFO: Batch:  2/31	Total Loss -4.4647 (-11.4622)
2022-11-03 01:35:59,187:INFO: Batch:  3/31	Total Loss -2.6050 (-9.1857)
2022-11-03 01:35:59,680:INFO: Batch:  4/31	Total Loss -6.7773 (-8.7038)
2022-11-03 01:36:00,196:INFO: Batch:  5/31	Total Loss -10.7389 (-9.0402)
2022-11-03 01:36:00,694:INFO: Batch:  6/31	Total Loss -17.7044 (-10.4102)
2022-11-03 01:36:01,193:INFO: Batch:  7/31	Total Loss 2.9862 (-8.8904)
2022-11-03 01:36:01,693:INFO: Batch:  8/31	Total Loss -6.2041 (-8.6284)
2022-11-03 01:36:02,192:INFO: Batch:  9/31	Total Loss -17.3684 (-9.5749)
2022-11-03 01:36:02,689:INFO: Batch: 10/31	Total Loss -8.3734 (-9.4765)
2022-11-03 01:36:03,186:INFO: Batch: 11/31	Total Loss 0.3976 (-8.6532)
2022-11-03 01:36:03,686:INFO: Batch: 12/31	Total Loss -12.3425 (-8.9581)
2022-11-03 01:36:04,188:INFO: Batch: 13/31	Total Loss 7.7967 (-7.8435)
2022-11-03 01:36:04,687:INFO: Batch: 14/31	Total Loss -11.4602 (-8.1154)
2022-11-03 01:36:05,187:INFO: Batch: 15/31	Total Loss -15.3740 (-8.5572)
2022-11-03 01:36:05,686:INFO: Batch: 16/31	Total Loss -16.5912 (-9.0331)
2022-11-03 01:36:06,185:INFO: Batch: 17/31	Total Loss -11.8407 (-9.1909)
2022-11-03 01:36:06,685:INFO: Batch: 18/31	Total Loss -13.8313 (-9.4255)
2022-11-03 01:36:07,184:INFO: Batch: 19/31	Total Loss -21.5985 (-10.0498)
2022-11-03 01:36:07,686:INFO: Batch: 20/31	Total Loss -19.6357 (-10.5608)
2022-11-03 01:36:08,186:INFO: Batch: 21/31	Total Loss -13.4453 (-10.7028)
2022-11-03 01:36:08,684:INFO: Batch: 22/31	Total Loss -17.0961 (-10.9781)
2022-11-03 01:36:09,182:INFO: Batch: 23/31	Total Loss -12.5119 (-11.0388)
2022-11-03 01:36:09,681:INFO: Batch: 24/31	Total Loss -13.3588 (-11.1290)
2022-11-03 01:36:10,182:INFO: Batch: 25/31	Total Loss -26.6893 (-11.7527)
2022-11-03 01:36:10,679:INFO: Batch: 26/31	Total Loss -18.6412 (-12.0192)
2022-11-03 01:36:11,188:INFO: Batch: 27/31	Total Loss -15.4668 (-12.1435)
2022-11-03 01:36:11,685:INFO: Batch: 28/31	Total Loss -16.0602 (-12.2630)
2022-11-03 01:36:12,184:INFO: Batch: 29/31	Total Loss -18.3205 (-12.4706)
2022-11-03 01:36:12,577:INFO: Batch: 30/31	Total Loss -50.1084 (-12.8339)
2022-11-03 01:36:12,729:INFO: - Computing ADE (validation o)
2022-11-03 01:36:13,459:INFO: 		 ADE on eth                       dataset:	 1.1190685033798218
2022-11-03 01:36:13,459:INFO: Average validation o:	ADE  1.1191	FDE  1.9334
2022-11-03 01:36:13,460:INFO: - Computing ADE (validation)
2022-11-03 01:36:13,762:INFO: 		 ADE on hotel                     dataset:	 0.9627004861831665
2022-11-03 01:36:14,121:INFO: 		 ADE on univ                      dataset:	 0.8720634579658508
2022-11-03 01:36:14,406:INFO: 		 ADE on zara1                     dataset:	 0.6653226613998413
2022-11-03 01:36:14,869:INFO: 		 ADE on zara2                     dataset:	 0.5228676795959473
2022-11-03 01:36:14,869:INFO: Average validation:	ADE  0.7369	FDE  1.3532
2022-11-03 01:36:14,870:INFO: - Computing ADE (training)
2022-11-03 01:36:15,468:INFO: 		 ADE on hotel                     dataset:	 1.275505781173706
2022-11-03 01:36:16,519:INFO: 		 ADE on univ                      dataset:	 0.805271327495575
2022-11-03 01:36:17,294:INFO: 		 ADE on zara1                     dataset:	 0.7713524103164673
2022-11-03 01:36:18,503:INFO: 		 ADE on zara2                     dataset:	 0.5753006935119629
2022-11-03 01:36:18,504:INFO: Average training:	ADE  0.7684	FDE  1.4057
2022-11-03 01:36:18,515:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_566.pth.tar
2022-11-03 01:36:18,516:INFO: 
===> EPOCH: 567 (P4)
2022-11-03 01:36:18,516:INFO: - Computing loss (training)
2022-11-03 01:36:19,621:INFO: Batch:  0/31	Total Loss -23.2798 (-23.2798)
2022-11-03 01:36:20,122:INFO: Batch:  1/31	Total Loss -22.9256 (-23.1078)
2022-11-03 01:36:20,630:INFO: Batch:  2/31	Total Loss -1.5402 (-16.3443)
2022-11-03 01:36:21,133:INFO: Batch:  3/31	Total Loss -5.4638 (-13.6101)
2022-11-03 01:36:21,634:INFO: Batch:  4/31	Total Loss 4.1162 (-10.4400)
2022-11-03 01:36:22,133:INFO: Batch:  5/31	Total Loss -18.3274 (-11.8449)
2022-11-03 01:36:22,633:INFO: Batch:  6/31	Total Loss -15.2071 (-12.3452)
2022-11-03 01:36:23,127:INFO: Batch:  7/31	Total Loss -16.3233 (-12.8529)
2022-11-03 01:36:23,622:INFO: Batch:  8/31	Total Loss -18.3340 (-13.4339)
2022-11-03 01:36:24,119:INFO: Batch:  9/31	Total Loss -12.8755 (-13.3814)
2022-11-03 01:36:24,618:INFO: Batch: 10/31	Total Loss -23.9648 (-14.4342)
2022-11-03 01:36:25,113:INFO: Batch: 11/31	Total Loss -28.6504 (-15.7327)
2022-11-03 01:36:25,619:INFO: Batch: 12/31	Total Loss -26.6162 (-16.7565)
2022-11-03 01:36:26,118:INFO: Batch: 13/31	Total Loss -20.5069 (-17.0324)
2022-11-03 01:36:26,618:INFO: Batch: 14/31	Total Loss -6.1491 (-16.3590)
2022-11-03 01:36:27,117:INFO: Batch: 15/31	Total Loss -20.4859 (-16.6264)
2022-11-03 01:36:27,617:INFO: Batch: 16/31	Total Loss -12.4097 (-16.3906)
2022-11-03 01:36:28,115:INFO: Batch: 17/31	Total Loss -16.2371 (-16.3822)
2022-11-03 01:36:28,615:INFO: Batch: 18/31	Total Loss -15.4420 (-16.3346)
2022-11-03 01:36:29,113:INFO: Batch: 19/31	Total Loss -17.4592 (-16.3925)
2022-11-03 01:36:29,610:INFO: Batch: 20/31	Total Loss -15.9208 (-16.3709)
2022-11-03 01:36:30,109:INFO: Batch: 21/31	Total Loss -4.2651 (-15.8194)
2022-11-03 01:36:30,690:INFO: Batch: 22/31	Total Loss -0.6439 (-15.2420)
2022-11-03 01:36:31,188:INFO: Batch: 23/31	Total Loss -14.5415 (-15.2144)
2022-11-03 01:36:31,685:INFO: Batch: 24/31	Total Loss -19.6985 (-15.3913)
2022-11-03 01:36:32,183:INFO: Batch: 25/31	Total Loss -22.4350 (-15.6709)
2022-11-03 01:36:32,681:INFO: Batch: 26/31	Total Loss -8.5083 (-15.4121)
2022-11-03 01:36:33,179:INFO: Batch: 27/31	Total Loss -15.3256 (-15.4086)
2022-11-03 01:36:33,677:INFO: Batch: 28/31	Total Loss -10.1443 (-15.2230)
2022-11-03 01:36:34,175:INFO: Batch: 29/31	Total Loss -16.6823 (-15.2756)
2022-11-03 01:36:34,570:INFO: Batch: 30/31	Total Loss -44.0136 (-15.4727)
2022-11-03 01:36:34,711:INFO: - Computing ADE (validation o)
2022-11-03 01:36:35,384:INFO: 		 ADE on eth                       dataset:	 1.1105737686157227
2022-11-03 01:36:35,385:INFO: Average validation o:	ADE  1.1106	FDE  1.9437
2022-11-03 01:36:35,385:INFO: - Computing ADE (validation)
2022-11-03 01:36:35,685:INFO: 		 ADE on hotel                     dataset:	 0.9546372294425964
2022-11-03 01:36:36,076:INFO: 		 ADE on univ                      dataset:	 0.865354061126709
2022-11-03 01:36:36,375:INFO: 		 ADE on zara1                     dataset:	 0.6513816714286804
2022-11-03 01:36:36,847:INFO: 		 ADE on zara2                     dataset:	 0.5174208283424377
2022-11-03 01:36:36,847:INFO: Average validation:	ADE  0.7302	FDE  1.3519
2022-11-03 01:36:36,848:INFO: - Computing ADE (training)
2022-11-03 01:36:37,436:INFO: 		 ADE on hotel                     dataset:	 1.2664035558700562
2022-11-03 01:36:38,472:INFO: 		 ADE on univ                      dataset:	 0.7974899411201477
2022-11-03 01:36:39,224:INFO: 		 ADE on zara1                     dataset:	 0.7673558592796326
2022-11-03 01:36:40,399:INFO: 		 ADE on zara2                     dataset:	 0.5691769123077393
2022-11-03 01:36:40,399:INFO: Average training:	ADE  0.7612	FDE  1.4047
2022-11-03 01:36:40,411:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_567.pth.tar
2022-11-03 01:36:40,411:INFO: 
===> EPOCH: 568 (P4)
2022-11-03 01:36:40,411:INFO: - Computing loss (training)
2022-11-03 01:36:41,541:INFO: Batch:  0/31	Total Loss -11.5267 (-11.5267)
2022-11-03 01:36:42,040:INFO: Batch:  1/31	Total Loss -16.3161 (-13.8975)
2022-11-03 01:36:42,539:INFO: Batch:  2/31	Total Loss -11.2942 (-13.0711)
2022-11-03 01:36:43,036:INFO: Batch:  3/31	Total Loss -18.6259 (-14.6137)
2022-11-03 01:36:43,530:INFO: Batch:  4/31	Total Loss -19.6648 (-15.5706)
2022-11-03 01:36:44,027:INFO: Batch:  5/31	Total Loss -11.7976 (-14.9570)
2022-11-03 01:36:44,525:INFO: Batch:  6/31	Total Loss -26.8370 (-16.8144)
2022-11-03 01:36:45,018:INFO: Batch:  7/31	Total Loss -19.1817 (-17.1080)
2022-11-03 01:36:45,518:INFO: Batch:  8/31	Total Loss -31.6508 (-18.6598)
2022-11-03 01:36:46,016:INFO: Batch:  9/31	Total Loss -23.8372 (-19.1743)
2022-11-03 01:36:46,512:INFO: Batch: 10/31	Total Loss -7.2964 (-18.1172)
2022-11-03 01:36:47,008:INFO: Batch: 11/31	Total Loss -1.8896 (-16.8444)
2022-11-03 01:36:47,509:INFO: Batch: 12/31	Total Loss -10.8433 (-16.3895)
2022-11-03 01:36:48,008:INFO: Batch: 13/31	Total Loss -25.2929 (-17.0505)
2022-11-03 01:36:48,506:INFO: Batch: 14/31	Total Loss -11.4932 (-16.7090)
2022-11-03 01:36:49,005:INFO: Batch: 15/31	Total Loss -16.6651 (-16.7063)
2022-11-03 01:36:49,504:INFO: Batch: 16/31	Total Loss -7.2719 (-16.2071)
2022-11-03 01:36:50,001:INFO: Batch: 17/31	Total Loss -16.6479 (-16.2307)
2022-11-03 01:36:50,503:INFO: Batch: 18/31	Total Loss -11.6438 (-16.0078)
2022-11-03 01:36:51,005:INFO: Batch: 19/31	Total Loss -6.9924 (-15.6221)
2022-11-03 01:36:51,504:INFO: Batch: 20/31	Total Loss -8.4553 (-15.2938)
2022-11-03 01:36:52,003:INFO: Batch: 21/31	Total Loss -26.2703 (-15.8880)
2022-11-03 01:36:52,503:INFO: Batch: 22/31	Total Loss -24.3196 (-16.2557)
2022-11-03 01:36:53,003:INFO: Batch: 23/31	Total Loss -16.2711 (-16.2563)
2022-11-03 01:36:53,502:INFO: Batch: 24/31	Total Loss -22.9533 (-16.5440)
2022-11-03 01:36:53,999:INFO: Batch: 25/31	Total Loss -18.0402 (-16.6003)
2022-11-03 01:36:54,498:INFO: Batch: 26/31	Total Loss -16.4184 (-16.5944)
2022-11-03 01:36:55,000:INFO: Batch: 27/31	Total Loss -17.7949 (-16.6381)
2022-11-03 01:36:55,500:INFO: Batch: 28/31	Total Loss -20.7179 (-16.7770)
2022-11-03 01:36:55,999:INFO: Batch: 29/31	Total Loss -23.4506 (-17.0184)
2022-11-03 01:36:56,392:INFO: Batch: 30/31	Total Loss -53.4016 (-17.3353)
2022-11-03 01:36:56,539:INFO: - Computing ADE (validation o)
2022-11-03 01:36:57,220:INFO: 		 ADE on eth                       dataset:	 1.0853629112243652
2022-11-03 01:36:57,220:INFO: Average validation o:	ADE  1.0854	FDE  1.9129
2022-11-03 01:36:57,221:INFO: - Computing ADE (validation)
2022-11-03 01:36:57,519:INFO: 		 ADE on hotel                     dataset:	 0.9632266163825989
2022-11-03 01:36:57,892:INFO: 		 ADE on univ                      dataset:	 0.8595685362815857
2022-11-03 01:36:58,182:INFO: 		 ADE on zara1                     dataset:	 0.5980222821235657
2022-11-03 01:36:58,670:INFO: 		 ADE on zara2                     dataset:	 0.508616030216217
2022-11-03 01:36:58,670:INFO: Average validation:	ADE  0.7213	FDE  1.3543
2022-11-03 01:36:58,671:INFO: - Computing ADE (training)
2022-11-03 01:36:59,262:INFO: 		 ADE on hotel                     dataset:	 1.2646780014038086
2022-11-03 01:37:00,331:INFO: 		 ADE on univ                      dataset:	 0.7915140390396118
2022-11-03 01:37:01,068:INFO: 		 ADE on zara1                     dataset:	 0.7407992482185364
2022-11-03 01:37:02,267:INFO: 		 ADE on zara2                     dataset:	 0.560943067073822
2022-11-03 01:37:02,267:INFO: Average training:	ADE  0.7535	FDE  1.4081
2022-11-03 01:37:02,279:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_568.pth.tar
2022-11-03 01:37:02,279:INFO: 
===> EPOCH: 569 (P4)
2022-11-03 01:37:02,280:INFO: - Computing loss (training)
2022-11-03 01:37:03,408:INFO: Batch:  0/31	Total Loss -31.6691 (-31.6691)
2022-11-03 01:37:03,912:INFO: Batch:  1/31	Total Loss -18.6891 (-25.5843)
2022-11-03 01:37:04,417:INFO: Batch:  2/31	Total Loss -16.4447 (-22.5295)
2022-11-03 01:37:04,916:INFO: Batch:  3/31	Total Loss -16.3126 (-20.9721)
2022-11-03 01:37:05,419:INFO: Batch:  4/31	Total Loss -14.2668 (-19.7043)
2022-11-03 01:37:05,923:INFO: Batch:  5/31	Total Loss -22.4353 (-20.1701)
2022-11-03 01:37:06,426:INFO: Batch:  6/31	Total Loss -16.5115 (-19.6247)
2022-11-03 01:37:06,925:INFO: Batch:  7/31	Total Loss -16.0230 (-19.1921)
2022-11-03 01:37:07,427:INFO: Batch:  8/31	Total Loss -9.8323 (-18.2914)
2022-11-03 01:37:07,928:INFO: Batch:  9/31	Total Loss -18.5224 (-18.3145)
2022-11-03 01:37:08,429:INFO: Batch: 10/31	Total Loss -15.1944 (-18.0351)
2022-11-03 01:37:08,932:INFO: Batch: 11/31	Total Loss -27.8569 (-18.9512)
2022-11-03 01:37:09,433:INFO: Batch: 12/31	Total Loss -22.6497 (-19.2411)
2022-11-03 01:37:09,939:INFO: Batch: 13/31	Total Loss -22.7619 (-19.4929)
2022-11-03 01:37:10,448:INFO: Batch: 14/31	Total Loss -27.3971 (-20.0991)
2022-11-03 01:37:10,953:INFO: Batch: 15/31	Total Loss -19.2949 (-20.0484)
2022-11-03 01:37:11,458:INFO: Batch: 16/31	Total Loss -28.5619 (-20.5422)
2022-11-03 01:37:11,964:INFO: Batch: 17/31	Total Loss -26.2908 (-20.8696)
2022-11-03 01:37:12,468:INFO: Batch: 18/31	Total Loss -25.9787 (-21.1491)
2022-11-03 01:37:12,972:INFO: Batch: 19/31	Total Loss -31.7537 (-21.7150)
2022-11-03 01:37:13,476:INFO: Batch: 20/31	Total Loss -30.0032 (-22.1303)
2022-11-03 01:37:13,981:INFO: Batch: 21/31	Total Loss -30.3625 (-22.5494)
2022-11-03 01:37:14,486:INFO: Batch: 22/31	Total Loss -21.5598 (-22.5081)
2022-11-03 01:37:14,989:INFO: Batch: 23/31	Total Loss -18.7227 (-22.3648)
2022-11-03 01:37:15,496:INFO: Batch: 24/31	Total Loss -12.4719 (-22.0317)
2022-11-03 01:37:16,006:INFO: Batch: 25/31	Total Loss -24.3325 (-22.1231)
2022-11-03 01:37:16,517:INFO: Batch: 26/31	Total Loss -25.8051 (-22.2617)
2022-11-03 01:37:17,025:INFO: Batch: 27/31	Total Loss -20.9330 (-22.2163)
2022-11-03 01:37:17,535:INFO: Batch: 28/31	Total Loss -25.4450 (-22.3208)
2022-11-03 01:37:18,043:INFO: Batch: 29/31	Total Loss -28.5457 (-22.5521)
2022-11-03 01:37:18,443:INFO: Batch: 30/31	Total Loss -49.8083 (-22.8006)
2022-11-03 01:37:18,593:INFO: - Computing ADE (validation o)
2022-11-03 01:37:19,282:INFO: 		 ADE on eth                       dataset:	 1.0450036525726318
2022-11-03 01:37:19,282:INFO: Average validation o:	ADE  1.0450	FDE  1.8917
2022-11-03 01:37:19,283:INFO: - Computing ADE (validation)
2022-11-03 01:37:19,591:INFO: 		 ADE on hotel                     dataset:	 0.9635775089263916
2022-11-03 01:37:19,966:INFO: 		 ADE on univ                      dataset:	 0.8339576125144958
2022-11-03 01:37:20,265:INFO: 		 ADE on zara1                     dataset:	 0.5287448167800903
2022-11-03 01:37:20,737:INFO: 		 ADE on zara2                     dataset:	 0.48204460740089417
2022-11-03 01:37:20,737:INFO: Average validation:	ADE  0.6942	FDE  1.3194
2022-11-03 01:37:20,738:INFO: - Computing ADE (training)
2022-11-03 01:37:21,339:INFO: 		 ADE on hotel                     dataset:	 1.2523959875106812
2022-11-03 01:37:22,379:INFO: 		 ADE on univ                      dataset:	 0.7770360708236694
2022-11-03 01:37:23,132:INFO: 		 ADE on zara1                     dataset:	 0.6713583469390869
2022-11-03 01:37:24,326:INFO: 		 ADE on zara2                     dataset:	 0.5160490274429321
2022-11-03 01:37:24,326:INFO: Average training:	ADE  0.7294	FDE  1.3790
2022-11-03 01:37:24,337:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_569.pth.tar
2022-11-03 01:37:24,337:INFO: 
===> EPOCH: 570 (P4)
2022-11-03 01:37:24,337:INFO: - Computing loss (training)
2022-11-03 01:37:25,469:INFO: Batch:  0/31	Total Loss -26.6323 (-26.6323)
2022-11-03 01:37:25,979:INFO: Batch:  1/31	Total Loss -27.9270 (-27.2772)
2022-11-03 01:37:26,491:INFO: Batch:  2/31	Total Loss -28.1446 (-27.5589)
2022-11-03 01:37:26,996:INFO: Batch:  3/31	Total Loss -3.4240 (-22.4330)
2022-11-03 01:37:27,501:INFO: Batch:  4/31	Total Loss -22.5378 (-22.4535)
2022-11-03 01:37:28,016:INFO: Batch:  5/31	Total Loss -16.1229 (-21.4309)
2022-11-03 01:37:28,521:INFO: Batch:  6/31	Total Loss -20.0787 (-21.2578)
2022-11-03 01:37:29,024:INFO: Batch:  7/31	Total Loss -22.7653 (-21.4491)
2022-11-03 01:37:29,528:INFO: Batch:  8/31	Total Loss -18.3119 (-21.0894)
2022-11-03 01:37:30,030:INFO: Batch:  9/31	Total Loss -21.3139 (-21.1110)
2022-11-03 01:37:30,613:INFO: Batch: 10/31	Total Loss -35.2857 (-22.5934)
2022-11-03 01:37:31,115:INFO: Batch: 11/31	Total Loss -21.3905 (-22.4903)
2022-11-03 01:37:31,622:INFO: Batch: 12/31	Total Loss -27.7932 (-22.9261)
2022-11-03 01:37:32,126:INFO: Batch: 13/31	Total Loss -19.1225 (-22.6655)
2022-11-03 01:37:32,623:INFO: Batch: 14/31	Total Loss -26.6339 (-22.9083)
2022-11-03 01:37:33,118:INFO: Batch: 15/31	Total Loss -16.5992 (-22.5372)
2022-11-03 01:37:33,612:INFO: Batch: 16/31	Total Loss -20.2690 (-22.3906)
2022-11-03 01:37:34,107:INFO: Batch: 17/31	Total Loss -20.5351 (-22.2888)
2022-11-03 01:37:34,601:INFO: Batch: 18/31	Total Loss -28.7662 (-22.6352)
2022-11-03 01:37:35,095:INFO: Batch: 19/31	Total Loss -34.6545 (-23.3352)
2022-11-03 01:37:35,589:INFO: Batch: 20/31	Total Loss -20.4534 (-23.1973)
2022-11-03 01:37:36,082:INFO: Batch: 21/31	Total Loss -22.0279 (-23.1470)
2022-11-03 01:37:36,574:INFO: Batch: 22/31	Total Loss -32.5673 (-23.5715)
2022-11-03 01:37:37,068:INFO: Batch: 23/31	Total Loss -22.8489 (-23.5404)
2022-11-03 01:37:37,564:INFO: Batch: 24/31	Total Loss -20.1146 (-23.4044)
2022-11-03 01:37:38,057:INFO: Batch: 25/31	Total Loss -15.9180 (-23.1281)
2022-11-03 01:37:38,551:INFO: Batch: 26/31	Total Loss -30.0329 (-23.4000)
2022-11-03 01:37:39,050:INFO: Batch: 27/31	Total Loss -24.0435 (-23.4247)
2022-11-03 01:37:39,545:INFO: Batch: 28/31	Total Loss -35.8656 (-23.8537)
2022-11-03 01:37:40,046:INFO: Batch: 29/31	Total Loss -25.3767 (-23.8998)
2022-11-03 01:37:40,438:INFO: Batch: 30/31	Total Loss -42.7041 (-24.0339)
2022-11-03 01:37:40,589:INFO: - Computing ADE (validation o)
2022-11-03 01:37:41,283:INFO: 		 ADE on eth                       dataset:	 1.0646708011627197
2022-11-03 01:37:41,283:INFO: Average validation o:	ADE  1.0647	FDE  1.9630
2022-11-03 01:37:41,284:INFO: - Computing ADE (validation)
2022-11-03 01:37:41,571:INFO: 		 ADE on hotel                     dataset:	 0.9555795192718506
2022-11-03 01:37:41,939:INFO: 		 ADE on univ                      dataset:	 0.8477185368537903
2022-11-03 01:37:42,231:INFO: 		 ADE on zara1                     dataset:	 0.607611358165741
2022-11-03 01:37:42,714:INFO: 		 ADE on zara2                     dataset:	 0.498199999332428
2022-11-03 01:37:42,714:INFO: Average validation:	ADE  0.7115	FDE  1.3651
2022-11-03 01:37:42,715:INFO: - Computing ADE (training)
2022-11-03 01:37:43,275:INFO: 		 ADE on hotel                     dataset:	 1.25411856174469
2022-11-03 01:37:44,314:INFO: 		 ADE on univ                      dataset:	 0.7839319705963135
2022-11-03 01:37:45,098:INFO: 		 ADE on zara1                     dataset:	 0.7017014622688293
2022-11-03 01:37:46,267:INFO: 		 ADE on zara2                     dataset:	 0.5354281067848206
2022-11-03 01:37:46,267:INFO: Average training:	ADE  0.7402	FDE  1.4126
2022-11-03 01:37:46,278:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_570.pth.tar
2022-11-03 01:37:46,278:INFO: 
===> EPOCH: 571 (P4)
2022-11-03 01:37:46,279:INFO: - Computing loss (training)
2022-11-03 01:37:47,384:INFO: Batch:  0/31	Total Loss -23.0961 (-23.0961)
2022-11-03 01:37:47,877:INFO: Batch:  1/31	Total Loss -30.2591 (-26.8234)
2022-11-03 01:37:48,374:INFO: Batch:  2/31	Total Loss -19.6885 (-24.4934)
2022-11-03 01:37:48,863:INFO: Batch:  3/31	Total Loss -31.2864 (-26.3664)
2022-11-03 01:37:49,356:INFO: Batch:  4/31	Total Loss -21.5305 (-25.4868)
2022-11-03 01:37:49,850:INFO: Batch:  5/31	Total Loss -15.3777 (-23.7854)
2022-11-03 01:37:50,340:INFO: Batch:  6/31	Total Loss -31.3584 (-24.9045)
2022-11-03 01:37:50,833:INFO: Batch:  7/31	Total Loss -8.2085 (-22.9101)
2022-11-03 01:37:51,322:INFO: Batch:  8/31	Total Loss -33.4523 (-24.2026)
2022-11-03 01:37:51,811:INFO: Batch:  9/31	Total Loss -38.7272 (-25.7822)
2022-11-03 01:37:52,303:INFO: Batch: 10/31	Total Loss -35.6392 (-26.7076)
2022-11-03 01:37:52,794:INFO: Batch: 11/31	Total Loss -4.2741 (-24.9944)
2022-11-03 01:37:53,288:INFO: Batch: 12/31	Total Loss -20.3945 (-24.6371)
2022-11-03 01:37:53,781:INFO: Batch: 13/31	Total Loss -39.0172 (-25.7829)
2022-11-03 01:37:54,273:INFO: Batch: 14/31	Total Loss -25.1246 (-25.7421)
2022-11-03 01:37:54,765:INFO: Batch: 15/31	Total Loss -35.1767 (-26.3724)
2022-11-03 01:37:55,260:INFO: Batch: 16/31	Total Loss -43.0072 (-27.4449)
2022-11-03 01:37:55,752:INFO: Batch: 17/31	Total Loss -28.4557 (-27.5022)
2022-11-03 01:37:56,244:INFO: Batch: 18/31	Total Loss -31.2703 (-27.6873)
2022-11-03 01:37:56,737:INFO: Batch: 19/31	Total Loss -31.3117 (-27.8732)
2022-11-03 01:37:57,230:INFO: Batch: 20/31	Total Loss -23.8316 (-27.7000)
2022-11-03 01:37:57,723:INFO: Batch: 21/31	Total Loss -18.7534 (-27.2881)
2022-11-03 01:37:58,215:INFO: Batch: 22/31	Total Loss -29.7569 (-27.4005)
2022-11-03 01:37:58,707:INFO: Batch: 23/31	Total Loss -21.0312 (-27.1378)
2022-11-03 01:37:59,200:INFO: Batch: 24/31	Total Loss -14.1854 (-26.6442)
2022-11-03 01:37:59,692:INFO: Batch: 25/31	Total Loss -38.9104 (-27.1535)
2022-11-03 01:38:00,187:INFO: Batch: 26/31	Total Loss -30.4211 (-27.2745)
2022-11-03 01:38:00,678:INFO: Batch: 27/31	Total Loss -30.0171 (-27.3744)
2022-11-03 01:38:01,175:INFO: Batch: 28/31	Total Loss -27.2232 (-27.3690)
2022-11-03 01:38:01,667:INFO: Batch: 29/31	Total Loss -22.6766 (-27.2074)
2022-11-03 01:38:02,055:INFO: Batch: 30/31	Total Loss -54.7974 (-27.4514)
2022-11-03 01:38:02,209:INFO: - Computing ADE (validation o)
2022-11-03 01:38:02,906:INFO: 		 ADE on eth                       dataset:	 1.0422040224075317
2022-11-03 01:38:02,906:INFO: Average validation o:	ADE  1.0422	FDE  1.9385
2022-11-03 01:38:02,907:INFO: - Computing ADE (validation)
2022-11-03 01:38:03,205:INFO: 		 ADE on hotel                     dataset:	 0.9330055713653564
2022-11-03 01:38:03,573:INFO: 		 ADE on univ                      dataset:	 0.8187301158905029
2022-11-03 01:38:03,855:INFO: 		 ADE on zara1                     dataset:	 0.5469338893890381
2022-11-03 01:38:04,339:INFO: 		 ADE on zara2                     dataset:	 0.47624102234840393
2022-11-03 01:38:04,339:INFO: Average validation:	ADE  0.6836	FDE  1.3095
2022-11-03 01:38:04,340:INFO: - Computing ADE (training)
2022-11-03 01:38:04,898:INFO: 		 ADE on hotel                     dataset:	 1.2167577743530273
2022-11-03 01:38:06,002:INFO: 		 ADE on univ                      dataset:	 0.7619525790214539
2022-11-03 01:38:06,730:INFO: 		 ADE on zara1                     dataset:	 0.6766185164451599
2022-11-03 01:38:07,927:INFO: 		 ADE on zara2                     dataset:	 0.5144458413124084
2022-11-03 01:38:07,927:INFO: Average training:	ADE  0.7179	FDE  1.3699
2022-11-03 01:38:07,938:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_571.pth.tar
2022-11-03 01:38:07,938:INFO: 
===> EPOCH: 572 (P4)
2022-11-03 01:38:07,939:INFO: - Computing loss (training)
2022-11-03 01:38:09,062:INFO: Batch:  0/31	Total Loss -17.5407 (-17.5407)
2022-11-03 01:38:09,560:INFO: Batch:  1/31	Total Loss -24.1545 (-21.1087)
2022-11-03 01:38:10,062:INFO: Batch:  2/31	Total Loss -13.8044 (-18.6090)
2022-11-03 01:38:10,561:INFO: Batch:  3/31	Total Loss -33.9125 (-22.9299)
2022-11-03 01:38:11,057:INFO: Batch:  4/31	Total Loss -32.6529 (-24.8275)
2022-11-03 01:38:11,558:INFO: Batch:  5/31	Total Loss -18.2849 (-23.7382)
2022-11-03 01:38:12,052:INFO: Batch:  6/31	Total Loss -23.4366 (-23.6946)
2022-11-03 01:38:12,546:INFO: Batch:  7/31	Total Loss -32.1609 (-24.8166)
2022-11-03 01:38:13,043:INFO: Batch:  8/31	Total Loss -27.3597 (-25.0850)
2022-11-03 01:38:13,539:INFO: Batch:  9/31	Total Loss -23.9892 (-24.9741)
2022-11-03 01:38:14,035:INFO: Batch: 10/31	Total Loss -32.2131 (-25.6454)
2022-11-03 01:38:14,532:INFO: Batch: 11/31	Total Loss -30.7819 (-26.1325)
2022-11-03 01:38:15,031:INFO: Batch: 12/31	Total Loss -15.6406 (-25.3758)
2022-11-03 01:38:15,530:INFO: Batch: 13/31	Total Loss -34.2318 (-26.0229)
2022-11-03 01:38:16,029:INFO: Batch: 14/31	Total Loss -28.7960 (-26.2250)
2022-11-03 01:38:16,530:INFO: Batch: 15/31	Total Loss -20.8458 (-25.9319)
2022-11-03 01:38:17,028:INFO: Batch: 16/31	Total Loss -36.2893 (-26.5857)
2022-11-03 01:38:17,526:INFO: Batch: 17/31	Total Loss -35.2003 (-27.0890)
2022-11-03 01:38:18,025:INFO: Batch: 18/31	Total Loss -25.9035 (-27.0269)
2022-11-03 01:38:18,525:INFO: Batch: 19/31	Total Loss -18.8065 (-26.6378)
2022-11-03 01:38:19,024:INFO: Batch: 20/31	Total Loss -8.5291 (-25.8710)
2022-11-03 01:38:19,525:INFO: Batch: 21/31	Total Loss -32.7142 (-26.1989)
2022-11-03 01:38:20,025:INFO: Batch: 22/31	Total Loss -37.2107 (-26.7064)
2022-11-03 01:38:20,523:INFO: Batch: 23/31	Total Loss -14.2091 (-26.2539)
2022-11-03 01:38:21,025:INFO: Batch: 24/31	Total Loss -41.4159 (-26.9675)
2022-11-03 01:38:21,525:INFO: Batch: 25/31	Total Loss -35.1934 (-27.2837)
2022-11-03 01:38:22,026:INFO: Batch: 26/31	Total Loss -27.3076 (-27.2846)
2022-11-03 01:38:22,606:INFO: Batch: 27/31	Total Loss -17.5518 (-26.9415)
2022-11-03 01:38:23,110:INFO: Batch: 28/31	Total Loss -33.1983 (-27.1827)
2022-11-03 01:38:23,611:INFO: Batch: 29/31	Total Loss -16.5179 (-26.8703)
2022-11-03 01:38:24,006:INFO: Batch: 30/31	Total Loss -55.9325 (-27.1959)
2022-11-03 01:38:24,163:INFO: - Computing ADE (validation o)
2022-11-03 01:38:24,861:INFO: 		 ADE on eth                       dataset:	 1.01021409034729
2022-11-03 01:38:24,862:INFO: Average validation o:	ADE  1.0102	FDE  1.9046
2022-11-03 01:38:24,862:INFO: - Computing ADE (validation)
2022-11-03 01:38:25,162:INFO: 		 ADE on hotel                     dataset:	 0.9226835370063782
2022-11-03 01:38:25,567:INFO: 		 ADE on univ                      dataset:	 0.8119192719459534
2022-11-03 01:38:25,851:INFO: 		 ADE on zara1                     dataset:	 0.49078744649887085
2022-11-03 01:38:26,313:INFO: 		 ADE on zara2                     dataset:	 0.45295435190200806
2022-11-03 01:38:26,313:INFO: Average validation:	ADE  0.6676	FDE  1.2997
2022-11-03 01:38:26,314:INFO: - Computing ADE (training)
2022-11-03 01:38:26,875:INFO: 		 ADE on hotel                     dataset:	 1.199579119682312
2022-11-03 01:38:27,956:INFO: 		 ADE on univ                      dataset:	 0.747689425945282
2022-11-03 01:38:28,700:INFO: 		 ADE on zara1                     dataset:	 0.6115216016769409
2022-11-03 01:38:29,868:INFO: 		 ADE on zara2                     dataset:	 0.4763146936893463
2022-11-03 01:38:29,868:INFO: Average training:	ADE  0.6954	FDE  1.3442
2022-11-03 01:38:29,880:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_572.pth.tar
2022-11-03 01:38:29,880:INFO: 
===> EPOCH: 573 (P4)
2022-11-03 01:38:29,881:INFO: - Computing loss (training)
2022-11-03 01:38:31,017:INFO: Batch:  0/31	Total Loss -30.8969 (-30.8969)
2022-11-03 01:38:31,532:INFO: Batch:  1/31	Total Loss -28.5760 (-29.7758)
2022-11-03 01:38:32,039:INFO: Batch:  2/31	Total Loss -44.1473 (-34.7764)
2022-11-03 01:38:32,544:INFO: Batch:  3/31	Total Loss -29.5365 (-33.6217)
2022-11-03 01:38:33,055:INFO: Batch:  4/31	Total Loss -26.2320 (-32.1404)
2022-11-03 01:38:33,565:INFO: Batch:  5/31	Total Loss -32.0786 (-32.1300)
2022-11-03 01:38:34,075:INFO: Batch:  6/31	Total Loss -40.2989 (-33.3419)
2022-11-03 01:38:34,581:INFO: Batch:  7/31	Total Loss -28.6103 (-32.7601)
2022-11-03 01:38:35,086:INFO: Batch:  8/31	Total Loss -40.0562 (-33.5464)
2022-11-03 01:38:35,591:INFO: Batch:  9/31	Total Loss -23.5000 (-32.5663)
2022-11-03 01:38:36,097:INFO: Batch: 10/31	Total Loss -38.4338 (-33.1395)
2022-11-03 01:38:36,601:INFO: Batch: 11/31	Total Loss -26.7301 (-32.6609)
2022-11-03 01:38:37,111:INFO: Batch: 12/31	Total Loss -36.3985 (-32.9707)
2022-11-03 01:38:37,622:INFO: Batch: 13/31	Total Loss -35.4794 (-33.1645)
2022-11-03 01:38:38,131:INFO: Batch: 14/31	Total Loss -40.4946 (-33.6752)
2022-11-03 01:38:38,639:INFO: Batch: 15/31	Total Loss -22.2295 (-32.9820)
2022-11-03 01:38:39,143:INFO: Batch: 16/31	Total Loss -34.3455 (-33.0662)
2022-11-03 01:38:39,647:INFO: Batch: 17/31	Total Loss -25.8540 (-32.6769)
2022-11-03 01:38:40,150:INFO: Batch: 18/31	Total Loss -32.5740 (-32.6714)
2022-11-03 01:38:40,656:INFO: Batch: 19/31	Total Loss -25.3605 (-32.3179)
2022-11-03 01:38:41,159:INFO: Batch: 20/31	Total Loss -29.4060 (-32.1862)
2022-11-03 01:38:41,661:INFO: Batch: 21/31	Total Loss -22.8594 (-31.7734)
2022-11-03 01:38:42,163:INFO: Batch: 22/31	Total Loss -43.7381 (-32.3326)
2022-11-03 01:38:42,665:INFO: Batch: 23/31	Total Loss -37.3278 (-32.5577)
2022-11-03 01:38:43,167:INFO: Batch: 24/31	Total Loss -27.9212 (-32.3844)
2022-11-03 01:38:43,669:INFO: Batch: 25/31	Total Loss -25.5677 (-32.1433)
2022-11-03 01:38:44,170:INFO: Batch: 26/31	Total Loss -20.9860 (-31.7511)
2022-11-03 01:38:44,671:INFO: Batch: 27/31	Total Loss -29.7029 (-31.6814)
2022-11-03 01:38:45,173:INFO: Batch: 28/31	Total Loss -26.9626 (-31.5298)
2022-11-03 01:38:45,674:INFO: Batch: 29/31	Total Loss -32.6579 (-31.5713)
2022-11-03 01:38:46,071:INFO: Batch: 30/31	Total Loss -59.9262 (-31.9060)
2022-11-03 01:38:46,212:INFO: - Computing ADE (validation o)
2022-11-03 01:38:46,914:INFO: 		 ADE on eth                       dataset:	 0.9944208860397339
2022-11-03 01:38:46,914:INFO: Average validation o:	ADE  0.9944	FDE  1.9160
2022-11-03 01:38:46,915:INFO: - Computing ADE (validation)
2022-11-03 01:38:47,220:INFO: 		 ADE on hotel                     dataset:	 0.8854740858078003
2022-11-03 01:38:47,580:INFO: 		 ADE on univ                      dataset:	 0.7804202437400818
2022-11-03 01:38:47,868:INFO: 		 ADE on zara1                     dataset:	 0.47121769189834595
2022-11-03 01:38:48,342:INFO: 		 ADE on zara2                     dataset:	 0.44860541820526123
2022-11-03 01:38:48,342:INFO: Average validation:	ADE  0.6465	FDE  1.2681
2022-11-03 01:38:48,343:INFO: - Computing ADE (training)
2022-11-03 01:38:48,931:INFO: 		 ADE on hotel                     dataset:	 1.1329084634780884
2022-11-03 01:38:49,975:INFO: 		 ADE on univ                      dataset:	 0.7237650752067566
2022-11-03 01:38:50,711:INFO: 		 ADE on zara1                     dataset:	 0.5894393920898438
2022-11-03 01:38:51,883:INFO: 		 ADE on zara2                     dataset:	 0.46608778834342957
2022-11-03 01:38:51,883:INFO: Average training:	ADE  0.6733	FDE  1.3133
2022-11-03 01:38:51,894:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_573.pth.tar
2022-11-03 01:38:51,894:INFO: 
===> EPOCH: 574 (P4)
2022-11-03 01:38:51,894:INFO: - Computing loss (training)
2022-11-03 01:38:53,030:INFO: Batch:  0/31	Total Loss -24.9184 (-24.9184)
2022-11-03 01:38:53,529:INFO: Batch:  1/31	Total Loss -27.1255 (-26.0310)
2022-11-03 01:38:54,028:INFO: Batch:  2/31	Total Loss -25.2344 (-25.7846)
2022-11-03 01:38:54,530:INFO: Batch:  3/31	Total Loss -40.6227 (-29.7872)
2022-11-03 01:38:55,031:INFO: Batch:  4/31	Total Loss -33.3899 (-30.4547)
2022-11-03 01:38:55,529:INFO: Batch:  5/31	Total Loss -27.8200 (-30.0322)
2022-11-03 01:38:56,025:INFO: Batch:  6/31	Total Loss -32.7864 (-30.4410)
2022-11-03 01:38:56,520:INFO: Batch:  7/31	Total Loss -38.3970 (-31.4629)
2022-11-03 01:38:57,016:INFO: Batch:  8/31	Total Loss -27.6456 (-31.0386)
2022-11-03 01:38:57,512:INFO: Batch:  9/31	Total Loss -30.7839 (-31.0123)
2022-11-03 01:38:58,007:INFO: Batch: 10/31	Total Loss -42.0363 (-32.0778)
2022-11-03 01:38:58,505:INFO: Batch: 11/31	Total Loss -36.0227 (-32.4143)
2022-11-03 01:38:59,003:INFO: Batch: 12/31	Total Loss -23.9690 (-31.7773)
2022-11-03 01:38:59,502:INFO: Batch: 13/31	Total Loss -21.9597 (-31.0475)
2022-11-03 01:39:00,001:INFO: Batch: 14/31	Total Loss -33.6666 (-31.2193)
2022-11-03 01:39:00,506:INFO: Batch: 15/31	Total Loss -30.9692 (-31.2035)
2022-11-03 01:39:01,006:INFO: Batch: 16/31	Total Loss -28.1423 (-31.0307)
2022-11-03 01:39:01,508:INFO: Batch: 17/31	Total Loss -19.9305 (-30.4350)
2022-11-03 01:39:02,007:INFO: Batch: 18/31	Total Loss -45.2334 (-31.3070)
2022-11-03 01:39:02,504:INFO: Batch: 19/31	Total Loss -36.5181 (-31.5552)
2022-11-03 01:39:03,001:INFO: Batch: 20/31	Total Loss -43.0422 (-32.1608)
2022-11-03 01:39:03,497:INFO: Batch: 21/31	Total Loss -39.6512 (-32.4912)
2022-11-03 01:39:03,994:INFO: Batch: 22/31	Total Loss -35.7842 (-32.6391)
2022-11-03 01:39:04,492:INFO: Batch: 23/31	Total Loss -38.9343 (-32.9120)
2022-11-03 01:39:04,990:INFO: Batch: 24/31	Total Loss -36.2932 (-33.0461)
2022-11-03 01:39:05,486:INFO: Batch: 25/31	Total Loss -37.7608 (-33.2331)
2022-11-03 01:39:05,983:INFO: Batch: 26/31	Total Loss -48.7701 (-33.8818)
2022-11-03 01:39:06,480:INFO: Batch: 27/31	Total Loss -29.5865 (-33.7245)
2022-11-03 01:39:06,977:INFO: Batch: 28/31	Total Loss -33.3569 (-33.7121)
2022-11-03 01:39:07,474:INFO: Batch: 29/31	Total Loss -32.3402 (-33.6635)
2022-11-03 01:39:07,870:INFO: Batch: 30/31	Total Loss -58.4585 (-33.9220)
2022-11-03 01:39:08,030:INFO: - Computing ADE (validation o)
2022-11-03 01:39:08,703:INFO: 		 ADE on eth                       dataset:	 0.983191192150116
2022-11-03 01:39:08,704:INFO: Average validation o:	ADE  0.9832	FDE  1.9164
2022-11-03 01:39:08,704:INFO: - Computing ADE (validation)
2022-11-03 01:39:09,016:INFO: 		 ADE on hotel                     dataset:	 0.7415052652359009
2022-11-03 01:39:09,404:INFO: 		 ADE on univ                      dataset:	 0.6854761242866516
2022-11-03 01:39:09,703:INFO: 		 ADE on zara1                     dataset:	 0.48061808943748474
2022-11-03 01:39:10,187:INFO: 		 ADE on zara2                     dataset:	 0.461751252412796
2022-11-03 01:39:10,187:INFO: Average validation:	ADE  0.5946	FDE  1.1826
2022-11-03 01:39:10,188:INFO: - Computing ADE (training)
2022-11-03 01:39:10,785:INFO: 		 ADE on hotel                     dataset:	 0.8868996500968933
2022-11-03 01:39:11,809:INFO: 		 ADE on univ                      dataset:	 0.6491730213165283
2022-11-03 01:39:12,559:INFO: 		 ADE on zara1                     dataset:	 0.546867311000824
2022-11-03 01:39:13,772:INFO: 		 ADE on zara2                     dataset:	 0.46727055311203003
2022-11-03 01:39:13,772:INFO: Average training:	ADE  0.6118	FDE  1.2085
2022-11-03 01:39:13,784:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_574.pth.tar
2022-11-03 01:39:13,784:INFO: 
===> EPOCH: 575 (P4)
2022-11-03 01:39:13,784:INFO: - Computing loss (training)
2022-11-03 01:39:14,923:INFO: Batch:  0/31	Total Loss -40.5156 (-40.5156)
2022-11-03 01:39:15,441:INFO: Batch:  1/31	Total Loss -39.0104 (-39.7522)
2022-11-03 01:39:15,955:INFO: Batch:  2/31	Total Loss -35.7725 (-38.5134)
2022-11-03 01:39:16,464:INFO: Batch:  3/31	Total Loss -19.1568 (-34.0483)
2022-11-03 01:39:16,969:INFO: Batch:  4/31	Total Loss -28.1713 (-32.9302)
2022-11-03 01:39:17,479:INFO: Batch:  5/31	Total Loss -39.0237 (-34.0107)
2022-11-03 01:39:17,987:INFO: Batch:  6/31	Total Loss -38.9988 (-34.6738)
2022-11-03 01:39:18,573:INFO: Batch:  7/31	Total Loss -44.8575 (-35.9478)
2022-11-03 01:39:19,080:INFO: Batch:  8/31	Total Loss -35.8874 (-35.9412)
2022-11-03 01:39:19,599:INFO: Batch:  9/31	Total Loss -34.0255 (-35.7494)
2022-11-03 01:39:20,106:INFO: Batch: 10/31	Total Loss -32.8550 (-35.4912)
2022-11-03 01:39:20,617:INFO: Batch: 11/31	Total Loss -36.5382 (-35.5829)
2022-11-03 01:39:21,127:INFO: Batch: 12/31	Total Loss -43.5661 (-36.2373)
2022-11-03 01:39:21,637:INFO: Batch: 13/31	Total Loss -37.6310 (-36.3322)
2022-11-03 01:39:22,147:INFO: Batch: 14/31	Total Loss -40.6547 (-36.6106)
2022-11-03 01:39:22,659:INFO: Batch: 15/31	Total Loss -42.5854 (-36.9950)
2022-11-03 01:39:23,168:INFO: Batch: 16/31	Total Loss -47.4593 (-37.6346)
2022-11-03 01:39:23,679:INFO: Batch: 17/31	Total Loss -45.7355 (-38.1047)
2022-11-03 01:39:24,189:INFO: Batch: 18/31	Total Loss -48.9600 (-38.7120)
2022-11-03 01:39:24,698:INFO: Batch: 19/31	Total Loss -32.8759 (-38.4301)
2022-11-03 01:39:25,209:INFO: Batch: 20/31	Total Loss -43.1451 (-38.6682)
2022-11-03 01:39:25,717:INFO: Batch: 21/31	Total Loss -32.7672 (-38.4123)
2022-11-03 01:39:26,225:INFO: Batch: 22/31	Total Loss -43.8893 (-38.6528)
2022-11-03 01:39:26,733:INFO: Batch: 23/31	Total Loss -34.4439 (-38.4877)
2022-11-03 01:39:27,240:INFO: Batch: 24/31	Total Loss -35.2602 (-38.3640)
2022-11-03 01:39:27,747:INFO: Batch: 25/31	Total Loss -42.7997 (-38.5308)
2022-11-03 01:39:28,255:INFO: Batch: 26/31	Total Loss -35.1759 (-38.4190)
2022-11-03 01:39:28,762:INFO: Batch: 27/31	Total Loss -41.2544 (-38.5201)
2022-11-03 01:39:29,270:INFO: Batch: 28/31	Total Loss -44.3269 (-38.7225)
2022-11-03 01:39:29,778:INFO: Batch: 29/31	Total Loss -42.6362 (-38.8478)
2022-11-03 01:39:30,178:INFO: Batch: 30/31	Total Loss -61.7488 (-39.0550)
2022-11-03 01:39:30,318:INFO: - Computing ADE (validation o)
2022-11-03 01:39:31,020:INFO: 		 ADE on eth                       dataset:	 0.9752715229988098
2022-11-03 01:39:31,020:INFO: Average validation o:	ADE  0.9753	FDE  1.9299
2022-11-03 01:39:31,021:INFO: - Computing ADE (validation)
2022-11-03 01:39:31,319:INFO: 		 ADE on hotel                     dataset:	 0.6405096054077148
2022-11-03 01:39:31,688:INFO: 		 ADE on univ                      dataset:	 0.6030208468437195
2022-11-03 01:39:31,995:INFO: 		 ADE on zara1                     dataset:	 0.43973106145858765
2022-11-03 01:39:32,470:INFO: 		 ADE on zara2                     dataset:	 0.47185441851615906
2022-11-03 01:39:32,471:INFO: Average validation:	ADE  0.5475	FDE  1.1120
2022-11-03 01:39:32,472:INFO: - Computing ADE (training)
2022-11-03 01:39:33,046:INFO: 		 ADE on hotel                     dataset:	 0.706548810005188
2022-11-03 01:39:34,104:INFO: 		 ADE on univ                      dataset:	 0.6044579744338989
2022-11-03 01:39:34,832:INFO: 		 ADE on zara1                     dataset:	 0.5373378992080688
2022-11-03 01:39:36,022:INFO: 		 ADE on zara2                     dataset:	 0.473169207572937
2022-11-03 01:39:36,022:INFO: Average training:	ADE  0.5761	FDE  1.1710
2022-11-03 01:39:36,034:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_575.pth.tar
2022-11-03 01:39:36,034:INFO: 
===> EPOCH: 576 (P4)
2022-11-03 01:39:36,034:INFO: - Computing loss (training)
2022-11-03 01:39:37,163:INFO: Batch:  0/31	Total Loss -40.2073 (-40.2073)
2022-11-03 01:39:37,671:INFO: Batch:  1/31	Total Loss -47.5253 (-43.7564)
2022-11-03 01:39:38,169:INFO: Batch:  2/31	Total Loss -33.7393 (-40.5594)
2022-11-03 01:39:38,666:INFO: Batch:  3/31	Total Loss -45.0218 (-41.6231)
2022-11-03 01:39:39,167:INFO: Batch:  4/31	Total Loss -48.0972 (-42.8166)
2022-11-03 01:39:39,668:INFO: Batch:  5/31	Total Loss -34.3284 (-41.4193)
2022-11-03 01:39:40,167:INFO: Batch:  6/31	Total Loss -52.3336 (-43.0653)
2022-11-03 01:39:40,669:INFO: Batch:  7/31	Total Loss -34.4187 (-41.9915)
2022-11-03 01:39:41,166:INFO: Batch:  8/31	Total Loss -34.7872 (-41.2694)
2022-11-03 01:39:41,663:INFO: Batch:  9/31	Total Loss -48.2472 (-41.9483)
2022-11-03 01:39:42,161:INFO: Batch: 10/31	Total Loss -32.2567 (-41.1259)
2022-11-03 01:39:42,660:INFO: Batch: 11/31	Total Loss -37.3634 (-40.8077)
2022-11-03 01:39:43,162:INFO: Batch: 12/31	Total Loss -36.7511 (-40.5058)
2022-11-03 01:39:43,663:INFO: Batch: 13/31	Total Loss -45.9586 (-40.8824)
2022-11-03 01:39:44,163:INFO: Batch: 14/31	Total Loss -42.3223 (-40.9885)
2022-11-03 01:39:44,666:INFO: Batch: 15/31	Total Loss -48.4348 (-41.4469)
2022-11-03 01:39:45,169:INFO: Batch: 16/31	Total Loss -48.4762 (-41.8950)
2022-11-03 01:39:45,669:INFO: Batch: 17/31	Total Loss -55.4658 (-42.7268)
2022-11-03 01:39:46,166:INFO: Batch: 18/31	Total Loss -46.2880 (-42.9083)
2022-11-03 01:39:46,666:INFO: Batch: 19/31	Total Loss -38.3965 (-42.6921)
2022-11-03 01:39:47,166:INFO: Batch: 20/31	Total Loss -46.8298 (-42.8855)
2022-11-03 01:39:47,666:INFO: Batch: 21/31	Total Loss -38.2217 (-42.6849)
2022-11-03 01:39:48,166:INFO: Batch: 22/31	Total Loss -35.8084 (-42.4167)
2022-11-03 01:39:48,666:INFO: Batch: 23/31	Total Loss -31.5837 (-41.9982)
2022-11-03 01:39:49,164:INFO: Batch: 24/31	Total Loss -45.1953 (-42.1198)
2022-11-03 01:39:49,665:INFO: Batch: 25/31	Total Loss -45.0895 (-42.2555)
2022-11-03 01:39:50,163:INFO: Batch: 26/31	Total Loss -57.9019 (-42.9215)
2022-11-03 01:39:50,664:INFO: Batch: 27/31	Total Loss -45.2534 (-43.0033)
2022-11-03 01:39:51,164:INFO: Batch: 28/31	Total Loss -50.6766 (-43.2447)
2022-11-03 01:39:51,665:INFO: Batch: 29/31	Total Loss -35.2318 (-42.9911)
2022-11-03 01:39:52,057:INFO: Batch: 30/31	Total Loss -68.9118 (-43.2717)
2022-11-03 01:39:52,214:INFO: - Computing ADE (validation o)
2022-11-03 01:39:52,872:INFO: 		 ADE on eth                       dataset:	 0.9734333753585815
2022-11-03 01:39:52,872:INFO: Average validation o:	ADE  0.9734	FDE  1.8931
2022-11-03 01:39:52,873:INFO: - Computing ADE (validation)
2022-11-03 01:39:53,174:INFO: 		 ADE on hotel                     dataset:	 0.5944207906723022
2022-11-03 01:39:53,557:INFO: 		 ADE on univ                      dataset:	 0.5971006751060486
2022-11-03 01:39:53,854:INFO: 		 ADE on zara1                     dataset:	 0.45071443915367126
2022-11-03 01:39:54,337:INFO: 		 ADE on zara2                     dataset:	 0.4485580325126648
2022-11-03 01:39:54,337:INFO: Average validation:	ADE  0.5340	FDE  1.0708
2022-11-03 01:39:54,338:INFO: - Computing ADE (training)
2022-11-03 01:39:54,891:INFO: 		 ADE on hotel                     dataset:	 0.6741480231285095
2022-11-03 01:39:55,918:INFO: 		 ADE on univ                      dataset:	 0.5817326903343201
2022-11-03 01:39:56,636:INFO: 		 ADE on zara1                     dataset:	 0.5485935211181641
2022-11-03 01:39:57,803:INFO: 		 ADE on zara2                     dataset:	 0.4609113335609436
2022-11-03 01:39:57,803:INFO: Average training:	ADE  0.5575	FDE  1.1197
2022-11-03 01:39:57,815:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_576.pth.tar
2022-11-03 01:39:57,815:INFO: 
===> EPOCH: 577 (P4)
2022-11-03 01:39:57,815:INFO: - Computing loss (training)
2022-11-03 01:39:58,948:INFO: Batch:  0/31	Total Loss -49.9097 (-49.9097)
2022-11-03 01:39:59,452:INFO: Batch:  1/31	Total Loss -42.0965 (-46.2676)
2022-11-03 01:39:59,956:INFO: Batch:  2/31	Total Loss -47.1040 (-46.5548)
2022-11-03 01:40:00,456:INFO: Batch:  3/31	Total Loss -51.1475 (-47.7940)
2022-11-03 01:40:00,958:INFO: Batch:  4/31	Total Loss -40.3065 (-46.2858)
2022-11-03 01:40:01,461:INFO: Batch:  5/31	Total Loss -41.1028 (-45.4098)
2022-11-03 01:40:01,962:INFO: Batch:  6/31	Total Loss -62.8668 (-48.0153)
2022-11-03 01:40:02,459:INFO: Batch:  7/31	Total Loss -41.6774 (-47.2815)
2022-11-03 01:40:02,959:INFO: Batch:  8/31	Total Loss -52.2333 (-47.8358)
2022-11-03 01:40:03,455:INFO: Batch:  9/31	Total Loss -54.2864 (-48.4931)
2022-11-03 01:40:03,955:INFO: Batch: 10/31	Total Loss -32.1775 (-47.0803)
2022-11-03 01:40:04,454:INFO: Batch: 11/31	Total Loss -50.9887 (-47.3753)
2022-11-03 01:40:04,959:INFO: Batch: 12/31	Total Loss -47.7336 (-47.4036)
2022-11-03 01:40:05,461:INFO: Batch: 13/31	Total Loss -54.6453 (-47.9249)
2022-11-03 01:40:05,964:INFO: Batch: 14/31	Total Loss -43.1398 (-47.6277)
2022-11-03 01:40:06,463:INFO: Batch: 15/31	Total Loss -34.7169 (-46.8620)
2022-11-03 01:40:06,959:INFO: Batch: 16/31	Total Loss -43.6817 (-46.6647)
2022-11-03 01:40:07,452:INFO: Batch: 17/31	Total Loss -48.0671 (-46.7519)
2022-11-03 01:40:07,948:INFO: Batch: 18/31	Total Loss -33.8770 (-46.1136)
2022-11-03 01:40:08,440:INFO: Batch: 19/31	Total Loss -39.3644 (-45.8103)
2022-11-03 01:40:08,933:INFO: Batch: 20/31	Total Loss -43.6707 (-45.7175)
2022-11-03 01:40:09,428:INFO: Batch: 21/31	Total Loss -34.6443 (-45.2163)
2022-11-03 01:40:09,923:INFO: Batch: 22/31	Total Loss -28.4028 (-44.5434)
2022-11-03 01:40:10,415:INFO: Batch: 23/31	Total Loss -34.9767 (-44.1477)
2022-11-03 01:40:10,908:INFO: Batch: 24/31	Total Loss -56.4177 (-44.6863)
2022-11-03 01:40:11,400:INFO: Batch: 25/31	Total Loss -46.2951 (-44.7465)
2022-11-03 01:40:11,893:INFO: Batch: 26/31	Total Loss -49.5103 (-44.9269)
2022-11-03 01:40:12,460:INFO: Batch: 27/31	Total Loss -37.0160 (-44.6874)
2022-11-03 01:40:12,953:INFO: Batch: 28/31	Total Loss -43.4102 (-44.6447)
2022-11-03 01:40:13,442:INFO: Batch: 29/31	Total Loss -31.4450 (-44.2896)
2022-11-03 01:40:13,833:INFO: Batch: 30/31	Total Loss -61.5817 (-44.4967)
2022-11-03 01:40:13,977:INFO: - Computing ADE (validation o)
2022-11-03 01:40:14,659:INFO: 		 ADE on eth                       dataset:	 0.9558588862419128
2022-11-03 01:40:14,660:INFO: Average validation o:	ADE  0.9559	FDE  1.8933
2022-11-03 01:40:14,669:INFO: - Computing ADE (validation)
2022-11-03 01:40:14,983:INFO: 		 ADE on hotel                     dataset:	 0.5832777619361877
2022-11-03 01:40:15,372:INFO: 		 ADE on univ                      dataset:	 0.6026961803436279
2022-11-03 01:40:15,659:INFO: 		 ADE on zara1                     dataset:	 0.4598354697227478
2022-11-03 01:40:16,136:INFO: 		 ADE on zara2                     dataset:	 0.43604350090026855
2022-11-03 01:40:16,137:INFO: Average validation:	ADE  0.5322	FDE  1.0895
2022-11-03 01:40:16,137:INFO: - Computing ADE (training)
2022-11-03 01:40:16,707:INFO: 		 ADE on hotel                     dataset:	 0.6560043692588806
2022-11-03 01:40:17,784:INFO: 		 ADE on univ                      dataset:	 0.5799285173416138
2022-11-03 01:40:18,516:INFO: 		 ADE on zara1                     dataset:	 0.5112999081611633
2022-11-03 01:40:19,708:INFO: 		 ADE on zara2                     dataset:	 0.43822887539863586
2022-11-03 01:40:19,708:INFO: Average training:	ADE  0.5487	FDE  1.1207
2022-11-03 01:40:19,728:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_577.pth.tar
2022-11-03 01:40:19,728:INFO: 
===> EPOCH: 578 (P4)
2022-11-03 01:40:19,728:INFO: - Computing loss (training)
2022-11-03 01:40:20,890:INFO: Batch:  0/31	Total Loss -41.8729 (-41.8729)
2022-11-03 01:40:21,394:INFO: Batch:  1/31	Total Loss -49.5479 (-45.7048)
2022-11-03 01:40:21,895:INFO: Batch:  2/31	Total Loss -42.2579 (-44.6380)
2022-11-03 01:40:22,395:INFO: Batch:  3/31	Total Loss -44.3733 (-44.5751)
2022-11-03 01:40:22,897:INFO: Batch:  4/31	Total Loss -40.4132 (-43.7461)
2022-11-03 01:40:23,401:INFO: Batch:  5/31	Total Loss -41.5793 (-43.3862)
2022-11-03 01:40:23,903:INFO: Batch:  6/31	Total Loss -61.8506 (-46.2337)
2022-11-03 01:40:24,403:INFO: Batch:  7/31	Total Loss -41.5175 (-45.6617)
2022-11-03 01:40:24,904:INFO: Batch:  8/31	Total Loss -51.8024 (-46.3884)
2022-11-03 01:40:25,403:INFO: Batch:  9/31	Total Loss -52.9973 (-47.0587)
2022-11-03 01:40:25,907:INFO: Batch: 10/31	Total Loss -38.4420 (-46.3410)
2022-11-03 01:40:26,406:INFO: Batch: 11/31	Total Loss -52.3267 (-46.8423)
2022-11-03 01:40:26,911:INFO: Batch: 12/31	Total Loss -46.6670 (-46.8283)
2022-11-03 01:40:27,412:INFO: Batch: 13/31	Total Loss -39.5272 (-46.3543)
2022-11-03 01:40:27,915:INFO: Batch: 14/31	Total Loss -48.3026 (-46.4871)
2022-11-03 01:40:28,417:INFO: Batch: 15/31	Total Loss -32.8595 (-45.8181)
2022-11-03 01:40:28,919:INFO: Batch: 16/31	Total Loss -49.6494 (-46.0684)
2022-11-03 01:40:29,421:INFO: Batch: 17/31	Total Loss -55.1605 (-46.5770)
2022-11-03 01:40:29,927:INFO: Batch: 18/31	Total Loss -51.3407 (-46.8257)
2022-11-03 01:40:30,429:INFO: Batch: 19/31	Total Loss -44.9740 (-46.7334)
2022-11-03 01:40:30,934:INFO: Batch: 20/31	Total Loss -43.5950 (-46.5880)
2022-11-03 01:40:31,437:INFO: Batch: 21/31	Total Loss -53.8933 (-46.9471)
2022-11-03 01:40:31,940:INFO: Batch: 22/31	Total Loss -41.4373 (-46.6836)
2022-11-03 01:40:32,443:INFO: Batch: 23/31	Total Loss -52.2473 (-46.9326)
2022-11-03 01:40:32,944:INFO: Batch: 24/31	Total Loss -50.0621 (-47.0712)
2022-11-03 01:40:33,445:INFO: Batch: 25/31	Total Loss -43.7901 (-46.9418)
2022-11-03 01:40:33,946:INFO: Batch: 26/31	Total Loss -55.7690 (-47.2699)
2022-11-03 01:40:34,446:INFO: Batch: 27/31	Total Loss -40.4595 (-47.0572)
2022-11-03 01:40:34,950:INFO: Batch: 28/31	Total Loss -41.7889 (-46.9012)
2022-11-03 01:40:35,451:INFO: Batch: 29/31	Total Loss -46.2241 (-46.8791)
2022-11-03 01:40:35,848:INFO: Batch: 30/31	Total Loss -57.3257 (-46.9740)
2022-11-03 01:40:36,000:INFO: - Computing ADE (validation o)
2022-11-03 01:40:36,696:INFO: 		 ADE on eth                       dataset:	 0.948128342628479
2022-11-03 01:40:36,697:INFO: Average validation o:	ADE  0.9481	FDE  1.8629
2022-11-03 01:40:36,697:INFO: - Computing ADE (validation)
2022-11-03 01:40:36,993:INFO: 		 ADE on hotel                     dataset:	 0.5780662298202515
2022-11-03 01:40:37,363:INFO: 		 ADE on univ                      dataset:	 0.5896598696708679
2022-11-03 01:40:37,652:INFO: 		 ADE on zara1                     dataset:	 0.46049341559410095
2022-11-03 01:40:38,112:INFO: 		 ADE on zara2                     dataset:	 0.4302412271499634
2022-11-03 01:40:38,113:INFO: Average validation:	ADE  0.5230	FDE  1.0615
2022-11-03 01:40:38,113:INFO: - Computing ADE (training)
2022-11-03 01:40:38,702:INFO: 		 ADE on hotel                     dataset:	 0.6443192958831787
2022-11-03 01:40:39,755:INFO: 		 ADE on univ                      dataset:	 0.5708169937133789
2022-11-03 01:40:40,546:INFO: 		 ADE on zara1                     dataset:	 0.5136620998382568
2022-11-03 01:40:41,727:INFO: 		 ADE on zara2                     dataset:	 0.4386945366859436
2022-11-03 01:40:41,727:INFO: Average training:	ADE  0.5422	FDE  1.1005
2022-11-03 01:40:41,738:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_578.pth.tar
2022-11-03 01:40:41,738:INFO: 
===> EPOCH: 579 (P4)
2022-11-03 01:40:41,738:INFO: - Computing loss (training)
2022-11-03 01:40:42,853:INFO: Batch:  0/31	Total Loss -52.0676 (-52.0676)
2022-11-03 01:40:43,361:INFO: Batch:  1/31	Total Loss -62.7764 (-57.4887)
2022-11-03 01:40:43,863:INFO: Batch:  2/31	Total Loss -44.8316 (-53.5044)
2022-11-03 01:40:44,367:INFO: Batch:  3/31	Total Loss -62.5644 (-55.9796)
2022-11-03 01:40:44,868:INFO: Batch:  4/31	Total Loss -56.3635 (-56.0513)
2022-11-03 01:40:45,373:INFO: Batch:  5/31	Total Loss -52.8689 (-55.5343)
2022-11-03 01:40:45,873:INFO: Batch:  6/31	Total Loss -57.6694 (-55.8297)
2022-11-03 01:40:46,371:INFO: Batch:  7/31	Total Loss -53.7718 (-55.5775)
2022-11-03 01:40:46,873:INFO: Batch:  8/31	Total Loss -56.5095 (-55.6781)
2022-11-03 01:40:47,373:INFO: Batch:  9/31	Total Loss -53.9255 (-55.4892)
2022-11-03 01:40:47,872:INFO: Batch: 10/31	Total Loss -44.9687 (-54.5612)
2022-11-03 01:40:48,373:INFO: Batch: 11/31	Total Loss -63.7843 (-55.3897)
2022-11-03 01:40:48,876:INFO: Batch: 12/31	Total Loss -30.6904 (-53.4367)
2022-11-03 01:40:49,377:INFO: Batch: 13/31	Total Loss -44.3485 (-52.7872)
2022-11-03 01:40:49,880:INFO: Batch: 14/31	Total Loss -47.1724 (-52.4187)
2022-11-03 01:40:50,385:INFO: Batch: 15/31	Total Loss -40.2850 (-51.7351)
2022-11-03 01:40:50,890:INFO: Batch: 16/31	Total Loss -54.3344 (-51.9013)
2022-11-03 01:40:51,390:INFO: Batch: 17/31	Total Loss -50.9972 (-51.8498)
2022-11-03 01:40:51,894:INFO: Batch: 18/31	Total Loss -32.7621 (-50.8449)
2022-11-03 01:40:52,398:INFO: Batch: 19/31	Total Loss -24.7826 (-49.6434)
2022-11-03 01:40:52,905:INFO: Batch: 20/31	Total Loss -36.2890 (-48.9926)
2022-11-03 01:40:53,409:INFO: Batch: 21/31	Total Loss -37.9148 (-48.5026)
2022-11-03 01:40:53,910:INFO: Batch: 22/31	Total Loss -40.9966 (-48.1601)
2022-11-03 01:40:54,408:INFO: Batch: 23/31	Total Loss -39.2972 (-47.8220)
2022-11-03 01:40:54,914:INFO: Batch: 24/31	Total Loss -48.7936 (-47.8604)
2022-11-03 01:40:55,410:INFO: Batch: 25/31	Total Loss -43.5122 (-47.6760)
2022-11-03 01:40:55,906:INFO: Batch: 26/31	Total Loss -43.5469 (-47.5345)
2022-11-03 01:40:56,402:INFO: Batch: 27/31	Total Loss -48.0879 (-47.5542)
2022-11-03 01:40:56,899:INFO: Batch: 28/31	Total Loss -63.4606 (-48.1237)
2022-11-03 01:40:57,394:INFO: Batch: 29/31	Total Loss -37.9523 (-47.8302)
2022-11-03 01:40:57,784:INFO: Batch: 30/31	Total Loss -64.6380 (-48.0043)
2022-11-03 01:40:57,931:INFO: - Computing ADE (validation o)
2022-11-03 01:40:58,606:INFO: 		 ADE on eth                       dataset:	 0.9477666020393372
2022-11-03 01:40:58,606:INFO: Average validation o:	ADE  0.9478	FDE  1.9024
2022-11-03 01:40:58,607:INFO: - Computing ADE (validation)
2022-11-03 01:40:58,909:INFO: 		 ADE on hotel                     dataset:	 0.5454795956611633
2022-11-03 01:40:59,272:INFO: 		 ADE on univ                      dataset:	 0.5713465213775635
2022-11-03 01:40:59,580:INFO: 		 ADE on zara1                     dataset:	 0.41902661323547363
2022-11-03 01:41:00,054:INFO: 		 ADE on zara2                     dataset:	 0.4140179455280304
2022-11-03 01:41:00,054:INFO: Average validation:	ADE  0.5034	FDE  1.0282
2022-11-03 01:41:00,054:INFO: - Computing ADE (training)
2022-11-03 01:41:00,620:INFO: 		 ADE on hotel                     dataset:	 0.5997899174690247
2022-11-03 01:41:01,656:INFO: 		 ADE on univ                      dataset:	 0.5598592162132263
2022-11-03 01:41:02,413:INFO: 		 ADE on zara1                     dataset:	 0.48505130410194397
2022-11-03 01:41:03,641:INFO: 		 ADE on zara2                     dataset:	 0.4144573509693146
2022-11-03 01:41:03,642:INFO: Average training:	ADE  0.5266	FDE  1.0783
2022-11-03 01:41:03,653:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_579.pth.tar
2022-11-03 01:41:03,653:INFO: 
===> EPOCH: 580 (P4)
2022-11-03 01:41:03,653:INFO: - Computing loss (training)
2022-11-03 01:41:04,766:INFO: Batch:  0/31	Total Loss -47.3900 (-47.3900)
2022-11-03 01:41:05,263:INFO: Batch:  1/31	Total Loss -62.1735 (-55.4000)
2022-11-03 01:41:05,768:INFO: Batch:  2/31	Total Loss -60.8176 (-57.2919)
2022-11-03 01:41:06,267:INFO: Batch:  3/31	Total Loss -38.7598 (-53.0763)
2022-11-03 01:41:06,766:INFO: Batch:  4/31	Total Loss -61.8625 (-54.8905)
2022-11-03 01:41:07,265:INFO: Batch:  5/31	Total Loss -54.5745 (-54.8393)
2022-11-03 01:41:07,764:INFO: Batch:  6/31	Total Loss -55.2637 (-54.8982)
2022-11-03 01:41:08,264:INFO: Batch:  7/31	Total Loss -30.4494 (-52.0125)
2022-11-03 01:41:08,762:INFO: Batch:  8/31	Total Loss -58.6216 (-52.7210)
2022-11-03 01:41:09,259:INFO: Batch:  9/31	Total Loss -53.2657 (-52.7733)
2022-11-03 01:41:09,756:INFO: Batch: 10/31	Total Loss -56.7428 (-53.1365)
2022-11-03 01:41:10,253:INFO: Batch: 11/31	Total Loss -41.5563 (-52.2841)
2022-11-03 01:41:10,756:INFO: Batch: 12/31	Total Loss -32.1099 (-50.8479)
2022-11-03 01:41:11,257:INFO: Batch: 13/31	Total Loss -55.5945 (-51.1718)
2022-11-03 01:41:11,834:INFO: Batch: 14/31	Total Loss -43.2336 (-50.6909)
2022-11-03 01:41:12,333:INFO: Batch: 15/31	Total Loss -58.2828 (-51.1622)
2022-11-03 01:41:12,833:INFO: Batch: 16/31	Total Loss -52.9618 (-51.2655)
2022-11-03 01:41:13,332:INFO: Batch: 17/31	Total Loss -39.4998 (-50.6912)
2022-11-03 01:41:13,832:INFO: Batch: 18/31	Total Loss -40.5175 (-50.1868)
2022-11-03 01:41:14,332:INFO: Batch: 19/31	Total Loss -61.4043 (-50.7183)
2022-11-03 01:41:14,830:INFO: Batch: 20/31	Total Loss -48.8217 (-50.6413)
2022-11-03 01:41:15,330:INFO: Batch: 21/31	Total Loss -53.1450 (-50.7693)
2022-11-03 01:41:15,831:INFO: Batch: 22/31	Total Loss -55.4399 (-50.9577)
2022-11-03 01:41:16,334:INFO: Batch: 23/31	Total Loss -55.0383 (-51.1396)
2022-11-03 01:41:16,834:INFO: Batch: 24/31	Total Loss -50.4654 (-51.1141)
2022-11-03 01:41:17,332:INFO: Batch: 25/31	Total Loss -31.2407 (-50.3915)
2022-11-03 01:41:17,830:INFO: Batch: 26/31	Total Loss -44.0678 (-50.1680)
2022-11-03 01:41:18,329:INFO: Batch: 27/31	Total Loss -63.9732 (-50.7053)
2022-11-03 01:41:18,827:INFO: Batch: 28/31	Total Loss -71.1787 (-51.4660)
2022-11-03 01:41:19,327:INFO: Batch: 29/31	Total Loss -43.5181 (-51.2112)
2022-11-03 01:41:19,720:INFO: Batch: 30/31	Total Loss -63.0856 (-51.3158)
2022-11-03 01:41:19,879:INFO: - Computing ADE (validation o)
2022-11-03 01:41:20,547:INFO: 		 ADE on eth                       dataset:	 0.957287073135376
2022-11-03 01:41:20,548:INFO: Average validation o:	ADE  0.9573	FDE  1.9028
2022-11-03 01:41:20,548:INFO: - Computing ADE (validation)
2022-11-03 01:41:20,857:INFO: 		 ADE on hotel                     dataset:	 0.5588499307632446
2022-11-03 01:41:21,237:INFO: 		 ADE on univ                      dataset:	 0.5718995332717896
2022-11-03 01:41:21,516:INFO: 		 ADE on zara1                     dataset:	 0.42798787355422974
2022-11-03 01:41:21,992:INFO: 		 ADE on zara2                     dataset:	 0.42571333050727844
2022-11-03 01:41:21,992:INFO: Average validation:	ADE  0.5092	FDE  1.0412
2022-11-03 01:41:21,993:INFO: - Computing ADE (training)
2022-11-03 01:41:22,594:INFO: 		 ADE on hotel                     dataset:	 0.6111997365951538
2022-11-03 01:41:23,635:INFO: 		 ADE on univ                      dataset:	 0.5608532428741455
2022-11-03 01:41:24,362:INFO: 		 ADE on zara1                     dataset:	 0.4944939911365509
2022-11-03 01:41:25,552:INFO: 		 ADE on zara2                     dataset:	 0.42963701486587524
2022-11-03 01:41:25,552:INFO: Average training:	ADE  0.5313	FDE  1.0889
2022-11-03 01:41:25,564:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_580.pth.tar
2022-11-03 01:41:25,564:INFO: 
===> EPOCH: 581 (P4)
2022-11-03 01:41:25,565:INFO: - Computing loss (training)
2022-11-03 01:41:26,674:INFO: Batch:  0/31	Total Loss -47.9890 (-47.9890)
2022-11-03 01:41:27,167:INFO: Batch:  1/31	Total Loss -47.7885 (-47.8895)
2022-11-03 01:41:27,663:INFO: Batch:  2/31	Total Loss -55.7329 (-50.7603)
2022-11-03 01:41:28,152:INFO: Batch:  3/31	Total Loss -57.7181 (-52.4854)
2022-11-03 01:41:28,640:INFO: Batch:  4/31	Total Loss -42.6059 (-50.6403)
2022-11-03 01:41:29,134:INFO: Batch:  5/31	Total Loss -60.8179 (-52.5296)
2022-11-03 01:41:29,626:INFO: Batch:  6/31	Total Loss -53.2239 (-52.6306)
2022-11-03 01:41:30,115:INFO: Batch:  7/31	Total Loss -65.5777 (-54.4293)
2022-11-03 01:41:30,609:INFO: Batch:  8/31	Total Loss -65.2038 (-55.7199)
2022-11-03 01:41:31,099:INFO: Batch:  9/31	Total Loss -67.1850 (-57.0431)
2022-11-03 01:41:31,590:INFO: Batch: 10/31	Total Loss -58.0241 (-57.1316)
2022-11-03 01:41:32,080:INFO: Batch: 11/31	Total Loss -57.5964 (-57.1724)
2022-11-03 01:41:32,571:INFO: Batch: 12/31	Total Loss -60.0728 (-57.4011)
2022-11-03 01:41:33,062:INFO: Batch: 13/31	Total Loss -57.9499 (-57.4380)
2022-11-03 01:41:33,555:INFO: Batch: 14/31	Total Loss -64.4839 (-57.8801)
2022-11-03 01:41:34,048:INFO: Batch: 15/31	Total Loss -63.9265 (-58.2905)
2022-11-03 01:41:34,540:INFO: Batch: 16/31	Total Loss -62.5931 (-58.5581)
2022-11-03 01:41:35,031:INFO: Batch: 17/31	Total Loss -38.2388 (-57.5070)
2022-11-03 01:41:35,523:INFO: Batch: 18/31	Total Loss -34.5550 (-56.3793)
2022-11-03 01:41:36,017:INFO: Batch: 19/31	Total Loss -60.9774 (-56.6086)
2022-11-03 01:41:36,509:INFO: Batch: 20/31	Total Loss -37.1702 (-55.7819)
2022-11-03 01:41:37,002:INFO: Batch: 21/31	Total Loss -43.6157 (-55.2780)
2022-11-03 01:41:37,493:INFO: Batch: 22/31	Total Loss -59.7230 (-55.4737)
2022-11-03 01:41:37,988:INFO: Batch: 23/31	Total Loss -41.5310 (-54.9586)
2022-11-03 01:41:38,481:INFO: Batch: 24/31	Total Loss -64.4214 (-55.3375)
2022-11-03 01:41:38,973:INFO: Batch: 25/31	Total Loss -48.0461 (-55.0939)
2022-11-03 01:41:39,467:INFO: Batch: 26/31	Total Loss -46.6545 (-54.7632)
2022-11-03 01:41:39,960:INFO: Batch: 27/31	Total Loss -65.9506 (-55.1705)
2022-11-03 01:41:40,454:INFO: Batch: 28/31	Total Loss -56.3856 (-55.2153)
2022-11-03 01:41:40,947:INFO: Batch: 29/31	Total Loss -60.5231 (-55.4073)
2022-11-03 01:41:41,335:INFO: Batch: 30/31	Total Loss -61.7787 (-55.4656)
2022-11-03 01:41:41,484:INFO: - Computing ADE (validation o)
2022-11-03 01:41:42,200:INFO: 		 ADE on eth                       dataset:	 0.9215760827064514
2022-11-03 01:41:42,200:INFO: Average validation o:	ADE  0.9216	FDE  1.8747
2022-11-03 01:41:42,201:INFO: - Computing ADE (validation)
2022-11-03 01:41:42,504:INFO: 		 ADE on hotel                     dataset:	 0.5637049674987793
2022-11-03 01:41:42,880:INFO: 		 ADE on univ                      dataset:	 0.5772945880889893
2022-11-03 01:41:43,172:INFO: 		 ADE on zara1                     dataset:	 0.42816779017448425
2022-11-03 01:41:43,651:INFO: 		 ADE on zara2                     dataset:	 0.4219180941581726
2022-11-03 01:41:43,651:INFO: Average validation:	ADE  0.5109	FDE  1.0588
2022-11-03 01:41:43,652:INFO: - Computing ADE (training)
2022-11-03 01:41:44,230:INFO: 		 ADE on hotel                     dataset:	 0.6189894676208496
2022-11-03 01:41:45,271:INFO: 		 ADE on univ                      dataset:	 0.5665081739425659
2022-11-03 01:41:46,024:INFO: 		 ADE on zara1                     dataset:	 0.46579042077064514
2022-11-03 01:41:47,183:INFO: 		 ADE on zara2                     dataset:	 0.4128846526145935
2022-11-03 01:41:47,183:INFO: Average training:	ADE  0.5302	FDE  1.0993
2022-11-03 01:41:47,194:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_581.pth.tar
2022-11-03 01:41:47,194:INFO: 
===> EPOCH: 582 (P4)
2022-11-03 01:41:47,195:INFO: - Computing loss (training)
2022-11-03 01:41:48,323:INFO: Batch:  0/31	Total Loss -58.4984 (-58.4984)
2022-11-03 01:41:48,821:INFO: Batch:  1/31	Total Loss -54.7345 (-56.6749)
2022-11-03 01:41:49,329:INFO: Batch:  2/31	Total Loss -60.7997 (-58.0742)
2022-11-03 01:41:49,829:INFO: Batch:  3/31	Total Loss -59.3876 (-58.3994)
2022-11-03 01:41:50,329:INFO: Batch:  4/31	Total Loss -65.8192 (-59.9751)
2022-11-03 01:41:50,834:INFO: Batch:  5/31	Total Loss -57.2262 (-59.5268)
2022-11-03 01:41:51,335:INFO: Batch:  6/31	Total Loss -58.2541 (-59.3539)
2022-11-03 01:41:51,836:INFO: Batch:  7/31	Total Loss -52.5706 (-58.5457)
2022-11-03 01:41:52,339:INFO: Batch:  8/31	Total Loss -68.8357 (-59.7667)
2022-11-03 01:41:52,842:INFO: Batch:  9/31	Total Loss -49.3781 (-58.6418)
2022-11-03 01:41:53,340:INFO: Batch: 10/31	Total Loss -54.4749 (-58.2593)
2022-11-03 01:41:53,838:INFO: Batch: 11/31	Total Loss -49.5707 (-57.5289)
2022-11-03 01:41:54,342:INFO: Batch: 12/31	Total Loss -65.0119 (-58.1326)
2022-11-03 01:41:54,844:INFO: Batch: 13/31	Total Loss -56.9147 (-58.0420)
2022-11-03 01:41:55,347:INFO: Batch: 14/31	Total Loss -41.2274 (-56.9430)
2022-11-03 01:41:55,850:INFO: Batch: 15/31	Total Loss -63.9366 (-57.3930)
2022-11-03 01:41:56,352:INFO: Batch: 16/31	Total Loss -56.5663 (-57.3446)
2022-11-03 01:41:56,854:INFO: Batch: 17/31	Total Loss -50.4974 (-57.0040)
2022-11-03 01:41:57,355:INFO: Batch: 18/31	Total Loss -68.9096 (-57.6629)
2022-11-03 01:41:57,861:INFO: Batch: 19/31	Total Loss -53.7327 (-57.4683)
2022-11-03 01:41:58,363:INFO: Batch: 20/31	Total Loss -60.6928 (-57.6323)
2022-11-03 01:41:58,868:INFO: Batch: 21/31	Total Loss -59.1453 (-57.7029)
2022-11-03 01:41:59,373:INFO: Batch: 22/31	Total Loss -53.6338 (-57.5255)
2022-11-03 01:41:59,875:INFO: Batch: 23/31	Total Loss -64.2508 (-57.8049)
2022-11-03 01:42:00,377:INFO: Batch: 24/31	Total Loss -65.8622 (-58.1462)
2022-11-03 01:42:00,883:INFO: Batch: 25/31	Total Loss -56.9517 (-58.1026)
2022-11-03 01:42:01,380:INFO: Batch: 26/31	Total Loss -47.0442 (-57.6874)
2022-11-03 01:42:01,873:INFO: Batch: 27/31	Total Loss -65.4631 (-57.9911)
2022-11-03 01:42:02,363:INFO: Batch: 28/31	Total Loss -47.8773 (-57.6667)
2022-11-03 01:42:02,855:INFO: Batch: 29/31	Total Loss -62.2968 (-57.8243)
2022-11-03 01:42:03,241:INFO: Batch: 30/31	Total Loss -67.3513 (-57.9095)
2022-11-03 01:42:03,396:INFO: - Computing ADE (validation o)
2022-11-03 01:42:04,142:INFO: 		 ADE on eth                       dataset:	 0.9431586861610413
2022-11-03 01:42:04,142:INFO: Average validation o:	ADE  0.9432	FDE  1.9357
2022-11-03 01:42:04,142:INFO: - Computing ADE (validation)
2022-11-03 01:42:04,458:INFO: 		 ADE on hotel                     dataset:	 0.5345632433891296
2022-11-03 01:42:04,836:INFO: 		 ADE on univ                      dataset:	 0.5691876411437988
2022-11-03 01:42:05,119:INFO: 		 ADE on zara1                     dataset:	 0.4323790371417999
2022-11-03 01:42:05,604:INFO: 		 ADE on zara2                     dataset:	 0.43064045906066895
2022-11-03 01:42:05,605:INFO: Average validation:	ADE  0.5085	FDE  1.0634
2022-11-03 01:42:05,605:INFO: - Computing ADE (training)
2022-11-03 01:42:06,167:INFO: 		 ADE on hotel                     dataset:	 0.578580379486084
2022-11-03 01:42:07,191:INFO: 		 ADE on univ                      dataset:	 0.5645768642425537
2022-11-03 01:42:07,936:INFO: 		 ADE on zara1                     dataset:	 0.473355233669281
2022-11-03 01:42:09,111:INFO: 		 ADE on zara2                     dataset:	 0.42589548230171204
2022-11-03 01:42:09,111:INFO: Average training:	ADE  0.5310	FDE  1.1141
2022-11-03 01:42:09,122:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_582.pth.tar
2022-11-03 01:42:09,122:INFO: 
===> EPOCH: 583 (P4)
2022-11-03 01:42:09,123:INFO: - Computing loss (training)
2022-11-03 01:42:10,224:INFO: Batch:  0/31	Total Loss -66.2665 (-66.2665)
2022-11-03 01:42:10,722:INFO: Batch:  1/31	Total Loss -49.8761 (-58.3887)
2022-11-03 01:42:11,217:INFO: Batch:  2/31	Total Loss -53.8712 (-56.9680)
2022-11-03 01:42:11,710:INFO: Batch:  3/31	Total Loss -69.8052 (-60.3998)
2022-11-03 01:42:12,273:INFO: Batch:  4/31	Total Loss -65.4225 (-61.3593)
2022-11-03 01:42:12,764:INFO: Batch:  5/31	Total Loss -47.4714 (-59.3531)
2022-11-03 01:42:13,252:INFO: Batch:  6/31	Total Loss -52.7920 (-58.4931)
2022-11-03 01:42:13,744:INFO: Batch:  7/31	Total Loss -59.1792 (-58.5829)
2022-11-03 01:42:14,235:INFO: Batch:  8/31	Total Loss -52.1800 (-57.8348)
2022-11-03 01:42:14,726:INFO: Batch:  9/31	Total Loss -66.9228 (-58.7502)
2022-11-03 01:42:15,218:INFO: Batch: 10/31	Total Loss -49.8799 (-57.9712)
2022-11-03 01:42:15,707:INFO: Batch: 11/31	Total Loss -63.3788 (-58.4488)
2022-11-03 01:42:16,202:INFO: Batch: 12/31	Total Loss -59.5717 (-58.5415)
2022-11-03 01:42:16,696:INFO: Batch: 13/31	Total Loss -66.4026 (-59.0939)
2022-11-03 01:42:17,188:INFO: Batch: 14/31	Total Loss -66.7967 (-59.6473)
2022-11-03 01:42:17,681:INFO: Batch: 15/31	Total Loss -57.8178 (-59.5255)
2022-11-03 01:42:18,173:INFO: Batch: 16/31	Total Loss -50.4059 (-59.0063)
2022-11-03 01:42:18,665:INFO: Batch: 17/31	Total Loss -66.3572 (-59.4176)
2022-11-03 01:42:19,161:INFO: Batch: 18/31	Total Loss -59.2167 (-59.4077)
2022-11-03 01:42:19,653:INFO: Batch: 19/31	Total Loss -68.4522 (-59.8890)
2022-11-03 01:42:20,147:INFO: Batch: 20/31	Total Loss -67.6561 (-60.2532)
2022-11-03 01:42:20,643:INFO: Batch: 21/31	Total Loss -56.0100 (-60.0697)
2022-11-03 01:42:21,136:INFO: Batch: 22/31	Total Loss -54.5647 (-59.8296)
2022-11-03 01:42:21,628:INFO: Batch: 23/31	Total Loss -72.8815 (-60.4418)
2022-11-03 01:42:22,118:INFO: Batch: 24/31	Total Loss -73.7564 (-60.9965)
2022-11-03 01:42:22,618:INFO: Batch: 25/31	Total Loss -59.7759 (-60.9514)
2022-11-03 01:42:23,117:INFO: Batch: 26/31	Total Loss -57.1637 (-60.8100)
2022-11-03 01:42:23,619:INFO: Batch: 27/31	Total Loss -72.3271 (-61.2161)
2022-11-03 01:42:24,118:INFO: Batch: 28/31	Total Loss -47.2864 (-60.7045)
2022-11-03 01:42:24,617:INFO: Batch: 29/31	Total Loss -48.5759 (-60.3698)
2022-11-03 01:42:25,011:INFO: Batch: 30/31	Total Loss -75.7794 (-60.5378)
2022-11-03 01:42:25,171:INFO: - Computing ADE (validation o)
2022-11-03 01:42:25,860:INFO: 		 ADE on eth                       dataset:	 0.9200459122657776
2022-11-03 01:42:25,861:INFO: Average validation o:	ADE  0.9200	FDE  1.8926
2022-11-03 01:42:25,861:INFO: - Computing ADE (validation)
2022-11-03 01:42:26,166:INFO: 		 ADE on hotel                     dataset:	 0.5230631828308105
2022-11-03 01:42:26,531:INFO: 		 ADE on univ                      dataset:	 0.5622538328170776
2022-11-03 01:42:26,812:INFO: 		 ADE on zara1                     dataset:	 0.4228523373603821
2022-11-03 01:42:27,274:INFO: 		 ADE on zara2                     dataset:	 0.409654438495636
2022-11-03 01:42:27,274:INFO: Average validation:	ADE  0.4960	FDE  1.0335
2022-11-03 01:42:27,275:INFO: - Computing ADE (training)
2022-11-03 01:42:27,850:INFO: 		 ADE on hotel                     dataset:	 0.567315936088562
2022-11-03 01:42:28,910:INFO: 		 ADE on univ                      dataset:	 0.5514547228813171
2022-11-03 01:42:29,690:INFO: 		 ADE on zara1                     dataset:	 0.45039746165275574
2022-11-03 01:42:30,856:INFO: 		 ADE on zara2                     dataset:	 0.39820894598960876
2022-11-03 01:42:30,856:INFO: Average training:	ADE  0.5143	FDE  1.0730
2022-11-03 01:42:30,867:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_583.pth.tar
2022-11-03 01:42:30,867:INFO: 
===> EPOCH: 584 (P4)
2022-11-03 01:42:30,868:INFO: - Computing loss (training)
2022-11-03 01:42:32,001:INFO: Batch:  0/31	Total Loss -46.8857 (-46.8857)
2022-11-03 01:42:32,520:INFO: Batch:  1/31	Total Loss -62.7106 (-55.0752)
2022-11-03 01:42:33,031:INFO: Batch:  2/31	Total Loss -65.5550 (-58.8383)
2022-11-03 01:42:33,527:INFO: Batch:  3/31	Total Loss -83.0324 (-65.3379)
2022-11-03 01:42:34,025:INFO: Batch:  4/31	Total Loss -59.2541 (-64.2128)
2022-11-03 01:42:34,517:INFO: Batch:  5/31	Total Loss -44.5518 (-60.8335)
2022-11-03 01:42:35,014:INFO: Batch:  6/31	Total Loss -80.7627 (-63.7328)
2022-11-03 01:42:35,505:INFO: Batch:  7/31	Total Loss -61.9921 (-63.5288)
2022-11-03 01:42:35,996:INFO: Batch:  8/31	Total Loss -48.8036 (-62.0272)
2022-11-03 01:42:36,491:INFO: Batch:  9/31	Total Loss -63.0249 (-62.1293)
2022-11-03 01:42:36,987:INFO: Batch: 10/31	Total Loss -52.4929 (-61.2709)
2022-11-03 01:42:37,477:INFO: Batch: 11/31	Total Loss -50.6952 (-60.4189)
2022-11-03 01:42:37,975:INFO: Batch: 12/31	Total Loss -46.0451 (-59.4605)
2022-11-03 01:42:38,473:INFO: Batch: 13/31	Total Loss -52.0404 (-58.9276)
2022-11-03 01:42:38,968:INFO: Batch: 14/31	Total Loss -70.7151 (-59.7387)
2022-11-03 01:42:39,464:INFO: Batch: 15/31	Total Loss -62.8839 (-59.9351)
2022-11-03 01:42:39,961:INFO: Batch: 16/31	Total Loss -74.4545 (-60.8383)
2022-11-03 01:42:40,457:INFO: Batch: 17/31	Total Loss -56.9426 (-60.6049)
2022-11-03 01:42:40,956:INFO: Batch: 18/31	Total Loss -59.5478 (-60.5533)
2022-11-03 01:42:41,452:INFO: Batch: 19/31	Total Loss -55.2691 (-60.3088)
2022-11-03 01:42:41,948:INFO: Batch: 20/31	Total Loss -68.5577 (-60.6978)
2022-11-03 01:42:42,444:INFO: Batch: 21/31	Total Loss -68.8404 (-61.0790)
2022-11-03 01:42:42,941:INFO: Batch: 22/31	Total Loss -39.3947 (-60.1644)
2022-11-03 01:42:43,432:INFO: Batch: 23/31	Total Loss -41.2210 (-59.5320)
2022-11-03 01:42:43,929:INFO: Batch: 24/31	Total Loss -64.6142 (-59.7354)
2022-11-03 01:42:44,425:INFO: Batch: 25/31	Total Loss -60.5663 (-59.7667)
2022-11-03 01:42:44,921:INFO: Batch: 26/31	Total Loss -49.8537 (-59.4686)
2022-11-03 01:42:45,417:INFO: Batch: 27/31	Total Loss -60.0743 (-59.4913)
2022-11-03 01:42:45,912:INFO: Batch: 28/31	Total Loss -57.3379 (-59.4199)
2022-11-03 01:42:46,407:INFO: Batch: 29/31	Total Loss -54.2083 (-59.2426)
2022-11-03 01:42:46,800:INFO: Batch: 30/31	Total Loss -74.5563 (-59.4150)
2022-11-03 01:42:46,951:INFO: - Computing ADE (validation o)
2022-11-03 01:42:47,631:INFO: 		 ADE on eth                       dataset:	 0.9341115951538086
2022-11-03 01:42:47,632:INFO: Average validation o:	ADE  0.9341	FDE  1.9026
2022-11-03 01:42:47,632:INFO: - Computing ADE (validation)
2022-11-03 01:42:47,944:INFO: 		 ADE on hotel                     dataset:	 0.5235517621040344
2022-11-03 01:42:48,327:INFO: 		 ADE on univ                      dataset:	 0.5598172545433044
2022-11-03 01:42:48,612:INFO: 		 ADE on zara1                     dataset:	 0.42453786730766296
2022-11-03 01:42:49,072:INFO: 		 ADE on zara2                     dataset:	 0.41490891575813293
2022-11-03 01:42:49,073:INFO: Average validation:	ADE  0.4968	FDE  1.0337
2022-11-03 01:42:49,073:INFO: - Computing ADE (training)
2022-11-03 01:42:49,628:INFO: 		 ADE on hotel                     dataset:	 0.5630727410316467
2022-11-03 01:42:50,711:INFO: 		 ADE on univ                      dataset:	 0.5522546172142029
2022-11-03 01:42:51,440:INFO: 		 ADE on zara1                     dataset:	 0.4619116187095642
2022-11-03 01:42:52,667:INFO: 		 ADE on zara2                     dataset:	 0.40867355465888977
2022-11-03 01:42:52,668:INFO: Average training:	ADE  0.5176	FDE  1.0799
2022-11-03 01:42:52,679:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_584.pth.tar
2022-11-03 01:42:52,679:INFO: 
===> EPOCH: 585 (P4)
2022-11-03 01:42:52,679:INFO: - Computing loss (training)
2022-11-03 01:42:53,802:INFO: Batch:  0/31	Total Loss -45.0879 (-45.0879)
2022-11-03 01:42:54,299:INFO: Batch:  1/31	Total Loss -47.6116 (-46.3388)
2022-11-03 01:42:54,804:INFO: Batch:  2/31	Total Loss -61.8979 (-51.8704)
2022-11-03 01:42:55,293:INFO: Batch:  3/31	Total Loss -42.4676 (-49.3721)
2022-11-03 01:42:55,787:INFO: Batch:  4/31	Total Loss -58.5150 (-51.3209)
2022-11-03 01:42:56,280:INFO: Batch:  5/31	Total Loss -58.4621 (-52.5515)
2022-11-03 01:42:56,770:INFO: Batch:  6/31	Total Loss -54.2908 (-52.8043)
2022-11-03 01:42:57,262:INFO: Batch:  7/31	Total Loss -56.6330 (-53.3617)
2022-11-03 01:42:57,757:INFO: Batch:  8/31	Total Loss -60.7985 (-54.2089)
2022-11-03 01:42:58,245:INFO: Batch:  9/31	Total Loss -69.0184 (-55.8365)
2022-11-03 01:42:58,736:INFO: Batch: 10/31	Total Loss -65.1566 (-56.6654)
2022-11-03 01:42:59,226:INFO: Batch: 11/31	Total Loss -69.9664 (-57.8183)
2022-11-03 01:42:59,721:INFO: Batch: 12/31	Total Loss -65.2093 (-58.3741)
2022-11-03 01:43:00,216:INFO: Batch: 13/31	Total Loss -67.1804 (-59.0049)
2022-11-03 01:43:00,713:INFO: Batch: 14/31	Total Loss -51.9518 (-58.5691)
2022-11-03 01:43:01,212:INFO: Batch: 15/31	Total Loss -52.9719 (-58.1958)
2022-11-03 01:43:01,707:INFO: Batch: 16/31	Total Loss -55.7672 (-58.0757)
2022-11-03 01:43:02,204:INFO: Batch: 17/31	Total Loss -75.2340 (-59.0561)
2022-11-03 01:43:02,699:INFO: Batch: 18/31	Total Loss -64.3068 (-59.3283)
2022-11-03 01:43:03,192:INFO: Batch: 19/31	Total Loss -70.1855 (-59.9191)
2022-11-03 01:43:03,686:INFO: Batch: 20/31	Total Loss -77.7215 (-60.8527)
2022-11-03 01:43:04,178:INFO: Batch: 21/31	Total Loss -53.2112 (-60.5272)
2022-11-03 01:43:04,670:INFO: Batch: 22/31	Total Loss -61.4319 (-60.5679)
2022-11-03 01:43:05,163:INFO: Batch: 23/31	Total Loss -58.8134 (-60.4981)
2022-11-03 01:43:05,657:INFO: Batch: 24/31	Total Loss -70.9962 (-60.9077)
2022-11-03 01:43:06,150:INFO: Batch: 25/31	Total Loss -50.7782 (-60.5200)
2022-11-03 01:43:06,645:INFO: Batch: 26/31	Total Loss -66.8956 (-60.7644)
2022-11-03 01:43:07,139:INFO: Batch: 27/31	Total Loss -70.3100 (-61.1218)
2022-11-03 01:43:07,634:INFO: Batch: 28/31	Total Loss -53.5397 (-60.8371)
2022-11-03 01:43:08,126:INFO: Batch: 29/31	Total Loss -66.8817 (-61.0644)
2022-11-03 01:43:08,515:INFO: Batch: 30/31	Total Loss -66.8616 (-61.1155)
2022-11-03 01:43:08,665:INFO: - Computing ADE (validation o)
2022-11-03 01:43:09,366:INFO: 		 ADE on eth                       dataset:	 0.9332504272460938
2022-11-03 01:43:09,367:INFO: Average validation o:	ADE  0.9333	FDE  1.8791
2022-11-03 01:43:09,367:INFO: - Computing ADE (validation)
2022-11-03 01:43:09,676:INFO: 		 ADE on hotel                     dataset:	 0.5237305760383606
2022-11-03 01:43:10,036:INFO: 		 ADE on univ                      dataset:	 0.5575204491615295
2022-11-03 01:43:10,316:INFO: 		 ADE on zara1                     dataset:	 0.4254002571105957
2022-11-03 01:43:10,771:INFO: 		 ADE on zara2                     dataset:	 0.42054107785224915
2022-11-03 01:43:10,771:INFO: Average validation:	ADE  0.4977	FDE  1.0307
2022-11-03 01:43:10,772:INFO: - Computing ADE (training)
2022-11-03 01:43:11,368:INFO: 		 ADE on hotel                     dataset:	 0.5628756880760193
2022-11-03 01:43:12,392:INFO: 		 ADE on univ                      dataset:	 0.549002468585968
2022-11-03 01:43:13,216:INFO: 		 ADE on zara1                     dataset:	 0.48030781745910645
2022-11-03 01:43:14,438:INFO: 		 ADE on zara2                     dataset:	 0.4205964207649231
2022-11-03 01:43:14,438:INFO: Average training:	ADE  0.5189	FDE  1.0778
2022-11-03 01:43:14,449:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_585.pth.tar
2022-11-03 01:43:14,449:INFO: 
===> EPOCH: 586 (P4)
2022-11-03 01:43:14,450:INFO: - Computing loss (training)
2022-11-03 01:43:15,551:INFO: Batch:  0/31	Total Loss -47.7961 (-47.7961)
2022-11-03 01:43:16,049:INFO: Batch:  1/31	Total Loss -79.1224 (-64.1991)
2022-11-03 01:43:16,546:INFO: Batch:  2/31	Total Loss -63.3568 (-63.9135)
2022-11-03 01:43:17,036:INFO: Batch:  3/31	Total Loss -61.1235 (-63.2514)
2022-11-03 01:43:17,522:INFO: Batch:  4/31	Total Loss -77.6251 (-65.9673)
2022-11-03 01:43:18,017:INFO: Batch:  5/31	Total Loss -74.1007 (-67.4492)
2022-11-03 01:43:18,506:INFO: Batch:  6/31	Total Loss -61.3044 (-66.5512)
2022-11-03 01:43:18,999:INFO: Batch:  7/31	Total Loss -83.9107 (-68.9184)
2022-11-03 01:43:19,489:INFO: Batch:  8/31	Total Loss -67.1965 (-68.7175)
2022-11-03 01:43:19,981:INFO: Batch:  9/31	Total Loss -68.7659 (-68.7221)
2022-11-03 01:43:20,471:INFO: Batch: 10/31	Total Loss -62.8261 (-68.2491)
2022-11-03 01:43:20,963:INFO: Batch: 11/31	Total Loss -17.9406 (-64.7079)
2022-11-03 01:43:21,456:INFO: Batch: 12/31	Total Loss -75.0628 (-65.6549)
2022-11-03 01:43:21,947:INFO: Batch: 13/31	Total Loss -52.0571 (-64.6717)
2022-11-03 01:43:22,440:INFO: Batch: 14/31	Total Loss -57.5392 (-64.2495)
2022-11-03 01:43:22,933:INFO: Batch: 15/31	Total Loss -68.1902 (-64.4979)
2022-11-03 01:43:23,425:INFO: Batch: 16/31	Total Loss -56.0065 (-64.0077)
2022-11-03 01:43:23,919:INFO: Batch: 17/31	Total Loss -54.9780 (-63.4933)
2022-11-03 01:43:24,412:INFO: Batch: 18/31	Total Loss -52.6162 (-62.9957)
2022-11-03 01:43:24,905:INFO: Batch: 19/31	Total Loss -61.6912 (-62.9301)
2022-11-03 01:43:25,399:INFO: Batch: 20/31	Total Loss -59.7934 (-62.7760)
2022-11-03 01:43:25,893:INFO: Batch: 21/31	Total Loss -41.8948 (-61.7969)
2022-11-03 01:43:26,383:INFO: Batch: 22/31	Total Loss -59.6002 (-61.7019)
2022-11-03 01:43:26,876:INFO: Batch: 23/31	Total Loss -61.9275 (-61.7111)
2022-11-03 01:43:27,367:INFO: Batch: 24/31	Total Loss -73.7222 (-62.1778)
2022-11-03 01:43:27,859:INFO: Batch: 25/31	Total Loss -77.1146 (-62.7845)
2022-11-03 01:43:28,351:INFO: Batch: 26/31	Total Loss -69.4473 (-63.0319)
2022-11-03 01:43:28,845:INFO: Batch: 27/31	Total Loss -76.1389 (-63.4902)
2022-11-03 01:43:29,340:INFO: Batch: 28/31	Total Loss -56.8835 (-63.2522)
2022-11-03 01:43:29,835:INFO: Batch: 29/31	Total Loss -41.6244 (-62.5491)
2022-11-03 01:43:30,224:INFO: Batch: 30/31	Total Loss -62.2773 (-62.5461)
2022-11-03 01:43:30,375:INFO: - Computing ADE (validation o)
2022-11-03 01:43:31,060:INFO: 		 ADE on eth                       dataset:	 0.9262161254882812
2022-11-03 01:43:31,060:INFO: Average validation o:	ADE  0.9262	FDE  1.8738
2022-11-03 01:43:31,061:INFO: - Computing ADE (validation)
2022-11-03 01:43:31,366:INFO: 		 ADE on hotel                     dataset:	 0.5116397738456726
2022-11-03 01:43:31,727:INFO: 		 ADE on univ                      dataset:	 0.5552883148193359
2022-11-03 01:43:32,019:INFO: 		 ADE on zara1                     dataset:	 0.4276351034641266
2022-11-03 01:43:32,476:INFO: 		 ADE on zara2                     dataset:	 0.4083569645881653
2022-11-03 01:43:32,477:INFO: Average validation:	ADE  0.4916	FDE  1.0273
2022-11-03 01:43:32,477:INFO: - Computing ADE (training)
2022-11-03 01:43:33,044:INFO: 		 ADE on hotel                     dataset:	 0.5484318137168884
2022-11-03 01:43:34,083:INFO: 		 ADE on univ                      dataset:	 0.54631108045578
2022-11-03 01:43:34,856:INFO: 		 ADE on zara1                     dataset:	 0.46286284923553467
2022-11-03 01:43:36,092:INFO: 		 ADE on zara2                     dataset:	 0.4049665927886963
2022-11-03 01:43:36,092:INFO: Average training:	ADE  0.5124	FDE  1.0747
2022-11-03 01:43:36,103:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_586.pth.tar
2022-11-03 01:43:36,103:INFO: 
===> EPOCH: 587 (P4)
2022-11-03 01:43:36,104:INFO: - Computing loss (training)
2022-11-03 01:43:37,207:INFO: Batch:  0/31	Total Loss -64.3512 (-64.3512)
2022-11-03 01:43:37,707:INFO: Batch:  1/31	Total Loss -56.0352 (-59.9033)
2022-11-03 01:43:38,210:INFO: Batch:  2/31	Total Loss -52.0323 (-57.3558)
2022-11-03 01:43:38,705:INFO: Batch:  3/31	Total Loss -51.9157 (-55.8695)
2022-11-03 01:43:39,200:INFO: Batch:  4/31	Total Loss -54.8106 (-55.6480)
2022-11-03 01:43:39,699:INFO: Batch:  5/31	Total Loss -73.0610 (-58.8078)
2022-11-03 01:43:40,194:INFO: Batch:  6/31	Total Loss -79.8695 (-62.1068)
2022-11-03 01:43:40,692:INFO: Batch:  7/31	Total Loss -60.3922 (-61.8954)
2022-11-03 01:43:41,191:INFO: Batch:  8/31	Total Loss -48.5092 (-60.5068)
2022-11-03 01:43:41,686:INFO: Batch:  9/31	Total Loss -65.7546 (-61.0781)
2022-11-03 01:43:42,185:INFO: Batch: 10/31	Total Loss -73.9099 (-62.2575)
2022-11-03 01:43:42,682:INFO: Batch: 11/31	Total Loss -73.4867 (-63.2052)
2022-11-03 01:43:43,181:INFO: Batch: 12/31	Total Loss -63.8540 (-63.2546)
2022-11-03 01:43:43,679:INFO: Batch: 13/31	Total Loss -60.9316 (-63.1047)
2022-11-03 01:43:44,179:INFO: Batch: 14/31	Total Loss -79.5365 (-64.2094)
2022-11-03 01:43:44,677:INFO: Batch: 15/31	Total Loss -67.1681 (-64.4052)
2022-11-03 01:43:45,175:INFO: Batch: 16/31	Total Loss -57.4002 (-64.0284)
2022-11-03 01:43:45,673:INFO: Batch: 17/31	Total Loss -55.2080 (-63.5306)
2022-11-03 01:43:46,173:INFO: Batch: 18/31	Total Loss -73.3006 (-64.0535)
2022-11-03 01:43:46,673:INFO: Batch: 19/31	Total Loss -58.7364 (-63.8054)
2022-11-03 01:43:47,173:INFO: Batch: 20/31	Total Loss -72.2306 (-64.2068)
2022-11-03 01:43:47,671:INFO: Batch: 21/31	Total Loss -63.4781 (-64.1752)
2022-11-03 01:43:48,169:INFO: Batch: 22/31	Total Loss -94.4284 (-65.5794)
2022-11-03 01:43:48,667:INFO: Batch: 23/31	Total Loss -80.5710 (-66.2582)
2022-11-03 01:43:49,165:INFO: Batch: 24/31	Total Loss -68.8264 (-66.3639)
2022-11-03 01:43:49,663:INFO: Batch: 25/31	Total Loss -53.5710 (-65.9009)
2022-11-03 01:43:50,160:INFO: Batch: 26/31	Total Loss -53.7412 (-65.5137)
2022-11-03 01:43:50,658:INFO: Batch: 27/31	Total Loss -68.7405 (-65.6202)
2022-11-03 01:43:51,155:INFO: Batch: 28/31	Total Loss -60.9084 (-65.4697)
2022-11-03 01:43:51,652:INFO: Batch: 29/31	Total Loss -56.1587 (-65.1185)
2022-11-03 01:43:52,044:INFO: Batch: 30/31	Total Loss -64.3913 (-65.1108)
2022-11-03 01:43:52,194:INFO: - Computing ADE (validation o)
2022-11-03 01:43:52,878:INFO: 		 ADE on eth                       dataset:	 0.9223103523254395
2022-11-03 01:43:52,878:INFO: Average validation o:	ADE  0.9223	FDE  1.8826
2022-11-03 01:43:52,879:INFO: - Computing ADE (validation)
2022-11-03 01:43:53,188:INFO: 		 ADE on hotel                     dataset:	 0.5164565443992615
2022-11-03 01:43:53,568:INFO: 		 ADE on univ                      dataset:	 0.552497386932373
2022-11-03 01:43:53,854:INFO: 		 ADE on zara1                     dataset:	 0.4218538999557495
2022-11-03 01:43:54,333:INFO: 		 ADE on zara2                     dataset:	 0.41061118245124817
2022-11-03 01:43:54,333:INFO: Average validation:	ADE  0.4909	FDE  1.0253
2022-11-03 01:43:54,334:INFO: - Computing ADE (training)
2022-11-03 01:43:54,894:INFO: 		 ADE on hotel                     dataset:	 0.5502294301986694
2022-11-03 01:43:55,954:INFO: 		 ADE on univ                      dataset:	 0.5457402467727661
2022-11-03 01:43:56,709:INFO: 		 ADE on zara1                     dataset:	 0.4567531943321228
2022-11-03 01:43:57,928:INFO: 		 ADE on zara2                     dataset:	 0.40356749296188354
2022-11-03 01:43:57,929:INFO: Average training:	ADE  0.5113	FDE  1.0714
2022-11-03 01:43:57,940:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_587.pth.tar
2022-11-03 01:43:57,940:INFO: 
===> EPOCH: 588 (P4)
2022-11-03 01:43:57,940:INFO: - Computing loss (training)
2022-11-03 01:43:59,072:INFO: Batch:  0/31	Total Loss -62.0573 (-62.0573)
2022-11-03 01:43:59,570:INFO: Batch:  1/31	Total Loss -75.9872 (-68.5570)
2022-11-03 01:44:00,076:INFO: Batch:  2/31	Total Loss -79.3473 (-72.1762)
2022-11-03 01:44:00,571:INFO: Batch:  3/31	Total Loss -69.3678 (-71.4449)
2022-11-03 01:44:01,067:INFO: Batch:  4/31	Total Loss -72.1617 (-71.5929)
2022-11-03 01:44:01,568:INFO: Batch:  5/31	Total Loss -64.8560 (-70.5331)
2022-11-03 01:44:02,058:INFO: Batch:  6/31	Total Loss -66.5982 (-70.0556)
2022-11-03 01:44:02,552:INFO: Batch:  7/31	Total Loss -79.0699 (-71.1388)
2022-11-03 01:44:03,047:INFO: Batch:  8/31	Total Loss -68.5618 (-70.8346)
2022-11-03 01:44:03,542:INFO: Batch:  9/31	Total Loss -82.7796 (-72.1157)
2022-11-03 01:44:04,039:INFO: Batch: 10/31	Total Loss -74.2590 (-72.3284)
2022-11-03 01:44:04,533:INFO: Batch: 11/31	Total Loss -79.5248 (-72.9403)
2022-11-03 01:44:05,031:INFO: Batch: 12/31	Total Loss -63.6412 (-72.2580)
2022-11-03 01:44:05,527:INFO: Batch: 13/31	Total Loss -61.8673 (-71.5198)
2022-11-03 01:44:06,026:INFO: Batch: 14/31	Total Loss -57.9584 (-70.5949)
2022-11-03 01:44:06,523:INFO: Batch: 15/31	Total Loss -73.4303 (-70.7740)
2022-11-03 01:44:07,021:INFO: Batch: 16/31	Total Loss -60.4584 (-70.1627)
2022-11-03 01:44:07,517:INFO: Batch: 17/31	Total Loss -85.7664 (-71.1206)
2022-11-03 01:44:08,097:INFO: Batch: 18/31	Total Loss -84.7485 (-71.8859)
2022-11-03 01:44:08,595:INFO: Batch: 19/31	Total Loss -80.2596 (-72.3594)
2022-11-03 01:44:09,091:INFO: Batch: 20/31	Total Loss -73.1786 (-72.3979)
2022-11-03 01:44:09,587:INFO: Batch: 21/31	Total Loss -79.0413 (-72.7254)
2022-11-03 01:44:10,085:INFO: Batch: 22/31	Total Loss -67.3022 (-72.4936)
2022-11-03 01:44:10,582:INFO: Batch: 23/31	Total Loss -65.9362 (-72.2307)
2022-11-03 01:44:11,080:INFO: Batch: 24/31	Total Loss -71.2711 (-72.1921)
2022-11-03 01:44:11,576:INFO: Batch: 25/31	Total Loss -77.0429 (-72.3828)
2022-11-03 01:44:12,072:INFO: Batch: 26/31	Total Loss -71.5783 (-72.3541)
2022-11-03 01:44:12,568:INFO: Batch: 27/31	Total Loss -69.3060 (-72.2480)
2022-11-03 01:44:13,065:INFO: Batch: 28/31	Total Loss -74.9155 (-72.3458)
2022-11-03 01:44:13,560:INFO: Batch: 29/31	Total Loss -70.0351 (-72.2751)
2022-11-03 01:44:13,952:INFO: Batch: 30/31	Total Loss -75.8791 (-72.3079)
2022-11-03 01:44:14,112:INFO: - Computing ADE (validation o)
2022-11-03 01:44:14,818:INFO: 		 ADE on eth                       dataset:	 0.9415682554244995
2022-11-03 01:44:14,819:INFO: Average validation o:	ADE  0.9416	FDE  1.9333
2022-11-03 01:44:14,819:INFO: - Computing ADE (validation)
2022-11-03 01:44:15,123:INFO: 		 ADE on hotel                     dataset:	 0.5168684124946594
2022-11-03 01:44:15,508:INFO: 		 ADE on univ                      dataset:	 0.5506272912025452
2022-11-03 01:44:15,786:INFO: 		 ADE on zara1                     dataset:	 0.3989793658256531
2022-11-03 01:44:16,255:INFO: 		 ADE on zara2                     dataset:	 0.4254852533340454
2022-11-03 01:44:16,255:INFO: Average validation:	ADE  0.4941	FDE  1.0461
2022-11-03 01:44:16,256:INFO: - Computing ADE (training)
2022-11-03 01:44:16,815:INFO: 		 ADE on hotel                     dataset:	 0.5363600254058838
2022-11-03 01:44:17,843:INFO: 		 ADE on univ                      dataset:	 0.5516440868377686
2022-11-03 01:44:18,612:INFO: 		 ADE on zara1                     dataset:	 0.4533068537712097
2022-11-03 01:44:19,854:INFO: 		 ADE on zara2                     dataset:	 0.41525644063949585
2022-11-03 01:44:19,854:INFO: Average training:	ADE  0.5173	FDE  1.0988
2022-11-03 01:44:19,866:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_588.pth.tar
2022-11-03 01:44:19,866:INFO: 
===> EPOCH: 589 (P4)
2022-11-03 01:44:19,866:INFO: - Computing loss (training)
2022-11-03 01:44:20,999:INFO: Batch:  0/31	Total Loss -60.4199 (-60.4199)
2022-11-03 01:44:21,505:INFO: Batch:  1/31	Total Loss -80.7371 (-70.7498)
2022-11-03 01:44:22,008:INFO: Batch:  2/31	Total Loss -71.9805 (-71.1454)
2022-11-03 01:44:22,515:INFO: Batch:  3/31	Total Loss -44.2825 (-64.1012)
2022-11-03 01:44:23,015:INFO: Batch:  4/31	Total Loss -71.9224 (-65.5273)
2022-11-03 01:44:23,517:INFO: Batch:  5/31	Total Loss -33.7010 (-61.1374)
2022-11-03 01:44:24,017:INFO: Batch:  6/31	Total Loss -71.4343 (-62.6399)
2022-11-03 01:44:24,519:INFO: Batch:  7/31	Total Loss -79.0878 (-64.9136)
2022-11-03 01:44:25,019:INFO: Batch:  8/31	Total Loss -80.7786 (-66.7339)
2022-11-03 01:44:25,521:INFO: Batch:  9/31	Total Loss -88.7255 (-69.0738)
2022-11-03 01:44:26,021:INFO: Batch: 10/31	Total Loss -65.1341 (-68.7448)
2022-11-03 01:44:26,520:INFO: Batch: 11/31	Total Loss -88.0083 (-70.5411)
2022-11-03 01:44:27,023:INFO: Batch: 12/31	Total Loss -86.6894 (-71.9093)
2022-11-03 01:44:27,525:INFO: Batch: 13/31	Total Loss -74.7281 (-72.1263)
2022-11-03 01:44:28,028:INFO: Batch: 14/31	Total Loss -88.3482 (-73.2368)
2022-11-03 01:44:28,530:INFO: Batch: 15/31	Total Loss -44.4441 (-71.6295)
2022-11-03 01:44:29,033:INFO: Batch: 16/31	Total Loss -69.6921 (-71.5269)
2022-11-03 01:44:29,535:INFO: Batch: 17/31	Total Loss -84.2169 (-72.2756)
2022-11-03 01:44:30,041:INFO: Batch: 18/31	Total Loss -72.3061 (-72.2771)
2022-11-03 01:44:30,550:INFO: Batch: 19/31	Total Loss -66.8042 (-72.0102)
2022-11-03 01:44:31,056:INFO: Batch: 20/31	Total Loss -70.7391 (-71.9532)
2022-11-03 01:44:31,554:INFO: Batch: 21/31	Total Loss -86.3733 (-72.7170)
2022-11-03 01:44:32,053:INFO: Batch: 22/31	Total Loss -67.6479 (-72.4915)
2022-11-03 01:44:32,552:INFO: Batch: 23/31	Total Loss -76.8091 (-72.6829)
2022-11-03 01:44:33,053:INFO: Batch: 24/31	Total Loss -66.4687 (-72.4552)
2022-11-03 01:44:33,551:INFO: Batch: 25/31	Total Loss -67.1405 (-72.2689)
2022-11-03 01:44:34,051:INFO: Batch: 26/31	Total Loss -79.6918 (-72.5334)
2022-11-03 01:44:34,548:INFO: Batch: 27/31	Total Loss -79.6989 (-72.7770)
2022-11-03 01:44:35,049:INFO: Batch: 28/31	Total Loss -81.3621 (-73.0853)
2022-11-03 01:44:35,546:INFO: Batch: 29/31	Total Loss -68.6816 (-72.9560)
2022-11-03 01:44:35,941:INFO: Batch: 30/31	Total Loss -73.6230 (-72.9615)
2022-11-03 01:44:36,092:INFO: - Computing ADE (validation o)
2022-11-03 01:44:36,822:INFO: 		 ADE on eth                       dataset:	 0.9311767220497131
2022-11-03 01:44:36,822:INFO: Average validation o:	ADE  0.9312	FDE  1.9115
2022-11-03 01:44:36,823:INFO: - Computing ADE (validation)
2022-11-03 01:44:37,117:INFO: 		 ADE on hotel                     dataset:	 0.49244916439056396
2022-11-03 01:44:37,486:INFO: 		 ADE on univ                      dataset:	 0.5411821603775024
2022-11-03 01:44:37,755:INFO: 		 ADE on zara1                     dataset:	 0.39138394594192505
2022-11-03 01:44:38,226:INFO: 		 ADE on zara2                     dataset:	 0.41198086738586426
2022-11-03 01:44:38,226:INFO: Average validation:	ADE  0.4824	FDE  1.0150
2022-11-03 01:44:38,227:INFO: - Computing ADE (training)
2022-11-03 01:44:38,804:INFO: 		 ADE on hotel                     dataset:	 0.5127739310264587
2022-11-03 01:44:39,880:INFO: 		 ADE on univ                      dataset:	 0.5422093868255615
2022-11-03 01:44:40,604:INFO: 		 ADE on zara1                     dataset:	 0.44846442341804504
2022-11-03 01:44:41,791:INFO: 		 ADE on zara2                     dataset:	 0.4037059545516968
2022-11-03 01:44:41,791:INFO: Average training:	ADE  0.5074	FDE  1.0729
2022-11-03 01:44:41,803:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_589.pth.tar
2022-11-03 01:44:41,803:INFO: 
===> EPOCH: 590 (P4)
2022-11-03 01:44:41,803:INFO: - Computing loss (training)
2022-11-03 01:44:42,921:INFO: Batch:  0/31	Total Loss -87.9830 (-87.9830)
2022-11-03 01:44:43,424:INFO: Batch:  1/31	Total Loss -74.4967 (-81.6209)
2022-11-03 01:44:43,932:INFO: Batch:  2/31	Total Loss -0.9146 (-55.4340)
2022-11-03 01:44:44,436:INFO: Batch:  3/31	Total Loss -73.5730 (-59.7245)
2022-11-03 01:44:44,937:INFO: Batch:  4/31	Total Loss -69.7017 (-61.6228)
2022-11-03 01:44:45,441:INFO: Batch:  5/31	Total Loss -73.3580 (-63.7054)
2022-11-03 01:44:45,940:INFO: Batch:  6/31	Total Loss -79.4308 (-66.1148)
2022-11-03 01:44:46,438:INFO: Batch:  7/31	Total Loss -71.9151 (-66.8532)
2022-11-03 01:44:46,938:INFO: Batch:  8/31	Total Loss -85.3171 (-69.0931)
2022-11-03 01:44:47,437:INFO: Batch:  9/31	Total Loss -87.3899 (-71.1703)
2022-11-03 01:44:47,932:INFO: Batch: 10/31	Total Loss -87.2216 (-72.7393)
2022-11-03 01:44:48,431:INFO: Batch: 11/31	Total Loss -77.3776 (-73.0783)
2022-11-03 01:44:48,931:INFO: Batch: 12/31	Total Loss -84.8573 (-74.0312)
2022-11-03 01:44:49,433:INFO: Batch: 13/31	Total Loss -67.6307 (-73.5992)
2022-11-03 01:44:49,937:INFO: Batch: 14/31	Total Loss -75.2657 (-73.7141)
2022-11-03 01:44:50,439:INFO: Batch: 15/31	Total Loss -82.3963 (-74.2075)
2022-11-03 01:44:50,942:INFO: Batch: 16/31	Total Loss -66.8573 (-73.7835)
2022-11-03 01:44:51,443:INFO: Batch: 17/31	Total Loss -79.4611 (-74.1105)
2022-11-03 01:44:51,945:INFO: Batch: 18/31	Total Loss -55.1288 (-73.2073)
2022-11-03 01:44:52,447:INFO: Batch: 19/31	Total Loss -80.8502 (-73.6084)
2022-11-03 01:44:52,951:INFO: Batch: 20/31	Total Loss -65.6648 (-73.2544)
2022-11-03 01:44:53,453:INFO: Batch: 21/31	Total Loss -63.5840 (-72.8401)
2022-11-03 01:44:53,954:INFO: Batch: 22/31	Total Loss -86.9035 (-73.4493)
2022-11-03 01:44:54,453:INFO: Batch: 23/31	Total Loss -64.2549 (-73.1173)
2022-11-03 01:44:54,955:INFO: Batch: 24/31	Total Loss -92.7216 (-73.9390)
2022-11-03 01:44:55,459:INFO: Batch: 25/31	Total Loss -79.1448 (-74.1375)
2022-11-03 01:44:55,960:INFO: Batch: 26/31	Total Loss -78.6943 (-74.3093)
2022-11-03 01:44:56,459:INFO: Batch: 27/31	Total Loss -75.1267 (-74.3339)
2022-11-03 01:44:56,956:INFO: Batch: 28/31	Total Loss -82.0129 (-74.6061)
2022-11-03 01:44:57,456:INFO: Batch: 29/31	Total Loss -82.3023 (-74.8870)
2022-11-03 01:44:57,849:INFO: Batch: 30/31	Total Loss -75.7044 (-74.8942)
2022-11-03 01:44:57,989:INFO: - Computing ADE (validation o)
2022-11-03 01:44:58,678:INFO: 		 ADE on eth                       dataset:	 0.9194326400756836
2022-11-03 01:44:58,678:INFO: Average validation o:	ADE  0.9194	FDE  1.8887
2022-11-03 01:44:58,679:INFO: - Computing ADE (validation)
2022-11-03 01:44:58,986:INFO: 		 ADE on hotel                     dataset:	 0.48792871832847595
2022-11-03 01:44:59,363:INFO: 		 ADE on univ                      dataset:	 0.5417436361312866
2022-11-03 01:44:59,664:INFO: 		 ADE on zara1                     dataset:	 0.4118909239768982
2022-11-03 01:45:00,127:INFO: 		 ADE on zara2                     dataset:	 0.4039941728115082
2022-11-03 01:45:00,127:INFO: Average validation:	ADE  0.4807	FDE  1.0125
2022-11-03 01:45:00,128:INFO: - Computing ADE (training)
2022-11-03 01:45:00,690:INFO: 		 ADE on hotel                     dataset:	 0.5140570998191833
2022-11-03 01:45:01,717:INFO: 		 ADE on univ                      dataset:	 0.539502739906311
2022-11-03 01:45:02,485:INFO: 		 ADE on zara1                     dataset:	 0.4375389516353607
2022-11-03 01:45:03,704:INFO: 		 ADE on zara2                     dataset:	 0.3895685374736786
2022-11-03 01:45:03,705:INFO: Average training:	ADE  0.5019	FDE  1.0600
2022-11-03 01:45:03,716:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_590.pth.tar
2022-11-03 01:45:03,716:INFO: 
===> EPOCH: 591 (P4)
2022-11-03 01:45:03,717:INFO: - Computing loss (training)
2022-11-03 01:45:04,839:INFO: Batch:  0/31	Total Loss -74.9387 (-74.9387)
2022-11-03 01:45:05,336:INFO: Batch:  1/31	Total Loss -85.3568 (-80.6601)
2022-11-03 01:45:05,909:INFO: Batch:  2/31	Total Loss -69.0464 (-77.1515)
2022-11-03 01:45:06,405:INFO: Batch:  3/31	Total Loss -71.8119 (-75.7514)
2022-11-03 01:45:06,901:INFO: Batch:  4/31	Total Loss -71.3943 (-74.9162)
2022-11-03 01:45:07,399:INFO: Batch:  5/31	Total Loss -81.1936 (-76.0903)
2022-11-03 01:45:07,897:INFO: Batch:  6/31	Total Loss -81.5517 (-76.9136)
2022-11-03 01:45:08,390:INFO: Batch:  7/31	Total Loss -76.9658 (-76.9202)
2022-11-03 01:45:08,882:INFO: Batch:  8/31	Total Loss -84.6970 (-77.8265)
2022-11-03 01:45:09,376:INFO: Batch:  9/31	Total Loss -89.8532 (-79.0488)
2022-11-03 01:45:09,873:INFO: Batch: 10/31	Total Loss -53.3612 (-76.8708)
2022-11-03 01:45:10,368:INFO: Batch: 11/31	Total Loss -80.3249 (-77.1596)
2022-11-03 01:45:10,866:INFO: Batch: 12/31	Total Loss -39.2578 (-74.3071)
2022-11-03 01:45:11,363:INFO: Batch: 13/31	Total Loss -81.7885 (-74.8435)
2022-11-03 01:45:11,861:INFO: Batch: 14/31	Total Loss -86.9675 (-75.7157)
2022-11-03 01:45:12,358:INFO: Batch: 15/31	Total Loss -63.0021 (-74.9607)
2022-11-03 01:45:12,854:INFO: Batch: 16/31	Total Loss -89.4707 (-75.8974)
2022-11-03 01:45:13,351:INFO: Batch: 17/31	Total Loss -91.9716 (-76.8688)
2022-11-03 01:45:13,850:INFO: Batch: 18/31	Total Loss -76.6398 (-76.8568)
2022-11-03 01:45:14,347:INFO: Batch: 19/31	Total Loss -73.2746 (-76.6758)
2022-11-03 01:45:14,843:INFO: Batch: 20/31	Total Loss -82.1844 (-76.9475)
2022-11-03 01:45:15,341:INFO: Batch: 21/31	Total Loss -75.4486 (-76.8792)
2022-11-03 01:45:15,837:INFO: Batch: 22/31	Total Loss -52.2594 (-75.8962)
2022-11-03 01:45:16,335:INFO: Batch: 23/31	Total Loss -83.9379 (-76.2079)
2022-11-03 01:45:16,832:INFO: Batch: 24/31	Total Loss -82.7165 (-76.4671)
2022-11-03 01:45:17,327:INFO: Batch: 25/31	Total Loss -76.5358 (-76.4695)
2022-11-03 01:45:17,824:INFO: Batch: 26/31	Total Loss -91.0142 (-77.0360)
2022-11-03 01:45:18,320:INFO: Batch: 27/31	Total Loss -91.5587 (-77.5774)
2022-11-03 01:45:18,816:INFO: Batch: 28/31	Total Loss -77.0975 (-77.5595)
2022-11-03 01:45:19,313:INFO: Batch: 29/31	Total Loss -92.8132 (-78.0493)
2022-11-03 01:45:19,705:INFO: Batch: 30/31	Total Loss -78.7291 (-78.0554)
2022-11-03 01:45:19,858:INFO: - Computing ADE (validation o)
2022-11-03 01:45:20,587:INFO: 		 ADE on eth                       dataset:	 0.9092416763305664
2022-11-03 01:45:20,587:INFO: Average validation o:	ADE  0.9092	FDE  1.8766
2022-11-03 01:45:20,588:INFO: - Computing ADE (validation)
2022-11-03 01:45:20,889:INFO: 		 ADE on hotel                     dataset:	 0.49932634830474854
2022-11-03 01:45:21,259:INFO: 		 ADE on univ                      dataset:	 0.5478479862213135
2022-11-03 01:45:21,546:INFO: 		 ADE on zara1                     dataset:	 0.40772169828414917
2022-11-03 01:45:22,002:INFO: 		 ADE on zara2                     dataset:	 0.4074002504348755
2022-11-03 01:45:22,002:INFO: Average validation:	ADE  0.4855	FDE  1.0191
2022-11-03 01:45:22,003:INFO: - Computing ADE (training)
2022-11-03 01:45:22,586:INFO: 		 ADE on hotel                     dataset:	 0.5302761793136597
2022-11-03 01:45:23,670:INFO: 		 ADE on univ                      dataset:	 0.5417283773422241
2022-11-03 01:45:24,444:INFO: 		 ADE on zara1                     dataset:	 0.4523453116416931
2022-11-03 01:45:25,662:INFO: 		 ADE on zara2                     dataset:	 0.39950039982795715
2022-11-03 01:45:25,663:INFO: Average training:	ADE  0.5069	FDE  1.0682
2022-11-03 01:45:25,674:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_591.pth.tar
2022-11-03 01:45:25,674:INFO: 
===> EPOCH: 592 (P4)
2022-11-03 01:45:25,674:INFO: - Computing loss (training)
2022-11-03 01:45:26,779:INFO: Batch:  0/31	Total Loss -97.6803 (-97.6803)
2022-11-03 01:45:27,270:INFO: Batch:  1/31	Total Loss -75.6696 (-86.7359)
2022-11-03 01:45:27,760:INFO: Batch:  2/31	Total Loss -71.2796 (-82.2058)
2022-11-03 01:45:28,252:INFO: Batch:  3/31	Total Loss -83.8458 (-82.6595)
2022-11-03 01:45:28,743:INFO: Batch:  4/31	Total Loss -94.7728 (-85.3094)
2022-11-03 01:45:29,232:INFO: Batch:  5/31	Total Loss -87.1405 (-85.6113)
2022-11-03 01:45:29,724:INFO: Batch:  6/31	Total Loss -96.6773 (-87.2577)
2022-11-03 01:45:30,214:INFO: Batch:  7/31	Total Loss -75.8632 (-85.9824)
2022-11-03 01:45:30,705:INFO: Batch:  8/31	Total Loss -86.9547 (-86.0894)
2022-11-03 01:45:31,194:INFO: Batch:  9/31	Total Loss -81.7460 (-85.6590)
2022-11-03 01:45:31,683:INFO: Batch: 10/31	Total Loss -88.9773 (-85.9671)
2022-11-03 01:45:32,171:INFO: Batch: 11/31	Total Loss -99.7368 (-87.1584)
2022-11-03 01:45:32,664:INFO: Batch: 12/31	Total Loss -77.4457 (-86.4613)
2022-11-03 01:45:33,156:INFO: Batch: 13/31	Total Loss -75.7637 (-85.7714)
2022-11-03 01:45:33,648:INFO: Batch: 14/31	Total Loss -38.1935 (-82.6834)
2022-11-03 01:45:34,139:INFO: Batch: 15/31	Total Loss -81.4103 (-82.6051)
2022-11-03 01:45:34,629:INFO: Batch: 16/31	Total Loss -92.3452 (-83.2394)
2022-11-03 01:45:35,121:INFO: Batch: 17/31	Total Loss -70.2062 (-82.5520)
2022-11-03 01:45:35,610:INFO: Batch: 18/31	Total Loss -57.8198 (-81.3179)
2022-11-03 01:45:36,100:INFO: Batch: 19/31	Total Loss -71.7435 (-80.8013)
2022-11-03 01:45:36,590:INFO: Batch: 20/31	Total Loss -66.1887 (-80.1419)
2022-11-03 01:45:37,080:INFO: Batch: 21/31	Total Loss -97.8909 (-81.0422)
2022-11-03 01:45:37,571:INFO: Batch: 22/31	Total Loss -93.2306 (-81.6239)
2022-11-03 01:45:38,061:INFO: Batch: 23/31	Total Loss -91.6301 (-82.0761)
2022-11-03 01:45:38,551:INFO: Batch: 24/31	Total Loss -88.8630 (-82.3759)
2022-11-03 01:45:39,042:INFO: Batch: 25/31	Total Loss -92.0063 (-82.7366)
2022-11-03 01:45:39,531:INFO: Batch: 26/31	Total Loss -75.7388 (-82.4711)
2022-11-03 01:45:40,022:INFO: Batch: 27/31	Total Loss -89.7824 (-82.7165)
2022-11-03 01:45:40,511:INFO: Batch: 28/31	Total Loss -41.6793 (-81.3699)
2022-11-03 01:45:41,001:INFO: Batch: 29/31	Total Loss -41.9028 (-80.2793)
2022-11-03 01:45:41,387:INFO: Batch: 30/31	Total Loss -80.3837 (-80.2803)
2022-11-03 01:45:41,540:INFO: - Computing ADE (validation o)
2022-11-03 01:45:42,259:INFO: 		 ADE on eth                       dataset:	 0.9203884601593018
2022-11-03 01:45:42,260:INFO: Average validation o:	ADE  0.9204	FDE  1.9168
2022-11-03 01:45:42,260:INFO: - Computing ADE (validation)
2022-11-03 01:45:42,556:INFO: 		 ADE on hotel                     dataset:	 0.47585245966911316
2022-11-03 01:45:42,926:INFO: 		 ADE on univ                      dataset:	 0.5453617572784424
2022-11-03 01:45:43,210:INFO: 		 ADE on zara1                     dataset:	 0.4076470136642456
2022-11-03 01:45:43,678:INFO: 		 ADE on zara2                     dataset:	 0.4009915292263031
2022-11-03 01:45:43,678:INFO: Average validation:	ADE  0.4806	FDE  1.0180
2022-11-03 01:45:43,679:INFO: - Computing ADE (training)
2022-11-03 01:45:44,244:INFO: 		 ADE on hotel                     dataset:	 0.4938656687736511
2022-11-03 01:45:45,303:INFO: 		 ADE on univ                      dataset:	 0.536733865737915
2022-11-03 01:45:46,052:INFO: 		 ADE on zara1                     dataset:	 0.44171226024627686
2022-11-03 01:45:47,202:INFO: 		 ADE on zara2                     dataset:	 0.3904109299182892
2022-11-03 01:45:47,202:INFO: Average training:	ADE  0.4999	FDE  1.0607
2022-11-03 01:45:47,213:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_592.pth.tar
2022-11-03 01:45:47,213:INFO: 
===> EPOCH: 593 (P4)
2022-11-03 01:45:47,213:INFO: - Computing loss (training)
2022-11-03 01:45:48,343:INFO: Batch:  0/31	Total Loss -81.4883 (-81.4883)
2022-11-03 01:45:48,841:INFO: Batch:  1/31	Total Loss -68.6225 (-75.8034)
2022-11-03 01:45:49,346:INFO: Batch:  2/31	Total Loss -80.4936 (-77.3857)
2022-11-03 01:45:49,846:INFO: Batch:  3/31	Total Loss -88.9988 (-80.4374)
2022-11-03 01:45:50,340:INFO: Batch:  4/31	Total Loss -94.5625 (-83.4204)
2022-11-03 01:45:50,840:INFO: Batch:  5/31	Total Loss -58.6315 (-79.9200)
2022-11-03 01:45:51,339:INFO: Batch:  6/31	Total Loss -83.0833 (-80.3628)
2022-11-03 01:45:51,836:INFO: Batch:  7/31	Total Loss -62.2855 (-78.0434)
2022-11-03 01:45:52,329:INFO: Batch:  8/31	Total Loss -51.6367 (-75.1214)
2022-11-03 01:45:52,824:INFO: Batch:  9/31	Total Loss -86.5319 (-76.2696)
2022-11-03 01:45:53,320:INFO: Batch: 10/31	Total Loss -67.9411 (-75.6522)
2022-11-03 01:45:53,816:INFO: Batch: 11/31	Total Loss -91.5244 (-77.0529)
2022-11-03 01:45:54,317:INFO: Batch: 12/31	Total Loss -86.7040 (-77.7680)
2022-11-03 01:45:54,815:INFO: Batch: 13/31	Total Loss -75.1241 (-77.5842)
2022-11-03 01:45:55,316:INFO: Batch: 14/31	Total Loss -92.9850 (-78.5697)
2022-11-03 01:45:55,817:INFO: Batch: 15/31	Total Loss -85.7656 (-79.0383)
2022-11-03 01:45:56,318:INFO: Batch: 16/31	Total Loss -78.7145 (-79.0181)
2022-11-03 01:45:56,819:INFO: Batch: 17/31	Total Loss -86.2025 (-79.4491)
2022-11-03 01:45:57,320:INFO: Batch: 18/31	Total Loss -83.1292 (-79.6383)
2022-11-03 01:45:57,822:INFO: Batch: 19/31	Total Loss -89.6028 (-80.1408)
2022-11-03 01:45:58,321:INFO: Batch: 20/31	Total Loss -80.9644 (-80.1792)
2022-11-03 01:45:58,820:INFO: Batch: 21/31	Total Loss -75.6360 (-79.9992)
2022-11-03 01:45:59,319:INFO: Batch: 22/31	Total Loss -78.8157 (-79.9515)
2022-11-03 01:45:59,818:INFO: Batch: 23/31	Total Loss -83.3107 (-80.0790)
2022-11-03 01:46:00,318:INFO: Batch: 24/31	Total Loss -104.4542 (-81.1590)
2022-11-03 01:46:00,820:INFO: Batch: 25/31	Total Loss -95.1606 (-81.7304)
2022-11-03 01:46:01,324:INFO: Batch: 26/31	Total Loss -89.3334 (-82.0003)
2022-11-03 01:46:01,823:INFO: Batch: 27/31	Total Loss -93.8521 (-82.4083)
2022-11-03 01:46:02,398:INFO: Batch: 28/31	Total Loss -87.5196 (-82.5763)
2022-11-03 01:46:02,899:INFO: Batch: 29/31	Total Loss -102.6965 (-83.3872)
2022-11-03 01:46:03,293:INFO: Batch: 30/31	Total Loss -81.9524 (-83.3738)
2022-11-03 01:46:03,444:INFO: - Computing ADE (validation o)
2022-11-03 01:46:04,157:INFO: 		 ADE on eth                       dataset:	 0.917527973651886
2022-11-03 01:46:04,157:INFO: Average validation o:	ADE  0.9175	FDE  1.8965
2022-11-03 01:46:04,167:INFO: - Computing ADE (validation)
2022-11-03 01:46:04,466:INFO: 		 ADE on hotel                     dataset:	 0.48188525438308716
2022-11-03 01:46:04,831:INFO: 		 ADE on univ                      dataset:	 0.5344723463058472
2022-11-03 01:46:05,116:INFO: 		 ADE on zara1                     dataset:	 0.3962717652320862
2022-11-03 01:46:05,592:INFO: 		 ADE on zara2                     dataset:	 0.40881040692329407
2022-11-03 01:46:05,592:INFO: Average validation:	ADE  0.4775	FDE  1.0083
2022-11-03 01:46:05,593:INFO: - Computing ADE (training)
2022-11-03 01:46:06,163:INFO: 		 ADE on hotel                     dataset:	 0.49741363525390625
2022-11-03 01:46:07,209:INFO: 		 ADE on univ                      dataset:	 0.5371107459068298
2022-11-03 01:46:07,977:INFO: 		 ADE on zara1                     dataset:	 0.4465545117855072
2022-11-03 01:46:09,170:INFO: 		 ADE on zara2                     dataset:	 0.39903396368026733
2022-11-03 01:46:09,170:INFO: Average training:	ADE  0.5023	FDE  1.0658
2022-11-03 01:46:09,191:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_593.pth.tar
2022-11-03 01:46:09,191:INFO: 
===> EPOCH: 594 (P4)
2022-11-03 01:46:09,192:INFO: - Computing loss (training)
2022-11-03 01:46:10,313:INFO: Batch:  0/31	Total Loss -92.8593 (-92.8593)
2022-11-03 01:46:10,815:INFO: Batch:  1/31	Total Loss -94.2166 (-93.5217)
2022-11-03 01:46:11,307:INFO: Batch:  2/31	Total Loss -94.2423 (-93.7529)
2022-11-03 01:46:11,803:INFO: Batch:  3/31	Total Loss -94.8827 (-94.0527)
2022-11-03 01:46:12,294:INFO: Batch:  4/31	Total Loss -63.2576 (-87.6678)
2022-11-03 01:46:12,788:INFO: Batch:  5/31	Total Loss -96.1976 (-89.0515)
2022-11-03 01:46:13,279:INFO: Batch:  6/31	Total Loss -99.4912 (-90.5850)
2022-11-03 01:46:13,769:INFO: Batch:  7/31	Total Loss -85.2873 (-89.9593)
2022-11-03 01:46:14,260:INFO: Batch:  8/31	Total Loss -77.8594 (-88.6578)
2022-11-03 01:46:14,752:INFO: Batch:  9/31	Total Loss -98.5739 (-89.6015)
2022-11-03 01:46:15,241:INFO: Batch: 10/31	Total Loss -90.5666 (-89.6946)
2022-11-03 01:46:15,735:INFO: Batch: 11/31	Total Loss -90.7429 (-89.7839)
2022-11-03 01:46:16,229:INFO: Batch: 12/31	Total Loss -88.9504 (-89.7161)
2022-11-03 01:46:16,725:INFO: Batch: 13/31	Total Loss -52.5526 (-87.3375)
2022-11-03 01:46:17,220:INFO: Batch: 14/31	Total Loss -77.6276 (-86.7024)
2022-11-03 01:46:17,715:INFO: Batch: 15/31	Total Loss -69.4163 (-85.7688)
2022-11-03 01:46:18,209:INFO: Batch: 16/31	Total Loss -92.1103 (-86.1600)
2022-11-03 01:46:18,703:INFO: Batch: 17/31	Total Loss -62.7430 (-84.6572)
2022-11-03 01:46:19,197:INFO: Batch: 18/31	Total Loss -68.3977 (-83.8575)
2022-11-03 01:46:19,690:INFO: Batch: 19/31	Total Loss -100.5100 (-84.7921)
2022-11-03 01:46:20,184:INFO: Batch: 20/31	Total Loss -66.3927 (-83.9613)
2022-11-03 01:46:20,680:INFO: Batch: 21/31	Total Loss -103.2398 (-84.9183)
2022-11-03 01:46:21,202:INFO: Batch: 22/31	Total Loss -78.5501 (-84.6877)
2022-11-03 01:46:21,698:INFO: Batch: 23/31	Total Loss -95.9289 (-85.1613)
2022-11-03 01:46:22,192:INFO: Batch: 24/31	Total Loss -80.6035 (-84.9593)
2022-11-03 01:46:22,690:INFO: Batch: 25/31	Total Loss -91.1902 (-85.1966)
2022-11-03 01:46:23,185:INFO: Batch: 26/31	Total Loss -41.6125 (-83.5734)
2022-11-03 01:46:23,677:INFO: Batch: 27/31	Total Loss -87.9763 (-83.7253)
2022-11-03 01:46:24,172:INFO: Batch: 28/31	Total Loss -82.8810 (-83.6953)
2022-11-03 01:46:24,664:INFO: Batch: 29/31	Total Loss -88.1661 (-83.8413)
2022-11-03 01:46:25,054:INFO: Batch: 30/31	Total Loss -81.4097 (-83.8198)
2022-11-03 01:46:25,203:INFO: - Computing ADE (validation o)
2022-11-03 01:46:25,895:INFO: 		 ADE on eth                       dataset:	 0.920443058013916
2022-11-03 01:46:25,896:INFO: Average validation o:	ADE  0.9204	FDE  1.9073
2022-11-03 01:46:25,896:INFO: - Computing ADE (validation)
2022-11-03 01:46:26,194:INFO: 		 ADE on hotel                     dataset:	 0.47576096653938293
2022-11-03 01:46:26,571:INFO: 		 ADE on univ                      dataset:	 0.5429635643959045
2022-11-03 01:46:26,851:INFO: 		 ADE on zara1                     dataset:	 0.40009674429893494
2022-11-03 01:46:27,323:INFO: 		 ADE on zara2                     dataset:	 0.416183203458786
2022-11-03 01:46:27,324:INFO: Average validation:	ADE  0.4845	FDE  1.0307
2022-11-03 01:46:27,324:INFO: - Computing ADE (training)
2022-11-03 01:46:27,893:INFO: 		 ADE on hotel                     dataset:	 0.4906865656375885
2022-11-03 01:46:28,941:INFO: 		 ADE on univ                      dataset:	 0.5446582436561584
2022-11-03 01:46:29,679:INFO: 		 ADE on zara1                     dataset:	 0.44520869851112366
2022-11-03 01:46:30,856:INFO: 		 ADE on zara2                     dataset:	 0.40626150369644165
2022-11-03 01:46:30,856:INFO: Average training:	ADE  0.5089	FDE  1.0869
2022-11-03 01:46:30,877:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_594.pth.tar
2022-11-03 01:46:30,877:INFO: 
===> EPOCH: 595 (P4)
2022-11-03 01:46:30,878:INFO: - Computing loss (training)
2022-11-03 01:46:31,987:INFO: Batch:  0/31	Total Loss -100.8284 (-100.8284)
2022-11-03 01:46:32,487:INFO: Batch:  1/31	Total Loss -97.6687 (-99.2429)
2022-11-03 01:46:32,986:INFO: Batch:  2/31	Total Loss -82.3904 (-93.8382)
2022-11-03 01:46:33,483:INFO: Batch:  3/31	Total Loss -82.5472 (-90.9461)
2022-11-03 01:46:33,982:INFO: Batch:  4/31	Total Loss -101.5328 (-93.2731)
2022-11-03 01:46:34,481:INFO: Batch:  5/31	Total Loss -85.9672 (-92.0126)
2022-11-03 01:46:34,976:INFO: Batch:  6/31	Total Loss -82.3285 (-90.6623)
2022-11-03 01:46:35,472:INFO: Batch:  7/31	Total Loss -93.5930 (-91.0296)
2022-11-03 01:46:35,966:INFO: Batch:  8/31	Total Loss -92.5395 (-91.1888)
2022-11-03 01:46:36,462:INFO: Batch:  9/31	Total Loss -88.5050 (-90.9294)
2022-11-03 01:46:36,958:INFO: Batch: 10/31	Total Loss -88.3817 (-90.7041)
2022-11-03 01:46:37,453:INFO: Batch: 11/31	Total Loss -77.0797 (-89.6150)
2022-11-03 01:46:37,953:INFO: Batch: 12/31	Total Loss -90.9629 (-89.7222)
2022-11-03 01:46:38,453:INFO: Batch: 13/31	Total Loss -84.4138 (-89.3526)
2022-11-03 01:46:38,953:INFO: Batch: 14/31	Total Loss -89.6269 (-89.3721)
2022-11-03 01:46:39,454:INFO: Batch: 15/31	Total Loss -102.3116 (-90.2723)
2022-11-03 01:46:39,954:INFO: Batch: 16/31	Total Loss -69.7774 (-89.1932)
2022-11-03 01:46:40,455:INFO: Batch: 17/31	Total Loss -95.3852 (-89.5275)
2022-11-03 01:46:40,955:INFO: Batch: 18/31	Total Loss -89.1102 (-89.5067)
2022-11-03 01:46:41,454:INFO: Batch: 19/31	Total Loss -81.7602 (-89.1559)
2022-11-03 01:46:41,953:INFO: Batch: 20/31	Total Loss -77.9146 (-88.6452)
2022-11-03 01:46:42,452:INFO: Batch: 21/31	Total Loss -72.8976 (-87.8594)
2022-11-03 01:46:42,950:INFO: Batch: 22/31	Total Loss -96.6930 (-88.2336)
2022-11-03 01:46:43,447:INFO: Batch: 23/31	Total Loss -89.9442 (-88.3007)
2022-11-03 01:46:43,946:INFO: Batch: 24/31	Total Loss -86.6195 (-88.2339)
2022-11-03 01:46:44,446:INFO: Batch: 25/31	Total Loss -91.5675 (-88.3791)
2022-11-03 01:46:44,944:INFO: Batch: 26/31	Total Loss -77.6222 (-87.9975)
2022-11-03 01:46:45,442:INFO: Batch: 27/31	Total Loss -84.4434 (-87.8625)
2022-11-03 01:46:45,941:INFO: Batch: 28/31	Total Loss -74.5075 (-87.4185)
2022-11-03 01:46:46,439:INFO: Batch: 29/31	Total Loss -94.9878 (-87.6885)
2022-11-03 01:46:46,834:INFO: Batch: 30/31	Total Loss -80.8222 (-87.6220)
2022-11-03 01:46:46,985:INFO: - Computing ADE (validation o)
2022-11-03 01:46:47,672:INFO: 		 ADE on eth                       dataset:	 0.9152393937110901
2022-11-03 01:46:47,672:INFO: Average validation o:	ADE  0.9152	FDE  1.8928
2022-11-03 01:46:47,673:INFO: - Computing ADE (validation)
2022-11-03 01:46:47,994:INFO: 		 ADE on hotel                     dataset:	 0.4824359118938446
2022-11-03 01:46:48,360:INFO: 		 ADE on univ                      dataset:	 0.5464382767677307
2022-11-03 01:46:48,643:INFO: 		 ADE on zara1                     dataset:	 0.40827038884162903
2022-11-03 01:46:49,114:INFO: 		 ADE on zara2                     dataset:	 0.4111965596675873
2022-11-03 01:46:49,114:INFO: Average validation:	ADE  0.4853	FDE  1.0380
2022-11-03 01:46:49,115:INFO: - Computing ADE (training)
2022-11-03 01:46:49,687:INFO: 		 ADE on hotel                     dataset:	 0.5007835626602173
2022-11-03 01:46:50,732:INFO: 		 ADE on univ                      dataset:	 0.5385180711746216
2022-11-03 01:46:51,468:INFO: 		 ADE on zara1                     dataset:	 0.45428240299224854
2022-11-03 01:46:52,668:INFO: 		 ADE on zara2                     dataset:	 0.40421828627586365
2022-11-03 01:46:52,668:INFO: Average training:	ADE  0.5049	FDE  1.0825
2022-11-03 01:46:52,689:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_595.pth.tar
2022-11-03 01:46:52,689:INFO: 
===> EPOCH: 596 (P4)
2022-11-03 01:46:52,689:INFO: - Computing loss (training)
2022-11-03 01:46:53,792:INFO: Batch:  0/31	Total Loss -68.7021 (-68.7021)
2022-11-03 01:46:54,281:INFO: Batch:  1/31	Total Loss -84.2880 (-76.4501)
2022-11-03 01:46:54,772:INFO: Batch:  2/31	Total Loss -100.5782 (-85.8361)
2022-11-03 01:46:55,269:INFO: Batch:  3/31	Total Loss -96.5074 (-88.4011)
2022-11-03 01:46:55,771:INFO: Batch:  4/31	Total Loss -75.4390 (-85.8376)
2022-11-03 01:46:56,270:INFO: Batch:  5/31	Total Loss -102.3119 (-88.8851)
2022-11-03 01:46:56,767:INFO: Batch:  6/31	Total Loss -105.4900 (-91.4357)
2022-11-03 01:46:57,267:INFO: Batch:  7/31	Total Loss -86.6441 (-90.8435)
2022-11-03 01:46:57,761:INFO: Batch:  8/31	Total Loss -102.6945 (-92.1787)
2022-11-03 01:46:58,288:INFO: Batch:  9/31	Total Loss -89.2007 (-91.8788)
2022-11-03 01:46:58,781:INFO: Batch: 10/31	Total Loss -84.6298 (-91.2788)
2022-11-03 01:46:59,362:INFO: Batch: 11/31	Total Loss -80.7804 (-90.4231)
2022-11-03 01:46:59,860:INFO: Batch: 12/31	Total Loss -109.5436 (-92.0268)
2022-11-03 01:47:00,361:INFO: Batch: 13/31	Total Loss -65.0137 (-90.2812)
2022-11-03 01:47:00,861:INFO: Batch: 14/31	Total Loss -98.1580 (-90.8471)
2022-11-03 01:47:01,363:INFO: Batch: 15/31	Total Loss -96.0842 (-91.2155)
2022-11-03 01:47:01,862:INFO: Batch: 16/31	Total Loss -103.3610 (-91.9628)
2022-11-03 01:47:02,362:INFO: Batch: 17/31	Total Loss -105.9036 (-92.8127)
2022-11-03 01:47:02,861:INFO: Batch: 18/31	Total Loss -74.6312 (-91.9004)
2022-11-03 01:47:03,360:INFO: Batch: 19/31	Total Loss -81.7549 (-91.4057)
2022-11-03 01:47:03,859:INFO: Batch: 20/31	Total Loss -98.2068 (-91.7510)
2022-11-03 01:47:04,357:INFO: Batch: 21/31	Total Loss -82.9762 (-91.3441)
2022-11-03 01:47:04,854:INFO: Batch: 22/31	Total Loss -86.7493 (-91.1434)
2022-11-03 01:47:05,351:INFO: Batch: 23/31	Total Loss -97.1300 (-91.3851)
2022-11-03 01:47:05,849:INFO: Batch: 24/31	Total Loss -98.1780 (-91.6632)
2022-11-03 01:47:06,348:INFO: Batch: 25/31	Total Loss -69.9614 (-90.8245)
2022-11-03 01:47:06,845:INFO: Batch: 26/31	Total Loss -100.8031 (-91.2270)
2022-11-03 01:47:07,344:INFO: Batch: 27/31	Total Loss -94.4977 (-91.3498)
2022-11-03 01:47:07,847:INFO: Batch: 28/31	Total Loss -88.2665 (-91.2517)
2022-11-03 01:47:08,346:INFO: Batch: 29/31	Total Loss -93.5599 (-91.3286)
2022-11-03 01:47:08,741:INFO: Batch: 30/31	Total Loss -89.9820 (-91.3134)
2022-11-03 01:47:08,890:INFO: - Computing ADE (validation o)
2022-11-03 01:47:09,575:INFO: 		 ADE on eth                       dataset:	 0.9170523285865784
2022-11-03 01:47:09,575:INFO: Average validation o:	ADE  0.9171	FDE  1.9210
2022-11-03 01:47:09,576:INFO: - Computing ADE (validation)
2022-11-03 01:47:09,886:INFO: 		 ADE on hotel                     dataset:	 0.4480728209018707
2022-11-03 01:47:10,259:INFO: 		 ADE on univ                      dataset:	 0.5399134755134583
2022-11-03 01:47:10,540:INFO: 		 ADE on zara1                     dataset:	 0.41139334440231323
2022-11-03 01:47:11,031:INFO: 		 ADE on zara2                     dataset:	 0.4041486382484436
2022-11-03 01:47:11,031:INFO: Average validation:	ADE  0.4776	FDE  1.0212
2022-11-03 01:47:11,032:INFO: - Computing ADE (training)
2022-11-03 01:47:11,609:INFO: 		 ADE on hotel                     dataset:	 0.46554842591285706
2022-11-03 01:47:12,700:INFO: 		 ADE on univ                      dataset:	 0.5360020399093628
2022-11-03 01:47:13,438:INFO: 		 ADE on zara1                     dataset:	 0.43867766857147217
2022-11-03 01:47:14,667:INFO: 		 ADE on zara2                     dataset:	 0.39043694734573364
2022-11-03 01:47:14,667:INFO: Average training:	ADE  0.4985	FDE  1.0674
2022-11-03 01:47:14,678:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_596.pth.tar
2022-11-03 01:47:14,678:INFO: 
===> EPOCH: 597 (P4)
2022-11-03 01:47:14,679:INFO: - Computing loss (training)
2022-11-03 01:47:15,813:INFO: Batch:  0/31	Total Loss -85.4216 (-85.4216)
2022-11-03 01:47:16,318:INFO: Batch:  1/31	Total Loss -88.4097 (-86.8279)
2022-11-03 01:47:16,822:INFO: Batch:  2/31	Total Loss -90.6155 (-88.1124)
2022-11-03 01:47:17,325:INFO: Batch:  3/31	Total Loss -96.5396 (-90.1198)
2022-11-03 01:47:17,832:INFO: Batch:  4/31	Total Loss -112.4910 (-95.0000)
2022-11-03 01:47:18,334:INFO: Batch:  5/31	Total Loss -94.2106 (-94.8744)
2022-11-03 01:47:18,833:INFO: Batch:  6/31	Total Loss -97.4376 (-95.2380)
2022-11-03 01:47:19,332:INFO: Batch:  7/31	Total Loss -95.0408 (-95.2136)
2022-11-03 01:47:19,833:INFO: Batch:  8/31	Total Loss -96.1986 (-95.3160)
2022-11-03 01:47:20,334:INFO: Batch:  9/31	Total Loss -100.9643 (-95.8836)
2022-11-03 01:47:20,840:INFO: Batch: 10/31	Total Loss -96.5725 (-95.9507)
2022-11-03 01:47:21,340:INFO: Batch: 11/31	Total Loss -97.1104 (-96.0555)
2022-11-03 01:47:21,845:INFO: Batch: 12/31	Total Loss -70.8119 (-94.2325)
2022-11-03 01:47:22,348:INFO: Batch: 13/31	Total Loss -85.6080 (-93.6359)
2022-11-03 01:47:22,854:INFO: Batch: 14/31	Total Loss -93.2162 (-93.6078)
2022-11-03 01:47:23,359:INFO: Batch: 15/31	Total Loss -107.7144 (-94.5238)
2022-11-03 01:47:23,864:INFO: Batch: 16/31	Total Loss -79.5202 (-93.6423)
2022-11-03 01:47:24,368:INFO: Batch: 17/31	Total Loss -101.6984 (-94.1072)
2022-11-03 01:47:24,873:INFO: Batch: 18/31	Total Loss -89.3549 (-93.8878)
2022-11-03 01:47:25,376:INFO: Batch: 19/31	Total Loss -107.9355 (-94.6641)
2022-11-03 01:47:25,879:INFO: Batch: 20/31	Total Loss -91.8658 (-94.5389)
2022-11-03 01:47:26,381:INFO: Batch: 21/31	Total Loss -89.0532 (-94.3167)
2022-11-03 01:47:26,886:INFO: Batch: 22/31	Total Loss -87.3381 (-94.0283)
2022-11-03 01:47:27,389:INFO: Batch: 23/31	Total Loss -109.2984 (-94.6807)
2022-11-03 01:47:27,893:INFO: Batch: 24/31	Total Loss -81.9091 (-94.1733)
2022-11-03 01:47:28,396:INFO: Batch: 25/31	Total Loss -103.6483 (-94.5595)
2022-11-03 01:47:28,900:INFO: Batch: 26/31	Total Loss -95.1086 (-94.5796)
2022-11-03 01:47:29,404:INFO: Batch: 27/31	Total Loss -91.6466 (-94.4774)
2022-11-03 01:47:29,902:INFO: Batch: 28/31	Total Loss -70.9527 (-93.8098)
2022-11-03 01:47:30,394:INFO: Batch: 29/31	Total Loss -83.5362 (-93.4571)
2022-11-03 01:47:30,783:INFO: Batch: 30/31	Total Loss -80.9897 (-93.3334)
2022-11-03 01:47:30,932:INFO: - Computing ADE (validation o)
2022-11-03 01:47:31,631:INFO: 		 ADE on eth                       dataset:	 0.9391782283782959
2022-11-03 01:47:31,631:INFO: Average validation o:	ADE  0.9392	FDE  1.9662
2022-11-03 01:47:31,632:INFO: - Computing ADE (validation)
2022-11-03 01:47:31,939:INFO: 		 ADE on hotel                     dataset:	 0.45382851362228394
2022-11-03 01:47:32,307:INFO: 		 ADE on univ                      dataset:	 0.5431645512580872
2022-11-03 01:47:32,587:INFO: 		 ADE on zara1                     dataset:	 0.40950241684913635
2022-11-03 01:47:33,071:INFO: 		 ADE on zara2                     dataset:	 0.41616731882095337
2022-11-03 01:47:33,071:INFO: Average validation:	ADE  0.4839	FDE  1.0302
2022-11-03 01:47:33,072:INFO: - Computing ADE (training)
2022-11-03 01:47:33,636:INFO: 		 ADE on hotel                     dataset:	 0.46148917078971863
2022-11-03 01:47:34,702:INFO: 		 ADE on univ                      dataset:	 0.5414043664932251
2022-11-03 01:47:35,446:INFO: 		 ADE on zara1                     dataset:	 0.44728851318359375
2022-11-03 01:47:36,631:INFO: 		 ADE on zara2                     dataset:	 0.40525999665260315
2022-11-03 01:47:36,631:INFO: Average training:	ADE  0.5057	FDE  1.0795
2022-11-03 01:47:36,642:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_597.pth.tar
2022-11-03 01:47:36,642:INFO: 
===> EPOCH: 598 (P4)
2022-11-03 01:47:36,643:INFO: - Computing loss (training)
2022-11-03 01:47:37,765:INFO: Batch:  0/31	Total Loss -65.3374 (-65.3374)
2022-11-03 01:47:38,266:INFO: Batch:  1/31	Total Loss -82.6277 (-74.4237)
2022-11-03 01:47:38,766:INFO: Batch:  2/31	Total Loss -94.1782 (-81.3043)
2022-11-03 01:47:39,264:INFO: Batch:  3/31	Total Loss -107.2610 (-88.2513)
2022-11-03 01:47:39,755:INFO: Batch:  4/31	Total Loss -97.8978 (-90.1732)
2022-11-03 01:47:40,250:INFO: Batch:  5/31	Total Loss -114.0864 (-94.5007)
2022-11-03 01:47:40,750:INFO: Batch:  6/31	Total Loss -99.8702 (-95.2513)
2022-11-03 01:47:41,242:INFO: Batch:  7/31	Total Loss -100.7533 (-95.9310)
2022-11-03 01:47:41,740:INFO: Batch:  8/31	Total Loss -90.6123 (-95.3683)
2022-11-03 01:47:42,233:INFO: Batch:  9/31	Total Loss -94.7105 (-95.3098)
2022-11-03 01:47:42,729:INFO: Batch: 10/31	Total Loss -103.9659 (-96.0540)
2022-11-03 01:47:43,221:INFO: Batch: 11/31	Total Loss -98.2245 (-96.2221)
2022-11-03 01:47:43,719:INFO: Batch: 12/31	Total Loss -85.5368 (-95.4541)
2022-11-03 01:47:44,217:INFO: Batch: 13/31	Total Loss -84.7763 (-94.8324)
2022-11-03 01:47:44,713:INFO: Batch: 14/31	Total Loss -95.3203 (-94.8672)
2022-11-03 01:47:45,211:INFO: Batch: 15/31	Total Loss -93.4513 (-94.7767)
2022-11-03 01:47:45,708:INFO: Batch: 16/31	Total Loss -103.8537 (-95.3109)
2022-11-03 01:47:46,208:INFO: Batch: 17/31	Total Loss -112.0817 (-96.2984)
2022-11-03 01:47:46,707:INFO: Batch: 18/31	Total Loss -105.5899 (-96.8032)
2022-11-03 01:47:47,205:INFO: Batch: 19/31	Total Loss -125.0228 (-98.3493)
2022-11-03 01:47:47,701:INFO: Batch: 20/31	Total Loss -99.2921 (-98.3975)
2022-11-03 01:47:48,196:INFO: Batch: 21/31	Total Loss -113.6112 (-99.0828)
2022-11-03 01:47:48,690:INFO: Batch: 22/31	Total Loss -108.5621 (-99.5047)
2022-11-03 01:47:49,188:INFO: Batch: 23/31	Total Loss -109.1203 (-99.9195)
2022-11-03 01:47:49,682:INFO: Batch: 24/31	Total Loss -111.5449 (-100.3912)
2022-11-03 01:47:50,180:INFO: Batch: 25/31	Total Loss -89.9241 (-99.9961)
2022-11-03 01:47:50,675:INFO: Batch: 26/31	Total Loss -101.0220 (-100.0320)
2022-11-03 01:47:51,170:INFO: Batch: 27/31	Total Loss -102.1244 (-100.1089)
2022-11-03 01:47:51,743:INFO: Batch: 28/31	Total Loss -110.8095 (-100.4829)
2022-11-03 01:47:52,241:INFO: Batch: 29/31	Total Loss -99.1584 (-100.4367)
2022-11-03 01:47:52,635:INFO: Batch: 30/31	Total Loss -92.8769 (-100.3607)
2022-11-03 01:47:52,781:INFO: - Computing ADE (validation o)
2022-11-03 01:47:53,511:INFO: 		 ADE on eth                       dataset:	 0.9238595366477966
2022-11-03 01:47:53,511:INFO: Average validation o:	ADE  0.9239	FDE  1.9189
2022-11-03 01:47:53,512:INFO: - Computing ADE (validation)
2022-11-03 01:47:53,812:INFO: 		 ADE on hotel                     dataset:	 0.4569889008998871
2022-11-03 01:47:54,198:INFO: 		 ADE on univ                      dataset:	 0.5428298711776733
2022-11-03 01:47:54,499:INFO: 		 ADE on zara1                     dataset:	 0.4090149402618408
2022-11-03 01:47:54,978:INFO: 		 ADE on zara2                     dataset:	 0.409938246011734
2022-11-03 01:47:54,978:INFO: Average validation:	ADE  0.4816	FDE  1.0210
2022-11-03 01:47:54,979:INFO: - Computing ADE (training)
2022-11-03 01:47:55,549:INFO: 		 ADE on hotel                     dataset:	 0.46665310859680176
2022-11-03 01:47:56,567:INFO: 		 ADE on univ                      dataset:	 0.5373901724815369
2022-11-03 01:47:57,307:INFO: 		 ADE on zara1                     dataset:	 0.44621047377586365
2022-11-03 01:47:58,487:INFO: 		 ADE on zara2                     dataset:	 0.39669498801231384
2022-11-03 01:47:58,487:INFO: Average training:	ADE  0.5012	FDE  1.0662
2022-11-03 01:47:58,498:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_598.pth.tar
2022-11-03 01:47:58,498:INFO: 
===> EPOCH: 599 (P4)
2022-11-03 01:47:58,499:INFO: - Computing loss (training)
2022-11-03 01:47:59,618:INFO: Batch:  0/31	Total Loss -114.5584 (-114.5584)
2022-11-03 01:48:00,115:INFO: Batch:  1/31	Total Loss -103.3751 (-108.9508)
2022-11-03 01:48:00,613:INFO: Batch:  2/31	Total Loss -75.3668 (-98.8234)
2022-11-03 01:48:01,103:INFO: Batch:  3/31	Total Loss -96.9670 (-98.3828)
2022-11-03 01:48:01,595:INFO: Batch:  4/31	Total Loss -115.6754 (-102.1065)
2022-11-03 01:48:02,085:INFO: Batch:  5/31	Total Loss -101.8108 (-102.0617)
2022-11-03 01:48:02,573:INFO: Batch:  6/31	Total Loss -118.8442 (-104.4644)
2022-11-03 01:48:03,060:INFO: Batch:  7/31	Total Loss -96.2725 (-103.4566)
2022-11-03 01:48:03,549:INFO: Batch:  8/31	Total Loss -103.6278 (-103.4758)
2022-11-03 01:48:04,037:INFO: Batch:  9/31	Total Loss -92.3907 (-102.4043)
2022-11-03 01:48:04,523:INFO: Batch: 10/31	Total Loss -51.8143 (-98.7520)
2022-11-03 01:48:05,012:INFO: Batch: 11/31	Total Loss -96.5705 (-98.5515)
2022-11-03 01:48:05,505:INFO: Batch: 12/31	Total Loss -122.4399 (-100.5216)
2022-11-03 01:48:05,996:INFO: Batch: 13/31	Total Loss -102.0140 (-100.6379)
2022-11-03 01:48:06,487:INFO: Batch: 14/31	Total Loss -119.9015 (-101.9716)
2022-11-03 01:48:06,980:INFO: Batch: 15/31	Total Loss -117.8586 (-102.9657)
2022-11-03 01:48:07,472:INFO: Batch: 16/31	Total Loss -92.2271 (-102.3821)
2022-11-03 01:48:07,963:INFO: Batch: 17/31	Total Loss -65.8511 (-100.4210)
2022-11-03 01:48:08,455:INFO: Batch: 18/31	Total Loss -112.3953 (-101.0505)
2022-11-03 01:48:08,945:INFO: Batch: 19/31	Total Loss -110.7394 (-101.5185)
2022-11-03 01:48:09,436:INFO: Batch: 20/31	Total Loss -105.2377 (-101.6988)
2022-11-03 01:48:09,929:INFO: Batch: 21/31	Total Loss -101.8655 (-101.7067)
2022-11-03 01:48:10,420:INFO: Batch: 22/31	Total Loss -98.1382 (-101.5573)
2022-11-03 01:48:10,913:INFO: Batch: 23/31	Total Loss -85.5781 (-100.8773)
2022-11-03 01:48:11,406:INFO: Batch: 24/31	Total Loss -90.9935 (-100.4869)
2022-11-03 01:48:11,898:INFO: Batch: 25/31	Total Loss -90.1949 (-100.1242)
2022-11-03 01:48:12,390:INFO: Batch: 26/31	Total Loss -99.4408 (-100.1014)
2022-11-03 01:48:12,881:INFO: Batch: 27/31	Total Loss -106.3773 (-100.3246)
2022-11-03 01:48:13,372:INFO: Batch: 28/31	Total Loss -100.7453 (-100.3393)
2022-11-03 01:48:13,864:INFO: Batch: 29/31	Total Loss -91.1902 (-100.0178)
2022-11-03 01:48:14,250:INFO: Batch: 30/31	Total Loss -86.5121 (-99.8819)
2022-11-03 01:48:14,404:INFO: - Computing ADE (validation o)
2022-11-03 01:48:15,111:INFO: 		 ADE on eth                       dataset:	 0.925690233707428
2022-11-03 01:48:15,111:INFO: Average validation o:	ADE  0.9257	FDE  1.9354
2022-11-03 01:48:15,112:INFO: - Computing ADE (validation)
2022-11-03 01:48:15,423:INFO: 		 ADE on hotel                     dataset:	 0.43857795000076294
2022-11-03 01:48:15,829:INFO: 		 ADE on univ                      dataset:	 0.5318145751953125
2022-11-03 01:48:16,110:INFO: 		 ADE on zara1                     dataset:	 0.3967701494693756
2022-11-03 01:48:16,573:INFO: 		 ADE on zara2                     dataset:	 0.4081101715564728
2022-11-03 01:48:16,573:INFO: Average validation:	ADE  0.4735	FDE  1.0053
2022-11-03 01:48:16,574:INFO: - Computing ADE (training)
2022-11-03 01:48:17,131:INFO: 		 ADE on hotel                     dataset:	 0.4496861398220062
2022-11-03 01:48:18,203:INFO: 		 ADE on univ                      dataset:	 0.5353453159332275
2022-11-03 01:48:18,968:INFO: 		 ADE on zara1                     dataset:	 0.4367055892944336
2022-11-03 01:48:20,173:INFO: 		 ADE on zara2                     dataset:	 0.39636701345443726
2022-11-03 01:48:20,173:INFO: Average training:	ADE  0.4987	FDE  1.0639
2022-11-03 01:48:20,184:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_599.pth.tar
2022-11-03 01:48:20,185:INFO: 
===> EPOCH: 600 (P4)
2022-11-03 01:48:20,185:INFO: - Computing loss (training)
2022-11-03 01:48:21,323:INFO: Batch:  0/31	Total Loss -120.2078 (-120.2078)
2022-11-03 01:48:21,831:INFO: Batch:  1/31	Total Loss -86.2299 (-105.2304)
2022-11-03 01:48:22,340:INFO: Batch:  2/31	Total Loss -84.4131 (-99.1633)
2022-11-03 01:48:22,849:INFO: Batch:  3/31	Total Loss -117.2348 (-103.7888)
2022-11-03 01:48:23,397:INFO: Batch:  4/31	Total Loss -83.1692 (-100.3336)
2022-11-03 01:48:23,936:INFO: Batch:  5/31	Total Loss -104.0128 (-100.9902)
2022-11-03 01:48:24,439:INFO: Batch:  6/31	Total Loss -96.4735 (-100.3292)
2022-11-03 01:48:24,938:INFO: Batch:  7/31	Total Loss -69.5071 (-96.0922)
2022-11-03 01:48:25,437:INFO: Batch:  8/31	Total Loss -113.5472 (-98.0608)
2022-11-03 01:48:25,938:INFO: Batch:  9/31	Total Loss -111.5338 (-99.4335)
2022-11-03 01:48:26,439:INFO: Batch: 10/31	Total Loss -65.5439 (-96.2130)
2022-11-03 01:48:26,941:INFO: Batch: 11/31	Total Loss -76.3871 (-94.5513)
2022-11-03 01:48:27,444:INFO: Batch: 12/31	Total Loss -85.3328 (-93.9111)
2022-11-03 01:48:27,947:INFO: Batch: 13/31	Total Loss -105.7718 (-94.7810)
2022-11-03 01:48:28,452:INFO: Batch: 14/31	Total Loss -92.6490 (-94.6337)
2022-11-03 01:48:28,959:INFO: Batch: 15/31	Total Loss -117.1215 (-96.1198)
2022-11-03 01:48:29,462:INFO: Batch: 16/31	Total Loss -108.2467 (-96.8541)
2022-11-03 01:48:29,968:INFO: Batch: 17/31	Total Loss -107.3905 (-97.4160)
2022-11-03 01:48:30,474:INFO: Batch: 18/31	Total Loss -108.9248 (-98.0468)
2022-11-03 01:48:30,978:INFO: Batch: 19/31	Total Loss -97.5442 (-98.0246)
2022-11-03 01:48:31,482:INFO: Batch: 20/31	Total Loss -103.9968 (-98.3031)
2022-11-03 01:48:31,987:INFO: Batch: 21/31	Total Loss -86.6189 (-97.7104)
2022-11-03 01:48:32,489:INFO: Batch: 22/31	Total Loss -69.3232 (-96.5935)
2022-11-03 01:48:32,992:INFO: Batch: 23/31	Total Loss -112.5647 (-97.2931)
2022-11-03 01:48:33,494:INFO: Batch: 24/31	Total Loss -86.6636 (-96.9052)
2022-11-03 01:48:33,996:INFO: Batch: 25/31	Total Loss -89.2255 (-96.6039)
2022-11-03 01:48:34,497:INFO: Batch: 26/31	Total Loss -90.1407 (-96.3882)
2022-11-03 01:48:35,000:INFO: Batch: 27/31	Total Loss -80.1632 (-95.8445)
2022-11-03 01:48:35,502:INFO: Batch: 28/31	Total Loss -105.2363 (-96.1446)
2022-11-03 01:48:36,004:INFO: Batch: 29/31	Total Loss -101.8419 (-96.3133)
2022-11-03 01:48:36,402:INFO: Batch: 30/31	Total Loss -80.3515 (-96.1674)
2022-11-03 01:48:36,554:INFO: - Computing ADE (validation o)
2022-11-03 01:48:37,268:INFO: 		 ADE on eth                       dataset:	 0.9170777797698975
2022-11-03 01:48:37,269:INFO: Average validation o:	ADE  0.9171	FDE  1.9147
2022-11-03 01:48:37,269:INFO: - Computing ADE (validation)
2022-11-03 01:48:37,563:INFO: 		 ADE on hotel                     dataset:	 0.4284537732601166
2022-11-03 01:48:37,948:INFO: 		 ADE on univ                      dataset:	 0.5322638750076294
2022-11-03 01:48:38,246:INFO: 		 ADE on zara1                     dataset:	 0.40753376483917236
2022-11-03 01:48:38,731:INFO: 		 ADE on zara2                     dataset:	 0.40018364787101746
2022-11-03 01:48:38,731:INFO: Average validation:	ADE  0.4709	FDE  1.0064
2022-11-03 01:48:38,732:INFO: - Computing ADE (training)
2022-11-03 01:48:39,335:INFO: 		 ADE on hotel                     dataset:	 0.4348779320716858
2022-11-03 01:48:40,415:INFO: 		 ADE on univ                      dataset:	 0.5298194885253906
2022-11-03 01:48:41,154:INFO: 		 ADE on zara1                     dataset:	 0.43433263897895813
2022-11-03 01:48:42,383:INFO: 		 ADE on zara2                     dataset:	 0.38670095801353455
2022-11-03 01:48:42,383:INFO: Average training:	ADE  0.4923	FDE  1.0542
2022-11-03 01:48:42,395:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_600.pth.tar
2022-11-03 01:48:42,395:INFO: 
===> EPOCH: 601 (P4)
2022-11-03 01:48:42,395:INFO: - Computing loss (training)
2022-11-03 01:48:43,522:INFO: Batch:  0/31	Total Loss -111.4702 (-111.4702)
2022-11-03 01:48:44,023:INFO: Batch:  1/31	Total Loss -95.2365 (-103.8412)
2022-11-03 01:48:44,523:INFO: Batch:  2/31	Total Loss -112.6822 (-107.0525)
2022-11-03 01:48:45,019:INFO: Batch:  3/31	Total Loss -106.4495 (-106.9070)
2022-11-03 01:48:45,512:INFO: Batch:  4/31	Total Loss -83.7341 (-102.9549)
2022-11-03 01:48:46,014:INFO: Batch:  5/31	Total Loss -100.6948 (-102.6152)
2022-11-03 01:48:46,509:INFO: Batch:  6/31	Total Loss -75.6853 (-99.2100)
2022-11-03 01:48:47,002:INFO: Batch:  7/31	Total Loss -101.7398 (-99.5022)
2022-11-03 01:48:47,498:INFO: Batch:  8/31	Total Loss -105.9761 (-100.1534)
2022-11-03 01:48:47,993:INFO: Batch:  9/31	Total Loss -94.1117 (-99.5780)
2022-11-03 01:48:48,489:INFO: Batch: 10/31	Total Loss -93.9890 (-99.0381)
2022-11-03 01:48:48,988:INFO: Batch: 11/31	Total Loss -120.0638 (-100.8302)
2022-11-03 01:48:49,566:INFO: Batch: 12/31	Total Loss -106.1668 (-101.2955)
2022-11-03 01:48:50,065:INFO: Batch: 13/31	Total Loss -106.5649 (-101.6878)
2022-11-03 01:48:50,565:INFO: Batch: 14/31	Total Loss -101.0167 (-101.6446)
2022-11-03 01:48:51,058:INFO: Batch: 15/31	Total Loss -85.8203 (-100.6812)
2022-11-03 01:48:51,549:INFO: Batch: 16/31	Total Loss -109.6818 (-101.2034)
2022-11-03 01:48:52,041:INFO: Batch: 17/31	Total Loss -101.5581 (-101.2238)
2022-11-03 01:48:52,531:INFO: Batch: 18/31	Total Loss -80.3601 (-100.2089)
2022-11-03 01:48:53,023:INFO: Batch: 19/31	Total Loss -105.8063 (-100.4885)
2022-11-03 01:48:53,512:INFO: Batch: 20/31	Total Loss -102.5341 (-100.5815)
2022-11-03 01:48:54,002:INFO: Batch: 21/31	Total Loss -102.5159 (-100.6734)
2022-11-03 01:48:54,491:INFO: Batch: 22/31	Total Loss -95.6481 (-100.4570)
2022-11-03 01:48:54,981:INFO: Batch: 23/31	Total Loss -109.0870 (-100.8411)
2022-11-03 01:48:55,472:INFO: Batch: 24/31	Total Loss -121.6564 (-101.7806)
2022-11-03 01:48:55,963:INFO: Batch: 25/31	Total Loss -108.4170 (-102.0672)
2022-11-03 01:48:56,454:INFO: Batch: 26/31	Total Loss -105.2842 (-102.1911)
2022-11-03 01:48:56,946:INFO: Batch: 27/31	Total Loss -107.0582 (-102.3586)
2022-11-03 01:48:57,437:INFO: Batch: 28/31	Total Loss -97.5810 (-102.1900)
2022-11-03 01:48:57,929:INFO: Batch: 29/31	Total Loss -117.9770 (-102.7753)
2022-11-03 01:48:58,317:INFO: Batch: 30/31	Total Loss -94.9185 (-102.6863)
2022-11-03 01:48:58,476:INFO: - Computing ADE (validation o)
2022-11-03 01:48:59,161:INFO: 		 ADE on eth                       dataset:	 0.9164161086082458
2022-11-03 01:48:59,162:INFO: Average validation o:	ADE  0.9164	FDE  1.8980
2022-11-03 01:48:59,162:INFO: - Computing ADE (validation)
2022-11-03 01:48:59,452:INFO: 		 ADE on hotel                     dataset:	 0.43520843982696533
2022-11-03 01:48:59,821:INFO: 		 ADE on univ                      dataset:	 0.5351679921150208
2022-11-03 01:49:00,103:INFO: 		 ADE on zara1                     dataset:	 0.41792619228363037
2022-11-03 01:49:00,580:INFO: 		 ADE on zara2                     dataset:	 0.4008024036884308
2022-11-03 01:49:00,580:INFO: Average validation:	ADE  0.4736	FDE  1.0074
2022-11-03 01:49:00,581:INFO: - Computing ADE (training)
2022-11-03 01:49:01,192:INFO: 		 ADE on hotel                     dataset:	 0.4516066312789917
2022-11-03 01:49:02,265:INFO: 		 ADE on univ                      dataset:	 0.5272033214569092
2022-11-03 01:49:02,998:INFO: 		 ADE on zara1                     dataset:	 0.4467180669307709
2022-11-03 01:49:04,207:INFO: 		 ADE on zara2                     dataset:	 0.39331188797950745
2022-11-03 01:49:04,207:INFO: Average training:	ADE  0.4930	FDE  1.0516
2022-11-03 01:49:04,219:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_601.pth.tar
2022-11-03 01:49:04,219:INFO: 
===> EPOCH: 602 (P4)
2022-11-03 01:49:04,220:INFO: - Computing loss (training)
2022-11-03 01:49:05,323:INFO: Batch:  0/31	Total Loss -131.6345 (-131.6345)
2022-11-03 01:49:05,817:INFO: Batch:  1/31	Total Loss -105.3859 (-119.1177)
2022-11-03 01:49:06,310:INFO: Batch:  2/31	Total Loss -117.7676 (-118.6933)
2022-11-03 01:49:06,809:INFO: Batch:  3/31	Total Loss -118.5150 (-118.6475)
2022-11-03 01:49:07,298:INFO: Batch:  4/31	Total Loss -100.4772 (-115.0400)
2022-11-03 01:49:07,796:INFO: Batch:  5/31	Total Loss -55.5092 (-105.0444)
2022-11-03 01:49:08,287:INFO: Batch:  6/31	Total Loss -90.9344 (-103.2621)
2022-11-03 01:49:08,777:INFO: Batch:  7/31	Total Loss -103.7977 (-103.3342)
2022-11-03 01:49:09,268:INFO: Batch:  8/31	Total Loss -81.8811 (-100.9389)
2022-11-03 01:49:09,761:INFO: Batch:  9/31	Total Loss -74.4954 (-98.1380)
2022-11-03 01:49:10,251:INFO: Batch: 10/31	Total Loss -80.9699 (-96.6129)
2022-11-03 01:49:10,744:INFO: Batch: 11/31	Total Loss -63.5783 (-93.8304)
2022-11-03 01:49:11,237:INFO: Batch: 12/31	Total Loss -79.1046 (-92.6992)
2022-11-03 01:49:11,729:INFO: Batch: 13/31	Total Loss -68.8792 (-90.8609)
2022-11-03 01:49:12,224:INFO: Batch: 14/31	Total Loss -96.6292 (-91.2619)
2022-11-03 01:49:12,717:INFO: Batch: 15/31	Total Loss -69.8382 (-90.0803)
2022-11-03 01:49:13,213:INFO: Batch: 16/31	Total Loss -88.4927 (-89.9881)
2022-11-03 01:49:13,706:INFO: Batch: 17/31	Total Loss -104.8524 (-90.8636)
2022-11-03 01:49:14,200:INFO: Batch: 18/31	Total Loss -98.7083 (-91.2676)
2022-11-03 01:49:14,694:INFO: Batch: 19/31	Total Loss -81.8039 (-90.8238)
2022-11-03 01:49:15,187:INFO: Batch: 20/31	Total Loss -99.0039 (-91.2208)
2022-11-03 01:49:15,680:INFO: Batch: 21/31	Total Loss -96.2843 (-91.4286)
2022-11-03 01:49:16,172:INFO: Batch: 22/31	Total Loss -55.6943 (-89.7758)
2022-11-03 01:49:16,666:INFO: Batch: 23/31	Total Loss -92.5694 (-89.8891)
2022-11-03 01:49:17,158:INFO: Batch: 24/31	Total Loss -98.5991 (-90.2214)
2022-11-03 01:49:17,650:INFO: Batch: 25/31	Total Loss -112.0325 (-91.1690)
2022-11-03 01:49:18,141:INFO: Batch: 26/31	Total Loss -86.9728 (-91.0255)
2022-11-03 01:49:18,637:INFO: Batch: 27/31	Total Loss -102.0637 (-91.4396)
2022-11-03 01:49:19,128:INFO: Batch: 28/31	Total Loss -7.3966 (-88.5939)
2022-11-03 01:49:19,626:INFO: Batch: 29/31	Total Loss -94.7649 (-88.7848)
2022-11-03 01:49:20,015:INFO: Batch: 30/31	Total Loss -84.9130 (-88.7430)
2022-11-03 01:49:20,165:INFO: - Computing ADE (validation o)
2022-11-03 01:49:20,894:INFO: 		 ADE on eth                       dataset:	 0.9324288964271545
2022-11-03 01:49:20,894:INFO: Average validation o:	ADE  0.9324	FDE  1.9709
2022-11-03 01:49:20,895:INFO: - Computing ADE (validation)
2022-11-03 01:49:21,203:INFO: 		 ADE on hotel                     dataset:	 0.43650946021080017
2022-11-03 01:49:21,581:INFO: 		 ADE on univ                      dataset:	 0.5384232401847839
2022-11-03 01:49:21,870:INFO: 		 ADE on zara1                     dataset:	 0.42270833253860474
2022-11-03 01:49:22,352:INFO: 		 ADE on zara2                     dataset:	 0.41747331619262695
2022-11-03 01:49:22,352:INFO: Average validation:	ADE  0.4817	FDE  1.0427
2022-11-03 01:49:22,353:INFO: - Computing ADE (training)
2022-11-03 01:49:22,922:INFO: 		 ADE on hotel                     dataset:	 0.4497085511684418
2022-11-03 01:49:23,966:INFO: 		 ADE on univ                      dataset:	 0.5388090014457703
2022-11-03 01:49:24,696:INFO: 		 ADE on zara1                     dataset:	 0.4440925419330597
2022-11-03 01:49:25,861:INFO: 		 ADE on zara2                     dataset:	 0.4064791202545166
2022-11-03 01:49:25,861:INFO: Average training:	ADE  0.5037	FDE  1.0915
2022-11-03 01:49:25,872:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_602.pth.tar
2022-11-03 01:49:25,872:INFO: 
===> EPOCH: 603 (P4)
2022-11-03 01:49:25,872:INFO: - Computing loss (training)
2022-11-03 01:49:26,982:INFO: Batch:  0/31	Total Loss -101.5663 (-101.5663)
2022-11-03 01:49:27,476:INFO: Batch:  1/31	Total Loss -105.9299 (-103.8098)
2022-11-03 01:49:27,965:INFO: Batch:  2/31	Total Loss -104.5663 (-104.0601)
2022-11-03 01:49:28,455:INFO: Batch:  3/31	Total Loss -99.0829 (-102.7969)
2022-11-03 01:49:28,946:INFO: Batch:  4/31	Total Loss -102.8378 (-102.8049)
2022-11-03 01:49:29,438:INFO: Batch:  5/31	Total Loss -112.1559 (-104.4277)
2022-11-03 01:49:29,928:INFO: Batch:  6/31	Total Loss -91.0381 (-102.5284)
2022-11-03 01:49:30,417:INFO: Batch:  7/31	Total Loss -113.0458 (-103.8486)
2022-11-03 01:49:30,905:INFO: Batch:  8/31	Total Loss -106.5885 (-104.1342)
2022-11-03 01:49:31,396:INFO: Batch:  9/31	Total Loss -107.5496 (-104.4929)
2022-11-03 01:49:31,887:INFO: Batch: 10/31	Total Loss -87.8821 (-103.1142)
2022-11-03 01:49:32,376:INFO: Batch: 11/31	Total Loss -92.4478 (-102.2358)
2022-11-03 01:49:32,869:INFO: Batch: 12/31	Total Loss -112.8554 (-103.1434)
2022-11-03 01:49:33,360:INFO: Batch: 13/31	Total Loss -97.3481 (-102.7341)
2022-11-03 01:49:33,853:INFO: Batch: 14/31	Total Loss -110.3178 (-103.2438)
2022-11-03 01:49:34,344:INFO: Batch: 15/31	Total Loss -95.9637 (-102.8155)
2022-11-03 01:49:34,835:INFO: Batch: 16/31	Total Loss -103.0825 (-102.8301)
2022-11-03 01:49:35,328:INFO: Batch: 17/31	Total Loss -112.8409 (-103.4326)
2022-11-03 01:49:35,820:INFO: Batch: 18/31	Total Loss -81.0234 (-102.4593)
2022-11-03 01:49:36,310:INFO: Batch: 19/31	Total Loss -74.9506 (-101.3237)
2022-11-03 01:49:36,803:INFO: Batch: 20/31	Total Loss -56.9238 (-99.2373)
2022-11-03 01:49:37,295:INFO: Batch: 21/31	Total Loss -91.7950 (-98.9046)
2022-11-03 01:49:37,788:INFO: Batch: 22/31	Total Loss -102.7577 (-99.0773)
2022-11-03 01:49:38,279:INFO: Batch: 23/31	Total Loss -100.3783 (-99.1274)
2022-11-03 01:49:38,772:INFO: Batch: 24/31	Total Loss -108.8153 (-99.5113)
2022-11-03 01:49:39,264:INFO: Batch: 25/31	Total Loss -105.0772 (-99.7401)
2022-11-03 01:49:39,758:INFO: Batch: 26/31	Total Loss -98.5343 (-99.6967)
2022-11-03 01:49:40,252:INFO: Batch: 27/31	Total Loss -103.5586 (-99.8315)
2022-11-03 01:49:40,744:INFO: Batch: 28/31	Total Loss -101.5942 (-99.8884)
2022-11-03 01:49:41,238:INFO: Batch: 29/31	Total Loss -112.6084 (-100.3455)
2022-11-03 01:49:41,701:INFO: Batch: 30/31	Total Loss -87.2732 (-100.2299)
2022-11-03 01:49:41,854:INFO: - Computing ADE (validation o)
2022-11-03 01:49:42,536:INFO: 		 ADE on eth                       dataset:	 0.9160641431808472
2022-11-03 01:49:42,536:INFO: Average validation o:	ADE  0.9161	FDE  1.9100
2022-11-03 01:49:42,537:INFO: - Computing ADE (validation)
2022-11-03 01:49:42,844:INFO: 		 ADE on hotel                     dataset:	 0.4379763901233673
2022-11-03 01:49:43,215:INFO: 		 ADE on univ                      dataset:	 0.5361425876617432
2022-11-03 01:49:43,491:INFO: 		 ADE on zara1                     dataset:	 0.4078274369239807
2022-11-03 01:49:43,971:INFO: 		 ADE on zara2                     dataset:	 0.4049016535282135
2022-11-03 01:49:43,971:INFO: Average validation:	ADE  0.4752	FDE  1.0106
2022-11-03 01:49:43,972:INFO: - Computing ADE (training)
2022-11-03 01:49:44,518:INFO: 		 ADE on hotel                     dataset:	 0.4554601311683655
2022-11-03 01:49:45,567:INFO: 		 ADE on univ                      dataset:	 0.5325284004211426
2022-11-03 01:49:46,330:INFO: 		 ADE on zara1                     dataset:	 0.4489746391773224
2022-11-03 01:49:47,510:INFO: 		 ADE on zara2                     dataset:	 0.3958483636379242
2022-11-03 01:49:47,510:INFO: Average training:	ADE  0.4975	FDE  1.0623
2022-11-03 01:49:47,521:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_603.pth.tar
2022-11-03 01:49:47,521:INFO: 
===> EPOCH: 604 (P4)
2022-11-03 01:49:47,521:INFO: - Computing loss (training)
2022-11-03 01:49:48,639:INFO: Batch:  0/31	Total Loss -94.3351 (-94.3351)
2022-11-03 01:49:49,139:INFO: Batch:  1/31	Total Loss -111.4609 (-103.0639)
2022-11-03 01:49:49,639:INFO: Batch:  2/31	Total Loss -101.9647 (-102.6884)
2022-11-03 01:49:50,140:INFO: Batch:  3/31	Total Loss -105.8916 (-103.4818)
2022-11-03 01:49:50,640:INFO: Batch:  4/31	Total Loss -110.5932 (-105.1326)
2022-11-03 01:49:51,140:INFO: Batch:  5/31	Total Loss -100.0431 (-104.3275)
2022-11-03 01:49:51,641:INFO: Batch:  6/31	Total Loss -89.6670 (-102.3326)
2022-11-03 01:49:52,138:INFO: Batch:  7/31	Total Loss -68.5958 (-98.1755)
2022-11-03 01:49:52,639:INFO: Batch:  8/31	Total Loss -98.3478 (-98.1932)
2022-11-03 01:49:53,139:INFO: Batch:  9/31	Total Loss -126.8455 (-101.3894)
2022-11-03 01:49:53,640:INFO: Batch: 10/31	Total Loss -102.1285 (-101.4619)
2022-11-03 01:49:54,137:INFO: Batch: 11/31	Total Loss -111.5208 (-102.4186)
2022-11-03 01:49:54,637:INFO: Batch: 12/31	Total Loss -86.1777 (-101.1991)
2022-11-03 01:49:55,138:INFO: Batch: 13/31	Total Loss -99.8798 (-101.1014)
2022-11-03 01:49:55,639:INFO: Batch: 14/31	Total Loss -97.4751 (-100.8560)
2022-11-03 01:49:56,139:INFO: Batch: 15/31	Total Loss -101.1004 (-100.8705)
2022-11-03 01:49:56,639:INFO: Batch: 16/31	Total Loss -86.3906 (-100.1358)
2022-11-03 01:49:57,140:INFO: Batch: 17/31	Total Loss -97.5888 (-99.9871)
2022-11-03 01:49:57,640:INFO: Batch: 18/31	Total Loss -95.6145 (-99.7488)
2022-11-03 01:49:58,139:INFO: Batch: 19/31	Total Loss -85.6425 (-99.0975)
2022-11-03 01:49:58,640:INFO: Batch: 20/31	Total Loss -118.0793 (-100.0724)
2022-11-03 01:49:59,139:INFO: Batch: 21/31	Total Loss -91.5420 (-99.7175)
2022-11-03 01:49:59,639:INFO: Batch: 22/31	Total Loss -123.5777 (-100.8186)
2022-11-03 01:50:00,141:INFO: Batch: 23/31	Total Loss -113.2702 (-101.3180)
2022-11-03 01:50:00,642:INFO: Batch: 24/31	Total Loss -120.3410 (-102.1585)
2022-11-03 01:50:01,144:INFO: Batch: 25/31	Total Loss -54.2660 (-100.1464)
2022-11-03 01:50:01,646:INFO: Batch: 26/31	Total Loss -122.9960 (-100.9882)
2022-11-03 01:50:02,146:INFO: Batch: 27/31	Total Loss -115.5810 (-101.4995)
2022-11-03 01:50:02,646:INFO: Batch: 28/31	Total Loss -109.3656 (-101.7858)
2022-11-03 01:50:03,146:INFO: Batch: 29/31	Total Loss -102.6887 (-101.8147)
2022-11-03 01:50:03,541:INFO: Batch: 30/31	Total Loss -95.1488 (-101.7430)
2022-11-03 01:50:03,696:INFO: - Computing ADE (validation o)
2022-11-03 01:50:04,396:INFO: 		 ADE on eth                       dataset:	 0.9268315434455872
2022-11-03 01:50:04,397:INFO: Average validation o:	ADE  0.9268	FDE  1.9447
2022-11-03 01:50:04,398:INFO: - Computing ADE (validation)
2022-11-03 01:50:04,725:INFO: 		 ADE on hotel                     dataset:	 0.44553428888320923
2022-11-03 01:50:05,094:INFO: 		 ADE on univ                      dataset:	 0.5426886677742004
2022-11-03 01:50:05,375:INFO: 		 ADE on zara1                     dataset:	 0.4078328311443329
2022-11-03 01:50:05,847:INFO: 		 ADE on zara2                     dataset:	 0.4099229872226715
2022-11-03 01:50:05,848:INFO: Average validation:	ADE  0.4808	FDE  1.0231
2022-11-03 01:50:05,848:INFO: - Computing ADE (training)
2022-11-03 01:50:06,410:INFO: 		 ADE on hotel                     dataset:	 0.45215535163879395
2022-11-03 01:50:07,492:INFO: 		 ADE on univ                      dataset:	 0.5372743010520935
2022-11-03 01:50:08,280:INFO: 		 ADE on zara1                     dataset:	 0.4379509687423706
2022-11-03 01:50:09,471:INFO: 		 ADE on zara2                     dataset:	 0.39431247115135193
2022-11-03 01:50:09,472:INFO: Average training:	ADE  0.4998	FDE  1.0652
2022-11-03 01:50:09,483:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_604.pth.tar
2022-11-03 01:50:09,484:INFO: 
===> EPOCH: 605 (P4)
2022-11-03 01:50:09,484:INFO: - Computing loss (training)
2022-11-03 01:50:10,607:INFO: Batch:  0/31	Total Loss -100.9008 (-100.9008)
2022-11-03 01:50:11,106:INFO: Batch:  1/31	Total Loss -94.9635 (-97.8617)
2022-11-03 01:50:11,604:INFO: Batch:  2/31	Total Loss -122.2015 (-105.9051)
2022-11-03 01:50:12,096:INFO: Batch:  3/31	Total Loss -120.8708 (-109.7579)
2022-11-03 01:50:12,591:INFO: Batch:  4/31	Total Loss -107.4200 (-109.3358)
2022-11-03 01:50:13,086:INFO: Batch:  5/31	Total Loss -121.6395 (-111.3785)
2022-11-03 01:50:13,580:INFO: Batch:  6/31	Total Loss -99.9646 (-109.7238)
2022-11-03 01:50:14,075:INFO: Batch:  7/31	Total Loss -97.0370 (-108.1945)
2022-11-03 01:50:14,569:INFO: Batch:  8/31	Total Loss -106.9793 (-108.0581)
2022-11-03 01:50:15,061:INFO: Batch:  9/31	Total Loss -107.8583 (-108.0397)
2022-11-03 01:50:15,557:INFO: Batch: 10/31	Total Loss -108.1807 (-108.0524)
2022-11-03 01:50:16,051:INFO: Batch: 11/31	Total Loss -127.9342 (-109.8804)
2022-11-03 01:50:16,547:INFO: Batch: 12/31	Total Loss -110.5810 (-109.9406)
2022-11-03 01:50:17,043:INFO: Batch: 13/31	Total Loss -111.9939 (-110.0880)
2022-11-03 01:50:17,539:INFO: Batch: 14/31	Total Loss -105.1173 (-109.7796)
2022-11-03 01:50:18,033:INFO: Batch: 15/31	Total Loss -101.7319 (-109.3526)
2022-11-03 01:50:18,528:INFO: Batch: 16/31	Total Loss -119.5466 (-109.9865)
2022-11-03 01:50:19,025:INFO: Batch: 17/31	Total Loss -119.8929 (-110.5339)
2022-11-03 01:50:19,521:INFO: Batch: 18/31	Total Loss -127.6177 (-111.5270)
2022-11-03 01:50:20,017:INFO: Batch: 19/31	Total Loss -118.9197 (-111.9051)
2022-11-03 01:50:20,512:INFO: Batch: 20/31	Total Loss -89.7216 (-111.0159)
2022-11-03 01:50:21,008:INFO: Batch: 21/31	Total Loss -112.1466 (-111.0601)
2022-11-03 01:50:21,505:INFO: Batch: 22/31	Total Loss -109.5585 (-110.9959)
2022-11-03 01:50:22,000:INFO: Batch: 23/31	Total Loss -96.9380 (-110.4136)
2022-11-03 01:50:22,496:INFO: Batch: 24/31	Total Loss -115.3092 (-110.6058)
2022-11-03 01:50:22,993:INFO: Batch: 25/31	Total Loss -120.9947 (-111.0304)
2022-11-03 01:50:23,488:INFO: Batch: 26/31	Total Loss -26.1587 (-108.2261)
2022-11-03 01:50:23,984:INFO: Batch: 27/31	Total Loss -105.3109 (-108.1206)
2022-11-03 01:50:24,479:INFO: Batch: 28/31	Total Loss -110.5704 (-108.2008)
2022-11-03 01:50:24,975:INFO: Batch: 29/31	Total Loss -130.1796 (-109.0097)
2022-11-03 01:50:25,369:INFO: Batch: 30/31	Total Loss -93.8533 (-108.8543)
2022-11-03 01:50:25,524:INFO: - Computing ADE (validation o)
2022-11-03 01:50:26,240:INFO: 		 ADE on eth                       dataset:	 0.9211597442626953
2022-11-03 01:50:26,240:INFO: Average validation o:	ADE  0.9212	FDE  1.9204
2022-11-03 01:50:26,241:INFO: - Computing ADE (validation)
2022-11-03 01:50:26,540:INFO: 		 ADE on hotel                     dataset:	 0.4286266267299652
2022-11-03 01:50:26,927:INFO: 		 ADE on univ                      dataset:	 0.5370993614196777
2022-11-03 01:50:27,218:INFO: 		 ADE on zara1                     dataset:	 0.40011078119277954
2022-11-03 01:50:27,693:INFO: 		 ADE on zara2                     dataset:	 0.40666496753692627
2022-11-03 01:50:27,693:INFO: Average validation:	ADE  0.4753	FDE  1.0077
2022-11-03 01:50:27,694:INFO: - Computing ADE (training)
2022-11-03 01:50:28,247:INFO: 		 ADE on hotel                     dataset:	 0.4484400749206543
2022-11-03 01:50:29,296:INFO: 		 ADE on univ                      dataset:	 0.5348612070083618
2022-11-03 01:50:30,030:INFO: 		 ADE on zara1                     dataset:	 0.4413186311721802
2022-11-03 01:50:31,202:INFO: 		 ADE on zara2                     dataset:	 0.39649948477745056
2022-11-03 01:50:31,203:INFO: Average training:	ADE  0.4986	FDE  1.0613
2022-11-03 01:50:31,215:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_605.pth.tar
2022-11-03 01:50:31,215:INFO: 
===> EPOCH: 606 (P4)
2022-11-03 01:50:31,215:INFO: - Computing loss (training)
2022-11-03 01:50:32,300:INFO: Batch:  0/31	Total Loss -104.2336 (-104.2336)
2022-11-03 01:50:32,807:INFO: Batch:  1/31	Total Loss -101.9977 (-103.1851)
2022-11-03 01:50:33,306:INFO: Batch:  2/31	Total Loss -124.9250 (-111.1770)
2022-11-03 01:50:33,803:INFO: Batch:  3/31	Total Loss -129.6555 (-116.0179)
2022-11-03 01:50:34,297:INFO: Batch:  4/31	Total Loss -99.4626 (-112.6470)
2022-11-03 01:50:34,794:INFO: Batch:  5/31	Total Loss -103.7279 (-111.1729)
2022-11-03 01:50:35,290:INFO: Batch:  6/31	Total Loss -101.0593 (-109.7749)
2022-11-03 01:50:35,785:INFO: Batch:  7/31	Total Loss -101.9734 (-108.8484)
2022-11-03 01:50:36,281:INFO: Batch:  8/31	Total Loss -112.3370 (-109.2391)
2022-11-03 01:50:36,771:INFO: Batch:  9/31	Total Loss -129.2922 (-111.1947)
2022-11-03 01:50:37,266:INFO: Batch: 10/31	Total Loss -106.7252 (-110.7938)
2022-11-03 01:50:37,762:INFO: Batch: 11/31	Total Loss -125.2117 (-112.1024)
2022-11-03 01:50:38,258:INFO: Batch: 12/31	Total Loss -102.0636 (-111.4302)
2022-11-03 01:50:38,755:INFO: Batch: 13/31	Total Loss -119.1400 (-111.9870)
2022-11-03 01:50:39,251:INFO: Batch: 14/31	Total Loss -121.6888 (-112.6311)
2022-11-03 01:50:39,749:INFO: Batch: 15/31	Total Loss -135.6986 (-114.1939)
2022-11-03 01:50:40,247:INFO: Batch: 16/31	Total Loss -125.0659 (-114.8417)
2022-11-03 01:50:40,745:INFO: Batch: 17/31	Total Loss -80.6554 (-113.1025)
2022-11-03 01:50:41,321:INFO: Batch: 18/31	Total Loss -123.2837 (-113.6526)
2022-11-03 01:50:41,816:INFO: Batch: 19/31	Total Loss -130.7689 (-114.5540)
2022-11-03 01:50:42,312:INFO: Batch: 20/31	Total Loss -124.2339 (-115.0026)
2022-11-03 01:50:42,808:INFO: Batch: 21/31	Total Loss -111.1415 (-114.8149)
2022-11-03 01:50:43,304:INFO: Batch: 22/31	Total Loss -122.8369 (-115.1925)
2022-11-03 01:50:43,799:INFO: Batch: 23/31	Total Loss -43.0435 (-112.3772)
2022-11-03 01:50:44,295:INFO: Batch: 24/31	Total Loss -119.0142 (-112.6616)
2022-11-03 01:50:44,791:INFO: Batch: 25/31	Total Loss -120.8996 (-112.9964)
2022-11-03 01:50:45,288:INFO: Batch: 26/31	Total Loss -89.3139 (-112.2555)
2022-11-03 01:50:45,784:INFO: Batch: 27/31	Total Loss -125.4915 (-112.7794)
2022-11-03 01:50:46,280:INFO: Batch: 28/31	Total Loss -114.1621 (-112.8266)
2022-11-03 01:50:46,775:INFO: Batch: 29/31	Total Loss -105.2864 (-112.6053)
2022-11-03 01:50:47,165:INFO: Batch: 30/31	Total Loss -94.1000 (-112.4777)
2022-11-03 01:50:47,316:INFO: - Computing ADE (validation o)
2022-11-03 01:50:48,030:INFO: 		 ADE on eth                       dataset:	 0.9111921787261963
2022-11-03 01:50:48,031:INFO: Average validation o:	ADE  0.9112	FDE  1.9101
2022-11-03 01:50:48,031:INFO: - Computing ADE (validation)
2022-11-03 01:50:48,322:INFO: 		 ADE on hotel                     dataset:	 0.41598206758499146
2022-11-03 01:50:48,700:INFO: 		 ADE on univ                      dataset:	 0.5291722416877747
2022-11-03 01:50:48,976:INFO: 		 ADE on zara1                     dataset:	 0.4042956531047821
2022-11-03 01:50:49,481:INFO: 		 ADE on zara2                     dataset:	 0.3973255157470703
2022-11-03 01:50:49,482:INFO: Average validation:	ADE  0.4674	FDE  0.9950
2022-11-03 01:50:49,482:INFO: - Computing ADE (training)
2022-11-03 01:50:50,044:INFO: 		 ADE on hotel                     dataset:	 0.42528486251831055
2022-11-03 01:50:51,096:INFO: 		 ADE on univ                      dataset:	 0.5275819897651672
2022-11-03 01:50:51,832:INFO: 		 ADE on zara1                     dataset:	 0.43580278754234314
2022-11-03 01:50:53,018:INFO: 		 ADE on zara2                     dataset:	 0.38640064001083374
2022-11-03 01:50:53,018:INFO: Average training:	ADE  0.4905	FDE  1.0481
2022-11-03 01:50:53,030:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_606.pth.tar
2022-11-03 01:50:53,030:INFO: 
===> EPOCH: 607 (P4)
2022-11-03 01:50:53,030:INFO: - Computing loss (training)
2022-11-03 01:50:54,142:INFO: Batch:  0/31	Total Loss -109.0501 (-109.0501)
2022-11-03 01:50:54,643:INFO: Batch:  1/31	Total Loss -113.0396 (-111.0657)
2022-11-03 01:50:55,144:INFO: Batch:  2/31	Total Loss -133.3357 (-119.0171)
2022-11-03 01:50:55,648:INFO: Batch:  3/31	Total Loss -109.3887 (-116.6711)
2022-11-03 01:50:56,144:INFO: Batch:  4/31	Total Loss -119.4887 (-117.2068)
2022-11-03 01:50:56,645:INFO: Batch:  5/31	Total Loss -123.0886 (-118.2345)
2022-11-03 01:50:57,141:INFO: Batch:  6/31	Total Loss -119.4632 (-118.4109)
2022-11-03 01:50:57,638:INFO: Batch:  7/31	Total Loss -126.8082 (-119.5150)
2022-11-03 01:50:58,136:INFO: Batch:  8/31	Total Loss -113.0382 (-118.8152)
2022-11-03 01:50:58,633:INFO: Batch:  9/31	Total Loss -124.4705 (-119.3666)
2022-11-03 01:50:59,131:INFO: Batch: 10/31	Total Loss -104.1498 (-118.0301)
2022-11-03 01:50:59,628:INFO: Batch: 11/31	Total Loss -124.5157 (-118.5323)
2022-11-03 01:51:00,130:INFO: Batch: 12/31	Total Loss -86.5812 (-116.3634)
2022-11-03 01:51:00,633:INFO: Batch: 13/31	Total Loss -121.4469 (-116.7274)
2022-11-03 01:51:01,134:INFO: Batch: 14/31	Total Loss -115.0851 (-116.6159)
2022-11-03 01:51:01,637:INFO: Batch: 15/31	Total Loss -126.8661 (-117.3146)
2022-11-03 01:51:02,136:INFO: Batch: 16/31	Total Loss -126.7450 (-117.8849)
2022-11-03 01:51:02,636:INFO: Batch: 17/31	Total Loss -108.0268 (-117.3700)
2022-11-03 01:51:03,135:INFO: Batch: 18/31	Total Loss -119.1966 (-117.4640)
2022-11-03 01:51:03,634:INFO: Batch: 19/31	Total Loss -117.7432 (-117.4784)
2022-11-03 01:51:04,132:INFO: Batch: 20/31	Total Loss -102.5133 (-116.8101)
2022-11-03 01:51:04,630:INFO: Batch: 21/31	Total Loss -89.4272 (-115.6385)
2022-11-03 01:51:05,130:INFO: Batch: 22/31	Total Loss -108.6741 (-115.3206)
2022-11-03 01:51:05,630:INFO: Batch: 23/31	Total Loss -100.2140 (-114.6848)
2022-11-03 01:51:06,130:INFO: Batch: 24/31	Total Loss -115.7567 (-114.7279)
2022-11-03 01:51:06,635:INFO: Batch: 25/31	Total Loss -133.8564 (-115.6176)
2022-11-03 01:51:07,133:INFO: Batch: 26/31	Total Loss -102.5860 (-115.0959)
2022-11-03 01:51:07,635:INFO: Batch: 27/31	Total Loss -99.5857 (-114.5396)
2022-11-03 01:51:08,136:INFO: Batch: 28/31	Total Loss -131.0186 (-115.1331)
2022-11-03 01:51:08,635:INFO: Batch: 29/31	Total Loss -112.8973 (-115.0554)
2022-11-03 01:51:09,030:INFO: Batch: 30/31	Total Loss -85.0316 (-114.8080)
2022-11-03 01:51:09,176:INFO: - Computing ADE (validation o)
2022-11-03 01:51:09,852:INFO: 		 ADE on eth                       dataset:	 0.9061766862869263
2022-11-03 01:51:09,852:INFO: Average validation o:	ADE  0.9062	FDE  1.9210
2022-11-03 01:51:09,853:INFO: - Computing ADE (validation)
2022-11-03 01:51:10,144:INFO: 		 ADE on hotel                     dataset:	 0.42648711800575256
2022-11-03 01:51:10,514:INFO: 		 ADE on univ                      dataset:	 0.5390775799751282
2022-11-03 01:51:10,792:INFO: 		 ADE on zara1                     dataset:	 0.4128235876560211
2022-11-03 01:51:11,257:INFO: 		 ADE on zara2                     dataset:	 0.400382399559021
2022-11-03 01:51:11,257:INFO: Average validation:	ADE  0.4747	FDE  1.0196
2022-11-03 01:51:11,258:INFO: - Computing ADE (training)
2022-11-03 01:51:11,851:INFO: 		 ADE on hotel                     dataset:	 0.4434505105018616
2022-11-03 01:51:12,908:INFO: 		 ADE on univ                      dataset:	 0.5345144271850586
2022-11-03 01:51:13,646:INFO: 		 ADE on zara1                     dataset:	 0.42807435989379883
2022-11-03 01:51:14,821:INFO: 		 ADE on zara2                     dataset:	 0.38202720880508423
2022-11-03 01:51:14,821:INFO: Average training:	ADE  0.4945	FDE  1.0616
2022-11-03 01:51:14,832:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_607.pth.tar
2022-11-03 01:51:14,832:INFO: 
===> EPOCH: 608 (P4)
2022-11-03 01:51:14,833:INFO: - Computing loss (training)
2022-11-03 01:51:15,964:INFO: Batch:  0/31	Total Loss -113.9195 (-113.9195)
2022-11-03 01:51:16,472:INFO: Batch:  1/31	Total Loss -135.1335 (-125.0481)
2022-11-03 01:51:16,972:INFO: Batch:  2/31	Total Loss -124.1932 (-124.7471)
2022-11-03 01:51:17,472:INFO: Batch:  3/31	Total Loss -115.8121 (-122.6063)
2022-11-03 01:51:17,967:INFO: Batch:  4/31	Total Loss -119.2335 (-121.9914)
2022-11-03 01:51:18,469:INFO: Batch:  5/31	Total Loss -113.1992 (-120.5708)
2022-11-03 01:51:18,966:INFO: Batch:  6/31	Total Loss -111.0975 (-119.3327)
2022-11-03 01:51:19,462:INFO: Batch:  7/31	Total Loss -111.2665 (-118.3912)
2022-11-03 01:51:19,960:INFO: Batch:  8/31	Total Loss -143.2330 (-121.3562)
2022-11-03 01:51:20,458:INFO: Batch:  9/31	Total Loss -120.9760 (-121.3172)
2022-11-03 01:51:20,962:INFO: Batch: 10/31	Total Loss -117.1355 (-120.9403)
2022-11-03 01:51:21,474:INFO: Batch: 11/31	Total Loss -125.4857 (-121.3450)
2022-11-03 01:51:21,976:INFO: Batch: 12/31	Total Loss -113.3330 (-120.6814)
2022-11-03 01:51:22,525:INFO: Batch: 13/31	Total Loss -130.2095 (-121.3430)
2022-11-03 01:51:23,033:INFO: Batch: 14/31	Total Loss -90.7826 (-119.5215)
2022-11-03 01:51:23,531:INFO: Batch: 15/31	Total Loss -104.6373 (-118.6145)
2022-11-03 01:51:24,030:INFO: Batch: 16/31	Total Loss -59.1921 (-115.4005)
2022-11-03 01:51:24,526:INFO: Batch: 17/31	Total Loss -76.3661 (-113.5077)
2022-11-03 01:51:25,025:INFO: Batch: 18/31	Total Loss -98.7264 (-112.7240)
2022-11-03 01:51:25,523:INFO: Batch: 19/31	Total Loss -107.0129 (-112.4541)
2022-11-03 01:51:26,021:INFO: Batch: 20/31	Total Loss -113.6593 (-112.5122)
2022-11-03 01:51:26,521:INFO: Batch: 21/31	Total Loss -107.0964 (-112.2512)
2022-11-03 01:51:27,019:INFO: Batch: 22/31	Total Loss -96.4508 (-111.4877)
2022-11-03 01:51:27,516:INFO: Batch: 23/31	Total Loss -106.4953 (-111.2931)
2022-11-03 01:51:28,015:INFO: Batch: 24/31	Total Loss -99.7733 (-110.8000)
2022-11-03 01:51:28,513:INFO: Batch: 25/31	Total Loss -87.9357 (-109.8830)
2022-11-03 01:51:29,011:INFO: Batch: 26/31	Total Loss -108.8507 (-109.8464)
2022-11-03 01:51:29,511:INFO: Batch: 27/31	Total Loss -114.5284 (-110.0355)
2022-11-03 01:51:30,011:INFO: Batch: 28/31	Total Loss -101.6621 (-109.7268)
2022-11-03 01:51:30,508:INFO: Batch: 29/31	Total Loss -92.1274 (-109.1775)
2022-11-03 01:51:30,904:INFO: Batch: 30/31	Total Loss -97.5766 (-109.0617)
2022-11-03 01:51:31,051:INFO: - Computing ADE (validation o)
2022-11-03 01:51:31,735:INFO: 		 ADE on eth                       dataset:	 0.9137775301933289
2022-11-03 01:51:31,735:INFO: Average validation o:	ADE  0.9138	FDE  1.9094
2022-11-03 01:51:31,736:INFO: - Computing ADE (validation)
2022-11-03 01:51:32,049:INFO: 		 ADE on hotel                     dataset:	 0.4111936390399933
2022-11-03 01:51:32,448:INFO: 		 ADE on univ                      dataset:	 0.5261783003807068
2022-11-03 01:51:32,748:INFO: 		 ADE on zara1                     dataset:	 0.4034371078014374
2022-11-03 01:51:33,234:INFO: 		 ADE on zara2                     dataset:	 0.39799097180366516
2022-11-03 01:51:33,235:INFO: Average validation:	ADE  0.4657	FDE  0.9904
2022-11-03 01:51:33,235:INFO: - Computing ADE (training)
2022-11-03 01:51:33,807:INFO: 		 ADE on hotel                     dataset:	 0.4202284812927246
2022-11-03 01:51:34,874:INFO: 		 ADE on univ                      dataset:	 0.524294912815094
2022-11-03 01:51:35,631:INFO: 		 ADE on zara1                     dataset:	 0.44050952792167664
2022-11-03 01:51:36,836:INFO: 		 ADE on zara2                     dataset:	 0.39033082127571106
2022-11-03 01:51:36,836:INFO: Average training:	ADE  0.4891	FDE  1.0446
2022-11-03 01:51:36,848:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_608.pth.tar
2022-11-03 01:51:36,848:INFO: 
===> EPOCH: 609 (P4)
2022-11-03 01:51:36,848:INFO: - Computing loss (training)
2022-11-03 01:51:37,951:INFO: Batch:  0/31	Total Loss -104.1668 (-104.1668)
2022-11-03 01:51:38,444:INFO: Batch:  1/31	Total Loss -107.4901 (-105.8703)
2022-11-03 01:51:39,015:INFO: Batch:  2/31	Total Loss -74.7314 (-96.1472)
2022-11-03 01:51:39,509:INFO: Batch:  3/31	Total Loss -119.8293 (-102.0751)
2022-11-03 01:51:39,999:INFO: Batch:  4/31	Total Loss -117.7064 (-105.2961)
2022-11-03 01:51:40,492:INFO: Batch:  5/31	Total Loss -117.0405 (-107.3107)
2022-11-03 01:51:40,983:INFO: Batch:  6/31	Total Loss -99.5872 (-106.1993)
2022-11-03 01:51:41,472:INFO: Batch:  7/31	Total Loss -86.0501 (-103.9549)
2022-11-03 01:51:41,963:INFO: Batch:  8/31	Total Loss -98.2681 (-103.3552)
2022-11-03 01:51:42,453:INFO: Batch:  9/31	Total Loss -94.5899 (-102.5319)
2022-11-03 01:51:42,942:INFO: Batch: 10/31	Total Loss -109.5702 (-103.1905)
2022-11-03 01:51:43,433:INFO: Batch: 11/31	Total Loss -101.0079 (-103.0190)
2022-11-03 01:51:43,925:INFO: Batch: 12/31	Total Loss -90.5532 (-102.0959)
2022-11-03 01:51:44,417:INFO: Batch: 13/31	Total Loss -61.2080 (-99.7262)
2022-11-03 01:51:44,909:INFO: Batch: 14/31	Total Loss -100.6646 (-99.7830)
2022-11-03 01:51:45,403:INFO: Batch: 15/31	Total Loss -115.1416 (-100.8068)
2022-11-03 01:51:45,895:INFO: Batch: 16/31	Total Loss -111.8392 (-101.4775)
2022-11-03 01:51:46,387:INFO: Batch: 17/31	Total Loss -103.7359 (-101.6022)
2022-11-03 01:51:46,880:INFO: Batch: 18/31	Total Loss -118.4901 (-102.5712)
2022-11-03 01:51:47,371:INFO: Batch: 19/31	Total Loss -101.0200 (-102.5006)
2022-11-03 01:51:47,862:INFO: Batch: 20/31	Total Loss -109.7971 (-102.8396)
2022-11-03 01:51:48,353:INFO: Batch: 21/31	Total Loss -131.8062 (-104.3056)
2022-11-03 01:51:48,842:INFO: Batch: 22/31	Total Loss -128.8533 (-105.4453)
2022-11-03 01:51:49,331:INFO: Batch: 23/31	Total Loss -134.7424 (-106.7405)
2022-11-03 01:51:49,823:INFO: Batch: 24/31	Total Loss -54.3846 (-104.4770)
2022-11-03 01:51:50,313:INFO: Batch: 25/31	Total Loss -106.9751 (-104.5679)
2022-11-03 01:51:50,806:INFO: Batch: 26/31	Total Loss -103.5853 (-104.5268)
2022-11-03 01:51:51,296:INFO: Batch: 27/31	Total Loss -102.8694 (-104.4696)
2022-11-03 01:51:51,786:INFO: Batch: 28/31	Total Loss -107.5440 (-104.5668)
2022-11-03 01:51:52,276:INFO: Batch: 29/31	Total Loss -122.7042 (-105.1575)
2022-11-03 01:51:52,667:INFO: Batch: 30/31	Total Loss -102.7215 (-105.1280)
2022-11-03 01:51:52,831:INFO: - Computing ADE (validation o)
2022-11-03 01:51:53,527:INFO: 		 ADE on eth                       dataset:	 0.9302239418029785
2022-11-03 01:51:53,527:INFO: Average validation o:	ADE  0.9302	FDE  1.9644
2022-11-03 01:51:53,528:INFO: - Computing ADE (validation)
2022-11-03 01:51:53,811:INFO: 		 ADE on hotel                     dataset:	 0.4325805604457855
2022-11-03 01:51:54,195:INFO: 		 ADE on univ                      dataset:	 0.5408833622932434
2022-11-03 01:51:54,483:INFO: 		 ADE on zara1                     dataset:	 0.4107774496078491
2022-11-03 01:51:54,958:INFO: 		 ADE on zara2                     dataset:	 0.4190100431442261
2022-11-03 01:51:54,958:INFO: Average validation:	ADE  0.4827	FDE  1.0194
2022-11-03 01:51:54,959:INFO: - Computing ADE (training)
2022-11-03 01:51:55,544:INFO: 		 ADE on hotel                     dataset:	 0.4399356245994568
2022-11-03 01:51:56,604:INFO: 		 ADE on univ                      dataset:	 0.5429815053939819
2022-11-03 01:51:57,328:INFO: 		 ADE on zara1                     dataset:	 0.43892183899879456
2022-11-03 01:51:58,552:INFO: 		 ADE on zara2                     dataset:	 0.40317532420158386
2022-11-03 01:51:58,552:INFO: Average training:	ADE  0.5054	FDE  1.0713
2022-11-03 01:51:58,563:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_609.pth.tar
2022-11-03 01:51:58,564:INFO: 
===> EPOCH: 610 (P4)
2022-11-03 01:51:58,564:INFO: - Computing loss (training)
2022-11-03 01:51:59,683:INFO: Batch:  0/31	Total Loss -112.8114 (-112.8114)
2022-11-03 01:52:00,174:INFO: Batch:  1/31	Total Loss -112.4355 (-112.6269)
2022-11-03 01:52:00,672:INFO: Batch:  2/31	Total Loss -123.0220 (-116.2132)
2022-11-03 01:52:01,157:INFO: Batch:  3/31	Total Loss -107.3929 (-113.9881)
2022-11-03 01:52:01,648:INFO: Batch:  4/31	Total Loss -115.5623 (-114.3037)
2022-11-03 01:52:02,141:INFO: Batch:  5/31	Total Loss -122.8636 (-115.7330)
2022-11-03 01:52:02,632:INFO: Batch:  6/31	Total Loss -100.7944 (-113.5053)
2022-11-03 01:52:03,119:INFO: Batch:  7/31	Total Loss -114.1359 (-113.5853)
2022-11-03 01:52:03,606:INFO: Batch:  8/31	Total Loss -111.7546 (-113.3838)
2022-11-03 01:52:04,094:INFO: Batch:  9/31	Total Loss -134.5937 (-115.8223)
2022-11-03 01:52:04,583:INFO: Batch: 10/31	Total Loss -129.5433 (-117.0229)
2022-11-03 01:52:05,071:INFO: Batch: 11/31	Total Loss -69.5113 (-112.8586)
2022-11-03 01:52:05,562:INFO: Batch: 12/31	Total Loss -121.3607 (-113.5347)
2022-11-03 01:52:06,053:INFO: Batch: 13/31	Total Loss -95.9133 (-112.3296)
2022-11-03 01:52:06,544:INFO: Batch: 14/31	Total Loss -124.7604 (-113.1738)
2022-11-03 01:52:07,035:INFO: Batch: 15/31	Total Loss -120.4381 (-113.6896)
2022-11-03 01:52:07,526:INFO: Batch: 16/31	Total Loss -105.4164 (-113.2028)
2022-11-03 01:52:08,019:INFO: Batch: 17/31	Total Loss -115.3383 (-113.3324)
2022-11-03 01:52:08,511:INFO: Batch: 18/31	Total Loss -65.9881 (-110.8877)
2022-11-03 01:52:09,002:INFO: Batch: 19/31	Total Loss -110.0325 (-110.8419)
2022-11-03 01:52:09,492:INFO: Batch: 20/31	Total Loss -107.9240 (-110.7146)
2022-11-03 01:52:09,984:INFO: Batch: 21/31	Total Loss -119.1269 (-111.0695)
2022-11-03 01:52:10,474:INFO: Batch: 22/31	Total Loss -113.3253 (-111.1692)
2022-11-03 01:52:10,968:INFO: Batch: 23/31	Total Loss -103.4788 (-110.8845)
2022-11-03 01:52:11,459:INFO: Batch: 24/31	Total Loss -87.3445 (-110.0449)
2022-11-03 01:52:11,951:INFO: Batch: 25/31	Total Loss -97.9299 (-109.6322)
2022-11-03 01:52:12,442:INFO: Batch: 26/31	Total Loss -105.3136 (-109.4803)
2022-11-03 01:52:12,933:INFO: Batch: 27/31	Total Loss -112.6007 (-109.5847)
2022-11-03 01:52:13,425:INFO: Batch: 28/31	Total Loss -125.4837 (-110.0942)
2022-11-03 01:52:13,917:INFO: Batch: 29/31	Total Loss -116.3934 (-110.2989)
2022-11-03 01:52:14,302:INFO: Batch: 30/31	Total Loss -87.9177 (-110.0888)
2022-11-03 01:52:14,452:INFO: - Computing ADE (validation o)
2022-11-03 01:52:15,195:INFO: 		 ADE on eth                       dataset:	 0.9209203124046326
2022-11-03 01:52:15,196:INFO: Average validation o:	ADE  0.9209	FDE  1.9633
2022-11-03 01:52:15,196:INFO: - Computing ADE (validation)
2022-11-03 01:52:15,506:INFO: 		 ADE on hotel                     dataset:	 0.4125515818595886
2022-11-03 01:52:15,870:INFO: 		 ADE on univ                      dataset:	 0.5347467064857483
2022-11-03 01:52:16,145:INFO: 		 ADE on zara1                     dataset:	 0.39741724729537964
2022-11-03 01:52:16,623:INFO: 		 ADE on zara2                     dataset:	 0.3948984444141388
2022-11-03 01:52:16,623:INFO: Average validation:	ADE  0.4688	FDE  1.0009
2022-11-03 01:52:16,624:INFO: - Computing ADE (training)
2022-11-03 01:52:17,207:INFO: 		 ADE on hotel                     dataset:	 0.42912083864212036
2022-11-03 01:52:18,247:INFO: 		 ADE on univ                      dataset:	 0.5290848612785339
2022-11-03 01:52:18,968:INFO: 		 ADE on zara1                     dataset:	 0.43041613698005676
2022-11-03 01:52:20,120:INFO: 		 ADE on zara2                     dataset:	 0.379935085773468
2022-11-03 01:52:20,121:INFO: Average training:	ADE  0.4900	FDE  1.0477
2022-11-03 01:52:20,132:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_610.pth.tar
2022-11-03 01:52:20,132:INFO: 
===> EPOCH: 611 (P4)
2022-11-03 01:52:20,132:INFO: - Computing loss (training)
2022-11-03 01:52:21,257:INFO: Batch:  0/31	Total Loss -110.7264 (-110.7264)
2022-11-03 01:52:21,765:INFO: Batch:  1/31	Total Loss -114.5953 (-112.5877)
2022-11-03 01:52:22,271:INFO: Batch:  2/31	Total Loss -114.3669 (-113.1884)
2022-11-03 01:52:22,776:INFO: Batch:  3/31	Total Loss -125.9698 (-116.4386)
2022-11-03 01:52:23,278:INFO: Batch:  4/31	Total Loss -104.3098 (-114.1822)
2022-11-03 01:52:23,788:INFO: Batch:  5/31	Total Loss -117.6477 (-114.7867)
2022-11-03 01:52:24,295:INFO: Batch:  6/31	Total Loss -104.5284 (-113.4379)
2022-11-03 01:52:24,802:INFO: Batch:  7/31	Total Loss -111.2716 (-113.1602)
2022-11-03 01:52:25,307:INFO: Batch:  8/31	Total Loss -128.9156 (-114.9221)
2022-11-03 01:52:25,811:INFO: Batch:  9/31	Total Loss -119.3195 (-115.3297)
2022-11-03 01:52:26,315:INFO: Batch: 10/31	Total Loss -125.0330 (-116.2664)
2022-11-03 01:52:26,822:INFO: Batch: 11/31	Total Loss -114.5401 (-116.1270)
2022-11-03 01:52:27,331:INFO: Batch: 12/31	Total Loss -106.4600 (-115.4454)
2022-11-03 01:52:27,839:INFO: Batch: 13/31	Total Loss -107.5523 (-114.9118)
2022-11-03 01:52:28,351:INFO: Batch: 14/31	Total Loss -128.3940 (-115.8945)
2022-11-03 01:52:28,857:INFO: Batch: 15/31	Total Loss -124.8185 (-116.4712)
2022-11-03 01:52:29,363:INFO: Batch: 16/31	Total Loss -121.2523 (-116.7683)
2022-11-03 01:52:29,866:INFO: Batch: 17/31	Total Loss -130.9212 (-117.5549)
2022-11-03 01:52:30,371:INFO: Batch: 18/31	Total Loss -120.5003 (-117.7088)
2022-11-03 01:52:30,877:INFO: Batch: 19/31	Total Loss -149.2996 (-119.4710)
2022-11-03 01:52:31,379:INFO: Batch: 20/31	Total Loss -122.8591 (-119.6195)
2022-11-03 01:52:31,882:INFO: Batch: 21/31	Total Loss -128.6576 (-120.0295)
2022-11-03 01:52:32,386:INFO: Batch: 22/31	Total Loss -127.8235 (-120.4048)
2022-11-03 01:52:32,891:INFO: Batch: 23/31	Total Loss -132.0840 (-120.8943)
2022-11-03 01:52:33,396:INFO: Batch: 24/31	Total Loss -128.8554 (-121.2596)
2022-11-03 01:52:33,902:INFO: Batch: 25/31	Total Loss -134.5237 (-121.7861)
2022-11-03 01:52:34,406:INFO: Batch: 26/31	Total Loss -136.7395 (-122.3570)
2022-11-03 01:52:34,912:INFO: Batch: 27/31	Total Loss -131.5267 (-122.6856)
2022-11-03 01:52:35,419:INFO: Batch: 28/31	Total Loss -51.8904 (-120.4642)
2022-11-03 01:52:35,925:INFO: Batch: 29/31	Total Loss -133.0342 (-120.8838)
2022-11-03 01:52:36,405:INFO: Batch: 30/31	Total Loss -74.6481 (-120.5138)
2022-11-03 01:52:36,553:INFO: - Computing ADE (validation o)
2022-11-03 01:52:37,241:INFO: 		 ADE on eth                       dataset:	 0.9131463170051575
2022-11-03 01:52:37,241:INFO: Average validation o:	ADE  0.9131	FDE  1.9527
2022-11-03 01:52:37,241:INFO: - Computing ADE (validation)
2022-11-03 01:52:37,534:INFO: 		 ADE on hotel                     dataset:	 0.4229305386543274
2022-11-03 01:52:37,934:INFO: 		 ADE on univ                      dataset:	 0.534612238407135
2022-11-03 01:52:38,227:INFO: 		 ADE on zara1                     dataset:	 0.39377933740615845
2022-11-03 01:52:38,696:INFO: 		 ADE on zara2                     dataset:	 0.3913627862930298
2022-11-03 01:52:38,697:INFO: Average validation:	ADE  0.4678	FDE  0.9958
2022-11-03 01:52:38,697:INFO: - Computing ADE (training)
2022-11-03 01:52:39,291:INFO: 		 ADE on hotel                     dataset:	 0.44231992959976196
2022-11-03 01:52:40,306:INFO: 		 ADE on univ                      dataset:	 0.5280132293701172
2022-11-03 01:52:41,086:INFO: 		 ADE on zara1                     dataset:	 0.4327984154224396
2022-11-03 01:52:42,255:INFO: 		 ADE on zara2                     dataset:	 0.38187888264656067
2022-11-03 01:52:42,255:INFO: Average training:	ADE  0.4901	FDE  1.0471
2022-11-03 01:52:42,266:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_611.pth.tar
2022-11-03 01:52:42,266:INFO: 
===> EPOCH: 612 (P4)
2022-11-03 01:52:42,267:INFO: - Computing loss (training)
2022-11-03 01:52:43,410:INFO: Batch:  0/31	Total Loss -128.5534 (-128.5534)
2022-11-03 01:52:43,919:INFO: Batch:  1/31	Total Loss -120.5888 (-124.6351)
2022-11-03 01:52:44,428:INFO: Batch:  2/31	Total Loss -114.3933 (-121.4992)
2022-11-03 01:52:44,934:INFO: Batch:  3/31	Total Loss -140.7525 (-126.4742)
2022-11-03 01:52:45,437:INFO: Batch:  4/31	Total Loss -119.6730 (-124.9970)
2022-11-03 01:52:45,950:INFO: Batch:  5/31	Total Loss -128.6871 (-125.6053)
2022-11-03 01:52:46,457:INFO: Batch:  6/31	Total Loss -125.3961 (-125.5755)
2022-11-03 01:52:46,974:INFO: Batch:  7/31	Total Loss -119.7574 (-124.8708)
2022-11-03 01:52:47,481:INFO: Batch:  8/31	Total Loss -114.9246 (-123.8524)
2022-11-03 01:52:47,984:INFO: Batch:  9/31	Total Loss -106.4443 (-122.2514)
2022-11-03 01:52:48,487:INFO: Batch: 10/31	Total Loss -92.9265 (-119.7865)
2022-11-03 01:52:48,994:INFO: Batch: 11/31	Total Loss -127.1693 (-120.4175)
2022-11-03 01:52:49,500:INFO: Batch: 12/31	Total Loss -111.5082 (-119.7627)
2022-11-03 01:52:50,006:INFO: Batch: 13/31	Total Loss -122.3904 (-119.9586)
2022-11-03 01:52:50,512:INFO: Batch: 14/31	Total Loss -136.8439 (-121.0797)
2022-11-03 01:52:51,019:INFO: Batch: 15/31	Total Loss -126.9385 (-121.4375)
2022-11-03 01:52:51,524:INFO: Batch: 16/31	Total Loss -113.3125 (-120.9470)
2022-11-03 01:52:52,030:INFO: Batch: 17/31	Total Loss -112.4739 (-120.5243)
2022-11-03 01:52:52,536:INFO: Batch: 18/31	Total Loss -111.4168 (-120.0995)
2022-11-03 01:52:53,043:INFO: Batch: 19/31	Total Loss -120.0508 (-120.0969)
2022-11-03 01:52:53,547:INFO: Batch: 20/31	Total Loss -118.4141 (-120.0139)
2022-11-03 01:52:54,051:INFO: Batch: 21/31	Total Loss -98.5316 (-118.9969)
2022-11-03 01:52:54,555:INFO: Batch: 22/31	Total Loss -126.3181 (-119.3105)
2022-11-03 01:52:55,060:INFO: Batch: 23/31	Total Loss -70.3056 (-117.3991)
2022-11-03 01:52:55,565:INFO: Batch: 24/31	Total Loss -128.5877 (-117.8467)
2022-11-03 01:52:56,069:INFO: Batch: 25/31	Total Loss -142.1805 (-118.8341)
2022-11-03 01:52:56,574:INFO: Batch: 26/31	Total Loss -117.4358 (-118.7819)
2022-11-03 01:52:57,078:INFO: Batch: 27/31	Total Loss -108.0511 (-118.3920)
2022-11-03 01:52:57,580:INFO: Batch: 28/31	Total Loss -101.2444 (-117.8366)
2022-11-03 01:52:58,082:INFO: Batch: 29/31	Total Loss -98.9758 (-117.2493)
2022-11-03 01:52:58,479:INFO: Batch: 30/31	Total Loss -95.7193 (-117.0197)
2022-11-03 01:52:58,619:INFO: - Computing ADE (validation o)
2022-11-03 01:52:59,335:INFO: 		 ADE on eth                       dataset:	 0.9217294454574585
2022-11-03 01:52:59,335:INFO: Average validation o:	ADE  0.9217	FDE  1.9368
2022-11-03 01:52:59,336:INFO: - Computing ADE (validation)
2022-11-03 01:52:59,639:INFO: 		 ADE on hotel                     dataset:	 0.41923943161964417
2022-11-03 01:53:00,006:INFO: 		 ADE on univ                      dataset:	 0.5424624681472778
2022-11-03 01:53:00,304:INFO: 		 ADE on zara1                     dataset:	 0.4283437430858612
2022-11-03 01:53:00,787:INFO: 		 ADE on zara2                     dataset:	 0.41560471057891846
2022-11-03 01:53:00,787:INFO: Average validation:	ADE  0.4825	FDE  1.0211
2022-11-03 01:53:00,788:INFO: - Computing ADE (training)
2022-11-03 01:53:01,346:INFO: 		 ADE on hotel                     dataset:	 0.427407443523407
2022-11-03 01:53:02,388:INFO: 		 ADE on univ                      dataset:	 0.5376984477043152
2022-11-03 01:53:03,155:INFO: 		 ADE on zara1                     dataset:	 0.4473281800746918
2022-11-03 01:53:04,326:INFO: 		 ADE on zara2                     dataset:	 0.4045374393463135
2022-11-03 01:53:04,327:INFO: Average training:	ADE  0.5021	FDE  1.0658
2022-11-03 01:53:04,338:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_612.pth.tar
2022-11-03 01:53:04,338:INFO: 
===> EPOCH: 613 (P4)
2022-11-03 01:53:04,339:INFO: - Computing loss (training)
2022-11-03 01:53:05,451:INFO: Batch:  0/31	Total Loss -119.2516 (-119.2516)
2022-11-03 01:53:05,950:INFO: Batch:  1/31	Total Loss -103.8261 (-112.0684)
2022-11-03 01:53:06,458:INFO: Batch:  2/31	Total Loss -98.9176 (-108.0314)
2022-11-03 01:53:06,956:INFO: Batch:  3/31	Total Loss -119.3207 (-110.9798)
2022-11-03 01:53:07,457:INFO: Batch:  4/31	Total Loss -103.6653 (-109.5464)
2022-11-03 01:53:07,960:INFO: Batch:  5/31	Total Loss -104.5511 (-108.7161)
2022-11-03 01:53:08,458:INFO: Batch:  6/31	Total Loss -110.9890 (-109.0275)
2022-11-03 01:53:08,959:INFO: Batch:  7/31	Total Loss -112.8957 (-109.5046)
2022-11-03 01:53:09,456:INFO: Batch:  8/31	Total Loss -139.2653 (-113.0631)
2022-11-03 01:53:09,952:INFO: Batch:  9/31	Total Loss -145.9841 (-116.6964)
2022-11-03 01:53:10,453:INFO: Batch: 10/31	Total Loss -134.6788 (-118.2649)
2022-11-03 01:53:10,949:INFO: Batch: 11/31	Total Loss -99.6072 (-116.6898)
2022-11-03 01:53:11,450:INFO: Batch: 12/31	Total Loss -146.5616 (-119.4238)
2022-11-03 01:53:11,950:INFO: Batch: 13/31	Total Loss -139.0399 (-120.9510)
2022-11-03 01:53:12,450:INFO: Batch: 14/31	Total Loss -115.6388 (-120.5643)
2022-11-03 01:53:12,950:INFO: Batch: 15/31	Total Loss -111.7644 (-120.0455)
2022-11-03 01:53:13,450:INFO: Batch: 16/31	Total Loss -133.7671 (-120.9315)
2022-11-03 01:53:13,951:INFO: Batch: 17/31	Total Loss -113.6385 (-120.5417)
2022-11-03 01:53:14,453:INFO: Batch: 18/31	Total Loss -103.2396 (-119.6887)
2022-11-03 01:53:14,952:INFO: Batch: 19/31	Total Loss -137.9811 (-120.6267)
2022-11-03 01:53:15,454:INFO: Batch: 20/31	Total Loss -137.6870 (-121.4415)
2022-11-03 01:53:15,953:INFO: Batch: 21/31	Total Loss -136.7118 (-122.2547)
2022-11-03 01:53:16,456:INFO: Batch: 22/31	Total Loss -136.4604 (-122.9021)
2022-11-03 01:53:16,959:INFO: Batch: 23/31	Total Loss -116.8458 (-122.6528)
2022-11-03 01:53:17,460:INFO: Batch: 24/31	Total Loss -112.5223 (-122.2900)
2022-11-03 01:53:17,962:INFO: Batch: 25/31	Total Loss -126.3454 (-122.4583)
2022-11-03 01:53:18,464:INFO: Batch: 26/31	Total Loss -123.1321 (-122.4832)
2022-11-03 01:53:18,966:INFO: Batch: 27/31	Total Loss -122.6852 (-122.4896)
2022-11-03 01:53:19,465:INFO: Batch: 28/31	Total Loss -145.0215 (-123.3043)
2022-11-03 01:53:19,964:INFO: Batch: 29/31	Total Loss -126.5114 (-123.4063)
2022-11-03 01:53:20,361:INFO: Batch: 30/31	Total Loss -81.2727 (-122.9572)
2022-11-03 01:53:20,521:INFO: - Computing ADE (validation o)
2022-11-03 01:53:21,223:INFO: 		 ADE on eth                       dataset:	 0.928849458694458
2022-11-03 01:53:21,223:INFO: Average validation o:	ADE  0.9288	FDE  1.9948
2022-11-03 01:53:21,223:INFO: - Computing ADE (validation)
2022-11-03 01:53:21,537:INFO: 		 ADE on hotel                     dataset:	 0.4151571989059448
2022-11-03 01:53:21,915:INFO: 		 ADE on univ                      dataset:	 0.5387688279151917
2022-11-03 01:53:22,202:INFO: 		 ADE on zara1                     dataset:	 0.40062007308006287
2022-11-03 01:53:22,691:INFO: 		 ADE on zara2                     dataset:	 0.4025670289993286
2022-11-03 01:53:22,691:INFO: Average validation:	ADE  0.4740	FDE  1.0196
2022-11-03 01:53:22,692:INFO: - Computing ADE (training)
2022-11-03 01:53:23,267:INFO: 		 ADE on hotel                     dataset:	 0.4311997592449188
2022-11-03 01:53:24,320:INFO: 		 ADE on univ                      dataset:	 0.5364524722099304
2022-11-03 01:53:25,077:INFO: 		 ADE on zara1                     dataset:	 0.43295589089393616
2022-11-03 01:53:26,258:INFO: 		 ADE on zara2                     dataset:	 0.38877588510513306
2022-11-03 01:53:26,258:INFO: Average training:	ADE  0.4972	FDE  1.0710
2022-11-03 01:53:26,270:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_613.pth.tar
2022-11-03 01:53:26,270:INFO: 
===> EPOCH: 614 (P4)
2022-11-03 01:53:26,270:INFO: - Computing loss (training)
2022-11-03 01:53:27,401:INFO: Batch:  0/31	Total Loss -120.3856 (-120.3856)
2022-11-03 01:53:27,895:INFO: Batch:  1/31	Total Loss -106.4753 (-113.4076)
2022-11-03 01:53:28,396:INFO: Batch:  2/31	Total Loss -123.5760 (-116.9584)
2022-11-03 01:53:28,900:INFO: Batch:  3/31	Total Loss -113.7974 (-116.1811)
2022-11-03 01:53:29,396:INFO: Batch:  4/31	Total Loss -112.7567 (-115.5058)
2022-11-03 01:53:29,901:INFO: Batch:  5/31	Total Loss -121.7259 (-116.6310)
2022-11-03 01:53:30,401:INFO: Batch:  6/31	Total Loss -121.3261 (-117.3348)
2022-11-03 01:53:30,908:INFO: Batch:  7/31	Total Loss -142.2707 (-120.6529)
2022-11-03 01:53:31,409:INFO: Batch:  8/31	Total Loss -129.7994 (-121.6843)
2022-11-03 01:53:31,911:INFO: Batch:  9/31	Total Loss -130.0150 (-122.5254)
2022-11-03 01:53:32,413:INFO: Batch: 10/31	Total Loss -120.6801 (-122.3630)
2022-11-03 01:53:32,993:INFO: Batch: 11/31	Total Loss -147.4174 (-124.4635)
2022-11-03 01:53:33,497:INFO: Batch: 12/31	Total Loss -118.0637 (-123.8995)
2022-11-03 01:53:34,001:INFO: Batch: 13/31	Total Loss -124.5817 (-123.9492)
2022-11-03 01:53:34,503:INFO: Batch: 14/31	Total Loss -133.3557 (-124.5969)
2022-11-03 01:53:35,007:INFO: Batch: 15/31	Total Loss -141.5715 (-125.6560)
2022-11-03 01:53:35,509:INFO: Batch: 16/31	Total Loss -148.6973 (-127.1375)
2022-11-03 01:53:36,008:INFO: Batch: 17/31	Total Loss -124.3889 (-127.0167)
2022-11-03 01:53:36,510:INFO: Batch: 18/31	Total Loss -147.9968 (-128.1859)
2022-11-03 01:53:37,014:INFO: Batch: 19/31	Total Loss -141.2195 (-128.8990)
2022-11-03 01:53:37,517:INFO: Batch: 20/31	Total Loss -120.1581 (-128.4866)
2022-11-03 01:53:38,021:INFO: Batch: 21/31	Total Loss -128.7918 (-128.5010)
2022-11-03 01:53:38,523:INFO: Batch: 22/31	Total Loss -131.5588 (-128.6339)
2022-11-03 01:53:39,026:INFO: Batch: 23/31	Total Loss -139.5855 (-129.0778)
2022-11-03 01:53:39,527:INFO: Batch: 24/31	Total Loss -140.5132 (-129.5103)
2022-11-03 01:53:40,029:INFO: Batch: 25/31	Total Loss -109.3188 (-128.7768)
2022-11-03 01:53:40,532:INFO: Batch: 26/31	Total Loss -131.7726 (-128.8944)
2022-11-03 01:53:41,036:INFO: Batch: 27/31	Total Loss -137.8443 (-129.2306)
2022-11-03 01:53:41,539:INFO: Batch: 28/31	Total Loss -151.2465 (-130.0097)
2022-11-03 01:53:42,043:INFO: Batch: 29/31	Total Loss -143.3562 (-130.4920)
2022-11-03 01:53:42,441:INFO: Batch: 30/31	Total Loss -83.5760 (-130.1591)
2022-11-03 01:53:42,591:INFO: - Computing ADE (validation o)
2022-11-03 01:53:43,294:INFO: 		 ADE on eth                       dataset:	 0.9244143962860107
2022-11-03 01:53:43,294:INFO: Average validation o:	ADE  0.9244	FDE  1.9355
2022-11-03 01:53:43,295:INFO: - Computing ADE (validation)
2022-11-03 01:53:43,581:INFO: 		 ADE on hotel                     dataset:	 0.39924299716949463
2022-11-03 01:53:43,983:INFO: 		 ADE on univ                      dataset:	 0.5260788202285767
2022-11-03 01:53:44,253:INFO: 		 ADE on zara1                     dataset:	 0.3967822790145874
2022-11-03 01:53:44,760:INFO: 		 ADE on zara2                     dataset:	 0.3963867127895355
2022-11-03 01:53:44,760:INFO: Average validation:	ADE  0.4640	FDE  0.9898
2022-11-03 01:53:44,761:INFO: - Computing ADE (training)
2022-11-03 01:53:45,375:INFO: 		 ADE on hotel                     dataset:	 0.4096231460571289
2022-11-03 01:53:46,441:INFO: 		 ADE on univ                      dataset:	 0.5230752229690552
2022-11-03 01:53:47,179:INFO: 		 ADE on zara1                     dataset:	 0.4442475140094757
2022-11-03 01:53:48,355:INFO: 		 ADE on zara2                     dataset:	 0.39266154170036316
2022-11-03 01:53:48,356:INFO: Average training:	ADE  0.4887	FDE  1.0462
2022-11-03 01:53:48,367:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_614.pth.tar
2022-11-03 01:53:48,367:INFO: 
===> EPOCH: 615 (P4)
2022-11-03 01:53:48,368:INFO: - Computing loss (training)
2022-11-03 01:53:49,499:INFO: Batch:  0/31	Total Loss -136.9316 (-136.9316)
2022-11-03 01:53:50,010:INFO: Batch:  1/31	Total Loss -149.7598 (-143.4624)
2022-11-03 01:53:50,508:INFO: Batch:  2/31	Total Loss -147.0597 (-144.7022)
2022-11-03 01:53:51,007:INFO: Batch:  3/31	Total Loss -156.8049 (-147.8167)
2022-11-03 01:53:51,504:INFO: Batch:  4/31	Total Loss -133.8879 (-145.1348)
2022-11-03 01:53:51,996:INFO: Batch:  5/31	Total Loss -153.4219 (-146.4197)
2022-11-03 01:53:52,490:INFO: Batch:  6/31	Total Loss -145.6493 (-146.3172)
2022-11-03 01:53:52,987:INFO: Batch:  7/31	Total Loss -128.1794 (-144.0752)
2022-11-03 01:53:53,482:INFO: Batch:  8/31	Total Loss -135.8505 (-143.2484)
2022-11-03 01:53:53,977:INFO: Batch:  9/31	Total Loss -141.1118 (-143.0503)
2022-11-03 01:53:54,473:INFO: Batch: 10/31	Total Loss -130.1806 (-141.9046)
2022-11-03 01:53:54,967:INFO: Batch: 11/31	Total Loss -157.0675 (-143.1693)
2022-11-03 01:53:55,464:INFO: Batch: 12/31	Total Loss -142.4660 (-143.1134)
2022-11-03 01:53:55,963:INFO: Batch: 13/31	Total Loss -146.6423 (-143.3643)
2022-11-03 01:53:56,461:INFO: Batch: 14/31	Total Loss -128.9292 (-142.4265)
2022-11-03 01:53:56,959:INFO: Batch: 15/31	Total Loss -104.5378 (-140.4682)
2022-11-03 01:53:57,454:INFO: Batch: 16/31	Total Loss -159.5796 (-141.6574)
2022-11-03 01:53:57,950:INFO: Batch: 17/31	Total Loss -160.4718 (-142.7868)
2022-11-03 01:53:58,445:INFO: Batch: 18/31	Total Loss -136.5830 (-142.4703)
2022-11-03 01:53:58,941:INFO: Batch: 19/31	Total Loss -120.7070 (-141.4904)
2022-11-03 01:53:59,438:INFO: Batch: 20/31	Total Loss -138.0761 (-141.3319)
2022-11-03 01:53:59,943:INFO: Batch: 21/31	Total Loss -120.2541 (-140.4983)
2022-11-03 01:54:00,450:INFO: Batch: 22/31	Total Loss -146.3579 (-140.7436)
2022-11-03 01:54:00,956:INFO: Batch: 23/31	Total Loss -141.2085 (-140.7624)
2022-11-03 01:54:01,464:INFO: Batch: 24/31	Total Loss -148.5578 (-141.0898)
2022-11-03 01:54:01,970:INFO: Batch: 25/31	Total Loss -130.6597 (-140.7152)
2022-11-03 01:54:02,473:INFO: Batch: 26/31	Total Loss -124.2609 (-140.1608)
2022-11-03 01:54:02,978:INFO: Batch: 27/31	Total Loss -150.8031 (-140.5233)
2022-11-03 01:54:03,481:INFO: Batch: 28/31	Total Loss -113.6110 (-139.6887)
2022-11-03 01:54:03,986:INFO: Batch: 29/31	Total Loss -136.0055 (-139.5719)
2022-11-03 01:54:04,387:INFO: Batch: 30/31	Total Loss -101.9036 (-139.2044)
2022-11-03 01:54:04,533:INFO: - Computing ADE (validation o)
2022-11-03 01:54:05,228:INFO: 		 ADE on eth                       dataset:	 0.923974335193634
2022-11-03 01:54:05,229:INFO: Average validation o:	ADE  0.9240	FDE  1.9494
2022-11-03 01:54:05,229:INFO: - Computing ADE (validation)
2022-11-03 01:54:05,527:INFO: 		 ADE on hotel                     dataset:	 0.39317941665649414
2022-11-03 01:54:05,912:INFO: 		 ADE on univ                      dataset:	 0.5302920341491699
2022-11-03 01:54:06,220:INFO: 		 ADE on zara1                     dataset:	 0.3986281156539917
2022-11-03 01:54:06,691:INFO: 		 ADE on zara2                     dataset:	 0.39483386278152466
2022-11-03 01:54:06,691:INFO: Average validation:	ADE  0.4654	FDE  0.9969
2022-11-03 01:54:06,692:INFO: - Computing ADE (training)
2022-11-03 01:54:07,259:INFO: 		 ADE on hotel                     dataset:	 0.4022086262702942
2022-11-03 01:54:08,374:INFO: 		 ADE on univ                      dataset:	 0.5242599248886108
2022-11-03 01:54:09,143:INFO: 		 ADE on zara1                     dataset:	 0.4334968030452728
2022-11-03 01:54:10,375:INFO: 		 ADE on zara2                     dataset:	 0.3820745646953583
2022-11-03 01:54:10,376:INFO: Average training:	ADE  0.4865	FDE  1.0434
2022-11-03 01:54:10,387:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_615.pth.tar
2022-11-03 01:54:10,388:INFO: 
===> EPOCH: 616 (P4)
2022-11-03 01:54:10,388:INFO: - Computing loss (training)
2022-11-03 01:54:11,560:INFO: Batch:  0/31	Total Loss -8.4075 (-8.4075)
2022-11-03 01:54:12,066:INFO: Batch:  1/31	Total Loss -168.3721 (-92.9227)
2022-11-03 01:54:12,569:INFO: Batch:  2/31	Total Loss -149.5972 (-110.4640)
2022-11-03 01:54:13,072:INFO: Batch:  3/31	Total Loss -148.1376 (-119.6428)
2022-11-03 01:54:13,574:INFO: Batch:  4/31	Total Loss -127.3690 (-121.2289)
2022-11-03 01:54:14,074:INFO: Batch:  5/31	Total Loss -139.3622 (-124.2148)
2022-11-03 01:54:14,577:INFO: Batch:  6/31	Total Loss -144.7229 (-127.2604)
2022-11-03 01:54:15,076:INFO: Batch:  7/31	Total Loss -107.0158 (-125.1851)
2022-11-03 01:54:15,577:INFO: Batch:  8/31	Total Loss -146.9538 (-127.5240)
2022-11-03 01:54:16,077:INFO: Batch:  9/31	Total Loss -135.3192 (-128.3056)
2022-11-03 01:54:16,580:INFO: Batch: 10/31	Total Loss -135.2282 (-128.8509)
2022-11-03 01:54:17,081:INFO: Batch: 11/31	Total Loss -154.0896 (-131.0950)
2022-11-03 01:54:17,586:INFO: Batch: 12/31	Total Loss -145.3979 (-132.2650)
2022-11-03 01:54:18,092:INFO: Batch: 13/31	Total Loss -162.9185 (-134.5081)
2022-11-03 01:54:18,594:INFO: Batch: 14/31	Total Loss -146.8325 (-135.3462)
2022-11-03 01:54:19,089:INFO: Batch: 15/31	Total Loss -141.9285 (-135.7557)
2022-11-03 01:54:19,591:INFO: Batch: 16/31	Total Loss -132.9385 (-135.6017)
2022-11-03 01:54:20,087:INFO: Batch: 17/31	Total Loss -155.4001 (-136.7242)
2022-11-03 01:54:20,586:INFO: Batch: 18/31	Total Loss -139.6106 (-136.8715)
2022-11-03 01:54:21,083:INFO: Batch: 19/31	Total Loss -132.9444 (-136.6825)
2022-11-03 01:54:21,580:INFO: Batch: 20/31	Total Loss -150.6805 (-137.3810)
2022-11-03 01:54:22,076:INFO: Batch: 21/31	Total Loss -158.0387 (-138.2984)
2022-11-03 01:54:22,573:INFO: Batch: 22/31	Total Loss -143.3313 (-138.4995)
2022-11-03 01:54:23,070:INFO: Batch: 23/31	Total Loss -143.2985 (-138.6785)
2022-11-03 01:54:23,567:INFO: Batch: 24/31	Total Loss -146.8538 (-139.0056)
2022-11-03 01:54:24,063:INFO: Batch: 25/31	Total Loss -146.1700 (-139.2831)
2022-11-03 01:54:24,559:INFO: Batch: 26/31	Total Loss -136.5020 (-139.1886)
2022-11-03 01:54:25,056:INFO: Batch: 27/31	Total Loss -163.1184 (-140.0558)
2022-11-03 01:54:25,552:INFO: Batch: 28/31	Total Loss -157.1204 (-140.6829)
2022-11-03 01:54:26,047:INFO: Batch: 29/31	Total Loss 30.8945 (-135.9224)
2022-11-03 01:54:26,437:INFO: Batch: 30/31	Total Loss -95.6518 (-135.6544)
2022-11-03 01:54:26,585:INFO: - Computing ADE (validation o)
2022-11-03 01:54:27,266:INFO: 		 ADE on eth                       dataset:	 0.9379326701164246
2022-11-03 01:54:27,267:INFO: Average validation o:	ADE  0.9379	FDE  2.0256
2022-11-03 01:54:27,267:INFO: - Computing ADE (validation)
2022-11-03 01:54:27,552:INFO: 		 ADE on hotel                     dataset:	 0.40177059173583984
2022-11-03 01:54:27,925:INFO: 		 ADE on univ                      dataset:	 0.5396005511283875
2022-11-03 01:54:28,208:INFO: 		 ADE on zara1                     dataset:	 0.400246798992157
2022-11-03 01:54:28,699:INFO: 		 ADE on zara2                     dataset:	 0.4140675961971283
2022-11-03 01:54:28,699:INFO: Average validation:	ADE  0.4779	FDE  1.0237
2022-11-03 01:54:28,700:INFO: - Computing ADE (training)
2022-11-03 01:54:29,283:INFO: 		 ADE on hotel                     dataset:	 0.40401187539100647
2022-11-03 01:54:30,364:INFO: 		 ADE on univ                      dataset:	 0.5401877164840698
2022-11-03 01:54:31,136:INFO: 		 ADE on zara1                     dataset:	 0.43695294857025146
2022-11-03 01:54:32,296:INFO: 		 ADE on zara2                     dataset:	 0.394601434469223
2022-11-03 01:54:32,296:INFO: Average training:	ADE  0.5006	FDE  1.0739
2022-11-03 01:54:32,308:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_616.pth.tar
2022-11-03 01:54:32,308:INFO: 
===> EPOCH: 617 (P4)
2022-11-03 01:54:32,308:INFO: - Computing loss (training)
2022-11-03 01:54:33,502:INFO: Batch:  0/31	Total Loss 10.3217 (10.3217)
2022-11-03 01:54:33,998:INFO: Batch:  1/31	Total Loss -145.2806 (-70.4826)
2022-11-03 01:54:34,489:INFO: Batch:  2/31	Total Loss -160.4868 (-100.8625)
2022-11-03 01:54:34,978:INFO: Batch:  3/31	Total Loss -154.5010 (-114.4598)
2022-11-03 01:54:35,468:INFO: Batch:  4/31	Total Loss -146.8786 (-121.1258)
2022-11-03 01:54:35,962:INFO: Batch:  5/31	Total Loss -133.5150 (-123.2594)
2022-11-03 01:54:36,449:INFO: Batch:  6/31	Total Loss -156.7597 (-128.0870)
2022-11-03 01:54:36,936:INFO: Batch:  7/31	Total Loss -144.3151 (-130.0146)
2022-11-03 01:54:37,423:INFO: Batch:  8/31	Total Loss -131.1791 (-130.1393)
2022-11-03 01:54:37,914:INFO: Batch:  9/31	Total Loss -152.4169 (-132.2324)
2022-11-03 01:54:38,404:INFO: Batch: 10/31	Total Loss -156.3801 (-134.7010)
2022-11-03 01:54:38,896:INFO: Batch: 11/31	Total Loss -147.8872 (-135.8498)
2022-11-03 01:54:39,388:INFO: Batch: 12/31	Total Loss -145.9870 (-136.5717)
2022-11-03 01:54:39,882:INFO: Batch: 13/31	Total Loss -167.2067 (-138.8672)
2022-11-03 01:54:40,381:INFO: Batch: 14/31	Total Loss -134.6440 (-138.5974)
2022-11-03 01:54:40,875:INFO: Batch: 15/31	Total Loss -158.6393 (-139.9017)
2022-11-03 01:54:41,367:INFO: Batch: 16/31	Total Loss -139.7191 (-139.8919)
2022-11-03 01:54:41,864:INFO: Batch: 17/31	Total Loss -150.5566 (-140.4625)
2022-11-03 01:54:42,358:INFO: Batch: 18/31	Total Loss -132.2982 (-140.0703)
2022-11-03 01:54:42,852:INFO: Batch: 19/31	Total Loss -142.0009 (-140.1640)
2022-11-03 01:54:43,343:INFO: Batch: 20/31	Total Loss -117.3736 (-139.0915)
2022-11-03 01:54:43,837:INFO: Batch: 21/31	Total Loss -138.5381 (-139.0686)
2022-11-03 01:54:44,331:INFO: Batch: 22/31	Total Loss -155.1989 (-139.8183)
2022-11-03 01:54:44,825:INFO: Batch: 23/31	Total Loss -155.7208 (-140.5382)
2022-11-03 01:54:45,319:INFO: Batch: 24/31	Total Loss -142.1195 (-140.5978)
2022-11-03 01:54:45,812:INFO: Batch: 25/31	Total Loss -157.4518 (-141.2277)
2022-11-03 01:54:46,303:INFO: Batch: 26/31	Total Loss -147.9543 (-141.4648)
2022-11-03 01:54:46,797:INFO: Batch: 27/31	Total Loss -154.7912 (-141.9727)
2022-11-03 01:54:47,288:INFO: Batch: 28/31	Total Loss -142.6098 (-141.9942)
2022-11-03 01:54:47,781:INFO: Batch: 29/31	Total Loss -159.7709 (-142.6355)
2022-11-03 01:54:48,168:INFO: Batch: 30/31	Total Loss -113.5594 (-142.3196)
2022-11-03 01:54:48,327:INFO: - Computing ADE (validation o)
2022-11-03 01:54:49,026:INFO: 		 ADE on eth                       dataset:	 0.9246922731399536
2022-11-03 01:54:49,027:INFO: Average validation o:	ADE  0.9247	FDE  1.9685
2022-11-03 01:54:49,027:INFO: - Computing ADE (validation)
2022-11-03 01:54:49,337:INFO: 		 ADE on hotel                     dataset:	 0.39487186074256897
2022-11-03 01:54:49,722:INFO: 		 ADE on univ                      dataset:	 0.5348164439201355
2022-11-03 01:54:50,018:INFO: 		 ADE on zara1                     dataset:	 0.4007550776004791
2022-11-03 01:54:50,493:INFO: 		 ADE on zara2                     dataset:	 0.40476304292678833
2022-11-03 01:54:50,493:INFO: Average validation:	ADE  0.4717	FDE  1.0173
2022-11-03 01:54:50,494:INFO: - Computing ADE (training)
2022-11-03 01:54:51,041:INFO: 		 ADE on hotel                     dataset:	 0.4056309163570404
2022-11-03 01:54:52,125:INFO: 		 ADE on univ                      dataset:	 0.5352413058280945
2022-11-03 01:54:52,868:INFO: 		 ADE on zara1                     dataset:	 0.4312664568424225
2022-11-03 01:54:54,046:INFO: 		 ADE on zara2                     dataset:	 0.3903735876083374
2022-11-03 01:54:54,047:INFO: Average training:	ADE  0.4959	FDE  1.0706
2022-11-03 01:54:54,058:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_617.pth.tar
2022-11-03 01:54:54,058:INFO: 
===> EPOCH: 618 (P4)
2022-11-03 01:54:54,059:INFO: - Computing loss (training)
2022-11-03 01:54:55,170:INFO: Batch:  0/31	Total Loss -162.7607 (-162.7607)
2022-11-03 01:54:55,669:INFO: Batch:  1/31	Total Loss -140.5590 (-152.2363)
2022-11-03 01:54:56,171:INFO: Batch:  2/31	Total Loss -179.5524 (-162.4504)
2022-11-03 01:54:56,664:INFO: Batch:  3/31	Total Loss -151.1179 (-159.7823)
2022-11-03 01:54:57,158:INFO: Batch:  4/31	Total Loss -142.7599 (-156.5902)
2022-11-03 01:54:57,653:INFO: Batch:  5/31	Total Loss -168.2348 (-158.5278)
2022-11-03 01:54:58,146:INFO: Batch:  6/31	Total Loss -156.6181 (-158.2393)
2022-11-03 01:54:58,638:INFO: Batch:  7/31	Total Loss -160.6031 (-158.5149)
2022-11-03 01:54:59,132:INFO: Batch:  8/31	Total Loss -152.4312 (-157.8063)
2022-11-03 01:54:59,622:INFO: Batch:  9/31	Total Loss -144.6773 (-156.5212)
2022-11-03 01:55:00,115:INFO: Batch: 10/31	Total Loss -151.7142 (-156.0982)
2022-11-03 01:55:00,613:INFO: Batch: 11/31	Total Loss -161.3298 (-156.5265)
2022-11-03 01:55:01,115:INFO: Batch: 12/31	Total Loss -159.2637 (-156.7183)
2022-11-03 01:55:01,616:INFO: Batch: 13/31	Total Loss 9.0430 (-145.1778)
2022-11-03 01:55:02,115:INFO: Batch: 14/31	Total Loss -128.3888 (-144.2087)
2022-11-03 01:55:02,614:INFO: Batch: 15/31	Total Loss -149.6104 (-144.5332)
2022-11-03 01:55:03,111:INFO: Batch: 16/31	Total Loss -113.5412 (-142.6898)
2022-11-03 01:55:03,608:INFO: Batch: 17/31	Total Loss -157.0349 (-143.5179)
2022-11-03 01:55:04,106:INFO: Batch: 18/31	Total Loss -158.0639 (-144.3859)
2022-11-03 01:55:04,602:INFO: Batch: 19/31	Total Loss -162.9393 (-145.3006)
2022-11-03 01:55:05,098:INFO: Batch: 20/31	Total Loss -128.1995 (-144.5581)
2022-11-03 01:55:05,595:INFO: Batch: 21/31	Total Loss -105.1163 (-142.9777)
2022-11-03 01:55:06,092:INFO: Batch: 22/31	Total Loss -136.2144 (-142.7068)
2022-11-03 01:55:06,589:INFO: Batch: 23/31	Total Loss -160.9260 (-143.5143)
2022-11-03 01:55:07,087:INFO: Batch: 24/31	Total Loss -115.2068 (-142.4940)
2022-11-03 01:55:07,586:INFO: Batch: 25/31	Total Loss -130.8042 (-142.0317)
2022-11-03 01:55:08,084:INFO: Batch: 26/31	Total Loss -119.4811 (-141.2294)
2022-11-03 01:55:08,580:INFO: Batch: 27/31	Total Loss -115.5722 (-140.3264)
2022-11-03 01:55:09,077:INFO: Batch: 28/31	Total Loss -131.6422 (-140.0376)
2022-11-03 01:55:09,574:INFO: Batch: 29/31	Total Loss -149.8021 (-140.3721)
2022-11-03 01:55:09,968:INFO: Batch: 30/31	Total Loss -109.0676 (-140.0374)
2022-11-03 01:55:10,124:INFO: - Computing ADE (validation o)
2022-11-03 01:55:10,798:INFO: 		 ADE on eth                       dataset:	 0.9165071249008179
2022-11-03 01:55:10,799:INFO: Average validation o:	ADE  0.9165	FDE  1.9168
2022-11-03 01:55:10,799:INFO: - Computing ADE (validation)
2022-11-03 01:55:11,104:INFO: 		 ADE on hotel                     dataset:	 0.395332932472229
2022-11-03 01:55:11,479:INFO: 		 ADE on univ                      dataset:	 0.5231416821479797
2022-11-03 01:55:11,789:INFO: 		 ADE on zara1                     dataset:	 0.4060586094856262
2022-11-03 01:55:12,251:INFO: 		 ADE on zara2                     dataset:	 0.3981396555900574
2022-11-03 01:55:12,251:INFO: Average validation:	ADE  0.4635	FDE  0.9880
2022-11-03 01:55:12,252:INFO: - Computing ADE (training)
2022-11-03 01:55:12,835:INFO: 		 ADE on hotel                     dataset:	 0.40858811140060425
2022-11-03 01:55:13,889:INFO: 		 ADE on univ                      dataset:	 0.5238754153251648
2022-11-03 01:55:14,644:INFO: 		 ADE on zara1                     dataset:	 0.4391378164291382
2022-11-03 01:55:15,808:INFO: 		 ADE on zara2                     dataset:	 0.38933753967285156
2022-11-03 01:55:15,808:INFO: Average training:	ADE  0.4882	FDE  1.0440
2022-11-03 01:55:15,819:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_618.pth.tar
2022-11-03 01:55:15,819:INFO: 
===> EPOCH: 619 (P4)
2022-11-03 01:55:15,819:INFO: - Computing loss (training)
2022-11-03 01:55:16,925:INFO: Batch:  0/31	Total Loss -137.6576 (-137.6576)
2022-11-03 01:55:17,427:INFO: Batch:  1/31	Total Loss -149.8844 (-144.1168)
2022-11-03 01:55:17,931:INFO: Batch:  2/31	Total Loss -147.8951 (-145.3514)
2022-11-03 01:55:18,431:INFO: Batch:  3/31	Total Loss -147.8125 (-145.9708)
2022-11-03 01:55:18,925:INFO: Batch:  4/31	Total Loss -129.7283 (-142.8843)
2022-11-03 01:55:19,424:INFO: Batch:  5/31	Total Loss -132.2684 (-141.1354)
2022-11-03 01:55:19,921:INFO: Batch:  6/31	Total Loss -150.7778 (-142.4968)
2022-11-03 01:55:20,419:INFO: Batch:  7/31	Total Loss -170.0809 (-146.1237)
2022-11-03 01:55:20,917:INFO: Batch:  8/31	Total Loss -152.6500 (-146.8044)
2022-11-03 01:55:21,417:INFO: Batch:  9/31	Total Loss -163.7699 (-148.7434)
2022-11-03 01:55:21,915:INFO: Batch: 10/31	Total Loss -119.2780 (-146.1237)
2022-11-03 01:55:22,413:INFO: Batch: 11/31	Total Loss -148.8202 (-146.3533)
2022-11-03 01:55:22,916:INFO: Batch: 12/31	Total Loss -148.6947 (-146.5265)
2022-11-03 01:55:23,417:INFO: Batch: 13/31	Total Loss -129.2622 (-145.2973)
2022-11-03 01:55:23,918:INFO: Batch: 14/31	Total Loss -151.7172 (-145.7682)
2022-11-03 01:55:24,420:INFO: Batch: 15/31	Total Loss -158.0902 (-146.6190)
2022-11-03 01:55:24,921:INFO: Batch: 16/31	Total Loss -143.2324 (-146.4255)
2022-11-03 01:55:25,496:INFO: Batch: 17/31	Total Loss -114.9710 (-144.7421)
2022-11-03 01:55:25,995:INFO: Batch: 18/31	Total Loss -148.7546 (-144.9601)
2022-11-03 01:55:26,495:INFO: Batch: 19/31	Total Loss -126.9268 (-144.0411)
2022-11-03 01:55:26,993:INFO: Batch: 20/31	Total Loss -160.4156 (-144.8850)
2022-11-03 01:55:27,493:INFO: Batch: 21/31	Total Loss 43.2381 (-136.2610)
2022-11-03 01:55:27,991:INFO: Batch: 22/31	Total Loss -134.2335 (-136.1689)
2022-11-03 01:55:28,491:INFO: Batch: 23/31	Total Loss -131.8370 (-135.9986)
2022-11-03 01:55:28,989:INFO: Batch: 24/31	Total Loss -116.0922 (-135.2494)
2022-11-03 01:55:29,489:INFO: Batch: 25/31	Total Loss -141.3376 (-135.4870)
2022-11-03 01:55:29,990:INFO: Batch: 26/31	Total Loss -124.9534 (-135.1540)
2022-11-03 01:55:30,487:INFO: Batch: 27/31	Total Loss -146.9426 (-135.5916)
2022-11-03 01:55:30,986:INFO: Batch: 28/31	Total Loss -127.1760 (-135.3236)
2022-11-03 01:55:31,486:INFO: Batch: 29/31	Total Loss -126.9119 (-135.0739)
2022-11-03 01:55:31,882:INFO: Batch: 30/31	Total Loss -100.0862 (-134.7704)
2022-11-03 01:55:32,041:INFO: - Computing ADE (validation o)
2022-11-03 01:55:32,732:INFO: 		 ADE on eth                       dataset:	 0.9450263977050781
2022-11-03 01:55:32,732:INFO: Average validation o:	ADE  0.9450	FDE  2.0130
2022-11-03 01:55:32,732:INFO: - Computing ADE (validation)
2022-11-03 01:55:33,043:INFO: 		 ADE on hotel                     dataset:	 0.44053247570991516
2022-11-03 01:55:33,400:INFO: 		 ADE on univ                      dataset:	 0.5669959783554077
2022-11-03 01:55:33,682:INFO: 		 ADE on zara1                     dataset:	 0.4474404752254486
2022-11-03 01:55:34,160:INFO: 		 ADE on zara2                     dataset:	 0.4517041742801666
2022-11-03 01:55:34,160:INFO: Average validation:	ADE  0.5108	FDE  1.0889
2022-11-03 01:55:34,161:INFO: - Computing ADE (training)
2022-11-03 01:55:34,762:INFO: 		 ADE on hotel                     dataset:	 0.45464393496513367
2022-11-03 01:55:35,844:INFO: 		 ADE on univ                      dataset:	 0.5665203332901001
2022-11-03 01:55:36,632:INFO: 		 ADE on zara1                     dataset:	 0.4689180552959442
2022-11-03 01:55:37,836:INFO: 		 ADE on zara2                     dataset:	 0.43732333183288574
2022-11-03 01:55:37,836:INFO: Average training:	ADE  0.5312	FDE  1.1330
2022-11-03 01:55:37,848:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_619.pth.tar
2022-11-03 01:55:37,848:INFO: 
===> EPOCH: 620 (P4)
2022-11-03 01:55:37,848:INFO: - Computing loss (training)
2022-11-03 01:55:39,043:INFO: Batch:  0/31	Total Loss -139.1198 (-139.1198)
2022-11-03 01:55:39,546:INFO: Batch:  1/31	Total Loss -163.8555 (-152.3298)
2022-11-03 01:55:40,053:INFO: Batch:  2/31	Total Loss -161.3799 (-155.3730)
2022-11-03 01:55:40,551:INFO: Batch:  3/31	Total Loss -132.1091 (-149.3750)
2022-11-03 01:55:41,052:INFO: Batch:  4/31	Total Loss -107.9662 (-142.2874)
2022-11-03 01:55:41,552:INFO: Batch:  5/31	Total Loss -109.1880 (-137.1921)
2022-11-03 01:55:42,049:INFO: Batch:  6/31	Total Loss -161.4328 (-141.0641)
2022-11-03 01:55:42,544:INFO: Batch:  7/31	Total Loss -166.1962 (-144.3926)
2022-11-03 01:55:43,042:INFO: Batch:  8/31	Total Loss -143.3951 (-144.2793)
2022-11-03 01:55:43,539:INFO: Batch:  9/31	Total Loss -149.1042 (-144.7867)
2022-11-03 01:55:44,035:INFO: Batch: 10/31	Total Loss -163.0242 (-146.6004)
2022-11-03 01:55:44,534:INFO: Batch: 11/31	Total Loss -147.9657 (-146.7041)
2022-11-03 01:55:45,037:INFO: Batch: 12/31	Total Loss -153.0793 (-147.1795)
2022-11-03 01:55:45,538:INFO: Batch: 13/31	Total Loss -154.2433 (-147.6969)
2022-11-03 01:55:46,039:INFO: Batch: 14/31	Total Loss -150.1419 (-147.8520)
2022-11-03 01:55:46,540:INFO: Batch: 15/31	Total Loss -158.6263 (-148.5436)
2022-11-03 01:55:47,038:INFO: Batch: 16/31	Total Loss -158.1426 (-149.1059)
2022-11-03 01:55:47,539:INFO: Batch: 17/31	Total Loss -139.8221 (-148.5729)
2022-11-03 01:55:48,039:INFO: Batch: 18/31	Total Loss -166.2138 (-149.5891)
2022-11-03 01:55:48,539:INFO: Batch: 19/31	Total Loss -156.0867 (-149.9427)
2022-11-03 01:55:49,037:INFO: Batch: 20/31	Total Loss -140.6742 (-149.5703)
2022-11-03 01:55:49,535:INFO: Batch: 21/31	Total Loss -146.8778 (-149.4517)
2022-11-03 01:55:50,033:INFO: Batch: 22/31	Total Loss -162.4862 (-150.0427)
2022-11-03 01:55:50,532:INFO: Batch: 23/31	Total Loss -171.3822 (-150.9356)
2022-11-03 01:55:51,031:INFO: Batch: 24/31	Total Loss -108.2137 (-149.5003)
2022-11-03 01:55:51,529:INFO: Batch: 25/31	Total Loss -142.1016 (-149.2443)
2022-11-03 01:55:52,029:INFO: Batch: 26/31	Total Loss -161.9486 (-149.7226)
2022-11-03 01:55:52,527:INFO: Batch: 27/31	Total Loss -143.1457 (-149.5007)
2022-11-03 01:55:53,028:INFO: Batch: 28/31	Total Loss -135.8033 (-149.0008)
2022-11-03 01:55:53,528:INFO: Batch: 29/31	Total Loss -157.5082 (-149.2937)
2022-11-03 01:55:53,925:INFO: Batch: 30/31	Total Loss -118.6976 (-148.9439)
2022-11-03 01:55:54,075:INFO: - Computing ADE (validation o)
2022-11-03 01:55:54,799:INFO: 		 ADE on eth                       dataset:	 0.931770384311676
2022-11-03 01:55:54,799:INFO: Average validation o:	ADE  0.9318	FDE  1.9896
2022-11-03 01:55:54,800:INFO: - Computing ADE (validation)
2022-11-03 01:55:55,130:INFO: 		 ADE on hotel                     dataset:	 0.4025283753871918
2022-11-03 01:55:55,501:INFO: 		 ADE on univ                      dataset:	 0.5285082459449768
2022-11-03 01:55:55,786:INFO: 		 ADE on zara1                     dataset:	 0.38141122460365295
2022-11-03 01:55:56,289:INFO: 		 ADE on zara2                     dataset:	 0.4048762917518616
2022-11-03 01:55:56,289:INFO: Average validation:	ADE  0.4677	FDE  0.9981
2022-11-03 01:55:56,290:INFO: - Computing ADE (training)
2022-11-03 01:55:56,880:INFO: 		 ADE on hotel                     dataset:	 0.4080236554145813
2022-11-03 01:55:57,926:INFO: 		 ADE on univ                      dataset:	 0.5319136381149292
2022-11-03 01:55:58,676:INFO: 		 ADE on zara1                     dataset:	 0.4327150881290436
2022-11-03 01:55:59,827:INFO: 		 ADE on zara2                     dataset:	 0.39344361424446106
2022-11-03 01:55:59,827:INFO: Average training:	ADE  0.4943	FDE  1.0612
2022-11-03 01:55:59,838:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_620.pth.tar
2022-11-03 01:55:59,839:INFO: 
===> EPOCH: 621 (P4)
2022-11-03 01:55:59,839:INFO: - Computing loss (training)
2022-11-03 01:56:00,958:INFO: Batch:  0/31	Total Loss -143.7524 (-143.7524)
2022-11-03 01:56:01,457:INFO: Batch:  1/31	Total Loss -151.8748 (-148.0219)
2022-11-03 01:56:01,954:INFO: Batch:  2/31	Total Loss -154.2802 (-150.1366)
2022-11-03 01:56:02,446:INFO: Batch:  3/31	Total Loss -153.0473 (-150.7891)
2022-11-03 01:56:02,938:INFO: Batch:  4/31	Total Loss -144.7124 (-149.5846)
2022-11-03 01:56:03,430:INFO: Batch:  5/31	Total Loss -130.7530 (-146.8096)
2022-11-03 01:56:03,923:INFO: Batch:  6/31	Total Loss -156.6661 (-148.2830)
2022-11-03 01:56:04,416:INFO: Batch:  7/31	Total Loss -159.3036 (-149.6705)
2022-11-03 01:56:04,907:INFO: Batch:  8/31	Total Loss -163.2854 (-151.2480)
2022-11-03 01:56:05,398:INFO: Batch:  9/31	Total Loss -155.2707 (-151.6424)
2022-11-03 01:56:05,892:INFO: Batch: 10/31	Total Loss -180.2585 (-154.7973)
2022-11-03 01:56:06,383:INFO: Batch: 11/31	Total Loss -161.1550 (-155.3235)
2022-11-03 01:56:06,878:INFO: Batch: 12/31	Total Loss -154.0057 (-155.2203)
2022-11-03 01:56:07,372:INFO: Batch: 13/31	Total Loss -148.8369 (-154.8211)
2022-11-03 01:56:07,867:INFO: Batch: 14/31	Total Loss -169.1155 (-155.8674)
2022-11-03 01:56:08,357:INFO: Batch: 15/31	Total Loss -131.0001 (-154.3612)
2022-11-03 01:56:08,850:INFO: Batch: 16/31	Total Loss -150.9946 (-154.1894)
2022-11-03 01:56:09,342:INFO: Batch: 17/31	Total Loss -118.9216 (-152.4870)
2022-11-03 01:56:09,835:INFO: Batch: 18/31	Total Loss -156.0856 (-152.6584)
2022-11-03 01:56:10,330:INFO: Batch: 19/31	Total Loss -167.9103 (-153.4902)
2022-11-03 01:56:10,824:INFO: Batch: 20/31	Total Loss -159.0772 (-153.7701)
2022-11-03 01:56:11,316:INFO: Batch: 21/31	Total Loss -158.6526 (-153.9938)
2022-11-03 01:56:11,806:INFO: Batch: 22/31	Total Loss -134.6258 (-153.2007)
2022-11-03 01:56:12,296:INFO: Batch: 23/31	Total Loss -160.3576 (-153.4831)
2022-11-03 01:56:12,787:INFO: Batch: 24/31	Total Loss -147.7681 (-153.2660)
2022-11-03 01:56:13,276:INFO: Batch: 25/31	Total Loss -193.0703 (-154.9755)
2022-11-03 01:56:13,765:INFO: Batch: 26/31	Total Loss -156.1588 (-155.0164)
2022-11-03 01:56:14,256:INFO: Batch: 27/31	Total Loss -170.6039 (-155.6074)
2022-11-03 01:56:14,748:INFO: Batch: 28/31	Total Loss -175.5366 (-156.3083)
2022-11-03 01:56:15,239:INFO: Batch: 29/31	Total Loss -165.4041 (-156.6419)
2022-11-03 01:56:15,634:INFO: Batch: 30/31	Total Loss -114.1392 (-156.1573)
2022-11-03 01:56:15,777:INFO: - Computing ADE (validation o)
2022-11-03 01:56:16,494:INFO: 		 ADE on eth                       dataset:	 0.9206150770187378
2022-11-03 01:56:16,495:INFO: Average validation o:	ADE  0.9206	FDE  1.9473
2022-11-03 01:56:16,495:INFO: - Computing ADE (validation)
2022-11-03 01:56:16,791:INFO: 		 ADE on hotel                     dataset:	 0.3787461817264557
2022-11-03 01:56:17,155:INFO: 		 ADE on univ                      dataset:	 0.5303828120231628
2022-11-03 01:56:17,455:INFO: 		 ADE on zara1                     dataset:	 0.4182204008102417
2022-11-03 01:56:17,946:INFO: 		 ADE on zara2                     dataset:	 0.4002057909965515
2022-11-03 01:56:17,946:INFO: Average validation:	ADE  0.4678	FDE  1.0088
2022-11-03 01:56:17,947:INFO: - Computing ADE (training)
2022-11-03 01:56:18,536:INFO: 		 ADE on hotel                     dataset:	 0.3867994546890259
2022-11-03 01:56:19,570:INFO: 		 ADE on univ                      dataset:	 0.5262775421142578
2022-11-03 01:56:20,287:INFO: 		 ADE on zara1                     dataset:	 0.4362119436264038
2022-11-03 01:56:21,447:INFO: 		 ADE on zara2                     dataset:	 0.3887346684932709
2022-11-03 01:56:21,447:INFO: Average training:	ADE  0.4891	FDE  1.0549
2022-11-03 01:56:21,458:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_621.pth.tar
2022-11-03 01:56:21,459:INFO: 
===> EPOCH: 622 (P4)
2022-11-03 01:56:21,459:INFO: - Computing loss (training)
2022-11-03 01:56:22,577:INFO: Batch:  0/31	Total Loss -166.7433 (-166.7433)
2022-11-03 01:56:23,083:INFO: Batch:  1/31	Total Loss -149.9671 (-158.7539)
2022-11-03 01:56:23,661:INFO: Batch:  2/31	Total Loss -163.5621 (-160.4489)
2022-11-03 01:56:24,158:INFO: Batch:  3/31	Total Loss -163.9021 (-161.2568)
2022-11-03 01:56:24,652:INFO: Batch:  4/31	Total Loss -144.1842 (-157.8423)
2022-11-03 01:56:25,151:INFO: Batch:  5/31	Total Loss -157.5898 (-157.7985)
2022-11-03 01:56:25,647:INFO: Batch:  6/31	Total Loss -158.5576 (-157.9008)
2022-11-03 01:56:26,145:INFO: Batch:  7/31	Total Loss -156.3103 (-157.6923)
2022-11-03 01:56:26,642:INFO: Batch:  8/31	Total Loss -144.3137 (-156.2734)
2022-11-03 01:56:27,145:INFO: Batch:  9/31	Total Loss -172.6791 (-158.0222)
2022-11-03 01:56:27,644:INFO: Batch: 10/31	Total Loss -148.5738 (-157.1436)
2022-11-03 01:56:28,142:INFO: Batch: 11/31	Total Loss -152.0785 (-156.7300)
2022-11-03 01:56:28,644:INFO: Batch: 12/31	Total Loss -119.4505 (-154.0721)
2022-11-03 01:56:29,142:INFO: Batch: 13/31	Total Loss -104.2305 (-151.1734)
2022-11-03 01:56:29,643:INFO: Batch: 14/31	Total Loss -143.0065 (-150.6094)
2022-11-03 01:56:30,144:INFO: Batch: 15/31	Total Loss -125.3827 (-149.0275)
2022-11-03 01:56:30,649:INFO: Batch: 16/31	Total Loss -139.4272 (-148.4492)
2022-11-03 01:56:31,152:INFO: Batch: 17/31	Total Loss -161.8264 (-149.2227)
2022-11-03 01:56:31,649:INFO: Batch: 18/31	Total Loss -139.0335 (-148.7502)
2022-11-03 01:56:32,149:INFO: Batch: 19/31	Total Loss -154.6165 (-149.0542)
2022-11-03 01:56:32,651:INFO: Batch: 20/31	Total Loss -146.4643 (-148.9485)
2022-11-03 01:56:33,152:INFO: Batch: 21/31	Total Loss -117.6817 (-147.4899)
2022-11-03 01:56:33,652:INFO: Batch: 22/31	Total Loss -159.5915 (-148.0711)
2022-11-03 01:56:34,153:INFO: Batch: 23/31	Total Loss -161.3814 (-148.6424)
2022-11-03 01:56:34,652:INFO: Batch: 24/31	Total Loss -138.6490 (-148.2490)
2022-11-03 01:56:35,151:INFO: Batch: 25/31	Total Loss -148.0031 (-148.2402)
2022-11-03 01:56:35,651:INFO: Batch: 26/31	Total Loss -172.5840 (-149.2424)
2022-11-03 01:56:36,151:INFO: Batch: 27/31	Total Loss -139.1075 (-148.9133)
2022-11-03 01:56:36,650:INFO: Batch: 28/31	Total Loss -145.3272 (-148.7882)
2022-11-03 01:56:37,149:INFO: Batch: 29/31	Total Loss -131.4733 (-148.2747)
2022-11-03 01:56:37,543:INFO: Batch: 30/31	Total Loss -108.5819 (-147.8716)
2022-11-03 01:56:37,688:INFO: - Computing ADE (validation o)
2022-11-03 01:56:38,371:INFO: 		 ADE on eth                       dataset:	 0.9185581207275391
2022-11-03 01:56:38,372:INFO: Average validation o:	ADE  0.9186	FDE  1.9499
2022-11-03 01:56:38,372:INFO: - Computing ADE (validation)
2022-11-03 01:56:38,685:INFO: 		 ADE on hotel                     dataset:	 0.3768107295036316
2022-11-03 01:56:39,054:INFO: 		 ADE on univ                      dataset:	 0.5251248478889465
2022-11-03 01:56:39,334:INFO: 		 ADE on zara1                     dataset:	 0.38486629724502563
2022-11-03 01:56:39,809:INFO: 		 ADE on zara2                     dataset:	 0.3908345103263855
2022-11-03 01:56:39,809:INFO: Average validation:	ADE  0.4596	FDE  0.9878
2022-11-03 01:56:39,809:INFO: - Computing ADE (training)
2022-11-03 01:56:40,380:INFO: 		 ADE on hotel                     dataset:	 0.38595545291900635
2022-11-03 01:56:41,432:INFO: 		 ADE on univ                      dataset:	 0.5248610973358154
2022-11-03 01:56:42,167:INFO: 		 ADE on zara1                     dataset:	 0.4232523441314697
2022-11-03 01:56:43,322:INFO: 		 ADE on zara2                     dataset:	 0.3754774332046509
2022-11-03 01:56:43,322:INFO: Average training:	ADE  0.4845	FDE  1.0435
2022-11-03 01:56:43,334:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_622.pth.tar
2022-11-03 01:56:43,334:INFO: 
===> EPOCH: 623 (P4)
2022-11-03 01:56:43,334:INFO: - Computing loss (training)
2022-11-03 01:56:44,475:INFO: Batch:  0/31	Total Loss -162.0451 (-162.0451)
2022-11-03 01:56:44,987:INFO: Batch:  1/31	Total Loss -146.1321 (-153.9630)
2022-11-03 01:56:45,493:INFO: Batch:  2/31	Total Loss -169.1350 (-158.8061)
2022-11-03 01:56:45,994:INFO: Batch:  3/31	Total Loss -137.8340 (-154.2303)
2022-11-03 01:56:46,492:INFO: Batch:  4/31	Total Loss -157.4527 (-154.8911)
2022-11-03 01:56:46,998:INFO: Batch:  5/31	Total Loss -160.0666 (-155.7627)
2022-11-03 01:56:47,500:INFO: Batch:  6/31	Total Loss -148.6653 (-154.8451)
2022-11-03 01:56:48,004:INFO: Batch:  7/31	Total Loss -162.6476 (-155.8065)
2022-11-03 01:56:48,503:INFO: Batch:  8/31	Total Loss -157.5089 (-155.9924)
2022-11-03 01:56:49,001:INFO: Batch:  9/31	Total Loss -159.7246 (-156.3601)
2022-11-03 01:56:49,499:INFO: Batch: 10/31	Total Loss -165.6572 (-157.2371)
2022-11-03 01:56:49,998:INFO: Batch: 11/31	Total Loss -161.5247 (-157.5696)
2022-11-03 01:56:50,502:INFO: Batch: 12/31	Total Loss -171.5622 (-158.6856)
2022-11-03 01:56:51,003:INFO: Batch: 13/31	Total Loss -152.4704 (-158.2875)
2022-11-03 01:56:51,506:INFO: Batch: 14/31	Total Loss -167.9862 (-158.9211)
2022-11-03 01:56:52,008:INFO: Batch: 15/31	Total Loss -161.1096 (-159.0514)
2022-11-03 01:56:52,511:INFO: Batch: 16/31	Total Loss -157.0560 (-158.9366)
2022-11-03 01:56:53,016:INFO: Batch: 17/31	Total Loss -162.4175 (-159.1388)
2022-11-03 01:56:53,518:INFO: Batch: 18/31	Total Loss -183.0366 (-160.3602)
2022-11-03 01:56:54,020:INFO: Batch: 19/31	Total Loss -174.4701 (-161.0905)
2022-11-03 01:56:54,523:INFO: Batch: 20/31	Total Loss -166.2186 (-161.3377)
2022-11-03 01:56:55,023:INFO: Batch: 21/31	Total Loss -152.6396 (-160.9339)
2022-11-03 01:56:55,525:INFO: Batch: 22/31	Total Loss -170.5250 (-161.3493)
2022-11-03 01:56:56,026:INFO: Batch: 23/31	Total Loss -168.2954 (-161.6483)
2022-11-03 01:56:56,528:INFO: Batch: 24/31	Total Loss -165.0720 (-161.7767)
2022-11-03 01:56:57,029:INFO: Batch: 25/31	Total Loss -145.3483 (-161.1742)
2022-11-03 01:56:57,528:INFO: Batch: 26/31	Total Loss -148.9375 (-160.7297)
2022-11-03 01:56:58,028:INFO: Batch: 27/31	Total Loss -153.0544 (-160.4342)
2022-11-03 01:56:58,528:INFO: Batch: 28/31	Total Loss -173.7852 (-160.8550)
2022-11-03 01:56:59,035:INFO: Batch: 29/31	Total Loss -155.7803 (-160.6918)
2022-11-03 01:56:59,431:INFO: Batch: 30/31	Total Loss -96.1182 (-160.2424)
2022-11-03 01:56:59,593:INFO: - Computing ADE (validation o)
2022-11-03 01:57:00,283:INFO: 		 ADE on eth                       dataset:	 0.956287682056427
2022-11-03 01:57:00,284:INFO: Average validation o:	ADE  0.9563	FDE  2.0939
2022-11-03 01:57:00,284:INFO: - Computing ADE (validation)
2022-11-03 01:57:00,580:INFO: 		 ADE on hotel                     dataset:	 0.3901214003562927
2022-11-03 01:57:00,939:INFO: 		 ADE on univ                      dataset:	 0.5407849550247192
2022-11-03 01:57:01,232:INFO: 		 ADE on zara1                     dataset:	 0.3854652941226959
2022-11-03 01:57:01,703:INFO: 		 ADE on zara2                     dataset:	 0.4068920910358429
2022-11-03 01:57:01,703:INFO: Average validation:	ADE  0.4744	FDE  1.0255
2022-11-03 01:57:01,704:INFO: - Computing ADE (training)
2022-11-03 01:57:02,302:INFO: 		 ADE on hotel                     dataset:	 0.4056103229522705
2022-11-03 01:57:03,380:INFO: 		 ADE on univ                      dataset:	 0.537024974822998
2022-11-03 01:57:04,170:INFO: 		 ADE on zara1                     dataset:	 0.4391610324382782
2022-11-03 01:57:05,369:INFO: 		 ADE on zara2                     dataset:	 0.39510631561279297
2022-11-03 01:57:05,369:INFO: Average training:	ADE  0.4986	FDE  1.0798
2022-11-03 01:57:05,380:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_623.pth.tar
2022-11-03 01:57:05,380:INFO: 
===> EPOCH: 624 (P4)
2022-11-03 01:57:05,381:INFO: - Computing loss (training)
2022-11-03 01:57:06,493:INFO: Batch:  0/31	Total Loss -159.5076 (-159.5076)
2022-11-03 01:57:06,984:INFO: Batch:  1/31	Total Loss -165.6046 (-162.5379)
2022-11-03 01:57:07,478:INFO: Batch:  2/31	Total Loss -171.2233 (-165.6823)
2022-11-03 01:57:07,974:INFO: Batch:  3/31	Total Loss -150.8046 (-162.0269)
2022-11-03 01:57:08,463:INFO: Batch:  4/31	Total Loss -172.0293 (-164.1043)
2022-11-03 01:57:08,958:INFO: Batch:  5/31	Total Loss -176.0461 (-166.2418)
2022-11-03 01:57:09,450:INFO: Batch:  6/31	Total Loss -164.1711 (-165.9295)
2022-11-03 01:57:09,940:INFO: Batch:  7/31	Total Loss -127.9885 (-161.6863)
2022-11-03 01:57:10,428:INFO: Batch:  8/31	Total Loss -158.2741 (-161.3030)
2022-11-03 01:57:10,920:INFO: Batch:  9/31	Total Loss -157.1804 (-160.8885)
2022-11-03 01:57:11,411:INFO: Batch: 10/31	Total Loss -158.8728 (-160.7034)
2022-11-03 01:57:11,900:INFO: Batch: 11/31	Total Loss -164.4946 (-161.0367)
2022-11-03 01:57:12,394:INFO: Batch: 12/31	Total Loss -170.5867 (-161.7798)
2022-11-03 01:57:12,888:INFO: Batch: 13/31	Total Loss -176.1782 (-162.8095)
2022-11-03 01:57:13,380:INFO: Batch: 14/31	Total Loss -158.6706 (-162.5364)
2022-11-03 01:57:13,875:INFO: Batch: 15/31	Total Loss -180.8491 (-163.6852)
2022-11-03 01:57:14,369:INFO: Batch: 16/31	Total Loss -167.3967 (-163.8985)
2022-11-03 01:57:14,864:INFO: Batch: 17/31	Total Loss -158.8598 (-163.6344)
2022-11-03 01:57:15,358:INFO: Batch: 18/31	Total Loss -172.1211 (-164.0980)
2022-11-03 01:57:15,856:INFO: Batch: 19/31	Total Loss -174.4124 (-164.6378)
2022-11-03 01:57:16,350:INFO: Batch: 20/31	Total Loss -180.8912 (-165.4207)
2022-11-03 01:57:16,846:INFO: Batch: 21/31	Total Loss -153.8708 (-164.9615)
2022-11-03 01:57:17,417:INFO: Batch: 22/31	Total Loss -146.5241 (-164.1683)
2022-11-03 01:57:17,911:INFO: Batch: 23/31	Total Loss -172.7261 (-164.5206)
2022-11-03 01:57:18,404:INFO: Batch: 24/31	Total Loss -152.4957 (-164.0315)
2022-11-03 01:57:18,898:INFO: Batch: 25/31	Total Loss -182.1626 (-164.7148)
2022-11-03 01:57:19,392:INFO: Batch: 26/31	Total Loss -149.6547 (-164.1033)
2022-11-03 01:57:19,886:INFO: Batch: 27/31	Total Loss -161.4908 (-164.0084)
2022-11-03 01:57:20,380:INFO: Batch: 28/31	Total Loss -130.0018 (-162.9200)
2022-11-03 01:57:20,872:INFO: Batch: 29/31	Total Loss -145.6167 (-162.3049)
2022-11-03 01:57:21,259:INFO: Batch: 30/31	Total Loss -110.1246 (-161.8540)
2022-11-03 01:57:21,419:INFO: - Computing ADE (validation o)
2022-11-03 01:57:22,133:INFO: 		 ADE on eth                       dataset:	 0.9286249876022339
2022-11-03 01:57:22,134:INFO: Average validation o:	ADE  0.9286	FDE  2.0067
2022-11-03 01:57:22,134:INFO: - Computing ADE (validation)
2022-11-03 01:57:22,448:INFO: 		 ADE on hotel                     dataset:	 0.39204612374305725
2022-11-03 01:57:22,831:INFO: 		 ADE on univ                      dataset:	 0.5292533040046692
2022-11-03 01:57:23,124:INFO: 		 ADE on zara1                     dataset:	 0.3842259645462036
2022-11-03 01:57:23,597:INFO: 		 ADE on zara2                     dataset:	 0.4003320336341858
2022-11-03 01:57:23,597:INFO: Average validation:	ADE  0.4660	FDE  1.0081
2022-11-03 01:57:23,598:INFO: - Computing ADE (training)
2022-11-03 01:57:24,207:INFO: 		 ADE on hotel                     dataset:	 0.398164302110672
2022-11-03 01:57:25,258:INFO: 		 ADE on univ                      dataset:	 0.5330402255058289
2022-11-03 01:57:26,000:INFO: 		 ADE on zara1                     dataset:	 0.4190995395183563
2022-11-03 01:57:27,182:INFO: 		 ADE on zara2                     dataset:	 0.381832093000412
2022-11-03 01:57:27,182:INFO: Average training:	ADE  0.4917	FDE  1.0661
2022-11-03 01:57:27,193:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_624.pth.tar
2022-11-03 01:57:27,193:INFO: 
===> EPOCH: 625 (P4)
2022-11-03 01:57:27,194:INFO: - Computing loss (training)
2022-11-03 01:57:28,325:INFO: Batch:  0/31	Total Loss -171.1880 (-171.1880)
2022-11-03 01:57:28,836:INFO: Batch:  1/31	Total Loss -182.3702 (-176.9227)
2022-11-03 01:57:29,340:INFO: Batch:  2/31	Total Loss -156.9695 (-170.3957)
2022-11-03 01:57:29,846:INFO: Batch:  3/31	Total Loss -151.7156 (-165.7554)
2022-11-03 01:57:30,348:INFO: Batch:  4/31	Total Loss -159.2984 (-164.4801)
2022-11-03 01:57:30,854:INFO: Batch:  5/31	Total Loss -144.0813 (-160.9088)
2022-11-03 01:57:31,357:INFO: Batch:  6/31	Total Loss -150.3867 (-159.4020)
2022-11-03 01:57:31,857:INFO: Batch:  7/31	Total Loss -171.9498 (-161.0167)
2022-11-03 01:57:32,356:INFO: Batch:  8/31	Total Loss -170.4616 (-162.1140)
2022-11-03 01:57:32,860:INFO: Batch:  9/31	Total Loss -168.4454 (-162.7142)
2022-11-03 01:57:33,360:INFO: Batch: 10/31	Total Loss -155.5218 (-162.0757)
2022-11-03 01:57:33,858:INFO: Batch: 11/31	Total Loss -166.8286 (-162.4254)
2022-11-03 01:57:34,362:INFO: Batch: 12/31	Total Loss -172.1003 (-163.2039)
2022-11-03 01:57:34,867:INFO: Batch: 13/31	Total Loss -177.3840 (-164.3533)
2022-11-03 01:57:35,370:INFO: Batch: 14/31	Total Loss -111.6784 (-161.0635)
2022-11-03 01:57:35,876:INFO: Batch: 15/31	Total Loss -145.7634 (-160.1268)
2022-11-03 01:57:36,380:INFO: Batch: 16/31	Total Loss -154.8189 (-159.8272)
2022-11-03 01:57:36,894:INFO: Batch: 17/31	Total Loss -155.6627 (-159.6131)
2022-11-03 01:57:37,397:INFO: Batch: 18/31	Total Loss -169.6665 (-160.1374)
2022-11-03 01:57:37,903:INFO: Batch: 19/31	Total Loss -187.9059 (-161.6091)
2022-11-03 01:57:38,406:INFO: Batch: 20/31	Total Loss -147.0828 (-160.9651)
2022-11-03 01:57:38,910:INFO: Batch: 21/31	Total Loss -171.6251 (-161.4686)
2022-11-03 01:57:39,412:INFO: Batch: 22/31	Total Loss -141.4602 (-160.7141)
2022-11-03 01:57:39,912:INFO: Batch: 23/31	Total Loss -169.9504 (-161.1055)
2022-11-03 01:57:40,414:INFO: Batch: 24/31	Total Loss -144.8573 (-160.4488)
2022-11-03 01:57:40,915:INFO: Batch: 25/31	Total Loss -164.1006 (-160.6069)
2022-11-03 01:57:41,417:INFO: Batch: 26/31	Total Loss -175.4854 (-161.2402)
2022-11-03 01:57:41,919:INFO: Batch: 27/31	Total Loss -174.9675 (-161.7280)
2022-11-03 01:57:42,424:INFO: Batch: 28/31	Total Loss -142.3341 (-161.0887)
2022-11-03 01:57:42,926:INFO: Batch: 29/31	Total Loss -133.9489 (-160.3200)
2022-11-03 01:57:43,322:INFO: Batch: 30/31	Total Loss -86.7605 (-159.6149)
2022-11-03 01:57:43,470:INFO: - Computing ADE (validation o)
2022-11-03 01:57:44,173:INFO: 		 ADE on eth                       dataset:	 0.9272403120994568
2022-11-03 01:57:44,173:INFO: Average validation o:	ADE  0.9272	FDE  2.0149
2022-11-03 01:57:44,174:INFO: - Computing ADE (validation)
2022-11-03 01:57:44,466:INFO: 		 ADE on hotel                     dataset:	 0.3931375741958618
2022-11-03 01:57:44,842:INFO: 		 ADE on univ                      dataset:	 0.5354273915290833
2022-11-03 01:57:45,136:INFO: 		 ADE on zara1                     dataset:	 0.40824437141418457
2022-11-03 01:57:45,616:INFO: 		 ADE on zara2                     dataset:	 0.39565378427505493
2022-11-03 01:57:45,617:INFO: Average validation:	ADE  0.4690	FDE  1.0097
2022-11-03 01:57:45,617:INFO: - Computing ADE (training)
2022-11-03 01:57:46,179:INFO: 		 ADE on hotel                     dataset:	 0.4040027856826782
2022-11-03 01:57:47,267:INFO: 		 ADE on univ                      dataset:	 0.5319877862930298
2022-11-03 01:57:48,016:INFO: 		 ADE on zara1                     dataset:	 0.42517805099487305
2022-11-03 01:57:49,180:INFO: 		 ADE on zara2                     dataset:	 0.37644699215888977
2022-11-03 01:57:49,180:INFO: Average training:	ADE  0.4904	FDE  1.0553
2022-11-03 01:57:49,191:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_625.pth.tar
2022-11-03 01:57:49,192:INFO: 
===> EPOCH: 626 (P4)
2022-11-03 01:57:49,192:INFO: - Computing loss (training)
2022-11-03 01:57:50,312:INFO: Batch:  0/31	Total Loss -189.1365 (-189.1365)
2022-11-03 01:57:50,825:INFO: Batch:  1/31	Total Loss -165.7239 (-177.4695)
2022-11-03 01:57:51,324:INFO: Batch:  2/31	Total Loss -164.3469 (-173.3617)
2022-11-03 01:57:51,828:INFO: Batch:  3/31	Total Loss -164.3209 (-171.0826)
2022-11-03 01:57:52,331:INFO: Batch:  4/31	Total Loss -177.1256 (-172.3163)
2022-11-03 01:57:52,838:INFO: Batch:  5/31	Total Loss -160.4163 (-170.3278)
2022-11-03 01:57:53,339:INFO: Batch:  6/31	Total Loss -172.4186 (-170.6181)
2022-11-03 01:57:53,840:INFO: Batch:  7/31	Total Loss -183.3556 (-172.1516)
2022-11-03 01:57:54,341:INFO: Batch:  8/31	Total Loss -170.9453 (-172.0137)
2022-11-03 01:57:54,843:INFO: Batch:  9/31	Total Loss -169.7468 (-171.7808)
2022-11-03 01:57:55,346:INFO: Batch: 10/31	Total Loss -173.2202 (-171.8958)
2022-11-03 01:57:55,848:INFO: Batch: 11/31	Total Loss -161.9429 (-171.1463)
2022-11-03 01:57:56,351:INFO: Batch: 12/31	Total Loss -150.4825 (-169.6426)
2022-11-03 01:57:56,856:INFO: Batch: 13/31	Total Loss -170.7164 (-169.7219)
2022-11-03 01:57:57,361:INFO: Batch: 14/31	Total Loss -165.6611 (-169.4541)
2022-11-03 01:57:57,866:INFO: Batch: 15/31	Total Loss -159.6957 (-168.9397)
2022-11-03 01:57:58,370:INFO: Batch: 16/31	Total Loss -182.2137 (-169.6957)
2022-11-03 01:57:58,875:INFO: Batch: 17/31	Total Loss -172.1955 (-169.8334)
2022-11-03 01:57:59,380:INFO: Batch: 18/31	Total Loss -144.4953 (-168.5484)
2022-11-03 01:57:59,886:INFO: Batch: 19/31	Total Loss -173.7980 (-168.8117)
2022-11-03 01:58:00,391:INFO: Batch: 20/31	Total Loss -189.9404 (-169.9636)
2022-11-03 01:58:00,902:INFO: Batch: 21/31	Total Loss -190.5958 (-170.9664)
2022-11-03 01:58:01,406:INFO: Batch: 22/31	Total Loss -160.2967 (-170.5450)
2022-11-03 01:58:01,909:INFO: Batch: 23/31	Total Loss -175.4027 (-170.7458)
2022-11-03 01:58:02,416:INFO: Batch: 24/31	Total Loss -180.7096 (-171.1614)
2022-11-03 01:58:02,923:INFO: Batch: 25/31	Total Loss -193.9696 (-172.0526)
2022-11-03 01:58:03,429:INFO: Batch: 26/31	Total Loss -155.3704 (-171.5501)
2022-11-03 01:58:03,921:INFO: Batch: 27/31	Total Loss -191.6390 (-172.3230)
2022-11-03 01:58:04,414:INFO: Batch: 28/31	Total Loss -177.9730 (-172.5121)
2022-11-03 01:58:04,907:INFO: Batch: 29/31	Total Loss -168.0351 (-172.3700)
2022-11-03 01:58:05,296:INFO: Batch: 30/31	Total Loss -116.3958 (-171.8129)
2022-11-03 01:58:05,452:INFO: - Computing ADE (validation o)
2022-11-03 01:58:06,135:INFO: 		 ADE on eth                       dataset:	 0.9190756678581238
2022-11-03 01:58:06,135:INFO: Average validation o:	ADE  0.9191	FDE  1.9290
2022-11-03 01:58:06,136:INFO: - Computing ADE (validation)
2022-11-03 01:58:06,446:INFO: 		 ADE on hotel                     dataset:	 0.3899375796318054
2022-11-03 01:58:06,817:INFO: 		 ADE on univ                      dataset:	 0.5257732272148132
2022-11-03 01:58:07,122:INFO: 		 ADE on zara1                     dataset:	 0.4035896062850952
2022-11-03 01:58:07,592:INFO: 		 ADE on zara2                     dataset:	 0.4015228748321533
2022-11-03 01:58:07,593:INFO: Average validation:	ADE  0.4657	FDE  0.9954
2022-11-03 01:58:07,594:INFO: - Computing ADE (training)
2022-11-03 01:58:08,155:INFO: 		 ADE on hotel                     dataset:	 0.4011143743991852
2022-11-03 01:58:09,218:INFO: 		 ADE on univ                      dataset:	 0.5259201526641846
2022-11-03 01:58:09,963:INFO: 		 ADE on zara1                     dataset:	 0.4454992711544037
2022-11-03 01:58:11,187:INFO: 		 ADE on zara2                     dataset:	 0.39636358618736267
2022-11-03 01:58:11,188:INFO: Average training:	ADE  0.4913	FDE  1.0532
2022-11-03 01:58:11,198:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_626.pth.tar
2022-11-03 01:58:11,199:INFO: 
===> EPOCH: 627 (P4)
2022-11-03 01:58:11,199:INFO: - Computing loss (training)
2022-11-03 01:58:12,320:INFO: Batch:  0/31	Total Loss -180.1712 (-180.1712)
2022-11-03 01:58:12,832:INFO: Batch:  1/31	Total Loss -166.1923 (-173.6236)
2022-11-03 01:58:13,337:INFO: Batch:  2/31	Total Loss -171.6816 (-172.9871)
2022-11-03 01:58:13,919:INFO: Batch:  3/31	Total Loss -180.8025 (-174.9608)
2022-11-03 01:58:14,425:INFO: Batch:  4/31	Total Loss -151.8772 (-170.3604)
2022-11-03 01:58:14,938:INFO: Batch:  5/31	Total Loss -192.3318 (-174.3552)
2022-11-03 01:58:15,442:INFO: Batch:  6/31	Total Loss -200.5964 (-178.3667)
2022-11-03 01:58:15,945:INFO: Batch:  7/31	Total Loss -172.7073 (-177.6441)
2022-11-03 01:58:16,451:INFO: Batch:  8/31	Total Loss -195.9454 (-179.8760)
2022-11-03 01:58:16,953:INFO: Batch:  9/31	Total Loss -175.0901 (-179.4160)
2022-11-03 01:58:17,456:INFO: Batch: 10/31	Total Loss -165.7671 (-178.2967)
2022-11-03 01:58:17,961:INFO: Batch: 11/31	Total Loss -195.6322 (-179.7467)
2022-11-03 01:58:18,467:INFO: Batch: 12/31	Total Loss -187.4183 (-180.3793)
2022-11-03 01:58:18,972:INFO: Batch: 13/31	Total Loss -153.3288 (-178.6090)
2022-11-03 01:58:19,481:INFO: Batch: 14/31	Total Loss -176.1921 (-178.4509)
2022-11-03 01:58:19,987:INFO: Batch: 15/31	Total Loss -193.4596 (-179.3733)
2022-11-03 01:58:20,493:INFO: Batch: 16/31	Total Loss -160.8029 (-178.2668)
2022-11-03 01:58:20,999:INFO: Batch: 17/31	Total Loss -192.1299 (-179.0801)
2022-11-03 01:58:21,498:INFO: Batch: 18/31	Total Loss -185.7729 (-179.4190)
2022-11-03 01:58:21,995:INFO: Batch: 19/31	Total Loss -188.6195 (-179.8544)
2022-11-03 01:58:22,492:INFO: Batch: 20/31	Total Loss -173.2586 (-179.5609)
2022-11-03 01:58:22,996:INFO: Batch: 21/31	Total Loss -190.0841 (-180.0590)
2022-11-03 01:58:23,497:INFO: Batch: 22/31	Total Loss -188.9905 (-180.4671)
2022-11-03 01:58:23,999:INFO: Batch: 23/31	Total Loss -153.3995 (-179.3608)
2022-11-03 01:58:24,501:INFO: Batch: 24/31	Total Loss -163.8051 (-178.7246)
2022-11-03 01:58:25,009:INFO: Batch: 25/31	Total Loss -187.4866 (-179.0512)
2022-11-03 01:58:25,510:INFO: Batch: 26/31	Total Loss -170.1652 (-178.7636)
2022-11-03 01:58:26,011:INFO: Batch: 27/31	Total Loss -173.7351 (-178.5808)
2022-11-03 01:58:26,511:INFO: Batch: 28/31	Total Loss -208.9226 (-179.6881)
2022-11-03 01:58:27,013:INFO: Batch: 29/31	Total Loss -184.8204 (-179.8596)
2022-11-03 01:58:27,409:INFO: Batch: 30/31	Total Loss -103.5032 (-179.3257)
2022-11-03 01:58:27,561:INFO: - Computing ADE (validation o)
2022-11-03 01:58:28,254:INFO: 		 ADE on eth                       dataset:	 0.9333438873291016
2022-11-03 01:58:28,254:INFO: Average validation o:	ADE  0.9333	FDE  2.0171
2022-11-03 01:58:28,255:INFO: - Computing ADE (validation)
2022-11-03 01:58:28,564:INFO: 		 ADE on hotel                     dataset:	 0.3930615484714508
2022-11-03 01:58:28,938:INFO: 		 ADE on univ                      dataset:	 0.5345219969749451
2022-11-03 01:58:29,234:INFO: 		 ADE on zara1                     dataset:	 0.3883693814277649
2022-11-03 01:58:29,714:INFO: 		 ADE on zara2                     dataset:	 0.39327824115753174
2022-11-03 01:58:29,715:INFO: Average validation:	ADE  0.4665	FDE  0.9962
2022-11-03 01:58:29,715:INFO: - Computing ADE (training)
2022-11-03 01:58:30,265:INFO: 		 ADE on hotel                     dataset:	 0.3993400037288666
2022-11-03 01:58:31,295:INFO: 		 ADE on univ                      dataset:	 0.5286463499069214
2022-11-03 01:58:32,034:INFO: 		 ADE on zara1                     dataset:	 0.4305953085422516
2022-11-03 01:58:33,227:INFO: 		 ADE on zara2                     dataset:	 0.37917909026145935
2022-11-03 01:58:33,227:INFO: Average training:	ADE  0.4888	FDE  1.0465
2022-11-03 01:58:33,239:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_627.pth.tar
2022-11-03 01:58:33,239:INFO: 
===> EPOCH: 628 (P4)
2022-11-03 01:58:33,239:INFO: - Computing loss (training)
2022-11-03 01:58:34,385:INFO: Batch:  0/31	Total Loss -166.8864 (-166.8864)
2022-11-03 01:58:34,890:INFO: Batch:  1/31	Total Loss -163.3368 (-165.1245)
2022-11-03 01:58:35,397:INFO: Batch:  2/31	Total Loss -202.2671 (-177.8011)
2022-11-03 01:58:35,894:INFO: Batch:  3/31	Total Loss -180.1042 (-178.3932)
2022-11-03 01:58:36,394:INFO: Batch:  4/31	Total Loss -181.3306 (-179.0108)
2022-11-03 01:58:36,901:INFO: Batch:  5/31	Total Loss -151.0766 (-174.2307)
2022-11-03 01:58:37,400:INFO: Batch:  6/31	Total Loss -174.7935 (-174.3144)
2022-11-03 01:58:37,900:INFO: Batch:  7/31	Total Loss -145.8192 (-171.2658)
2022-11-03 01:58:38,399:INFO: Batch:  8/31	Total Loss -156.7788 (-169.6963)
2022-11-03 01:58:38,899:INFO: Batch:  9/31	Total Loss -147.3147 (-167.5538)
2022-11-03 01:58:39,397:INFO: Batch: 10/31	Total Loss -174.8065 (-168.2693)
2022-11-03 01:58:39,899:INFO: Batch: 11/31	Total Loss -166.7790 (-168.1427)
2022-11-03 01:58:40,404:INFO: Batch: 12/31	Total Loss -153.7691 (-167.1137)
2022-11-03 01:58:40,911:INFO: Batch: 13/31	Total Loss -180.2132 (-168.0393)
2022-11-03 01:58:41,416:INFO: Batch: 14/31	Total Loss -157.9340 (-167.3419)
2022-11-03 01:58:41,922:INFO: Batch: 15/31	Total Loss -194.3017 (-169.0728)
2022-11-03 01:58:42,414:INFO: Batch: 16/31	Total Loss -191.2094 (-170.4366)
2022-11-03 01:58:42,906:INFO: Batch: 17/31	Total Loss -155.1871 (-169.6548)
2022-11-03 01:58:43,399:INFO: Batch: 18/31	Total Loss -185.9050 (-170.5326)
2022-11-03 01:58:43,891:INFO: Batch: 19/31	Total Loss -159.1936 (-169.9831)
2022-11-03 01:58:44,381:INFO: Batch: 20/31	Total Loss -171.8049 (-170.0686)
2022-11-03 01:58:44,873:INFO: Batch: 21/31	Total Loss -155.9676 (-169.5102)
2022-11-03 01:58:45,363:INFO: Batch: 22/31	Total Loss -177.4992 (-169.8149)
2022-11-03 01:58:45,856:INFO: Batch: 23/31	Total Loss -193.5649 (-170.8392)
2022-11-03 01:58:46,348:INFO: Batch: 24/31	Total Loss -175.0960 (-171.0318)
2022-11-03 01:58:46,841:INFO: Batch: 25/31	Total Loss -200.0259 (-172.1044)
2022-11-03 01:58:47,332:INFO: Batch: 26/31	Total Loss -115.9261 (-169.9392)
2022-11-03 01:58:47,823:INFO: Batch: 27/31	Total Loss -194.6405 (-170.8067)
2022-11-03 01:58:48,312:INFO: Batch: 28/31	Total Loss -172.1974 (-170.8522)
2022-11-03 01:58:48,806:INFO: Batch: 29/31	Total Loss -182.4409 (-171.2500)
2022-11-03 01:58:49,192:INFO: Batch: 30/31	Total Loss -117.7040 (-170.7747)
2022-11-03 01:58:49,341:INFO: - Computing ADE (validation o)
2022-11-03 01:58:50,007:INFO: 		 ADE on eth                       dataset:	 0.9150153994560242
2022-11-03 01:58:50,007:INFO: Average validation o:	ADE  0.9150	FDE  1.9464
2022-11-03 01:58:50,008:INFO: - Computing ADE (validation)
2022-11-03 01:58:50,308:INFO: 		 ADE on hotel                     dataset:	 0.3887527287006378
2022-11-03 01:58:50,679:INFO: 		 ADE on univ                      dataset:	 0.5379636287689209
2022-11-03 01:58:50,962:INFO: 		 ADE on zara1                     dataset:	 0.429866760969162
2022-11-03 01:58:51,437:INFO: 		 ADE on zara2                     dataset:	 0.4094184935092926
2022-11-03 01:58:51,437:INFO: Average validation:	ADE  0.4764	FDE  1.0231
2022-11-03 01:58:51,438:INFO: - Computing ADE (training)
2022-11-03 01:58:51,998:INFO: 		 ADE on hotel                     dataset:	 0.40129807591438293
2022-11-03 01:58:53,084:INFO: 		 ADE on univ                      dataset:	 0.5353941321372986
2022-11-03 01:58:53,867:INFO: 		 ADE on zara1                     dataset:	 0.4318230152130127
2022-11-03 01:58:55,047:INFO: 		 ADE on zara2                     dataset:	 0.39029502868652344
2022-11-03 01:58:55,048:INFO: Average training:	ADE  0.4959	FDE  1.0633
2022-11-03 01:58:55,058:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_628.pth.tar
2022-11-03 01:58:55,058:INFO: 
===> EPOCH: 629 (P4)
2022-11-03 01:58:55,059:INFO: - Computing loss (training)
2022-11-03 01:58:56,165:INFO: Batch:  0/31	Total Loss -181.6577 (-181.6577)
2022-11-03 01:58:56,668:INFO: Batch:  1/31	Total Loss -176.1725 (-178.9727)
2022-11-03 01:58:57,163:INFO: Batch:  2/31	Total Loss -163.6201 (-173.8769)
2022-11-03 01:58:57,659:INFO: Batch:  3/31	Total Loss -184.4849 (-176.4852)
2022-11-03 01:58:58,153:INFO: Batch:  4/31	Total Loss -172.5942 (-175.6983)
2022-11-03 01:58:58,647:INFO: Batch:  5/31	Total Loss -148.6661 (-171.6613)
2022-11-03 01:58:59,136:INFO: Batch:  6/31	Total Loss -172.8081 (-171.8250)
2022-11-03 01:58:59,624:INFO: Batch:  7/31	Total Loss -174.5512 (-172.1384)
2022-11-03 01:59:00,116:INFO: Batch:  8/31	Total Loss -171.0326 (-172.0233)
2022-11-03 01:59:00,608:INFO: Batch:  9/31	Total Loss -198.2980 (-174.7716)
2022-11-03 01:59:01,104:INFO: Batch: 10/31	Total Loss -139.3251 (-172.0314)
2022-11-03 01:59:01,599:INFO: Batch: 11/31	Total Loss -169.0000 (-171.8063)
2022-11-03 01:59:02,094:INFO: Batch: 12/31	Total Loss -188.6497 (-173.1681)
2022-11-03 01:59:02,588:INFO: Batch: 13/31	Total Loss -168.3243 (-172.8154)
2022-11-03 01:59:03,083:INFO: Batch: 14/31	Total Loss -184.9685 (-173.6823)
2022-11-03 01:59:03,577:INFO: Batch: 15/31	Total Loss -192.7248 (-174.9102)
2022-11-03 01:59:04,071:INFO: Batch: 16/31	Total Loss -161.5296 (-174.2245)
2022-11-03 01:59:04,641:INFO: Batch: 17/31	Total Loss -195.9306 (-175.5134)
2022-11-03 01:59:05,134:INFO: Batch: 18/31	Total Loss -172.6047 (-175.3524)
2022-11-03 01:59:05,626:INFO: Batch: 19/31	Total Loss -176.0928 (-175.3907)
2022-11-03 01:59:06,118:INFO: Batch: 20/31	Total Loss -138.0326 (-173.8003)
2022-11-03 01:59:06,612:INFO: Batch: 21/31	Total Loss -179.2702 (-174.0539)
2022-11-03 01:59:07,112:INFO: Batch: 22/31	Total Loss -194.3388 (-174.9865)
2022-11-03 01:59:07,608:INFO: Batch: 23/31	Total Loss -178.0492 (-175.1037)
2022-11-03 01:59:08,101:INFO: Batch: 24/31	Total Loss -194.9383 (-175.9966)
2022-11-03 01:59:08,595:INFO: Batch: 25/31	Total Loss -206.6127 (-177.3708)
2022-11-03 01:59:09,088:INFO: Batch: 26/31	Total Loss -218.8839 (-179.0133)
2022-11-03 01:59:09,580:INFO: Batch: 27/31	Total Loss -167.2526 (-178.6309)
2022-11-03 01:59:10,074:INFO: Batch: 28/31	Total Loss -190.5176 (-179.0344)
2022-11-03 01:59:10,566:INFO: Batch: 29/31	Total Loss -177.0739 (-178.9700)
2022-11-03 01:59:10,954:INFO: Batch: 30/31	Total Loss -109.6671 (-178.0798)
2022-11-03 01:59:11,111:INFO: - Computing ADE (validation o)
2022-11-03 01:59:11,816:INFO: 		 ADE on eth                       dataset:	 0.9224905371665955
2022-11-03 01:59:11,816:INFO: Average validation o:	ADE  0.9225	FDE  1.9566
2022-11-03 01:59:11,817:INFO: - Computing ADE (validation)
2022-11-03 01:59:12,116:INFO: 		 ADE on hotel                     dataset:	 0.37922003865242004
2022-11-03 01:59:12,478:INFO: 		 ADE on univ                      dataset:	 0.5305600166320801
2022-11-03 01:59:12,787:INFO: 		 ADE on zara1                     dataset:	 0.3921629786491394
2022-11-03 01:59:13,276:INFO: 		 ADE on zara2                     dataset:	 0.39855432510375977
2022-11-03 01:59:13,276:INFO: Average validation:	ADE  0.4658	FDE  0.9925
2022-11-03 01:59:13,277:INFO: - Computing ADE (training)
2022-11-03 01:59:13,859:INFO: 		 ADE on hotel                     dataset:	 0.391604483127594
2022-11-03 01:59:14,909:INFO: 		 ADE on univ                      dataset:	 0.5278783440589905
2022-11-03 01:59:15,635:INFO: 		 ADE on zara1                     dataset:	 0.4337460696697235
2022-11-03 01:59:16,794:INFO: 		 ADE on zara2                     dataset:	 0.3873249590396881
2022-11-03 01:59:16,795:INFO: Average training:	ADE  0.4899	FDE  1.0480
2022-11-03 01:59:16,807:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_629.pth.tar
2022-11-03 01:59:16,807:INFO: 
===> EPOCH: 630 (P4)
2022-11-03 01:59:16,807:INFO: - Computing loss (training)
2022-11-03 01:59:17,935:INFO: Batch:  0/31	Total Loss -164.2848 (-164.2848)
2022-11-03 01:59:18,431:INFO: Batch:  1/31	Total Loss -203.9016 (-185.8979)
2022-11-03 01:59:18,931:INFO: Batch:  2/31	Total Loss -201.3988 (-191.6165)
2022-11-03 01:59:19,424:INFO: Batch:  3/31	Total Loss -175.8500 (-187.8787)
2022-11-03 01:59:19,920:INFO: Batch:  4/31	Total Loss -184.7034 (-187.2011)
2022-11-03 01:59:20,412:INFO: Batch:  5/31	Total Loss -192.2602 (-188.0401)
2022-11-03 01:59:20,907:INFO: Batch:  6/31	Total Loss -209.1401 (-190.9962)
2022-11-03 01:59:21,399:INFO: Batch:  7/31	Total Loss -184.4136 (-190.1799)
2022-11-03 01:59:21,891:INFO: Batch:  8/31	Total Loss -194.8676 (-190.6966)
2022-11-03 01:59:22,383:INFO: Batch:  9/31	Total Loss -195.5655 (-191.2030)
2022-11-03 01:59:22,874:INFO: Batch: 10/31	Total Loss -197.6655 (-191.7905)
2022-11-03 01:59:23,365:INFO: Batch: 11/31	Total Loss -201.2299 (-192.6126)
2022-11-03 01:59:23,859:INFO: Batch: 12/31	Total Loss -209.8112 (-193.9668)
2022-11-03 01:59:24,355:INFO: Batch: 13/31	Total Loss -187.6504 (-193.5147)
2022-11-03 01:59:24,850:INFO: Batch: 14/31	Total Loss -211.5507 (-194.7970)
2022-11-03 01:59:25,344:INFO: Batch: 15/31	Total Loss -191.6431 (-194.5992)
2022-11-03 01:59:25,839:INFO: Batch: 16/31	Total Loss -167.0288 (-193.0849)
2022-11-03 01:59:26,334:INFO: Batch: 17/31	Total Loss -198.9948 (-193.4105)
2022-11-03 01:59:26,829:INFO: Batch: 18/31	Total Loss -182.4999 (-192.8811)
2022-11-03 01:59:27,322:INFO: Batch: 19/31	Total Loss -171.0261 (-191.7715)
2022-11-03 01:59:27,816:INFO: Batch: 20/31	Total Loss -185.7934 (-191.4765)
2022-11-03 01:59:28,308:INFO: Batch: 21/31	Total Loss -119.6310 (-188.3602)
2022-11-03 01:59:28,803:INFO: Batch: 22/31	Total Loss -202.8277 (-189.0412)
2022-11-03 01:59:29,296:INFO: Batch: 23/31	Total Loss -200.8578 (-189.5647)
2022-11-03 01:59:29,791:INFO: Batch: 24/31	Total Loss -167.6054 (-188.7631)
2022-11-03 01:59:30,285:INFO: Batch: 25/31	Total Loss -177.7622 (-188.3451)
2022-11-03 01:59:30,779:INFO: Batch: 26/31	Total Loss -165.9660 (-187.5162)
2022-11-03 01:59:31,273:INFO: Batch: 27/31	Total Loss -159.1613 (-186.4905)
2022-11-03 01:59:31,767:INFO: Batch: 28/31	Total Loss -174.5530 (-186.0276)
2022-11-03 01:59:32,260:INFO: Batch: 29/31	Total Loss -139.8050 (-184.4925)
2022-11-03 01:59:32,649:INFO: Batch: 30/31	Total Loss -119.5320 (-183.8764)
2022-11-03 01:59:32,806:INFO: - Computing ADE (validation o)
2022-11-03 01:59:33,534:INFO: 		 ADE on eth                       dataset:	 0.9269644618034363
2022-11-03 01:59:33,534:INFO: Average validation o:	ADE  0.9270	FDE  1.9771
2022-11-03 01:59:33,535:INFO: - Computing ADE (validation)
2022-11-03 01:59:33,848:INFO: 		 ADE on hotel                     dataset:	 0.3627815246582031
2022-11-03 01:59:34,210:INFO: 		 ADE on univ                      dataset:	 0.5275723934173584
2022-11-03 01:59:34,507:INFO: 		 ADE on zara1                     dataset:	 0.3872808516025543
2022-11-03 01:59:34,982:INFO: 		 ADE on zara2                     dataset:	 0.3940298557281494
2022-11-03 01:59:34,982:INFO: Average validation:	ADE  0.4614	FDE  0.9918
2022-11-03 01:59:34,983:INFO: - Computing ADE (training)
2022-11-03 01:59:35,560:INFO: 		 ADE on hotel                     dataset:	 0.36923760175704956
2022-11-03 01:59:36,628:INFO: 		 ADE on univ                      dataset:	 0.5247316360473633
2022-11-03 01:59:37,358:INFO: 		 ADE on zara1                     dataset:	 0.43446460366249084
2022-11-03 01:59:38,500:INFO: 		 ADE on zara2                     dataset:	 0.38240981101989746
2022-11-03 01:59:38,500:INFO: Average training:	ADE  0.4861	FDE  1.0485
2022-11-03 01:59:38,511:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_630.pth.tar
2022-11-03 01:59:38,511:INFO: 
===> EPOCH: 631 (P4)
2022-11-03 01:59:38,512:INFO: - Computing loss (training)
2022-11-03 01:59:39,644:INFO: Batch:  0/31	Total Loss -122.7933 (-122.7933)
2022-11-03 01:59:40,136:INFO: Batch:  1/31	Total Loss -166.7090 (-144.6056)
2022-11-03 01:59:40,633:INFO: Batch:  2/31	Total Loss -145.9494 (-145.0647)
2022-11-03 01:59:41,132:INFO: Batch:  3/31	Total Loss -157.6016 (-148.0349)
2022-11-03 01:59:41,627:INFO: Batch:  4/31	Total Loss -167.1902 (-151.6471)
2022-11-03 01:59:42,120:INFO: Batch:  5/31	Total Loss -181.9872 (-156.6295)
2022-11-03 01:59:42,611:INFO: Batch:  6/31	Total Loss -162.6743 (-157.3959)
2022-11-03 01:59:43,104:INFO: Batch:  7/31	Total Loss -166.0540 (-158.4235)
2022-11-03 01:59:43,595:INFO: Batch:  8/31	Total Loss -165.4817 (-159.1165)
2022-11-03 01:59:44,087:INFO: Batch:  9/31	Total Loss -183.5753 (-161.4095)
2022-11-03 01:59:44,580:INFO: Batch: 10/31	Total Loss -190.0893 (-164.1636)
2022-11-03 01:59:45,072:INFO: Batch: 11/31	Total Loss -168.6145 (-164.5058)
2022-11-03 01:59:45,568:INFO: Batch: 12/31	Total Loss -173.1410 (-165.1517)
2022-11-03 01:59:46,062:INFO: Batch: 13/31	Total Loss -137.8613 (-163.2541)
2022-11-03 01:59:46,557:INFO: Batch: 14/31	Total Loss -164.5331 (-163.3379)
2022-11-03 01:59:47,052:INFO: Batch: 15/31	Total Loss -154.8613 (-162.8228)
2022-11-03 01:59:47,548:INFO: Batch: 16/31	Total Loss -195.0901 (-164.8701)
2022-11-03 01:59:48,044:INFO: Batch: 17/31	Total Loss -190.8427 (-166.4059)
2022-11-03 01:59:48,539:INFO: Batch: 18/31	Total Loss -197.0103 (-168.1238)
2022-11-03 01:59:49,032:INFO: Batch: 19/31	Total Loss -130.1983 (-166.3980)
2022-11-03 01:59:49,526:INFO: Batch: 20/31	Total Loss -178.9786 (-166.9776)
2022-11-03 01:59:50,020:INFO: Batch: 21/31	Total Loss -179.2818 (-167.5543)
2022-11-03 01:59:50,516:INFO: Batch: 22/31	Total Loss -215.2534 (-169.9097)
2022-11-03 01:59:51,012:INFO: Batch: 23/31	Total Loss -184.7310 (-170.4826)
2022-11-03 01:59:51,506:INFO: Batch: 24/31	Total Loss -171.1666 (-170.5099)
2022-11-03 01:59:51,999:INFO: Batch: 25/31	Total Loss -162.5950 (-170.2581)
2022-11-03 01:59:52,494:INFO: Batch: 26/31	Total Loss -170.9514 (-170.2836)
2022-11-03 01:59:52,989:INFO: Batch: 27/31	Total Loss -166.0258 (-170.1263)
2022-11-03 01:59:53,483:INFO: Batch: 28/31	Total Loss -192.9304 (-170.9579)
2022-11-03 01:59:53,978:INFO: Batch: 29/31	Total Loss -170.3297 (-170.9382)
2022-11-03 01:59:54,368:INFO: Batch: 30/31	Total Loss -124.7882 (-170.4927)
2022-11-03 01:59:54,508:INFO: - Computing ADE (validation o)
2022-11-03 01:59:55,214:INFO: 		 ADE on eth                       dataset:	 0.9270262122154236
2022-11-03 01:59:55,214:INFO: Average validation o:	ADE  0.9270	FDE  2.0077
2022-11-03 01:59:55,215:INFO: - Computing ADE (validation)
2022-11-03 01:59:55,523:INFO: 		 ADE on hotel                     dataset:	 0.3889416456222534
2022-11-03 01:59:55,890:INFO: 		 ADE on univ                      dataset:	 0.5291131138801575
2022-11-03 01:59:56,184:INFO: 		 ADE on zara1                     dataset:	 0.39065274596214294
2022-11-03 01:59:56,660:INFO: 		 ADE on zara2                     dataset:	 0.3996579647064209
2022-11-03 01:59:56,660:INFO: Average validation:	ADE  0.4659	FDE  1.0005
2022-11-03 01:59:56,661:INFO: - Computing ADE (training)
2022-11-03 01:59:57,252:INFO: 		 ADE on hotel                     dataset:	 0.3905283510684967
2022-11-03 01:59:58,303:INFO: 		 ADE on univ                      dataset:	 0.5307214856147766
2022-11-03 01:59:59,055:INFO: 		 ADE on zara1                     dataset:	 0.4223015606403351
2022-11-03 02:00:00,267:INFO: 		 ADE on zara2                     dataset:	 0.3801991939544678
2022-11-03 02:00:00,267:INFO: Average training:	ADE  0.4897	FDE  1.0541
2022-11-03 02:00:00,279:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_631.pth.tar
2022-11-03 02:00:00,279:INFO: 
===> EPOCH: 632 (P4)
2022-11-03 02:00:00,279:INFO: - Computing loss (training)
2022-11-03 02:00:01,425:INFO: Batch:  0/31	Total Loss -175.3162 (-175.3162)
2022-11-03 02:00:01,928:INFO: Batch:  1/31	Total Loss -159.6863 (-168.1144)
2022-11-03 02:00:02,511:INFO: Batch:  2/31	Total Loss -183.2439 (-173.5400)
2022-11-03 02:00:03,011:INFO: Batch:  3/31	Total Loss -165.9629 (-171.6634)
2022-11-03 02:00:03,512:INFO: Batch:  4/31	Total Loss -199.7953 (-177.8844)
2022-11-03 02:00:04,016:INFO: Batch:  5/31	Total Loss -201.0444 (-181.9093)
2022-11-03 02:00:04,522:INFO: Batch:  6/31	Total Loss -173.6434 (-180.7300)
2022-11-03 02:00:05,022:INFO: Batch:  7/31	Total Loss -183.5621 (-181.0769)
2022-11-03 02:00:05,522:INFO: Batch:  8/31	Total Loss -178.2630 (-180.7341)
2022-11-03 02:00:06,021:INFO: Batch:  9/31	Total Loss -188.0195 (-181.5115)
2022-11-03 02:00:06,519:INFO: Batch: 10/31	Total Loss -186.4409 (-181.9762)
2022-11-03 02:00:07,021:INFO: Batch: 11/31	Total Loss -206.7440 (-183.9840)
2022-11-03 02:00:07,524:INFO: Batch: 12/31	Total Loss -188.6220 (-184.3170)
2022-11-03 02:00:08,030:INFO: Batch: 13/31	Total Loss -195.1902 (-185.0816)
2022-11-03 02:00:08,534:INFO: Batch: 14/31	Total Loss -204.7433 (-186.3345)
2022-11-03 02:00:09,038:INFO: Batch: 15/31	Total Loss -170.4113 (-185.3310)
2022-11-03 02:00:09,543:INFO: Batch: 16/31	Total Loss -181.8149 (-185.1340)
2022-11-03 02:00:10,048:INFO: Batch: 17/31	Total Loss -216.8275 (-187.0644)
2022-11-03 02:00:10,556:INFO: Batch: 18/31	Total Loss -208.3315 (-188.1281)
2022-11-03 02:00:11,061:INFO: Batch: 19/31	Total Loss -161.7443 (-186.9448)
2022-11-03 02:00:11,565:INFO: Batch: 20/31	Total Loss -139.8151 (-184.7959)
2022-11-03 02:00:12,070:INFO: Batch: 21/31	Total Loss -189.4205 (-185.0137)
2022-11-03 02:00:12,574:INFO: Batch: 22/31	Total Loss -202.4624 (-185.8317)
2022-11-03 02:00:13,076:INFO: Batch: 23/31	Total Loss -143.5633 (-184.1579)
2022-11-03 02:00:13,578:INFO: Batch: 24/31	Total Loss -208.9638 (-185.1527)
2022-11-03 02:00:14,079:INFO: Batch: 25/31	Total Loss -216.1583 (-186.4372)
2022-11-03 02:00:14,583:INFO: Batch: 26/31	Total Loss -217.0619 (-187.6311)
2022-11-03 02:00:15,088:INFO: Batch: 27/31	Total Loss -200.1512 (-188.0877)
2022-11-03 02:00:15,594:INFO: Batch: 28/31	Total Loss -198.3077 (-188.4459)
2022-11-03 02:00:16,097:INFO: Batch: 29/31	Total Loss -183.4821 (-188.2902)
2022-11-03 02:00:16,495:INFO: Batch: 30/31	Total Loss -128.1309 (-187.6083)
2022-11-03 02:00:16,643:INFO: - Computing ADE (validation o)
2022-11-03 02:00:17,328:INFO: 		 ADE on eth                       dataset:	 0.9182792901992798
2022-11-03 02:00:17,328:INFO: Average validation o:	ADE  0.9183	FDE  1.9621
2022-11-03 02:00:17,329:INFO: - Computing ADE (validation)
2022-11-03 02:00:17,631:INFO: 		 ADE on hotel                     dataset:	 0.37080880999565125
2022-11-03 02:00:18,014:INFO: 		 ADE on univ                      dataset:	 0.5202338695526123
2022-11-03 02:00:18,311:INFO: 		 ADE on zara1                     dataset:	 0.38684386014938354
2022-11-03 02:00:18,798:INFO: 		 ADE on zara2                     dataset:	 0.3849078118801117
2022-11-03 02:00:18,799:INFO: Average validation:	ADE  0.4547	FDE  0.9755
2022-11-03 02:00:18,799:INFO: - Computing ADE (training)
2022-11-03 02:00:19,370:INFO: 		 ADE on hotel                     dataset:	 0.3786657750606537
2022-11-03 02:00:20,418:INFO: 		 ADE on univ                      dataset:	 0.5205022096633911
2022-11-03 02:00:21,168:INFO: 		 ADE on zara1                     dataset:	 0.4186340272426605
2022-11-03 02:00:22,342:INFO: 		 ADE on zara2                     dataset:	 0.3711254894733429
2022-11-03 02:00:22,342:INFO: Average training:	ADE  0.4801	FDE  1.0337
2022-11-03 02:00:22,354:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_632.pth.tar
2022-11-03 02:00:22,354:INFO: 
===> EPOCH: 633 (P4)
2022-11-03 02:00:22,354:INFO: - Computing loss (training)
2022-11-03 02:00:23,484:INFO: Batch:  0/31	Total Loss -171.8009 (-171.8009)
2022-11-03 02:00:23,987:INFO: Batch:  1/31	Total Loss -198.8569 (-186.5455)
2022-11-03 02:00:24,500:INFO: Batch:  2/31	Total Loss -209.3148 (-194.5616)
2022-11-03 02:00:24,999:INFO: Batch:  3/31	Total Loss -195.1497 (-194.7044)
2022-11-03 02:00:25,502:INFO: Batch:  4/31	Total Loss -205.3349 (-197.0847)
2022-11-03 02:00:26,004:INFO: Batch:  5/31	Total Loss -164.7003 (-191.9687)
2022-11-03 02:00:26,506:INFO: Batch:  6/31	Total Loss -180.1477 (-190.3606)
2022-11-03 02:00:27,006:INFO: Batch:  7/31	Total Loss -184.3745 (-189.5453)
2022-11-03 02:00:27,508:INFO: Batch:  8/31	Total Loss -180.4723 (-188.6640)
2022-11-03 02:00:28,006:INFO: Batch:  9/31	Total Loss -208.6860 (-190.7654)
2022-11-03 02:00:28,508:INFO: Batch: 10/31	Total Loss -178.1028 (-189.5919)
2022-11-03 02:00:29,006:INFO: Batch: 11/31	Total Loss -209.5423 (-191.4266)
2022-11-03 02:00:29,510:INFO: Batch: 12/31	Total Loss -196.9875 (-191.8808)
2022-11-03 02:00:30,017:INFO: Batch: 13/31	Total Loss -218.6887 (-193.9954)
2022-11-03 02:00:30,521:INFO: Batch: 14/31	Total Loss -177.9986 (-193.0526)
2022-11-03 02:00:31,027:INFO: Batch: 15/31	Total Loss -202.5452 (-193.6566)
2022-11-03 02:00:31,533:INFO: Batch: 16/31	Total Loss -216.8220 (-195.0906)
2022-11-03 02:00:32,036:INFO: Batch: 17/31	Total Loss -208.5462 (-195.8678)
2022-11-03 02:00:32,540:INFO: Batch: 18/31	Total Loss -188.2270 (-195.4855)
2022-11-03 02:00:33,044:INFO: Batch: 19/31	Total Loss -189.8096 (-195.2059)
2022-11-03 02:00:33,545:INFO: Batch: 20/31	Total Loss -182.5639 (-194.6106)
2022-11-03 02:00:34,047:INFO: Batch: 21/31	Total Loss -197.2398 (-194.7313)
2022-11-03 02:00:34,549:INFO: Batch: 22/31	Total Loss -198.6446 (-194.9050)
2022-11-03 02:00:35,050:INFO: Batch: 23/31	Total Loss -200.8792 (-195.1539)
2022-11-03 02:00:35,552:INFO: Batch: 24/31	Total Loss -198.1908 (-195.2757)
2022-11-03 02:00:36,051:INFO: Batch: 25/31	Total Loss -193.8705 (-195.2205)
2022-11-03 02:00:36,554:INFO: Batch: 26/31	Total Loss -204.0564 (-195.5145)
2022-11-03 02:00:37,056:INFO: Batch: 27/31	Total Loss -207.3320 (-195.9630)
2022-11-03 02:00:37,556:INFO: Batch: 28/31	Total Loss -203.7140 (-196.2514)
2022-11-03 02:00:38,059:INFO: Batch: 29/31	Total Loss -212.9938 (-196.8306)
2022-11-03 02:00:38,453:INFO: Batch: 30/31	Total Loss -104.6521 (-196.0993)
2022-11-03 02:00:38,597:INFO: - Computing ADE (validation o)
2022-11-03 02:00:39,271:INFO: 		 ADE on eth                       dataset:	 0.9225989580154419
2022-11-03 02:00:39,271:INFO: Average validation o:	ADE  0.9226	FDE  1.9570
2022-11-03 02:00:39,272:INFO: - Computing ADE (validation)
2022-11-03 02:00:39,576:INFO: 		 ADE on hotel                     dataset:	 0.36235207319259644
2022-11-03 02:00:39,963:INFO: 		 ADE on univ                      dataset:	 0.5254924297332764
2022-11-03 02:00:40,240:INFO: 		 ADE on zara1                     dataset:	 0.3985074460506439
2022-11-03 02:00:40,710:INFO: 		 ADE on zara2                     dataset:	 0.3892824649810791
2022-11-03 02:00:40,710:INFO: Average validation:	ADE  0.4592	FDE  0.9849
2022-11-03 02:00:40,711:INFO: - Computing ADE (training)
2022-11-03 02:00:41,285:INFO: 		 ADE on hotel                     dataset:	 0.373679518699646
2022-11-03 02:00:42,347:INFO: 		 ADE on univ                      dataset:	 0.519646167755127
2022-11-03 02:00:43,123:INFO: 		 ADE on zara1                     dataset:	 0.4390864670276642
2022-11-03 02:00:44,308:INFO: 		 ADE on zara2                     dataset:	 0.3837125301361084
2022-11-03 02:00:44,308:INFO: Average training:	ADE  0.4832	FDE  1.0394
2022-11-03 02:00:44,320:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_633.pth.tar
2022-11-03 02:00:44,320:INFO: 
===> EPOCH: 634 (P4)
2022-11-03 02:00:44,320:INFO: - Computing loss (training)
2022-11-03 02:00:45,452:INFO: Batch:  0/31	Total Loss -202.4611 (-202.4611)
2022-11-03 02:00:45,947:INFO: Batch:  1/31	Total Loss -223.3906 (-213.4510)
2022-11-03 02:00:46,446:INFO: Batch:  2/31	Total Loss -226.6656 (-218.2046)
2022-11-03 02:00:46,941:INFO: Batch:  3/31	Total Loss -180.6739 (-209.1783)
2022-11-03 02:00:47,429:INFO: Batch:  4/31	Total Loss -198.7383 (-207.2040)
2022-11-03 02:00:47,921:INFO: Batch:  5/31	Total Loss -212.9528 (-208.1805)
2022-11-03 02:00:48,415:INFO: Batch:  6/31	Total Loss -215.9853 (-209.3330)
2022-11-03 02:00:48,910:INFO: Batch:  7/31	Total Loss -225.6346 (-211.5701)
2022-11-03 02:00:49,400:INFO: Batch:  8/31	Total Loss -193.7064 (-209.6537)
2022-11-03 02:00:49,895:INFO: Batch:  9/31	Total Loss -198.5629 (-208.6541)
2022-11-03 02:00:50,386:INFO: Batch: 10/31	Total Loss -172.1474 (-205.5398)
2022-11-03 02:00:50,882:INFO: Batch: 11/31	Total Loss -201.4074 (-205.2017)
2022-11-03 02:00:51,379:INFO: Batch: 12/31	Total Loss -175.5406 (-203.0169)
2022-11-03 02:00:51,874:INFO: Batch: 13/31	Total Loss -193.0554 (-202.3104)
2022-11-03 02:00:52,369:INFO: Batch: 14/31	Total Loss -196.4785 (-201.9451)
2022-11-03 02:00:52,867:INFO: Batch: 15/31	Total Loss -212.5809 (-202.6106)
2022-11-03 02:00:53,362:INFO: Batch: 16/31	Total Loss -193.0114 (-202.0557)
2022-11-03 02:00:53,857:INFO: Batch: 17/31	Total Loss -212.7240 (-202.7410)
2022-11-03 02:00:54,351:INFO: Batch: 18/31	Total Loss -198.4415 (-202.5256)
2022-11-03 02:00:54,844:INFO: Batch: 19/31	Total Loss -200.2515 (-202.4073)
2022-11-03 02:00:55,339:INFO: Batch: 20/31	Total Loss -187.0838 (-201.7619)
2022-11-03 02:00:55,909:INFO: Batch: 21/31	Total Loss -206.7888 (-201.9992)
2022-11-03 02:00:56,403:INFO: Batch: 22/31	Total Loss -200.1147 (-201.9180)
2022-11-03 02:00:56,900:INFO: Batch: 23/31	Total Loss -216.7524 (-202.5489)
2022-11-03 02:00:57,396:INFO: Batch: 24/31	Total Loss -217.8153 (-203.2057)
2022-11-03 02:00:57,891:INFO: Batch: 25/31	Total Loss -193.2121 (-202.8557)
2022-11-03 02:00:58,388:INFO: Batch: 26/31	Total Loss -232.8768 (-203.9923)
2022-11-03 02:00:58,884:INFO: Batch: 27/31	Total Loss -186.4689 (-203.3864)
2022-11-03 02:00:59,381:INFO: Batch: 28/31	Total Loss -235.0191 (-204.5749)
2022-11-03 02:00:59,876:INFO: Batch: 29/31	Total Loss -219.1456 (-205.0820)
2022-11-03 02:01:00,268:INFO: Batch: 30/31	Total Loss -114.4482 (-204.1160)
2022-11-03 02:01:00,432:INFO: - Computing ADE (validation o)
2022-11-03 02:01:01,116:INFO: 		 ADE on eth                       dataset:	 0.9141194224357605
2022-11-03 02:01:01,117:INFO: Average validation o:	ADE  0.9141	FDE  1.9360
2022-11-03 02:01:01,117:INFO: - Computing ADE (validation)
2022-11-03 02:01:01,424:INFO: 		 ADE on hotel                     dataset:	 0.39051133394241333
2022-11-03 02:01:01,796:INFO: 		 ADE on univ                      dataset:	 0.5302702188491821
2022-11-03 02:01:02,093:INFO: 		 ADE on zara1                     dataset:	 0.39438360929489136
2022-11-03 02:01:02,546:INFO: 		 ADE on zara2                     dataset:	 0.39454808831214905
2022-11-03 02:01:02,547:INFO: Average validation:	ADE  0.4649	FDE  0.9908
2022-11-03 02:01:02,547:INFO: - Computing ADE (training)
2022-11-03 02:01:03,129:INFO: 		 ADE on hotel                     dataset:	 0.3953898549079895
2022-11-03 02:01:04,197:INFO: 		 ADE on univ                      dataset:	 0.5272072553634644
2022-11-03 02:01:05,001:INFO: 		 ADE on zara1                     dataset:	 0.4329914152622223
2022-11-03 02:01:06,164:INFO: 		 ADE on zara2                     dataset:	 0.3843773901462555
2022-11-03 02:01:06,164:INFO: Average training:	ADE  0.4889	FDE  1.0460
2022-11-03 02:01:06,184:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_634.pth.tar
2022-11-03 02:01:06,184:INFO: 
===> EPOCH: 635 (P4)
2022-11-03 02:01:06,184:INFO: - Computing loss (training)
2022-11-03 02:01:07,280:INFO: Batch:  0/31	Total Loss -219.1782 (-219.1782)
2022-11-03 02:01:07,775:INFO: Batch:  1/31	Total Loss -202.0667 (-210.5494)
2022-11-03 02:01:08,271:INFO: Batch:  2/31	Total Loss -231.7264 (-218.0503)
2022-11-03 02:01:08,756:INFO: Batch:  3/31	Total Loss -184.3351 (-209.9940)
2022-11-03 02:01:09,242:INFO: Batch:  4/31	Total Loss -204.4195 (-208.9368)
2022-11-03 02:01:09,732:INFO: Batch:  5/31	Total Loss -220.7779 (-210.9614)
2022-11-03 02:01:10,222:INFO: Batch:  6/31	Total Loss -214.0355 (-211.3752)
2022-11-03 02:01:10,717:INFO: Batch:  7/31	Total Loss -231.7411 (-213.8998)
2022-11-03 02:01:11,208:INFO: Batch:  8/31	Total Loss -186.4436 (-211.1844)
2022-11-03 02:01:11,699:INFO: Batch:  9/31	Total Loss -186.3454 (-208.9000)
2022-11-03 02:01:12,188:INFO: Batch: 10/31	Total Loss -174.2291 (-205.9472)
2022-11-03 02:01:12,678:INFO: Batch: 11/31	Total Loss -186.1479 (-204.3774)
2022-11-03 02:01:13,169:INFO: Batch: 12/31	Total Loss -230.2015 (-206.4024)
2022-11-03 02:01:13,662:INFO: Batch: 13/31	Total Loss -203.2783 (-206.1654)
2022-11-03 02:01:14,152:INFO: Batch: 14/31	Total Loss -229.2674 (-207.8370)
2022-11-03 02:01:14,644:INFO: Batch: 15/31	Total Loss -235.9646 (-209.8317)
2022-11-03 02:01:15,135:INFO: Batch: 16/31	Total Loss -200.6513 (-209.3624)
2022-11-03 02:01:15,631:INFO: Batch: 17/31	Total Loss -209.4869 (-209.3697)
2022-11-03 02:01:16,124:INFO: Batch: 18/31	Total Loss -217.6289 (-209.8332)
2022-11-03 02:01:16,616:INFO: Batch: 19/31	Total Loss -223.3506 (-210.5000)
2022-11-03 02:01:17,108:INFO: Batch: 20/31	Total Loss -226.3615 (-211.3312)
2022-11-03 02:01:17,599:INFO: Batch: 21/31	Total Loss -231.7559 (-212.2694)
2022-11-03 02:01:18,091:INFO: Batch: 22/31	Total Loss -217.9899 (-212.5273)
2022-11-03 02:01:18,583:INFO: Batch: 23/31	Total Loss -234.3542 (-213.4383)
2022-11-03 02:01:19,074:INFO: Batch: 24/31	Total Loss -193.7579 (-212.7421)
2022-11-03 02:01:19,566:INFO: Batch: 25/31	Total Loss -205.7224 (-212.4607)
2022-11-03 02:01:20,059:INFO: Batch: 26/31	Total Loss -235.8485 (-213.3673)
2022-11-03 02:01:20,550:INFO: Batch: 27/31	Total Loss -204.6069 (-213.0728)
2022-11-03 02:01:21,051:INFO: Batch: 28/31	Total Loss 13.2737 (-204.8007)
2022-11-03 02:01:21,546:INFO: Batch: 29/31	Total Loss -207.3713 (-204.8810)
2022-11-03 02:01:21,932:INFO: Batch: 30/31	Total Loss -106.3772 (-204.1621)
2022-11-03 02:01:22,080:INFO: - Computing ADE (validation o)
2022-11-03 02:01:22,790:INFO: 		 ADE on eth                       dataset:	 0.9301609992980957
2022-11-03 02:01:22,790:INFO: Average validation o:	ADE  0.9302	FDE  1.9658
2022-11-03 02:01:22,790:INFO: - Computing ADE (validation)
2022-11-03 02:01:23,100:INFO: 		 ADE on hotel                     dataset:	 0.3918319046497345
2022-11-03 02:01:23,470:INFO: 		 ADE on univ                      dataset:	 0.5414146780967712
2022-11-03 02:01:23,751:INFO: 		 ADE on zara1                     dataset:	 0.4047981798648834
2022-11-03 02:01:24,214:INFO: 		 ADE on zara2                     dataset:	 0.40884530544281006
2022-11-03 02:01:24,215:INFO: Average validation:	ADE  0.4767	FDE  1.0115
2022-11-03 02:01:24,215:INFO: - Computing ADE (training)
2022-11-03 02:01:24,782:INFO: 		 ADE on hotel                     dataset:	 0.3970247209072113
2022-11-03 02:01:25,851:INFO: 		 ADE on univ                      dataset:	 0.534126877784729
2022-11-03 02:01:26,649:INFO: 		 ADE on zara1                     dataset:	 0.4429372251033783
2022-11-03 02:01:27,843:INFO: 		 ADE on zara2                     dataset:	 0.3934769630432129
2022-11-03 02:01:27,844:INFO: Average training:	ADE  0.4963	FDE  1.0567
2022-11-03 02:01:27,855:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_635.pth.tar
2022-11-03 02:01:27,855:INFO: 
===> EPOCH: 636 (P4)
2022-11-03 02:01:27,855:INFO: - Computing loss (training)
2022-11-03 02:01:28,967:INFO: Batch:  0/31	Total Loss -197.8650 (-197.8650)
2022-11-03 02:01:29,461:INFO: Batch:  1/31	Total Loss -103.3914 (-153.4979)
2022-11-03 02:01:29,955:INFO: Batch:  2/31	Total Loss -125.3913 (-145.2054)
2022-11-03 02:01:30,451:INFO: Batch:  3/31	Total Loss -94.0310 (-132.3305)
2022-11-03 02:01:30,943:INFO: Batch:  4/31	Total Loss -91.9447 (-124.1664)
2022-11-03 02:01:31,437:INFO: Batch:  5/31	Total Loss -147.2510 (-127.9472)
2022-11-03 02:01:31,927:INFO: Batch:  6/31	Total Loss -138.1699 (-129.4165)
2022-11-03 02:01:32,415:INFO: Batch:  7/31	Total Loss -145.4477 (-131.6000)
2022-11-03 02:01:32,908:INFO: Batch:  8/31	Total Loss -146.5351 (-133.2997)
2022-11-03 02:01:33,397:INFO: Batch:  9/31	Total Loss -161.5967 (-136.1784)
2022-11-03 02:01:33,887:INFO: Batch: 10/31	Total Loss -128.4511 (-135.5381)
2022-11-03 02:01:34,376:INFO: Batch: 11/31	Total Loss -181.8381 (-139.7714)
2022-11-03 02:01:34,871:INFO: Batch: 12/31	Total Loss -149.5600 (-140.5571)
2022-11-03 02:01:35,362:INFO: Batch: 13/31	Total Loss -168.7472 (-142.4314)
2022-11-03 02:01:35,855:INFO: Batch: 14/31	Total Loss -132.6516 (-141.8003)
2022-11-03 02:01:36,349:INFO: Batch: 15/31	Total Loss -155.0433 (-142.6328)
2022-11-03 02:01:36,842:INFO: Batch: 16/31	Total Loss -156.0315 (-143.3460)
2022-11-03 02:01:37,333:INFO: Batch: 17/31	Total Loss -168.5498 (-144.6035)
2022-11-03 02:01:37,829:INFO: Batch: 18/31	Total Loss -160.8344 (-145.3765)
2022-11-03 02:01:38,320:INFO: Batch: 19/31	Total Loss -149.8076 (-145.5897)
2022-11-03 02:01:38,813:INFO: Batch: 20/31	Total Loss 3.6829 (-138.5178)
2022-11-03 02:01:39,305:INFO: Batch: 21/31	Total Loss -156.8878 (-139.3070)
2022-11-03 02:01:39,798:INFO: Batch: 22/31	Total Loss -147.0580 (-139.6303)
2022-11-03 02:01:40,289:INFO: Batch: 23/31	Total Loss -175.8018 (-141.1261)
2022-11-03 02:01:40,782:INFO: Batch: 24/31	Total Loss -118.8602 (-140.2015)
2022-11-03 02:01:41,274:INFO: Batch: 25/31	Total Loss -154.5329 (-140.7940)
2022-11-03 02:01:41,767:INFO: Batch: 26/31	Total Loss -136.9189 (-140.6505)
2022-11-03 02:01:42,261:INFO: Batch: 27/31	Total Loss -131.4717 (-140.3132)
2022-11-03 02:01:42,753:INFO: Batch: 28/31	Total Loss -107.0609 (-139.1868)
2022-11-03 02:01:43,245:INFO: Batch: 29/31	Total Loss -156.3182 (-139.8341)
2022-11-03 02:01:43,635:INFO: Batch: 30/31	Total Loss -90.2938 (-139.4308)
2022-11-03 02:01:43,789:INFO: - Computing ADE (validation o)
2022-11-03 02:01:44,500:INFO: 		 ADE on eth                       dataset:	 0.9394394159317017
2022-11-03 02:01:44,500:INFO: Average validation o:	ADE  0.9394	FDE  2.0129
2022-11-03 02:01:44,501:INFO: - Computing ADE (validation)
2022-11-03 02:01:44,795:INFO: 		 ADE on hotel                     dataset:	 0.3864823579788208
2022-11-03 02:01:45,156:INFO: 		 ADE on univ                      dataset:	 0.5390608310699463
2022-11-03 02:01:45,458:INFO: 		 ADE on zara1                     dataset:	 0.38583680987358093
2022-11-03 02:01:45,930:INFO: 		 ADE on zara2                     dataset:	 0.41370704770088196
2022-11-03 02:01:45,930:INFO: Average validation:	ADE  0.4758	FDE  1.0098
2022-11-03 02:01:45,931:INFO: - Computing ADE (training)
2022-11-03 02:01:46,508:INFO: 		 ADE on hotel                     dataset:	 0.390244722366333
2022-11-03 02:01:47,572:INFO: 		 ADE on univ                      dataset:	 0.5385286211967468
2022-11-03 02:01:48,317:INFO: 		 ADE on zara1                     dataset:	 0.4390089511871338
2022-11-03 02:01:49,552:INFO: 		 ADE on zara2                     dataset:	 0.40091195702552795
2022-11-03 02:01:49,552:INFO: Average training:	ADE  0.5005	FDE  1.0676
2022-11-03 02:01:49,563:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_636.pth.tar
2022-11-03 02:01:49,563:INFO: 
===> EPOCH: 637 (P4)
2022-11-03 02:01:49,563:INFO: - Computing loss (training)
2022-11-03 02:01:50,656:INFO: Batch:  0/31	Total Loss -95.0227 (-95.0227)
2022-11-03 02:01:51,153:INFO: Batch:  1/31	Total Loss -94.4252 (-94.7286)
2022-11-03 02:01:51,719:INFO: Batch:  2/31	Total Loss -127.4089 (-106.0515)
2022-11-03 02:01:52,215:INFO: Batch:  3/31	Total Loss -116.8749 (-108.6359)
2022-11-03 02:01:52,706:INFO: Batch:  4/31	Total Loss -119.8739 (-110.9776)
2022-11-03 02:01:53,197:INFO: Batch:  5/31	Total Loss -153.4383 (-118.9475)
2022-11-03 02:01:53,689:INFO: Batch:  6/31	Total Loss -117.2007 (-118.7041)
2022-11-03 02:01:54,180:INFO: Batch:  7/31	Total Loss -132.5960 (-120.2889)
2022-11-03 02:01:54,672:INFO: Batch:  8/31	Total Loss -131.7817 (-121.4729)
2022-11-03 02:01:55,162:INFO: Batch:  9/31	Total Loss -141.3400 (-123.4855)
2022-11-03 02:01:55,654:INFO: Batch: 10/31	Total Loss -150.0092 (-126.1256)
2022-11-03 02:01:56,146:INFO: Batch: 11/31	Total Loss -139.7700 (-127.2791)
2022-11-03 02:01:56,638:INFO: Batch: 12/31	Total Loss -132.6579 (-127.7209)
2022-11-03 02:01:57,132:INFO: Batch: 13/31	Total Loss -87.3071 (-125.0163)
2022-11-03 02:01:57,626:INFO: Batch: 14/31	Total Loss -172.1827 (-128.4096)
2022-11-03 02:01:58,119:INFO: Batch: 15/31	Total Loss -176.9723 (-131.6020)
2022-11-03 02:01:58,612:INFO: Batch: 16/31	Total Loss -148.6812 (-132.6738)
2022-11-03 02:01:59,110:INFO: Batch: 17/31	Total Loss -168.4340 (-134.8140)
2022-11-03 02:01:59,603:INFO: Batch: 18/31	Total Loss -165.3588 (-136.3794)
2022-11-03 02:02:00,107:INFO: Batch: 19/31	Total Loss -145.6457 (-136.8662)
2022-11-03 02:02:00,603:INFO: Batch: 20/31	Total Loss -172.7152 (-138.5661)
2022-11-03 02:02:01,097:INFO: Batch: 21/31	Total Loss -134.2347 (-138.3904)
2022-11-03 02:02:01,608:INFO: Batch: 22/31	Total Loss -162.7939 (-139.4741)
2022-11-03 02:02:02,100:INFO: Batch: 23/31	Total Loss -156.5953 (-140.2271)
2022-11-03 02:02:02,592:INFO: Batch: 24/31	Total Loss -173.8103 (-141.5751)
2022-11-03 02:02:03,086:INFO: Batch: 25/31	Total Loss -169.9859 (-142.6329)
2022-11-03 02:02:03,578:INFO: Batch: 26/31	Total Loss -148.4876 (-142.8383)
2022-11-03 02:02:04,072:INFO: Batch: 27/31	Total Loss -168.7883 (-143.7885)
2022-11-03 02:02:04,567:INFO: Batch: 28/31	Total Loss -174.6715 (-144.9004)
2022-11-03 02:02:05,059:INFO: Batch: 29/31	Total Loss -188.9142 (-146.5005)
2022-11-03 02:02:05,449:INFO: Batch: 30/31	Total Loss -115.8150 (-146.2487)
2022-11-03 02:02:05,601:INFO: - Computing ADE (validation o)
2022-11-03 02:02:06,277:INFO: 		 ADE on eth                       dataset:	 0.9210659265518188
2022-11-03 02:02:06,278:INFO: Average validation o:	ADE  0.9211	FDE  1.9587
2022-11-03 02:02:06,278:INFO: - Computing ADE (validation)
2022-11-03 02:02:06,590:INFO: 		 ADE on hotel                     dataset:	 0.3747725188732147
2022-11-03 02:02:06,952:INFO: 		 ADE on univ                      dataset:	 0.5294229388237
2022-11-03 02:02:07,237:INFO: 		 ADE on zara1                     dataset:	 0.40099141001701355
2022-11-03 02:02:07,714:INFO: 		 ADE on zara2                     dataset:	 0.39842650294303894
2022-11-03 02:02:07,714:INFO: Average validation:	ADE  0.4654	FDE  0.9909
2022-11-03 02:02:07,715:INFO: - Computing ADE (training)
2022-11-03 02:02:08,252:INFO: 		 ADE on hotel                     dataset:	 0.38464003801345825
2022-11-03 02:02:09,335:INFO: 		 ADE on univ                      dataset:	 0.5281595587730408
2022-11-03 02:02:10,072:INFO: 		 ADE on zara1                     dataset:	 0.4303399920463562
2022-11-03 02:02:11,339:INFO: 		 ADE on zara2                     dataset:	 0.3840787410736084
2022-11-03 02:02:11,339:INFO: Average training:	ADE  0.4890	FDE  1.0449
2022-11-03 02:02:11,350:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_637.pth.tar
2022-11-03 02:02:11,350:INFO: 
===> EPOCH: 638 (P4)
2022-11-03 02:02:11,350:INFO: - Computing loss (training)
2022-11-03 02:02:12,504:INFO: Batch:  0/31	Total Loss -199.7967 (-199.7967)
2022-11-03 02:02:13,009:INFO: Batch:  1/31	Total Loss -170.9983 (-186.8618)
2022-11-03 02:02:13,513:INFO: Batch:  2/31	Total Loss -170.3925 (-181.4418)
2022-11-03 02:02:14,017:INFO: Batch:  3/31	Total Loss -168.9539 (-178.3214)
2022-11-03 02:02:14,513:INFO: Batch:  4/31	Total Loss -186.5794 (-179.9803)
2022-11-03 02:02:15,011:INFO: Batch:  5/31	Total Loss -117.8680 (-171.3768)
2022-11-03 02:02:15,513:INFO: Batch:  6/31	Total Loss -190.8649 (-174.3949)
2022-11-03 02:02:16,012:INFO: Batch:  7/31	Total Loss -184.4681 (-175.5794)
2022-11-03 02:02:16,510:INFO: Batch:  8/31	Total Loss -209.1708 (-179.6481)
2022-11-03 02:02:17,010:INFO: Batch:  9/31	Total Loss -188.5208 (-180.5907)
2022-11-03 02:02:17,508:INFO: Batch: 10/31	Total Loss -174.7943 (-180.0868)
2022-11-03 02:02:18,007:INFO: Batch: 11/31	Total Loss -192.1926 (-181.0767)
2022-11-03 02:02:18,508:INFO: Batch: 12/31	Total Loss -186.2439 (-181.4886)
2022-11-03 02:02:19,007:INFO: Batch: 13/31	Total Loss -201.4948 (-182.9975)
2022-11-03 02:02:19,509:INFO: Batch: 14/31	Total Loss -202.2341 (-184.1904)
2022-11-03 02:02:20,009:INFO: Batch: 15/31	Total Loss -203.6099 (-185.4033)
2022-11-03 02:02:20,513:INFO: Batch: 16/31	Total Loss -210.7143 (-186.9296)
2022-11-03 02:02:21,020:INFO: Batch: 17/31	Total Loss -159.7551 (-185.3625)
2022-11-03 02:02:21,524:INFO: Batch: 18/31	Total Loss -176.1181 (-184.8794)
2022-11-03 02:02:22,027:INFO: Batch: 19/31	Total Loss -181.0473 (-184.7138)
2022-11-03 02:02:22,530:INFO: Batch: 20/31	Total Loss -160.6273 (-183.7002)
2022-11-03 02:02:23,033:INFO: Batch: 21/31	Total Loss -223.5286 (-185.6862)
2022-11-03 02:02:23,534:INFO: Batch: 22/31	Total Loss -189.9146 (-185.8575)
2022-11-03 02:02:24,035:INFO: Batch: 23/31	Total Loss -222.1820 (-187.4098)
2022-11-03 02:02:24,535:INFO: Batch: 24/31	Total Loss -191.2248 (-187.5449)
2022-11-03 02:02:25,035:INFO: Batch: 25/31	Total Loss -213.2744 (-188.5898)
2022-11-03 02:02:25,535:INFO: Batch: 26/31	Total Loss -216.6761 (-189.7644)
2022-11-03 02:02:26,035:INFO: Batch: 27/31	Total Loss -174.7322 (-189.2267)
2022-11-03 02:02:26,534:INFO: Batch: 28/31	Total Loss -179.0794 (-188.8800)
2022-11-03 02:02:27,036:INFO: Batch: 29/31	Total Loss -185.5002 (-188.7644)
2022-11-03 02:02:27,432:INFO: Batch: 30/31	Total Loss -127.2370 (-188.1169)
2022-11-03 02:02:27,583:INFO: - Computing ADE (validation o)
2022-11-03 02:02:28,279:INFO: 		 ADE on eth                       dataset:	 0.9211417436599731
2022-11-03 02:02:28,279:INFO: Average validation o:	ADE  0.9211	FDE  1.9564
2022-11-03 02:02:28,280:INFO: - Computing ADE (validation)
2022-11-03 02:02:28,596:INFO: 		 ADE on hotel                     dataset:	 0.38840019702911377
2022-11-03 02:02:28,968:INFO: 		 ADE on univ                      dataset:	 0.5317896008491516
2022-11-03 02:02:29,246:INFO: 		 ADE on zara1                     dataset:	 0.4035104811191559
2022-11-03 02:02:29,726:INFO: 		 ADE on zara2                     dataset:	 0.391355037689209
2022-11-03 02:02:29,727:INFO: Average validation:	ADE  0.4650	FDE  0.9942
2022-11-03 02:02:29,727:INFO: - Computing ADE (training)
2022-11-03 02:02:30,334:INFO: 		 ADE on hotel                     dataset:	 0.40507009625434875
2022-11-03 02:02:31,375:INFO: 		 ADE on univ                      dataset:	 0.5250317454338074
2022-11-03 02:02:32,099:INFO: 		 ADE on zara1                     dataset:	 0.4302048683166504
2022-11-03 02:02:33,273:INFO: 		 ADE on zara2                     dataset:	 0.37996619939804077
2022-11-03 02:02:33,273:INFO: Average training:	ADE  0.4865	FDE  1.0426
2022-11-03 02:02:33,285:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_638.pth.tar
2022-11-03 02:02:33,285:INFO: 
===> EPOCH: 639 (P4)
2022-11-03 02:02:33,285:INFO: - Computing loss (training)
2022-11-03 02:02:34,403:INFO: Batch:  0/31	Total Loss -168.3113 (-168.3113)
2022-11-03 02:02:34,908:INFO: Batch:  1/31	Total Loss -220.4187 (-195.4420)
2022-11-03 02:02:35,413:INFO: Batch:  2/31	Total Loss -202.1743 (-197.7819)
2022-11-03 02:02:35,914:INFO: Batch:  3/31	Total Loss -180.5623 (-193.3116)
2022-11-03 02:02:36,415:INFO: Batch:  4/31	Total Loss -206.8438 (-196.0136)
2022-11-03 02:02:36,919:INFO: Batch:  5/31	Total Loss -223.2641 (-200.8591)
2022-11-03 02:02:37,417:INFO: Batch:  6/31	Total Loss -194.1045 (-199.9796)
2022-11-03 02:02:37,919:INFO: Batch:  7/31	Total Loss -214.6994 (-201.8886)
2022-11-03 02:02:38,417:INFO: Batch:  8/31	Total Loss -204.1680 (-202.1385)
2022-11-03 02:02:38,917:INFO: Batch:  9/31	Total Loss -211.4930 (-203.0722)
2022-11-03 02:02:39,416:INFO: Batch: 10/31	Total Loss -194.9617 (-202.3105)
2022-11-03 02:02:39,920:INFO: Batch: 11/31	Total Loss -212.3678 (-203.1662)
2022-11-03 02:02:40,423:INFO: Batch: 12/31	Total Loss -215.5727 (-204.1267)
2022-11-03 02:02:40,928:INFO: Batch: 13/31	Total Loss -203.2299 (-204.0660)
2022-11-03 02:02:41,431:INFO: Batch: 14/31	Total Loss -190.8441 (-203.2183)
2022-11-03 02:02:41,937:INFO: Batch: 15/31	Total Loss -184.7339 (-202.1630)
2022-11-03 02:02:42,440:INFO: Batch: 16/31	Total Loss -206.9789 (-202.4206)
2022-11-03 02:02:42,946:INFO: Batch: 17/31	Total Loss -207.8181 (-202.7011)
2022-11-03 02:02:43,448:INFO: Batch: 18/31	Total Loss -219.0336 (-203.5775)
2022-11-03 02:02:44,030:INFO: Batch: 19/31	Total Loss -212.5162 (-204.0244)
2022-11-03 02:02:44,534:INFO: Batch: 20/31	Total Loss -218.8558 (-204.7726)
2022-11-03 02:02:45,038:INFO: Batch: 21/31	Total Loss -182.5978 (-203.7508)
2022-11-03 02:02:45,536:INFO: Batch: 22/31	Total Loss -184.4803 (-202.9248)
2022-11-03 02:02:46,033:INFO: Batch: 23/31	Total Loss -227.1945 (-203.9520)
2022-11-03 02:02:46,529:INFO: Batch: 24/31	Total Loss -184.1656 (-203.1022)
2022-11-03 02:02:47,027:INFO: Batch: 25/31	Total Loss -201.6885 (-203.0440)
2022-11-03 02:02:47,523:INFO: Batch: 26/31	Total Loss -203.1660 (-203.0485)
2022-11-03 02:02:48,022:INFO: Batch: 27/31	Total Loss -241.7290 (-204.4797)
2022-11-03 02:02:48,519:INFO: Batch: 28/31	Total Loss -195.7880 (-204.2359)
2022-11-03 02:02:49,017:INFO: Batch: 29/31	Total Loss -219.7608 (-204.7865)
2022-11-03 02:02:49,409:INFO: Batch: 30/31	Total Loss -133.0318 (-204.1158)
2022-11-03 02:02:49,568:INFO: - Computing ADE (validation o)
2022-11-03 02:02:50,315:INFO: 		 ADE on eth                       dataset:	 0.9173713326454163
2022-11-03 02:02:50,315:INFO: Average validation o:	ADE  0.9174	FDE  1.9448
2022-11-03 02:02:50,316:INFO: - Computing ADE (validation)
2022-11-03 02:02:50,609:INFO: 		 ADE on hotel                     dataset:	 0.3787843585014343
2022-11-03 02:02:50,993:INFO: 		 ADE on univ                      dataset:	 0.5322471261024475
2022-11-03 02:02:51,285:INFO: 		 ADE on zara1                     dataset:	 0.4026340842247009
2022-11-03 02:02:51,760:INFO: 		 ADE on zara2                     dataset:	 0.39046159386634827
2022-11-03 02:02:51,760:INFO: Average validation:	ADE  0.4643	FDE  0.9993
2022-11-03 02:02:51,761:INFO: - Computing ADE (training)
2022-11-03 02:02:52,364:INFO: 		 ADE on hotel                     dataset:	 0.3843896985054016
2022-11-03 02:02:53,464:INFO: 		 ADE on univ                      dataset:	 0.5236444473266602
2022-11-03 02:02:54,263:INFO: 		 ADE on zara1                     dataset:	 0.4336753189563751
2022-11-03 02:02:55,442:INFO: 		 ADE on zara2                     dataset:	 0.3796760141849518
2022-11-03 02:02:55,442:INFO: Average training:	ADE  0.4852	FDE  1.0453
2022-11-03 02:02:55,454:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_639.pth.tar
2022-11-03 02:02:55,454:INFO: 
===> EPOCH: 640 (P4)
2022-11-03 02:02:55,454:INFO: - Computing loss (training)
2022-11-03 02:02:56,572:INFO: Batch:  0/31	Total Loss -184.8592 (-184.8592)
2022-11-03 02:02:57,076:INFO: Batch:  1/31	Total Loss -229.5329 (-209.4082)
2022-11-03 02:02:57,585:INFO: Batch:  2/31	Total Loss -209.3843 (-209.4004)
2022-11-03 02:02:58,090:INFO: Batch:  3/31	Total Loss -172.3480 (-200.9229)
2022-11-03 02:02:58,588:INFO: Batch:  4/31	Total Loss -196.6152 (-200.0711)
2022-11-03 02:02:59,089:INFO: Batch:  5/31	Total Loss -210.3753 (-201.9439)
2022-11-03 02:02:59,589:INFO: Batch:  6/31	Total Loss -222.6440 (-205.1147)
2022-11-03 02:03:00,091:INFO: Batch:  7/31	Total Loss -223.9491 (-207.4781)
2022-11-03 02:03:00,593:INFO: Batch:  8/31	Total Loss -194.3411 (-206.0804)
2022-11-03 02:03:01,100:INFO: Batch:  9/31	Total Loss -209.9920 (-206.4810)
2022-11-03 02:03:01,607:INFO: Batch: 10/31	Total Loss -194.0665 (-205.3194)
2022-11-03 02:03:02,107:INFO: Batch: 11/31	Total Loss -196.8229 (-204.6634)
2022-11-03 02:03:02,611:INFO: Batch: 12/31	Total Loss -220.1139 (-205.9442)
2022-11-03 02:03:03,116:INFO: Batch: 13/31	Total Loss -212.7265 (-206.3955)
2022-11-03 02:03:03,616:INFO: Batch: 14/31	Total Loss -220.2044 (-207.3829)
2022-11-03 02:03:04,109:INFO: Batch: 15/31	Total Loss -219.1848 (-208.1726)
2022-11-03 02:03:04,603:INFO: Batch: 16/31	Total Loss -212.8783 (-208.4484)
2022-11-03 02:03:05,099:INFO: Batch: 17/31	Total Loss -211.1007 (-208.5899)
2022-11-03 02:03:05,594:INFO: Batch: 18/31	Total Loss -198.6475 (-208.1365)
2022-11-03 02:03:06,089:INFO: Batch: 19/31	Total Loss -212.5918 (-208.3616)
2022-11-03 02:03:06,585:INFO: Batch: 20/31	Total Loss -233.1599 (-209.6179)
2022-11-03 02:03:07,080:INFO: Batch: 21/31	Total Loss -224.4329 (-210.3697)
2022-11-03 02:03:07,575:INFO: Batch: 22/31	Total Loss -239.6818 (-211.7988)
2022-11-03 02:03:08,075:INFO: Batch: 23/31	Total Loss -201.8174 (-211.4076)
2022-11-03 02:03:08,573:INFO: Batch: 24/31	Total Loss -239.5210 (-212.5462)
2022-11-03 02:03:09,072:INFO: Batch: 25/31	Total Loss -235.3213 (-213.5054)
2022-11-03 02:03:09,569:INFO: Batch: 26/31	Total Loss -219.4569 (-213.7324)
2022-11-03 02:03:10,064:INFO: Batch: 27/31	Total Loss -216.4501 (-213.8214)
2022-11-03 02:03:10,560:INFO: Batch: 28/31	Total Loss -216.4947 (-213.9154)
2022-11-03 02:03:11,057:INFO: Batch: 29/31	Total Loss -215.2831 (-213.9581)
2022-11-03 02:03:11,448:INFO: Batch: 30/31	Total Loss -142.8356 (-213.2263)
2022-11-03 02:03:11,597:INFO: - Computing ADE (validation o)
2022-11-03 02:03:12,306:INFO: 		 ADE on eth                       dataset:	 0.9216651916503906
2022-11-03 02:03:12,306:INFO: Average validation o:	ADE  0.9217	FDE  1.9620
2022-11-03 02:03:12,307:INFO: - Computing ADE (validation)
2022-11-03 02:03:12,586:INFO: 		 ADE on hotel                     dataset:	 0.3660143315792084
2022-11-03 02:03:12,954:INFO: 		 ADE on univ                      dataset:	 0.5221147537231445
2022-11-03 02:03:13,246:INFO: 		 ADE on zara1                     dataset:	 0.3881238102912903
2022-11-03 02:03:13,731:INFO: 		 ADE on zara2                     dataset:	 0.3858090341091156
2022-11-03 02:03:13,731:INFO: Average validation:	ADE  0.4558	FDE  0.9794
2022-11-03 02:03:13,732:INFO: - Computing ADE (training)
2022-11-03 02:03:14,310:INFO: 		 ADE on hotel                     dataset:	 0.3700573742389679
2022-11-03 02:03:15,388:INFO: 		 ADE on univ                      dataset:	 0.5201526880264282
2022-11-03 02:03:16,133:INFO: 		 ADE on zara1                     dataset:	 0.4221332371234894
2022-11-03 02:03:17,298:INFO: 		 ADE on zara2                     dataset:	 0.37297865748405457
2022-11-03 02:03:17,298:INFO: Average training:	ADE  0.4802	FDE  1.0350
2022-11-03 02:03:17,310:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_640.pth.tar
2022-11-03 02:03:17,310:INFO: 
===> EPOCH: 641 (P4)
2022-11-03 02:03:17,311:INFO: - Computing loss (training)
2022-11-03 02:03:18,426:INFO: Batch:  0/31	Total Loss -223.5048 (-223.5048)
2022-11-03 02:03:18,925:INFO: Batch:  1/31	Total Loss -217.0345 (-220.3029)
2022-11-03 02:03:19,424:INFO: Batch:  2/31	Total Loss -172.8713 (-205.3043)
2022-11-03 02:03:19,923:INFO: Batch:  3/31	Total Loss -219.1578 (-208.6968)
2022-11-03 02:03:20,423:INFO: Batch:  4/31	Total Loss -234.7213 (-214.1325)
2022-11-03 02:03:20,926:INFO: Batch:  5/31	Total Loss -217.6610 (-214.7129)
2022-11-03 02:03:21,424:INFO: Batch:  6/31	Total Loss -222.4763 (-215.8486)
2022-11-03 02:03:21,923:INFO: Batch:  7/31	Total Loss -223.1028 (-216.8252)
2022-11-03 02:03:22,420:INFO: Batch:  8/31	Total Loss -217.8639 (-216.9470)
2022-11-03 02:03:22,921:INFO: Batch:  9/31	Total Loss -186.6533 (-214.2057)
2022-11-03 02:03:23,419:INFO: Batch: 10/31	Total Loss -226.3070 (-215.4696)
2022-11-03 02:03:23,918:INFO: Batch: 11/31	Total Loss -209.1207 (-214.9534)
2022-11-03 02:03:24,419:INFO: Batch: 12/31	Total Loss -220.3944 (-215.3681)
2022-11-03 02:03:24,922:INFO: Batch: 13/31	Total Loss -216.5667 (-215.4483)
2022-11-03 02:03:25,423:INFO: Batch: 14/31	Total Loss -171.6952 (-212.7272)
2022-11-03 02:03:25,924:INFO: Batch: 15/31	Total Loss -218.9669 (-213.0967)
2022-11-03 02:03:26,426:INFO: Batch: 16/31	Total Loss -226.5764 (-213.9591)
2022-11-03 02:03:26,927:INFO: Batch: 17/31	Total Loss -251.2655 (-216.1620)
2022-11-03 02:03:27,428:INFO: Batch: 18/31	Total Loss -227.9263 (-216.7501)
2022-11-03 02:03:27,929:INFO: Batch: 19/31	Total Loss -230.3018 (-217.5004)
2022-11-03 02:03:28,429:INFO: Batch: 20/31	Total Loss -207.4830 (-216.9893)
2022-11-03 02:03:28,928:INFO: Batch: 21/31	Total Loss -212.7496 (-216.7985)
2022-11-03 02:03:29,426:INFO: Batch: 22/31	Total Loss -213.7492 (-216.6637)
2022-11-03 02:03:29,936:INFO: Batch: 23/31	Total Loss -235.7469 (-217.5168)
2022-11-03 02:03:30,447:INFO: Batch: 24/31	Total Loss -238.6263 (-218.4702)
2022-11-03 02:03:30,956:INFO: Batch: 25/31	Total Loss -227.1965 (-218.8167)
2022-11-03 02:03:31,463:INFO: Batch: 26/31	Total Loss -194.1939 (-217.9488)
2022-11-03 02:03:31,970:INFO: Batch: 27/31	Total Loss -226.9861 (-218.2692)
2022-11-03 02:03:32,477:INFO: Batch: 28/31	Total Loss -238.8902 (-219.0038)
2022-11-03 02:03:32,986:INFO: Batch: 29/31	Total Loss -204.4815 (-218.5347)
2022-11-03 02:03:33,385:INFO: Batch: 30/31	Total Loss -120.7503 (-217.6469)
2022-11-03 02:03:33,532:INFO: - Computing ADE (validation o)
2022-11-03 02:03:34,246:INFO: 		 ADE on eth                       dataset:	 0.9273353815078735
2022-11-03 02:03:34,246:INFO: Average validation o:	ADE  0.9273	FDE  1.9916
2022-11-03 02:03:34,247:INFO: - Computing ADE (validation)
2022-11-03 02:03:34,550:INFO: 		 ADE on hotel                     dataset:	 0.376708447933197
2022-11-03 02:03:34,922:INFO: 		 ADE on univ                      dataset:	 0.5304708480834961
2022-11-03 02:03:35,198:INFO: 		 ADE on zara1                     dataset:	 0.3844205439090729
2022-11-03 02:03:35,667:INFO: 		 ADE on zara2                     dataset:	 0.3900395631790161
2022-11-03 02:03:35,667:INFO: Average validation:	ADE  0.4620	FDE  0.9898
2022-11-03 02:03:35,668:INFO: - Computing ADE (training)
2022-11-03 02:03:36,242:INFO: 		 ADE on hotel                     dataset:	 0.38242754340171814
2022-11-03 02:03:37,291:INFO: 		 ADE on univ                      dataset:	 0.5256223082542419
2022-11-03 02:03:38,026:INFO: 		 ADE on zara1                     dataset:	 0.42483988404273987
2022-11-03 02:03:39,237:INFO: 		 ADE on zara2                     dataset:	 0.3730398118495941
2022-11-03 02:03:39,238:INFO: Average training:	ADE  0.4846	FDE  1.0405
2022-11-03 02:03:39,249:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_641.pth.tar
2022-11-03 02:03:39,249:INFO: 
===> EPOCH: 642 (P4)
2022-11-03 02:03:39,249:INFO: - Computing loss (training)
2022-11-03 02:03:40,390:INFO: Batch:  0/31	Total Loss -243.6766 (-243.6766)
2022-11-03 02:03:40,907:INFO: Batch:  1/31	Total Loss -223.3272 (-233.7721)
2022-11-03 02:03:41,418:INFO: Batch:  2/31	Total Loss -208.0046 (-225.8523)
2022-11-03 02:03:41,923:INFO: Batch:  3/31	Total Loss -192.6249 (-218.7078)
2022-11-03 02:03:42,428:INFO: Batch:  4/31	Total Loss -190.0193 (-212.7706)
2022-11-03 02:03:42,935:INFO: Batch:  5/31	Total Loss -188.8624 (-209.1219)
2022-11-03 02:03:43,440:INFO: Batch:  6/31	Total Loss -224.7542 (-211.2661)
2022-11-03 02:03:43,946:INFO: Batch:  7/31	Total Loss -243.8136 (-215.7810)
2022-11-03 02:03:44,527:INFO: Batch:  8/31	Total Loss -204.7738 (-214.5709)
2022-11-03 02:03:45,030:INFO: Batch:  9/31	Total Loss -221.2176 (-215.2355)
2022-11-03 02:03:45,534:INFO: Batch: 10/31	Total Loss -241.0825 (-217.7543)
2022-11-03 02:03:46,039:INFO: Batch: 11/31	Total Loss -216.0372 (-217.6112)
2022-11-03 02:03:46,547:INFO: Batch: 12/31	Total Loss -192.4953 (-215.5480)
2022-11-03 02:03:47,054:INFO: Batch: 13/31	Total Loss -194.4395 (-214.0061)
2022-11-03 02:03:47,562:INFO: Batch: 14/31	Total Loss -212.1690 (-213.8772)
2022-11-03 02:03:48,070:INFO: Batch: 15/31	Total Loss -214.6333 (-213.9235)
2022-11-03 02:03:48,580:INFO: Batch: 16/31	Total Loss -231.6586 (-215.0157)
2022-11-03 02:03:49,090:INFO: Batch: 17/31	Total Loss -200.7634 (-214.2667)
2022-11-03 02:03:49,597:INFO: Batch: 18/31	Total Loss -200.5048 (-213.5327)
2022-11-03 02:03:50,103:INFO: Batch: 19/31	Total Loss -218.8986 (-213.7989)
2022-11-03 02:03:50,611:INFO: Batch: 20/31	Total Loss -234.1130 (-214.8348)
2022-11-03 02:03:51,118:INFO: Batch: 21/31	Total Loss -212.8071 (-214.7419)
2022-11-03 02:03:51,625:INFO: Batch: 22/31	Total Loss -217.0117 (-214.8486)
2022-11-03 02:03:52,137:INFO: Batch: 23/31	Total Loss -206.8357 (-214.5210)
2022-11-03 02:03:52,646:INFO: Batch: 24/31	Total Loss -228.4534 (-215.1425)
2022-11-03 02:03:53,162:INFO: Batch: 25/31	Total Loss -217.3710 (-215.2321)
2022-11-03 02:03:53,670:INFO: Batch: 26/31	Total Loss -223.3963 (-215.5438)
2022-11-03 02:03:54,179:INFO: Batch: 27/31	Total Loss -210.5826 (-215.3645)
2022-11-03 02:03:54,678:INFO: Batch: 28/31	Total Loss -216.0579 (-215.3888)
2022-11-03 02:03:55,178:INFO: Batch: 29/31	Total Loss -193.6902 (-214.7354)
2022-11-03 02:03:55,575:INFO: Batch: 30/31	Total Loss -144.7629 (-213.9942)
2022-11-03 02:03:55,725:INFO: - Computing ADE (validation o)
2022-11-03 02:03:56,424:INFO: 		 ADE on eth                       dataset:	 0.9340108036994934
2022-11-03 02:03:56,424:INFO: Average validation o:	ADE  0.9340	FDE  2.0238
2022-11-03 02:03:56,425:INFO: - Computing ADE (validation)
2022-11-03 02:03:56,726:INFO: 		 ADE on hotel                     dataset:	 0.3900035321712494
2022-11-03 02:03:57,094:INFO: 		 ADE on univ                      dataset:	 0.5387869477272034
2022-11-03 02:03:57,379:INFO: 		 ADE on zara1                     dataset:	 0.4023827910423279
2022-11-03 02:03:57,862:INFO: 		 ADE on zara2                     dataset:	 0.39923426508903503
2022-11-03 02:03:57,862:INFO: Average validation:	ADE  0.4715	FDE  1.0162
2022-11-03 02:03:57,863:INFO: - Computing ADE (training)
2022-11-03 02:03:58,432:INFO: 		 ADE on hotel                     dataset:	 0.39205941557884216
2022-11-03 02:03:59,520:INFO: 		 ADE on univ                      dataset:	 0.5327563285827637
2022-11-03 02:04:00,294:INFO: 		 ADE on zara1                     dataset:	 0.4241291284561157
2022-11-03 02:04:01,484:INFO: 		 ADE on zara2                     dataset:	 0.3797292709350586
2022-11-03 02:04:01,484:INFO: Average training:	ADE  0.4912	FDE  1.0585
2022-11-03 02:04:01,497:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_642.pth.tar
2022-11-03 02:04:01,497:INFO: 
===> EPOCH: 643 (P4)
2022-11-03 02:04:01,497:INFO: - Computing loss (training)
2022-11-03 02:04:02,586:INFO: Batch:  0/31	Total Loss -170.7140 (-170.7140)
2022-11-03 02:04:03,079:INFO: Batch:  1/31	Total Loss -243.1580 (-209.4253)
2022-11-03 02:04:03,573:INFO: Batch:  2/31	Total Loss -211.4027 (-210.0901)
2022-11-03 02:04:04,063:INFO: Batch:  3/31	Total Loss -126.9281 (-191.5646)
2022-11-03 02:04:04,556:INFO: Batch:  4/31	Total Loss -209.0475 (-195.0870)
2022-11-03 02:04:05,048:INFO: Batch:  5/31	Total Loss -180.3639 (-192.6790)
2022-11-03 02:04:05,538:INFO: Batch:  6/31	Total Loss -219.4874 (-196.4710)
2022-11-03 02:04:06,025:INFO: Batch:  7/31	Total Loss -243.7115 (-202.7271)
2022-11-03 02:04:06,515:INFO: Batch:  8/31	Total Loss -233.2185 (-206.1308)
2022-11-03 02:04:07,005:INFO: Batch:  9/31	Total Loss -233.1742 (-208.8166)
2022-11-03 02:04:07,494:INFO: Batch: 10/31	Total Loss -215.3576 (-209.4340)
2022-11-03 02:04:07,987:INFO: Batch: 11/31	Total Loss -216.5177 (-210.0141)
2022-11-03 02:04:08,480:INFO: Batch: 12/31	Total Loss -222.5516 (-211.0139)
2022-11-03 02:04:08,971:INFO: Batch: 13/31	Total Loss -208.8035 (-210.8632)
2022-11-03 02:04:09,463:INFO: Batch: 14/31	Total Loss -215.3738 (-211.1540)
2022-11-03 02:04:09,955:INFO: Batch: 15/31	Total Loss -216.7056 (-211.4650)
2022-11-03 02:04:10,448:INFO: Batch: 16/31	Total Loss -231.0420 (-212.5116)
2022-11-03 02:04:10,943:INFO: Batch: 17/31	Total Loss -192.5863 (-211.3776)
2022-11-03 02:04:11,435:INFO: Batch: 18/31	Total Loss -234.4593 (-212.7457)
2022-11-03 02:04:11,930:INFO: Batch: 19/31	Total Loss -236.5151 (-213.8933)
2022-11-03 02:04:12,421:INFO: Batch: 20/31	Total Loss -207.1635 (-213.5676)
2022-11-03 02:04:12,913:INFO: Batch: 21/31	Total Loss -241.4102 (-214.8763)
2022-11-03 02:04:13,403:INFO: Batch: 22/31	Total Loss -226.3923 (-215.3825)
2022-11-03 02:04:13,897:INFO: Batch: 23/31	Total Loss -275.1834 (-218.3546)
2022-11-03 02:04:14,388:INFO: Batch: 24/31	Total Loss -234.7969 (-218.9740)
2022-11-03 02:04:14,882:INFO: Batch: 25/31	Total Loss -236.3786 (-219.6209)
2022-11-03 02:04:15,373:INFO: Batch: 26/31	Total Loss -251.6627 (-220.9253)
2022-11-03 02:04:15,865:INFO: Batch: 27/31	Total Loss -214.0321 (-220.6969)
2022-11-03 02:04:16,357:INFO: Batch: 28/31	Total Loss -254.2360 (-222.0168)
2022-11-03 02:04:16,850:INFO: Batch: 29/31	Total Loss -228.0555 (-222.2109)
2022-11-03 02:04:17,236:INFO: Batch: 30/31	Total Loss -134.9042 (-221.5445)
2022-11-03 02:04:17,390:INFO: - Computing ADE (validation o)
2022-11-03 02:04:18,084:INFO: 		 ADE on eth                       dataset:	 0.9135478734970093
2022-11-03 02:04:18,084:INFO: Average validation o:	ADE  0.9135	FDE  1.9373
2022-11-03 02:04:18,085:INFO: - Computing ADE (validation)
2022-11-03 02:04:18,380:INFO: 		 ADE on hotel                     dataset:	 0.3734177052974701
2022-11-03 02:04:18,753:INFO: 		 ADE on univ                      dataset:	 0.5336694121360779
2022-11-03 02:04:19,039:INFO: 		 ADE on zara1                     dataset:	 0.4121590256690979
2022-11-03 02:04:19,527:INFO: 		 ADE on zara2                     dataset:	 0.39542651176452637
2022-11-03 02:04:19,528:INFO: Average validation:	ADE  0.4671	FDE  1.0065
2022-11-03 02:04:19,528:INFO: - Computing ADE (training)
2022-11-03 02:04:20,102:INFO: 		 ADE on hotel                     dataset:	 0.3842213451862335
2022-11-03 02:04:21,177:INFO: 		 ADE on univ                      dataset:	 0.5256498456001282
2022-11-03 02:04:21,928:INFO: 		 ADE on zara1                     dataset:	 0.43496087193489075
2022-11-03 02:04:23,144:INFO: 		 ADE on zara2                     dataset:	 0.3838692903518677
2022-11-03 02:04:23,144:INFO: Average training:	ADE  0.4875	FDE  1.0504
2022-11-03 02:04:23,155:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_643.pth.tar
2022-11-03 02:04:23,156:INFO: 
===> EPOCH: 644 (P4)
2022-11-03 02:04:23,156:INFO: - Computing loss (training)
2022-11-03 02:04:24,282:INFO: Batch:  0/31	Total Loss -225.0851 (-225.0851)
2022-11-03 02:04:24,776:INFO: Batch:  1/31	Total Loss -248.4633 (-236.5172)
2022-11-03 02:04:25,272:INFO: Batch:  2/31	Total Loss -232.9009 (-235.2832)
2022-11-03 02:04:25,769:INFO: Batch:  3/31	Total Loss -226.8437 (-233.1081)
2022-11-03 02:04:26,258:INFO: Batch:  4/31	Total Loss -231.4227 (-232.7569)
2022-11-03 02:04:26,750:INFO: Batch:  5/31	Total Loss -255.9388 (-236.9599)
2022-11-03 02:04:27,243:INFO: Batch:  6/31	Total Loss -207.5616 (-232.7926)
2022-11-03 02:04:27,733:INFO: Batch:  7/31	Total Loss -240.6193 (-233.7176)
2022-11-03 02:04:28,221:INFO: Batch:  8/31	Total Loss -243.2579 (-234.8076)
2022-11-03 02:04:28,714:INFO: Batch:  9/31	Total Loss -216.1579 (-232.9693)
2022-11-03 02:04:29,205:INFO: Batch: 10/31	Total Loss -248.0289 (-234.3141)
2022-11-03 02:04:29,696:INFO: Batch: 11/31	Total Loss -212.7899 (-232.5005)
2022-11-03 02:04:30,190:INFO: Batch: 12/31	Total Loss -210.4301 (-230.7693)
2022-11-03 02:04:30,687:INFO: Batch: 13/31	Total Loss -257.5885 (-232.6524)
2022-11-03 02:04:31,183:INFO: Batch: 14/31	Total Loss -261.3578 (-234.6603)
2022-11-03 02:04:31,679:INFO: Batch: 15/31	Total Loss -258.2056 (-236.3708)
2022-11-03 02:04:32,173:INFO: Batch: 16/31	Total Loss -219.6921 (-235.4844)
2022-11-03 02:04:32,669:INFO: Batch: 17/31	Total Loss -247.5164 (-236.1601)
2022-11-03 02:04:33,162:INFO: Batch: 18/31	Total Loss -198.1300 (-234.3903)
2022-11-03 02:04:33,655:INFO: Batch: 19/31	Total Loss -219.2363 (-233.6482)
2022-11-03 02:04:34,147:INFO: Batch: 20/31	Total Loss -217.0400 (-232.8766)
2022-11-03 02:04:34,642:INFO: Batch: 21/31	Total Loss -251.5375 (-233.7764)
2022-11-03 02:04:35,135:INFO: Batch: 22/31	Total Loss -212.3226 (-232.8287)
2022-11-03 02:04:35,628:INFO: Batch: 23/31	Total Loss -227.9053 (-232.6200)
2022-11-03 02:04:36,121:INFO: Batch: 24/31	Total Loss -248.4581 (-233.2560)
2022-11-03 02:04:36,614:INFO: Batch: 25/31	Total Loss -247.1284 (-233.8432)
2022-11-03 02:04:37,106:INFO: Batch: 26/31	Total Loss -244.0806 (-234.2182)
2022-11-03 02:04:37,600:INFO: Batch: 27/31	Total Loss -212.3738 (-233.5264)
2022-11-03 02:04:38,098:INFO: Batch: 28/31	Total Loss -245.7402 (-233.9842)
2022-11-03 02:04:38,678:INFO: Batch: 29/31	Total Loss -236.0026 (-234.0549)
2022-11-03 02:04:39,073:INFO: Batch: 30/31	Total Loss -142.8530 (-233.2726)
2022-11-03 02:04:39,217:INFO: - Computing ADE (validation o)
2022-11-03 02:04:39,907:INFO: 		 ADE on eth                       dataset:	 0.9262294173240662
2022-11-03 02:04:39,907:INFO: Average validation o:	ADE  0.9262	FDE  1.9941
2022-11-03 02:04:39,908:INFO: - Computing ADE (validation)
2022-11-03 02:04:40,216:INFO: 		 ADE on hotel                     dataset:	 0.3626771569252014
2022-11-03 02:04:40,592:INFO: 		 ADE on univ                      dataset:	 0.5257508158683777
2022-11-03 02:04:40,872:INFO: 		 ADE on zara1                     dataset:	 0.3765725791454315
2022-11-03 02:04:41,334:INFO: 		 ADE on zara2                     dataset:	 0.38951054215431213
2022-11-03 02:04:41,334:INFO: Average validation:	ADE  0.4582	FDE  0.9804
2022-11-03 02:04:41,343:INFO: - Computing ADE (training)
2022-11-03 02:04:41,919:INFO: 		 ADE on hotel                     dataset:	 0.36595743894577026
2022-11-03 02:04:42,992:INFO: 		 ADE on univ                      dataset:	 0.5249695777893066
2022-11-03 02:04:43,739:INFO: 		 ADE on zara1                     dataset:	 0.42450785636901855
2022-11-03 02:04:44,911:INFO: 		 ADE on zara2                     dataset:	 0.37815287709236145
2022-11-03 02:04:44,911:INFO: Average training:	ADE  0.4847	FDE  1.0420
2022-11-03 02:04:44,922:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_644.pth.tar
2022-11-03 02:04:44,922:INFO: 
===> EPOCH: 645 (P4)
2022-11-03 02:04:44,923:INFO: - Computing loss (training)
2022-11-03 02:04:46,056:INFO: Batch:  0/31	Total Loss -205.2803 (-205.2803)
2022-11-03 02:04:46,558:INFO: Batch:  1/31	Total Loss -256.9510 (-232.6197)
2022-11-03 02:04:47,058:INFO: Batch:  2/31	Total Loss -219.3768 (-228.6097)
2022-11-03 02:04:47,555:INFO: Batch:  3/31	Total Loss -211.5167 (-224.1292)
2022-11-03 02:04:48,058:INFO: Batch:  4/31	Total Loss -190.9711 (-217.5384)
2022-11-03 02:04:48,558:INFO: Batch:  5/31	Total Loss -239.6929 (-221.4190)
2022-11-03 02:04:49,060:INFO: Batch:  6/31	Total Loss -216.4530 (-220.7415)
2022-11-03 02:04:49,557:INFO: Batch:  7/31	Total Loss -239.7549 (-223.1018)
2022-11-03 02:04:50,056:INFO: Batch:  8/31	Total Loss -251.4158 (-226.3672)
2022-11-03 02:04:50,555:INFO: Batch:  9/31	Total Loss -253.7805 (-229.1838)
2022-11-03 02:04:51,052:INFO: Batch: 10/31	Total Loss -237.6826 (-229.9867)
2022-11-03 02:04:51,551:INFO: Batch: 11/31	Total Loss -230.2532 (-230.0078)
2022-11-03 02:04:52,050:INFO: Batch: 12/31	Total Loss -238.4801 (-230.6770)
2022-11-03 02:04:52,550:INFO: Batch: 13/31	Total Loss -218.3353 (-229.8121)
2022-11-03 02:04:53,052:INFO: Batch: 14/31	Total Loss -244.9523 (-230.7817)
2022-11-03 02:04:53,552:INFO: Batch: 15/31	Total Loss -210.5213 (-229.5121)
2022-11-03 02:04:54,051:INFO: Batch: 16/31	Total Loss -231.8099 (-229.6640)
2022-11-03 02:04:54,553:INFO: Batch: 17/31	Total Loss -234.6843 (-229.9676)
2022-11-03 02:04:55,054:INFO: Batch: 18/31	Total Loss -252.4893 (-231.2149)
2022-11-03 02:04:55,555:INFO: Batch: 19/31	Total Loss -254.3195 (-232.4916)
2022-11-03 02:04:56,055:INFO: Batch: 20/31	Total Loss -269.7972 (-234.4849)
2022-11-03 02:04:56,554:INFO: Batch: 21/31	Total Loss -212.0508 (-233.4313)
2022-11-03 02:04:57,051:INFO: Batch: 22/31	Total Loss -220.2100 (-232.8754)
2022-11-03 02:04:57,550:INFO: Batch: 23/31	Total Loss -236.9639 (-233.0507)
2022-11-03 02:04:58,047:INFO: Batch: 24/31	Total Loss -248.1958 (-233.6599)
2022-11-03 02:04:58,545:INFO: Batch: 25/31	Total Loss -253.2403 (-234.4769)
2022-11-03 02:04:59,041:INFO: Batch: 26/31	Total Loss -235.7791 (-234.5215)
2022-11-03 02:04:59,539:INFO: Batch: 27/31	Total Loss -249.5782 (-235.1078)
2022-11-03 02:05:00,037:INFO: Batch: 28/31	Total Loss -263.4092 (-236.1381)
2022-11-03 02:05:00,536:INFO: Batch: 29/31	Total Loss -236.9390 (-236.1647)
2022-11-03 02:05:00,930:INFO: Batch: 30/31	Total Loss -146.6934 (-235.3256)
2022-11-03 02:05:01,083:INFO: - Computing ADE (validation o)
2022-11-03 02:05:01,766:INFO: 		 ADE on eth                       dataset:	 0.9356133341789246
2022-11-03 02:05:01,766:INFO: Average validation o:	ADE  0.9356	FDE  2.0165
2022-11-03 02:05:01,767:INFO: - Computing ADE (validation)
2022-11-03 02:05:02,067:INFO: 		 ADE on hotel                     dataset:	 0.39411279559135437
2022-11-03 02:05:02,434:INFO: 		 ADE on univ                      dataset:	 0.5384020805358887
2022-11-03 02:05:02,728:INFO: 		 ADE on zara1                     dataset:	 0.4132055938243866
2022-11-03 02:05:03,203:INFO: 		 ADE on zara2                     dataset:	 0.41232985258102417
2022-11-03 02:05:03,203:INFO: Average validation:	ADE  0.4770	FDE  1.0300
2022-11-03 02:05:03,204:INFO: - Computing ADE (training)
2022-11-03 02:05:03,770:INFO: 		 ADE on hotel                     dataset:	 0.3990841805934906
2022-11-03 02:05:04,806:INFO: 		 ADE on univ                      dataset:	 0.5382707715034485
2022-11-03 02:05:05,552:INFO: 		 ADE on zara1                     dataset:	 0.429053395986557
2022-11-03 02:05:06,746:INFO: 		 ADE on zara2                     dataset:	 0.39230573177337646
2022-11-03 02:05:06,747:INFO: Average training:	ADE  0.4982	FDE  1.0742
2022-11-03 02:05:06,758:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_645.pth.tar
2022-11-03 02:05:06,758:INFO: 
===> EPOCH: 646 (P4)
2022-11-03 02:05:06,759:INFO: - Computing loss (training)
2022-11-03 02:05:07,876:INFO: Batch:  0/31	Total Loss -238.6092 (-238.6092)
2022-11-03 02:05:08,367:INFO: Batch:  1/31	Total Loss -225.3274 (-232.0166)
2022-11-03 02:05:08,865:INFO: Batch:  2/31	Total Loss -259.8616 (-242.4084)
2022-11-03 02:05:09,362:INFO: Batch:  3/31	Total Loss -221.0342 (-236.6353)
2022-11-03 02:05:09,853:INFO: Batch:  4/31	Total Loss -265.8763 (-242.7838)
2022-11-03 02:05:10,343:INFO: Batch:  5/31	Total Loss -239.6624 (-242.2845)
2022-11-03 02:05:10,842:INFO: Batch:  6/31	Total Loss -267.6188 (-245.9468)
2022-11-03 02:05:11,332:INFO: Batch:  7/31	Total Loss -256.2260 (-247.2371)
2022-11-03 02:05:11,822:INFO: Batch:  8/31	Total Loss -255.5361 (-248.2089)
2022-11-03 02:05:12,312:INFO: Batch:  9/31	Total Loss -254.2101 (-248.8288)
2022-11-03 02:05:12,803:INFO: Batch: 10/31	Total Loss -219.2964 (-246.4299)
2022-11-03 02:05:13,292:INFO: Batch: 11/31	Total Loss -228.4360 (-245.1051)
2022-11-03 02:05:13,786:INFO: Batch: 12/31	Total Loss -265.0493 (-246.7730)
2022-11-03 02:05:14,279:INFO: Batch: 13/31	Total Loss -237.2505 (-246.0848)
2022-11-03 02:05:14,772:INFO: Batch: 14/31	Total Loss -269.1220 (-247.7478)
2022-11-03 02:05:15,265:INFO: Batch: 15/31	Total Loss 762.9893 (-189.1133)
2022-11-03 02:05:15,760:INFO: Batch: 16/31	Total Loss -199.9252 (-189.7884)
2022-11-03 02:05:16,251:INFO: Batch: 17/31	Total Loss -92.5455 (-184.7253)
2022-11-03 02:05:16,744:INFO: Batch: 18/31	Total Loss 80.1299 (-171.3745)
2022-11-03 02:05:17,238:INFO: Batch: 19/31	Total Loss 79.2894 (-160.4358)
2022-11-03 02:05:17,731:INFO: Batch: 20/31	Total Loss 46.2876 (-149.7665)
2022-11-03 02:05:18,224:INFO: Batch: 21/31	Total Loss 68.1240 (-140.3565)
2022-11-03 02:05:18,715:INFO: Batch: 22/31	Total Loss 16.6285 (-133.4019)
2022-11-03 02:05:19,207:INFO: Batch: 23/31	Total Loss 18.3261 (-126.9344)
2022-11-03 02:05:19,700:INFO: Batch: 24/31	Total Loss 116.3381 (-118.0331)
2022-11-03 02:05:20,192:INFO: Batch: 25/31	Total Loss 28.5881 (-112.2494)
2022-11-03 02:05:20,684:INFO: Batch: 26/31	Total Loss -34.7442 (-109.3167)
2022-11-03 02:05:21,176:INFO: Batch: 27/31	Total Loss -36.0290 (-106.8466)
2022-11-03 02:05:21,668:INFO: Batch: 28/31	Total Loss -1.5661 (-102.6038)
2022-11-03 02:05:22,161:INFO: Batch: 29/31	Total Loss 53.3014 (-96.9863)
2022-11-03 02:05:22,552:INFO: Batch: 30/31	Total Loss -86.0512 (-96.8885)
2022-11-03 02:05:22,700:INFO: - Computing ADE (validation o)
2022-11-03 02:05:23,400:INFO: 		 ADE on eth                       dataset:	 0.9972636699676514
2022-11-03 02:05:23,401:INFO: Average validation o:	ADE  0.9973	FDE  2.0865
2022-11-03 02:05:23,401:INFO: - Computing ADE (validation)
2022-11-03 02:05:23,707:INFO: 		 ADE on hotel                     dataset:	 0.5306534767150879
2022-11-03 02:05:24,066:INFO: 		 ADE on univ                      dataset:	 0.6202045679092407
2022-11-03 02:05:24,344:INFO: 		 ADE on zara1                     dataset:	 0.46777039766311646
2022-11-03 02:05:24,808:INFO: 		 ADE on zara2                     dataset:	 0.5173536539077759
2022-11-03 02:05:24,808:INFO: Average validation:	ADE  0.5687	FDE  1.1545
2022-11-03 02:05:24,809:INFO: - Computing ADE (training)
2022-11-03 02:05:25,365:INFO: 		 ADE on hotel                     dataset:	 0.5343994498252869
2022-11-03 02:05:26,420:INFO: 		 ADE on univ                      dataset:	 0.6145641803741455
2022-11-03 02:05:27,174:INFO: 		 ADE on zara1                     dataset:	 0.5473149418830872
2022-11-03 02:05:28,367:INFO: 		 ADE on zara2                     dataset:	 0.5199365019798279
2022-11-03 02:05:28,367:INFO: Average training:	ADE  0.5890	FDE  1.2026
2022-11-03 02:05:28,378:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_646.pth.tar
2022-11-03 02:05:28,378:INFO: 
===> EPOCH: 647 (P4)
2022-11-03 02:05:28,379:INFO: - Computing loss (training)
2022-11-03 02:05:29,521:INFO: Batch:  0/31	Total Loss 11.7560 (11.7560)
2022-11-03 02:05:30,012:INFO: Batch:  1/31	Total Loss 23.3072 (17.9124)
2022-11-03 02:05:30,506:INFO: Batch:  2/31	Total Loss -35.3871 (-0.6296)
2022-11-03 02:05:30,997:INFO: Batch:  3/31	Total Loss -16.4948 (-4.5693)
2022-11-03 02:05:31,489:INFO: Batch:  4/31	Total Loss -62.8781 (-14.5716)
2022-11-03 02:05:31,980:INFO: Batch:  5/31	Total Loss -37.1030 (-18.2193)
2022-11-03 02:05:32,467:INFO: Batch:  6/31	Total Loss -47.1463 (-22.2350)
2022-11-03 02:05:32,958:INFO: Batch:  7/31	Total Loss -35.8961 (-24.0441)
2022-11-03 02:05:33,446:INFO: Batch:  8/31	Total Loss -59.4443 (-28.5324)
2022-11-03 02:05:33,933:INFO: Batch:  9/31	Total Loss -55.4652 (-31.0307)
2022-11-03 02:05:34,424:INFO: Batch: 10/31	Total Loss -60.4091 (-33.7709)
2022-11-03 02:05:34,912:INFO: Batch: 11/31	Total Loss -59.3101 (-35.8365)
2022-11-03 02:05:35,403:INFO: Batch: 12/31	Total Loss -57.5185 (-37.6328)
2022-11-03 02:05:35,898:INFO: Batch: 13/31	Total Loss -69.5690 (-40.0292)
2022-11-03 02:05:36,391:INFO: Batch: 14/31	Total Loss -58.1483 (-41.1340)
2022-11-03 02:05:36,888:INFO: Batch: 15/31	Total Loss -33.8483 (-40.6712)
2022-11-03 02:05:37,381:INFO: Batch: 16/31	Total Loss -14.4024 (-39.1572)
2022-11-03 02:05:37,877:INFO: Batch: 17/31	Total Loss -63.6171 (-40.2842)
2022-11-03 02:05:38,369:INFO: Batch: 18/31	Total Loss -62.5200 (-41.3847)
2022-11-03 02:05:38,862:INFO: Batch: 19/31	Total Loss -74.4348 (-43.2353)
2022-11-03 02:05:39,429:INFO: Batch: 20/31	Total Loss -56.8865 (-43.8891)
2022-11-03 02:05:39,922:INFO: Batch: 21/31	Total Loss -69.3236 (-45.1204)
2022-11-03 02:05:40,414:INFO: Batch: 22/31	Total Loss -65.7452 (-45.9932)
2022-11-03 02:05:40,912:INFO: Batch: 23/31	Total Loss -67.4786 (-46.8892)
2022-11-03 02:05:41,412:INFO: Batch: 24/31	Total Loss -59.8821 (-47.4317)
2022-11-03 02:05:41,912:INFO: Batch: 25/31	Total Loss -68.5881 (-48.2885)
2022-11-03 02:05:42,412:INFO: Batch: 26/31	Total Loss -65.9957 (-48.8959)
2022-11-03 02:05:42,912:INFO: Batch: 27/31	Total Loss -70.9221 (-49.7203)
2022-11-03 02:05:43,410:INFO: Batch: 28/31	Total Loss -74.5964 (-50.5806)
2022-11-03 02:05:43,907:INFO: Batch: 29/31	Total Loss -70.6451 (-51.2533)
2022-11-03 02:05:44,301:INFO: Batch: 30/31	Total Loss -96.6154 (-51.6988)
2022-11-03 02:05:44,455:INFO: - Computing ADE (validation o)
2022-11-03 02:05:45,156:INFO: 		 ADE on eth                       dataset:	 0.9270190000534058
2022-11-03 02:05:45,156:INFO: Average validation o:	ADE  0.9270	FDE  1.9919
2022-11-03 02:05:45,157:INFO: - Computing ADE (validation)
2022-11-03 02:05:45,463:INFO: 		 ADE on hotel                     dataset:	 0.3690524399280548
2022-11-03 02:05:45,824:INFO: 		 ADE on univ                      dataset:	 0.5307590365409851
2022-11-03 02:05:46,116:INFO: 		 ADE on zara1                     dataset:	 0.40252387523651123
2022-11-03 02:05:46,576:INFO: 		 ADE on zara2                     dataset:	 0.3936910033226013
2022-11-03 02:05:46,576:INFO: Average validation:	ADE  0.4642	FDE  1.0023
2022-11-03 02:05:46,577:INFO: - Computing ADE (training)
2022-11-03 02:05:47,123:INFO: 		 ADE on hotel                     dataset:	 0.3800309896469116
2022-11-03 02:05:48,180:INFO: 		 ADE on univ                      dataset:	 0.526343047618866
2022-11-03 02:05:48,926:INFO: 		 ADE on zara1                     dataset:	 0.4261876344680786
2022-11-03 02:05:50,156:INFO: 		 ADE on zara2                     dataset:	 0.3798036575317383
2022-11-03 02:05:50,156:INFO: Average training:	ADE  0.4865	FDE  1.0514
2022-11-03 02:05:50,176:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_647.pth.tar
2022-11-03 02:05:50,176:INFO: 
===> EPOCH: 648 (P4)
2022-11-03 02:05:50,176:INFO: - Computing loss (training)
2022-11-03 02:05:51,354:INFO: Batch:  0/31	Total Loss -67.6092 (-67.6092)
2022-11-03 02:05:51,870:INFO: Batch:  1/31	Total Loss -81.9500 (-75.1094)
2022-11-03 02:05:52,374:INFO: Batch:  2/31	Total Loss -84.2563 (-78.4722)
2022-11-03 02:05:52,879:INFO: Batch:  3/31	Total Loss -81.3559 (-79.1299)
2022-11-03 02:05:53,386:INFO: Batch:  4/31	Total Loss -83.4403 (-80.0175)
2022-11-03 02:05:53,893:INFO: Batch:  5/31	Total Loss -82.3985 (-80.4270)
2022-11-03 02:05:54,395:INFO: Batch:  6/31	Total Loss -83.5889 (-80.8803)
2022-11-03 02:05:54,907:INFO: Batch:  7/31	Total Loss -81.2246 (-80.9245)
2022-11-03 02:05:55,411:INFO: Batch:  8/31	Total Loss -83.7979 (-81.2566)
2022-11-03 02:05:55,917:INFO: Batch:  9/31	Total Loss -86.4371 (-81.7570)
2022-11-03 02:05:56,423:INFO: Batch: 10/31	Total Loss -69.7698 (-80.7916)
2022-11-03 02:05:56,927:INFO: Batch: 11/31	Total Loss -70.4465 (-79.9884)
2022-11-03 02:05:57,433:INFO: Batch: 12/31	Total Loss -80.7966 (-80.0477)
2022-11-03 02:05:57,937:INFO: Batch: 13/31	Total Loss -70.0621 (-79.3830)
2022-11-03 02:05:58,443:INFO: Batch: 14/31	Total Loss -78.7513 (-79.3374)
2022-11-03 02:05:58,950:INFO: Batch: 15/31	Total Loss -86.0550 (-79.7641)
2022-11-03 02:05:59,457:INFO: Batch: 16/31	Total Loss -85.4359 (-80.0940)
2022-11-03 02:05:59,962:INFO: Batch: 17/31	Total Loss -90.4141 (-80.6815)
2022-11-03 02:06:00,466:INFO: Batch: 18/31	Total Loss -90.7846 (-81.2655)
2022-11-03 02:06:00,972:INFO: Batch: 19/31	Total Loss -75.1742 (-80.9520)
2022-11-03 02:06:01,489:INFO: Batch: 20/31	Total Loss -81.5393 (-80.9784)
2022-11-03 02:06:01,993:INFO: Batch: 21/31	Total Loss -88.4373 (-81.2884)
2022-11-03 02:06:02,496:INFO: Batch: 22/31	Total Loss -64.8653 (-80.6157)
2022-11-03 02:06:03,000:INFO: Batch: 23/31	Total Loss -72.2594 (-80.2814)
2022-11-03 02:06:03,501:INFO: Batch: 24/31	Total Loss -57.4595 (-79.4196)
2022-11-03 02:06:04,003:INFO: Batch: 25/31	Total Loss -87.6140 (-79.7409)
2022-11-03 02:06:04,503:INFO: Batch: 26/31	Total Loss -85.7347 (-79.9542)
2022-11-03 02:06:05,001:INFO: Batch: 27/31	Total Loss -73.0053 (-79.7220)
2022-11-03 02:06:05,500:INFO: Batch: 28/31	Total Loss -92.8018 (-80.1987)
2022-11-03 02:06:05,997:INFO: Batch: 29/31	Total Loss -81.2557 (-80.2321)
2022-11-03 02:06:06,390:INFO: Batch: 30/31	Total Loss -97.9542 (-80.3900)
2022-11-03 02:06:06,545:INFO: - Computing ADE (validation o)
2022-11-03 02:06:07,239:INFO: 		 ADE on eth                       dataset:	 0.9139626622200012
2022-11-03 02:06:07,239:INFO: Average validation o:	ADE  0.9140	FDE  1.9399
2022-11-03 02:06:07,240:INFO: - Computing ADE (validation)
2022-11-03 02:06:07,559:INFO: 		 ADE on hotel                     dataset:	 0.3547350764274597
2022-11-03 02:06:07,934:INFO: 		 ADE on univ                      dataset:	 0.5231043100357056
2022-11-03 02:06:08,215:INFO: 		 ADE on zara1                     dataset:	 0.38914424180984497
2022-11-03 02:06:08,670:INFO: 		 ADE on zara2                     dataset:	 0.37966907024383545
2022-11-03 02:06:08,670:INFO: Average validation:	ADE  0.4535	FDE  0.9778
2022-11-03 02:06:08,670:INFO: - Computing ADE (training)
2022-11-03 02:06:09,242:INFO: 		 ADE on hotel                     dataset:	 0.3612949550151825
2022-11-03 02:06:10,328:INFO: 		 ADE on univ                      dataset:	 0.5169606804847717
2022-11-03 02:06:11,094:INFO: 		 ADE on zara1                     dataset:	 0.4221045672893524
2022-11-03 02:06:12,278:INFO: 		 ADE on zara2                     dataset:	 0.3682803809642792
2022-11-03 02:06:12,278:INFO: Average training:	ADE  0.4768	FDE  1.0287
2022-11-03 02:06:12,290:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_648.pth.tar
2022-11-03 02:06:12,290:INFO: 
===> EPOCH: 649 (P4)
2022-11-03 02:06:12,290:INFO: - Computing loss (training)
2022-11-03 02:06:13,400:INFO: Batch:  0/31	Total Loss -91.0408 (-91.0408)
2022-11-03 02:06:13,900:INFO: Batch:  1/31	Total Loss -91.6099 (-91.3180)
2022-11-03 02:06:14,402:INFO: Batch:  2/31	Total Loss -93.6433 (-92.1058)
2022-11-03 02:06:14,904:INFO: Batch:  3/31	Total Loss -85.4247 (-90.4251)
2022-11-03 02:06:15,403:INFO: Batch:  4/31	Total Loss -97.4114 (-91.8680)
2022-11-03 02:06:15,904:INFO: Batch:  5/31	Total Loss -70.9508 (-88.5471)
2022-11-03 02:06:16,403:INFO: Batch:  6/31	Total Loss -84.5348 (-88.0331)
2022-11-03 02:06:16,902:INFO: Batch:  7/31	Total Loss -88.0668 (-88.0375)
2022-11-03 02:06:17,398:INFO: Batch:  8/31	Total Loss -95.2213 (-88.8218)
2022-11-03 02:06:17,896:INFO: Batch:  9/31	Total Loss -75.1398 (-87.4128)
2022-11-03 02:06:18,395:INFO: Batch: 10/31	Total Loss -88.9713 (-87.5456)
2022-11-03 02:06:18,894:INFO: Batch: 11/31	Total Loss -80.0373 (-86.8922)
2022-11-03 02:06:19,394:INFO: Batch: 12/31	Total Loss -94.6008 (-87.4439)
2022-11-03 02:06:19,897:INFO: Batch: 13/31	Total Loss -103.0216 (-88.5853)
2022-11-03 02:06:20,399:INFO: Batch: 14/31	Total Loss -78.2328 (-87.9620)
2022-11-03 02:06:20,906:INFO: Batch: 15/31	Total Loss -93.9063 (-88.3411)
2022-11-03 02:06:21,409:INFO: Batch: 16/31	Total Loss -96.8744 (-88.8651)
2022-11-03 02:06:21,912:INFO: Batch: 17/31	Total Loss -94.5020 (-89.1560)
2022-11-03 02:06:22,414:INFO: Batch: 18/31	Total Loss -103.9410 (-89.8837)
2022-11-03 02:06:22,916:INFO: Batch: 19/31	Total Loss -92.1282 (-89.9937)
2022-11-03 02:06:23,418:INFO: Batch: 20/31	Total Loss -101.4266 (-90.5482)
2022-11-03 02:06:23,921:INFO: Batch: 21/31	Total Loss -102.5187 (-91.1045)
2022-11-03 02:06:24,419:INFO: Batch: 22/31	Total Loss -107.9016 (-91.8269)
2022-11-03 02:06:24,921:INFO: Batch: 23/31	Total Loss -111.8835 (-92.7796)
2022-11-03 02:06:25,423:INFO: Batch: 24/31	Total Loss -118.7862 (-93.9276)
2022-11-03 02:06:25,926:INFO: Batch: 25/31	Total Loss -109.0311 (-94.5052)
2022-11-03 02:06:26,431:INFO: Batch: 26/31	Total Loss -58.9788 (-93.0762)
2022-11-03 02:06:26,938:INFO: Batch: 27/31	Total Loss -85.2004 (-92.7919)
2022-11-03 02:06:27,442:INFO: Batch: 28/31	Total Loss -99.4462 (-93.0035)
2022-11-03 02:06:27,948:INFO: Batch: 29/31	Total Loss -23.1997 (-91.0425)
2022-11-03 02:06:28,349:INFO: Batch: 30/31	Total Loss -105.6661 (-91.1919)
2022-11-03 02:06:28,498:INFO: - Computing ADE (validation o)
2022-11-03 02:06:29,162:INFO: 		 ADE on eth                       dataset:	 0.9141910672187805
2022-11-03 02:06:29,162:INFO: Average validation o:	ADE  0.9142	FDE  1.9345
2022-11-03 02:06:29,163:INFO: - Computing ADE (validation)
2022-11-03 02:06:29,460:INFO: 		 ADE on hotel                     dataset:	 0.3585139214992523
2022-11-03 02:06:29,840:INFO: 		 ADE on univ                      dataset:	 0.5214918851852417
2022-11-03 02:06:30,144:INFO: 		 ADE on zara1                     dataset:	 0.38775888085365295
2022-11-03 02:06:30,631:INFO: 		 ADE on zara2                     dataset:	 0.38506320118904114
2022-11-03 02:06:30,631:INFO: Average validation:	ADE  0.4547	FDE  0.9767
2022-11-03 02:06:30,640:INFO: - Computing ADE (training)
2022-11-03 02:06:31,222:INFO: 		 ADE on hotel                     dataset:	 0.36128297448158264
2022-11-03 02:06:32,267:INFO: 		 ADE on univ                      dataset:	 0.5170460343360901
2022-11-03 02:06:32,996:INFO: 		 ADE on zara1                     dataset:	 0.4336301386356354
2022-11-03 02:06:34,266:INFO: 		 ADE on zara2                     dataset:	 0.38008999824523926
2022-11-03 02:06:34,266:INFO: Average training:	ADE  0.4800	FDE  1.0354
2022-11-03 02:06:34,279:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_649.pth.tar
2022-11-03 02:06:34,279:INFO: 
===> EPOCH: 650 (P4)
2022-11-03 02:06:34,279:INFO: - Computing loss (training)
2022-11-03 02:06:35,402:INFO: Batch:  0/31	Total Loss -113.4650 (-113.4650)
2022-11-03 02:06:35,900:INFO: Batch:  1/31	Total Loss -84.8105 (-99.3016)
2022-11-03 02:06:36,397:INFO: Batch:  2/31	Total Loss -104.1614 (-100.9167)
2022-11-03 02:06:36,885:INFO: Batch:  3/31	Total Loss -104.4533 (-101.8270)
2022-11-03 02:06:37,377:INFO: Batch:  4/31	Total Loss -95.8123 (-100.6014)
2022-11-03 02:06:37,873:INFO: Batch:  5/31	Total Loss -79.1868 (-97.5669)
2022-11-03 02:06:38,438:INFO: Batch:  6/31	Total Loss -87.8132 (-96.2813)
2022-11-03 02:06:38,926:INFO: Batch:  7/31	Total Loss -109.6298 (-97.8510)
2022-11-03 02:06:39,415:INFO: Batch:  8/31	Total Loss -107.2133 (-98.8785)
2022-11-03 02:06:39,905:INFO: Batch:  9/31	Total Loss -104.6546 (-99.4313)
2022-11-03 02:06:40,394:INFO: Batch: 10/31	Total Loss -113.1465 (-100.6506)
2022-11-03 02:06:40,888:INFO: Batch: 11/31	Total Loss -114.0285 (-101.7791)
2022-11-03 02:06:41,374:INFO: Batch: 12/31	Total Loss -70.7000 (-99.9675)
2022-11-03 02:06:41,866:INFO: Batch: 13/31	Total Loss -104.6828 (-100.3029)
2022-11-03 02:06:42,358:INFO: Batch: 14/31	Total Loss -97.3603 (-100.1141)
2022-11-03 02:06:42,852:INFO: Batch: 15/31	Total Loss -119.7049 (-101.4111)
2022-11-03 02:06:43,343:INFO: Batch: 16/31	Total Loss -99.9730 (-101.3163)
2022-11-03 02:06:43,834:INFO: Batch: 17/31	Total Loss -73.9556 (-99.6122)
2022-11-03 02:06:44,328:INFO: Batch: 18/31	Total Loss -115.2688 (-100.5358)
2022-11-03 02:06:44,821:INFO: Batch: 19/31	Total Loss -97.3600 (-100.3771)
2022-11-03 02:06:45,312:INFO: Batch: 20/31	Total Loss -116.1245 (-101.1606)
2022-11-03 02:06:45,805:INFO: Batch: 21/31	Total Loss -115.2104 (-101.8121)
2022-11-03 02:06:46,296:INFO: Batch: 22/31	Total Loss -110.5105 (-102.2132)
2022-11-03 02:06:46,787:INFO: Batch: 23/31	Total Loss -113.3045 (-102.7143)
2022-11-03 02:06:47,279:INFO: Batch: 24/31	Total Loss -119.0286 (-103.4184)
2022-11-03 02:06:47,771:INFO: Batch: 25/31	Total Loss -120.0140 (-104.1018)
2022-11-03 02:06:48,261:INFO: Batch: 26/31	Total Loss -113.4228 (-104.4301)
2022-11-03 02:06:48,752:INFO: Batch: 27/31	Total Loss -114.3901 (-104.7812)
2022-11-03 02:06:49,243:INFO: Batch: 28/31	Total Loss -115.5536 (-105.1873)
2022-11-03 02:06:49,733:INFO: Batch: 29/31	Total Loss -122.6871 (-105.8189)
2022-11-03 02:06:50,121:INFO: Batch: 30/31	Total Loss -108.4680 (-105.8426)
2022-11-03 02:06:50,269:INFO: - Computing ADE (validation o)
2022-11-03 02:06:50,963:INFO: 		 ADE on eth                       dataset:	 0.9291645288467407
2022-11-03 02:06:50,963:INFO: Average validation o:	ADE  0.9292	FDE  1.9980
2022-11-03 02:06:50,964:INFO: - Computing ADE (validation)
2022-11-03 02:06:51,270:INFO: 		 ADE on hotel                     dataset:	 0.38686805963516235
2022-11-03 02:06:51,648:INFO: 		 ADE on univ                      dataset:	 0.5423158407211304
2022-11-03 02:06:51,928:INFO: 		 ADE on zara1                     dataset:	 0.4157627820968628
2022-11-03 02:06:52,406:INFO: 		 ADE on zara2                     dataset:	 0.4040192663669586
2022-11-03 02:06:52,407:INFO: Average validation:	ADE  0.4757	FDE  1.0275
2022-11-03 02:06:52,408:INFO: - Computing ADE (training)
2022-11-03 02:06:52,974:INFO: 		 ADE on hotel                     dataset:	 0.3933161497116089
2022-11-03 02:06:54,012:INFO: 		 ADE on univ                      dataset:	 0.5345367789268494
2022-11-03 02:06:54,746:INFO: 		 ADE on zara1                     dataset:	 0.42930322885513306
2022-11-03 02:06:55,928:INFO: 		 ADE on zara2                     dataset:	 0.38579457998275757
2022-11-03 02:06:55,928:INFO: Average training:	ADE  0.4941	FDE  1.0641
2022-11-03 02:06:55,939:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_650.pth.tar
2022-11-03 02:06:55,939:INFO: 
===> EPOCH: 651 (P4)
2022-11-03 02:06:55,939:INFO: - Computing loss (training)
2022-11-03 02:06:57,040:INFO: Batch:  0/31	Total Loss -125.4977 (-125.4977)
2022-11-03 02:06:57,531:INFO: Batch:  1/31	Total Loss -117.3198 (-121.6429)
2022-11-03 02:06:58,025:INFO: Batch:  2/31	Total Loss -117.5485 (-120.3119)
2022-11-03 02:06:58,510:INFO: Batch:  3/31	Total Loss -124.1849 (-121.2489)
2022-11-03 02:06:58,997:INFO: Batch:  4/31	Total Loss -117.2288 (-120.4697)
2022-11-03 02:06:59,492:INFO: Batch:  5/31	Total Loss -111.9086 (-119.0508)
2022-11-03 02:06:59,982:INFO: Batch:  6/31	Total Loss -107.8257 (-117.5235)
2022-11-03 02:07:00,478:INFO: Batch:  7/31	Total Loss -116.9409 (-117.4507)
2022-11-03 02:07:00,971:INFO: Batch:  8/31	Total Loss -129.9827 (-118.8988)
2022-11-03 02:07:01,461:INFO: Batch:  9/31	Total Loss -113.6161 (-118.4299)
2022-11-03 02:07:01,953:INFO: Batch: 10/31	Total Loss -87.4255 (-115.5284)
2022-11-03 02:07:02,443:INFO: Batch: 11/31	Total Loss -128.3913 (-116.6501)
2022-11-03 02:07:02,936:INFO: Batch: 12/31	Total Loss -128.0550 (-117.5854)
2022-11-03 02:07:03,428:INFO: Batch: 13/31	Total Loss -141.9738 (-119.3718)
2022-11-03 02:07:03,922:INFO: Batch: 14/31	Total Loss -103.2283 (-118.3873)
2022-11-03 02:07:04,415:INFO: Batch: 15/31	Total Loss -116.5049 (-118.2665)
2022-11-03 02:07:04,908:INFO: Batch: 16/31	Total Loss -127.3159 (-118.7571)
2022-11-03 02:07:05,400:INFO: Batch: 17/31	Total Loss -109.7597 (-118.2707)
2022-11-03 02:07:05,895:INFO: Batch: 18/31	Total Loss -119.4871 (-118.3344)
2022-11-03 02:07:06,389:INFO: Batch: 19/31	Total Loss -128.9758 (-118.8401)
2022-11-03 02:07:06,886:INFO: Batch: 20/31	Total Loss -118.5363 (-118.8244)
2022-11-03 02:07:07,380:INFO: Batch: 21/31	Total Loss -121.3974 (-118.9368)
2022-11-03 02:07:07,875:INFO: Batch: 22/31	Total Loss -110.8289 (-118.5889)
2022-11-03 02:07:08,368:INFO: Batch: 23/31	Total Loss -117.3288 (-118.5359)
2022-11-03 02:07:08,863:INFO: Batch: 24/31	Total Loss -138.0789 (-119.3403)
2022-11-03 02:07:09,357:INFO: Batch: 25/31	Total Loss -121.6100 (-119.4183)
2022-11-03 02:07:09,852:INFO: Batch: 26/31	Total Loss -146.7326 (-120.5638)
2022-11-03 02:07:10,346:INFO: Batch: 27/31	Total Loss -139.8240 (-121.2683)
2022-11-03 02:07:10,841:INFO: Batch: 28/31	Total Loss -110.5917 (-120.9094)
2022-11-03 02:07:11,335:INFO: Batch: 29/31	Total Loss -128.5252 (-121.1816)
2022-11-03 02:07:11,726:INFO: Batch: 30/31	Total Loss -106.0796 (-121.0444)
2022-11-03 02:07:11,881:INFO: - Computing ADE (validation o)
2022-11-03 02:07:12,586:INFO: 		 ADE on eth                       dataset:	 0.9099133014678955
2022-11-03 02:07:12,587:INFO: Average validation o:	ADE  0.9099	FDE  1.9299
2022-11-03 02:07:12,587:INFO: - Computing ADE (validation)
2022-11-03 02:07:12,890:INFO: 		 ADE on hotel                     dataset:	 0.37373894453048706
2022-11-03 02:07:13,259:INFO: 		 ADE on univ                      dataset:	 0.5309381484985352
2022-11-03 02:07:13,547:INFO: 		 ADE on zara1                     dataset:	 0.3900434970855713
2022-11-03 02:07:14,006:INFO: 		 ADE on zara2                     dataset:	 0.3842107057571411
2022-11-03 02:07:14,007:INFO: Average validation:	ADE  0.4603	FDE  0.9896
2022-11-03 02:07:14,007:INFO: - Computing ADE (training)
2022-11-03 02:07:14,562:INFO: 		 ADE on hotel                     dataset:	 0.3827518820762634
2022-11-03 02:07:15,606:INFO: 		 ADE on univ                      dataset:	 0.5214372873306274
2022-11-03 02:07:16,373:INFO: 		 ADE on zara1                     dataset:	 0.43043360114097595
2022-11-03 02:07:17,623:INFO: 		 ADE on zara2                     dataset:	 0.37439993023872375
2022-11-03 02:07:17,623:INFO: Average training:	ADE  0.4823	FDE  1.0386
2022-11-03 02:07:17,643:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_651.pth.tar
2022-11-03 02:07:17,643:INFO: 
===> EPOCH: 652 (P4)
2022-11-03 02:07:17,644:INFO: - Computing loss (training)
2022-11-03 02:07:18,771:INFO: Batch:  0/31	Total Loss -123.9398 (-123.9398)
2022-11-03 02:07:19,271:INFO: Batch:  1/31	Total Loss -143.8425 (-134.0373)
2022-11-03 02:07:19,770:INFO: Batch:  2/31	Total Loss -123.5720 (-130.9487)
2022-11-03 02:07:20,268:INFO: Batch:  3/31	Total Loss -125.0220 (-129.3820)
2022-11-03 02:07:20,766:INFO: Batch:  4/31	Total Loss -128.6729 (-129.2445)
2022-11-03 02:07:21,265:INFO: Batch:  5/31	Total Loss -138.6406 (-130.8662)
2022-11-03 02:07:21,763:INFO: Batch:  6/31	Total Loss -118.8244 (-129.3617)
2022-11-03 02:07:22,256:INFO: Batch:  7/31	Total Loss -115.1333 (-127.8131)
2022-11-03 02:07:22,753:INFO: Batch:  8/31	Total Loss -144.7984 (-129.7632)
2022-11-03 02:07:23,248:INFO: Batch:  9/31	Total Loss -136.7286 (-130.4602)
2022-11-03 02:07:23,744:INFO: Batch: 10/31	Total Loss -131.3269 (-130.5449)
2022-11-03 02:07:24,240:INFO: Batch: 11/31	Total Loss -136.0433 (-131.0489)
2022-11-03 02:07:24,739:INFO: Batch: 12/31	Total Loss -123.8186 (-130.4903)
2022-11-03 02:07:25,237:INFO: Batch: 13/31	Total Loss -134.6087 (-130.7927)
2022-11-03 02:07:25,735:INFO: Batch: 14/31	Total Loss -137.0426 (-131.1869)
2022-11-03 02:07:26,232:INFO: Batch: 15/31	Total Loss -125.6196 (-130.8556)
2022-11-03 02:07:26,729:INFO: Batch: 16/31	Total Loss -134.2185 (-131.0575)
2022-11-03 02:07:27,227:INFO: Batch: 17/31	Total Loss -122.4333 (-130.5705)
2022-11-03 02:07:27,724:INFO: Batch: 18/31	Total Loss -144.9954 (-131.3653)
2022-11-03 02:07:28,223:INFO: Batch: 19/31	Total Loss -139.5879 (-131.8023)
2022-11-03 02:07:28,720:INFO: Batch: 20/31	Total Loss -135.8748 (-131.9936)
2022-11-03 02:07:29,221:INFO: Batch: 21/31	Total Loss -127.3711 (-131.7639)
2022-11-03 02:07:29,719:INFO: Batch: 22/31	Total Loss -130.6496 (-131.7172)
2022-11-03 02:07:30,217:INFO: Batch: 23/31	Total Loss -143.1916 (-132.2184)
2022-11-03 02:07:30,717:INFO: Batch: 24/31	Total Loss -143.7493 (-132.6910)
2022-11-03 02:07:31,214:INFO: Batch: 25/31	Total Loss -130.9856 (-132.6261)
2022-11-03 02:07:31,713:INFO: Batch: 26/31	Total Loss -134.0401 (-132.6769)
2022-11-03 02:07:32,211:INFO: Batch: 27/31	Total Loss -136.6092 (-132.8177)
2022-11-03 02:07:32,712:INFO: Batch: 28/31	Total Loss -155.3629 (-133.6953)
2022-11-03 02:07:33,285:INFO: Batch: 29/31	Total Loss -146.3441 (-134.1650)
2022-11-03 02:07:33,680:INFO: Batch: 30/31	Total Loss -114.6085 (-133.9887)
2022-11-03 02:07:33,836:INFO: - Computing ADE (validation o)
2022-11-03 02:07:34,518:INFO: 		 ADE on eth                       dataset:	 0.9182451963424683
2022-11-03 02:07:34,519:INFO: Average validation o:	ADE  0.9182	FDE  1.9573
2022-11-03 02:07:34,528:INFO: - Computing ADE (validation)
2022-11-03 02:07:34,844:INFO: 		 ADE on hotel                     dataset:	 0.38195160031318665
2022-11-03 02:07:35,225:INFO: 		 ADE on univ                      dataset:	 0.5346930027008057
2022-11-03 02:07:35,505:INFO: 		 ADE on zara1                     dataset:	 0.4000173807144165
2022-11-03 02:07:35,966:INFO: 		 ADE on zara2                     dataset:	 0.39799314737319946
2022-11-03 02:07:35,966:INFO: Average validation:	ADE  0.4684	FDE  1.0131
2022-11-03 02:07:35,967:INFO: - Computing ADE (training)
2022-11-03 02:07:36,530:INFO: 		 ADE on hotel                     dataset:	 0.3883711099624634
2022-11-03 02:07:37,622:INFO: 		 ADE on univ                      dataset:	 0.5290683507919312
2022-11-03 02:07:38,397:INFO: 		 ADE on zara1                     dataset:	 0.4394966959953308
2022-11-03 02:07:39,583:INFO: 		 ADE on zara2                     dataset:	 0.3866158723831177
2022-11-03 02:07:39,584:INFO: Average training:	ADE  0.4909	FDE  1.0644
2022-11-03 02:07:39,595:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_652.pth.tar
2022-11-03 02:07:39,595:INFO: 
===> EPOCH: 653 (P4)
2022-11-03 02:07:39,595:INFO: - Computing loss (training)
2022-11-03 02:07:40,733:INFO: Batch:  0/31	Total Loss -94.4919 (-94.4919)
2022-11-03 02:07:41,247:INFO: Batch:  1/31	Total Loss -124.9478 (-108.5108)
2022-11-03 02:07:41,757:INFO: Batch:  2/31	Total Loss -120.0024 (-112.2267)
2022-11-03 02:07:42,269:INFO: Batch:  3/31	Total Loss -153.8016 (-122.5859)
2022-11-03 02:07:42,773:INFO: Batch:  4/31	Total Loss -148.8500 (-128.0627)
2022-11-03 02:07:43,283:INFO: Batch:  5/31	Total Loss -135.6024 (-129.3469)
2022-11-03 02:07:43,789:INFO: Batch:  6/31	Total Loss -135.0956 (-130.2095)
2022-11-03 02:07:44,292:INFO: Batch:  7/31	Total Loss -135.8479 (-130.8798)
2022-11-03 02:07:44,797:INFO: Batch:  8/31	Total Loss -151.5229 (-133.3125)
2022-11-03 02:07:45,303:INFO: Batch:  9/31	Total Loss -129.4927 (-132.9736)
2022-11-03 02:07:45,809:INFO: Batch: 10/31	Total Loss -121.4181 (-131.8998)
2022-11-03 02:07:46,318:INFO: Batch: 11/31	Total Loss -141.0468 (-132.6564)
2022-11-03 02:07:46,826:INFO: Batch: 12/31	Total Loss -126.5002 (-132.2580)
2022-11-03 02:07:47,336:INFO: Batch: 13/31	Total Loss -144.9115 (-133.1632)
2022-11-03 02:07:47,846:INFO: Batch: 14/31	Total Loss -135.3078 (-133.3093)
2022-11-03 02:07:48,355:INFO: Batch: 15/31	Total Loss -118.4516 (-132.4100)
2022-11-03 02:07:48,863:INFO: Batch: 16/31	Total Loss -141.7225 (-132.9335)
2022-11-03 02:07:49,371:INFO: Batch: 17/31	Total Loss -147.9044 (-133.7755)
2022-11-03 02:07:49,881:INFO: Batch: 18/31	Total Loss -147.2980 (-134.5086)
2022-11-03 02:07:50,390:INFO: Batch: 19/31	Total Loss -155.0057 (-135.6398)
2022-11-03 02:07:50,902:INFO: Batch: 20/31	Total Loss -147.4579 (-136.1747)
2022-11-03 02:07:51,411:INFO: Batch: 21/31	Total Loss -143.6705 (-136.5070)
2022-11-03 02:07:51,919:INFO: Batch: 22/31	Total Loss -136.6316 (-136.5118)
2022-11-03 02:07:52,427:INFO: Batch: 23/31	Total Loss -141.2801 (-136.7039)
2022-11-03 02:07:52,938:INFO: Batch: 24/31	Total Loss -137.1766 (-136.7219)
2022-11-03 02:07:53,446:INFO: Batch: 25/31	Total Loss -150.9079 (-137.2943)
2022-11-03 02:07:53,956:INFO: Batch: 26/31	Total Loss -147.7382 (-137.6913)
2022-11-03 02:07:54,462:INFO: Batch: 27/31	Total Loss -163.5085 (-138.7112)
2022-11-03 02:07:54,972:INFO: Batch: 28/31	Total Loss -175.4223 (-140.0953)
2022-11-03 02:07:55,479:INFO: Batch: 29/31	Total Loss -114.2972 (-139.2746)
2022-11-03 02:07:55,880:INFO: Batch: 30/31	Total Loss -125.9681 (-139.1328)
2022-11-03 02:07:56,026:INFO: - Computing ADE (validation o)
2022-11-03 02:07:56,711:INFO: 		 ADE on eth                       dataset:	 0.9234278202056885
2022-11-03 02:07:56,711:INFO: Average validation o:	ADE  0.9234	FDE  1.9935
2022-11-03 02:07:56,712:INFO: - Computing ADE (validation)
2022-11-03 02:07:57,021:INFO: 		 ADE on hotel                     dataset:	 0.3511437177658081
2022-11-03 02:07:57,404:INFO: 		 ADE on univ                      dataset:	 0.5232287049293518
2022-11-03 02:07:57,711:INFO: 		 ADE on zara1                     dataset:	 0.38043537735939026
2022-11-03 02:07:58,180:INFO: 		 ADE on zara2                     dataset:	 0.38003551959991455
2022-11-03 02:07:58,180:INFO: Average validation:	ADE  0.4530	FDE  0.9785
2022-11-03 02:07:58,181:INFO: - Computing ADE (training)
2022-11-03 02:07:58,771:INFO: 		 ADE on hotel                     dataset:	 0.35927629470825195
2022-11-03 02:07:59,837:INFO: 		 ADE on univ                      dataset:	 0.5204293131828308
2022-11-03 02:08:00,577:INFO: 		 ADE on zara1                     dataset:	 0.4142323434352875
2022-11-03 02:08:01,756:INFO: 		 ADE on zara2                     dataset:	 0.3653838038444519
2022-11-03 02:08:01,756:INFO: Average training:	ADE  0.4781	FDE  1.0349
2022-11-03 02:08:01,768:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_653.pth.tar
2022-11-03 02:08:01,768:INFO: 
===> EPOCH: 654 (P4)
2022-11-03 02:08:01,768:INFO: - Computing loss (training)
2022-11-03 02:08:02,918:INFO: Batch:  0/31	Total Loss -149.1690 (-149.1690)
2022-11-03 02:08:03,415:INFO: Batch:  1/31	Total Loss -143.8473 (-146.5607)
2022-11-03 02:08:03,919:INFO: Batch:  2/31	Total Loss -121.4230 (-138.9290)
2022-11-03 02:08:04,417:INFO: Batch:  3/31	Total Loss -124.9713 (-135.1236)
2022-11-03 02:08:04,916:INFO: Batch:  4/31	Total Loss -150.7524 (-138.4071)
2022-11-03 02:08:05,414:INFO: Batch:  5/31	Total Loss -126.6372 (-136.3914)
2022-11-03 02:08:05,911:INFO: Batch:  6/31	Total Loss -136.0372 (-136.3433)
2022-11-03 02:08:06,407:INFO: Batch:  7/31	Total Loss -136.0620 (-136.3056)
2022-11-03 02:08:06,904:INFO: Batch:  8/31	Total Loss -109.2941 (-133.4442)
2022-11-03 02:08:07,401:INFO: Batch:  9/31	Total Loss -87.3327 (-128.7665)
2022-11-03 02:08:07,898:INFO: Batch: 10/31	Total Loss -114.4154 (-127.3936)
2022-11-03 02:08:08,392:INFO: Batch: 11/31	Total Loss -112.2560 (-126.1740)
2022-11-03 02:08:08,891:INFO: Batch: 12/31	Total Loss -138.5931 (-127.1480)
2022-11-03 02:08:09,388:INFO: Batch: 13/31	Total Loss -140.3311 (-128.0060)
2022-11-03 02:08:09,887:INFO: Batch: 14/31	Total Loss -130.7981 (-128.1983)
2022-11-03 02:08:10,386:INFO: Batch: 15/31	Total Loss -138.8881 (-128.8625)
2022-11-03 02:08:10,891:INFO: Batch: 16/31	Total Loss -127.6977 (-128.8046)
2022-11-03 02:08:11,389:INFO: Batch: 17/31	Total Loss -136.8766 (-129.2766)
2022-11-03 02:08:11,887:INFO: Batch: 18/31	Total Loss -147.7460 (-130.3646)
2022-11-03 02:08:12,384:INFO: Batch: 19/31	Total Loss -131.4159 (-130.4138)
2022-11-03 02:08:12,887:INFO: Batch: 20/31	Total Loss -168.6451 (-132.3438)
2022-11-03 02:08:13,383:INFO: Batch: 21/31	Total Loss -156.3028 (-133.4365)
2022-11-03 02:08:13,883:INFO: Batch: 22/31	Total Loss -145.1036 (-133.9385)
2022-11-03 02:08:14,379:INFO: Batch: 23/31	Total Loss -143.3040 (-134.3082)
2022-11-03 02:08:14,877:INFO: Batch: 24/31	Total Loss -110.6369 (-133.4250)
2022-11-03 02:08:15,375:INFO: Batch: 25/31	Total Loss -59.9771 (-130.8916)
2022-11-03 02:08:15,876:INFO: Batch: 26/31	Total Loss -153.3353 (-131.7489)
2022-11-03 02:08:16,374:INFO: Batch: 27/31	Total Loss -158.5418 (-132.7851)
2022-11-03 02:08:16,873:INFO: Batch: 28/31	Total Loss -127.6597 (-132.6157)
2022-11-03 02:08:17,370:INFO: Batch: 29/31	Total Loss -151.6550 (-133.2492)
2022-11-03 02:08:17,762:INFO: Batch: 30/31	Total Loss -106.9900 (-133.0249)
2022-11-03 02:08:17,919:INFO: - Computing ADE (validation o)
2022-11-03 02:08:18,602:INFO: 		 ADE on eth                       dataset:	 0.9242469072341919
2022-11-03 02:08:18,602:INFO: Average validation o:	ADE  0.9242	FDE  1.9639
2022-11-03 02:08:18,603:INFO: - Computing ADE (validation)
2022-11-03 02:08:18,927:INFO: 		 ADE on hotel                     dataset:	 0.3712141215801239
2022-11-03 02:08:19,290:INFO: 		 ADE on univ                      dataset:	 0.5279375910758972
2022-11-03 02:08:19,585:INFO: 		 ADE on zara1                     dataset:	 0.37997153401374817
2022-11-03 02:08:20,044:INFO: 		 ADE on zara2                     dataset:	 0.39732739329338074
2022-11-03 02:08:20,045:INFO: Average validation:	ADE  0.4628	FDE  0.9941
2022-11-03 02:08:20,045:INFO: - Computing ADE (training)
2022-11-03 02:08:20,598:INFO: 		 ADE on hotel                     dataset:	 0.372162401676178
2022-11-03 02:08:21,739:INFO: 		 ADE on univ                      dataset:	 0.5268794894218445
2022-11-03 02:08:22,511:INFO: 		 ADE on zara1                     dataset:	 0.4338324964046478
2022-11-03 02:08:23,680:INFO: 		 ADE on zara2                     dataset:	 0.3858202397823334
2022-11-03 02:08:23,680:INFO: Average training:	ADE  0.4884	FDE  1.0544
2022-11-03 02:08:23,691:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_654.pth.tar
2022-11-03 02:08:23,691:INFO: 
===> EPOCH: 655 (P4)
2022-11-03 02:08:23,692:INFO: - Computing loss (training)
2022-11-03 02:08:24,832:INFO: Batch:  0/31	Total Loss -163.2105 (-163.2105)
2022-11-03 02:08:25,341:INFO: Batch:  1/31	Total Loss -140.6266 (-152.5790)
2022-11-03 02:08:25,848:INFO: Batch:  2/31	Total Loss -154.9958 (-153.3912)
2022-11-03 02:08:26,354:INFO: Batch:  3/31	Total Loss -122.2183 (-146.6071)
2022-11-03 02:08:26,863:INFO: Batch:  4/31	Total Loss -128.6190 (-143.3379)
2022-11-03 02:08:27,367:INFO: Batch:  5/31	Total Loss -138.7741 (-142.6287)
2022-11-03 02:08:27,877:INFO: Batch:  6/31	Total Loss -146.1453 (-143.1370)
2022-11-03 02:08:28,381:INFO: Batch:  7/31	Total Loss -152.2488 (-144.2858)
2022-11-03 02:08:28,887:INFO: Batch:  8/31	Total Loss -140.7333 (-143.8791)
2022-11-03 02:08:29,396:INFO: Batch:  9/31	Total Loss -140.6874 (-143.5659)
2022-11-03 02:08:29,902:INFO: Batch: 10/31	Total Loss -166.6880 (-145.7495)
2022-11-03 02:08:30,407:INFO: Batch: 11/31	Total Loss -142.2551 (-145.4572)
2022-11-03 02:08:30,922:INFO: Batch: 12/31	Total Loss -162.4980 (-146.9123)
2022-11-03 02:08:31,428:INFO: Batch: 13/31	Total Loss -157.0085 (-147.6818)
2022-11-03 02:08:31,938:INFO: Batch: 14/31	Total Loss -143.1606 (-147.3859)
2022-11-03 02:08:32,446:INFO: Batch: 15/31	Total Loss -140.3682 (-146.9712)
2022-11-03 02:08:32,958:INFO: Batch: 16/31	Total Loss -137.8487 (-146.4038)
2022-11-03 02:08:33,465:INFO: Batch: 17/31	Total Loss -130.7122 (-145.4974)
2022-11-03 02:08:33,976:INFO: Batch: 18/31	Total Loss -132.2205 (-144.7916)
2022-11-03 02:08:34,484:INFO: Batch: 19/31	Total Loss -159.4568 (-145.5171)
2022-11-03 02:08:35,071:INFO: Batch: 20/31	Total Loss -143.9302 (-145.4435)
2022-11-03 02:08:35,579:INFO: Batch: 21/31	Total Loss -110.7158 (-143.9217)
2022-11-03 02:08:36,087:INFO: Batch: 22/31	Total Loss -135.7912 (-143.5862)
2022-11-03 02:08:36,595:INFO: Batch: 23/31	Total Loss -114.1881 (-142.4715)
2022-11-03 02:08:37,104:INFO: Batch: 24/31	Total Loss -139.5622 (-142.3589)
2022-11-03 02:08:37,614:INFO: Batch: 25/31	Total Loss -140.2094 (-142.2740)
2022-11-03 02:08:38,124:INFO: Batch: 26/31	Total Loss -143.1614 (-142.3053)
2022-11-03 02:08:38,633:INFO: Batch: 27/31	Total Loss -161.8953 (-143.0670)
2022-11-03 02:08:39,140:INFO: Batch: 28/31	Total Loss -141.8641 (-143.0279)
2022-11-03 02:08:39,649:INFO: Batch: 29/31	Total Loss -156.3763 (-143.4598)
2022-11-03 02:08:40,050:INFO: Batch: 30/31	Total Loss -93.5089 (-142.9777)
2022-11-03 02:08:40,195:INFO: - Computing ADE (validation o)
2022-11-03 02:08:40,909:INFO: 		 ADE on eth                       dataset:	 0.9226075410842896
2022-11-03 02:08:40,909:INFO: Average validation o:	ADE  0.9226	FDE  1.9612
2022-11-03 02:08:40,910:INFO: - Computing ADE (validation)
2022-11-03 02:08:41,227:INFO: 		 ADE on hotel                     dataset:	 0.35222843289375305
2022-11-03 02:08:41,588:INFO: 		 ADE on univ                      dataset:	 0.5235051512718201
2022-11-03 02:08:41,878:INFO: 		 ADE on zara1                     dataset:	 0.39171603322029114
2022-11-03 02:08:42,342:INFO: 		 ADE on zara2                     dataset:	 0.38588011264801025
2022-11-03 02:08:42,343:INFO: Average validation:	ADE  0.4560	FDE  0.9844
2022-11-03 02:08:42,343:INFO: - Computing ADE (training)
2022-11-03 02:08:42,894:INFO: 		 ADE on hotel                     dataset:	 0.35786446928977966
2022-11-03 02:08:43,997:INFO: 		 ADE on univ                      dataset:	 0.5199615359306335
2022-11-03 02:08:44,723:INFO: 		 ADE on zara1                     dataset:	 0.42938461899757385
2022-11-03 02:08:45,921:INFO: 		 ADE on zara2                     dataset:	 0.3787091374397278
2022-11-03 02:08:45,922:INFO: Average training:	ADE  0.4814	FDE  1.0422
2022-11-03 02:08:45,943:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_655.pth.tar
2022-11-03 02:08:45,943:INFO: 
===> EPOCH: 656 (P4)
2022-11-03 02:08:45,943:INFO: - Computing loss (training)
2022-11-03 02:08:47,051:INFO: Batch:  0/31	Total Loss -139.1180 (-139.1180)
2022-11-03 02:08:47,556:INFO: Batch:  1/31	Total Loss -132.8444 (-135.9555)
2022-11-03 02:08:48,059:INFO: Batch:  2/31	Total Loss -134.4093 (-135.3808)
2022-11-03 02:08:48,554:INFO: Batch:  3/31	Total Loss -124.9684 (-132.7403)
2022-11-03 02:08:49,051:INFO: Batch:  4/31	Total Loss -159.3410 (-138.1949)
2022-11-03 02:08:49,552:INFO: Batch:  5/31	Total Loss -126.9986 (-136.4496)
2022-11-03 02:08:50,050:INFO: Batch:  6/31	Total Loss -145.9360 (-137.8362)
2022-11-03 02:08:50,550:INFO: Batch:  7/31	Total Loss -146.3847 (-138.9092)
2022-11-03 02:08:51,049:INFO: Batch:  8/31	Total Loss -148.7305 (-139.9915)
2022-11-03 02:08:51,546:INFO: Batch:  9/31	Total Loss -143.3708 (-140.3533)
2022-11-03 02:08:52,045:INFO: Batch: 10/31	Total Loss -144.1658 (-140.6530)
2022-11-03 02:08:52,542:INFO: Batch: 11/31	Total Loss -159.1039 (-142.2998)
2022-11-03 02:08:53,045:INFO: Batch: 12/31	Total Loss -149.6263 (-142.8688)
2022-11-03 02:08:53,546:INFO: Batch: 13/31	Total Loss -147.0419 (-143.1632)
2022-11-03 02:08:54,046:INFO: Batch: 14/31	Total Loss -168.5186 (-145.1486)
2022-11-03 02:08:54,545:INFO: Batch: 15/31	Total Loss -143.9300 (-145.0705)
2022-11-03 02:08:55,044:INFO: Batch: 16/31	Total Loss -166.9114 (-146.3396)
2022-11-03 02:08:55,543:INFO: Batch: 17/31	Total Loss -139.5693 (-146.0045)
2022-11-03 02:08:56,044:INFO: Batch: 18/31	Total Loss -148.2347 (-146.1295)
2022-11-03 02:08:56,543:INFO: Batch: 19/31	Total Loss -168.5801 (-147.2810)
2022-11-03 02:08:57,041:INFO: Batch: 20/31	Total Loss -163.2129 (-148.0889)
2022-11-03 02:08:57,541:INFO: Batch: 21/31	Total Loss -126.5061 (-147.1514)
2022-11-03 02:08:58,040:INFO: Batch: 22/31	Total Loss -154.6993 (-147.4563)
2022-11-03 02:08:58,535:INFO: Batch: 23/31	Total Loss -158.9134 (-147.9185)
2022-11-03 02:08:59,031:INFO: Batch: 24/31	Total Loss -145.1494 (-147.8121)
2022-11-03 02:08:59,528:INFO: Batch: 25/31	Total Loss -146.0800 (-147.7514)
2022-11-03 02:09:00,027:INFO: Batch: 26/31	Total Loss -136.2299 (-147.3155)
2022-11-03 02:09:00,527:INFO: Batch: 27/31	Total Loss -143.5869 (-147.1843)
2022-11-03 02:09:01,027:INFO: Batch: 28/31	Total Loss -160.1866 (-147.6559)
2022-11-03 02:09:01,527:INFO: Batch: 29/31	Total Loss -147.5862 (-147.6535)
2022-11-03 02:09:01,921:INFO: Batch: 30/31	Total Loss -134.8776 (-147.4972)
2022-11-03 02:09:02,067:INFO: - Computing ADE (validation o)
2022-11-03 02:09:02,767:INFO: 		 ADE on eth                       dataset:	 0.9119352698326111
2022-11-03 02:09:02,767:INFO: Average validation o:	ADE  0.9119	FDE  1.9648
2022-11-03 02:09:02,776:INFO: - Computing ADE (validation)
2022-11-03 02:09:03,076:INFO: 		 ADE on hotel                     dataset:	 0.35820943117141724
2022-11-03 02:09:03,432:INFO: 		 ADE on univ                      dataset:	 0.5265451669692993
2022-11-03 02:09:03,730:INFO: 		 ADE on zara1                     dataset:	 0.416705846786499
2022-11-03 02:09:04,224:INFO: 		 ADE on zara2                     dataset:	 0.38383162021636963
2022-11-03 02:09:04,224:INFO: Average validation:	ADE  0.4586	FDE  0.9851
2022-11-03 02:09:04,225:INFO: - Computing ADE (training)
2022-11-03 02:09:04,774:INFO: 		 ADE on hotel                     dataset:	 0.36128169298171997
2022-11-03 02:09:05,850:INFO: 		 ADE on univ                      dataset:	 0.5215636491775513
2022-11-03 02:09:06,578:INFO: 		 ADE on zara1                     dataset:	 0.4174748659133911
2022-11-03 02:09:07,748:INFO: 		 ADE on zara2                     dataset:	 0.36610665917396545
2022-11-03 02:09:07,748:INFO: Average training:	ADE  0.4793	FDE  1.0316
2022-11-03 02:09:07,760:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_656.pth.tar
2022-11-03 02:09:07,760:INFO: 
===> EPOCH: 657 (P4)
2022-11-03 02:09:07,760:INFO: - Computing loss (training)
2022-11-03 02:09:08,877:INFO: Batch:  0/31	Total Loss -160.6882 (-160.6882)
2022-11-03 02:09:09,371:INFO: Batch:  1/31	Total Loss -160.8467 (-160.7677)
2022-11-03 02:09:09,862:INFO: Batch:  2/31	Total Loss -172.4175 (-164.6832)
2022-11-03 02:09:10,353:INFO: Batch:  3/31	Total Loss -152.3347 (-161.7309)
2022-11-03 02:09:10,845:INFO: Batch:  4/31	Total Loss -167.8436 (-163.0566)
2022-11-03 02:09:11,337:INFO: Batch:  5/31	Total Loss -121.3211 (-156.4807)
2022-11-03 02:09:11,825:INFO: Batch:  6/31	Total Loss -167.0441 (-157.9434)
2022-11-03 02:09:12,312:INFO: Batch:  7/31	Total Loss -105.4692 (-151.6776)
2022-11-03 02:09:12,800:INFO: Batch:  8/31	Total Loss -161.4866 (-152.7358)
2022-11-03 02:09:13,288:INFO: Batch:  9/31	Total Loss -111.4609 (-148.9455)
2022-11-03 02:09:13,777:INFO: Batch: 10/31	Total Loss -148.2234 (-148.8832)
2022-11-03 02:09:14,266:INFO: Batch: 11/31	Total Loss -164.2922 (-150.2555)
2022-11-03 02:09:14,756:INFO: Batch: 12/31	Total Loss -160.0647 (-151.0344)
2022-11-03 02:09:15,247:INFO: Batch: 13/31	Total Loss -160.1418 (-151.6636)
2022-11-03 02:09:15,741:INFO: Batch: 14/31	Total Loss -142.8771 (-151.1534)
2022-11-03 02:09:16,235:INFO: Batch: 15/31	Total Loss -163.0221 (-151.8772)
2022-11-03 02:09:16,728:INFO: Batch: 16/31	Total Loss -166.6185 (-152.7608)
2022-11-03 02:09:17,220:INFO: Batch: 17/31	Total Loss -166.0331 (-153.5342)
2022-11-03 02:09:17,711:INFO: Batch: 18/31	Total Loss -142.8951 (-152.9882)
2022-11-03 02:09:18,205:INFO: Batch: 19/31	Total Loss -133.7095 (-151.9632)
2022-11-03 02:09:18,699:INFO: Batch: 20/31	Total Loss -160.7800 (-152.4278)
2022-11-03 02:09:19,190:INFO: Batch: 21/31	Total Loss -151.8351 (-152.3999)
2022-11-03 02:09:19,690:INFO: Batch: 22/31	Total Loss -182.8446 (-153.7413)
2022-11-03 02:09:20,174:INFO: Batch: 23/31	Total Loss -139.1821 (-153.2481)
2022-11-03 02:09:20,665:INFO: Batch: 24/31	Total Loss -183.1590 (-154.4965)
2022-11-03 02:09:21,155:INFO: Batch: 25/31	Total Loss -160.6532 (-154.7212)
2022-11-03 02:09:21,645:INFO: Batch: 26/31	Total Loss -155.1025 (-154.7354)
2022-11-03 02:09:22,136:INFO: Batch: 27/31	Total Loss -172.4993 (-155.4337)
2022-11-03 02:09:22,628:INFO: Batch: 28/31	Total Loss -145.5481 (-155.1018)
2022-11-03 02:09:23,119:INFO: Batch: 29/31	Total Loss -182.8049 (-156.2055)
2022-11-03 02:09:23,507:INFO: Batch: 30/31	Total Loss -123.2165 (-155.8928)
2022-11-03 02:09:23,648:INFO: - Computing ADE (validation o)
2022-11-03 02:09:24,338:INFO: 		 ADE on eth                       dataset:	 0.9136883020401001
2022-11-03 02:09:24,338:INFO: Average validation o:	ADE  0.9137	FDE  1.9367
2022-11-03 02:09:24,339:INFO: - Computing ADE (validation)
2022-11-03 02:09:24,655:INFO: 		 ADE on hotel                     dataset:	 0.3514791429042816
2022-11-03 02:09:25,011:INFO: 		 ADE on univ                      dataset:	 0.5241516828536987
2022-11-03 02:09:25,312:INFO: 		 ADE on zara1                     dataset:	 0.39556872844696045
2022-11-03 02:09:25,793:INFO: 		 ADE on zara2                     dataset:	 0.3830196261405945
2022-11-03 02:09:25,793:INFO: Average validation:	ADE  0.4555	FDE  0.9805
2022-11-03 02:09:25,794:INFO: - Computing ADE (training)
2022-11-03 02:09:26,383:INFO: 		 ADE on hotel                     dataset:	 0.36412593722343445
2022-11-03 02:09:27,420:INFO: 		 ADE on univ                      dataset:	 0.5191127061843872
2022-11-03 02:09:28,166:INFO: 		 ADE on zara1                     dataset:	 0.42571359872817993
2022-11-03 02:09:29,335:INFO: 		 ADE on zara2                     dataset:	 0.3718813955783844
2022-11-03 02:09:29,336:INFO: Average training:	ADE  0.4793	FDE  1.0333
2022-11-03 02:09:29,348:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_657.pth.tar
2022-11-03 02:09:29,348:INFO: 
===> EPOCH: 658 (P4)
2022-11-03 02:09:29,349:INFO: - Computing loss (training)
2022-11-03 02:09:30,484:INFO: Batch:  0/31	Total Loss -152.9133 (-152.9133)
2022-11-03 02:09:30,993:INFO: Batch:  1/31	Total Loss -168.6161 (-160.8797)
2022-11-03 02:09:31,499:INFO: Batch:  2/31	Total Loss -155.3729 (-159.1832)
2022-11-03 02:09:32,000:INFO: Batch:  3/31	Total Loss -166.2488 (-160.8588)
2022-11-03 02:09:32,582:INFO: Batch:  4/31	Total Loss -158.5518 (-160.3662)
2022-11-03 02:09:33,087:INFO: Batch:  5/31	Total Loss -165.2063 (-161.2254)
2022-11-03 02:09:33,589:INFO: Batch:  6/31	Total Loss -131.7195 (-156.8654)
2022-11-03 02:09:34,086:INFO: Batch:  7/31	Total Loss -157.1346 (-156.8957)
2022-11-03 02:09:34,584:INFO: Batch:  8/31	Total Loss -170.2813 (-158.2929)
2022-11-03 02:09:35,082:INFO: Batch:  9/31	Total Loss -157.1274 (-158.1756)
2022-11-03 02:09:35,581:INFO: Batch: 10/31	Total Loss -170.6281 (-159.3235)
2022-11-03 02:09:36,082:INFO: Batch: 11/31	Total Loss -176.8568 (-160.8188)
2022-11-03 02:09:36,584:INFO: Batch: 12/31	Total Loss -162.7772 (-160.9645)
2022-11-03 02:09:37,089:INFO: Batch: 13/31	Total Loss -171.0927 (-161.7349)
2022-11-03 02:09:37,590:INFO: Batch: 14/31	Total Loss -173.6606 (-162.5740)
2022-11-03 02:09:38,096:INFO: Batch: 15/31	Total Loss -160.6776 (-162.4396)
2022-11-03 02:09:38,599:INFO: Batch: 16/31	Total Loss -180.3922 (-163.6686)
2022-11-03 02:09:39,105:INFO: Batch: 17/31	Total Loss -172.1470 (-164.0873)
2022-11-03 02:09:39,607:INFO: Batch: 18/31	Total Loss -174.8486 (-164.7172)
2022-11-03 02:09:40,109:INFO: Batch: 19/31	Total Loss -177.3735 (-165.4012)
2022-11-03 02:09:40,612:INFO: Batch: 20/31	Total Loss -151.9799 (-164.7666)
2022-11-03 02:09:41,119:INFO: Batch: 21/31	Total Loss -154.9929 (-164.3801)
2022-11-03 02:09:41,623:INFO: Batch: 22/31	Total Loss -182.1574 (-165.2657)
2022-11-03 02:09:42,125:INFO: Batch: 23/31	Total Loss -169.2553 (-165.4410)
2022-11-03 02:09:42,625:INFO: Batch: 24/31	Total Loss -141.5106 (-164.5790)
2022-11-03 02:09:43,128:INFO: Batch: 25/31	Total Loss -182.1054 (-165.2744)
2022-11-03 02:09:43,629:INFO: Batch: 26/31	Total Loss -143.4993 (-164.5003)
2022-11-03 02:09:44,132:INFO: Batch: 27/31	Total Loss -189.4259 (-165.4875)
2022-11-03 02:09:44,635:INFO: Batch: 28/31	Total Loss -159.5075 (-165.2859)
2022-11-03 02:09:45,135:INFO: Batch: 29/31	Total Loss -165.0090 (-165.2772)
2022-11-03 02:09:45,532:INFO: Batch: 30/31	Total Loss -123.3707 (-164.9559)
2022-11-03 02:09:45,686:INFO: - Computing ADE (validation o)
2022-11-03 02:09:46,364:INFO: 		 ADE on eth                       dataset:	 0.9519269466400146
2022-11-03 02:09:46,365:INFO: Average validation o:	ADE  0.9519	FDE  2.0773
2022-11-03 02:09:46,365:INFO: - Computing ADE (validation)
2022-11-03 02:09:46,664:INFO: 		 ADE on hotel                     dataset:	 0.37596645951271057
2022-11-03 02:09:47,022:INFO: 		 ADE on univ                      dataset:	 0.5347165465354919
2022-11-03 02:09:47,310:INFO: 		 ADE on zara1                     dataset:	 0.3802613317966461
2022-11-03 02:09:47,790:INFO: 		 ADE on zara2                     dataset:	 0.40945231914520264
2022-11-03 02:09:47,791:INFO: Average validation:	ADE  0.4711	FDE  1.0203
2022-11-03 02:09:47,791:INFO: - Computing ADE (training)
2022-11-03 02:09:48,367:INFO: 		 ADE on hotel                     dataset:	 0.37889885902404785
2022-11-03 02:09:49,453:INFO: 		 ADE on univ                      dataset:	 0.5364882946014404
2022-11-03 02:09:50,191:INFO: 		 ADE on zara1                     dataset:	 0.42545372247695923
2022-11-03 02:09:51,351:INFO: 		 ADE on zara2                     dataset:	 0.3923218846321106
2022-11-03 02:09:51,352:INFO: Average training:	ADE  0.4961	FDE  1.0761
2022-11-03 02:09:51,363:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_658.pth.tar
2022-11-03 02:09:51,363:INFO: 
===> EPOCH: 659 (P4)
2022-11-03 02:09:51,363:INFO: - Computing loss (training)
2022-11-03 02:09:52,445:INFO: Batch:  0/31	Total Loss -175.8833 (-175.8833)
2022-11-03 02:09:52,951:INFO: Batch:  1/31	Total Loss -173.1073 (-174.4345)
2022-11-03 02:09:53,452:INFO: Batch:  2/31	Total Loss -115.1751 (-155.9212)
2022-11-03 02:09:53,952:INFO: Batch:  3/31	Total Loss -159.5391 (-156.7987)
2022-11-03 02:09:54,446:INFO: Batch:  4/31	Total Loss -188.3779 (-164.0565)
2022-11-03 02:09:54,952:INFO: Batch:  5/31	Total Loss -191.5774 (-169.1392)
2022-11-03 02:09:55,450:INFO: Batch:  6/31	Total Loss -193.9485 (-172.7105)
2022-11-03 02:09:55,951:INFO: Batch:  7/31	Total Loss -174.7012 (-172.9493)
2022-11-03 02:09:56,448:INFO: Batch:  8/31	Total Loss -152.7183 (-170.7294)
2022-11-03 02:09:56,947:INFO: Batch:  9/31	Total Loss -193.0367 (-173.0046)
2022-11-03 02:09:57,442:INFO: Batch: 10/31	Total Loss -151.4079 (-171.1495)
2022-11-03 02:09:57,940:INFO: Batch: 11/31	Total Loss -157.9818 (-170.0368)
2022-11-03 02:09:58,440:INFO: Batch: 12/31	Total Loss -154.5686 (-168.8148)
2022-11-03 02:09:58,939:INFO: Batch: 13/31	Total Loss -169.9866 (-168.8988)
2022-11-03 02:09:59,439:INFO: Batch: 14/31	Total Loss -124.1204 (-166.3771)
2022-11-03 02:09:59,938:INFO: Batch: 15/31	Total Loss -180.1386 (-167.3066)
2022-11-03 02:10:00,436:INFO: Batch: 16/31	Total Loss -154.2591 (-166.5629)
2022-11-03 02:10:00,942:INFO: Batch: 17/31	Total Loss -184.4951 (-167.5887)
2022-11-03 02:10:01,441:INFO: Batch: 18/31	Total Loss -151.9466 (-166.8514)
2022-11-03 02:10:01,943:INFO: Batch: 19/31	Total Loss -170.4312 (-167.0275)
2022-11-03 02:10:02,444:INFO: Batch: 20/31	Total Loss -185.4990 (-167.8469)
2022-11-03 02:10:02,946:INFO: Batch: 21/31	Total Loss -170.5552 (-167.9740)
2022-11-03 02:10:03,444:INFO: Batch: 22/31	Total Loss -184.5788 (-168.6982)
2022-11-03 02:10:03,944:INFO: Batch: 23/31	Total Loss -173.1708 (-168.8859)
2022-11-03 02:10:04,436:INFO: Batch: 24/31	Total Loss -177.4850 (-169.2823)
2022-11-03 02:10:04,930:INFO: Batch: 25/31	Total Loss 94.4811 (-159.0212)
2022-11-03 02:10:05,421:INFO: Batch: 26/31	Total Loss -172.3072 (-159.5240)
2022-11-03 02:10:05,917:INFO: Batch: 27/31	Total Loss -159.2540 (-159.5135)
2022-11-03 02:10:06,409:INFO: Batch: 28/31	Total Loss -153.4852 (-159.2905)
2022-11-03 02:10:06,904:INFO: Batch: 29/31	Total Loss -167.3195 (-159.5488)
2022-11-03 02:10:07,291:INFO: Batch: 30/31	Total Loss -138.9325 (-159.3559)
2022-11-03 02:10:07,440:INFO: - Computing ADE (validation o)
2022-11-03 02:10:08,128:INFO: 		 ADE on eth                       dataset:	 0.9471369981765747
2022-11-03 02:10:08,129:INFO: Average validation o:	ADE  0.9471	FDE  2.0067
2022-11-03 02:10:08,129:INFO: - Computing ADE (validation)
2022-11-03 02:10:08,443:INFO: 		 ADE on hotel                     dataset:	 0.4085067808628082
2022-11-03 02:10:08,825:INFO: 		 ADE on univ                      dataset:	 0.5616222023963928
2022-11-03 02:10:09,103:INFO: 		 ADE on zara1                     dataset:	 0.4262073040008545
2022-11-03 02:10:09,567:INFO: 		 ADE on zara2                     dataset:	 0.4331144690513611
2022-11-03 02:10:09,567:INFO: Average validation:	ADE  0.4982	FDE  1.0496
2022-11-03 02:10:09,568:INFO: - Computing ADE (training)
2022-11-03 02:10:10,122:INFO: 		 ADE on hotel                     dataset:	 0.4128572642803192
2022-11-03 02:10:11,216:INFO: 		 ADE on univ                      dataset:	 0.5544124245643616
2022-11-03 02:10:11,958:INFO: 		 ADE on zara1                     dataset:	 0.4602009057998657
2022-11-03 02:10:13,119:INFO: 		 ADE on zara2                     dataset:	 0.42097315192222595
2022-11-03 02:10:13,119:INFO: Average training:	ADE  0.5177	FDE  1.0941
2022-11-03 02:10:13,130:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_659.pth.tar
2022-11-03 02:10:13,130:INFO: 
===> EPOCH: 660 (P4)
2022-11-03 02:10:13,131:INFO: - Computing loss (training)
2022-11-03 02:10:14,242:INFO: Batch:  0/31	Total Loss -164.5447 (-164.5447)
2022-11-03 02:10:14,738:INFO: Batch:  1/31	Total Loss -164.4445 (-164.4941)
2022-11-03 02:10:15,230:INFO: Batch:  2/31	Total Loss -165.1790 (-164.7158)
2022-11-03 02:10:15,720:INFO: Batch:  3/31	Total Loss -167.7490 (-165.4940)
2022-11-03 02:10:16,216:INFO: Batch:  4/31	Total Loss -129.1585 (-157.9468)
2022-11-03 02:10:16,705:INFO: Batch:  5/31	Total Loss -139.4376 (-155.2888)
2022-11-03 02:10:17,194:INFO: Batch:  6/31	Total Loss -172.2533 (-158.0122)
2022-11-03 02:10:17,686:INFO: Batch:  7/31	Total Loss -155.2776 (-157.6838)
2022-11-03 02:10:18,175:INFO: Batch:  8/31	Total Loss -172.1564 (-159.4722)
2022-11-03 02:10:18,665:INFO: Batch:  9/31	Total Loss -128.7768 (-156.3891)
2022-11-03 02:10:19,155:INFO: Batch: 10/31	Total Loss -175.0113 (-158.2441)
2022-11-03 02:10:19,647:INFO: Batch: 11/31	Total Loss -165.7659 (-158.9554)
2022-11-03 02:10:20,138:INFO: Batch: 12/31	Total Loss -153.9954 (-158.5594)
2022-11-03 02:10:20,633:INFO: Batch: 13/31	Total Loss -148.8969 (-157.8889)
2022-11-03 02:10:21,126:INFO: Batch: 14/31	Total Loss -177.8414 (-159.2853)
2022-11-03 02:10:21,622:INFO: Batch: 15/31	Total Loss -186.3352 (-161.1941)
2022-11-03 02:10:22,115:INFO: Batch: 16/31	Total Loss -151.2330 (-160.6581)
2022-11-03 02:10:22,609:INFO: Batch: 17/31	Total Loss -194.8659 (-162.8153)
2022-11-03 02:10:23,103:INFO: Batch: 18/31	Total Loss -140.9707 (-161.7502)
2022-11-03 02:10:23,597:INFO: Batch: 19/31	Total Loss -165.6987 (-161.9576)
2022-11-03 02:10:24,089:INFO: Batch: 20/31	Total Loss -182.0715 (-162.9283)
2022-11-03 02:10:24,582:INFO: Batch: 21/31	Total Loss -167.8830 (-163.1426)
2022-11-03 02:10:25,149:INFO: Batch: 22/31	Total Loss -137.0910 (-162.1999)
2022-11-03 02:10:25,642:INFO: Batch: 23/31	Total Loss -189.4026 (-163.3133)
2022-11-03 02:10:26,133:INFO: Batch: 24/31	Total Loss -176.5662 (-163.8797)
2022-11-03 02:10:26,624:INFO: Batch: 25/31	Total Loss -180.5535 (-164.5649)
2022-11-03 02:10:27,116:INFO: Batch: 26/31	Total Loss -174.4118 (-164.9414)
2022-11-03 02:10:27,607:INFO: Batch: 27/31	Total Loss -151.6263 (-164.4930)
2022-11-03 02:10:28,097:INFO: Batch: 28/31	Total Loss -183.2520 (-165.1856)
2022-11-03 02:10:28,588:INFO: Batch: 29/31	Total Loss -161.2788 (-165.0637)
2022-11-03 02:10:28,977:INFO: Batch: 30/31	Total Loss -125.9867 (-164.7037)
2022-11-03 02:10:29,132:INFO: - Computing ADE (validation o)
2022-11-03 02:10:29,816:INFO: 		 ADE on eth                       dataset:	 0.9216448664665222
2022-11-03 02:10:29,816:INFO: Average validation o:	ADE  0.9216	FDE  1.9537
2022-11-03 02:10:29,817:INFO: - Computing ADE (validation)
2022-11-03 02:10:30,124:INFO: 		 ADE on hotel                     dataset:	 0.348177969455719
2022-11-03 02:10:30,495:INFO: 		 ADE on univ                      dataset:	 0.523132860660553
2022-11-03 02:10:30,791:INFO: 		 ADE on zara1                     dataset:	 0.38456785678863525
2022-11-03 02:10:31,259:INFO: 		 ADE on zara2                     dataset:	 0.3858537971973419
2022-11-03 02:10:31,259:INFO: Average validation:	ADE  0.4551	FDE  0.9779
2022-11-03 02:10:31,260:INFO: - Computing ADE (training)
2022-11-03 02:10:31,828:INFO: 		 ADE on hotel                     dataset:	 0.3514750003814697
2022-11-03 02:10:32,884:INFO: 		 ADE on univ                      dataset:	 0.5185603499412537
2022-11-03 02:10:33,608:INFO: 		 ADE on zara1                     dataset:	 0.432319313287735
2022-11-03 02:10:34,835:INFO: 		 ADE on zara2                     dataset:	 0.3789350688457489
2022-11-03 02:10:34,835:INFO: Average training:	ADE  0.4805	FDE  1.0352
2022-11-03 02:10:34,847:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_660.pth.tar
2022-11-03 02:10:34,847:INFO: 
===> EPOCH: 661 (P4)
2022-11-03 02:10:34,847:INFO: - Computing loss (training)
2022-11-03 02:10:35,959:INFO: Batch:  0/31	Total Loss -182.7384 (-182.7384)
2022-11-03 02:10:36,454:INFO: Batch:  1/31	Total Loss -193.7628 (-188.8681)
2022-11-03 02:10:36,949:INFO: Batch:  2/31	Total Loss -180.8228 (-186.3096)
2022-11-03 02:10:37,440:INFO: Batch:  3/31	Total Loss -167.9903 (-181.9420)
2022-11-03 02:10:37,932:INFO: Batch:  4/31	Total Loss -139.3448 (-175.2001)
2022-11-03 02:10:38,426:INFO: Batch:  5/31	Total Loss -171.4402 (-174.5598)
2022-11-03 02:10:38,922:INFO: Batch:  6/31	Total Loss -161.8929 (-172.8183)
2022-11-03 02:10:39,416:INFO: Batch:  7/31	Total Loss -120.5410 (-166.4824)
2022-11-03 02:10:39,907:INFO: Batch:  8/31	Total Loss -170.1844 (-166.8995)
2022-11-03 02:10:40,398:INFO: Batch:  9/31	Total Loss -177.9974 (-167.9751)
2022-11-03 02:10:40,893:INFO: Batch: 10/31	Total Loss -162.3222 (-167.4615)
2022-11-03 02:10:41,386:INFO: Batch: 11/31	Total Loss -187.5223 (-169.2605)
2022-11-03 02:10:41,880:INFO: Batch: 12/31	Total Loss -170.4465 (-169.3477)
2022-11-03 02:10:42,375:INFO: Batch: 13/31	Total Loss -146.1911 (-167.8512)
2022-11-03 02:10:42,871:INFO: Batch: 14/31	Total Loss -168.7110 (-167.9057)
2022-11-03 02:10:43,365:INFO: Batch: 15/31	Total Loss -155.2167 (-167.1322)
2022-11-03 02:10:43,860:INFO: Batch: 16/31	Total Loss -152.0703 (-166.3212)
2022-11-03 02:10:44,355:INFO: Batch: 17/31	Total Loss -153.1750 (-165.5959)
2022-11-03 02:10:44,850:INFO: Batch: 18/31	Total Loss -135.2182 (-164.0323)
2022-11-03 02:10:45,343:INFO: Batch: 19/31	Total Loss -163.1439 (-163.9853)
2022-11-03 02:10:45,837:INFO: Batch: 20/31	Total Loss -140.1850 (-162.9252)
2022-11-03 02:10:46,331:INFO: Batch: 21/31	Total Loss -167.2395 (-163.1241)
2022-11-03 02:10:46,830:INFO: Batch: 22/31	Total Loss -175.8753 (-163.7301)
2022-11-03 02:10:47,322:INFO: Batch: 23/31	Total Loss -158.9575 (-163.5364)
2022-11-03 02:10:47,816:INFO: Batch: 24/31	Total Loss -173.6256 (-163.9162)
2022-11-03 02:10:48,308:INFO: Batch: 25/31	Total Loss -146.8875 (-163.3287)
2022-11-03 02:10:48,800:INFO: Batch: 26/31	Total Loss -175.6975 (-163.8319)
2022-11-03 02:10:49,294:INFO: Batch: 27/31	Total Loss -153.2189 (-163.4159)
2022-11-03 02:10:49,786:INFO: Batch: 28/31	Total Loss -133.3505 (-162.4158)
2022-11-03 02:10:50,280:INFO: Batch: 29/31	Total Loss -158.1405 (-162.2747)
2022-11-03 02:10:50,669:INFO: Batch: 30/31	Total Loss -116.8075 (-161.9093)
2022-11-03 02:10:50,810:INFO: - Computing ADE (validation o)
2022-11-03 02:10:51,501:INFO: 		 ADE on eth                       dataset:	 0.9302218556404114
2022-11-03 02:10:51,501:INFO: Average validation o:	ADE  0.9302	FDE  2.0088
2022-11-03 02:10:51,502:INFO: - Computing ADE (validation)
2022-11-03 02:10:51,815:INFO: 		 ADE on hotel                     dataset:	 0.36530977487564087
2022-11-03 02:10:52,178:INFO: 		 ADE on univ                      dataset:	 0.5269755721092224
2022-11-03 02:10:52,480:INFO: 		 ADE on zara1                     dataset:	 0.37887418270111084
2022-11-03 02:10:52,969:INFO: 		 ADE on zara2                     dataset:	 0.38970819115638733
2022-11-03 02:10:52,969:INFO: Average validation:	ADE  0.4592	FDE  0.9826
2022-11-03 02:10:52,970:INFO: - Computing ADE (training)
2022-11-03 02:10:53,565:INFO: 		 ADE on hotel                     dataset:	 0.3678934574127197
2022-11-03 02:10:54,619:INFO: 		 ADE on univ                      dataset:	 0.5256827473640442
2022-11-03 02:10:55,390:INFO: 		 ADE on zara1                     dataset:	 0.4202309250831604
2022-11-03 02:10:56,549:INFO: 		 ADE on zara2                     dataset:	 0.3757973611354828
2022-11-03 02:10:56,550:INFO: Average training:	ADE  0.4845	FDE  1.0408
2022-11-03 02:10:56,561:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_661.pth.tar
2022-11-03 02:10:56,561:INFO: 
===> EPOCH: 662 (P4)
2022-11-03 02:10:56,561:INFO: - Computing loss (training)
2022-11-03 02:10:57,708:INFO: Batch:  0/31	Total Loss -95.2810 (-95.2810)
2022-11-03 02:10:58,216:INFO: Batch:  1/31	Total Loss -173.3980 (-136.6175)
2022-11-03 02:10:58,718:INFO: Batch:  2/31	Total Loss -158.4155 (-143.7748)
2022-11-03 02:10:59,217:INFO: Batch:  3/31	Total Loss -164.1982 (-149.2558)
2022-11-03 02:10:59,711:INFO: Batch:  4/31	Total Loss -184.4988 (-156.7981)
2022-11-03 02:11:00,211:INFO: Batch:  5/31	Total Loss -142.0091 (-154.4193)
2022-11-03 02:11:00,710:INFO: Batch:  6/31	Total Loss -147.9077 (-153.4717)
2022-11-03 02:11:01,210:INFO: Batch:  7/31	Total Loss -162.6340 (-154.6571)
2022-11-03 02:11:01,707:INFO: Batch:  8/31	Total Loss -187.3040 (-158.4786)
2022-11-03 02:11:02,202:INFO: Batch:  9/31	Total Loss -169.9614 (-159.5664)
2022-11-03 02:11:02,697:INFO: Batch: 10/31	Total Loss -167.2926 (-160.3464)
2022-11-03 02:11:03,194:INFO: Batch: 11/31	Total Loss -156.2747 (-160.0247)
2022-11-03 02:11:03,694:INFO: Batch: 12/31	Total Loss -170.8597 (-160.9103)
2022-11-03 02:11:04,193:INFO: Batch: 13/31	Total Loss -138.9109 (-159.5866)
2022-11-03 02:11:04,693:INFO: Batch: 14/31	Total Loss -175.0309 (-160.6883)
2022-11-03 02:11:05,192:INFO: Batch: 15/31	Total Loss -155.6828 (-160.3518)
2022-11-03 02:11:05,691:INFO: Batch: 16/31	Total Loss -129.3269 (-158.8025)
2022-11-03 02:11:06,191:INFO: Batch: 17/31	Total Loss -150.4698 (-158.4048)
2022-11-03 02:11:06,690:INFO: Batch: 18/31	Total Loss -189.5347 (-160.2735)
2022-11-03 02:11:07,188:INFO: Batch: 19/31	Total Loss -169.0644 (-160.6919)
2022-11-03 02:11:07,690:INFO: Batch: 20/31	Total Loss -158.4735 (-160.5913)
2022-11-03 02:11:08,187:INFO: Batch: 21/31	Total Loss -167.9481 (-160.9330)
2022-11-03 02:11:08,686:INFO: Batch: 22/31	Total Loss -167.4864 (-161.2194)
2022-11-03 02:11:09,184:INFO: Batch: 23/31	Total Loss -162.8584 (-161.2877)
2022-11-03 02:11:09,686:INFO: Batch: 24/31	Total Loss -175.2012 (-161.8804)
2022-11-03 02:11:10,186:INFO: Batch: 25/31	Total Loss -165.9674 (-162.0446)
2022-11-03 02:11:10,687:INFO: Batch: 26/31	Total Loss -168.3783 (-162.2846)
2022-11-03 02:11:11,187:INFO: Batch: 27/31	Total Loss -173.9233 (-162.6732)
2022-11-03 02:11:11,687:INFO: Batch: 28/31	Total Loss -172.4559 (-163.0212)
2022-11-03 02:11:12,186:INFO: Batch: 29/31	Total Loss -180.9057 (-163.6644)
2022-11-03 02:11:12,580:INFO: Batch: 30/31	Total Loss -129.1662 (-163.3245)
2022-11-03 02:11:12,723:INFO: - Computing ADE (validation o)
2022-11-03 02:11:13,469:INFO: 		 ADE on eth                       dataset:	 0.916904866695404
2022-11-03 02:11:13,469:INFO: Average validation o:	ADE  0.9169	FDE  1.9488
2022-11-03 02:11:13,470:INFO: - Computing ADE (validation)
2022-11-03 02:11:13,788:INFO: 		 ADE on hotel                     dataset:	 0.3620360791683197
2022-11-03 02:11:14,162:INFO: 		 ADE on univ                      dataset:	 0.526725709438324
2022-11-03 02:11:14,453:INFO: 		 ADE on zara1                     dataset:	 0.3945387601852417
2022-11-03 02:11:14,931:INFO: 		 ADE on zara2                     dataset:	 0.388090044260025
2022-11-03 02:11:14,932:INFO: Average validation:	ADE  0.4592	FDE  0.9925
2022-11-03 02:11:14,932:INFO: - Computing ADE (training)
2022-11-03 02:11:15,511:INFO: 		 ADE on hotel                     dataset:	 0.37265706062316895
2022-11-03 02:11:16,590:INFO: 		 ADE on univ                      dataset:	 0.522583544254303
2022-11-03 02:11:17,338:INFO: 		 ADE on zara1                     dataset:	 0.42347458004951477
2022-11-03 02:11:18,535:INFO: 		 ADE on zara2                     dataset:	 0.376128613948822
2022-11-03 02:11:18,535:INFO: Average training:	ADE  0.4827	FDE  1.0447
2022-11-03 02:11:18,547:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_662.pth.tar
2022-11-03 02:11:18,547:INFO: 
===> EPOCH: 663 (P4)
2022-11-03 02:11:18,547:INFO: - Computing loss (training)
2022-11-03 02:11:19,678:INFO: Batch:  0/31	Total Loss -183.6070 (-183.6070)
2022-11-03 02:11:20,183:INFO: Batch:  1/31	Total Loss -147.3180 (-166.1777)
2022-11-03 02:11:20,686:INFO: Batch:  2/31	Total Loss -186.5823 (-173.7499)
2022-11-03 02:11:21,186:INFO: Batch:  3/31	Total Loss -175.5545 (-174.2063)
2022-11-03 02:11:21,684:INFO: Batch:  4/31	Total Loss -183.6459 (-176.2676)
2022-11-03 02:11:22,175:INFO: Batch:  5/31	Total Loss -172.3110 (-175.5795)
2022-11-03 02:11:22,667:INFO: Batch:  6/31	Total Loss -185.9385 (-177.1384)
2022-11-03 02:11:23,153:INFO: Batch:  7/31	Total Loss -160.7875 (-175.1665)
2022-11-03 02:11:23,645:INFO: Batch:  8/31	Total Loss -148.2142 (-172.3181)
2022-11-03 02:11:24,138:INFO: Batch:  9/31	Total Loss -204.7729 (-175.9673)
2022-11-03 02:11:24,629:INFO: Batch: 10/31	Total Loss -183.0208 (-176.5704)
2022-11-03 02:11:25,123:INFO: Batch: 11/31	Total Loss -158.2059 (-175.0907)
2022-11-03 02:11:25,690:INFO: Batch: 12/31	Total Loss -180.4462 (-175.4916)
2022-11-03 02:11:26,183:INFO: Batch: 13/31	Total Loss -184.3394 (-176.1295)
2022-11-03 02:11:26,675:INFO: Batch: 14/31	Total Loss -182.5395 (-176.5930)
2022-11-03 02:11:27,167:INFO: Batch: 15/31	Total Loss -181.2914 (-176.9092)
2022-11-03 02:11:27,659:INFO: Batch: 16/31	Total Loss -139.8961 (-174.6780)
2022-11-03 02:11:28,152:INFO: Batch: 17/31	Total Loss -169.1760 (-174.4018)
2022-11-03 02:11:28,645:INFO: Batch: 18/31	Total Loss -179.7894 (-174.6717)
2022-11-03 02:11:29,137:INFO: Batch: 19/31	Total Loss -190.5746 (-175.4905)
2022-11-03 02:11:29,628:INFO: Batch: 20/31	Total Loss -188.8309 (-176.1295)
2022-11-03 02:11:30,121:INFO: Batch: 21/31	Total Loss -192.8108 (-176.9537)
2022-11-03 02:11:30,612:INFO: Batch: 22/31	Total Loss -172.4380 (-176.7441)
2022-11-03 02:11:31,104:INFO: Batch: 23/31	Total Loss -168.7891 (-176.4317)
2022-11-03 02:11:31,595:INFO: Batch: 24/31	Total Loss -161.8949 (-175.8955)
2022-11-03 02:11:32,087:INFO: Batch: 25/31	Total Loss -179.5031 (-176.0254)
2022-11-03 02:11:32,580:INFO: Batch: 26/31	Total Loss -212.8654 (-177.5031)
2022-11-03 02:11:33,074:INFO: Batch: 27/31	Total Loss -184.1489 (-177.7269)
2022-11-03 02:11:33,564:INFO: Batch: 28/31	Total Loss -172.7873 (-177.5650)
2022-11-03 02:11:34,058:INFO: Batch: 29/31	Total Loss -180.5378 (-177.6637)
2022-11-03 02:11:34,445:INFO: Batch: 30/31	Total Loss -126.5296 (-177.1597)
2022-11-03 02:11:34,591:INFO: - Computing ADE (validation o)
2022-11-03 02:11:35,296:INFO: 		 ADE on eth                       dataset:	 0.9237545728683472
2022-11-03 02:11:35,296:INFO: Average validation o:	ADE  0.9238	FDE  1.9875
2022-11-03 02:11:35,297:INFO: - Computing ADE (validation)
2022-11-03 02:11:35,590:INFO: 		 ADE on hotel                     dataset:	 0.36449697613716125
2022-11-03 02:11:35,957:INFO: 		 ADE on univ                      dataset:	 0.5337488055229187
2022-11-03 02:11:36,247:INFO: 		 ADE on zara1                     dataset:	 0.4029431641101837
2022-11-03 02:11:36,742:INFO: 		 ADE on zara2                     dataset:	 0.3869917094707489
2022-11-03 02:11:36,742:INFO: Average validation:	ADE  0.4630	FDE  0.9959
2022-11-03 02:11:36,743:INFO: - Computing ADE (training)
2022-11-03 02:11:37,300:INFO: 		 ADE on hotel                     dataset:	 0.37102946639060974
2022-11-03 02:11:38,332:INFO: 		 ADE on univ                      dataset:	 0.5257891416549683
2022-11-03 02:11:39,086:INFO: 		 ADE on zara1                     dataset:	 0.4209239184856415
2022-11-03 02:11:40,276:INFO: 		 ADE on zara2                     dataset:	 0.372667133808136
2022-11-03 02:11:40,276:INFO: Average training:	ADE  0.4841	FDE  1.0415
2022-11-03 02:11:40,287:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_663.pth.tar
2022-11-03 02:11:40,287:INFO: 
===> EPOCH: 664 (P4)
2022-11-03 02:11:40,288:INFO: - Computing loss (training)
2022-11-03 02:11:41,410:INFO: Batch:  0/31	Total Loss -151.7962 (-151.7962)
2022-11-03 02:11:41,903:INFO: Batch:  1/31	Total Loss -136.2379 (-143.4814)
2022-11-03 02:11:42,397:INFO: Batch:  2/31	Total Loss -192.9602 (-161.7051)
2022-11-03 02:11:42,894:INFO: Batch:  3/31	Total Loss -190.1997 (-168.8195)
2022-11-03 02:11:43,387:INFO: Batch:  4/31	Total Loss -180.6176 (-171.2408)
2022-11-03 02:11:43,878:INFO: Batch:  5/31	Total Loss -207.7982 (-177.2887)
2022-11-03 02:11:44,370:INFO: Batch:  6/31	Total Loss -202.2650 (-180.8499)
2022-11-03 02:11:44,860:INFO: Batch:  7/31	Total Loss -177.2520 (-180.3764)
2022-11-03 02:11:45,351:INFO: Batch:  8/31	Total Loss -191.3558 (-181.6490)
2022-11-03 02:11:45,842:INFO: Batch:  9/31	Total Loss -202.0069 (-183.8866)
2022-11-03 02:11:46,330:INFO: Batch: 10/31	Total Loss -172.9428 (-182.9776)
2022-11-03 02:11:46,820:INFO: Batch: 11/31	Total Loss -194.0154 (-183.9153)
2022-11-03 02:11:47,312:INFO: Batch: 12/31	Total Loss -208.2013 (-185.8258)
2022-11-03 02:11:47,813:INFO: Batch: 13/31	Total Loss -193.1815 (-186.3266)
2022-11-03 02:11:48,312:INFO: Batch: 14/31	Total Loss -133.8897 (-183.0908)
2022-11-03 02:11:48,812:INFO: Batch: 15/31	Total Loss -181.4193 (-182.9880)
2022-11-03 02:11:49,311:INFO: Batch: 16/31	Total Loss -201.6439 (-184.1508)
2022-11-03 02:11:49,810:INFO: Batch: 17/31	Total Loss -203.3855 (-185.2640)
2022-11-03 02:11:50,309:INFO: Batch: 18/31	Total Loss -205.0482 (-186.1895)
2022-11-03 02:11:50,812:INFO: Batch: 19/31	Total Loss -204.4504 (-187.1248)
2022-11-03 02:11:51,311:INFO: Batch: 20/31	Total Loss -172.9395 (-186.4724)
2022-11-03 02:11:51,810:INFO: Batch: 21/31	Total Loss -225.3364 (-188.4166)
2022-11-03 02:11:52,307:INFO: Batch: 22/31	Total Loss -169.3740 (-187.6640)
2022-11-03 02:11:52,807:INFO: Batch: 23/31	Total Loss -218.0576 (-189.0365)
2022-11-03 02:11:53,306:INFO: Batch: 24/31	Total Loss -182.3331 (-188.7803)
2022-11-03 02:11:53,803:INFO: Batch: 25/31	Total Loss -178.1627 (-188.3835)
2022-11-03 02:11:54,303:INFO: Batch: 26/31	Total Loss -193.5469 (-188.5825)
2022-11-03 02:11:54,800:INFO: Batch: 27/31	Total Loss -213.9439 (-189.5316)
2022-11-03 02:11:55,297:INFO: Batch: 28/31	Total Loss -183.7670 (-189.3326)
2022-11-03 02:11:55,794:INFO: Batch: 29/31	Total Loss -195.4960 (-189.5216)
2022-11-03 02:11:56,188:INFO: Batch: 30/31	Total Loss -142.5356 (-189.0128)
2022-11-03 02:11:56,344:INFO: - Computing ADE (validation o)
2022-11-03 02:11:57,024:INFO: 		 ADE on eth                       dataset:	 0.9271453619003296
2022-11-03 02:11:57,024:INFO: Average validation o:	ADE  0.9271	FDE  1.9543
2022-11-03 02:11:57,025:INFO: - Computing ADE (validation)
2022-11-03 02:11:57,331:INFO: 		 ADE on hotel                     dataset:	 0.37735098600387573
2022-11-03 02:11:57,718:INFO: 		 ADE on univ                      dataset:	 0.5279926061630249
2022-11-03 02:11:58,008:INFO: 		 ADE on zara1                     dataset:	 0.3853527903556824
2022-11-03 02:11:58,479:INFO: 		 ADE on zara2                     dataset:	 0.4028705358505249
2022-11-03 02:11:58,480:INFO: Average validation:	ADE  0.4656	FDE  0.9989
2022-11-03 02:11:58,489:INFO: - Computing ADE (training)
2022-11-03 02:11:59,057:INFO: 		 ADE on hotel                     dataset:	 0.379596084356308
2022-11-03 02:12:00,106:INFO: 		 ADE on univ                      dataset:	 0.5265702605247498
2022-11-03 02:12:00,840:INFO: 		 ADE on zara1                     dataset:	 0.4414626359939575
2022-11-03 02:12:02,039:INFO: 		 ADE on zara2                     dataset:	 0.3969433903694153
2022-11-03 02:12:02,040:INFO: Average training:	ADE  0.4911	FDE  1.0588
2022-11-03 02:12:02,052:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_664.pth.tar
2022-11-03 02:12:02,052:INFO: 
===> EPOCH: 665 (P4)
2022-11-03 02:12:02,052:INFO: - Computing loss (training)
2022-11-03 02:12:03,166:INFO: Batch:  0/31	Total Loss -201.0937 (-201.0937)
2022-11-03 02:12:03,658:INFO: Batch:  1/31	Total Loss -193.3809 (-197.4435)
2022-11-03 02:12:04,151:INFO: Batch:  2/31	Total Loss -216.9450 (-204.4701)
2022-11-03 02:12:04,643:INFO: Batch:  3/31	Total Loss -187.3930 (-200.4540)
2022-11-03 02:12:05,136:INFO: Batch:  4/31	Total Loss -148.5150 (-191.0016)
2022-11-03 02:12:05,640:INFO: Batch:  5/31	Total Loss -170.7460 (-187.5190)
2022-11-03 02:12:06,136:INFO: Batch:  6/31	Total Loss -209.5327 (-190.8548)
2022-11-03 02:12:06,625:INFO: Batch:  7/31	Total Loss -174.6400 (-188.9092)
2022-11-03 02:12:07,117:INFO: Batch:  8/31	Total Loss -221.8927 (-192.9007)
2022-11-03 02:12:07,606:INFO: Batch:  9/31	Total Loss -200.0935 (-193.6333)
2022-11-03 02:12:08,101:INFO: Batch: 10/31	Total Loss -131.9702 (-188.1967)
2022-11-03 02:12:08,590:INFO: Batch: 11/31	Total Loss -197.4480 (-189.0143)
2022-11-03 02:12:09,083:INFO: Batch: 12/31	Total Loss -206.6870 (-190.3977)
2022-11-03 02:12:09,577:INFO: Batch: 13/31	Total Loss -199.8103 (-191.1054)
2022-11-03 02:12:10,072:INFO: Batch: 14/31	Total Loss -191.3671 (-191.1227)
2022-11-03 02:12:10,566:INFO: Batch: 15/31	Total Loss -205.0672 (-191.9662)
2022-11-03 02:12:11,064:INFO: Batch: 16/31	Total Loss -168.2323 (-190.7985)
2022-11-03 02:12:11,557:INFO: Batch: 17/31	Total Loss -193.9270 (-190.9856)
2022-11-03 02:12:12,051:INFO: Batch: 18/31	Total Loss -184.9081 (-190.6723)
2022-11-03 02:12:12,542:INFO: Batch: 19/31	Total Loss -193.2086 (-190.8002)
2022-11-03 02:12:13,035:INFO: Batch: 20/31	Total Loss -199.8116 (-191.2453)
2022-11-03 02:12:13,526:INFO: Batch: 21/31	Total Loss -212.5494 (-192.2385)
2022-11-03 02:12:14,018:INFO: Batch: 22/31	Total Loss -194.4113 (-192.3351)
2022-11-03 02:12:14,509:INFO: Batch: 23/31	Total Loss -202.9395 (-192.8169)
2022-11-03 02:12:15,001:INFO: Batch: 24/31	Total Loss -215.6468 (-193.8429)
2022-11-03 02:12:15,492:INFO: Batch: 25/31	Total Loss -215.6032 (-194.6938)
2022-11-03 02:12:15,987:INFO: Batch: 26/31	Total Loss -191.2499 (-194.5537)
2022-11-03 02:12:16,476:INFO: Batch: 27/31	Total Loss -199.3845 (-194.7319)
2022-11-03 02:12:16,970:INFO: Batch: 28/31	Total Loss -171.5169 (-194.0487)
2022-11-03 02:12:17,461:INFO: Batch: 29/31	Total Loss -200.6874 (-194.2725)
2022-11-03 02:12:17,848:INFO: Batch: 30/31	Total Loss -145.1894 (-193.7357)
2022-11-03 02:12:17,994:INFO: - Computing ADE (validation o)
2022-11-03 02:12:18,704:INFO: 		 ADE on eth                       dataset:	 0.9351152181625366
2022-11-03 02:12:18,704:INFO: Average validation o:	ADE  0.9351	FDE  1.9988
2022-11-03 02:12:18,705:INFO: - Computing ADE (validation)
2022-11-03 02:12:19,023:INFO: 		 ADE on hotel                     dataset:	 0.3763238489627838
2022-11-03 02:12:19,396:INFO: 		 ADE on univ                      dataset:	 0.5384249091148376
2022-11-03 02:12:19,682:INFO: 		 ADE on zara1                     dataset:	 0.413042277097702
2022-11-03 02:12:20,230:INFO: 		 ADE on zara2                     dataset:	 0.41049328446388245
2022-11-03 02:12:20,230:INFO: Average validation:	ADE  0.4753	FDE  1.0354
2022-11-03 02:12:20,231:INFO: - Computing ADE (training)
2022-11-03 02:12:20,814:INFO: 		 ADE on hotel                     dataset:	 0.387876957654953
2022-11-03 02:12:21,957:INFO: 		 ADE on univ                      dataset:	 0.5355134606361389
2022-11-03 02:12:22,732:INFO: 		 ADE on zara1                     dataset:	 0.4373343288898468
2022-11-03 02:12:23,935:INFO: 		 ADE on zara2                     dataset:	 0.3999994397163391
2022-11-03 02:12:23,935:INFO: Average training:	ADE  0.4980	FDE  1.0837
2022-11-03 02:12:23,955:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_665.pth.tar
2022-11-03 02:12:23,955:INFO: 
===> EPOCH: 666 (P4)
2022-11-03 02:12:23,956:INFO: - Computing loss (training)
2022-11-03 02:12:25,082:INFO: Batch:  0/31	Total Loss -209.0142 (-209.0142)
2022-11-03 02:12:25,605:INFO: Batch:  1/31	Total Loss -195.2879 (-201.8360)
2022-11-03 02:12:26,129:INFO: Batch:  2/31	Total Loss -222.8963 (-208.8332)
2022-11-03 02:12:26,627:INFO: Batch:  3/31	Total Loss -213.5509 (-210.0089)
2022-11-03 02:12:27,129:INFO: Batch:  4/31	Total Loss -192.0605 (-206.4963)
2022-11-03 02:12:27,623:INFO: Batch:  5/31	Total Loss -187.2812 (-203.5224)
2022-11-03 02:12:28,118:INFO: Batch:  6/31	Total Loss -218.3603 (-205.7670)
2022-11-03 02:12:28,614:INFO: Batch:  7/31	Total Loss -226.5957 (-208.4100)
2022-11-03 02:12:29,117:INFO: Batch:  8/31	Total Loss -216.2219 (-209.2958)
2022-11-03 02:12:29,622:INFO: Batch:  9/31	Total Loss -220.6974 (-210.4124)
2022-11-03 02:12:30,123:INFO: Batch: 10/31	Total Loss -207.8844 (-210.1959)
2022-11-03 02:12:30,635:INFO: Batch: 11/31	Total Loss -193.8456 (-208.9483)
2022-11-03 02:12:31,417:INFO: Batch: 12/31	Total Loss -195.3566 (-207.9652)
2022-11-03 02:12:32,000:INFO: Batch: 13/31	Total Loss -238.2852 (-210.4536)
2022-11-03 02:12:32,609:INFO: Batch: 14/31	Total Loss -225.5225 (-211.4086)
2022-11-03 02:12:33,154:INFO: Batch: 15/31	Total Loss -219.3695 (-211.9365)
2022-11-03 02:12:33,707:INFO: Batch: 16/31	Total Loss -166.4871 (-209.2594)
2022-11-03 02:12:34,225:INFO: Batch: 17/31	Total Loss -200.9835 (-208.8064)
2022-11-03 02:12:34,738:INFO: Batch: 18/31	Total Loss -238.7262 (-210.3948)
2022-11-03 02:12:35,271:INFO: Batch: 19/31	Total Loss -178.4406 (-209.0773)
2022-11-03 02:12:35,810:INFO: Batch: 20/31	Total Loss -218.0817 (-209.5028)
2022-11-03 02:12:36,331:INFO: Batch: 21/31	Total Loss -146.2555 (-206.7621)
2022-11-03 02:12:36,851:INFO: Batch: 22/31	Total Loss -220.6960 (-207.3391)
2022-11-03 02:12:37,377:INFO: Batch: 23/31	Total Loss -196.0060 (-206.8857)
2022-11-03 02:12:37,930:INFO: Batch: 24/31	Total Loss -219.8998 (-207.3807)
2022-11-03 02:12:38,457:INFO: Batch: 25/31	Total Loss -186.0378 (-206.6107)
2022-11-03 02:12:38,983:INFO: Batch: 26/31	Total Loss -203.5039 (-206.4993)
2022-11-03 02:12:39,547:INFO: Batch: 27/31	Total Loss -200.5063 (-206.2882)
2022-11-03 02:12:40,071:INFO: Batch: 28/31	Total Loss -176.3325 (-205.3531)
2022-11-03 02:12:40,610:INFO: Batch: 29/31	Total Loss -198.0516 (-205.1021)
2022-11-03 02:12:41,036:INFO: Batch: 30/31	Total Loss -118.1881 (-204.4209)
2022-11-03 02:12:41,235:INFO: - Computing ADE (validation o)
2022-11-03 02:12:42,026:INFO: 		 ADE on eth                       dataset:	 0.9186058640480042
2022-11-03 02:12:42,027:INFO: Average validation o:	ADE  0.9186	FDE  1.9374
2022-11-03 02:12:42,027:INFO: - Computing ADE (validation)
2022-11-03 02:12:42,364:INFO: 		 ADE on hotel                     dataset:	 0.37627649307250977
2022-11-03 02:12:42,764:INFO: 		 ADE on univ                      dataset:	 0.5355789065361023
2022-11-03 02:12:43,068:INFO: 		 ADE on zara1                     dataset:	 0.4050939083099365
2022-11-03 02:12:43,540:INFO: 		 ADE on zara2                     dataset:	 0.4067036807537079
2022-11-03 02:12:43,541:INFO: Average validation:	ADE  0.4720	FDE  1.0115
2022-11-03 02:12:43,550:INFO: - Computing ADE (training)
2022-11-03 02:12:44,188:INFO: 		 ADE on hotel                     dataset:	 0.3798294961452484
2022-11-03 02:12:45,294:INFO: 		 ADE on univ                      dataset:	 0.5317559242248535
2022-11-03 02:12:46,062:INFO: 		 ADE on zara1                     dataset:	 0.44403567910194397
2022-11-03 02:12:47,339:INFO: 		 ADE on zara2                     dataset:	 0.39837247133255005
2022-11-03 02:12:47,340:INFO: Average training:	ADE  0.4952	FDE  1.0645
2022-11-03 02:12:47,353:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_666.pth.tar
2022-11-03 02:12:47,353:INFO: 
===> EPOCH: 667 (P4)
2022-11-03 02:12:47,354:INFO: - Computing loss (training)
2022-11-03 02:12:48,588:INFO: Batch:  0/31	Total Loss -203.2718 (-203.2718)
2022-11-03 02:12:49,106:INFO: Batch:  1/31	Total Loss -223.7369 (-213.9248)
2022-11-03 02:12:49,618:INFO: Batch:  2/31	Total Loss -198.9400 (-209.0653)
2022-11-03 02:12:50,126:INFO: Batch:  3/31	Total Loss -228.7939 (-214.2735)
2022-11-03 02:12:50,642:INFO: Batch:  4/31	Total Loss -200.6848 (-211.7660)
2022-11-03 02:12:51,186:INFO: Batch:  5/31	Total Loss -215.0872 (-212.3058)
2022-11-03 02:12:51,738:INFO: Batch:  6/31	Total Loss -225.3012 (-214.0582)
2022-11-03 02:12:52,285:INFO: Batch:  7/31	Total Loss -217.0704 (-214.4519)
2022-11-03 02:12:52,813:INFO: Batch:  8/31	Total Loss -221.3938 (-215.2531)
2022-11-03 02:12:53,354:INFO: Batch:  9/31	Total Loss -228.0793 (-216.6425)
2022-11-03 02:12:53,854:INFO: Batch: 10/31	Total Loss -204.5401 (-215.6063)
2022-11-03 02:12:54,352:INFO: Batch: 11/31	Total Loss -210.6330 (-215.1614)
2022-11-03 02:12:54,890:INFO: Batch: 12/31	Total Loss -222.0746 (-215.6891)
2022-11-03 02:12:55,421:INFO: Batch: 13/31	Total Loss -215.0905 (-215.6444)
2022-11-03 02:12:55,929:INFO: Batch: 14/31	Total Loss -206.6062 (-215.0921)
2022-11-03 02:12:56,435:INFO: Batch: 15/31	Total Loss -228.1020 (-215.8452)
2022-11-03 02:12:56,950:INFO: Batch: 16/31	Total Loss -158.7400 (-212.9876)
2022-11-03 02:12:57,455:INFO: Batch: 17/31	Total Loss -213.0519 (-212.9912)
2022-11-03 02:12:57,959:INFO: Batch: 18/31	Total Loss -208.7664 (-212.7858)
2022-11-03 02:12:58,487:INFO: Batch: 19/31	Total Loss -244.4800 (-214.5274)
2022-11-03 02:12:59,046:INFO: Batch: 20/31	Total Loss -205.3306 (-214.1007)
2022-11-03 02:12:59,568:INFO: Batch: 21/31	Total Loss -207.8257 (-213.8127)
2022-11-03 02:13:00,087:INFO: Batch: 22/31	Total Loss -180.7569 (-212.4115)
2022-11-03 02:13:00,598:INFO: Batch: 23/31	Total Loss -203.7523 (-212.0726)
2022-11-03 02:13:01,119:INFO: Batch: 24/31	Total Loss -233.2783 (-212.9344)
2022-11-03 02:13:01,710:INFO: Batch: 25/31	Total Loss -207.2543 (-212.7335)
2022-11-03 02:13:02,293:INFO: Batch: 26/31	Total Loss -242.2434 (-213.8520)
2022-11-03 02:13:02,856:INFO: Batch: 27/31	Total Loss -173.9010 (-212.6771)
2022-11-03 02:13:03,410:INFO: Batch: 28/31	Total Loss -206.3157 (-212.4792)
2022-11-03 02:13:03,916:INFO: Batch: 29/31	Total Loss -202.1311 (-212.1576)
2022-11-03 02:13:04,322:INFO: Batch: 30/31	Total Loss -140.1614 (-211.4867)
2022-11-03 02:13:04,473:INFO: - Computing ADE (validation o)
2022-11-03 02:13:05,191:INFO: 		 ADE on eth                       dataset:	 0.9162583947181702
2022-11-03 02:13:05,191:INFO: Average validation o:	ADE  0.9163	FDE  1.9517
2022-11-03 02:13:05,192:INFO: - Computing ADE (validation)
2022-11-03 02:13:05,514:INFO: 		 ADE on hotel                     dataset:	 0.36209338903427124
2022-11-03 02:13:05,892:INFO: 		 ADE on univ                      dataset:	 0.5254806876182556
2022-11-03 02:13:06,192:INFO: 		 ADE on zara1                     dataset:	 0.3894408047199249
2022-11-03 02:13:06,671:INFO: 		 ADE on zara2                     dataset:	 0.38512375950813293
2022-11-03 02:13:06,672:INFO: Average validation:	ADE  0.4571	FDE  0.9812
2022-11-03 02:13:06,672:INFO: - Computing ADE (training)
2022-11-03 02:13:07,275:INFO: 		 ADE on hotel                     dataset:	 0.36507588624954224
2022-11-03 02:13:08,364:INFO: 		 ADE on univ                      dataset:	 0.522185206413269
2022-11-03 02:13:09,132:INFO: 		 ADE on zara1                     dataset:	 0.4210614562034607
2022-11-03 02:13:10,312:INFO: 		 ADE on zara2                     dataset:	 0.37195754051208496
2022-11-03 02:13:10,312:INFO: Average training:	ADE  0.4813	FDE  1.0350
2022-11-03 02:13:10,324:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_667.pth.tar
2022-11-03 02:13:10,324:INFO: 
===> EPOCH: 668 (P4)
2022-11-03 02:13:10,324:INFO: - Computing loss (training)
2022-11-03 02:13:11,459:INFO: Batch:  0/31	Total Loss -228.2537 (-228.2537)
2022-11-03 02:13:11,995:INFO: Batch:  1/31	Total Loss -207.8165 (-218.2194)
2022-11-03 02:13:12,627:INFO: Batch:  2/31	Total Loss -192.4625 (-210.5851)
2022-11-03 02:13:13,352:INFO: Batch:  3/31	Total Loss -178.8210 (-203.2131)
2022-11-03 02:13:13,935:INFO: Batch:  4/31	Total Loss -221.5927 (-206.9292)
2022-11-03 02:13:14,509:INFO: Batch:  5/31	Total Loss -213.1070 (-207.9879)
2022-11-03 02:13:15,091:INFO: Batch:  6/31	Total Loss -232.1221 (-211.7279)
2022-11-03 02:13:15,646:INFO: Batch:  7/31	Total Loss -233.7582 (-214.7226)
2022-11-03 02:13:16,205:INFO: Batch:  8/31	Total Loss -208.5477 (-214.0204)
2022-11-03 02:13:16,756:INFO: Batch:  9/31	Total Loss -220.1752 (-214.6405)
2022-11-03 02:13:17,339:INFO: Batch: 10/31	Total Loss -237.1681 (-216.8481)
2022-11-03 02:13:17,900:INFO: Batch: 11/31	Total Loss -235.3460 (-218.4301)
2022-11-03 02:13:18,497:INFO: Batch: 12/31	Total Loss -216.5684 (-218.2920)
2022-11-03 02:13:19,046:INFO: Batch: 13/31	Total Loss -219.0585 (-218.3483)
2022-11-03 02:13:19,605:INFO: Batch: 14/31	Total Loss -214.0467 (-218.0543)
2022-11-03 02:13:20,191:INFO: Batch: 15/31	Total Loss -212.7007 (-217.7203)
2022-11-03 02:13:20,733:INFO: Batch: 16/31	Total Loss -208.7220 (-217.2224)
2022-11-03 02:13:21,286:INFO: Batch: 17/31	Total Loss -215.5248 (-217.1344)
2022-11-03 02:13:21,858:INFO: Batch: 18/31	Total Loss -217.0836 (-217.1317)
2022-11-03 02:13:22,374:INFO: Batch: 19/31	Total Loss -206.9029 (-216.6264)
2022-11-03 02:13:22,903:INFO: Batch: 20/31	Total Loss -220.1548 (-216.7892)
2022-11-03 02:13:23,460:INFO: Batch: 21/31	Total Loss -211.6130 (-216.5606)
2022-11-03 02:13:23,978:INFO: Batch: 22/31	Total Loss -230.5863 (-217.1539)
2022-11-03 02:13:24,575:INFO: Batch: 23/31	Total Loss -205.1127 (-216.6535)
2022-11-03 02:13:25,094:INFO: Batch: 24/31	Total Loss -231.7816 (-217.2085)
2022-11-03 02:13:25,597:INFO: Batch: 25/31	Total Loss -243.3524 (-218.2991)
2022-11-03 02:13:26,110:INFO: Batch: 26/31	Total Loss -220.7337 (-218.3832)
2022-11-03 02:13:26,621:INFO: Batch: 27/31	Total Loss -233.9700 (-218.9256)
2022-11-03 02:13:27,129:INFO: Batch: 28/31	Total Loss -228.8051 (-219.2689)
2022-11-03 02:13:27,673:INFO: Batch: 29/31	Total Loss -236.1244 (-219.8156)
2022-11-03 02:13:28,151:INFO: Batch: 30/31	Total Loss -142.7556 (-219.0692)
2022-11-03 02:13:28,322:INFO: - Computing ADE (validation o)
2022-11-03 02:13:29,011:INFO: 		 ADE on eth                       dataset:	 0.9152633547782898
2022-11-03 02:13:29,011:INFO: Average validation o:	ADE  0.9153	FDE  1.9631
2022-11-03 02:13:29,012:INFO: - Computing ADE (validation)
2022-11-03 02:13:29,318:INFO: 		 ADE on hotel                     dataset:	 0.36154016852378845
2022-11-03 02:13:29,696:INFO: 		 ADE on univ                      dataset:	 0.5278857350349426
2022-11-03 02:13:30,058:INFO: 		 ADE on zara1                     dataset:	 0.3985222578048706
2022-11-03 02:13:30,536:INFO: 		 ADE on zara2                     dataset:	 0.38648301362991333
2022-11-03 02:13:30,536:INFO: Average validation:	ADE  0.4594	FDE  0.9900
2022-11-03 02:13:30,537:INFO: - Computing ADE (training)
2022-11-03 02:13:31,142:INFO: 		 ADE on hotel                     dataset:	 0.368381530046463
2022-11-03 02:13:32,228:INFO: 		 ADE on univ                      dataset:	 0.5244179964065552
2022-11-03 02:13:32,953:INFO: 		 ADE on zara1                     dataset:	 0.41676294803619385
2022-11-03 02:13:34,167:INFO: 		 ADE on zara2                     dataset:	 0.3707084655761719
2022-11-03 02:13:34,167:INFO: Average training:	ADE  0.4824	FDE  1.0391
2022-11-03 02:13:34,180:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_668.pth.tar
2022-11-03 02:13:34,180:INFO: 
===> EPOCH: 669 (P4)
2022-11-03 02:13:34,181:INFO: - Computing loss (training)
2022-11-03 02:13:35,310:INFO: Batch:  0/31	Total Loss -227.7293 (-227.7293)
2022-11-03 02:13:35,853:INFO: Batch:  1/31	Total Loss -168.0053 (-197.7921)
2022-11-03 02:13:36,364:INFO: Batch:  2/31	Total Loss -247.2007 (-215.6345)
2022-11-03 02:13:36,887:INFO: Batch:  3/31	Total Loss -214.3460 (-215.3311)
2022-11-03 02:13:37,412:INFO: Batch:  4/31	Total Loss -211.5633 (-214.5853)
2022-11-03 02:13:37,927:INFO: Batch:  5/31	Total Loss -228.7825 (-216.8209)
2022-11-03 02:13:38,467:INFO: Batch:  6/31	Total Loss -254.5739 (-222.5955)
2022-11-03 02:13:39,024:INFO: Batch:  7/31	Total Loss -228.6635 (-223.3222)
2022-11-03 02:13:39,573:INFO: Batch:  8/31	Total Loss -171.3038 (-218.1058)
2022-11-03 02:13:40,120:INFO: Batch:  9/31	Total Loss -196.1121 (-216.1176)
2022-11-03 02:13:40,664:INFO: Batch: 10/31	Total Loss -206.8649 (-215.2753)
2022-11-03 02:13:41,196:INFO: Batch: 11/31	Total Loss -198.8292 (-213.9788)
2022-11-03 02:13:41,741:INFO: Batch: 12/31	Total Loss -237.7981 (-215.8970)
2022-11-03 02:13:42,263:INFO: Batch: 13/31	Total Loss -199.1534 (-214.7915)
2022-11-03 02:13:42,843:INFO: Batch: 14/31	Total Loss -231.2968 (-216.0435)
2022-11-03 02:13:43,367:INFO: Batch: 15/31	Total Loss -203.7005 (-215.3078)
2022-11-03 02:13:43,866:INFO: Batch: 16/31	Total Loss -199.7495 (-214.4812)
2022-11-03 02:13:44,380:INFO: Batch: 17/31	Total Loss -209.0870 (-214.1789)
2022-11-03 02:13:44,926:INFO: Batch: 18/31	Total Loss -227.4500 (-214.8785)
2022-11-03 02:13:45,449:INFO: Batch: 19/31	Total Loss -213.5028 (-214.8145)
2022-11-03 02:13:45,967:INFO: Batch: 20/31	Total Loss -226.7058 (-215.4554)
2022-11-03 02:13:46,493:INFO: Batch: 21/31	Total Loss -219.0564 (-215.6201)
2022-11-03 02:13:47,006:INFO: Batch: 22/31	Total Loss -235.7706 (-216.4940)
2022-11-03 02:13:47,534:INFO: Batch: 23/31	Total Loss -219.6281 (-216.6218)
2022-11-03 02:13:48,040:INFO: Batch: 24/31	Total Loss -203.3189 (-216.1213)
2022-11-03 02:13:48,550:INFO: Batch: 25/31	Total Loss -235.1179 (-216.8238)
2022-11-03 02:13:49,087:INFO: Batch: 26/31	Total Loss -241.8471 (-217.7445)
2022-11-03 02:13:49,616:INFO: Batch: 27/31	Total Loss -232.2542 (-218.2533)
2022-11-03 02:13:50,128:INFO: Batch: 28/31	Total Loss -221.1382 (-218.3569)
2022-11-03 02:13:50,649:INFO: Batch: 29/31	Total Loss -214.4124 (-218.2254)
2022-11-03 02:13:51,070:INFO: Batch: 30/31	Total Loss -159.9615 (-217.4911)
2022-11-03 02:13:51,224:INFO: - Computing ADE (validation o)
2022-11-03 02:13:51,982:INFO: 		 ADE on eth                       dataset:	 0.9196404218673706
2022-11-03 02:13:51,982:INFO: Average validation o:	ADE  0.9196	FDE  1.9500
2022-11-03 02:13:51,983:INFO: - Computing ADE (validation)
2022-11-03 02:13:52,308:INFO: 		 ADE on hotel                     dataset:	 0.3635462522506714
2022-11-03 02:13:52,741:INFO: 		 ADE on univ                      dataset:	 0.5264692902565002
2022-11-03 02:13:53,060:INFO: 		 ADE on zara1                     dataset:	 0.37873387336730957
2022-11-03 02:13:53,578:INFO: 		 ADE on zara2                     dataset:	 0.38220492005348206
2022-11-03 02:13:53,578:INFO: Average validation:	ADE  0.4560	FDE  0.9775
2022-11-03 02:13:53,579:INFO: - Computing ADE (training)
2022-11-03 02:13:54,191:INFO: 		 ADE on hotel                     dataset:	 0.3689216673374176
2022-11-03 02:13:55,226:INFO: 		 ADE on univ                      dataset:	 0.5205957889556885
2022-11-03 02:13:56,025:INFO: 		 ADE on zara1                     dataset:	 0.4302254915237427
2022-11-03 02:13:57,315:INFO: 		 ADE on zara2                     dataset:	 0.3748321533203125
2022-11-03 02:13:57,316:INFO: Average training:	ADE  0.4814	FDE  1.0352
2022-11-03 02:13:57,329:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_669.pth.tar
2022-11-03 02:13:57,329:INFO: 
===> EPOCH: 670 (P4)
2022-11-03 02:13:57,330:INFO: - Computing loss (training)
2022-11-03 02:13:58,680:INFO: Batch:  0/31	Total Loss -223.3684 (-223.3684)
2022-11-03 02:13:59,215:INFO: Batch:  1/31	Total Loss -74.8577 (-150.1937)
2022-11-03 02:13:59,742:INFO: Batch:  2/31	Total Loss -232.8241 (-177.2364)
2022-11-03 02:14:00,273:INFO: Batch:  3/31	Total Loss -243.8298 (-195.0197)
2022-11-03 02:14:00,785:INFO: Batch:  4/31	Total Loss -203.6276 (-196.7434)
2022-11-03 02:14:01,326:INFO: Batch:  5/31	Total Loss -227.7187 (-201.9464)
2022-11-03 02:14:01,835:INFO: Batch:  6/31	Total Loss -219.2905 (-204.3623)
2022-11-03 02:14:02,344:INFO: Batch:  7/31	Total Loss -233.4806 (-208.2571)
2022-11-03 02:14:02,858:INFO: Batch:  8/31	Total Loss -232.1625 (-210.7630)
2022-11-03 02:14:03,365:INFO: Batch:  9/31	Total Loss -233.3793 (-213.0907)
2022-11-03 02:14:03,874:INFO: Batch: 10/31	Total Loss -199.5257 (-211.8660)
2022-11-03 02:14:04,375:INFO: Batch: 11/31	Total Loss -248.3933 (-215.3079)
2022-11-03 02:14:04,880:INFO: Batch: 12/31	Total Loss -190.7149 (-213.5983)
2022-11-03 02:14:05,387:INFO: Batch: 13/31	Total Loss -210.0522 (-213.3654)
2022-11-03 02:14:05,896:INFO: Batch: 14/31	Total Loss -218.0185 (-213.6522)
2022-11-03 02:14:06,404:INFO: Batch: 15/31	Total Loss -234.1820 (-214.9088)
2022-11-03 02:14:06,910:INFO: Batch: 16/31	Total Loss -245.2434 (-216.7537)
2022-11-03 02:14:07,412:INFO: Batch: 17/31	Total Loss -227.0371 (-217.3449)
2022-11-03 02:14:07,913:INFO: Batch: 18/31	Total Loss -232.4304 (-218.0760)
2022-11-03 02:14:08,417:INFO: Batch: 19/31	Total Loss -223.5584 (-218.3267)
2022-11-03 02:14:08,918:INFO: Batch: 20/31	Total Loss -240.3887 (-219.4357)
2022-11-03 02:14:09,418:INFO: Batch: 21/31	Total Loss -229.2658 (-219.8613)
2022-11-03 02:14:09,919:INFO: Batch: 22/31	Total Loss -223.5192 (-220.0366)
2022-11-03 02:14:10,419:INFO: Batch: 23/31	Total Loss -222.8800 (-220.1499)
2022-11-03 02:14:10,921:INFO: Batch: 24/31	Total Loss -247.6096 (-221.2932)
2022-11-03 02:14:11,424:INFO: Batch: 25/31	Total Loss -238.7516 (-221.9245)
2022-11-03 02:14:11,928:INFO: Batch: 26/31	Total Loss -242.2630 (-222.6786)
2022-11-03 02:14:12,429:INFO: Batch: 27/31	Total Loss -219.9678 (-222.5673)
2022-11-03 02:14:12,932:INFO: Batch: 28/31	Total Loss -244.7290 (-223.4105)
2022-11-03 02:14:13,434:INFO: Batch: 29/31	Total Loss -180.1473 (-221.8616)
2022-11-03 02:14:13,832:INFO: Batch: 30/31	Total Loss -160.9219 (-221.1301)
2022-11-03 02:14:13,984:INFO: - Computing ADE (validation o)
2022-11-03 02:14:14,674:INFO: 		 ADE on eth                       dataset:	 0.9160540103912354
2022-11-03 02:14:14,674:INFO: Average validation o:	ADE  0.9161	FDE  1.9415
2022-11-03 02:14:14,675:INFO: - Computing ADE (validation)
2022-11-03 02:14:14,990:INFO: 		 ADE on hotel                     dataset:	 0.36077648401260376
2022-11-03 02:14:15,385:INFO: 		 ADE on univ                      dataset:	 0.5297862887382507
2022-11-03 02:14:15,665:INFO: 		 ADE on zara1                     dataset:	 0.42154720425605774
2022-11-03 02:14:16,160:INFO: 		 ADE on zara2                     dataset:	 0.3936624825000763
2022-11-03 02:14:16,160:INFO: Average validation:	ADE  0.4643	FDE  0.9951
2022-11-03 02:14:16,161:INFO: - Computing ADE (training)
2022-11-03 02:14:16,742:INFO: 		 ADE on hotel                     dataset:	 0.36453184485435486
2022-11-03 02:14:17,767:INFO: 		 ADE on univ                      dataset:	 0.5248633027076721
2022-11-03 02:14:18,532:INFO: 		 ADE on zara1                     dataset:	 0.42873430252075195
2022-11-03 02:14:19,704:INFO: 		 ADE on zara2                     dataset:	 0.38203927874565125
2022-11-03 02:14:19,704:INFO: Average training:	ADE  0.4857	FDE  1.0420
2022-11-03 02:14:19,716:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_670.pth.tar
2022-11-03 02:14:19,716:INFO: 
===> EPOCH: 671 (P4)
2022-11-03 02:14:19,717:INFO: - Computing loss (training)
2022-11-03 02:14:20,826:INFO: Batch:  0/31	Total Loss -228.5967 (-228.5967)
2022-11-03 02:14:21,328:INFO: Batch:  1/31	Total Loss -255.2275 (-241.9247)
2022-11-03 02:14:21,828:INFO: Batch:  2/31	Total Loss -217.6924 (-234.8874)
2022-11-03 02:14:22,336:INFO: Batch:  3/31	Total Loss -238.5825 (-235.8285)
2022-11-03 02:14:22,834:INFO: Batch:  4/31	Total Loss -242.9432 (-237.1844)
2022-11-03 02:14:23,367:INFO: Batch:  5/31	Total Loss -229.1040 (-235.7432)
2022-11-03 02:14:24,101:INFO: Batch:  6/31	Total Loss -263.3496 (-239.9712)
2022-11-03 02:14:24,675:INFO: Batch:  7/31	Total Loss -248.1693 (-241.0172)
2022-11-03 02:14:25,229:INFO: Batch:  8/31	Total Loss -256.5917 (-242.9107)
2022-11-03 02:14:25,777:INFO: Batch:  9/31	Total Loss -239.0320 (-242.5546)
2022-11-03 02:14:26,447:INFO: Batch: 10/31	Total Loss -246.1926 (-242.8881)
2022-11-03 02:14:26,960:INFO: Batch: 11/31	Total Loss -230.1789 (-241.8533)
2022-11-03 02:14:27,466:INFO: Batch: 12/31	Total Loss -179.5726 (-237.5455)
2022-11-03 02:14:27,967:INFO: Batch: 13/31	Total Loss -235.6669 (-237.4075)
2022-11-03 02:14:28,518:INFO: Batch: 14/31	Total Loss -242.5211 (-237.7215)
2022-11-03 02:14:29,071:INFO: Batch: 15/31	Total Loss -223.0756 (-236.8699)
2022-11-03 02:14:29,639:INFO: Batch: 16/31	Total Loss -233.5526 (-236.6930)
2022-11-03 02:14:30,161:INFO: Batch: 17/31	Total Loss -244.4446 (-237.1236)
2022-11-03 02:14:30,683:INFO: Batch: 18/31	Total Loss -230.0159 (-236.7484)
2022-11-03 02:14:31,194:INFO: Batch: 19/31	Total Loss -229.8996 (-236.4402)
2022-11-03 02:14:31,705:INFO: Batch: 20/31	Total Loss -232.5090 (-236.2447)
2022-11-03 02:14:32,205:INFO: Batch: 21/31	Total Loss -219.4963 (-235.5025)
2022-11-03 02:14:32,721:INFO: Batch: 22/31	Total Loss -226.5102 (-235.1372)
2022-11-03 02:14:33,263:INFO: Batch: 23/31	Total Loss -203.2014 (-233.9230)
2022-11-03 02:14:33,823:INFO: Batch: 24/31	Total Loss -220.4658 (-233.4137)
2022-11-03 02:14:34,341:INFO: Batch: 25/31	Total Loss -226.0362 (-233.1322)
2022-11-03 02:14:34,839:INFO: Batch: 26/31	Total Loss -258.0884 (-234.1594)
2022-11-03 02:14:35,369:INFO: Batch: 27/31	Total Loss -214.5243 (-233.5413)
2022-11-03 02:14:35,883:INFO: Batch: 28/31	Total Loss -180.7684 (-231.5305)
2022-11-03 02:14:36,380:INFO: Batch: 29/31	Total Loss -227.4346 (-231.4107)
2022-11-03 02:14:36,774:INFO: Batch: 30/31	Total Loss -145.0836 (-230.7370)
2022-11-03 02:14:36,924:INFO: - Computing ADE (validation o)
2022-11-03 02:14:37,595:INFO: 		 ADE on eth                       dataset:	 0.9243689775466919
2022-11-03 02:14:37,595:INFO: Average validation o:	ADE  0.9244	FDE  1.9805
2022-11-03 02:14:37,596:INFO: - Computing ADE (validation)
2022-11-03 02:14:37,906:INFO: 		 ADE on hotel                     dataset:	 0.367341548204422
2022-11-03 02:14:38,276:INFO: 		 ADE on univ                      dataset:	 0.5229830741882324
2022-11-03 02:14:38,575:INFO: 		 ADE on zara1                     dataset:	 0.37421131134033203
2022-11-03 02:14:39,068:INFO: 		 ADE on zara2                     dataset:	 0.38587522506713867
2022-11-03 02:14:39,068:INFO: Average validation:	ADE  0.4555	FDE  0.9801
2022-11-03 02:14:39,069:INFO: - Computing ADE (training)
2022-11-03 02:14:39,666:INFO: 		 ADE on hotel                     dataset:	 0.3739701807498932
2022-11-03 02:14:40,744:INFO: 		 ADE on univ                      dataset:	 0.523842453956604
2022-11-03 02:14:41,511:INFO: 		 ADE on zara1                     dataset:	 0.41740652918815613
2022-11-03 02:14:42,710:INFO: 		 ADE on zara2                     dataset:	 0.37371787428855896
2022-11-03 02:14:42,710:INFO: Average training:	ADE  0.4828	FDE  1.0429
2022-11-03 02:14:42,722:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_671.pth.tar
2022-11-03 02:14:42,722:INFO: 
===> EPOCH: 672 (P4)
2022-11-03 02:14:42,722:INFO: - Computing loss (training)
2022-11-03 02:14:43,887:INFO: Batch:  0/31	Total Loss -223.8411 (-223.8411)
2022-11-03 02:14:44,516:INFO: Batch:  1/31	Total Loss -209.7475 (-216.7652)
2022-11-03 02:14:45,213:INFO: Batch:  2/31	Total Loss -250.0397 (-228.8142)
2022-11-03 02:14:45,712:INFO: Batch:  3/31	Total Loss -251.2626 (-234.5434)
2022-11-03 02:14:46,216:INFO: Batch:  4/31	Total Loss -238.0728 (-235.2101)
2022-11-03 02:14:46,716:INFO: Batch:  5/31	Total Loss -211.9225 (-231.6090)
2022-11-03 02:14:47,214:INFO: Batch:  6/31	Total Loss -237.4012 (-232.4439)
2022-11-03 02:14:47,716:INFO: Batch:  7/31	Total Loss -217.7282 (-230.5673)
2022-11-03 02:14:48,215:INFO: Batch:  8/31	Total Loss -221.4200 (-229.5909)
2022-11-03 02:14:48,717:INFO: Batch:  9/31	Total Loss -253.2786 (-232.1030)
2022-11-03 02:14:49,216:INFO: Batch: 10/31	Total Loss -214.9888 (-230.7553)
2022-11-03 02:14:49,715:INFO: Batch: 11/31	Total Loss -235.1689 (-231.1342)
2022-11-03 02:14:50,218:INFO: Batch: 12/31	Total Loss -243.5212 (-232.1241)
2022-11-03 02:14:50,719:INFO: Batch: 13/31	Total Loss -244.2803 (-233.0108)
2022-11-03 02:14:51,223:INFO: Batch: 14/31	Total Loss -227.8163 (-232.6934)
2022-11-03 02:14:51,723:INFO: Batch: 15/31	Total Loss -219.4500 (-231.8564)
2022-11-03 02:14:52,218:INFO: Batch: 16/31	Total Loss -223.2205 (-231.4346)
2022-11-03 02:14:52,717:INFO: Batch: 17/31	Total Loss -202.0794 (-229.8918)
2022-11-03 02:14:53,216:INFO: Batch: 18/31	Total Loss -236.9366 (-230.2602)
2022-11-03 02:14:53,715:INFO: Batch: 19/31	Total Loss -265.0335 (-232.0088)
2022-11-03 02:14:54,215:INFO: Batch: 20/31	Total Loss -257.9269 (-233.3460)
2022-11-03 02:14:54,712:INFO: Batch: 21/31	Total Loss -248.6359 (-234.0840)
2022-11-03 02:14:55,214:INFO: Batch: 22/31	Total Loss -253.9525 (-234.9820)
2022-11-03 02:14:55,712:INFO: Batch: 23/31	Total Loss -223.1010 (-234.5302)
2022-11-03 02:14:56,211:INFO: Batch: 24/31	Total Loss -254.1520 (-235.3532)
2022-11-03 02:14:56,710:INFO: Batch: 25/31	Total Loss -205.0639 (-234.1865)
2022-11-03 02:14:57,209:INFO: Batch: 26/31	Total Loss -265.3868 (-235.3574)
2022-11-03 02:14:57,709:INFO: Batch: 27/31	Total Loss -250.5379 (-235.9394)
2022-11-03 02:14:58,206:INFO: Batch: 28/31	Total Loss -245.6273 (-236.2459)
2022-11-03 02:14:58,706:INFO: Batch: 29/31	Total Loss -248.4376 (-236.6772)
2022-11-03 02:14:59,100:INFO: Batch: 30/31	Total Loss -153.4602 (-235.8576)
2022-11-03 02:14:59,266:INFO: - Computing ADE (validation o)
2022-11-03 02:14:59,964:INFO: 		 ADE on eth                       dataset:	 0.9354274272918701
2022-11-03 02:14:59,964:INFO: Average validation o:	ADE  0.9354	FDE  2.0118
2022-11-03 02:14:59,965:INFO: - Computing ADE (validation)
2022-11-03 02:15:00,265:INFO: 		 ADE on hotel                     dataset:	 0.3524911105632782
2022-11-03 02:15:00,625:INFO: 		 ADE on univ                      dataset:	 0.5268417000770569
2022-11-03 02:15:00,904:INFO: 		 ADE on zara1                     dataset:	 0.3817134499549866
2022-11-03 02:15:01,379:INFO: 		 ADE on zara2                     dataset:	 0.37852025032043457
2022-11-03 02:15:01,379:INFO: Average validation:	ADE  0.4544	FDE  0.9779
2022-11-03 02:15:01,380:INFO: - Computing ADE (training)
2022-11-03 02:15:01,983:INFO: 		 ADE on hotel                     dataset:	 0.3550184965133667
2022-11-03 02:15:03,075:INFO: 		 ADE on univ                      dataset:	 0.5190730094909668
2022-11-03 02:15:03,827:INFO: 		 ADE on zara1                     dataset:	 0.41777050495147705
2022-11-03 02:15:05,013:INFO: 		 ADE on zara2                     dataset:	 0.3658493161201477
2022-11-03 02:15:05,014:INFO: Average training:	ADE  0.4774	FDE  1.0287
2022-11-03 02:15:05,025:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_672.pth.tar
2022-11-03 02:15:05,025:INFO: 
===> EPOCH: 673 (P4)
2022-11-03 02:15:05,025:INFO: - Computing loss (training)
2022-11-03 02:15:06,119:INFO: Batch:  0/31	Total Loss -255.0129 (-255.0129)
2022-11-03 02:15:06,614:INFO: Batch:  1/31	Total Loss -267.8110 (-261.5435)
2022-11-03 02:15:07,116:INFO: Batch:  2/31	Total Loss -272.4708 (-265.2114)
2022-11-03 02:15:07,605:INFO: Batch:  3/31	Total Loss -254.7277 (-262.6319)
2022-11-03 02:15:08,095:INFO: Batch:  4/31	Total Loss -241.8616 (-258.1531)
2022-11-03 02:15:08,585:INFO: Batch:  5/31	Total Loss -264.3597 (-259.2124)
2022-11-03 02:15:09,077:INFO: Batch:  6/31	Total Loss -231.0841 (-255.5694)
2022-11-03 02:15:09,576:INFO: Batch:  7/31	Total Loss -274.9299 (-258.3142)
2022-11-03 02:15:10,075:INFO: Batch:  8/31	Total Loss -243.1809 (-256.8109)
2022-11-03 02:15:10,569:INFO: Batch:  9/31	Total Loss -251.5485 (-256.2484)
2022-11-03 02:15:11,061:INFO: Batch: 10/31	Total Loss -223.1994 (-253.4924)
2022-11-03 02:15:11,552:INFO: Batch: 11/31	Total Loss -257.2046 (-253.7829)
2022-11-03 02:15:12,048:INFO: Batch: 12/31	Total Loss -220.6742 (-251.4837)
2022-11-03 02:15:12,542:INFO: Batch: 13/31	Total Loss -223.4583 (-249.5772)
2022-11-03 02:15:13,040:INFO: Batch: 14/31	Total Loss -272.1876 (-251.1139)
2022-11-03 02:15:13,535:INFO: Batch: 15/31	Total Loss -256.4149 (-251.4506)
2022-11-03 02:15:14,029:INFO: Batch: 16/31	Total Loss -206.9822 (-249.1782)
2022-11-03 02:15:14,523:INFO: Batch: 17/31	Total Loss -223.5899 (-247.8092)
2022-11-03 02:15:15,016:INFO: Batch: 18/31	Total Loss -253.8767 (-248.1103)
2022-11-03 02:15:15,509:INFO: Batch: 19/31	Total Loss -247.8658 (-248.0973)
2022-11-03 02:15:16,007:INFO: Batch: 20/31	Total Loss -257.8046 (-248.6253)
2022-11-03 02:15:16,501:INFO: Batch: 21/31	Total Loss -248.6830 (-248.6281)
2022-11-03 02:15:16,997:INFO: Batch: 22/31	Total Loss -249.0035 (-248.6434)
2022-11-03 02:15:17,501:INFO: Batch: 23/31	Total Loss -234.6741 (-248.1558)
2022-11-03 02:15:18,036:INFO: Batch: 24/31	Total Loss -247.5847 (-248.1337)
2022-11-03 02:15:18,532:INFO: Batch: 25/31	Total Loss -245.6265 (-248.0425)
2022-11-03 02:15:19,027:INFO: Batch: 26/31	Total Loss -227.5693 (-247.2926)
2022-11-03 02:15:19,521:INFO: Batch: 27/31	Total Loss -234.9219 (-246.8424)
2022-11-03 02:15:20,015:INFO: Batch: 28/31	Total Loss -232.1891 (-246.4078)
2022-11-03 02:15:20,506:INFO: Batch: 29/31	Total Loss -259.6815 (-246.8949)
2022-11-03 02:15:20,895:INFO: Batch: 30/31	Total Loss -168.0396 (-245.9882)
2022-11-03 02:15:21,049:INFO: - Computing ADE (validation o)
2022-11-03 02:15:21,760:INFO: 		 ADE on eth                       dataset:	 0.9229217171669006
2022-11-03 02:15:21,760:INFO: Average validation o:	ADE  0.9229	FDE  1.9544
2022-11-03 02:15:21,761:INFO: - Computing ADE (validation)
2022-11-03 02:15:22,079:INFO: 		 ADE on hotel                     dataset:	 0.3545162081718445
2022-11-03 02:15:22,435:INFO: 		 ADE on univ                      dataset:	 0.5235536098480225
2022-11-03 02:15:22,728:INFO: 		 ADE on zara1                     dataset:	 0.3938153088092804
2022-11-03 02:15:23,190:INFO: 		 ADE on zara2                     dataset:	 0.3881888687610626
2022-11-03 02:15:23,191:INFO: Average validation:	ADE  0.4571	FDE  0.9822
2022-11-03 02:15:23,191:INFO: - Computing ADE (training)
2022-11-03 02:15:23,747:INFO: 		 ADE on hotel                     dataset:	 0.35755136609077454
2022-11-03 02:15:24,814:INFO: 		 ADE on univ                      dataset:	 0.5187954902648926
2022-11-03 02:15:25,612:INFO: 		 ADE on zara1                     dataset:	 0.4324692487716675
2022-11-03 02:15:26,808:INFO: 		 ADE on zara2                     dataset:	 0.38050997257232666
2022-11-03 02:15:26,808:INFO: Average training:	ADE  0.4811	FDE  1.0369
2022-11-03 02:15:26,819:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_673.pth.tar
2022-11-03 02:15:26,819:INFO: 
===> EPOCH: 674 (P4)
2022-11-03 02:15:26,820:INFO: - Computing loss (training)
2022-11-03 02:15:27,939:INFO: Batch:  0/31	Total Loss -251.2452 (-251.2452)
2022-11-03 02:15:28,515:INFO: Batch:  1/31	Total Loss -237.7843 (-244.6606)
2022-11-03 02:15:29,019:INFO: Batch:  2/31	Total Loss -268.9377 (-253.4252)
2022-11-03 02:15:29,515:INFO: Batch:  3/31	Total Loss -243.7610 (-251.0224)
2022-11-03 02:15:30,014:INFO: Batch:  4/31	Total Loss -243.0853 (-249.4485)
2022-11-03 02:15:30,517:INFO: Batch:  5/31	Total Loss -279.9276 (-255.1937)
2022-11-03 02:15:31,015:INFO: Batch:  6/31	Total Loss -246.9004 (-254.1061)
2022-11-03 02:15:31,512:INFO: Batch:  7/31	Total Loss -247.1175 (-253.2362)
2022-11-03 02:15:32,010:INFO: Batch:  8/31	Total Loss -255.1370 (-253.4601)
2022-11-03 02:15:32,503:INFO: Batch:  9/31	Total Loss -267.4990 (-254.8917)
2022-11-03 02:15:32,997:INFO: Batch: 10/31	Total Loss -243.3826 (-253.8218)
2022-11-03 02:15:33,491:INFO: Batch: 11/31	Total Loss -242.9767 (-253.0313)
2022-11-03 02:15:33,987:INFO: Batch: 12/31	Total Loss -259.8319 (-253.5630)
2022-11-03 02:15:34,487:INFO: Batch: 13/31	Total Loss -220.5017 (-251.3170)
2022-11-03 02:15:34,982:INFO: Batch: 14/31	Total Loss -261.3419 (-252.0337)
2022-11-03 02:15:35,477:INFO: Batch: 15/31	Total Loss -279.1783 (-254.0151)
2022-11-03 02:15:35,973:INFO: Batch: 16/31	Total Loss -243.2882 (-253.3947)
2022-11-03 02:15:36,469:INFO: Batch: 17/31	Total Loss -247.1663 (-253.0718)
2022-11-03 02:15:36,966:INFO: Batch: 18/31	Total Loss -269.9951 (-253.9508)
2022-11-03 02:15:37,463:INFO: Batch: 19/31	Total Loss -235.5519 (-253.0201)
2022-11-03 02:15:37,958:INFO: Batch: 20/31	Total Loss -272.2581 (-253.9642)
2022-11-03 02:15:38,453:INFO: Batch: 21/31	Total Loss -229.4258 (-252.9621)
2022-11-03 02:15:38,948:INFO: Batch: 22/31	Total Loss -254.3279 (-253.0151)
2022-11-03 02:15:39,444:INFO: Batch: 23/31	Total Loss -268.7431 (-253.7350)
2022-11-03 02:15:39,945:INFO: Batch: 24/31	Total Loss -242.9481 (-253.3052)
2022-11-03 02:15:40,451:INFO: Batch: 25/31	Total Loss -280.1707 (-254.4372)
2022-11-03 02:15:40,952:INFO: Batch: 26/31	Total Loss -272.0412 (-255.1407)
2022-11-03 02:15:41,451:INFO: Batch: 27/31	Total Loss -265.2227 (-255.5453)
2022-11-03 02:15:41,952:INFO: Batch: 28/31	Total Loss -257.0104 (-255.5958)
2022-11-03 02:15:42,448:INFO: Batch: 29/31	Total Loss -183.8842 (-253.5578)
2022-11-03 02:15:42,842:INFO: Batch: 30/31	Total Loss -164.6989 (-252.7960)
2022-11-03 02:15:43,006:INFO: - Computing ADE (validation o)
2022-11-03 02:15:43,715:INFO: 		 ADE on eth                       dataset:	 0.9259886741638184
2022-11-03 02:15:43,715:INFO: Average validation o:	ADE  0.9260	FDE  1.9751
2022-11-03 02:15:43,716:INFO: - Computing ADE (validation)
2022-11-03 02:15:44,033:INFO: 		 ADE on hotel                     dataset:	 0.3479713499546051
2022-11-03 02:15:44,404:INFO: 		 ADE on univ                      dataset:	 0.5233579277992249
2022-11-03 02:15:44,708:INFO: 		 ADE on zara1                     dataset:	 0.4012473225593567
2022-11-03 02:15:45,176:INFO: 		 ADE on zara2                     dataset:	 0.38259902596473694
2022-11-03 02:15:45,177:INFO: Average validation:	ADE  0.4550	FDE  0.9802
2022-11-03 02:15:45,177:INFO: - Computing ADE (training)
2022-11-03 02:15:45,755:INFO: 		 ADE on hotel                     dataset:	 0.350585013628006
2022-11-03 02:15:46,809:INFO: 		 ADE on univ                      dataset:	 0.5167776942253113
2022-11-03 02:15:47,563:INFO: 		 ADE on zara1                     dataset:	 0.43015867471694946
2022-11-03 02:15:48,752:INFO: 		 ADE on zara2                     dataset:	 0.37691548466682434
2022-11-03 02:15:48,752:INFO: Average training:	ADE  0.4786	FDE  1.0331
2022-11-03 02:15:48,763:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_674.pth.tar
2022-11-03 02:15:48,764:INFO: 
===> EPOCH: 675 (P4)
2022-11-03 02:15:48,764:INFO: - Computing loss (training)
2022-11-03 02:15:49,858:INFO: Batch:  0/31	Total Loss -256.4155 (-256.4155)
2022-11-03 02:15:50,358:INFO: Batch:  1/31	Total Loss -247.0680 (-252.1368)
2022-11-03 02:15:50,859:INFO: Batch:  2/31	Total Loss -260.9757 (-255.0590)
2022-11-03 02:15:51,356:INFO: Batch:  3/31	Total Loss -303.5901 (-268.4154)
2022-11-03 02:15:51,852:INFO: Batch:  4/31	Total Loss -284.1316 (-271.9012)
2022-11-03 02:15:52,352:INFO: Batch:  5/31	Total Loss -251.6532 (-268.6356)
2022-11-03 02:15:52,863:INFO: Batch:  6/31	Total Loss -252.4555 (-266.4148)
2022-11-03 02:15:53,367:INFO: Batch:  7/31	Total Loss -296.0706 (-270.4873)
2022-11-03 02:15:53,922:INFO: Batch:  8/31	Total Loss -270.6596 (-270.5077)
2022-11-03 02:15:54,570:INFO: Batch:  9/31	Total Loss -243.6301 (-268.2654)
2022-11-03 02:15:55,178:INFO: Batch: 10/31	Total Loss -257.8759 (-267.3425)
2022-11-03 02:15:55,731:INFO: Batch: 11/31	Total Loss -263.8008 (-267.0505)
2022-11-03 02:15:56,281:INFO: Batch: 12/31	Total Loss -287.1064 (-268.7474)
2022-11-03 02:15:56,785:INFO: Batch: 13/31	Total Loss -228.4310 (-265.9291)
2022-11-03 02:15:57,286:INFO: Batch: 14/31	Total Loss -237.8118 (-264.1612)
2022-11-03 02:15:57,788:INFO: Batch: 15/31	Total Loss -228.8832 (-262.2823)
2022-11-03 02:15:58,289:INFO: Batch: 16/31	Total Loss -236.5778 (-260.5861)
2022-11-03 02:15:58,793:INFO: Batch: 17/31	Total Loss -281.7788 (-261.8701)
2022-11-03 02:15:59,311:INFO: Batch: 18/31	Total Loss -249.7173 (-261.2638)
2022-11-03 02:15:59,852:INFO: Batch: 19/31	Total Loss -270.0917 (-261.6803)
2022-11-03 02:16:00,390:INFO: Batch: 20/31	Total Loss -246.0900 (-260.9678)
2022-11-03 02:16:00,936:INFO: Batch: 21/31	Total Loss -246.6988 (-260.3384)
2022-11-03 02:16:01,440:INFO: Batch: 22/31	Total Loss -275.6246 (-261.0205)
2022-11-03 02:16:01,940:INFO: Batch: 23/31	Total Loss -273.2516 (-261.5622)
2022-11-03 02:16:02,454:INFO: Batch: 24/31	Total Loss -247.5241 (-261.0462)
2022-11-03 02:16:02,981:INFO: Batch: 25/31	Total Loss -259.4177 (-260.9869)
2022-11-03 02:16:03,540:INFO: Batch: 26/31	Total Loss -258.4474 (-260.8892)
2022-11-03 02:16:04,056:INFO: Batch: 27/31	Total Loss -257.7960 (-260.7771)
2022-11-03 02:16:04,623:INFO: Batch: 28/31	Total Loss -228.1205 (-259.6749)
2022-11-03 02:16:05,160:INFO: Batch: 29/31	Total Loss -264.8276 (-259.8557)
2022-11-03 02:16:05,588:INFO: Batch: 30/31	Total Loss -165.5183 (-259.0844)
2022-11-03 02:16:05,742:INFO: - Computing ADE (validation o)
2022-11-03 02:16:06,459:INFO: 		 ADE on eth                       dataset:	 0.9246930480003357
2022-11-03 02:16:06,460:INFO: Average validation o:	ADE  0.9247	FDE  2.0060
2022-11-03 02:16:06,461:INFO: - Computing ADE (validation)
2022-11-03 02:16:06,763:INFO: 		 ADE on hotel                     dataset:	 0.3791552186012268
2022-11-03 02:16:07,177:INFO: 		 ADE on univ                      dataset:	 0.5430534482002258
2022-11-03 02:16:07,475:INFO: 		 ADE on zara1                     dataset:	 0.40628352761268616
2022-11-03 02:16:07,963:INFO: 		 ADE on zara2                     dataset:	 0.39400383830070496
2022-11-03 02:16:07,963:INFO: Average validation:	ADE  0.4715	FDE  1.0207
2022-11-03 02:16:07,964:INFO: - Computing ADE (training)
2022-11-03 02:16:08,610:INFO: 		 ADE on hotel                     dataset:	 0.387572318315506
2022-11-03 02:16:09,768:INFO: 		 ADE on univ                      dataset:	 0.5331094264984131
2022-11-03 02:16:10,496:INFO: 		 ADE on zara1                     dataset:	 0.4266487658023834
2022-11-03 02:16:11,690:INFO: 		 ADE on zara2                     dataset:	 0.37743449211120605
2022-11-03 02:16:11,690:INFO: Average training:	ADE  0.4910	FDE  1.0620
2022-11-03 02:16:11,702:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_675.pth.tar
2022-11-03 02:16:11,702:INFO: 
===> EPOCH: 676 (P4)
2022-11-03 02:16:11,702:INFO: - Computing loss (training)
2022-11-03 02:16:12,859:INFO: Batch:  0/31	Total Loss -251.5941 (-251.5941)
2022-11-03 02:16:13,359:INFO: Batch:  1/31	Total Loss -292.1771 (-272.8640)
2022-11-03 02:16:13,884:INFO: Batch:  2/31	Total Loss -236.1231 (-261.1415)
2022-11-03 02:16:14,407:INFO: Batch:  3/31	Total Loss -283.7421 (-267.2679)
2022-11-03 02:16:14,913:INFO: Batch:  4/31	Total Loss -258.5837 (-265.6160)
2022-11-03 02:16:15,421:INFO: Batch:  5/31	Total Loss -293.8530 (-270.9007)
2022-11-03 02:16:15,946:INFO: Batch:  6/31	Total Loss -298.4108 (-274.9946)
2022-11-03 02:16:16,486:INFO: Batch:  7/31	Total Loss -246.8750 (-271.6762)
2022-11-03 02:16:17,018:INFO: Batch:  8/31	Total Loss -248.1088 (-269.2518)
2022-11-03 02:16:17,523:INFO: Batch:  9/31	Total Loss -266.6301 (-268.9688)
2022-11-03 02:16:18,054:INFO: Batch: 10/31	Total Loss -253.7416 (-267.6548)
2022-11-03 02:16:18,565:INFO: Batch: 11/31	Total Loss -262.7048 (-267.2240)
2022-11-03 02:16:19,083:INFO: Batch: 12/31	Total Loss -286.3828 (-268.8602)
2022-11-03 02:16:19,623:INFO: Batch: 13/31	Total Loss -277.3739 (-269.4930)
2022-11-03 02:16:20,175:INFO: Batch: 14/31	Total Loss -243.8981 (-267.7528)
2022-11-03 02:16:20,689:INFO: Batch: 15/31	Total Loss -283.2398 (-268.7663)
2022-11-03 02:16:21,238:INFO: Batch: 16/31	Total Loss -253.6260 (-267.9298)
2022-11-03 02:16:21,767:INFO: Batch: 17/31	Total Loss -269.6292 (-268.0200)
2022-11-03 02:16:22,306:INFO: Batch: 18/31	Total Loss -265.7231 (-267.8968)
2022-11-03 02:16:22,835:INFO: Batch: 19/31	Total Loss -270.4937 (-268.0270)
2022-11-03 02:16:23,359:INFO: Batch: 20/31	Total Loss -247.2855 (-267.1747)
2022-11-03 02:16:23,861:INFO: Batch: 21/31	Total Loss -268.8560 (-267.2576)
2022-11-03 02:16:24,398:INFO: Batch: 22/31	Total Loss -262.0037 (-267.0180)
2022-11-03 02:16:25,013:INFO: Batch: 23/31	Total Loss -232.3386 (-265.7458)
2022-11-03 02:16:25,521:INFO: Batch: 24/31	Total Loss -253.8251 (-265.2618)
2022-11-03 02:16:26,033:INFO: Batch: 25/31	Total Loss -285.6982 (-266.0405)
2022-11-03 02:16:26,563:INFO: Batch: 26/31	Total Loss -274.0713 (-266.3339)
2022-11-03 02:16:27,140:INFO: Batch: 27/31	Total Loss -250.0751 (-265.6623)
2022-11-03 02:16:27,660:INFO: Batch: 28/31	Total Loss -269.1082 (-265.7849)
2022-11-03 02:16:28,183:INFO: Batch: 29/31	Total Loss -267.8599 (-265.8508)
2022-11-03 02:16:28,583:INFO: Batch: 30/31	Total Loss -162.4142 (-264.8732)
2022-11-03 02:16:28,737:INFO: - Computing ADE (validation o)
2022-11-03 02:16:29,442:INFO: 		 ADE on eth                       dataset:	 0.938003659248352
2022-11-03 02:16:29,442:INFO: Average validation o:	ADE  0.9380	FDE  2.0281
2022-11-03 02:16:29,443:INFO: - Computing ADE (validation)
2022-11-03 02:16:29,767:INFO: 		 ADE on hotel                     dataset:	 0.38049471378326416
2022-11-03 02:16:30,155:INFO: 		 ADE on univ                      dataset:	 0.5352598428726196
2022-11-03 02:16:30,468:INFO: 		 ADE on zara1                     dataset:	 0.383113294839859
2022-11-03 02:16:30,943:INFO: 		 ADE on zara2                     dataset:	 0.40378156304359436
2022-11-03 02:16:30,943:INFO: Average validation:	ADE  0.4697	FDE  1.0051
2022-11-03 02:16:30,944:INFO: - Computing ADE (training)
2022-11-03 02:16:31,556:INFO: 		 ADE on hotel                     dataset:	 0.3803150951862335
2022-11-03 02:16:33,004:INFO: 		 ADE on univ                      dataset:	 0.5343347191810608
2022-11-03 02:16:33,788:INFO: 		 ADE on zara1                     dataset:	 0.4271574914455414
2022-11-03 02:16:35,045:INFO: 		 ADE on zara2                     dataset:	 0.3878819942474365
2022-11-03 02:16:35,045:INFO: Average training:	ADE  0.4939	FDE  1.0626
2022-11-03 02:16:35,057:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_676.pth.tar
2022-11-03 02:16:35,057:INFO: 
===> EPOCH: 677 (P4)
2022-11-03 02:16:35,057:INFO: - Computing loss (training)
2022-11-03 02:16:36,186:INFO: Batch:  0/31	Total Loss -266.7843 (-266.7843)
2022-11-03 02:16:36,686:INFO: Batch:  1/31	Total Loss -274.7853 (-270.6796)
2022-11-03 02:16:37,192:INFO: Batch:  2/31	Total Loss -253.5802 (-265.0728)
2022-11-03 02:16:37,697:INFO: Batch:  3/31	Total Loss -236.6624 (-258.1620)
2022-11-03 02:16:38,198:INFO: Batch:  4/31	Total Loss -280.1350 (-262.7876)
2022-11-03 02:16:38,700:INFO: Batch:  5/31	Total Loss -268.4959 (-263.6884)
2022-11-03 02:16:39,200:INFO: Batch:  6/31	Total Loss -264.8976 (-263.8526)
2022-11-03 02:16:39,699:INFO: Batch:  7/31	Total Loss -260.7845 (-263.4939)
2022-11-03 02:16:40,200:INFO: Batch:  8/31	Total Loss -284.9416 (-266.0696)
2022-11-03 02:16:40,698:INFO: Batch:  9/31	Total Loss -283.6127 (-267.9071)
2022-11-03 02:16:41,203:INFO: Batch: 10/31	Total Loss -249.3625 (-266.1990)
2022-11-03 02:16:41,702:INFO: Batch: 11/31	Total Loss -281.9042 (-267.5088)
2022-11-03 02:16:42,217:INFO: Batch: 12/31	Total Loss -262.5715 (-267.1602)
2022-11-03 02:16:42,722:INFO: Batch: 13/31	Total Loss -306.6408 (-270.3483)
2022-11-03 02:16:43,229:INFO: Batch: 14/31	Total Loss -200.9682 (-265.5882)
2022-11-03 02:16:43,736:INFO: Batch: 15/31	Total Loss -255.3712 (-264.9433)
2022-11-03 02:16:44,242:INFO: Batch: 16/31	Total Loss -291.2148 (-266.5919)
2022-11-03 02:16:44,747:INFO: Batch: 17/31	Total Loss -279.8388 (-267.3643)
2022-11-03 02:16:45,254:INFO: Batch: 18/31	Total Loss -271.2783 (-267.5709)
2022-11-03 02:16:45,760:INFO: Batch: 19/31	Total Loss -249.4662 (-266.7262)
2022-11-03 02:16:46,266:INFO: Batch: 20/31	Total Loss -271.2005 (-266.9304)
2022-11-03 02:16:46,770:INFO: Batch: 21/31	Total Loss -285.5547 (-267.7433)
2022-11-03 02:16:47,275:INFO: Batch: 22/31	Total Loss -278.0842 (-268.2079)
2022-11-03 02:16:47,778:INFO: Batch: 23/31	Total Loss -290.1728 (-269.1673)
2022-11-03 02:16:48,279:INFO: Batch: 24/31	Total Loss -269.2484 (-269.1703)
2022-11-03 02:16:48,784:INFO: Batch: 25/31	Total Loss -283.3445 (-269.6896)
2022-11-03 02:16:49,286:INFO: Batch: 26/31	Total Loss -282.6015 (-270.1901)
2022-11-03 02:16:49,789:INFO: Batch: 27/31	Total Loss -296.6727 (-271.2818)
2022-11-03 02:16:50,292:INFO: Batch: 28/31	Total Loss -255.1284 (-270.7520)
2022-11-03 02:16:50,798:INFO: Batch: 29/31	Total Loss -267.7032 (-270.6533)
2022-11-03 02:16:51,196:INFO: Batch: 30/31	Total Loss -150.5320 (-269.6558)
2022-11-03 02:16:51,339:INFO: - Computing ADE (validation o)
2022-11-03 02:16:52,039:INFO: 		 ADE on eth                       dataset:	 0.9246945977210999
2022-11-03 02:16:52,039:INFO: Average validation o:	ADE  0.9247	FDE  1.9270
2022-11-03 02:16:52,040:INFO: - Computing ADE (validation)
2022-11-03 02:16:52,372:INFO: 		 ADE on hotel                     dataset:	 0.36713773012161255
2022-11-03 02:16:52,750:INFO: 		 ADE on univ                      dataset:	 0.5307674407958984
2022-11-03 02:16:53,044:INFO: 		 ADE on zara1                     dataset:	 0.3959541320800781
2022-11-03 02:16:53,507:INFO: 		 ADE on zara2                     dataset:	 0.4045237898826599
2022-11-03 02:16:53,507:INFO: Average validation:	ADE  0.4677	FDE  1.0035
2022-11-03 02:16:53,508:INFO: - Computing ADE (training)
2022-11-03 02:16:54,076:INFO: 		 ADE on hotel                     dataset:	 0.36638692021369934
2022-11-03 02:16:55,160:INFO: 		 ADE on univ                      dataset:	 0.5259213447570801
2022-11-03 02:16:55,926:INFO: 		 ADE on zara1                     dataset:	 0.44605955481529236
2022-11-03 02:16:57,172:INFO: 		 ADE on zara2                     dataset:	 0.3965766429901123
2022-11-03 02:16:57,172:INFO: Average training:	ADE  0.4905	FDE  1.0552
2022-11-03 02:16:57,183:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_677.pth.tar
2022-11-03 02:16:57,183:INFO: 
===> EPOCH: 678 (P4)
2022-11-03 02:16:57,183:INFO: - Computing loss (training)
2022-11-03 02:16:58,308:INFO: Batch:  0/31	Total Loss -249.5336 (-249.5336)
2022-11-03 02:16:58,813:INFO: Batch:  1/31	Total Loss -276.1323 (-262.5547)
2022-11-03 02:16:59,320:INFO: Batch:  2/31	Total Loss -282.1927 (-269.4127)
2022-11-03 02:16:59,829:INFO: Batch:  3/31	Total Loss -287.3952 (-273.9518)
2022-11-03 02:17:00,332:INFO: Batch:  4/31	Total Loss -276.3733 (-274.4188)
2022-11-03 02:17:00,852:INFO: Batch:  5/31	Total Loss -275.8761 (-274.6606)
2022-11-03 02:17:01,363:INFO: Batch:  6/31	Total Loss -293.0783 (-277.3241)
2022-11-03 02:17:01,877:INFO: Batch:  7/31	Total Loss -233.9785 (-272.6850)
2022-11-03 02:17:02,398:INFO: Batch:  8/31	Total Loss -301.6279 (-275.8157)
2022-11-03 02:17:02,913:INFO: Batch:  9/31	Total Loss -216.3237 (-270.4648)
2022-11-03 02:17:03,460:INFO: Batch: 10/31	Total Loss -279.2467 (-271.2764)
2022-11-03 02:17:03,960:INFO: Batch: 11/31	Total Loss -288.7036 (-272.8557)
2022-11-03 02:17:04,501:INFO: Batch: 12/31	Total Loss -264.4211 (-272.2093)
2022-11-03 02:17:05,014:INFO: Batch: 13/31	Total Loss -268.2811 (-271.9193)
2022-11-03 02:17:05,518:INFO: Batch: 14/31	Total Loss -293.4646 (-273.4620)
2022-11-03 02:17:06,026:INFO: Batch: 15/31	Total Loss -302.9909 (-275.7953)
2022-11-03 02:17:06,528:INFO: Batch: 16/31	Total Loss -320.2347 (-278.6895)
2022-11-03 02:17:07,032:INFO: Batch: 17/31	Total Loss -307.6459 (-280.2177)
2022-11-03 02:17:07,539:INFO: Batch: 18/31	Total Loss -280.7142 (-280.2451)
2022-11-03 02:17:08,043:INFO: Batch: 19/31	Total Loss -302.4555 (-281.4417)
2022-11-03 02:17:08,544:INFO: Batch: 20/31	Total Loss -285.8683 (-281.6627)
2022-11-03 02:17:09,047:INFO: Batch: 21/31	Total Loss -293.3729 (-282.2181)
2022-11-03 02:17:09,550:INFO: Batch: 22/31	Total Loss -279.6765 (-282.1018)
2022-11-03 02:17:10,052:INFO: Batch: 23/31	Total Loss -257.3718 (-281.0708)
2022-11-03 02:17:10,555:INFO: Batch: 24/31	Total Loss -249.3004 (-279.9376)
2022-11-03 02:17:11,061:INFO: Batch: 25/31	Total Loss -281.6844 (-280.0012)
2022-11-03 02:17:11,565:INFO: Batch: 26/31	Total Loss -301.6181 (-280.8860)
2022-11-03 02:17:12,071:INFO: Batch: 27/31	Total Loss -284.9727 (-281.0328)
2022-11-03 02:17:12,573:INFO: Batch: 28/31	Total Loss -183.9844 (-278.1821)
2022-11-03 02:17:13,076:INFO: Batch: 29/31	Total Loss -267.3568 (-277.8581)
2022-11-03 02:17:13,473:INFO: Batch: 30/31	Total Loss -167.1962 (-276.7641)
2022-11-03 02:17:13,633:INFO: - Computing ADE (validation o)
2022-11-03 02:17:14,346:INFO: 		 ADE on eth                       dataset:	 0.9262505769729614
2022-11-03 02:17:14,347:INFO: Average validation o:	ADE  0.9263	FDE  1.9818
2022-11-03 02:17:14,348:INFO: - Computing ADE (validation)
2022-11-03 02:17:14,661:INFO: 		 ADE on hotel                     dataset:	 0.3556871712207794
2022-11-03 02:17:15,027:INFO: 		 ADE on univ                      dataset:	 0.5244253277778625
2022-11-03 02:17:15,307:INFO: 		 ADE on zara1                     dataset:	 0.3852831721305847
2022-11-03 02:17:15,786:INFO: 		 ADE on zara2                     dataset:	 0.3847946226596832
2022-11-03 02:17:15,786:INFO: Average validation:	ADE  0.4559	FDE  0.9860
2022-11-03 02:17:15,787:INFO: - Computing ADE (training)
2022-11-03 02:17:16,336:INFO: 		 ADE on hotel                     dataset:	 0.35091179609298706
2022-11-03 02:17:17,413:INFO: 		 ADE on univ                      dataset:	 0.5218707323074341
2022-11-03 02:17:18,142:INFO: 		 ADE on zara1                     dataset:	 0.4157065749168396
2022-11-03 02:17:19,331:INFO: 		 ADE on zara2                     dataset:	 0.3690410256385803
2022-11-03 02:17:19,331:INFO: Average training:	ADE  0.4797	FDE  1.0378
2022-11-03 02:17:19,343:INFO:  --> Model Saved in ./models/eth/CRMF_risk_irm_5.0_batch_het_data_eth_ds_0_bk_20_ep_(150, 100, 300, 400)_shuffle_true_seed_72/pretrain/P4/CRMF_epoch_678.pth.tar
2022-11-03 02:17:19,343:INFO: 
===> EPOCH: 679 (P4)
2022-11-03 02:17:19,343:INFO: - Computing loss (training)
2022-11-03 02:17:20,537:INFO: Batch:  0/31	Total Loss -312.0598 (-312.0598)
2022-11-03 02:17:21,053:INFO: Batch:  1/31	Total Loss -272.6839 (-294.1653)
2022-11-03 02:17:21,565:INFO: Batch:  2/31	Total Loss -304.3400 (-297.8292)
2022-11-03 02:17:22,071:INFO: Batch:  3/31	Total Loss -285.8365 (-295.0214)
2022-11-03 02:17:22,590:INFO: Batch:  4/31	Total Loss -292.8087 (-294.5663)
2022-11-03 02:17:23,109:INFO: Batch:  5/31	Total Loss -270.1188 (-290.6814)
