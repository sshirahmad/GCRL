2022-11-26 18:44:41,912:INFO: Initializing Training Set
2022-11-26 18:44:43,358:INFO: Initializing Validation Set
2022-11-26 18:44:43,529:INFO: Initializing Validation O Set
2022-11-26 18:44:45,531:INFO: 
===> EPOCH: 251 (P3)
2022-11-26 18:44:45,531:INFO: - Computing loss (training)
2022-11-26 18:44:46,230:INFO: Dataset: hotel               Batch: 1/4	Loss 220.0826 (220.0826)
2022-11-26 18:44:46,688:INFO: Dataset: hotel               Batch: 2/4	Loss 216.8382 (218.4485)
2022-11-26 18:44:47,146:INFO: Dataset: hotel               Batch: 3/4	Loss 213.2402 (216.6269)
2022-11-26 18:44:47,571:INFO: Dataset: hotel               Batch: 4/4	Loss 130.7700 (202.0153)
2022-11-26 18:44:48,395:INFO: Dataset: univ                Batch:  1/15	Loss 206.3543 (206.3543)
2022-11-26 18:44:48,901:INFO: Dataset: univ                Batch:  2/15	Loss 205.4891 (205.9282)
2022-11-26 18:44:49,503:INFO: Dataset: univ                Batch:  3/15	Loss 205.0400 (205.6144)
2022-11-26 18:44:50,025:INFO: Dataset: univ                Batch:  4/15	Loss 203.5749 (205.0779)
2022-11-26 18:44:50,534:INFO: Dataset: univ                Batch:  5/15	Loss 203.2873 (204.7425)
2022-11-26 18:44:51,067:INFO: Dataset: univ                Batch:  6/15	Loss 201.7655 (204.2197)
2022-11-26 18:44:51,580:INFO: Dataset: univ                Batch:  7/15	Loss 200.8475 (203.7307)
2022-11-26 18:44:52,090:INFO: Dataset: univ                Batch:  8/15	Loss 199.9265 (203.2675)
2022-11-26 18:44:52,594:INFO: Dataset: univ                Batch:  9/15	Loss 199.4941 (202.8824)
2022-11-26 18:44:53,093:INFO: Dataset: univ                Batch: 10/15	Loss 198.5828 (202.5232)
2022-11-26 18:44:53,624:INFO: Dataset: univ                Batch: 11/15	Loss 196.8737 (201.9486)
2022-11-26 18:44:54,127:INFO: Dataset: univ                Batch: 12/15	Loss 196.5433 (201.5476)
2022-11-26 18:44:54,639:INFO: Dataset: univ                Batch: 13/15	Loss 194.1971 (200.9853)
2022-11-26 18:44:55,152:INFO: Dataset: univ                Batch: 14/15	Loss 192.9890 (200.3992)
2022-11-26 18:44:55,561:INFO: Dataset: univ                Batch: 15/15	Loss 35.8741 (198.0992)
2022-11-26 18:44:56,317:INFO: Dataset: zara1               Batch: 1/8	Loss 209.8380 (209.8380)
2022-11-26 18:44:56,789:INFO: Dataset: zara1               Batch: 2/8	Loss 208.6532 (209.2277)
2022-11-26 18:44:57,255:INFO: Dataset: zara1               Batch: 3/8	Loss 207.9073 (208.7858)
2022-11-26 18:44:57,719:INFO: Dataset: zara1               Batch: 4/8	Loss 205.9991 (208.1103)
2022-11-26 18:44:58,185:INFO: Dataset: zara1               Batch: 5/8	Loss 204.3683 (207.3876)
2022-11-26 18:44:58,653:INFO: Dataset: zara1               Batch: 6/8	Loss 202.4903 (206.5921)
2022-11-26 18:44:59,118:INFO: Dataset: zara1               Batch: 7/8	Loss 200.5240 (205.7845)
2022-11-26 18:44:59,572:INFO: Dataset: zara1               Batch: 8/8	Loss 170.7879 (201.7875)
2022-11-26 18:45:00,388:INFO: Dataset: zara2               Batch:  1/18	Loss 196.0942 (196.0942)
2022-11-26 18:45:00,866:INFO: Dataset: zara2               Batch:  2/18	Loss 192.7128 (194.5308)
2022-11-26 18:45:01,344:INFO: Dataset: zara2               Batch:  3/18	Loss 190.1690 (192.9804)
2022-11-26 18:45:01,820:INFO: Dataset: zara2               Batch:  4/18	Loss 186.4760 (191.2090)
2022-11-26 18:45:02,294:INFO: Dataset: zara2               Batch:  5/18	Loss 182.0801 (189.4256)
2022-11-26 18:45:02,772:INFO: Dataset: zara2               Batch:  6/18	Loss 178.4343 (187.7558)
2022-11-26 18:45:03,248:INFO: Dataset: zara2               Batch:  7/18	Loss 174.9849 (185.8992)
2022-11-26 18:45:03,721:INFO: Dataset: zara2               Batch:  8/18	Loss 172.2306 (184.0860)
2022-11-26 18:45:04,197:INFO: Dataset: zara2               Batch:  9/18	Loss 171.6832 (182.7835)
2022-11-26 18:45:04,672:INFO: Dataset: zara2               Batch: 10/18	Loss 170.4234 (181.5398)
2022-11-26 18:45:05,149:INFO: Dataset: zara2               Batch: 11/18	Loss 176.2413 (181.0982)
2022-11-26 18:45:05,625:INFO: Dataset: zara2               Batch: 12/18	Loss 176.0583 (180.6920)
2022-11-26 18:45:06,100:INFO: Dataset: zara2               Batch: 13/18	Loss 305.7718 (190.9663)
2022-11-26 18:45:06,577:INFO: Dataset: zara2               Batch: 14/18	Loss 170.2273 (189.5787)
2022-11-26 18:45:07,054:INFO: Dataset: zara2               Batch: 15/18	Loss 170.6792 (188.3200)
2022-11-26 18:45:07,532:INFO: Dataset: zara2               Batch: 16/18	Loss 176.3456 (187.4856)
2022-11-26 18:45:08,009:INFO: Dataset: zara2               Batch: 17/18	Loss 178.7841 (186.9694)
2022-11-26 18:45:08,474:INFO: Dataset: zara2               Batch: 18/18	Loss 151.7863 (185.4164)
2022-11-26 18:45:08,532:INFO: - Computing ADE (validation)
2022-11-26 18:45:08,888:INFO: 		 ADE on hotel                     dataset:	 3.053438663482666
2022-11-26 18:45:09,301:INFO: 		 ADE on univ                      dataset:	 3.8399460315704346
2022-11-26 18:45:09,640:INFO: 		 ADE on zara1                     dataset:	 3.103445291519165
2022-11-26 18:45:10,171:INFO: 		 ADE on zara2                     dataset:	 3.314304828643799
2022-11-26 18:45:10,171:INFO: Average validation:	ADE  3.5612	FDE  5.2216
2022-11-26 18:45:10,172:INFO: - Computing ADE (validation o)
2022-11-26 18:45:10,470:INFO: 		 ADE on eth                       dataset:	 3.1098968982696533
2022-11-26 18:45:10,471:INFO: Average validation o:	ADE  3.1099	FDE  4.1429
2022-11-26 18:45:10,478:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_251.pth.tar
2022-11-26 18:45:10,478:INFO: 
===> EPOCH: 252 (P3)
2022-11-26 18:45:10,479:INFO: - Computing loss (training)
2022-11-26 18:45:11,162:INFO: Dataset: hotel               Batch: 1/4	Loss 223.0128 (223.0128)
2022-11-26 18:45:11,646:INFO: Dataset: hotel               Batch: 2/4	Loss 272.3919 (246.4408)
2022-11-26 18:45:12,109:INFO: Dataset: hotel               Batch: 3/4	Loss 204.6623 (231.7032)
2022-11-26 18:45:12,528:INFO: Dataset: hotel               Batch: 4/4	Loss 118.5938 (213.3490)
2022-11-26 18:45:13,326:INFO: Dataset: univ                Batch:  1/15	Loss 173.6228 (173.6228)
2022-11-26 18:45:13,854:INFO: Dataset: univ                Batch:  2/15	Loss 172.6061 (173.0904)
2022-11-26 18:45:14,369:INFO: Dataset: univ                Batch:  3/15	Loss 170.6096 (172.2581)
2022-11-26 18:45:14,888:INFO: Dataset: univ                Batch:  4/15	Loss 170.5757 (171.8182)
2022-11-26 18:45:15,405:INFO: Dataset: univ                Batch:  5/15	Loss 171.2345 (171.7019)
2022-11-26 18:45:15,919:INFO: Dataset: univ                Batch:  6/15	Loss 170.2140 (171.4550)
2022-11-26 18:45:16,431:INFO: Dataset: univ                Batch:  7/15	Loss 173.2525 (171.7106)
2022-11-26 18:45:16,953:INFO: Dataset: univ                Batch:  8/15	Loss 170.5493 (171.5514)
2022-11-26 18:45:17,466:INFO: Dataset: univ                Batch:  9/15	Loss 169.9032 (171.3682)
2022-11-26 18:45:17,977:INFO: Dataset: univ                Batch: 10/15	Loss 170.6882 (171.3020)
2022-11-26 18:45:18,487:INFO: Dataset: univ                Batch: 11/15	Loss 169.7135 (171.1640)
2022-11-26 18:45:19,000:INFO: Dataset: univ                Batch: 12/15	Loss 170.0759 (171.0770)
2022-11-26 18:45:19,510:INFO: Dataset: univ                Batch: 13/15	Loss 170.2596 (171.0193)
2022-11-26 18:45:20,108:INFO: Dataset: univ                Batch: 14/15	Loss 169.7686 (170.9294)
2022-11-26 18:45:20,516:INFO: Dataset: univ                Batch: 15/15	Loss 31.7292 (169.4319)
2022-11-26 18:45:21,285:INFO: Dataset: zara1               Batch: 1/8	Loss 180.2318 (180.2318)
2022-11-26 18:45:21,760:INFO: Dataset: zara1               Batch: 2/8	Loss 179.9180 (180.0692)
2022-11-26 18:45:22,231:INFO: Dataset: zara1               Batch: 3/8	Loss 179.1492 (179.7820)
2022-11-26 18:45:22,704:INFO: Dataset: zara1               Batch: 4/8	Loss 179.4464 (179.6944)
2022-11-26 18:45:23,171:INFO: Dataset: zara1               Batch: 5/8	Loss 179.3226 (179.6267)
2022-11-26 18:45:23,641:INFO: Dataset: zara1               Batch: 6/8	Loss 179.4816 (179.6039)
2022-11-26 18:45:24,118:INFO: Dataset: zara1               Batch: 7/8	Loss 179.9753 (179.6626)
2022-11-26 18:45:24,574:INFO: Dataset: zara1               Batch: 8/8	Loss 154.0669 (176.8201)
2022-11-26 18:45:25,354:INFO: Dataset: zara2               Batch:  1/18	Loss 177.0773 (177.0773)
2022-11-26 18:45:25,834:INFO: Dataset: zara2               Batch:  2/18	Loss 175.8686 (176.4550)
2022-11-26 18:45:26,313:INFO: Dataset: zara2               Batch:  3/18	Loss 175.5794 (176.1780)
2022-11-26 18:45:26,793:INFO: Dataset: zara2               Batch:  4/18	Loss 176.4847 (176.2524)
2022-11-26 18:45:27,271:INFO: Dataset: zara2               Batch:  5/18	Loss 175.5768 (176.0969)
2022-11-26 18:45:27,751:INFO: Dataset: zara2               Batch:  6/18	Loss 173.9362 (175.7550)
2022-11-26 18:45:28,226:INFO: Dataset: zara2               Batch:  7/18	Loss 174.5147 (175.5611)
2022-11-26 18:45:28,704:INFO: Dataset: zara2               Batch:  8/18	Loss 174.8363 (175.4720)
2022-11-26 18:45:29,182:INFO: Dataset: zara2               Batch:  9/18	Loss 174.3650 (175.3379)
2022-11-26 18:45:29,659:INFO: Dataset: zara2               Batch: 10/18	Loss 173.8167 (175.1875)
2022-11-26 18:45:30,141:INFO: Dataset: zara2               Batch: 11/18	Loss 173.1319 (175.0308)
2022-11-26 18:45:30,618:INFO: Dataset: zara2               Batch: 12/18	Loss 174.9590 (175.0248)
2022-11-26 18:45:31,096:INFO: Dataset: zara2               Batch: 13/18	Loss 173.8400 (174.9331)
2022-11-26 18:45:31,575:INFO: Dataset: zara2               Batch: 14/18	Loss 172.0441 (174.6996)
2022-11-26 18:45:32,055:INFO: Dataset: zara2               Batch: 15/18	Loss 172.5874 (174.5730)
2022-11-26 18:45:32,534:INFO: Dataset: zara2               Batch: 16/18	Loss 171.2897 (174.3683)
2022-11-26 18:45:33,014:INFO: Dataset: zara2               Batch: 17/18	Loss 170.8780 (174.1595)
2022-11-26 18:45:33,481:INFO: Dataset: zara2               Batch: 18/18	Loss 146.5089 (172.7927)
2022-11-26 18:45:33,538:INFO: - Computing ADE (validation)
2022-11-26 18:45:33,884:INFO: 		 ADE on hotel                     dataset:	 3.0266456604003906
2022-11-26 18:45:34,295:INFO: 		 ADE on univ                      dataset:	 3.555929660797119
2022-11-26 18:45:34,632:INFO: 		 ADE on zara1                     dataset:	 2.996668815612793
2022-11-26 18:45:35,162:INFO: 		 ADE on zara2                     dataset:	 3.0729990005493164
2022-11-26 18:45:35,162:INFO: Average validation:	ADE  3.3173	FDE  4.5668
2022-11-26 18:45:35,163:INFO: - Computing ADE (validation o)
2022-11-26 18:45:35,459:INFO: 		 ADE on eth                       dataset:	 2.8696093559265137
2022-11-26 18:45:35,459:INFO: Average validation o:	ADE  2.8696	FDE  3.8450
2022-11-26 18:45:35,466:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_252.pth.tar
2022-11-26 18:45:35,467:INFO: 
===> EPOCH: 253 (P3)
2022-11-26 18:45:35,467:INFO: - Computing loss (training)
2022-11-26 18:45:36,170:INFO: Dataset: hotel               Batch: 1/4	Loss 220.9146 (220.9146)
2022-11-26 18:45:36,646:INFO: Dataset: hotel               Batch: 2/4	Loss 217.7357 (219.3327)
2022-11-26 18:45:37,146:INFO: Dataset: hotel               Batch: 3/4	Loss 201.6753 (213.6551)
2022-11-26 18:45:37,593:INFO: Dataset: hotel               Batch: 4/4	Loss 117.6218 (196.4248)
2022-11-26 18:45:38,392:INFO: Dataset: univ                Batch:  1/15	Loss 165.9740 (165.9740)
2022-11-26 18:45:38,911:INFO: Dataset: univ                Batch:  2/15	Loss 165.6468 (165.8053)
2022-11-26 18:45:39,417:INFO: Dataset: univ                Batch:  3/15	Loss 165.4640 (165.7029)
2022-11-26 18:45:39,933:INFO: Dataset: univ                Batch:  4/15	Loss 165.0423 (165.5348)
2022-11-26 18:45:40,449:INFO: Dataset: univ                Batch:  5/15	Loss 165.2342 (165.4762)
2022-11-26 18:45:40,969:INFO: Dataset: univ                Batch:  6/15	Loss 164.9438 (165.3882)
2022-11-26 18:45:41,486:INFO: Dataset: univ                Batch:  7/15	Loss 165.1383 (165.3507)
2022-11-26 18:45:41,993:INFO: Dataset: univ                Batch:  8/15	Loss 164.8201 (165.2884)
2022-11-26 18:45:42,520:INFO: Dataset: univ                Batch:  9/15	Loss 164.3626 (165.1741)
2022-11-26 18:45:43,036:INFO: Dataset: univ                Batch: 10/15	Loss 164.6488 (165.1195)
2022-11-26 18:45:43,552:INFO: Dataset: univ                Batch: 11/15	Loss 164.7245 (165.0840)
2022-11-26 18:45:44,085:INFO: Dataset: univ                Batch: 12/15	Loss 163.9463 (164.9738)
2022-11-26 18:45:44,606:INFO: Dataset: univ                Batch: 13/15	Loss 163.5598 (164.8591)
2022-11-26 18:45:45,137:INFO: Dataset: univ                Batch: 14/15	Loss 163.7151 (164.7772)
2022-11-26 18:45:45,556:INFO: Dataset: univ                Batch: 15/15	Loss 30.3775 (162.7837)
2022-11-26 18:45:46,333:INFO: Dataset: zara1               Batch: 1/8	Loss 173.0827 (173.0827)
2022-11-26 18:45:46,812:INFO: Dataset: zara1               Batch: 2/8	Loss 172.7699 (172.9354)
2022-11-26 18:45:47,306:INFO: Dataset: zara1               Batch: 3/8	Loss 173.3554 (173.0940)
2022-11-26 18:45:47,786:INFO: Dataset: zara1               Batch: 4/8	Loss 173.4130 (173.1726)
2022-11-26 18:45:48,260:INFO: Dataset: zara1               Batch: 5/8	Loss 172.0733 (172.9595)
2022-11-26 18:45:48,839:INFO: Dataset: zara1               Batch: 6/8	Loss 173.4826 (173.0379)
2022-11-26 18:45:49,423:INFO: Dataset: zara1               Batch: 7/8	Loss 172.2466 (172.9284)
2022-11-26 18:45:49,924:INFO: Dataset: zara1               Batch: 8/8	Loss 148.5571 (170.6965)
2022-11-26 18:45:50,718:INFO: Dataset: zara2               Batch:  1/18	Loss 169.8168 (169.8168)
2022-11-26 18:45:51,219:INFO: Dataset: zara2               Batch:  2/18	Loss 169.5786 (169.6999)
2022-11-26 18:45:51,735:INFO: Dataset: zara2               Batch:  3/18	Loss 169.3117 (169.5731)
2022-11-26 18:45:52,224:INFO: Dataset: zara2               Batch:  4/18	Loss 167.5202 (169.1311)
2022-11-26 18:45:52,756:INFO: Dataset: zara2               Batch:  5/18	Loss 168.2516 (168.9454)
2022-11-26 18:45:53,293:INFO: Dataset: zara2               Batch:  6/18	Loss 166.3794 (168.5235)
2022-11-26 18:45:53,855:INFO: Dataset: zara2               Batch:  7/18	Loss 167.1338 (168.3052)
2022-11-26 18:45:54,353:INFO: Dataset: zara2               Batch:  8/18	Loss 166.2348 (168.0438)
2022-11-26 18:45:54,846:INFO: Dataset: zara2               Batch:  9/18	Loss 165.4261 (167.7866)
2022-11-26 18:45:55,332:INFO: Dataset: zara2               Batch: 10/18	Loss 165.1906 (167.5227)
2022-11-26 18:45:55,817:INFO: Dataset: zara2               Batch: 11/18	Loss 164.5448 (167.2663)
2022-11-26 18:45:56,305:INFO: Dataset: zara2               Batch: 12/18	Loss 164.9550 (167.0693)
2022-11-26 18:45:56,786:INFO: Dataset: zara2               Batch: 13/18	Loss 163.9738 (166.8137)
2022-11-26 18:45:57,268:INFO: Dataset: zara2               Batch: 14/18	Loss 163.9484 (166.6003)
2022-11-26 18:45:57,750:INFO: Dataset: zara2               Batch: 15/18	Loss 163.2878 (166.3810)
2022-11-26 18:45:58,232:INFO: Dataset: zara2               Batch: 16/18	Loss 163.0346 (166.1587)
2022-11-26 18:45:58,714:INFO: Dataset: zara2               Batch: 17/18	Loss 162.1335 (165.9073)
2022-11-26 18:45:59,185:INFO: Dataset: zara2               Batch: 18/18	Loss 139.6746 (164.7451)
2022-11-26 18:45:59,242:INFO: - Computing ADE (validation)
2022-11-26 18:45:59,602:INFO: 		 ADE on hotel                     dataset:	 2.909734010696411
2022-11-26 18:46:00,015:INFO: 		 ADE on univ                      dataset:	 3.5374083518981934
2022-11-26 18:46:00,361:INFO: 		 ADE on zara1                     dataset:	 2.9642417430877686
2022-11-26 18:46:00,898:INFO: 		 ADE on zara2                     dataset:	 3.0596344470977783
2022-11-26 18:46:00,898:INFO: Average validation:	ADE  3.2945	FDE  4.5302
2022-11-26 18:46:00,899:INFO: - Computing ADE (validation o)
2022-11-26 18:46:01,194:INFO: 		 ADE on eth                       dataset:	 3.050565481185913
2022-11-26 18:46:01,194:INFO: Average validation o:	ADE  3.0506	FDE  4.1325
2022-11-26 18:46:01,202:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_253.pth.tar
2022-11-26 18:46:01,202:INFO: 
===> EPOCH: 254 (P3)
2022-11-26 18:46:01,202:INFO: - Computing loss (training)
2022-11-26 18:46:01,901:INFO: Dataset: hotel               Batch: 1/4	Loss 176.9806 (176.9806)
2022-11-26 18:46:02,378:INFO: Dataset: hotel               Batch: 2/4	Loss 179.3672 (178.1852)
2022-11-26 18:46:02,849:INFO: Dataset: hotel               Batch: 3/4	Loss 178.9550 (178.4426)
2022-11-26 18:46:03,272:INFO: Dataset: hotel               Batch: 4/4	Loss 104.3792 (166.6198)
2022-11-26 18:46:04,115:INFO: Dataset: univ                Batch:  1/15	Loss 159.6761 (159.6761)
2022-11-26 18:46:04,628:INFO: Dataset: univ                Batch:  2/15	Loss 160.7113 (160.1579)
2022-11-26 18:46:05,142:INFO: Dataset: univ                Batch:  3/15	Loss 160.0860 (160.1354)
2022-11-26 18:46:05,661:INFO: Dataset: univ                Batch:  4/15	Loss 158.1593 (159.6268)
2022-11-26 18:46:06,189:INFO: Dataset: univ                Batch:  5/15	Loss 156.1471 (158.8743)
2022-11-26 18:46:06,711:INFO: Dataset: univ                Batch:  6/15	Loss 155.7133 (158.3512)
2022-11-26 18:46:07,224:INFO: Dataset: univ                Batch:  7/15	Loss 155.5005 (157.9643)
2022-11-26 18:46:07,749:INFO: Dataset: univ                Batch:  8/15	Loss 154.7168 (157.5346)
2022-11-26 18:46:08,265:INFO: Dataset: univ                Batch:  9/15	Loss 154.7095 (157.2348)
2022-11-26 18:46:08,784:INFO: Dataset: univ                Batch: 10/15	Loss 154.7574 (156.9811)
2022-11-26 18:46:09,304:INFO: Dataset: univ                Batch: 11/15	Loss 155.5725 (156.8549)
2022-11-26 18:46:09,827:INFO: Dataset: univ                Batch: 12/15	Loss 154.8303 (156.6809)
2022-11-26 18:46:10,342:INFO: Dataset: univ                Batch: 13/15	Loss 155.3452 (156.5839)
2022-11-26 18:46:10,862:INFO: Dataset: univ                Batch: 14/15	Loss 154.4607 (156.4338)
2022-11-26 18:46:11,279:INFO: Dataset: univ                Batch: 15/15	Loss 28.8970 (154.4696)
2022-11-26 18:46:12,032:INFO: Dataset: zara1               Batch: 1/8	Loss 160.3839 (160.3839)
2022-11-26 18:46:12,508:INFO: Dataset: zara1               Batch: 2/8	Loss 160.5115 (160.4485)
2022-11-26 18:46:12,995:INFO: Dataset: zara1               Batch: 3/8	Loss 159.3799 (160.0769)
2022-11-26 18:46:13,470:INFO: Dataset: zara1               Batch: 4/8	Loss 158.8291 (159.7787)
2022-11-26 18:46:13,944:INFO: Dataset: zara1               Batch: 5/8	Loss 159.4043 (159.7023)
2022-11-26 18:46:14,419:INFO: Dataset: zara1               Batch: 6/8	Loss 158.9319 (159.5796)
2022-11-26 18:46:14,893:INFO: Dataset: zara1               Batch: 7/8	Loss 158.0019 (159.3589)
2022-11-26 18:46:15,355:INFO: Dataset: zara1               Batch: 8/8	Loss 135.3645 (156.7574)
2022-11-26 18:46:16,129:INFO: Dataset: zara2               Batch:  1/18	Loss 157.1593 (157.1593)
2022-11-26 18:46:16,614:INFO: Dataset: zara2               Batch:  2/18	Loss 156.4944 (156.8181)
2022-11-26 18:46:17,097:INFO: Dataset: zara2               Batch:  3/18	Loss 157.0599 (156.9024)
2022-11-26 18:46:17,585:INFO: Dataset: zara2               Batch:  4/18	Loss 155.5753 (156.5530)
2022-11-26 18:46:18,068:INFO: Dataset: zara2               Batch:  5/18	Loss 154.9074 (156.2223)
2022-11-26 18:46:18,554:INFO: Dataset: zara2               Batch:  6/18	Loss 156.0009 (156.1840)
2022-11-26 18:46:19,118:INFO: Dataset: zara2               Batch:  7/18	Loss 155.1262 (156.0291)
2022-11-26 18:46:19,603:INFO: Dataset: zara2               Batch:  8/18	Loss 154.6225 (155.8661)
2022-11-26 18:46:20,085:INFO: Dataset: zara2               Batch:  9/18	Loss 154.3041 (155.6840)
2022-11-26 18:46:20,570:INFO: Dataset: zara2               Batch: 10/18	Loss 153.3716 (155.4539)
2022-11-26 18:46:21,055:INFO: Dataset: zara2               Batch: 11/18	Loss 153.5645 (155.2950)
2022-11-26 18:46:21,540:INFO: Dataset: zara2               Batch: 12/18	Loss 153.6701 (155.1608)
2022-11-26 18:46:22,024:INFO: Dataset: zara2               Batch: 13/18	Loss 153.5617 (155.0351)
2022-11-26 18:46:22,509:INFO: Dataset: zara2               Batch: 14/18	Loss 152.9922 (154.8878)
2022-11-26 18:46:22,993:INFO: Dataset: zara2               Batch: 15/18	Loss 152.1893 (154.7098)
2022-11-26 18:46:23,479:INFO: Dataset: zara2               Batch: 16/18	Loss 153.2210 (154.6138)
2022-11-26 18:46:23,965:INFO: Dataset: zara2               Batch: 17/18	Loss 151.5945 (154.4492)
2022-11-26 18:46:24,438:INFO: Dataset: zara2               Batch: 18/18	Loss 130.7626 (153.3136)
2022-11-26 18:46:24,497:INFO: - Computing ADE (validation)
2022-11-26 18:46:24,843:INFO: 		 ADE on hotel                     dataset:	 2.982001781463623
2022-11-26 18:46:25,258:INFO: 		 ADE on univ                      dataset:	 3.4864208698272705
2022-11-26 18:46:25,593:INFO: 		 ADE on zara1                     dataset:	 2.9400315284729004
2022-11-26 18:46:26,122:INFO: 		 ADE on zara2                     dataset:	 3.0406296253204346
2022-11-26 18:46:26,122:INFO: Average validation:	ADE  3.2635	FDE  4.5430
2022-11-26 18:46:26,123:INFO: - Computing ADE (validation o)
2022-11-26 18:46:26,415:INFO: 		 ADE on eth                       dataset:	 3.142540454864502
2022-11-26 18:46:26,415:INFO: Average validation o:	ADE  3.1425	FDE  3.7883
2022-11-26 18:46:26,423:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_254.pth.tar
2022-11-26 18:46:26,423:INFO: 
===> EPOCH: 255 (P3)
2022-11-26 18:46:26,424:INFO: - Computing loss (training)
2022-11-26 18:46:27,111:INFO: Dataset: hotel               Batch: 1/4	Loss 162.5446 (162.5446)
2022-11-26 18:46:27,588:INFO: Dataset: hotel               Batch: 2/4	Loss 158.1609 (160.4106)
2022-11-26 18:46:28,060:INFO: Dataset: hotel               Batch: 3/4	Loss 158.5326 (159.7737)
2022-11-26 18:46:28,487:INFO: Dataset: hotel               Batch: 4/4	Loss 100.4952 (149.8418)
2022-11-26 18:46:29,306:INFO: Dataset: univ                Batch:  1/15	Loss 149.7699 (149.7699)
2022-11-26 18:46:29,836:INFO: Dataset: univ                Batch:  2/15	Loss 149.8632 (149.8178)
2022-11-26 18:46:30,364:INFO: Dataset: univ                Batch:  3/15	Loss 151.1125 (150.2453)
2022-11-26 18:46:30,883:INFO: Dataset: univ                Batch:  4/15	Loss 149.5650 (150.0883)
2022-11-26 18:46:31,414:INFO: Dataset: univ                Batch:  5/15	Loss 149.8353 (150.0356)
2022-11-26 18:46:31,946:INFO: Dataset: univ                Batch:  6/15	Loss 150.1552 (150.0560)
2022-11-26 18:46:32,471:INFO: Dataset: univ                Batch:  7/15	Loss 150.3017 (150.0907)
2022-11-26 18:46:32,990:INFO: Dataset: univ                Batch:  8/15	Loss 149.8864 (150.0670)
2022-11-26 18:46:33,512:INFO: Dataset: univ                Batch:  9/15	Loss 150.5298 (150.1163)
2022-11-26 18:46:34,041:INFO: Dataset: univ                Batch: 10/15	Loss 149.4582 (150.0484)
2022-11-26 18:46:34,567:INFO: Dataset: univ                Batch: 11/15	Loss 149.3457 (149.9823)
2022-11-26 18:46:35,097:INFO: Dataset: univ                Batch: 12/15	Loss 149.2878 (149.9221)
2022-11-26 18:46:35,620:INFO: Dataset: univ                Batch: 13/15	Loss 149.4707 (149.8878)
2022-11-26 18:46:36,151:INFO: Dataset: univ                Batch: 14/15	Loss 149.2267 (149.8379)
2022-11-26 18:46:36,574:INFO: Dataset: univ                Batch: 15/15	Loss 27.9256 (148.0297)
2022-11-26 18:46:37,331:INFO: Dataset: zara1               Batch: 1/8	Loss 153.9793 (153.9793)
2022-11-26 18:46:37,816:INFO: Dataset: zara1               Batch: 2/8	Loss 152.4061 (153.1715)
2022-11-26 18:46:38,291:INFO: Dataset: zara1               Batch: 3/8	Loss 151.8161 (152.7776)
2022-11-26 18:46:38,767:INFO: Dataset: zara1               Batch: 4/8	Loss 151.9456 (152.5972)
2022-11-26 18:46:39,243:INFO: Dataset: zara1               Batch: 5/8	Loss 151.2655 (152.3428)
2022-11-26 18:46:39,740:INFO: Dataset: zara1               Batch: 6/8	Loss 150.3986 (151.9695)
2022-11-26 18:46:40,215:INFO: Dataset: zara1               Batch: 7/8	Loss 151.8433 (151.9510)
2022-11-26 18:46:40,677:INFO: Dataset: zara1               Batch: 8/8	Loss 130.6386 (149.4608)
2022-11-26 18:46:41,440:INFO: Dataset: zara2               Batch:  1/18	Loss 149.8056 (149.8056)
2022-11-26 18:46:41,933:INFO: Dataset: zara2               Batch:  2/18	Loss 150.2931 (150.0190)
2022-11-26 18:46:42,423:INFO: Dataset: zara2               Batch:  3/18	Loss 151.8738 (150.6456)
2022-11-26 18:46:42,915:INFO: Dataset: zara2               Batch:  4/18	Loss 149.3525 (150.3253)
2022-11-26 18:46:43,405:INFO: Dataset: zara2               Batch:  5/18	Loss 149.9454 (150.2501)
2022-11-26 18:46:43,900:INFO: Dataset: zara2               Batch:  6/18	Loss 149.9913 (150.2067)
2022-11-26 18:46:44,392:INFO: Dataset: zara2               Batch:  7/18	Loss 148.8839 (150.0219)
2022-11-26 18:46:44,883:INFO: Dataset: zara2               Batch:  8/18	Loss 149.2586 (149.9369)
2022-11-26 18:46:45,372:INFO: Dataset: zara2               Batch:  9/18	Loss 149.2880 (149.8695)
2022-11-26 18:46:45,862:INFO: Dataset: zara2               Batch: 10/18	Loss 149.2010 (149.7988)
2022-11-26 18:46:46,352:INFO: Dataset: zara2               Batch: 11/18	Loss 150.2648 (149.8439)
2022-11-26 18:46:46,843:INFO: Dataset: zara2               Batch: 12/18	Loss 149.0883 (149.7865)
2022-11-26 18:46:47,342:INFO: Dataset: zara2               Batch: 13/18	Loss 149.1658 (149.7367)
2022-11-26 18:46:47,841:INFO: Dataset: zara2               Batch: 14/18	Loss 149.7680 (149.7389)
2022-11-26 18:46:48,341:INFO: Dataset: zara2               Batch: 15/18	Loss 148.8470 (149.6795)
2022-11-26 18:46:48,840:INFO: Dataset: zara2               Batch: 16/18	Loss 149.2853 (149.6550)
2022-11-26 18:46:49,348:INFO: Dataset: zara2               Batch: 17/18	Loss 149.8899 (149.6682)
2022-11-26 18:46:49,936:INFO: Dataset: zara2               Batch: 18/18	Loss 129.2005 (148.6328)
2022-11-26 18:46:49,995:INFO: - Computing ADE (validation)
2022-11-26 18:46:50,350:INFO: 		 ADE on hotel                     dataset:	 2.8229827880859375
2022-11-26 18:46:50,765:INFO: 		 ADE on univ                      dataset:	 3.4479727745056152
2022-11-26 18:46:51,122:INFO: 		 ADE on zara1                     dataset:	 2.9205915927886963
2022-11-26 18:46:51,653:INFO: 		 ADE on zara2                     dataset:	 3.0006163120269775
2022-11-26 18:46:51,653:INFO: Average validation:	ADE  3.2190	FDE  4.4247
2022-11-26 18:46:51,654:INFO: - Computing ADE (validation o)
2022-11-26 18:46:51,950:INFO: 		 ADE on eth                       dataset:	 2.9805543422698975
2022-11-26 18:46:51,950:INFO: Average validation o:	ADE  2.9806	FDE  3.7052
2022-11-26 18:46:51,958:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_255.pth.tar
2022-11-26 18:46:51,958:INFO: 
===> EPOCH: 256 (P3)
2022-11-26 18:46:51,958:INFO: - Computing loss (training)
2022-11-26 18:46:52,655:INFO: Dataset: hotel               Batch: 1/4	Loss 154.6670 (154.6670)
2022-11-26 18:46:53,136:INFO: Dataset: hotel               Batch: 2/4	Loss 156.3345 (155.4479)
2022-11-26 18:46:53,613:INFO: Dataset: hotel               Batch: 3/4	Loss 155.9033 (155.5878)
2022-11-26 18:46:54,041:INFO: Dataset: hotel               Batch: 4/4	Loss 97.1422 (146.3352)
2022-11-26 18:46:54,820:INFO: Dataset: univ                Batch:  1/15	Loss 148.4911 (148.4911)
2022-11-26 18:46:55,340:INFO: Dataset: univ                Batch:  2/15	Loss 148.2041 (148.3415)
2022-11-26 18:46:55,862:INFO: Dataset: univ                Batch:  3/15	Loss 148.9499 (148.5499)
2022-11-26 18:46:56,386:INFO: Dataset: univ                Batch:  4/15	Loss 147.2827 (148.2155)
2022-11-26 18:46:56,921:INFO: Dataset: univ                Batch:  5/15	Loss 148.6599 (148.3050)
2022-11-26 18:46:57,459:INFO: Dataset: univ                Batch:  6/15	Loss 146.9863 (148.0489)
2022-11-26 18:46:57,989:INFO: Dataset: univ                Batch:  7/15	Loss 147.5136 (147.9644)
2022-11-26 18:46:58,510:INFO: Dataset: univ                Batch:  8/15	Loss 148.5206 (148.0339)
2022-11-26 18:46:59,036:INFO: Dataset: univ                Batch:  9/15	Loss 147.2049 (147.9380)
2022-11-26 18:46:59,559:INFO: Dataset: univ                Batch: 10/15	Loss 146.7188 (147.8145)
2022-11-26 18:47:00,083:INFO: Dataset: univ                Batch: 11/15	Loss 147.2070 (147.7598)
2022-11-26 18:47:00,604:INFO: Dataset: univ                Batch: 12/15	Loss 146.6395 (147.6684)
2022-11-26 18:47:01,124:INFO: Dataset: univ                Batch: 13/15	Loss 147.6420 (147.6664)
2022-11-26 18:47:01,645:INFO: Dataset: univ                Batch: 14/15	Loss 146.5391 (147.5902)
2022-11-26 18:47:02,066:INFO: Dataset: univ                Batch: 15/15	Loss 27.4098 (145.7792)
2022-11-26 18:47:02,830:INFO: Dataset: zara1               Batch: 1/8	Loss 149.7150 (149.7150)
2022-11-26 18:47:03,311:INFO: Dataset: zara1               Batch: 2/8	Loss 148.9893 (149.3606)
2022-11-26 18:47:03,787:INFO: Dataset: zara1               Batch: 3/8	Loss 148.8889 (149.2023)
2022-11-26 18:47:04,275:INFO: Dataset: zara1               Batch: 4/8	Loss 147.7179 (148.8030)
2022-11-26 18:47:04,752:INFO: Dataset: zara1               Batch: 5/8	Loss 149.4871 (148.9276)
2022-11-26 18:47:05,239:INFO: Dataset: zara1               Batch: 6/8	Loss 148.0711 (148.7746)
2022-11-26 18:47:05,716:INFO: Dataset: zara1               Batch: 7/8	Loss 147.8935 (148.6482)
2022-11-26 18:47:06,181:INFO: Dataset: zara1               Batch: 8/8	Loss 128.0386 (146.4028)
2022-11-26 18:47:06,948:INFO: Dataset: zara2               Batch:  1/18	Loss 147.3670 (147.3670)
2022-11-26 18:47:07,443:INFO: Dataset: zara2               Batch:  2/18	Loss 147.3954 (147.3816)
2022-11-26 18:47:07,943:INFO: Dataset: zara2               Batch:  3/18	Loss 147.6548 (147.4678)
2022-11-26 18:47:08,435:INFO: Dataset: zara2               Batch:  4/18	Loss 147.8831 (147.5663)
2022-11-26 18:47:08,930:INFO: Dataset: zara2               Batch:  5/18	Loss 146.7711 (147.4120)
2022-11-26 18:47:09,428:INFO: Dataset: zara2               Batch:  6/18	Loss 147.3206 (147.3968)
2022-11-26 18:47:09,921:INFO: Dataset: zara2               Batch:  7/18	Loss 147.1448 (147.3619)
2022-11-26 18:47:10,413:INFO: Dataset: zara2               Batch:  8/18	Loss 146.8266 (147.2918)
2022-11-26 18:47:10,910:INFO: Dataset: zara2               Batch:  9/18	Loss 147.1759 (147.2787)
2022-11-26 18:47:11,409:INFO: Dataset: zara2               Batch: 10/18	Loss 146.5078 (147.2066)
2022-11-26 18:47:11,919:INFO: Dataset: zara2               Batch: 11/18	Loss 146.8761 (147.1778)
2022-11-26 18:47:12,428:INFO: Dataset: zara2               Batch: 12/18	Loss 147.2381 (147.1827)
2022-11-26 18:47:12,934:INFO: Dataset: zara2               Batch: 13/18	Loss 146.2237 (147.1026)
2022-11-26 18:47:13,446:INFO: Dataset: zara2               Batch: 14/18	Loss 146.7656 (147.0801)
2022-11-26 18:47:13,947:INFO: Dataset: zara2               Batch: 15/18	Loss 146.1093 (147.0083)
2022-11-26 18:47:14,445:INFO: Dataset: zara2               Batch: 16/18	Loss 148.2977 (147.0898)
2022-11-26 18:47:15,012:INFO: Dataset: zara2               Batch: 17/18	Loss 146.5199 (147.0561)
2022-11-26 18:47:15,588:INFO: Dataset: zara2               Batch: 18/18	Loss 126.2981 (146.0918)
2022-11-26 18:47:15,652:INFO: - Computing ADE (validation)
2022-11-26 18:47:16,025:INFO: 		 ADE on hotel                     dataset:	 2.7750728130340576
2022-11-26 18:47:16,478:INFO: 		 ADE on univ                      dataset:	 3.405564546585083
2022-11-26 18:47:16,832:INFO: 		 ADE on zara1                     dataset:	 2.8051159381866455
2022-11-26 18:47:17,377:INFO: 		 ADE on zara2                     dataset:	 2.984586238861084
2022-11-26 18:47:17,377:INFO: Average validation:	ADE  3.1817	FDE  4.3535
2022-11-26 18:47:17,378:INFO: - Computing ADE (validation o)
2022-11-26 18:47:17,681:INFO: 		 ADE on eth                       dataset:	 2.9145989418029785
2022-11-26 18:47:17,681:INFO: Average validation o:	ADE  2.9146	FDE  3.7770
2022-11-26 18:47:17,689:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_256.pth.tar
2022-11-26 18:47:17,689:INFO: 
===> EPOCH: 257 (P3)
2022-11-26 18:47:17,690:INFO: - Computing loss (training)
2022-11-26 18:47:18,415:INFO: Dataset: hotel               Batch: 1/4	Loss 154.3163 (154.3163)
2022-11-26 18:47:18,927:INFO: Dataset: hotel               Batch: 2/4	Loss 150.4787 (152.3651)
2022-11-26 18:47:19,419:INFO: Dataset: hotel               Batch: 3/4	Loss 148.5894 (151.0845)
2022-11-26 18:47:19,884:INFO: Dataset: hotel               Batch: 4/4	Loss 92.6913 (141.0699)
2022-11-26 18:47:20,899:INFO: Dataset: univ                Batch:  1/15	Loss 150.5765 (150.5765)
2022-11-26 18:47:21,554:INFO: Dataset: univ                Batch:  2/15	Loss 146.9822 (148.9129)
2022-11-26 18:47:22,090:INFO: Dataset: univ                Batch:  3/15	Loss 145.1831 (147.6753)
2022-11-26 18:47:22,617:INFO: Dataset: univ                Batch:  4/15	Loss 146.5565 (147.4165)
2022-11-26 18:47:23,149:INFO: Dataset: univ                Batch:  5/15	Loss 145.6167 (147.0684)
2022-11-26 18:47:23,675:INFO: Dataset: univ                Batch:  6/15	Loss 145.8274 (146.8811)
2022-11-26 18:47:24,210:INFO: Dataset: univ                Batch:  7/15	Loss 145.7689 (146.7103)
2022-11-26 18:47:24,736:INFO: Dataset: univ                Batch:  8/15	Loss 145.9963 (146.6169)
2022-11-26 18:47:25,251:INFO: Dataset: univ                Batch:  9/15	Loss 146.3624 (146.5903)
2022-11-26 18:47:25,772:INFO: Dataset: univ                Batch: 10/15	Loss 144.7941 (146.4110)
2022-11-26 18:47:26,295:INFO: Dataset: univ                Batch: 11/15	Loss 145.2743 (146.3024)
2022-11-26 18:47:26,817:INFO: Dataset: univ                Batch: 12/15	Loss 144.8627 (146.1779)
2022-11-26 18:47:27,334:INFO: Dataset: univ                Batch: 13/15	Loss 145.0380 (146.0920)
2022-11-26 18:47:27,865:INFO: Dataset: univ                Batch: 14/15	Loss 144.4714 (145.9648)
2022-11-26 18:47:28,283:INFO: Dataset: univ                Batch: 15/15	Loss 26.9507 (144.2615)
2022-11-26 18:47:29,055:INFO: Dataset: zara1               Batch: 1/8	Loss 147.2061 (147.2061)
2022-11-26 18:47:29,532:INFO: Dataset: zara1               Batch: 2/8	Loss 146.2822 (146.7469)
2022-11-26 18:47:30,013:INFO: Dataset: zara1               Batch: 3/8	Loss 145.3859 (146.3012)
2022-11-26 18:47:30,496:INFO: Dataset: zara1               Batch: 4/8	Loss 146.5210 (146.3556)
2022-11-26 18:47:30,974:INFO: Dataset: zara1               Batch: 5/8	Loss 146.4413 (146.3706)
2022-11-26 18:47:31,459:INFO: Dataset: zara1               Batch: 6/8	Loss 147.2497 (146.5256)
2022-11-26 18:47:31,937:INFO: Dataset: zara1               Batch: 7/8	Loss 145.8496 (146.4325)
2022-11-26 18:47:32,405:INFO: Dataset: zara1               Batch: 8/8	Loss 125.2095 (144.0198)
2022-11-26 18:47:33,180:INFO: Dataset: zara2               Batch:  1/18	Loss 145.5961 (145.5961)
2022-11-26 18:47:33,680:INFO: Dataset: zara2               Batch:  2/18	Loss 145.3550 (145.4798)
2022-11-26 18:47:34,171:INFO: Dataset: zara2               Batch:  3/18	Loss 145.2551 (145.4038)
2022-11-26 18:47:34,661:INFO: Dataset: zara2               Batch:  4/18	Loss 145.0479 (145.3124)
2022-11-26 18:47:35,156:INFO: Dataset: zara2               Batch:  5/18	Loss 144.3331 (145.1043)
2022-11-26 18:47:35,660:INFO: Dataset: zara2               Batch:  6/18	Loss 144.5972 (145.0224)
2022-11-26 18:47:36,152:INFO: Dataset: zara2               Batch:  7/18	Loss 145.9108 (145.1481)
2022-11-26 18:47:36,644:INFO: Dataset: zara2               Batch:  8/18	Loss 144.6700 (145.0894)
2022-11-26 18:47:37,134:INFO: Dataset: zara2               Batch:  9/18	Loss 145.9143 (145.1861)
2022-11-26 18:47:37,627:INFO: Dataset: zara2               Batch: 10/18	Loss 144.5985 (145.1337)
2022-11-26 18:47:38,119:INFO: Dataset: zara2               Batch: 11/18	Loss 143.8204 (145.0301)
2022-11-26 18:47:38,612:INFO: Dataset: zara2               Batch: 12/18	Loss 144.4268 (144.9789)
2022-11-26 18:47:39,104:INFO: Dataset: zara2               Batch: 13/18	Loss 144.0548 (144.9131)
2022-11-26 18:47:39,595:INFO: Dataset: zara2               Batch: 14/18	Loss 143.7870 (144.8326)
2022-11-26 18:47:40,087:INFO: Dataset: zara2               Batch: 15/18	Loss 144.4470 (144.8076)
2022-11-26 18:47:40,579:INFO: Dataset: zara2               Batch: 16/18	Loss 143.6309 (144.7312)
2022-11-26 18:47:41,071:INFO: Dataset: zara2               Batch: 17/18	Loss 144.7570 (144.7326)
2022-11-26 18:47:41,552:INFO: Dataset: zara2               Batch: 18/18	Loss 123.8131 (143.7608)
2022-11-26 18:47:41,613:INFO: - Computing ADE (validation)
2022-11-26 18:47:41,963:INFO: 		 ADE on hotel                     dataset:	 2.7141189575195312
2022-11-26 18:47:42,376:INFO: 		 ADE on univ                      dataset:	 3.3420660495758057
2022-11-26 18:47:42,710:INFO: 		 ADE on zara1                     dataset:	 2.8113646507263184
2022-11-26 18:47:43,246:INFO: 		 ADE on zara2                     dataset:	 2.966549873352051
2022-11-26 18:47:43,246:INFO: Average validation:	ADE  3.1391	FDE  4.3735
2022-11-26 18:47:43,247:INFO: - Computing ADE (validation o)
2022-11-26 18:47:43,535:INFO: 		 ADE on eth                       dataset:	 2.9196441173553467
2022-11-26 18:47:43,535:INFO: Average validation o:	ADE  2.9196	FDE  3.7217
2022-11-26 18:47:43,544:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_257.pth.tar
2022-11-26 18:47:43,544:INFO: 
===> EPOCH: 258 (P3)
2022-11-26 18:47:43,544:INFO: - Computing loss (training)
2022-11-26 18:47:44,235:INFO: Dataset: hotel               Batch: 1/4	Loss 147.7770 (147.7770)
2022-11-26 18:47:44,719:INFO: Dataset: hotel               Batch: 2/4	Loss 148.8807 (148.3195)
2022-11-26 18:47:45,202:INFO: Dataset: hotel               Batch: 3/4	Loss 147.3389 (147.9995)
2022-11-26 18:47:45,647:INFO: Dataset: hotel               Batch: 4/4	Loss 88.7239 (137.1297)
2022-11-26 18:47:46,476:INFO: Dataset: univ                Batch:  1/15	Loss 144.8670 (144.8670)
2022-11-26 18:47:47,009:INFO: Dataset: univ                Batch:  2/15	Loss 144.1056 (144.4743)
2022-11-26 18:47:47,540:INFO: Dataset: univ                Batch:  3/15	Loss 144.7891 (144.5780)
2022-11-26 18:47:48,068:INFO: Dataset: univ                Batch:  4/15	Loss 143.6369 (144.3387)
2022-11-26 18:47:48,587:INFO: Dataset: univ                Batch:  5/15	Loss 144.9163 (144.4432)
2022-11-26 18:47:49,108:INFO: Dataset: univ                Batch:  6/15	Loss 143.2426 (144.2647)
2022-11-26 18:47:49,633:INFO: Dataset: univ                Batch:  7/15	Loss 144.9054 (144.3553)
2022-11-26 18:47:50,145:INFO: Dataset: univ                Batch:  8/15	Loss 144.1031 (144.3282)
2022-11-26 18:47:50,668:INFO: Dataset: univ                Batch:  9/15	Loss 143.6833 (144.2571)
2022-11-26 18:47:51,191:INFO: Dataset: univ                Batch: 10/15	Loss 144.3747 (144.2689)
2022-11-26 18:47:51,707:INFO: Dataset: univ                Batch: 11/15	Loss 143.6878 (144.2203)
2022-11-26 18:47:52,306:INFO: Dataset: univ                Batch: 12/15	Loss 143.8233 (144.1895)
2022-11-26 18:47:52,823:INFO: Dataset: univ                Batch: 13/15	Loss 144.1545 (144.1870)
2022-11-26 18:47:53,338:INFO: Dataset: univ                Batch: 14/15	Loss 143.0756 (144.1155)
2022-11-26 18:47:53,759:INFO: Dataset: univ                Batch: 15/15	Loss 26.8260 (142.5036)
2022-11-26 18:47:54,516:INFO: Dataset: zara1               Batch: 1/8	Loss 144.8675 (144.8675)
2022-11-26 18:47:54,994:INFO: Dataset: zara1               Batch: 2/8	Loss 144.2995 (144.5759)
2022-11-26 18:47:55,469:INFO: Dataset: zara1               Batch: 3/8	Loss 143.4293 (144.2182)
2022-11-26 18:47:55,946:INFO: Dataset: zara1               Batch: 4/8	Loss 144.2897 (144.2365)
2022-11-26 18:47:56,422:INFO: Dataset: zara1               Batch: 5/8	Loss 143.0921 (144.0069)
2022-11-26 18:47:56,910:INFO: Dataset: zara1               Batch: 6/8	Loss 144.2193 (144.0425)
2022-11-26 18:47:57,385:INFO: Dataset: zara1               Batch: 7/8	Loss 143.5829 (143.9732)
2022-11-26 18:47:57,850:INFO: Dataset: zara1               Batch: 8/8	Loss 123.0894 (141.4561)
2022-11-26 18:47:58,617:INFO: Dataset: zara2               Batch:  1/18	Loss 143.0220 (143.0220)
2022-11-26 18:47:59,105:INFO: Dataset: zara2               Batch:  2/18	Loss 143.1833 (143.1010)
2022-11-26 18:47:59,592:INFO: Dataset: zara2               Batch:  3/18	Loss 143.7969 (143.3483)
2022-11-26 18:48:00,080:INFO: Dataset: zara2               Batch:  4/18	Loss 142.5469 (143.1604)
2022-11-26 18:48:00,569:INFO: Dataset: zara2               Batch:  5/18	Loss 142.4055 (143.0020)
2022-11-26 18:48:01,060:INFO: Dataset: zara2               Batch:  6/18	Loss 141.7242 (142.7940)
2022-11-26 18:48:01,546:INFO: Dataset: zara2               Batch:  7/18	Loss 141.2664 (142.5711)
2022-11-26 18:48:02,031:INFO: Dataset: zara2               Batch:  8/18	Loss 141.7451 (142.4739)
2022-11-26 18:48:02,516:INFO: Dataset: zara2               Batch:  9/18	Loss 141.9034 (142.4080)
2022-11-26 18:48:02,999:INFO: Dataset: zara2               Batch: 10/18	Loss 142.9126 (142.4609)
2022-11-26 18:48:03,484:INFO: Dataset: zara2               Batch: 11/18	Loss 142.3569 (142.4520)
2022-11-26 18:48:03,970:INFO: Dataset: zara2               Batch: 12/18	Loss 141.6126 (142.3878)
2022-11-26 18:48:04,455:INFO: Dataset: zara2               Batch: 13/18	Loss 141.8886 (142.3520)
2022-11-26 18:48:04,941:INFO: Dataset: zara2               Batch: 14/18	Loss 142.2617 (142.3467)
2022-11-26 18:48:05,425:INFO: Dataset: zara2               Batch: 15/18	Loss 141.2626 (142.2726)
2022-11-26 18:48:05,910:INFO: Dataset: zara2               Batch: 16/18	Loss 141.6728 (142.2361)
2022-11-26 18:48:06,396:INFO: Dataset: zara2               Batch: 17/18	Loss 141.5967 (142.2004)
2022-11-26 18:48:06,872:INFO: Dataset: zara2               Batch: 18/18	Loss 121.2587 (141.1479)
2022-11-26 18:48:06,932:INFO: - Computing ADE (validation)
2022-11-26 18:48:07,289:INFO: 		 ADE on hotel                     dataset:	 2.681699514389038
2022-11-26 18:48:07,717:INFO: 		 ADE on univ                      dataset:	 3.3255395889282227
2022-11-26 18:48:08,059:INFO: 		 ADE on zara1                     dataset:	 2.8190574645996094
2022-11-26 18:48:08,594:INFO: 		 ADE on zara2                     dataset:	 2.861564874649048
2022-11-26 18:48:08,594:INFO: Average validation:	ADE  3.0906	FDE  4.2520
2022-11-26 18:48:08,595:INFO: - Computing ADE (validation o)
2022-11-26 18:48:08,890:INFO: 		 ADE on eth                       dataset:	 2.8747012615203857
2022-11-26 18:48:08,890:INFO: Average validation o:	ADE  2.8747	FDE  3.6076
2022-11-26 18:48:08,899:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_258.pth.tar
2022-11-26 18:48:08,899:INFO: 
===> EPOCH: 259 (P3)
2022-11-26 18:48:08,899:INFO: - Computing loss (training)
2022-11-26 18:48:09,592:INFO: Dataset: hotel               Batch: 1/4	Loss 144.4432 (144.4432)
2022-11-26 18:48:10,074:INFO: Dataset: hotel               Batch: 2/4	Loss 144.5163 (144.4802)
2022-11-26 18:48:10,554:INFO: Dataset: hotel               Batch: 3/4	Loss 145.5347 (144.8189)
2022-11-26 18:48:10,982:INFO: Dataset: hotel               Batch: 4/4	Loss 88.1553 (135.6242)
2022-11-26 18:48:11,793:INFO: Dataset: univ                Batch:  1/15	Loss 142.2505 (142.2505)
2022-11-26 18:48:12,330:INFO: Dataset: univ                Batch:  2/15	Loss 141.0151 (141.6290)
2022-11-26 18:48:12,860:INFO: Dataset: univ                Batch:  3/15	Loss 141.1697 (141.4937)
2022-11-26 18:48:13,388:INFO: Dataset: univ                Batch:  4/15	Loss 140.2034 (141.1758)
2022-11-26 18:48:13,923:INFO: Dataset: univ                Batch:  5/15	Loss 140.9312 (141.1260)
2022-11-26 18:48:14,452:INFO: Dataset: univ                Batch:  6/15	Loss 139.9808 (140.9360)
2022-11-26 18:48:14,972:INFO: Dataset: univ                Batch:  7/15	Loss 140.3318 (140.8591)
2022-11-26 18:48:15,490:INFO: Dataset: univ                Batch:  8/15	Loss 140.3548 (140.8059)
2022-11-26 18:48:16,015:INFO: Dataset: univ                Batch:  9/15	Loss 140.4489 (140.7671)
2022-11-26 18:48:16,541:INFO: Dataset: univ                Batch: 10/15	Loss 140.3935 (140.7299)
2022-11-26 18:48:17,077:INFO: Dataset: univ                Batch: 11/15	Loss 140.4590 (140.7025)
2022-11-26 18:48:17,604:INFO: Dataset: univ                Batch: 12/15	Loss 140.2033 (140.6616)
2022-11-26 18:48:18,130:INFO: Dataset: univ                Batch: 13/15	Loss 141.0404 (140.6910)
2022-11-26 18:48:18,656:INFO: Dataset: univ                Batch: 14/15	Loss 139.8855 (140.6348)
2022-11-26 18:48:19,093:INFO: Dataset: univ                Batch: 15/15	Loss 26.3104 (138.9662)
2022-11-26 18:48:19,871:INFO: Dataset: zara1               Batch: 1/8	Loss 142.3514 (142.3514)
2022-11-26 18:48:20,357:INFO: Dataset: zara1               Batch: 2/8	Loss 142.0755 (142.2226)
2022-11-26 18:48:20,839:INFO: Dataset: zara1               Batch: 3/8	Loss 141.5446 (142.0010)
2022-11-26 18:48:21,322:INFO: Dataset: zara1               Batch: 4/8	Loss 140.6815 (141.6941)
2022-11-26 18:48:21,804:INFO: Dataset: zara1               Batch: 5/8	Loss 140.9201 (141.5337)
2022-11-26 18:48:22,288:INFO: Dataset: zara1               Batch: 6/8	Loss 140.7955 (141.4026)
2022-11-26 18:48:22,851:INFO: Dataset: zara1               Batch: 7/8	Loss 140.6452 (141.2946)
2022-11-26 18:48:23,328:INFO: Dataset: zara1               Batch: 8/8	Loss 121.1970 (138.8512)
2022-11-26 18:48:24,118:INFO: Dataset: zara2               Batch:  1/18	Loss 140.4084 (140.4084)
2022-11-26 18:48:24,625:INFO: Dataset: zara2               Batch:  2/18	Loss 139.3967 (139.8898)
2022-11-26 18:48:25,126:INFO: Dataset: zara2               Batch:  3/18	Loss 138.9714 (139.5791)
2022-11-26 18:48:25,644:INFO: Dataset: zara2               Batch:  4/18	Loss 138.9504 (139.4209)
2022-11-26 18:48:26,165:INFO: Dataset: zara2               Batch:  5/18	Loss 139.8735 (139.5074)
2022-11-26 18:48:26,698:INFO: Dataset: zara2               Batch:  6/18	Loss 139.4153 (139.4920)
2022-11-26 18:48:27,212:INFO: Dataset: zara2               Batch:  7/18	Loss 139.2639 (139.4590)
2022-11-26 18:48:27,831:INFO: Dataset: zara2               Batch:  8/18	Loss 142.7968 (139.9034)
2022-11-26 18:48:28,350:INFO: Dataset: zara2               Batch:  9/18	Loss 139.6568 (139.8772)
2022-11-26 18:48:28,890:INFO: Dataset: zara2               Batch: 10/18	Loss 140.2920 (139.9208)
2022-11-26 18:48:29,410:INFO: Dataset: zara2               Batch: 11/18	Loss 139.3265 (139.8697)
2022-11-26 18:48:29,913:INFO: Dataset: zara2               Batch: 12/18	Loss 138.6117 (139.7744)
2022-11-26 18:48:30,427:INFO: Dataset: zara2               Batch: 13/18	Loss 139.1360 (139.7220)
2022-11-26 18:48:30,942:INFO: Dataset: zara2               Batch: 14/18	Loss 139.5800 (139.7108)
2022-11-26 18:48:31,447:INFO: Dataset: zara2               Batch: 15/18	Loss 140.0561 (139.7331)
2022-11-26 18:48:31,984:INFO: Dataset: zara2               Batch: 16/18	Loss 139.1907 (139.6976)
2022-11-26 18:48:32,542:INFO: Dataset: zara2               Batch: 17/18	Loss 138.8526 (139.6503)
2022-11-26 18:48:33,157:INFO: Dataset: zara2               Batch: 18/18	Loss 120.5190 (138.7710)
2022-11-26 18:48:33,229:INFO: - Computing ADE (validation)
2022-11-26 18:48:33,574:INFO: 		 ADE on hotel                     dataset:	 2.5705349445343018
2022-11-26 18:48:34,004:INFO: 		 ADE on univ                      dataset:	 3.238359212875366
2022-11-26 18:48:34,342:INFO: 		 ADE on zara1                     dataset:	 2.746551036834717
2022-11-26 18:48:34,866:INFO: 		 ADE on zara2                     dataset:	 2.8569140434265137
2022-11-26 18:48:34,866:INFO: Average validation:	ADE  3.0333	FDE  4.1834
2022-11-26 18:48:34,867:INFO: - Computing ADE (validation o)
2022-11-26 18:48:35,168:INFO: 		 ADE on eth                       dataset:	 2.8284056186676025
2022-11-26 18:48:35,168:INFO: Average validation o:	ADE  2.8284	FDE  3.4638
2022-11-26 18:48:35,177:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_259.pth.tar
2022-11-26 18:48:35,177:INFO: 
===> EPOCH: 260 (P3)
2022-11-26 18:48:35,177:INFO: - Computing loss (training)
2022-11-26 18:48:35,894:INFO: Dataset: hotel               Batch: 1/4	Loss 143.3404 (143.3404)
2022-11-26 18:48:36,388:INFO: Dataset: hotel               Batch: 2/4	Loss 144.1341 (143.7391)
2022-11-26 18:48:36,880:INFO: Dataset: hotel               Batch: 3/4	Loss 140.7556 (142.7636)
2022-11-26 18:48:37,336:INFO: Dataset: hotel               Batch: 4/4	Loss 91.2919 (133.8681)
2022-11-26 18:48:38,164:INFO: Dataset: univ                Batch:  1/15	Loss 139.0438 (139.0438)
2022-11-26 18:48:38,703:INFO: Dataset: univ                Batch:  2/15	Loss 138.8204 (138.9313)
2022-11-26 18:48:39,256:INFO: Dataset: univ                Batch:  3/15	Loss 139.3371 (139.0712)
2022-11-26 18:48:39,800:INFO: Dataset: univ                Batch:  4/15	Loss 138.2578 (138.8903)
2022-11-26 18:48:40,349:INFO: Dataset: univ                Batch:  5/15	Loss 137.7368 (138.6487)
2022-11-26 18:48:40,939:INFO: Dataset: univ                Batch:  6/15	Loss 137.7497 (138.4845)
2022-11-26 18:48:41,564:INFO: Dataset: univ                Batch:  7/15	Loss 138.1121 (138.4326)
2022-11-26 18:48:42,105:INFO: Dataset: univ                Batch:  8/15	Loss 137.6864 (138.3385)
2022-11-26 18:48:42,668:INFO: Dataset: univ                Batch:  9/15	Loss 138.6210 (138.3701)
2022-11-26 18:48:43,210:INFO: Dataset: univ                Batch: 10/15	Loss 137.4033 (138.2706)
2022-11-26 18:48:43,741:INFO: Dataset: univ                Batch: 11/15	Loss 138.1068 (138.2566)
2022-11-26 18:48:44,276:INFO: Dataset: univ                Batch: 12/15	Loss 138.6611 (138.2898)
2022-11-26 18:48:44,818:INFO: Dataset: univ                Batch: 13/15	Loss 137.5602 (138.2308)
2022-11-26 18:48:45,384:INFO: Dataset: univ                Batch: 14/15	Loss 138.0798 (138.2212)
2022-11-26 18:48:45,826:INFO: Dataset: univ                Batch: 15/15	Loss 25.7134 (136.3764)
2022-11-26 18:48:46,622:INFO: Dataset: zara1               Batch: 1/8	Loss 138.5204 (138.5204)
2022-11-26 18:48:47,134:INFO: Dataset: zara1               Batch: 2/8	Loss 138.6066 (138.5687)
2022-11-26 18:48:47,658:INFO: Dataset: zara1               Batch: 3/8	Loss 138.3194 (138.4935)
2022-11-26 18:48:48,155:INFO: Dataset: zara1               Batch: 4/8	Loss 138.5345 (138.5033)
2022-11-26 18:48:48,682:INFO: Dataset: zara1               Batch: 5/8	Loss 139.0213 (138.6027)
2022-11-26 18:48:49,188:INFO: Dataset: zara1               Batch: 6/8	Loss 138.1545 (138.5339)
2022-11-26 18:48:49,679:INFO: Dataset: zara1               Batch: 7/8	Loss 138.4609 (138.5234)
2022-11-26 18:48:50,158:INFO: Dataset: zara1               Batch: 8/8	Loss 118.7688 (136.6104)
2022-11-26 18:48:50,970:INFO: Dataset: zara2               Batch:  1/18	Loss 138.0070 (138.0070)
2022-11-26 18:48:51,459:INFO: Dataset: zara2               Batch:  2/18	Loss 138.9720 (138.5061)
2022-11-26 18:48:51,949:INFO: Dataset: zara2               Batch:  3/18	Loss 136.9630 (137.9683)
2022-11-26 18:48:52,442:INFO: Dataset: zara2               Batch:  4/18	Loss 136.8638 (137.7021)
2022-11-26 18:48:52,929:INFO: Dataset: zara2               Batch:  5/18	Loss 136.9080 (137.5487)
2022-11-26 18:48:53,425:INFO: Dataset: zara2               Batch:  6/18	Loss 136.6607 (137.3872)
2022-11-26 18:48:53,995:INFO: Dataset: zara2               Batch:  7/18	Loss 137.2894 (137.3734)
2022-11-26 18:48:54,484:INFO: Dataset: zara2               Batch:  8/18	Loss 138.8274 (137.5529)
2022-11-26 18:48:54,971:INFO: Dataset: zara2               Batch:  9/18	Loss 136.9242 (137.4927)
2022-11-26 18:48:55,458:INFO: Dataset: zara2               Batch: 10/18	Loss 136.3749 (137.3757)
2022-11-26 18:48:55,947:INFO: Dataset: zara2               Batch: 11/18	Loss 136.9653 (137.3392)
2022-11-26 18:48:56,436:INFO: Dataset: zara2               Batch: 12/18	Loss 136.6991 (137.2864)
2022-11-26 18:48:56,923:INFO: Dataset: zara2               Batch: 13/18	Loss 136.3630 (137.2074)
2022-11-26 18:48:57,412:INFO: Dataset: zara2               Batch: 14/18	Loss 136.4779 (137.1558)
2022-11-26 18:48:57,901:INFO: Dataset: zara2               Batch: 15/18	Loss 136.2438 (137.0952)
2022-11-26 18:48:58,388:INFO: Dataset: zara2               Batch: 16/18	Loss 136.8209 (137.0786)
2022-11-26 18:48:58,876:INFO: Dataset: zara2               Batch: 17/18	Loss 136.4967 (137.0443)
2022-11-26 18:48:59,354:INFO: Dataset: zara2               Batch: 18/18	Loss 116.5287 (136.0370)
2022-11-26 18:48:59,412:INFO: - Computing ADE (validation)
2022-11-26 18:48:59,758:INFO: 		 ADE on hotel                     dataset:	 2.5881588459014893
2022-11-26 18:49:00,173:INFO: 		 ADE on univ                      dataset:	 3.2190051078796387
2022-11-26 18:49:00,511:INFO: 		 ADE on zara1                     dataset:	 2.656694173812866
2022-11-26 18:49:01,056:INFO: 		 ADE on zara2                     dataset:	 2.7903518676757812
2022-11-26 18:49:01,057:INFO: Average validation:	ADE  2.9945	FDE  4.1431
2022-11-26 18:49:01,057:INFO: - Computing ADE (validation o)
2022-11-26 18:49:01,358:INFO: 		 ADE on eth                       dataset:	 2.8180110454559326
2022-11-26 18:49:01,358:INFO: Average validation o:	ADE  2.8180	FDE  3.3127
2022-11-26 18:49:01,366:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_260.pth.tar
2022-11-26 18:49:01,367:INFO: 
===> EPOCH: 261 (P3)
2022-11-26 18:49:01,367:INFO: - Computing loss (training)
2022-11-26 18:49:02,064:INFO: Dataset: hotel               Batch: 1/4	Loss 138.1186 (138.1186)
2022-11-26 18:49:02,564:INFO: Dataset: hotel               Batch: 2/4	Loss 139.7997 (138.9412)
2022-11-26 18:49:03,049:INFO: Dataset: hotel               Batch: 3/4	Loss 138.0719 (138.6510)
2022-11-26 18:49:03,485:INFO: Dataset: hotel               Batch: 4/4	Loss 84.5824 (129.6633)
2022-11-26 18:49:04,288:INFO: Dataset: univ                Batch:  1/15	Loss 137.4019 (137.4019)
2022-11-26 18:49:04,812:INFO: Dataset: univ                Batch:  2/15	Loss 138.7142 (138.0639)
2022-11-26 18:49:05,352:INFO: Dataset: univ                Batch:  3/15	Loss 136.4689 (137.4480)
2022-11-26 18:49:05,880:INFO: Dataset: univ                Batch:  4/15	Loss 137.8709 (137.5522)
2022-11-26 18:49:06,397:INFO: Dataset: univ                Batch:  5/15	Loss 136.0622 (137.3018)
2022-11-26 18:49:06,943:INFO: Dataset: univ                Batch:  6/15	Loss 135.0664 (136.8846)
2022-11-26 18:49:07,470:INFO: Dataset: univ                Batch:  7/15	Loss 135.5143 (136.6781)
2022-11-26 18:49:07,997:INFO: Dataset: univ                Batch:  8/15	Loss 135.2629 (136.4937)
2022-11-26 18:49:08,522:INFO: Dataset: univ                Batch:  9/15	Loss 136.2526 (136.4672)
2022-11-26 18:49:09,051:INFO: Dataset: univ                Batch: 10/15	Loss 136.0775 (136.4270)
2022-11-26 18:49:09,586:INFO: Dataset: univ                Batch: 11/15	Loss 135.4267 (136.3291)
2022-11-26 18:49:10,115:INFO: Dataset: univ                Batch: 12/15	Loss 135.7733 (136.2822)
2022-11-26 18:49:10,651:INFO: Dataset: univ                Batch: 13/15	Loss 135.9700 (136.2556)
2022-11-26 18:49:11,185:INFO: Dataset: univ                Batch: 14/15	Loss 135.0347 (136.1645)
2022-11-26 18:49:11,612:INFO: Dataset: univ                Batch: 15/15	Loss 25.8458 (134.7948)
2022-11-26 18:49:12,377:INFO: Dataset: zara1               Batch: 1/8	Loss 137.0492 (137.0492)
2022-11-26 18:49:12,865:INFO: Dataset: zara1               Batch: 2/8	Loss 136.5182 (136.7938)
2022-11-26 18:49:13,359:INFO: Dataset: zara1               Batch: 3/8	Loss 136.2657 (136.6004)
2022-11-26 18:49:13,848:INFO: Dataset: zara1               Batch: 4/8	Loss 135.6832 (136.3761)
2022-11-26 18:49:14,335:INFO: Dataset: zara1               Batch: 5/8	Loss 135.6568 (136.2381)
2022-11-26 18:49:14,822:INFO: Dataset: zara1               Batch: 6/8	Loss 135.7494 (136.1643)
2022-11-26 18:49:15,308:INFO: Dataset: zara1               Batch: 7/8	Loss 135.7968 (136.1170)
2022-11-26 18:49:15,781:INFO: Dataset: zara1               Batch: 8/8	Loss 116.5029 (133.6704)
2022-11-26 18:49:16,573:INFO: Dataset: zara2               Batch:  1/18	Loss 135.4904 (135.4904)
2022-11-26 18:49:17,071:INFO: Dataset: zara2               Batch:  2/18	Loss 135.5129 (135.5018)
2022-11-26 18:49:17,583:INFO: Dataset: zara2               Batch:  3/18	Loss 135.0425 (135.3482)
2022-11-26 18:49:18,078:INFO: Dataset: zara2               Batch:  4/18	Loss 135.0576 (135.2698)
2022-11-26 18:49:18,574:INFO: Dataset: zara2               Batch:  5/18	Loss 134.2076 (135.0624)
2022-11-26 18:49:19,072:INFO: Dataset: zara2               Batch:  6/18	Loss 134.4373 (134.9633)
2022-11-26 18:49:19,568:INFO: Dataset: zara2               Batch:  7/18	Loss 134.7126 (134.9294)
2022-11-26 18:49:20,062:INFO: Dataset: zara2               Batch:  8/18	Loss 134.1030 (134.8263)
2022-11-26 18:49:20,558:INFO: Dataset: zara2               Batch:  9/18	Loss 134.1587 (134.7587)
2022-11-26 18:49:21,055:INFO: Dataset: zara2               Batch: 10/18	Loss 133.8029 (134.6711)
2022-11-26 18:49:21,554:INFO: Dataset: zara2               Batch: 11/18	Loss 134.3695 (134.6436)
2022-11-26 18:49:22,050:INFO: Dataset: zara2               Batch: 12/18	Loss 133.9005 (134.5803)
2022-11-26 18:49:22,546:INFO: Dataset: zara2               Batch: 13/18	Loss 134.0991 (134.5455)
2022-11-26 18:49:23,041:INFO: Dataset: zara2               Batch: 14/18	Loss 134.8230 (134.5662)
2022-11-26 18:49:23,609:INFO: Dataset: zara2               Batch: 15/18	Loss 134.5192 (134.5627)
2022-11-26 18:49:24,190:INFO: Dataset: zara2               Batch: 16/18	Loss 134.3832 (134.5522)
2022-11-26 18:49:24,687:INFO: Dataset: zara2               Batch: 17/18	Loss 134.0360 (134.5205)
2022-11-26 18:49:25,172:INFO: Dataset: zara2               Batch: 18/18	Loss 117.1483 (133.6187)
2022-11-26 18:49:25,229:INFO: - Computing ADE (validation)
2022-11-26 18:49:25,582:INFO: 		 ADE on hotel                     dataset:	 2.5393564701080322
2022-11-26 18:49:26,011:INFO: 		 ADE on univ                      dataset:	 3.1388378143310547
2022-11-26 18:49:26,353:INFO: 		 ADE on zara1                     dataset:	 2.68570613861084
2022-11-26 18:49:26,891:INFO: 		 ADE on zara2                     dataset:	 2.7707467079162598
2022-11-26 18:49:26,891:INFO: Average validation:	ADE  2.9446	FDE  4.0424
2022-11-26 18:49:26,892:INFO: - Computing ADE (validation o)
2022-11-26 18:49:27,187:INFO: 		 ADE on eth                       dataset:	 2.6286702156066895
2022-11-26 18:49:27,187:INFO: Average validation o:	ADE  2.6287	FDE  3.0661
2022-11-26 18:49:27,195:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_261.pth.tar
2022-11-26 18:49:27,195:INFO: 
===> EPOCH: 262 (P3)
2022-11-26 18:49:27,195:INFO: - Computing loss (training)
2022-11-26 18:49:27,902:INFO: Dataset: hotel               Batch: 1/4	Loss 137.1447 (137.1447)
2022-11-26 18:49:28,391:INFO: Dataset: hotel               Batch: 2/4	Loss 136.8000 (136.9727)
2022-11-26 18:49:28,875:INFO: Dataset: hotel               Batch: 3/4	Loss 136.5445 (136.8284)
2022-11-26 18:49:29,323:INFO: Dataset: hotel               Batch: 4/4	Loss 83.1811 (128.5478)
2022-11-26 18:49:30,148:INFO: Dataset: univ                Batch:  1/15	Loss 132.8986 (132.8986)
2022-11-26 18:49:30,696:INFO: Dataset: univ                Batch:  2/15	Loss 133.2678 (133.0837)
2022-11-26 18:49:31,273:INFO: Dataset: univ                Batch:  3/15	Loss 132.9696 (133.0445)
2022-11-26 18:49:31,815:INFO: Dataset: univ                Batch:  4/15	Loss 132.7068 (132.9597)
2022-11-26 18:49:32,364:INFO: Dataset: univ                Batch:  5/15	Loss 132.5866 (132.8803)
2022-11-26 18:49:32,898:INFO: Dataset: univ                Batch:  6/15	Loss 132.7945 (132.8668)
2022-11-26 18:49:33,467:INFO: Dataset: univ                Batch:  7/15	Loss 133.1412 (132.9038)
2022-11-26 18:49:34,081:INFO: Dataset: univ                Batch:  8/15	Loss 132.8038 (132.8913)
2022-11-26 18:49:34,637:INFO: Dataset: univ                Batch:  9/15	Loss 132.8217 (132.8830)
2022-11-26 18:49:35,214:INFO: Dataset: univ                Batch: 10/15	Loss 132.2999 (132.8200)
2022-11-26 18:49:35,745:INFO: Dataset: univ                Batch: 11/15	Loss 132.4623 (132.7900)
2022-11-26 18:49:36,290:INFO: Dataset: univ                Batch: 12/15	Loss 133.8024 (132.8766)
2022-11-26 18:49:36,836:INFO: Dataset: univ                Batch: 13/15	Loss 133.1715 (132.9005)
2022-11-26 18:49:37,377:INFO: Dataset: univ                Batch: 14/15	Loss 132.5980 (132.8782)
2022-11-26 18:49:37,823:INFO: Dataset: univ                Batch: 15/15	Loss 25.0201 (131.6464)
2022-11-26 18:49:38,733:INFO: Dataset: zara1               Batch: 1/8	Loss 133.4277 (133.4277)
2022-11-26 18:49:39,249:INFO: Dataset: zara1               Batch: 2/8	Loss 133.1520 (133.2806)
2022-11-26 18:49:39,796:INFO: Dataset: zara1               Batch: 3/8	Loss 133.6676 (133.4033)
2022-11-26 18:49:40,301:INFO: Dataset: zara1               Batch: 4/8	Loss 132.8296 (133.2584)
2022-11-26 18:49:40,814:INFO: Dataset: zara1               Batch: 5/8	Loss 133.5994 (133.3320)
2022-11-26 18:49:41,327:INFO: Dataset: zara1               Batch: 6/8	Loss 133.4880 (133.3560)
2022-11-26 18:49:41,843:INFO: Dataset: zara1               Batch: 7/8	Loss 132.9224 (133.2940)
2022-11-26 18:49:42,347:INFO: Dataset: zara1               Batch: 8/8	Loss 114.1214 (131.1951)
2022-11-26 18:49:43,144:INFO: Dataset: zara2               Batch:  1/18	Loss 132.7183 (132.7183)
2022-11-26 18:49:43,665:INFO: Dataset: zara2               Batch:  2/18	Loss 132.3453 (132.5370)
2022-11-26 18:49:44,163:INFO: Dataset: zara2               Batch:  3/18	Loss 131.8206 (132.2853)
2022-11-26 18:49:44,663:INFO: Dataset: zara2               Batch:  4/18	Loss 131.9533 (132.2066)
2022-11-26 18:49:45,161:INFO: Dataset: zara2               Batch:  5/18	Loss 132.1823 (132.2019)
2022-11-26 18:49:45,688:INFO: Dataset: zara2               Batch:  6/18	Loss 132.3165 (132.2199)
2022-11-26 18:49:46,189:INFO: Dataset: zara2               Batch:  7/18	Loss 131.6279 (132.1380)
2022-11-26 18:49:46,691:INFO: Dataset: zara2               Batch:  8/18	Loss 131.6128 (132.0672)
2022-11-26 18:49:47,190:INFO: Dataset: zara2               Batch:  9/18	Loss 132.0166 (132.0615)
2022-11-26 18:49:47,705:INFO: Dataset: zara2               Batch: 10/18	Loss 131.5666 (132.0115)
2022-11-26 18:49:48,233:INFO: Dataset: zara2               Batch: 11/18	Loss 130.7792 (131.8841)
2022-11-26 18:49:48,732:INFO: Dataset: zara2               Batch: 12/18	Loss 131.1805 (131.8202)
2022-11-26 18:49:49,235:INFO: Dataset: zara2               Batch: 13/18	Loss 131.4214 (131.7911)
2022-11-26 18:49:49,768:INFO: Dataset: zara2               Batch: 14/18	Loss 131.4847 (131.7713)
2022-11-26 18:49:50,272:INFO: Dataset: zara2               Batch: 15/18	Loss 131.5036 (131.7547)
2022-11-26 18:49:50,771:INFO: Dataset: zara2               Batch: 16/18	Loss 131.7945 (131.7570)
2022-11-26 18:49:51,267:INFO: Dataset: zara2               Batch: 17/18	Loss 131.7642 (131.7574)
2022-11-26 18:49:51,755:INFO: Dataset: zara2               Batch: 18/18	Loss 113.3244 (130.9407)
2022-11-26 18:49:51,814:INFO: - Computing ADE (validation)
2022-11-26 18:49:52,179:INFO: 		 ADE on hotel                     dataset:	 2.482084274291992
2022-11-26 18:49:52,617:INFO: 		 ADE on univ                      dataset:	 3.106064796447754
2022-11-26 18:49:52,957:INFO: 		 ADE on zara1                     dataset:	 2.601613759994507
2022-11-26 18:49:53,493:INFO: 		 ADE on zara2                     dataset:	 2.7448270320892334
2022-11-26 18:49:53,493:INFO: Average validation:	ADE  2.9101	FDE  4.0143
2022-11-26 18:49:53,494:INFO: - Computing ADE (validation o)
2022-11-26 18:49:53,786:INFO: 		 ADE on eth                       dataset:	 2.7508656978607178
2022-11-26 18:49:53,786:INFO: Average validation o:	ADE  2.7509	FDE  3.1968
2022-11-26 18:49:53,794:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_262.pth.tar
2022-11-26 18:49:53,794:INFO: 
===> EPOCH: 263 (P3)
2022-11-26 18:49:53,795:INFO: - Computing loss (training)
2022-11-26 18:49:54,529:INFO: Dataset: hotel               Batch: 1/4	Loss 132.6927 (132.6927)
2022-11-26 18:49:55,031:INFO: Dataset: hotel               Batch: 2/4	Loss 133.3585 (133.0319)
2022-11-26 18:49:55,527:INFO: Dataset: hotel               Batch: 3/4	Loss 131.2906 (132.4551)
2022-11-26 18:49:56,010:INFO: Dataset: hotel               Batch: 4/4	Loss 81.1720 (124.2687)
2022-11-26 18:49:56,925:INFO: Dataset: univ                Batch:  1/15	Loss 130.9716 (130.9716)
2022-11-26 18:49:57,473:INFO: Dataset: univ                Batch:  2/15	Loss 131.6897 (131.3481)
2022-11-26 18:49:58,020:INFO: Dataset: univ                Batch:  3/15	Loss 132.8653 (131.8507)
2022-11-26 18:49:58,646:INFO: Dataset: univ                Batch:  4/15	Loss 130.8639 (131.6139)
2022-11-26 18:49:59,195:INFO: Dataset: univ                Batch:  5/15	Loss 130.8651 (131.4700)
2022-11-26 18:49:59,743:INFO: Dataset: univ                Batch:  6/15	Loss 130.4950 (131.3078)
2022-11-26 18:50:00,352:INFO: Dataset: univ                Batch:  7/15	Loss 130.1339 (131.1422)
2022-11-26 18:50:00,957:INFO: Dataset: univ                Batch:  8/15	Loss 130.3862 (131.0535)
2022-11-26 18:50:01,496:INFO: Dataset: univ                Batch:  9/15	Loss 130.5829 (131.0061)
2022-11-26 18:50:02,065:INFO: Dataset: univ                Batch: 10/15	Loss 130.2937 (130.9267)
2022-11-26 18:50:02,614:INFO: Dataset: univ                Batch: 11/15	Loss 129.9142 (130.8311)
2022-11-26 18:50:03,155:INFO: Dataset: univ                Batch: 12/15	Loss 129.6717 (130.7369)
2022-11-26 18:50:03,692:INFO: Dataset: univ                Batch: 13/15	Loss 130.6678 (130.7319)
2022-11-26 18:50:04,226:INFO: Dataset: univ                Batch: 14/15	Loss 130.0627 (130.6857)
2022-11-26 18:50:04,650:INFO: Dataset: univ                Batch: 15/15	Loss 24.4174 (129.4167)
2022-11-26 18:50:05,449:INFO: Dataset: zara1               Batch: 1/8	Loss 131.4102 (131.4102)
2022-11-26 18:50:05,946:INFO: Dataset: zara1               Batch: 2/8	Loss 130.5504 (130.9948)
2022-11-26 18:50:06,450:INFO: Dataset: zara1               Batch: 3/8	Loss 130.8760 (130.9548)
2022-11-26 18:50:06,968:INFO: Dataset: zara1               Batch: 4/8	Loss 130.7649 (130.9122)
2022-11-26 18:50:07,476:INFO: Dataset: zara1               Batch: 5/8	Loss 130.8895 (130.9078)
2022-11-26 18:50:07,975:INFO: Dataset: zara1               Batch: 6/8	Loss 130.1868 (130.7907)
2022-11-26 18:50:08,475:INFO: Dataset: zara1               Batch: 7/8	Loss 129.9978 (130.6811)
2022-11-26 18:50:08,957:INFO: Dataset: zara1               Batch: 8/8	Loss 111.9000 (128.5658)
2022-11-26 18:50:09,790:INFO: Dataset: zara2               Batch:  1/18	Loss 129.5919 (129.5919)
2022-11-26 18:50:10,304:INFO: Dataset: zara2               Batch:  2/18	Loss 129.2607 (129.4269)
2022-11-26 18:50:10,828:INFO: Dataset: zara2               Batch:  3/18	Loss 129.7047 (129.5247)
2022-11-26 18:50:11,360:INFO: Dataset: zara2               Batch:  4/18	Loss 129.8202 (129.6020)
2022-11-26 18:50:11,887:INFO: Dataset: zara2               Batch:  5/18	Loss 128.8559 (129.4516)
2022-11-26 18:50:12,392:INFO: Dataset: zara2               Batch:  6/18	Loss 128.4158 (129.2864)
2022-11-26 18:50:12,905:INFO: Dataset: zara2               Batch:  7/18	Loss 129.2755 (129.2848)
2022-11-26 18:50:13,427:INFO: Dataset: zara2               Batch:  8/18	Loss 129.3815 (129.2977)
2022-11-26 18:50:13,934:INFO: Dataset: zara2               Batch:  9/18	Loss 130.0039 (129.3803)
2022-11-26 18:50:14,441:INFO: Dataset: zara2               Batch: 10/18	Loss 129.0836 (129.3489)
2022-11-26 18:50:14,999:INFO: Dataset: zara2               Batch: 11/18	Loss 128.7391 (129.2920)
2022-11-26 18:50:15,513:INFO: Dataset: zara2               Batch: 12/18	Loss 128.7317 (129.2450)
2022-11-26 18:50:16,011:INFO: Dataset: zara2               Batch: 13/18	Loss 129.4584 (129.2591)
2022-11-26 18:50:16,510:INFO: Dataset: zara2               Batch: 14/18	Loss 128.6277 (129.2104)
2022-11-26 18:50:17,014:INFO: Dataset: zara2               Batch: 15/18	Loss 130.0104 (129.2586)
2022-11-26 18:50:17,516:INFO: Dataset: zara2               Batch: 16/18	Loss 128.9213 (129.2367)
2022-11-26 18:50:18,022:INFO: Dataset: zara2               Batch: 17/18	Loss 128.4643 (129.1937)
2022-11-26 18:50:18,515:INFO: Dataset: zara2               Batch: 18/18	Loss 110.3101 (128.2509)
2022-11-26 18:50:18,573:INFO: - Computing ADE (validation)
2022-11-26 18:50:18,944:INFO: 		 ADE on hotel                     dataset:	 2.4930145740509033
2022-11-26 18:50:19,379:INFO: 		 ADE on univ                      dataset:	 3.039815664291382
2022-11-26 18:50:19,737:INFO: 		 ADE on zara1                     dataset:	 2.610673189163208
2022-11-26 18:50:20,298:INFO: 		 ADE on zara2                     dataset:	 2.7028911113739014
2022-11-26 18:50:20,298:INFO: Average validation:	ADE  2.8613	FDE  3.9733
2022-11-26 18:50:20,299:INFO: - Computing ADE (validation o)
2022-11-26 18:50:20,629:INFO: 		 ADE on eth                       dataset:	 2.6855125427246094
2022-11-26 18:50:20,629:INFO: Average validation o:	ADE  2.6855	FDE  3.3473
2022-11-26 18:50:20,646:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_263.pth.tar
2022-11-26 18:50:20,646:INFO: 
===> EPOCH: 264 (P3)
2022-11-26 18:50:20,647:INFO: - Computing loss (training)
2022-11-26 18:50:21,436:INFO: Dataset: hotel               Batch: 1/4	Loss 130.2103 (130.2103)
2022-11-26 18:50:21,942:INFO: Dataset: hotel               Batch: 2/4	Loss 129.4928 (129.8473)
2022-11-26 18:50:22,435:INFO: Dataset: hotel               Batch: 3/4	Loss 130.1318 (129.9414)
2022-11-26 18:50:22,877:INFO: Dataset: hotel               Batch: 4/4	Loss 78.6763 (121.8256)
2022-11-26 18:50:23,703:INFO: Dataset: univ                Batch:  1/15	Loss 128.6873 (128.6873)
2022-11-26 18:50:24,252:INFO: Dataset: univ                Batch:  2/15	Loss 127.7826 (128.2206)
2022-11-26 18:50:24,791:INFO: Dataset: univ                Batch:  3/15	Loss 128.1842 (128.2090)
2022-11-26 18:50:25,335:INFO: Dataset: univ                Batch:  4/15	Loss 127.9102 (128.1324)
2022-11-26 18:50:25,865:INFO: Dataset: univ                Batch:  5/15	Loss 130.4088 (128.5532)
2022-11-26 18:50:26,406:INFO: Dataset: univ                Batch:  6/15	Loss 127.5160 (128.3748)
2022-11-26 18:50:26,948:INFO: Dataset: univ                Batch:  7/15	Loss 127.9941 (128.3164)
2022-11-26 18:50:27,488:INFO: Dataset: univ                Batch:  8/15	Loss 127.6955 (128.2376)
2022-11-26 18:50:28,118:INFO: Dataset: univ                Batch:  9/15	Loss 127.7338 (128.1822)
2022-11-26 18:50:28,658:INFO: Dataset: univ                Batch: 10/15	Loss 131.6602 (128.4994)
2022-11-26 18:50:29,192:INFO: Dataset: univ                Batch: 11/15	Loss 127.6920 (128.4346)
2022-11-26 18:50:29,733:INFO: Dataset: univ                Batch: 12/15	Loss 128.2375 (128.4191)
2022-11-26 18:50:30,260:INFO: Dataset: univ                Batch: 13/15	Loss 128.1882 (128.4023)
2022-11-26 18:50:30,790:INFO: Dataset: univ                Batch: 14/15	Loss 127.7899 (128.3601)
2022-11-26 18:50:31,220:INFO: Dataset: univ                Batch: 15/15	Loss 24.0222 (126.8224)
2022-11-26 18:50:32,034:INFO: Dataset: zara1               Batch: 1/8	Loss 127.9174 (127.9174)
2022-11-26 18:50:32,522:INFO: Dataset: zara1               Batch: 2/8	Loss 129.1621 (128.5012)
2022-11-26 18:50:33,045:INFO: Dataset: zara1               Batch: 3/8	Loss 128.2985 (128.4336)
2022-11-26 18:50:33,633:INFO: Dataset: zara1               Batch: 4/8	Loss 128.4550 (128.4393)
2022-11-26 18:50:34,149:INFO: Dataset: zara1               Batch: 5/8	Loss 128.3493 (128.4225)
2022-11-26 18:50:34,661:INFO: Dataset: zara1               Batch: 6/8	Loss 127.7684 (128.3059)
2022-11-26 18:50:35,154:INFO: Dataset: zara1               Batch: 7/8	Loss 128.3965 (128.3180)
2022-11-26 18:50:35,653:INFO: Dataset: zara1               Batch: 8/8	Loss 110.2173 (126.4412)
2022-11-26 18:50:36,538:INFO: Dataset: zara2               Batch:  1/18	Loss 127.6613 (127.6613)
2022-11-26 18:50:37,057:INFO: Dataset: zara2               Batch:  2/18	Loss 127.0607 (127.3624)
2022-11-26 18:50:37,574:INFO: Dataset: zara2               Batch:  3/18	Loss 127.1921 (127.3050)
2022-11-26 18:50:38,089:INFO: Dataset: zara2               Batch:  4/18	Loss 126.6937 (127.1554)
2022-11-26 18:50:38,619:INFO: Dataset: zara2               Batch:  5/18	Loss 126.7109 (127.0729)
2022-11-26 18:50:39,141:INFO: Dataset: zara2               Batch:  6/18	Loss 126.7369 (127.0081)
2022-11-26 18:50:39,648:INFO: Dataset: zara2               Batch:  7/18	Loss 126.5805 (126.9516)
2022-11-26 18:50:40,156:INFO: Dataset: zara2               Batch:  8/18	Loss 126.6812 (126.9224)
2022-11-26 18:50:40,668:INFO: Dataset: zara2               Batch:  9/18	Loss 127.1869 (126.9532)
2022-11-26 18:50:41,194:INFO: Dataset: zara2               Batch: 10/18	Loss 126.8139 (126.9365)
2022-11-26 18:50:41,724:INFO: Dataset: zara2               Batch: 11/18	Loss 126.7839 (126.9221)
2022-11-26 18:50:42,325:INFO: Dataset: zara2               Batch: 12/18	Loss 126.0720 (126.8450)
2022-11-26 18:50:42,927:INFO: Dataset: zara2               Batch: 13/18	Loss 125.9881 (126.7748)
2022-11-26 18:50:43,438:INFO: Dataset: zara2               Batch: 14/18	Loss 126.2579 (126.7394)
2022-11-26 18:50:43,952:INFO: Dataset: zara2               Batch: 15/18	Loss 126.1271 (126.6963)
2022-11-26 18:50:44,464:INFO: Dataset: zara2               Batch: 16/18	Loss 126.5251 (126.6840)
2022-11-26 18:50:44,981:INFO: Dataset: zara2               Batch: 17/18	Loss 126.3386 (126.6641)
2022-11-26 18:50:45,470:INFO: Dataset: zara2               Batch: 18/18	Loss 108.2444 (125.8693)
2022-11-26 18:50:45,530:INFO: - Computing ADE (validation)
2022-11-26 18:50:45,895:INFO: 		 ADE on hotel                     dataset:	 2.3883237838745117
2022-11-26 18:50:46,337:INFO: 		 ADE on univ                      dataset:	 2.960578680038452
2022-11-26 18:50:46,695:INFO: 		 ADE on zara1                     dataset:	 2.4726109504699707
2022-11-26 18:50:47,248:INFO: 		 ADE on zara2                     dataset:	 2.6231136322021484
2022-11-26 18:50:47,249:INFO: Average validation:	ADE  2.7771	FDE  3.7956
2022-11-26 18:50:47,249:INFO: - Computing ADE (validation o)
2022-11-26 18:50:47,553:INFO: 		 ADE on eth                       dataset:	 2.5098042488098145
2022-11-26 18:50:47,553:INFO: Average validation o:	ADE  2.5098	FDE  3.1705
2022-11-26 18:50:47,561:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_264.pth.tar
2022-11-26 18:50:47,561:INFO: 
===> EPOCH: 265 (P3)
2022-11-26 18:50:47,562:INFO: - Computing loss (training)
2022-11-26 18:50:48,268:INFO: Dataset: hotel               Batch: 1/4	Loss 131.3863 (131.3863)
2022-11-26 18:50:48,764:INFO: Dataset: hotel               Batch: 2/4	Loss 127.6444 (129.4658)
2022-11-26 18:50:49,266:INFO: Dataset: hotel               Batch: 3/4	Loss 127.3589 (128.7490)
2022-11-26 18:50:49,728:INFO: Dataset: hotel               Batch: 4/4	Loss 77.1442 (119.9666)
2022-11-26 18:50:50,615:INFO: Dataset: univ                Batch:  1/15	Loss 126.1636 (126.1636)
2022-11-26 18:50:51,262:INFO: Dataset: univ                Batch:  2/15	Loss 125.5506 (125.8649)
2022-11-26 18:50:51,871:INFO: Dataset: univ                Batch:  3/15	Loss 125.2935 (125.6724)
2022-11-26 18:50:52,418:INFO: Dataset: univ                Batch:  4/15	Loss 125.9282 (125.7329)
2022-11-26 18:50:52,990:INFO: Dataset: univ                Batch:  5/15	Loss 125.2374 (125.6291)
2022-11-26 18:50:53,529:INFO: Dataset: univ                Batch:  6/15	Loss 125.4535 (125.6006)
2022-11-26 18:50:54,066:INFO: Dataset: univ                Batch:  7/15	Loss 126.3268 (125.6995)
2022-11-26 18:50:54,601:INFO: Dataset: univ                Batch:  8/15	Loss 125.8148 (125.7126)
2022-11-26 18:50:55,157:INFO: Dataset: univ                Batch:  9/15	Loss 124.9648 (125.6249)
2022-11-26 18:50:55,741:INFO: Dataset: univ                Batch: 10/15	Loss 125.4460 (125.6057)
2022-11-26 18:50:56,470:INFO: Dataset: univ                Batch: 11/15	Loss 125.1597 (125.5662)
2022-11-26 18:50:57,031:INFO: Dataset: univ                Batch: 12/15	Loss 124.7719 (125.4953)
2022-11-26 18:50:57,584:INFO: Dataset: univ                Batch: 13/15	Loss 125.3346 (125.4832)
2022-11-26 18:50:58,151:INFO: Dataset: univ                Batch: 14/15	Loss 124.6338 (125.4194)
2022-11-26 18:50:58,603:INFO: Dataset: univ                Batch: 15/15	Loss 23.4304 (124.0806)
2022-11-26 18:50:59,410:INFO: Dataset: zara1               Batch: 1/8	Loss 125.9339 (125.9339)
2022-11-26 18:50:59,914:INFO: Dataset: zara1               Batch: 2/8	Loss 125.3947 (125.6319)
2022-11-26 18:51:00,405:INFO: Dataset: zara1               Batch: 3/8	Loss 125.8141 (125.6917)
2022-11-26 18:51:00,897:INFO: Dataset: zara1               Batch: 4/8	Loss 126.1008 (125.7935)
2022-11-26 18:51:01,474:INFO: Dataset: zara1               Batch: 5/8	Loss 125.4834 (125.7357)
2022-11-26 18:51:01,966:INFO: Dataset: zara1               Batch: 6/8	Loss 125.6092 (125.7150)
2022-11-26 18:51:02,456:INFO: Dataset: zara1               Batch: 7/8	Loss 124.9413 (125.6069)
2022-11-26 18:51:02,942:INFO: Dataset: zara1               Batch: 8/8	Loss 107.8421 (123.8958)
2022-11-26 18:51:03,750:INFO: Dataset: zara2               Batch:  1/18	Loss 124.1721 (124.1721)
2022-11-26 18:51:04,255:INFO: Dataset: zara2               Batch:  2/18	Loss 124.3529 (124.2680)
2022-11-26 18:51:04,757:INFO: Dataset: zara2               Batch:  3/18	Loss 124.4006 (124.3122)
2022-11-26 18:51:05,257:INFO: Dataset: zara2               Batch:  4/18	Loss 124.5650 (124.3733)
2022-11-26 18:51:05,761:INFO: Dataset: zara2               Batch:  5/18	Loss 124.7483 (124.4533)
2022-11-26 18:51:06,267:INFO: Dataset: zara2               Batch:  6/18	Loss 124.0192 (124.3797)
2022-11-26 18:51:06,775:INFO: Dataset: zara2               Batch:  7/18	Loss 124.1086 (124.3432)
2022-11-26 18:51:07,277:INFO: Dataset: zara2               Batch:  8/18	Loss 124.9407 (124.4093)
2022-11-26 18:51:07,778:INFO: Dataset: zara2               Batch:  9/18	Loss 123.9258 (124.3521)
2022-11-26 18:51:08,278:INFO: Dataset: zara2               Batch: 10/18	Loss 124.0447 (124.3196)
2022-11-26 18:51:08,782:INFO: Dataset: zara2               Batch: 11/18	Loss 123.8147 (124.2773)
2022-11-26 18:51:09,285:INFO: Dataset: zara2               Batch: 12/18	Loss 123.5424 (124.2170)
2022-11-26 18:51:09,786:INFO: Dataset: zara2               Batch: 13/18	Loss 124.6722 (124.2508)
2022-11-26 18:51:10,287:INFO: Dataset: zara2               Batch: 14/18	Loss 124.1220 (124.2422)
2022-11-26 18:51:10,788:INFO: Dataset: zara2               Batch: 15/18	Loss 123.9578 (124.2222)
2022-11-26 18:51:11,291:INFO: Dataset: zara2               Batch: 16/18	Loss 123.8514 (124.1994)
2022-11-26 18:51:11,791:INFO: Dataset: zara2               Batch: 17/18	Loss 123.4938 (124.1538)
2022-11-26 18:51:12,279:INFO: Dataset: zara2               Batch: 18/18	Loss 105.6035 (123.2522)
2022-11-26 18:51:12,337:INFO: - Computing ADE (validation)
2022-11-26 18:51:12,701:INFO: 		 ADE on hotel                     dataset:	 2.459645986557007
2022-11-26 18:51:13,135:INFO: 		 ADE on univ                      dataset:	 2.9611918926239014
2022-11-26 18:51:13,486:INFO: 		 ADE on zara1                     dataset:	 2.5231871604919434
2022-11-26 18:51:14,029:INFO: 		 ADE on zara2                     dataset:	 2.5888869762420654
2022-11-26 18:51:14,029:INFO: Average validation:	ADE  2.7717	FDE  3.7984
2022-11-26 18:51:14,030:INFO: - Computing ADE (validation o)
2022-11-26 18:51:14,325:INFO: 		 ADE on eth                       dataset:	 2.4699912071228027
2022-11-26 18:51:14,325:INFO: Average validation o:	ADE  2.4700	FDE  3.0772
2022-11-26 18:51:14,333:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_265.pth.tar
2022-11-26 18:51:14,334:INFO: 
===> EPOCH: 266 (P3)
2022-11-26 18:51:14,334:INFO: - Computing loss (training)
2022-11-26 18:51:15,052:INFO: Dataset: hotel               Batch: 1/4	Loss 124.7640 (124.7640)
2022-11-26 18:51:15,553:INFO: Dataset: hotel               Batch: 2/4	Loss 124.9440 (124.8600)
2022-11-26 18:51:16,046:INFO: Dataset: hotel               Batch: 3/4	Loss 124.7498 (124.8233)
2022-11-26 18:51:16,501:INFO: Dataset: hotel               Batch: 4/4	Loss 75.5238 (116.4983)
2022-11-26 18:51:17,324:INFO: Dataset: univ                Batch:  1/15	Loss 128.8134 (128.8134)
2022-11-26 18:51:17,875:INFO: Dataset: univ                Batch:  2/15	Loss 123.5287 (126.0241)
2022-11-26 18:51:18,414:INFO: Dataset: univ                Batch:  3/15	Loss 123.1824 (125.1387)
2022-11-26 18:51:18,948:INFO: Dataset: univ                Batch:  4/15	Loss 123.1165 (124.6611)
2022-11-26 18:51:19,483:INFO: Dataset: univ                Batch:  5/15	Loss 123.6942 (124.4704)
2022-11-26 18:51:20,024:INFO: Dataset: univ                Batch:  6/15	Loss 122.7656 (124.1802)
2022-11-26 18:51:20,556:INFO: Dataset: univ                Batch:  7/15	Loss 122.8497 (123.9957)
2022-11-26 18:51:21,085:INFO: Dataset: univ                Batch:  8/15	Loss 123.0204 (123.8822)
2022-11-26 18:51:21,625:INFO: Dataset: univ                Batch:  9/15	Loss 123.4174 (123.8309)
2022-11-26 18:51:22,159:INFO: Dataset: univ                Batch: 10/15	Loss 122.9730 (123.7431)
2022-11-26 18:51:22,698:INFO: Dataset: univ                Batch: 11/15	Loss 123.4234 (123.7135)
2022-11-26 18:51:23,236:INFO: Dataset: univ                Batch: 12/15	Loss 122.3952 (123.5983)
2022-11-26 18:51:23,771:INFO: Dataset: univ                Batch: 13/15	Loss 122.6397 (123.5262)
2022-11-26 18:51:24,310:INFO: Dataset: univ                Batch: 14/15	Loss 122.7195 (123.4699)
2022-11-26 18:51:24,734:INFO: Dataset: univ                Batch: 15/15	Loss 23.0393 (122.3372)
2022-11-26 18:51:25,528:INFO: Dataset: zara1               Batch: 1/8	Loss 123.5406 (123.5406)
2022-11-26 18:51:26,017:INFO: Dataset: zara1               Batch: 2/8	Loss 122.9720 (123.2831)
2022-11-26 18:51:26,510:INFO: Dataset: zara1               Batch: 3/8	Loss 123.4263 (123.3281)
2022-11-26 18:51:27,013:INFO: Dataset: zara1               Batch: 4/8	Loss 123.2567 (123.3095)
2022-11-26 18:51:27,516:INFO: Dataset: zara1               Batch: 5/8	Loss 123.2957 (123.3066)
2022-11-26 18:51:28,008:INFO: Dataset: zara1               Batch: 6/8	Loss 122.9923 (123.2571)
2022-11-26 18:51:28,498:INFO: Dataset: zara1               Batch: 7/8	Loss 123.3243 (123.2660)
2022-11-26 18:51:28,977:INFO: Dataset: zara1               Batch: 8/8	Loss 105.8504 (121.4786)
2022-11-26 18:51:29,763:INFO: Dataset: zara2               Batch:  1/18	Loss 121.7483 (121.7483)
2022-11-26 18:51:30,258:INFO: Dataset: zara2               Batch:  2/18	Loss 121.9833 (121.8608)
2022-11-26 18:51:30,755:INFO: Dataset: zara2               Batch:  3/18	Loss 121.7257 (121.8172)
2022-11-26 18:51:31,256:INFO: Dataset: zara2               Batch:  4/18	Loss 121.5799 (121.7591)
2022-11-26 18:51:31,767:INFO: Dataset: zara2               Batch:  5/18	Loss 121.8957 (121.7870)
2022-11-26 18:51:32,278:INFO: Dataset: zara2               Batch:  6/18	Loss 121.7567 (121.7820)
2022-11-26 18:51:32,779:INFO: Dataset: zara2               Batch:  7/18	Loss 121.3077 (121.7112)
2022-11-26 18:51:33,284:INFO: Dataset: zara2               Batch:  8/18	Loss 121.5126 (121.6860)
2022-11-26 18:51:33,792:INFO: Dataset: zara2               Batch:  9/18	Loss 121.3071 (121.6449)
2022-11-26 18:51:34,381:INFO: Dataset: zara2               Batch: 10/18	Loss 121.1735 (121.5945)
2022-11-26 18:51:34,882:INFO: Dataset: zara2               Batch: 11/18	Loss 121.4117 (121.5768)
2022-11-26 18:51:35,389:INFO: Dataset: zara2               Batch: 12/18	Loss 121.6719 (121.5849)
2022-11-26 18:51:35,894:INFO: Dataset: zara2               Batch: 13/18	Loss 121.3135 (121.5631)
2022-11-26 18:51:36,399:INFO: Dataset: zara2               Batch: 14/18	Loss 121.4901 (121.5577)
2022-11-26 18:51:36,901:INFO: Dataset: zara2               Batch: 15/18	Loss 121.0450 (121.5182)
2022-11-26 18:51:37,405:INFO: Dataset: zara2               Batch: 16/18	Loss 121.1212 (121.4931)
2022-11-26 18:51:37,908:INFO: Dataset: zara2               Batch: 17/18	Loss 121.0095 (121.4643)
2022-11-26 18:51:38,405:INFO: Dataset: zara2               Batch: 18/18	Loss 104.2588 (120.5769)
2022-11-26 18:51:38,466:INFO: - Computing ADE (validation)
2022-11-26 18:51:38,821:INFO: 		 ADE on hotel                     dataset:	 2.314145565032959
2022-11-26 18:51:39,258:INFO: 		 ADE on univ                      dataset:	 2.899704933166504
2022-11-26 18:51:39,601:INFO: 		 ADE on zara1                     dataset:	 2.3824613094329834
2022-11-26 18:51:40,155:INFO: 		 ADE on zara2                     dataset:	 2.5184919834136963
2022-11-26 18:51:40,155:INFO: Average validation:	ADE  2.6977	FDE  3.6675
2022-11-26 18:51:40,156:INFO: - Computing ADE (validation o)
2022-11-26 18:51:40,463:INFO: 		 ADE on eth                       dataset:	 2.45670223236084
2022-11-26 18:51:40,463:INFO: Average validation o:	ADE  2.4567	FDE  2.9942
2022-11-26 18:51:40,472:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_266.pth.tar
2022-11-26 18:51:40,472:INFO: 
===> EPOCH: 267 (P3)
2022-11-26 18:51:40,472:INFO: - Computing loss (training)
2022-11-26 18:51:41,190:INFO: Dataset: hotel               Batch: 1/4	Loss 122.4618 (122.4618)
2022-11-26 18:51:41,702:INFO: Dataset: hotel               Batch: 2/4	Loss 121.5530 (121.9867)
2022-11-26 18:51:42,196:INFO: Dataset: hotel               Batch: 3/4	Loss 121.6693 (121.8804)
2022-11-26 18:51:42,652:INFO: Dataset: hotel               Batch: 4/4	Loss 73.9491 (113.5968)
2022-11-26 18:51:43,466:INFO: Dataset: univ                Batch:  1/15	Loss 121.0742 (121.0742)
2022-11-26 18:51:44,004:INFO: Dataset: univ                Batch:  2/15	Loss 121.0138 (121.0431)
2022-11-26 18:51:44,552:INFO: Dataset: univ                Batch:  3/15	Loss 121.0502 (121.0456)
2022-11-26 18:51:45,094:INFO: Dataset: univ                Batch:  4/15	Loss 120.3530 (120.8642)
2022-11-26 18:51:45,625:INFO: Dataset: univ                Batch:  5/15	Loss 122.2215 (121.1149)
2022-11-26 18:51:46,152:INFO: Dataset: univ                Batch:  6/15	Loss 122.7478 (121.3576)
2022-11-26 18:51:46,691:INFO: Dataset: univ                Batch:  7/15	Loss 120.8944 (121.2874)
2022-11-26 18:51:47,228:INFO: Dataset: univ                Batch:  8/15	Loss 120.2166 (121.1475)
2022-11-26 18:51:47,766:INFO: Dataset: univ                Batch:  9/15	Loss 120.0725 (121.0216)
2022-11-26 18:51:48,294:INFO: Dataset: univ                Batch: 10/15	Loss 120.9178 (121.0121)
2022-11-26 18:51:48,826:INFO: Dataset: univ                Batch: 11/15	Loss 120.7116 (120.9859)
2022-11-26 18:51:49,369:INFO: Dataset: univ                Batch: 12/15	Loss 120.1562 (120.9119)
2022-11-26 18:51:49,900:INFO: Dataset: univ                Batch: 13/15	Loss 120.2246 (120.8607)
2022-11-26 18:51:50,444:INFO: Dataset: univ                Batch: 14/15	Loss 119.6993 (120.7693)
2022-11-26 18:51:50,879:INFO: Dataset: univ                Batch: 15/15	Loss 22.3825 (119.2820)
2022-11-26 18:51:51,667:INFO: Dataset: zara1               Batch: 1/8	Loss 121.0802 (121.0802)
2022-11-26 18:51:52,174:INFO: Dataset: zara1               Batch: 2/8	Loss 120.7438 (120.9161)
2022-11-26 18:51:52,679:INFO: Dataset: zara1               Batch: 3/8	Loss 120.2465 (120.7136)
2022-11-26 18:51:53,185:INFO: Dataset: zara1               Batch: 4/8	Loss 120.2107 (120.5816)
2022-11-26 18:51:53,701:INFO: Dataset: zara1               Batch: 5/8	Loss 120.6460 (120.5952)
2022-11-26 18:51:54,205:INFO: Dataset: zara1               Batch: 6/8	Loss 119.7541 (120.4610)
2022-11-26 18:51:54,710:INFO: Dataset: zara1               Batch: 7/8	Loss 119.9379 (120.3896)
2022-11-26 18:51:55,200:INFO: Dataset: zara1               Batch: 8/8	Loss 103.6719 (118.4890)
2022-11-26 18:51:55,993:INFO: Dataset: zara2               Batch:  1/18	Loss 119.4147 (119.4147)
2022-11-26 18:51:56,502:INFO: Dataset: zara2               Batch:  2/18	Loss 119.3383 (119.3744)
2022-11-26 18:51:57,018:INFO: Dataset: zara2               Batch:  3/18	Loss 119.1627 (119.2979)
2022-11-26 18:51:57,526:INFO: Dataset: zara2               Batch:  4/18	Loss 119.7630 (119.4075)
2022-11-26 18:51:58,028:INFO: Dataset: zara2               Batch:  5/18	Loss 119.5397 (119.4329)
2022-11-26 18:51:58,541:INFO: Dataset: zara2               Batch:  6/18	Loss 119.5138 (119.4473)
2022-11-26 18:51:59,042:INFO: Dataset: zara2               Batch:  7/18	Loss 118.5605 (119.3187)
2022-11-26 18:51:59,549:INFO: Dataset: zara2               Batch:  8/18	Loss 118.5042 (119.2115)
2022-11-26 18:52:00,058:INFO: Dataset: zara2               Batch:  9/18	Loss 119.0670 (119.1971)
2022-11-26 18:52:00,559:INFO: Dataset: zara2               Batch: 10/18	Loss 118.7924 (119.1591)
2022-11-26 18:52:01,066:INFO: Dataset: zara2               Batch: 11/18	Loss 118.5825 (119.1096)
2022-11-26 18:52:01,567:INFO: Dataset: zara2               Batch: 12/18	Loss 118.5914 (119.0670)
2022-11-26 18:52:02,068:INFO: Dataset: zara2               Batch: 13/18	Loss 118.9572 (119.0591)
2022-11-26 18:52:02,571:INFO: Dataset: zara2               Batch: 14/18	Loss 118.1570 (118.9916)
2022-11-26 18:52:03,157:INFO: Dataset: zara2               Batch: 15/18	Loss 118.6109 (118.9647)
2022-11-26 18:52:03,659:INFO: Dataset: zara2               Batch: 16/18	Loss 118.4555 (118.9296)
2022-11-26 18:52:04,165:INFO: Dataset: zara2               Batch: 17/18	Loss 118.2497 (118.8879)
2022-11-26 18:52:04,655:INFO: Dataset: zara2               Batch: 18/18	Loss 101.6514 (118.0986)
2022-11-26 18:52:04,715:INFO: - Computing ADE (validation)
2022-11-26 18:52:05,074:INFO: 		 ADE on hotel                     dataset:	 2.2841343879699707
2022-11-26 18:52:05,506:INFO: 		 ADE on univ                      dataset:	 2.838834047317505
2022-11-26 18:52:05,842:INFO: 		 ADE on zara1                     dataset:	 2.3320019245147705
2022-11-26 18:52:06,374:INFO: 		 ADE on zara2                     dataset:	 2.416959047317505
2022-11-26 18:52:06,374:INFO: Average validation:	ADE  2.6242	FDE  3.5955
2022-11-26 18:52:06,375:INFO: - Computing ADE (validation o)
2022-11-26 18:52:06,666:INFO: 		 ADE on eth                       dataset:	 2.3061583042144775
2022-11-26 18:52:06,667:INFO: Average validation o:	ADE  2.3062	FDE  2.9497
2022-11-26 18:52:06,675:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_267.pth.tar
2022-11-26 18:52:06,675:INFO: 
===> EPOCH: 268 (P3)
2022-11-26 18:52:06,675:INFO: - Computing loss (training)
2022-11-26 18:52:07,403:INFO: Dataset: hotel               Batch: 1/4	Loss 119.9607 (119.9607)
2022-11-26 18:52:07,908:INFO: Dataset: hotel               Batch: 2/4	Loss 119.4051 (119.6868)
2022-11-26 18:52:08,406:INFO: Dataset: hotel               Batch: 3/4	Loss 119.1237 (119.5069)
2022-11-26 18:52:08,867:INFO: Dataset: hotel               Batch: 4/4	Loss 72.5135 (111.3233)
2022-11-26 18:52:09,687:INFO: Dataset: univ                Batch:  1/15	Loss 118.0197 (118.0197)
2022-11-26 18:52:10,212:INFO: Dataset: univ                Batch:  2/15	Loss 118.7724 (118.3923)
2022-11-26 18:52:10,749:INFO: Dataset: univ                Batch:  3/15	Loss 117.8417 (118.1963)
2022-11-26 18:52:11,290:INFO: Dataset: univ                Batch:  4/15	Loss 117.3458 (117.9638)
2022-11-26 18:52:11,822:INFO: Dataset: univ                Batch:  5/15	Loss 117.6424 (117.9014)
2022-11-26 18:52:12,360:INFO: Dataset: univ                Batch:  6/15	Loss 118.5798 (118.0133)
2022-11-26 18:52:12,891:INFO: Dataset: univ                Batch:  7/15	Loss 117.7671 (117.9781)
2022-11-26 18:52:13,421:INFO: Dataset: univ                Batch:  8/15	Loss 117.6599 (117.9390)
2022-11-26 18:52:13,950:INFO: Dataset: univ                Batch:  9/15	Loss 117.9278 (117.9378)
2022-11-26 18:52:14,487:INFO: Dataset: univ                Batch: 10/15	Loss 117.8183 (117.9253)
2022-11-26 18:52:15,020:INFO: Dataset: univ                Batch: 11/15	Loss 117.0944 (117.8483)
2022-11-26 18:52:15,546:INFO: Dataset: univ                Batch: 12/15	Loss 118.4605 (117.8940)
2022-11-26 18:52:16,067:INFO: Dataset: univ                Batch: 13/15	Loss 118.0232 (117.9025)
2022-11-26 18:52:16,611:INFO: Dataset: univ                Batch: 14/15	Loss 117.2828 (117.8529)
2022-11-26 18:52:17,041:INFO: Dataset: univ                Batch: 15/15	Loss 22.0316 (116.6087)
2022-11-26 18:52:17,830:INFO: Dataset: zara1               Batch: 1/8	Loss 118.1968 (118.1968)
2022-11-26 18:52:18,334:INFO: Dataset: zara1               Batch: 2/8	Loss 118.1032 (118.1517)
2022-11-26 18:52:18,838:INFO: Dataset: zara1               Batch: 3/8	Loss 117.2572 (117.8514)
2022-11-26 18:52:19,340:INFO: Dataset: zara1               Batch: 4/8	Loss 117.7243 (117.8176)
2022-11-26 18:52:19,842:INFO: Dataset: zara1               Batch: 5/8	Loss 117.3306 (117.7274)
2022-11-26 18:52:20,357:INFO: Dataset: zara1               Batch: 6/8	Loss 117.8827 (117.7561)
2022-11-26 18:52:20,868:INFO: Dataset: zara1               Batch: 7/8	Loss 117.0782 (117.6508)
2022-11-26 18:52:21,358:INFO: Dataset: zara1               Batch: 8/8	Loss 101.3293 (115.6064)
2022-11-26 18:52:22,163:INFO: Dataset: zara2               Batch:  1/18	Loss 117.0385 (117.0385)
2022-11-26 18:52:22,676:INFO: Dataset: zara2               Batch:  2/18	Loss 116.9357 (116.9881)
2022-11-26 18:52:23,189:INFO: Dataset: zara2               Batch:  3/18	Loss 116.8814 (116.9541)
2022-11-26 18:52:23,700:INFO: Dataset: zara2               Batch:  4/18	Loss 116.6479 (116.8692)
2022-11-26 18:52:24,214:INFO: Dataset: zara2               Batch:  5/18	Loss 116.3345 (116.7687)
2022-11-26 18:52:24,726:INFO: Dataset: zara2               Batch:  6/18	Loss 116.5562 (116.7327)
2022-11-26 18:52:25,235:INFO: Dataset: zara2               Batch:  7/18	Loss 116.4607 (116.6963)
2022-11-26 18:52:25,743:INFO: Dataset: zara2               Batch:  8/18	Loss 115.9341 (116.5896)
2022-11-26 18:52:26,253:INFO: Dataset: zara2               Batch:  9/18	Loss 115.8940 (116.5057)
2022-11-26 18:52:26,761:INFO: Dataset: zara2               Batch: 10/18	Loss 116.0095 (116.4560)
2022-11-26 18:52:27,269:INFO: Dataset: zara2               Batch: 11/18	Loss 116.0254 (116.4126)
2022-11-26 18:52:27,776:INFO: Dataset: zara2               Batch: 12/18	Loss 115.5434 (116.3417)
2022-11-26 18:52:28,281:INFO: Dataset: zara2               Batch: 13/18	Loss 116.5915 (116.3623)
2022-11-26 18:52:28,787:INFO: Dataset: zara2               Batch: 14/18	Loss 115.3145 (116.2904)
2022-11-26 18:52:29,295:INFO: Dataset: zara2               Batch: 15/18	Loss 115.8463 (116.2636)
2022-11-26 18:52:29,804:INFO: Dataset: zara2               Batch: 16/18	Loss 115.4695 (116.2172)
2022-11-26 18:52:30,311:INFO: Dataset: zara2               Batch: 17/18	Loss 115.9131 (116.2022)
2022-11-26 18:52:30,805:INFO: Dataset: zara2               Batch: 18/18	Loss 99.0535 (115.3914)
2022-11-26 18:52:30,863:INFO: - Computing ADE (validation)
2022-11-26 18:52:31,225:INFO: 		 ADE on hotel                     dataset:	 2.3389484882354736
2022-11-26 18:52:31,658:INFO: 		 ADE on univ                      dataset:	 2.787574529647827
2022-11-26 18:52:32,014:INFO: 		 ADE on zara1                     dataset:	 2.31034255027771
2022-11-26 18:52:32,564:INFO: 		 ADE on zara2                     dataset:	 2.386582374572754
2022-11-26 18:52:32,564:INFO: Average validation:	ADE  2.5882	FDE  3.5523
2022-11-26 18:52:32,565:INFO: - Computing ADE (validation o)
2022-11-26 18:52:32,871:INFO: 		 ADE on eth                       dataset:	 2.3172764778137207
2022-11-26 18:52:32,871:INFO: Average validation o:	ADE  2.3173	FDE  2.8048
2022-11-26 18:52:32,880:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_268.pth.tar
2022-11-26 18:52:32,880:INFO: 
===> EPOCH: 269 (P3)
2022-11-26 18:52:32,880:INFO: - Computing loss (training)
2022-11-26 18:52:33,595:INFO: Dataset: hotel               Batch: 1/4	Loss 116.5365 (116.5365)
2022-11-26 18:52:34,088:INFO: Dataset: hotel               Batch: 2/4	Loss 116.7201 (116.6303)
2022-11-26 18:52:34,580:INFO: Dataset: hotel               Batch: 3/4	Loss 117.5900 (116.9611)
2022-11-26 18:52:35,036:INFO: Dataset: hotel               Batch: 4/4	Loss 70.5889 (108.3963)
2022-11-26 18:52:35,846:INFO: Dataset: univ                Batch:  1/15	Loss 115.8351 (115.8351)
2022-11-26 18:52:36,462:INFO: Dataset: univ                Batch:  2/15	Loss 116.2971 (116.0684)
2022-11-26 18:52:36,997:INFO: Dataset: univ                Batch:  3/15	Loss 115.4638 (115.8726)
2022-11-26 18:52:37,531:INFO: Dataset: univ                Batch:  4/15	Loss 115.5627 (115.7894)
2022-11-26 18:52:38,070:INFO: Dataset: univ                Batch:  5/15	Loss 115.0035 (115.6149)
2022-11-26 18:52:38,604:INFO: Dataset: univ                Batch:  6/15	Loss 115.2636 (115.5553)
2022-11-26 18:52:39,143:INFO: Dataset: univ                Batch:  7/15	Loss 114.8199 (115.4401)
2022-11-26 18:52:39,673:INFO: Dataset: univ                Batch:  8/15	Loss 114.9633 (115.3800)
2022-11-26 18:52:40,197:INFO: Dataset: univ                Batch:  9/15	Loss 115.4784 (115.3903)
2022-11-26 18:52:40,735:INFO: Dataset: univ                Batch: 10/15	Loss 114.7088 (115.3172)
2022-11-26 18:52:41,269:INFO: Dataset: univ                Batch: 11/15	Loss 115.0121 (115.2882)
2022-11-26 18:52:41,802:INFO: Dataset: univ                Batch: 12/15	Loss 114.6196 (115.2315)
2022-11-26 18:52:42,343:INFO: Dataset: univ                Batch: 13/15	Loss 114.5882 (115.1753)
2022-11-26 18:52:42,871:INFO: Dataset: univ                Batch: 14/15	Loss 116.1580 (115.2399)
2022-11-26 18:52:43,302:INFO: Dataset: univ                Batch: 15/15	Loss 21.4309 (114.0040)
2022-11-26 18:52:44,104:INFO: Dataset: zara1               Batch: 1/8	Loss 115.0182 (115.0182)
2022-11-26 18:52:44,611:INFO: Dataset: zara1               Batch: 2/8	Loss 115.0232 (115.0209)
2022-11-26 18:52:45,127:INFO: Dataset: zara1               Batch: 3/8	Loss 114.8636 (114.9622)
2022-11-26 18:52:45,632:INFO: Dataset: zara1               Batch: 4/8	Loss 114.5562 (114.8572)
2022-11-26 18:52:46,137:INFO: Dataset: zara1               Batch: 5/8	Loss 114.6303 (114.8101)
2022-11-26 18:52:46,642:INFO: Dataset: zara1               Batch: 6/8	Loss 114.2824 (114.7195)
2022-11-26 18:52:47,146:INFO: Dataset: zara1               Batch: 7/8	Loss 114.8295 (114.7356)
2022-11-26 18:52:47,641:INFO: Dataset: zara1               Batch: 8/8	Loss 98.3873 (113.0577)
2022-11-26 18:52:48,454:INFO: Dataset: zara2               Batch:  1/18	Loss 114.1772 (114.1772)
2022-11-26 18:52:48,963:INFO: Dataset: zara2               Batch:  2/18	Loss 114.5146 (114.3499)
2022-11-26 18:52:49,474:INFO: Dataset: zara2               Batch:  3/18	Loss 114.1386 (114.2751)
2022-11-26 18:52:49,986:INFO: Dataset: zara2               Batch:  4/18	Loss 113.3103 (114.0464)
2022-11-26 18:52:50,495:INFO: Dataset: zara2               Batch:  5/18	Loss 113.6937 (113.9739)
2022-11-26 18:52:51,006:INFO: Dataset: zara2               Batch:  6/18	Loss 114.0267 (113.9819)
2022-11-26 18:52:51,516:INFO: Dataset: zara2               Batch:  7/18	Loss 113.3620 (113.8971)
2022-11-26 18:52:52,023:INFO: Dataset: zara2               Batch:  8/18	Loss 113.5878 (113.8546)
2022-11-26 18:52:52,532:INFO: Dataset: zara2               Batch:  9/18	Loss 113.3600 (113.8044)
2022-11-26 18:52:53,041:INFO: Dataset: zara2               Batch: 10/18	Loss 112.9343 (113.7204)
2022-11-26 18:52:53,553:INFO: Dataset: zara2               Batch: 11/18	Loss 113.0134 (113.6535)
2022-11-26 18:52:54,060:INFO: Dataset: zara2               Batch: 12/18	Loss 113.0881 (113.6140)
2022-11-26 18:52:54,566:INFO: Dataset: zara2               Batch: 13/18	Loss 113.0309 (113.5662)
2022-11-26 18:52:55,073:INFO: Dataset: zara2               Batch: 14/18	Loss 112.9777 (113.5201)
2022-11-26 18:52:55,580:INFO: Dataset: zara2               Batch: 15/18	Loss 113.4155 (113.5130)
2022-11-26 18:52:56,089:INFO: Dataset: zara2               Batch: 16/18	Loss 113.3948 (113.5058)
2022-11-26 18:52:56,598:INFO: Dataset: zara2               Batch: 17/18	Loss 112.8287 (113.4674)
2022-11-26 18:52:57,094:INFO: Dataset: zara2               Batch: 18/18	Loss 97.4488 (112.6173)
2022-11-26 18:52:57,151:INFO: - Computing ADE (validation)
2022-11-26 18:52:57,505:INFO: 		 ADE on hotel                     dataset:	 2.3044188022613525
2022-11-26 18:52:57,939:INFO: 		 ADE on univ                      dataset:	 2.734483242034912
2022-11-26 18:52:58,291:INFO: 		 ADE on zara1                     dataset:	 2.244157314300537
2022-11-26 18:52:58,836:INFO: 		 ADE on zara2                     dataset:	 2.307624340057373
2022-11-26 18:52:58,836:INFO: Average validation:	ADE  2.5258	FDE  3.4927
2022-11-26 18:52:58,837:INFO: - Computing ADE (validation o)
2022-11-26 18:52:59,127:INFO: 		 ADE on eth                       dataset:	 2.098757266998291
2022-11-26 18:52:59,127:INFO: Average validation o:	ADE  2.0988	FDE  2.4450
2022-11-26 18:52:59,136:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_269.pth.tar
2022-11-26 18:52:59,136:INFO: 
===> EPOCH: 270 (P3)
2022-11-26 18:52:59,136:INFO: - Computing loss (training)
2022-11-26 18:52:59,839:INFO: Dataset: hotel               Batch: 1/4	Loss 114.3176 (114.3176)
2022-11-26 18:53:00,337:INFO: Dataset: hotel               Batch: 2/4	Loss 114.9971 (114.6663)
2022-11-26 18:53:00,831:INFO: Dataset: hotel               Batch: 3/4	Loss 113.2256 (114.1915)
2022-11-26 18:53:01,288:INFO: Dataset: hotel               Batch: 4/4	Loss 69.2142 (106.1217)
2022-11-26 18:53:02,135:INFO: Dataset: univ                Batch:  1/15	Loss 112.8582 (112.8582)
2022-11-26 18:53:02,699:INFO: Dataset: univ                Batch:  2/15	Loss 112.9554 (112.9067)
2022-11-26 18:53:03,254:INFO: Dataset: univ                Batch:  3/15	Loss 112.6148 (112.8100)
2022-11-26 18:53:03,813:INFO: Dataset: univ                Batch:  4/15	Loss 113.5474 (112.9900)
2022-11-26 18:53:04,366:INFO: Dataset: univ                Batch:  5/15	Loss 112.4976 (112.8955)
2022-11-26 18:53:04,924:INFO: Dataset: univ                Batch:  6/15	Loss 112.4707 (112.8213)
2022-11-26 18:53:05,472:INFO: Dataset: univ                Batch:  7/15	Loss 112.9573 (112.8404)
2022-11-26 18:53:06,028:INFO: Dataset: univ                Batch:  8/15	Loss 112.3265 (112.7704)
2022-11-26 18:53:06,658:INFO: Dataset: univ                Batch:  9/15	Loss 112.8699 (112.7801)
2022-11-26 18:53:07,201:INFO: Dataset: univ                Batch: 10/15	Loss 112.6941 (112.7723)
2022-11-26 18:53:07,747:INFO: Dataset: univ                Batch: 11/15	Loss 112.3580 (112.7344)
2022-11-26 18:53:08,302:INFO: Dataset: univ                Batch: 12/15	Loss 112.3665 (112.7017)
2022-11-26 18:53:08,845:INFO: Dataset: univ                Batch: 13/15	Loss 111.8772 (112.6417)
2022-11-26 18:53:09,395:INFO: Dataset: univ                Batch: 14/15	Loss 111.7072 (112.5748)
2022-11-26 18:53:09,841:INFO: Dataset: univ                Batch: 15/15	Loss 20.8922 (111.3974)
2022-11-26 18:53:10,628:INFO: Dataset: zara1               Batch: 1/8	Loss 111.4397 (111.4397)
2022-11-26 18:53:11,130:INFO: Dataset: zara1               Batch: 2/8	Loss 111.9458 (111.6817)
2022-11-26 18:53:11,633:INFO: Dataset: zara1               Batch: 3/8	Loss 112.5949 (111.9907)
2022-11-26 18:53:12,147:INFO: Dataset: zara1               Batch: 4/8	Loss 111.7992 (111.9393)
2022-11-26 18:53:12,659:INFO: Dataset: zara1               Batch: 5/8	Loss 111.7120 (111.9002)
2022-11-26 18:53:13,165:INFO: Dataset: zara1               Batch: 6/8	Loss 111.6098 (111.8497)
2022-11-26 18:53:13,667:INFO: Dataset: zara1               Batch: 7/8	Loss 111.6995 (111.8294)
2022-11-26 18:53:14,157:INFO: Dataset: zara1               Batch: 8/8	Loss 95.7143 (110.0228)
2022-11-26 18:53:14,992:INFO: Dataset: zara2               Batch:  1/18	Loss 110.9080 (110.9080)
2022-11-26 18:53:15,509:INFO: Dataset: zara2               Batch:  2/18	Loss 110.9697 (110.9427)
2022-11-26 18:53:16,025:INFO: Dataset: zara2               Batch:  3/18	Loss 110.9224 (110.9357)
2022-11-26 18:53:16,550:INFO: Dataset: zara2               Batch:  4/18	Loss 110.6881 (110.8769)
2022-11-26 18:53:17,069:INFO: Dataset: zara2               Batch:  5/18	Loss 111.4308 (110.9797)
2022-11-26 18:53:17,594:INFO: Dataset: zara2               Batch:  6/18	Loss 110.5187 (110.9060)
2022-11-26 18:53:18,116:INFO: Dataset: zara2               Batch:  7/18	Loss 110.4300 (110.8351)
2022-11-26 18:53:18,635:INFO: Dataset: zara2               Batch:  8/18	Loss 110.8057 (110.8314)
2022-11-26 18:53:19,154:INFO: Dataset: zara2               Batch:  9/18	Loss 110.3984 (110.7820)
2022-11-26 18:53:19,671:INFO: Dataset: zara2               Batch: 10/18	Loss 110.2624 (110.7299)
2022-11-26 18:53:20,193:INFO: Dataset: zara2               Batch: 11/18	Loss 110.0879 (110.6735)
2022-11-26 18:53:20,712:INFO: Dataset: zara2               Batch: 12/18	Loss 110.2158 (110.6369)
2022-11-26 18:53:21,236:INFO: Dataset: zara2               Batch: 13/18	Loss 110.1507 (110.6025)
2022-11-26 18:53:21,753:INFO: Dataset: zara2               Batch: 14/18	Loss 110.0385 (110.5559)
2022-11-26 18:53:22,269:INFO: Dataset: zara2               Batch: 15/18	Loss 110.3694 (110.5433)
2022-11-26 18:53:22,785:INFO: Dataset: zara2               Batch: 16/18	Loss 110.1101 (110.5150)
2022-11-26 18:53:23,300:INFO: Dataset: zara2               Batch: 17/18	Loss 109.6266 (110.4596)
2022-11-26 18:53:23,805:INFO: Dataset: zara2               Batch: 18/18	Loss 94.5386 (109.7147)
2022-11-26 18:53:23,865:INFO: - Computing ADE (validation)
2022-11-26 18:53:24,221:INFO: 		 ADE on hotel                     dataset:	 2.2315521240234375
2022-11-26 18:53:24,645:INFO: 		 ADE on univ                      dataset:	 2.6379988193511963
2022-11-26 18:53:24,993:INFO: 		 ADE on zara1                     dataset:	 2.1172752380371094
2022-11-26 18:53:25,532:INFO: 		 ADE on zara2                     dataset:	 2.2746171951293945
2022-11-26 18:53:25,532:INFO: Average validation:	ADE  2.4522	FDE  3.3606
2022-11-26 18:53:25,533:INFO: - Computing ADE (validation o)
2022-11-26 18:53:25,830:INFO: 		 ADE on eth                       dataset:	 2.011934518814087
2022-11-26 18:53:25,830:INFO: Average validation o:	ADE  2.0119	FDE  2.4801
2022-11-26 18:53:25,839:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_270.pth.tar
2022-11-26 18:53:25,839:INFO: 
===> EPOCH: 271 (P3)
2022-11-26 18:53:25,840:INFO: - Computing loss (training)
2022-11-26 18:53:26,552:INFO: Dataset: hotel               Batch: 1/4	Loss 111.2941 (111.2941)
2022-11-26 18:53:27,053:INFO: Dataset: hotel               Batch: 2/4	Loss 111.3885 (111.3432)
2022-11-26 18:53:27,550:INFO: Dataset: hotel               Batch: 3/4	Loss 112.6487 (111.7763)
2022-11-26 18:53:28,007:INFO: Dataset: hotel               Batch: 4/4	Loss 67.8730 (103.8413)
2022-11-26 18:53:28,841:INFO: Dataset: univ                Batch:  1/15	Loss 110.6064 (110.6064)
2022-11-26 18:53:29,384:INFO: Dataset: univ                Batch:  2/15	Loss 110.4542 (110.5308)
2022-11-26 18:53:29,936:INFO: Dataset: univ                Batch:  3/15	Loss 118.7855 (113.4545)
2022-11-26 18:53:30,488:INFO: Dataset: univ                Batch:  4/15	Loss 110.0261 (112.6257)
2022-11-26 18:53:31,033:INFO: Dataset: univ                Batch:  5/15	Loss 110.2520 (112.1670)
2022-11-26 18:53:31,575:INFO: Dataset: univ                Batch:  6/15	Loss 111.0227 (111.9851)
2022-11-26 18:53:32,115:INFO: Dataset: univ                Batch:  7/15	Loss 111.9930 (111.9863)
2022-11-26 18:53:32,643:INFO: Dataset: univ                Batch:  8/15	Loss 112.6895 (112.0613)
2022-11-26 18:53:33,196:INFO: Dataset: univ                Batch:  9/15	Loss 112.2585 (112.0856)
2022-11-26 18:53:33,731:INFO: Dataset: univ                Batch: 10/15	Loss 112.6698 (112.1411)
2022-11-26 18:53:34,272:INFO: Dataset: univ                Batch: 11/15	Loss 112.1848 (112.1452)
2022-11-26 18:53:34,806:INFO: Dataset: univ                Batch: 12/15	Loss 111.3467 (112.0838)
2022-11-26 18:53:35,346:INFO: Dataset: univ                Batch: 13/15	Loss 111.2515 (112.0188)
2022-11-26 18:53:35,898:INFO: Dataset: univ                Batch: 14/15	Loss 109.9373 (111.8724)
2022-11-26 18:53:36,339:INFO: Dataset: univ                Batch: 15/15	Loss 20.5388 (110.6691)
2022-11-26 18:53:37,211:INFO: Dataset: zara1               Batch: 1/8	Loss 111.3033 (111.3033)
2022-11-26 18:53:37,709:INFO: Dataset: zara1               Batch: 2/8	Loss 111.3200 (111.3120)
2022-11-26 18:53:38,217:INFO: Dataset: zara1               Batch: 3/8	Loss 110.6504 (111.0748)
2022-11-26 18:53:38,715:INFO: Dataset: zara1               Batch: 4/8	Loss 111.4804 (111.1652)
2022-11-26 18:53:39,211:INFO: Dataset: zara1               Batch: 5/8	Loss 111.1863 (111.1695)
2022-11-26 18:53:39,712:INFO: Dataset: zara1               Batch: 6/8	Loss 110.8421 (111.1154)
2022-11-26 18:53:40,211:INFO: Dataset: zara1               Batch: 7/8	Loss 111.3844 (111.1502)
2022-11-26 18:53:40,695:INFO: Dataset: zara1               Batch: 8/8	Loss 95.6405 (109.3136)
2022-11-26 18:53:41,490:INFO: Dataset: zara2               Batch:  1/18	Loss 109.1896 (109.1896)
2022-11-26 18:53:42,001:INFO: Dataset: zara2               Batch:  2/18	Loss 109.0769 (109.1338)
2022-11-26 18:53:42,507:INFO: Dataset: zara2               Batch:  3/18	Loss 109.2748 (109.1816)
2022-11-26 18:53:43,015:INFO: Dataset: zara2               Batch:  4/18	Loss 109.3471 (109.2230)
2022-11-26 18:53:43,521:INFO: Dataset: zara2               Batch:  5/18	Loss 109.0269 (109.1834)
2022-11-26 18:53:44,029:INFO: Dataset: zara2               Batch:  6/18	Loss 108.4368 (109.0596)
2022-11-26 18:53:44,534:INFO: Dataset: zara2               Batch:  7/18	Loss 108.6630 (109.0033)
2022-11-26 18:53:45,040:INFO: Dataset: zara2               Batch:  8/18	Loss 109.2356 (109.0365)
2022-11-26 18:53:45,545:INFO: Dataset: zara2               Batch:  9/18	Loss 108.6293 (108.9924)
2022-11-26 18:53:46,049:INFO: Dataset: zara2               Batch: 10/18	Loss 108.7486 (108.9648)
2022-11-26 18:53:46,554:INFO: Dataset: zara2               Batch: 11/18	Loss 108.7484 (108.9443)
2022-11-26 18:53:47,059:INFO: Dataset: zara2               Batch: 12/18	Loss 108.2676 (108.8909)
2022-11-26 18:53:47,564:INFO: Dataset: zara2               Batch: 13/18	Loss 108.0780 (108.8272)
2022-11-26 18:53:48,069:INFO: Dataset: zara2               Batch: 14/18	Loss 108.3451 (108.7893)
2022-11-26 18:53:48,576:INFO: Dataset: zara2               Batch: 15/18	Loss 108.3713 (108.7616)
2022-11-26 18:53:49,082:INFO: Dataset: zara2               Batch: 16/18	Loss 107.8057 (108.7048)
2022-11-26 18:53:49,591:INFO: Dataset: zara2               Batch: 17/18	Loss 107.9278 (108.6583)
2022-11-26 18:53:50,091:INFO: Dataset: zara2               Batch: 18/18	Loss 92.8378 (107.9129)
2022-11-26 18:53:50,152:INFO: - Computing ADE (validation)
2022-11-26 18:53:50,513:INFO: 		 ADE on hotel                     dataset:	 2.066793918609619
2022-11-26 18:53:50,953:INFO: 		 ADE on univ                      dataset:	 2.5833563804626465
2022-11-26 18:53:51,303:INFO: 		 ADE on zara1                     dataset:	 2.0919172763824463
2022-11-26 18:53:51,858:INFO: 		 ADE on zara2                     dataset:	 2.1999521255493164
2022-11-26 18:53:51,858:INFO: Average validation:	ADE  2.3859	FDE  3.3112
2022-11-26 18:53:51,859:INFO: - Computing ADE (validation o)
2022-11-26 18:53:52,155:INFO: 		 ADE on eth                       dataset:	 2.05900239944458
2022-11-26 18:53:52,156:INFO: Average validation o:	ADE  2.0590	FDE  2.5681
2022-11-26 18:53:52,164:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_271.pth.tar
2022-11-26 18:53:52,164:INFO: 
===> EPOCH: 272 (P3)
2022-11-26 18:53:52,164:INFO: - Computing loss (training)
2022-11-26 18:53:52,891:INFO: Dataset: hotel               Batch: 1/4	Loss 110.6357 (110.6357)
2022-11-26 18:53:53,401:INFO: Dataset: hotel               Batch: 2/4	Loss 109.4062 (110.0133)
2022-11-26 18:53:53,903:INFO: Dataset: hotel               Batch: 3/4	Loss 109.2537 (109.7467)
2022-11-26 18:53:54,363:INFO: Dataset: hotel               Batch: 4/4	Loss 65.9830 (101.8369)
2022-11-26 18:53:55,207:INFO: Dataset: univ                Batch:  1/15	Loss 108.7296 (108.7296)
2022-11-26 18:53:55,754:INFO: Dataset: univ                Batch:  2/15	Loss 108.2353 (108.4870)
2022-11-26 18:53:56,290:INFO: Dataset: univ                Batch:  3/15	Loss 108.1387 (108.3807)
2022-11-26 18:53:56,843:INFO: Dataset: univ                Batch:  4/15	Loss 107.5375 (108.1599)
2022-11-26 18:53:57,390:INFO: Dataset: univ                Batch:  5/15	Loss 107.9517 (108.1204)
2022-11-26 18:53:57,931:INFO: Dataset: univ                Batch:  6/15	Loss 107.2260 (107.9742)
2022-11-26 18:53:58,466:INFO: Dataset: univ                Batch:  7/15	Loss 108.0900 (107.9890)
2022-11-26 18:53:59,011:INFO: Dataset: univ                Batch:  8/15	Loss 107.1545 (107.8800)
2022-11-26 18:53:59,552:INFO: Dataset: univ                Batch:  9/15	Loss 107.3125 (107.8181)
2022-11-26 18:54:00,107:INFO: Dataset: univ                Batch: 10/15	Loss 107.3268 (107.7633)
2022-11-26 18:54:00,643:INFO: Dataset: univ                Batch: 11/15	Loss 116.4561 (108.4424)
2022-11-26 18:54:01,194:INFO: Dataset: univ                Batch: 12/15	Loss 107.2520 (108.3361)
2022-11-26 18:54:01,735:INFO: Dataset: univ                Batch: 13/15	Loss 107.4862 (108.2721)
2022-11-26 18:54:02,284:INFO: Dataset: univ                Batch: 14/15	Loss 107.8831 (108.2425)
2022-11-26 18:54:02,731:INFO: Dataset: univ                Batch: 15/15	Loss 20.2152 (107.1538)
2022-11-26 18:54:03,512:INFO: Dataset: zara1               Batch: 1/8	Loss 109.4414 (109.4414)
2022-11-26 18:54:04,021:INFO: Dataset: zara1               Batch: 2/8	Loss 108.5355 (108.9865)
2022-11-26 18:54:04,527:INFO: Dataset: zara1               Batch: 3/8	Loss 108.2350 (108.7403)
2022-11-26 18:54:05,039:INFO: Dataset: zara1               Batch: 4/8	Loss 108.2138 (108.5960)
2022-11-26 18:54:05,544:INFO: Dataset: zara1               Batch: 5/8	Loss 108.5159 (108.5803)
2022-11-26 18:54:06,061:INFO: Dataset: zara1               Batch: 6/8	Loss 107.7192 (108.4263)
2022-11-26 18:54:06,571:INFO: Dataset: zara1               Batch: 7/8	Loss 107.5440 (108.3021)
2022-11-26 18:54:07,065:INFO: Dataset: zara1               Batch: 8/8	Loss 92.2243 (106.6520)
2022-11-26 18:54:07,889:INFO: Dataset: zara2               Batch:  1/18	Loss 106.7142 (106.7142)
2022-11-26 18:54:08,524:INFO: Dataset: zara2               Batch:  2/18	Loss 106.5637 (106.6408)
2022-11-26 18:54:09,060:INFO: Dataset: zara2               Batch:  3/18	Loss 106.8998 (106.7232)
2022-11-26 18:54:09,578:INFO: Dataset: zara2               Batch:  4/18	Loss 106.3149 (106.6193)
2022-11-26 18:54:10,097:INFO: Dataset: zara2               Batch:  5/18	Loss 105.9590 (106.4987)
2022-11-26 18:54:10,612:INFO: Dataset: zara2               Batch:  6/18	Loss 106.5728 (106.5120)
2022-11-26 18:54:11,129:INFO: Dataset: zara2               Batch:  7/18	Loss 105.9186 (106.4292)
2022-11-26 18:54:11,644:INFO: Dataset: zara2               Batch:  8/18	Loss 105.9386 (106.3703)
2022-11-26 18:54:12,156:INFO: Dataset: zara2               Batch:  9/18	Loss 105.6052 (106.2800)
2022-11-26 18:54:12,676:INFO: Dataset: zara2               Batch: 10/18	Loss 105.6565 (106.2195)
2022-11-26 18:54:13,189:INFO: Dataset: zara2               Batch: 11/18	Loss 105.0701 (106.1166)
2022-11-26 18:54:13,703:INFO: Dataset: zara2               Batch: 12/18	Loss 105.6037 (106.0709)
2022-11-26 18:54:14,220:INFO: Dataset: zara2               Batch: 13/18	Loss 105.3365 (106.0157)
2022-11-26 18:54:14,732:INFO: Dataset: zara2               Batch: 14/18	Loss 105.0194 (105.9529)
2022-11-26 18:54:15,244:INFO: Dataset: zara2               Batch: 15/18	Loss 105.2710 (105.9079)
2022-11-26 18:54:15,755:INFO: Dataset: zara2               Batch: 16/18	Loss 104.9365 (105.8427)
2022-11-26 18:54:16,266:INFO: Dataset: zara2               Batch: 17/18	Loss 104.8853 (105.7866)
2022-11-26 18:54:16,766:INFO: Dataset: zara2               Batch: 18/18	Loss 90.3905 (105.1045)
2022-11-26 18:54:16,827:INFO: - Computing ADE (validation)
2022-11-26 18:54:17,181:INFO: 		 ADE on hotel                     dataset:	 2.100879669189453
2022-11-26 18:54:17,610:INFO: 		 ADE on univ                      dataset:	 2.5287420749664307
2022-11-26 18:54:17,963:INFO: 		 ADE on zara1                     dataset:	 2.0162734985351562
2022-11-26 18:54:18,523:INFO: 		 ADE on zara2                     dataset:	 2.1597635746002197
2022-11-26 18:54:18,523:INFO: Average validation:	ADE  2.3402	FDE  3.2257
2022-11-26 18:54:18,524:INFO: - Computing ADE (validation o)
2022-11-26 18:54:18,822:INFO: 		 ADE on eth                       dataset:	 1.924164056777954
2022-11-26 18:54:18,822:INFO: Average validation o:	ADE  1.9242	FDE  2.2520
2022-11-26 18:54:18,830:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_272.pth.tar
2022-11-26 18:54:18,831:INFO: 
===> EPOCH: 273 (P3)
2022-11-26 18:54:18,831:INFO: - Computing loss (training)
2022-11-26 18:54:19,544:INFO: Dataset: hotel               Batch: 1/4	Loss 107.0308 (107.0308)
2022-11-26 18:54:20,052:INFO: Dataset: hotel               Batch: 2/4	Loss 108.4929 (107.7601)
2022-11-26 18:54:20,552:INFO: Dataset: hotel               Batch: 3/4	Loss 106.9456 (107.4839)
2022-11-26 18:54:20,993:INFO: Dataset: hotel               Batch: 4/4	Loss 65.1230 (100.3865)
2022-11-26 18:54:21,853:INFO: Dataset: univ                Batch:  1/15	Loss 105.2752 (105.2752)
2022-11-26 18:54:22,395:INFO: Dataset: univ                Batch:  2/15	Loss 106.0458 (105.6647)
2022-11-26 18:54:22,930:INFO: Dataset: univ                Batch:  3/15	Loss 106.5382 (105.9406)
2022-11-26 18:54:23,484:INFO: Dataset: univ                Batch:  4/15	Loss 104.6002 (105.6028)
2022-11-26 18:54:24,027:INFO: Dataset: univ                Batch:  5/15	Loss 104.7671 (105.4253)
2022-11-26 18:54:24,569:INFO: Dataset: univ                Batch:  6/15	Loss 835.7972 (224.4171)
2022-11-26 18:54:25,109:INFO: Dataset: univ                Batch:  7/15	Loss 107.6565 (207.5248)
2022-11-26 18:54:25,651:INFO: Dataset: univ                Batch:  8/15	Loss 114.3633 (195.9540)
2022-11-26 18:54:26,191:INFO: Dataset: univ                Batch:  9/15	Loss 127.4022 (188.0172)
2022-11-26 18:54:26,730:INFO: Dataset: univ                Batch: 10/15	Loss 148.8193 (183.9980)
2022-11-26 18:54:27,287:INFO: Dataset: univ                Batch: 11/15	Loss 155.9840 (181.0714)
2022-11-26 18:54:27,833:INFO: Dataset: univ                Batch: 12/15	Loss 309.5388 (192.3370)
2022-11-26 18:54:28,367:INFO: Dataset: univ                Batch: 13/15	Loss 218.0244 (194.1969)
2022-11-26 18:54:28,913:INFO: Dataset: univ                Batch: 14/15	Loss 180.9172 (193.1986)
2022-11-26 18:54:29,355:INFO: Dataset: univ                Batch: 15/15	Loss 37.8404 (191.1003)
2022-11-26 18:54:30,138:INFO: Dataset: zara1               Batch: 1/8	Loss 123.0068 (123.0068)
2022-11-26 18:54:30,641:INFO: Dataset: zara1               Batch: 2/8	Loss 120.7149 (121.8977)
2022-11-26 18:54:31,152:INFO: Dataset: zara1               Batch: 3/8	Loss 117.6533 (120.3103)
2022-11-26 18:54:31,653:INFO: Dataset: zara1               Batch: 4/8	Loss 115.9690 (119.3043)
2022-11-26 18:54:32,157:INFO: Dataset: zara1               Batch: 5/8	Loss 117.5204 (118.9772)
2022-11-26 18:54:32,663:INFO: Dataset: zara1               Batch: 6/8	Loss 114.5347 (118.2029)
2022-11-26 18:54:33,168:INFO: Dataset: zara1               Batch: 7/8	Loss 115.2551 (117.7984)
2022-11-26 18:54:33,656:INFO: Dataset: zara1               Batch: 8/8	Loss 98.5420 (115.4572)
2022-11-26 18:54:34,465:INFO: Dataset: zara2               Batch:  1/18	Loss 119.2713 (119.2713)
2022-11-26 18:54:34,979:INFO: Dataset: zara2               Batch:  2/18	Loss 118.2746 (118.7714)
2022-11-26 18:54:35,496:INFO: Dataset: zara2               Batch:  3/18	Loss 118.0691 (118.5489)
2022-11-26 18:54:36,011:INFO: Dataset: zara2               Batch:  4/18	Loss 119.1996 (118.7115)
2022-11-26 18:54:36,531:INFO: Dataset: zara2               Batch:  5/18	Loss 118.5423 (118.6779)
2022-11-26 18:54:37,044:INFO: Dataset: zara2               Batch:  6/18	Loss 118.4420 (118.6360)
2022-11-26 18:54:37,555:INFO: Dataset: zara2               Batch:  7/18	Loss 116.4270 (118.2855)
2022-11-26 18:54:38,068:INFO: Dataset: zara2               Batch:  8/18	Loss 119.2357 (118.4132)
2022-11-26 18:54:38,582:INFO: Dataset: zara2               Batch:  9/18	Loss 117.9336 (118.3587)
2022-11-26 18:54:39,092:INFO: Dataset: zara2               Batch: 10/18	Loss 115.5502 (118.0820)
2022-11-26 18:54:39,605:INFO: Dataset: zara2               Batch: 11/18	Loss 115.5279 (117.8637)
2022-11-26 18:54:40,117:INFO: Dataset: zara2               Batch: 12/18	Loss 114.7605 (117.5973)
2022-11-26 18:54:40,714:INFO: Dataset: zara2               Batch: 13/18	Loss 115.0483 (117.3958)
2022-11-26 18:54:41,228:INFO: Dataset: zara2               Batch: 14/18	Loss 115.0191 (117.2227)
2022-11-26 18:54:41,743:INFO: Dataset: zara2               Batch: 15/18	Loss 118.1476 (117.2821)
2022-11-26 18:54:42,261:INFO: Dataset: zara2               Batch: 16/18	Loss 115.0810 (117.1439)
2022-11-26 18:54:42,773:INFO: Dataset: zara2               Batch: 17/18	Loss 114.1631 (116.9702)
2022-11-26 18:54:43,272:INFO: Dataset: zara2               Batch: 18/18	Loss 97.5607 (115.9563)
2022-11-26 18:54:43,331:INFO: - Computing ADE (validation)
2022-11-26 18:54:43,690:INFO: 		 ADE on hotel                     dataset:	 2.3154029846191406
2022-11-26 18:54:44,116:INFO: 		 ADE on univ                      dataset:	 2.8717844486236572
2022-11-26 18:54:44,461:INFO: 		 ADE on zara1                     dataset:	 2.1364848613739014
2022-11-26 18:54:45,004:INFO: 		 ADE on zara2                     dataset:	 2.534315347671509
2022-11-26 18:54:45,005:INFO: Average validation:	ADE  2.6748	FDE  4.0555
2022-11-26 18:54:45,005:INFO: - Computing ADE (validation o)
2022-11-26 18:54:45,305:INFO: 		 ADE on eth                       dataset:	 3.481579065322876
2022-11-26 18:54:45,305:INFO: Average validation o:	ADE  3.4816	FDE  6.0413
2022-11-26 18:54:45,314:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_273.pth.tar
2022-11-26 18:54:45,314:INFO: 
===> EPOCH: 274 (P3)
2022-11-26 18:54:45,314:INFO: - Computing loss (training)
2022-11-26 18:54:46,032:INFO: Dataset: hotel               Batch: 1/4	Loss 130.2823 (130.2823)
2022-11-26 18:54:46,531:INFO: Dataset: hotel               Batch: 2/4	Loss 141.6186 (135.9639)
2022-11-26 18:54:47,029:INFO: Dataset: hotel               Batch: 3/4	Loss 133.9635 (135.2753)
2022-11-26 18:54:47,470:INFO: Dataset: hotel               Batch: 4/4	Loss 78.1306 (126.5302)
2022-11-26 18:54:48,303:INFO: Dataset: univ                Batch:  1/15	Loss 115.1888 (115.1888)
2022-11-26 18:54:48,853:INFO: Dataset: univ                Batch:  2/15	Loss 115.4480 (115.3255)
2022-11-26 18:54:49,389:INFO: Dataset: univ                Batch:  3/15	Loss 118.0962 (116.1842)
2022-11-26 18:54:49,936:INFO: Dataset: univ                Batch:  4/15	Loss 114.5831 (115.7591)
2022-11-26 18:54:50,478:INFO: Dataset: univ                Batch:  5/15	Loss 116.5934 (115.9247)
2022-11-26 18:54:51,018:INFO: Dataset: univ                Batch:  6/15	Loss 115.5905 (115.8704)
2022-11-26 18:54:51,565:INFO: Dataset: univ                Batch:  7/15	Loss 117.0176 (116.0427)
2022-11-26 18:54:52,099:INFO: Dataset: univ                Batch:  8/15	Loss 116.0397 (116.0423)
2022-11-26 18:54:52,646:INFO: Dataset: univ                Batch:  9/15	Loss 113.1770 (115.7022)
2022-11-26 18:54:53,182:INFO: Dataset: univ                Batch: 10/15	Loss 114.2945 (115.5678)
2022-11-26 18:54:53,718:INFO: Dataset: univ                Batch: 11/15	Loss 113.1339 (115.3588)
2022-11-26 18:54:54,271:INFO: Dataset: univ                Batch: 12/15	Loss 112.6881 (115.1078)
2022-11-26 18:54:54,808:INFO: Dataset: univ                Batch: 13/15	Loss 114.1874 (115.0398)
2022-11-26 18:54:55,346:INFO: Dataset: univ                Batch: 14/15	Loss 112.2410 (114.8444)
2022-11-26 18:54:55,778:INFO: Dataset: univ                Batch: 15/15	Loss 20.9160 (113.7762)
2022-11-26 18:54:56,567:INFO: Dataset: zara1               Batch: 1/8	Loss 116.3048 (116.3048)
2022-11-26 18:54:57,087:INFO: Dataset: zara1               Batch: 2/8	Loss 115.1855 (115.7520)
2022-11-26 18:54:57,597:INFO: Dataset: zara1               Batch: 3/8	Loss 114.1376 (115.2595)
2022-11-26 18:54:58,113:INFO: Dataset: zara1               Batch: 4/8	Loss 111.4360 (114.2267)
2022-11-26 18:54:58,618:INFO: Dataset: zara1               Batch: 5/8	Loss 113.2201 (114.0277)
2022-11-26 18:54:59,126:INFO: Dataset: zara1               Batch: 6/8	Loss 113.1215 (113.8850)
2022-11-26 18:54:59,645:INFO: Dataset: zara1               Batch: 7/8	Loss 112.4826 (113.6622)
2022-11-26 18:55:00,143:INFO: Dataset: zara1               Batch: 8/8	Loss 96.6263 (111.9228)
2022-11-26 18:55:00,951:INFO: Dataset: zara2               Batch:  1/18	Loss 111.7583 (111.7583)
2022-11-26 18:55:01,468:INFO: Dataset: zara2               Batch:  2/18	Loss 112.1510 (111.9537)
2022-11-26 18:55:01,981:INFO: Dataset: zara2               Batch:  3/18	Loss 110.9190 (111.6099)
2022-11-26 18:55:02,508:INFO: Dataset: zara2               Batch:  4/18	Loss 111.0773 (111.4726)
2022-11-26 18:55:03,022:INFO: Dataset: zara2               Batch:  5/18	Loss 110.2363 (111.1956)
2022-11-26 18:55:03,540:INFO: Dataset: zara2               Batch:  6/18	Loss 110.9731 (111.1555)
2022-11-26 18:55:04,049:INFO: Dataset: zara2               Batch:  7/18	Loss 109.9674 (110.9846)
2022-11-26 18:55:04,561:INFO: Dataset: zara2               Batch:  8/18	Loss 110.3290 (110.9019)
2022-11-26 18:55:05,072:INFO: Dataset: zara2               Batch:  9/18	Loss 110.4011 (110.8457)
2022-11-26 18:55:05,582:INFO: Dataset: zara2               Batch: 10/18	Loss 110.5560 (110.8137)
2022-11-26 18:55:06,090:INFO: Dataset: zara2               Batch: 11/18	Loss 109.9122 (110.7179)
2022-11-26 18:55:06,607:INFO: Dataset: zara2               Batch: 12/18	Loss 110.6067 (110.7088)
2022-11-26 18:55:07,115:INFO: Dataset: zara2               Batch: 13/18	Loss 109.3273 (110.5952)
2022-11-26 18:55:07,628:INFO: Dataset: zara2               Batch: 14/18	Loss 109.4350 (110.5186)
2022-11-26 18:55:08,141:INFO: Dataset: zara2               Batch: 15/18	Loss 109.1934 (110.4374)
2022-11-26 18:55:08,652:INFO: Dataset: zara2               Batch: 16/18	Loss 109.2387 (110.3610)
2022-11-26 18:55:09,165:INFO: Dataset: zara2               Batch: 17/18	Loss 111.2190 (110.4112)
2022-11-26 18:55:09,663:INFO: Dataset: zara2               Batch: 18/18	Loss 94.5701 (109.6151)
2022-11-26 18:55:09,721:INFO: - Computing ADE (validation)
2022-11-26 18:55:10,071:INFO: 		 ADE on hotel                     dataset:	 2.1946322917938232
2022-11-26 18:55:10,507:INFO: 		 ADE on univ                      dataset:	 2.925509214401245
2022-11-26 18:55:10,854:INFO: 		 ADE on zara1                     dataset:	 2.2121541500091553
2022-11-26 18:55:11,398:INFO: 		 ADE on zara2                     dataset:	 2.4017457962036133
2022-11-26 18:55:11,399:INFO: Average validation:	ADE  2.6519	FDE  3.9483
2022-11-26 18:55:11,399:INFO: - Computing ADE (validation o)
2022-11-26 18:55:11,698:INFO: 		 ADE on eth                       dataset:	 3.2117514610290527
2022-11-26 18:55:11,698:INFO: Average validation o:	ADE  3.2118	FDE  5.3294
2022-11-26 18:55:11,706:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_274.pth.tar
2022-11-26 18:55:11,707:INFO: 
===> EPOCH: 275 (P3)
2022-11-26 18:55:11,707:INFO: - Computing loss (training)
2022-11-26 18:55:12,436:INFO: Dataset: hotel               Batch: 1/4	Loss 130.3279 (130.3279)
2022-11-26 18:55:12,947:INFO: Dataset: hotel               Batch: 2/4	Loss 122.2373 (126.4035)
2022-11-26 18:55:13,550:INFO: Dataset: hotel               Batch: 3/4	Loss 131.4154 (127.9712)
2022-11-26 18:55:13,998:INFO: Dataset: hotel               Batch: 4/4	Loss 71.1314 (118.5979)
2022-11-26 18:55:14,833:INFO: Dataset: univ                Batch:  1/15	Loss 120.1601 (120.1601)
2022-11-26 18:55:15,363:INFO: Dataset: univ                Batch:  2/15	Loss 128.3641 (124.0368)
2022-11-26 18:55:15,914:INFO: Dataset: univ                Batch:  3/15	Loss 115.3507 (121.0500)
2022-11-26 18:55:16,448:INFO: Dataset: univ                Batch:  4/15	Loss 114.7517 (119.5716)
2022-11-26 18:55:16,994:INFO: Dataset: univ                Batch:  5/15	Loss 111.3685 (117.7611)
2022-11-26 18:55:17,540:INFO: Dataset: univ                Batch:  6/15	Loss 110.9334 (116.5731)
2022-11-26 18:55:18,074:INFO: Dataset: univ                Batch:  7/15	Loss 109.7027 (115.6011)
2022-11-26 18:55:18,607:INFO: Dataset: univ                Batch:  8/15	Loss 111.6533 (115.1288)
2022-11-26 18:55:19,142:INFO: Dataset: univ                Batch:  9/15	Loss 108.7140 (114.4171)
2022-11-26 18:55:19,666:INFO: Dataset: univ                Batch: 10/15	Loss 110.2018 (114.0689)
2022-11-26 18:55:20,202:INFO: Dataset: univ                Batch: 11/15	Loss 110.4584 (113.7311)
2022-11-26 18:55:20,739:INFO: Dataset: univ                Batch: 12/15	Loss 109.4733 (113.3772)
2022-11-26 18:55:21,279:INFO: Dataset: univ                Batch: 13/15	Loss 110.2722 (113.1286)
2022-11-26 18:55:21,815:INFO: Dataset: univ                Batch: 14/15	Loss 111.1152 (112.9917)
2022-11-26 18:55:22,254:INFO: Dataset: univ                Batch: 15/15	Loss 20.2984 (111.5685)
2022-11-26 18:55:23,073:INFO: Dataset: zara1               Batch: 1/8	Loss 110.3644 (110.3644)
2022-11-26 18:55:23,576:INFO: Dataset: zara1               Batch: 2/8	Loss 110.5709 (110.4654)
2022-11-26 18:55:24,082:INFO: Dataset: zara1               Batch: 3/8	Loss 109.6603 (110.2030)
2022-11-26 18:55:24,588:INFO: Dataset: zara1               Batch: 4/8	Loss 111.3483 (110.4699)
2022-11-26 18:55:25,094:INFO: Dataset: zara1               Batch: 5/8	Loss 110.2350 (110.4232)
2022-11-26 18:55:25,598:INFO: Dataset: zara1               Batch: 6/8	Loss 110.4485 (110.4268)
2022-11-26 18:55:26,104:INFO: Dataset: zara1               Batch: 7/8	Loss 109.9033 (110.3543)
2022-11-26 18:55:26,592:INFO: Dataset: zara1               Batch: 8/8	Loss 93.5613 (108.5601)
2022-11-26 18:55:27,388:INFO: Dataset: zara2               Batch:  1/18	Loss 110.9347 (110.9347)
2022-11-26 18:55:27,896:INFO: Dataset: zara2               Batch:  2/18	Loss 110.2856 (110.6215)
2022-11-26 18:55:28,408:INFO: Dataset: zara2               Batch:  3/18	Loss 109.5773 (110.2994)
2022-11-26 18:55:28,922:INFO: Dataset: zara2               Batch:  4/18	Loss 109.8086 (110.1813)
2022-11-26 18:55:29,428:INFO: Dataset: zara2               Batch:  5/18	Loss 109.6616 (110.0758)
2022-11-26 18:55:29,940:INFO: Dataset: zara2               Batch:  6/18	Loss 108.6401 (109.8557)
2022-11-26 18:55:30,448:INFO: Dataset: zara2               Batch:  7/18	Loss 109.0359 (109.7415)
2022-11-26 18:55:30,963:INFO: Dataset: zara2               Batch:  8/18	Loss 107.9833 (109.5287)
2022-11-26 18:55:31,470:INFO: Dataset: zara2               Batch:  9/18	Loss 108.1160 (109.3819)
2022-11-26 18:55:31,977:INFO: Dataset: zara2               Batch: 10/18	Loss 107.2062 (109.1823)
2022-11-26 18:55:32,485:INFO: Dataset: zara2               Batch: 11/18	Loss 107.0998 (108.9935)
2022-11-26 18:55:32,991:INFO: Dataset: zara2               Batch: 12/18	Loss 107.9118 (108.9073)
2022-11-26 18:55:33,496:INFO: Dataset: zara2               Batch: 13/18	Loss 107.9136 (108.8250)
2022-11-26 18:55:34,002:INFO: Dataset: zara2               Batch: 14/18	Loss 107.1531 (108.7019)
2022-11-26 18:55:34,510:INFO: Dataset: zara2               Batch: 15/18	Loss 108.3230 (108.6775)
2022-11-26 18:55:35,019:INFO: Dataset: zara2               Batch: 16/18	Loss 108.2868 (108.6558)
2022-11-26 18:55:35,528:INFO: Dataset: zara2               Batch: 17/18	Loss 107.4229 (108.5843)
2022-11-26 18:55:36,024:INFO: Dataset: zara2               Batch: 18/18	Loss 93.3431 (107.8234)
2022-11-26 18:55:36,083:INFO: - Computing ADE (validation)
2022-11-26 18:55:36,437:INFO: 		 ADE on hotel                     dataset:	 2.312376022338867
2022-11-26 18:55:36,876:INFO: 		 ADE on univ                      dataset:	 2.7774713039398193
2022-11-26 18:55:37,230:INFO: 		 ADE on zara1                     dataset:	 2.3504884243011475
2022-11-26 18:55:37,766:INFO: 		 ADE on zara2                     dataset:	 2.3960368633270264
2022-11-26 18:55:37,766:INFO: Average validation:	ADE  2.5873	FDE  3.6616
2022-11-26 18:55:37,767:INFO: - Computing ADE (validation o)
2022-11-26 18:55:38,057:INFO: 		 ADE on eth                       dataset:	 2.99013090133667
2022-11-26 18:55:38,058:INFO: Average validation o:	ADE  2.9901	FDE  4.5777
2022-11-26 18:55:38,066:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_275.pth.tar
2022-11-26 18:55:38,066:INFO: 
===> EPOCH: 276 (P3)
2022-11-26 18:55:38,067:INFO: - Computing loss (training)
2022-11-26 18:55:38,787:INFO: Dataset: hotel               Batch: 1/4	Loss 120.3786 (120.3786)
2022-11-26 18:55:39,289:INFO: Dataset: hotel               Batch: 2/4	Loss 118.1318 (119.2446)
2022-11-26 18:55:39,785:INFO: Dataset: hotel               Batch: 3/4	Loss 119.4902 (119.3230)
2022-11-26 18:55:40,249:INFO: Dataset: hotel               Batch: 4/4	Loss 67.7067 (110.1301)
2022-11-26 18:55:41,065:INFO: Dataset: univ                Batch:  1/15	Loss 108.4060 (108.4060)
2022-11-26 18:55:41,604:INFO: Dataset: univ                Batch:  2/15	Loss 108.3443 (108.3751)
2022-11-26 18:55:42,139:INFO: Dataset: univ                Batch:  3/15	Loss 109.3418 (108.6919)
2022-11-26 18:55:42,752:INFO: Dataset: univ                Batch:  4/15	Loss 110.2439 (109.0497)
2022-11-26 18:55:43,301:INFO: Dataset: univ                Batch:  5/15	Loss 107.4191 (108.6825)
2022-11-26 18:55:43,839:INFO: Dataset: univ                Batch:  6/15	Loss 109.1397 (108.7599)
2022-11-26 18:55:44,374:INFO: Dataset: univ                Batch:  7/15	Loss 109.3552 (108.8455)
2022-11-26 18:55:44,919:INFO: Dataset: univ                Batch:  8/15	Loss 107.3155 (108.6340)
2022-11-26 18:55:45,463:INFO: Dataset: univ                Batch:  9/15	Loss 106.7533 (108.4036)
2022-11-26 18:55:45,994:INFO: Dataset: univ                Batch: 10/15	Loss 115.3675 (109.0450)
2022-11-26 18:55:46,537:INFO: Dataset: univ                Batch: 11/15	Loss 106.8195 (108.8358)
2022-11-26 18:55:47,077:INFO: Dataset: univ                Batch: 12/15	Loss 106.8852 (108.6686)
2022-11-26 18:55:47,614:INFO: Dataset: univ                Batch: 13/15	Loss 107.0347 (108.5409)
2022-11-26 18:55:48,138:INFO: Dataset: univ                Batch: 14/15	Loss 112.6595 (108.7842)
2022-11-26 18:55:48,576:INFO: Dataset: univ                Batch: 15/15	Loss 20.0125 (107.5432)
2022-11-26 18:55:49,356:INFO: Dataset: zara1               Batch: 1/8	Loss 107.4733 (107.4733)
2022-11-26 18:55:49,852:INFO: Dataset: zara1               Batch: 2/8	Loss 108.4042 (107.9691)
2022-11-26 18:55:50,360:INFO: Dataset: zara1               Batch: 3/8	Loss 108.0248 (107.9907)
2022-11-26 18:55:50,859:INFO: Dataset: zara1               Batch: 4/8	Loss 108.3447 (108.0749)
2022-11-26 18:55:51,362:INFO: Dataset: zara1               Batch: 5/8	Loss 107.4576 (107.9504)
2022-11-26 18:55:51,873:INFO: Dataset: zara1               Batch: 6/8	Loss 108.1009 (107.9771)
2022-11-26 18:55:52,369:INFO: Dataset: zara1               Batch: 7/8	Loss 110.1703 (108.2859)
2022-11-26 18:55:52,852:INFO: Dataset: zara1               Batch: 8/8	Loss 93.6743 (106.6710)
2022-11-26 18:55:53,653:INFO: Dataset: zara2               Batch:  1/18	Loss 107.1210 (107.1210)
2022-11-26 18:55:54,165:INFO: Dataset: zara2               Batch:  2/18	Loss 107.3122 (107.2197)
2022-11-26 18:55:54,679:INFO: Dataset: zara2               Batch:  3/18	Loss 107.5314 (107.3199)
2022-11-26 18:55:55,192:INFO: Dataset: zara2               Batch:  4/18	Loss 107.1997 (107.2924)
2022-11-26 18:55:55,703:INFO: Dataset: zara2               Batch:  5/18	Loss 109.0187 (107.6474)
2022-11-26 18:55:56,220:INFO: Dataset: zara2               Batch:  6/18	Loss 106.4469 (107.4515)
2022-11-26 18:55:56,730:INFO: Dataset: zara2               Batch:  7/18	Loss 110.2322 (107.8497)
2022-11-26 18:55:57,243:INFO: Dataset: zara2               Batch:  8/18	Loss 106.1037 (107.6310)
2022-11-26 18:55:57,755:INFO: Dataset: zara2               Batch:  9/18	Loss 106.7062 (107.5321)
2022-11-26 18:55:58,264:INFO: Dataset: zara2               Batch: 10/18	Loss 106.5936 (107.4359)
2022-11-26 18:55:58,776:INFO: Dataset: zara2               Batch: 11/18	Loss 111.2721 (107.7737)
2022-11-26 18:55:59,288:INFO: Dataset: zara2               Batch: 12/18	Loss 106.7828 (107.6879)
2022-11-26 18:55:59,799:INFO: Dataset: zara2               Batch: 13/18	Loss 105.5519 (107.5248)
2022-11-26 18:56:00,314:INFO: Dataset: zara2               Batch: 14/18	Loss 105.7422 (107.3959)
2022-11-26 18:56:00,831:INFO: Dataset: zara2               Batch: 15/18	Loss 105.6254 (107.2714)
2022-11-26 18:56:01,345:INFO: Dataset: zara2               Batch: 16/18	Loss 106.2255 (107.2080)
2022-11-26 18:56:01,856:INFO: Dataset: zara2               Batch: 17/18	Loss 106.3187 (107.1578)
2022-11-26 18:56:02,354:INFO: Dataset: zara2               Batch: 18/18	Loss 90.4107 (106.3023)
2022-11-26 18:56:02,412:INFO: - Computing ADE (validation)
2022-11-26 18:56:02,772:INFO: 		 ADE on hotel                     dataset:	 2.0155482292175293
2022-11-26 18:56:03,206:INFO: 		 ADE on univ                      dataset:	 2.671027660369873
2022-11-26 18:56:03,562:INFO: 		 ADE on zara1                     dataset:	 2.175051689147949
2022-11-26 18:56:04,103:INFO: 		 ADE on zara2                     dataset:	 2.339928150177002
2022-11-26 18:56:04,103:INFO: Average validation:	ADE  2.4848	FDE  3.5551
2022-11-26 18:56:04,104:INFO: - Computing ADE (validation o)
2022-11-26 18:56:04,396:INFO: 		 ADE on eth                       dataset:	 2.9755618572235107
2022-11-26 18:56:04,396:INFO: Average validation o:	ADE  2.9756	FDE  4.6679
2022-11-26 18:56:04,405:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_276.pth.tar
2022-11-26 18:56:04,406:INFO: 
===> EPOCH: 277 (P3)
2022-11-26 18:56:04,406:INFO: - Computing loss (training)
2022-11-26 18:56:05,129:INFO: Dataset: hotel               Batch: 1/4	Loss 111.3193 (111.3193)
2022-11-26 18:56:05,629:INFO: Dataset: hotel               Batch: 2/4	Loss 104.6090 (107.9642)
2022-11-26 18:56:06,124:INFO: Dataset: hotel               Batch: 3/4	Loss 115.9143 (110.4084)
2022-11-26 18:56:06,587:INFO: Dataset: hotel               Batch: 4/4	Loss 65.1479 (102.0489)
2022-11-26 18:56:07,446:INFO: Dataset: univ                Batch:  1/15	Loss 105.6075 (105.6075)
2022-11-26 18:56:07,981:INFO: Dataset: univ                Batch:  2/15	Loss 107.2121 (106.3618)
2022-11-26 18:56:08,534:INFO: Dataset: univ                Batch:  3/15	Loss 106.0208 (106.2333)
2022-11-26 18:56:09,072:INFO: Dataset: univ                Batch:  4/15	Loss 108.2385 (106.7350)
2022-11-26 18:56:09,606:INFO: Dataset: univ                Batch:  5/15	Loss 106.1852 (106.6344)
2022-11-26 18:56:10,148:INFO: Dataset: univ                Batch:  6/15	Loss 105.3959 (106.4325)
2022-11-26 18:56:10,696:INFO: Dataset: univ                Batch:  7/15	Loss 104.3371 (106.0978)
2022-11-26 18:56:11,234:INFO: Dataset: univ                Batch:  8/15	Loss 106.1653 (106.1061)
2022-11-26 18:56:11,776:INFO: Dataset: univ                Batch:  9/15	Loss 105.4528 (106.0337)
2022-11-26 18:56:12,314:INFO: Dataset: univ                Batch: 10/15	Loss 110.1448 (106.4320)
2022-11-26 18:56:12,866:INFO: Dataset: univ                Batch: 11/15	Loss 105.0403 (106.2918)
2022-11-26 18:56:13,499:INFO: Dataset: univ                Batch: 12/15	Loss 105.1103 (106.1880)
2022-11-26 18:56:14,032:INFO: Dataset: univ                Batch: 13/15	Loss 106.1200 (106.1833)
2022-11-26 18:56:14,577:INFO: Dataset: univ                Batch: 14/15	Loss 105.9018 (106.1626)
2022-11-26 18:56:15,023:INFO: Dataset: univ                Batch: 15/15	Loss 19.8972 (105.1119)
2022-11-26 18:56:15,813:INFO: Dataset: zara1               Batch: 1/8	Loss 106.0929 (106.0929)
2022-11-26 18:56:16,325:INFO: Dataset: zara1               Batch: 2/8	Loss 107.9530 (107.0172)
2022-11-26 18:56:16,832:INFO: Dataset: zara1               Batch: 3/8	Loss 107.4530 (107.1631)
2022-11-26 18:56:17,338:INFO: Dataset: zara1               Batch: 4/8	Loss 106.9056 (107.0991)
2022-11-26 18:56:17,839:INFO: Dataset: zara1               Batch: 5/8	Loss 105.8703 (106.8537)
2022-11-26 18:56:18,343:INFO: Dataset: zara1               Batch: 6/8	Loss 106.4274 (106.7813)
2022-11-26 18:56:18,843:INFO: Dataset: zara1               Batch: 7/8	Loss 106.0675 (106.6842)
2022-11-26 18:56:19,331:INFO: Dataset: zara1               Batch: 8/8	Loss 91.8341 (104.9881)
2022-11-26 18:56:20,133:INFO: Dataset: zara2               Batch:  1/18	Loss 105.3687 (105.3687)
2022-11-26 18:56:20,656:INFO: Dataset: zara2               Batch:  2/18	Loss 105.1743 (105.2683)
2022-11-26 18:56:21,187:INFO: Dataset: zara2               Batch:  3/18	Loss 105.7112 (105.4112)
2022-11-26 18:56:21,713:INFO: Dataset: zara2               Batch:  4/18	Loss 105.2595 (105.3745)
2022-11-26 18:56:22,239:INFO: Dataset: zara2               Batch:  5/18	Loss 105.2119 (105.3437)
2022-11-26 18:56:22,766:INFO: Dataset: zara2               Batch:  6/18	Loss 105.3100 (105.3381)
2022-11-26 18:56:23,287:INFO: Dataset: zara2               Batch:  7/18	Loss 104.5069 (105.2190)
2022-11-26 18:56:23,826:INFO: Dataset: zara2               Batch:  8/18	Loss 104.3385 (105.1099)
2022-11-26 18:56:24,373:INFO: Dataset: zara2               Batch:  9/18	Loss 104.0783 (104.9903)
2022-11-26 18:56:24,909:INFO: Dataset: zara2               Batch: 10/18	Loss 104.5968 (104.9486)
2022-11-26 18:56:25,434:INFO: Dataset: zara2               Batch: 11/18	Loss 104.4859 (104.9050)
2022-11-26 18:56:25,963:INFO: Dataset: zara2               Batch: 12/18	Loss 104.5985 (104.8781)
2022-11-26 18:56:26,483:INFO: Dataset: zara2               Batch: 13/18	Loss 105.4200 (104.9179)
2022-11-26 18:56:27,005:INFO: Dataset: zara2               Batch: 14/18	Loss 104.2746 (104.8725)
2022-11-26 18:56:27,530:INFO: Dataset: zara2               Batch: 15/18	Loss 104.3246 (104.8359)
2022-11-26 18:56:28,052:INFO: Dataset: zara2               Batch: 16/18	Loss 104.4359 (104.8108)
2022-11-26 18:56:28,573:INFO: Dataset: zara2               Batch: 17/18	Loss 104.2959 (104.7804)
2022-11-26 18:56:29,074:INFO: Dataset: zara2               Batch: 18/18	Loss 89.6361 (104.1646)
2022-11-26 18:56:29,132:INFO: - Computing ADE (validation)
2022-11-26 18:56:29,482:INFO: 		 ADE on hotel                     dataset:	 2.0590386390686035
2022-11-26 18:56:29,917:INFO: 		 ADE on univ                      dataset:	 2.593134641647339
2022-11-26 18:56:30,267:INFO: 		 ADE on zara1                     dataset:	 2.1964261531829834
2022-11-26 18:56:30,820:INFO: 		 ADE on zara2                     dataset:	 2.298607587814331
2022-11-26 18:56:30,820:INFO: Average validation:	ADE  2.4328	FDE  3.5100
2022-11-26 18:56:30,821:INFO: - Computing ADE (validation o)
2022-11-26 18:56:31,111:INFO: 		 ADE on eth                       dataset:	 2.8747928142547607
2022-11-26 18:56:31,111:INFO: Average validation o:	ADE  2.8748	FDE  4.6700
2022-11-26 18:56:31,119:INFO:  --> Model Saved in ./models/E1//P3/CRMF_epoch_277.pth.tar
2022-11-26 18:56:31,119:INFO: 
===> EPOCH: 278 (P3)
2022-11-26 18:56:31,120:INFO: - Computing loss (training)
2022-11-26 18:56:31,836:INFO: Dataset: hotel               Batch: 1/4	Loss 133.8802 (133.8802)
2022-11-26 18:56:32,339:INFO: Dataset: hotel               Batch: 2/4	Loss 104.0636 (118.6767)
2022-11-26 18:56:32,837:INFO: Dataset: hotel               Batch: 3/4	Loss 103.4009 (113.3228)
2022-11-26 18:56:33,297:INFO: Dataset: hotel               Batch: 4/4	Loss 62.7376 (104.2468)
2022-11-26 18:56:34,115:INFO: Dataset: univ                Batch:  1/15	Loss 104.8788 (104.8788)
2022-11-26 18:56:34,675:INFO: Dataset: univ                Batch:  2/15	Loss 103.9826 (104.4134)
2022-11-26 18:56:35,226:INFO: Dataset: univ                Batch:  3/15	Loss 104.5639 (104.4639)
2022-11-26 18:56:35,772:INFO: Dataset: univ                Batch:  4/15	Loss 105.4711 (104.7115)
2022-11-26 18:56:36,318:INFO: Dataset: univ                Batch:  5/15	Loss 105.3802 (104.8393)
2022-11-26 18:56:36,861:INFO: Dataset: univ                Batch:  6/15	Loss 104.5589 (104.7932)
2022-11-26 18:56:37,401:INFO: Dataset: univ                Batch:  7/15	Loss 105.9386 (104.9500)
2022-11-26 18:56:37,957:INFO: Dataset: univ                Batch:  8/15	Loss 103.8228 (104.7991)
2022-11-26 18:56:38,514:INFO: Dataset: univ                Batch:  9/15	Loss 103.2273 (104.6126)
2022-11-26 18:56:39,058:INFO: Dataset: univ                Batch: 10/15	Loss 106.9159 (104.8317)
2022-11-26 18:56:39,607:INFO: Dataset: univ                Batch: 11/15	Loss 104.0984 (104.7697)
2022-11-26 18:56:40,146:INFO: Dataset: univ                Batch: 12/15	Loss 103.7359 (104.6891)
2022-11-26 18:56:40,688:INFO: Dataset: univ                Batch: 13/15	Loss 103.5235 (104.6000)
2022-11-26 18:56:41,231:INFO: Dataset: univ                Batch: 14/15	Loss 103.5469 (104.5284)
2022-11-26 18:56:41,675:INFO: Dataset: univ                Batch: 15/15	Loss 19.3146 (103.4340)
2022-11-26 18:56:42,475:INFO: Dataset: zara1               Batch: 1/8	Loss 105.3341 (105.3341)
2022-11-26 18:56:42,977:INFO: Dataset: zara1               Batch: 2/8	Loss 105.4594 (105.4018)
2022-11-26 18:56:43,493:INFO: Dataset: zara1               Batch: 3/8	Loss 105.5588 (105.4613)
2022-11-26 18:56:43,996:INFO: Dataset: zara1               Batch: 4/8	Loss 105.1370 (105.3856)
2022-11-26 18:56:44,499:INFO: Dataset: zara1               Batch: 5/8	Loss 104.9441 (105.2962)
2022-11-26 18:56:45,004:INFO: Dataset: zara1               Batch: 6/8	Loss 105.2531 (105.2888)
2022-11-26 18:56:45,592:INFO: Dataset: zara1               Batch: 7/8	Loss 104.8164 (105.2194)
2022-11-26 18:56:46,081:INFO: Dataset: zara1               Batch: 8/8	Loss 89.7394 (103.5899)
2022-11-26 18:56:46,972:INFO: Dataset: zara2               Batch:  1/18	Loss 103.0630 (103.0630)
2022-11-26 18:56:47,497:INFO: Dataset: zara2               Batch:  2/18	Loss 103.6594 (103.3676)
2022-11-26 18:56:48,015:INFO: Dataset: zara2               Batch:  3/18	Loss 102.3168 (103.0061)
2022-11-26 18:56:48,539:INFO: Dataset: zara2               Batch:  4/18	Loss 103.2460 (103.0682)
2022-11-26 18:56:49,060:INFO: Dataset: zara2               Batch:  5/18	Loss 102.6447 (102.9864)
2022-11-26 18:56:49,583:INFO: Dataset: zara2               Batch:  6/18	Loss 103.3024 (103.0446)
2022-11-26 18:56:50,103:INFO: Dataset: zara2               Batch:  7/18	Loss 103.1501 (103.0600)
2022-11-26 18:56:50,692:INFO: Dataset: zara2               Batch:  8/18	Loss 103.2572 (103.0842)
2022-11-26 18:56:51,410:INFO: Dataset: zara2               Batch:  9/18	Loss 103.9978 (103.1897)
2022-11-26 18:56:51,931:INFO: Dataset: zara2               Batch: 10/18	Loss 103.1754 (103.1881)
