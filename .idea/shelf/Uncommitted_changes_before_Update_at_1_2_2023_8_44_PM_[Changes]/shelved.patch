Index: parser_file.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import argparse\r\nfrom utils import int_tuple\r\n\r\n\r\ndef get_parser():\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\"--log_dir\", default=\"./log/\", help=\"Directory containing logging file\")\r\n    parser.add_argument(\"--model_dir\", default=\"./models/E7/\", help=\"Directory containing logging file\")\r\n    parser.add_argument(\"--tfdir\", default='./runs/E7/', type=str)\r\n    parser.add_argument(\"--dataset_name\", default=\"v4\", type=str)\r\n    parser.add_argument(\"--model_name\", default=\"mlp\", type=str)\r\n    parser.add_argument(\"--resume\", default=\"\",\r\n                        type=str, metavar=\"PATH\", help=\"path to latest checkpoint (default: none)\")\r\n\r\n    # randomness\r\n    parser.add_argument(\"--num_samples\", type=int, default=10, help=\"Number of samples to calculate MC expectations\")\r\n    parser.add_argument(\"--seed\", type=int, default=1, help=\"Random seed\")\r\n\r\n    # computation\r\n    parser.add_argument(\"--gpu_num\", default=\"1\", type=str)\r\n    parser.add_argument(\"--loader_num_workers\", default=6, type=int)\r\n\r\n    # architecture (STGAT)\r\n    parser.add_argument(\"--traj_lstm_hidden_size\", default=32, type=int)\r\n    parser.add_argument(\"--hidden-units\", type=str, default=\"16\",\r\n                        help=\"Hidden units in each hidden layer, splitted with comma\")\r\n    parser.add_argument(\"--graph_lstm_hidden_size\", default=32, type=int)\r\n    parser.add_argument(\"--heads\", type=str, default=\"4,1\", help=\"Heads in each layer, splitted with comma\")\r\n    parser.add_argument(\"--graph_network_out_dims\", type=int, default=32,\r\n                        help=\"dims of every node after through GAT module\")\r\n    parser.add_argument(\"--dropout\", type=float, default=0, help=\"Dropout rate (1 - keep probability)\")\r\n    parser.add_argument(\"--alpha\", type=float, default=0.2, help=\"Alpha for the leaky_relu\")\r\n    parser.add_argument('--teachingratio', default=0.0, type=float,\r\n                        help=\"The probability of using ground truth future trajectories instead of model predictions during training\")\r\n\r\n    # dataset\r\n    parser.add_argument(\"--obs_len\", default=8, type=int)\r\n    parser.add_argument(\"--fut_len\", default=12, type=int)\r\n    parser.add_argument(\"--n_coordinates\", type=int, default=2, help=\"Number of coordinates\")\r\n    parser.add_argument(\"--filter_envs\", type=str, default=\"0.1-0.3-0.5\",\r\n                        help=\"Filter only certain environments (i.e 0.1-0.3-0.5)\")\r\n    parser.add_argument(\"--skip\", default=1, type=int)\r\n    parser.add_argument(\"--delim\", default=\"\\t\")\r\n    parser.add_argument(\"--finetune_ratio\", default=0.1, type=float, help=\"Number of batches to be used in finetuning\")\r\n    parser.add_argument(\"--batch_method\", default='het', type=str,\r\n                        help='Use Homogeneous (hom), Heterogeneous (het) or alternated homogeneous (alt) batches during training')\r\n    parser.add_argument(\"--contrastive\", default=False, type=bool, help='add contrastive loss')\r\n    parser.add_argument(\"--decoupled_loss\", default=True, type=bool, help='decouple ELBO from y')\r\n\r\n    parser.add_argument(\"--batch_size\", default='64', type=str)\r\n    parser.add_argument(\"--shuffle\", default=True, type=bool)\r\n    parser.add_argument('--reduce', default=0, type=int)\r\n    parser.add_argument('--reduceall', default=9000, type=int)\r\n\r\n\r\n    # architecture (VE)\r\n    parser.add_argument(\"--z_dim\", type=int, default=2, help=\"Dimension of z latent variable\")\r\n    parser.add_argument(\"--s_dim\", type=int, default=2, help=\"Dimension of s latent variable\")\r\n    parser.add_argument(\"--num_envs\", default=3, type=int, help=\"Number of environments in the dataset\")\r\n\r\n    # spurious feature\r\n    parser.add_argument(\"--add_confidence\", default=False, type=bool)\r\n    parser.add_argument(\"--domain_shifts\", default='0', type=str,\r\n                        help='domain_shifts per environment: hotel,univ,zara1,zara2,eth')\r\n\r\n    return parser\r\n\r\n\r\ndef get_evaluation_parser():\r\n    parser = get_parser()\r\n    parser.add_argument(\"--dset_type\", default=\"test\", type=str)\r\n    parser.add_argument(\"--best_k\", default=20, type=int)\r\n    parser.add_argument('--metrics', type=str, default='accuracy', choices=['accuracy', 'collision', 'qualitative'],\r\n                        help='evaluate metrics')\r\n\r\n    return parser\r\n\r\n\r\ndef get_training_parser():\r\n    parser = get_parser()\r\n\r\n    # dataset\r\n    parser.add_argument(\"--filter_envs_pretrain\", type=str, default=\"\",\r\n                        help=\"Say which env were used during pretraining (for contrastive loss) (i.e 0.1-0.3-0.5)\")\r\n\r\n    # training\r\n    parser.add_argument(\"--best_k\", default=20, type=int)\r\n    parser.add_argument(\"--start-epoch\", default=1, type=int, metavar=\"N\",\r\n                        help=\"manual epoch number (useful on restarts)\")\r\n    parser.add_argument(\"--use_gpu\", default=1, type=int)\r\n\r\n    # general training\r\n    parser.add_argument(\"--finetune\", default=\"\", type=str)\r\n    parser.add_argument(\"--num_epochs\", default='50-20-20-1-20-100', type=lambda x: int_tuple(x, '-'))  # '150-100-150',\r\n\r\n    # learning rates\r\n    parser.add_argument(\"--lr_scheduler\", default=False, type=bool)  # '150-100-150',\r\n\r\n    parser.add_argument(\"--lrvar\", default=1e-3, type=float,\r\n                        help=\"initial learning rate for variant encoder optimizer\")\r\n    parser.add_argument('--lrinv', default=1e-3, type=float,\r\n                        help=\"initial learning rate for the invariant encoder optimizer\")\r\n    parser.add_argument('--lrfut', default=1e-3, type=float,\r\n                        help=\"initial learning rate for the future decoder optimizer\")\r\n    parser.add_argument('--lrpast', default=1e-3, type=float,\r\n                        help=\"initial learning rate for the past decoder optimizer\")\r\n    parser.add_argument('--lrmap', default=1e-3, type=float,\r\n                        help=\"initial learning rate for the regressor optimizer\")\r\n    parser.add_argument('--lrpar', default=1e-3, type=float,\r\n                        help=\"initial learning rate for the parameters optimizer\")\r\n\r\n    return parser\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/parser_file.py b/parser_file.py
--- a/parser_file.py	(revision 371096bbe8b6e74baaa7825a994810e279f663d8)
+++ b/parser_file.py	(date 1672608246275)
@@ -9,7 +9,7 @@
     parser.add_argument("--tfdir", default='./runs/E7/', type=str)
     parser.add_argument("--dataset_name", default="v4", type=str)
     parser.add_argument("--model_name", default="mlp", type=str)
-    parser.add_argument("--resume", default="",
+    parser.add_argument("--resume", default="./models/E9/P6/CRMF_epoch_351.pth.tar",
                         type=str, metavar="PATH", help="path to latest checkpoint (default: none)")
 
     # randomness
@@ -44,7 +44,7 @@
     parser.add_argument("--finetune_ratio", default=0.1, type=float, help="Number of batches to be used in finetuning")
     parser.add_argument("--batch_method", default='het', type=str,
                         help='Use Homogeneous (hom), Heterogeneous (het) or alternated homogeneous (alt) batches during training')
-    parser.add_argument("--contrastive", default=False, type=bool, help='add contrastive loss')
+    parser.add_argument("--contrastive", default=True, type=bool, help='add contrastive loss')
     parser.add_argument("--decoupled_loss", default=True, type=bool, help='decouple ELBO from y')
 
     parser.add_argument("--batch_size", default='64', type=str)
Index: models.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nimport random\r\nfrom utils import *\r\nimport math\r\nfrom torch.distributions import MultivariateNormal, Categorical\r\nfrom sklearn.mixture import GaussianMixture as GMM\r\n\r\n\r\ndef get_noise(shape, noise_type):\r\n    if noise_type == \"gaussian\":\r\n        return torch.randn(*shape).cuda()\r\n    elif noise_type == \"uniform\":\r\n        return torch.rand(*shape).sub_(0.5).mul_(2.0).cuda()\r\n    raise ValueError('Unrecognized noise type \"%s\"' % noise_type)\r\n\r\n\r\nclass CouplingLayer(nn.Module):\r\n    \"\"\"Coupling layer in RealNVP.\r\n    Args:\r\n        in_channels (int): Number of channels in the input.\r\n        mid_channels (int): Number of channels in the `s` and `t` network.\r\n        num_blocks (int): Number of residual blocks in the `s` and `t` network.\r\n        mask_type (MaskType): One of `MaskType.CHECKERBOARD` or `MaskType.CHANNEL_WISE`.\r\n        reverse_mask (bool): Whether to reverse the mask. Useful for alternating masks.\r\n    \"\"\"\r\n\r\n    def __init__(self, latent_dim, reverse_mask, hidden_dims=None):\r\n        super(CouplingLayer, self).__init__()\r\n        # Save mask info\r\n        self.reverse_mask = reverse_mask\r\n\r\n        # Build scale and translate network\r\n        if hidden_dims is None:\r\n            hidden_dims = [8]\r\n\r\n        modules = []\r\n        in_channels = latent_dim // 2\r\n        for h_dim in hidden_dims:\r\n            modules.append(\r\n                nn.Sequential(\r\n                    nn.Linear(in_channels, h_dim),\r\n                    nn.LeakyReLU())\r\n            )\r\n            in_channels = h_dim\r\n\r\n        modules.append(nn.Linear(hidden_dims[-1], latent_dim))\r\n        self.st_net = nn.Sequential(*modules)\r\n\r\n        # Learnable scale for s\r\n        self.rescale = nn.utils.weight_norm(Rescale(latent_dim // 2))\r\n\r\n    def forward(self, x, sldj=None, reverse=False):\r\n        # Channel-wise mask\r\n        if self.reverse_mask:\r\n            x_id, x_change = x.chunk(2, dim=2)\r\n        else:\r\n            x_change, x_id = x.chunk(2, dim=2)\r\n\r\n        st = self.st_net(x_id)\r\n        s, t = st.chunk(2, dim=2)\r\n        s = self.rescale(torch.tanh(s))\r\n\r\n        # Scale and translate\r\n        if reverse:\r\n            inv_exp_s = s.mul(-1).exp()\r\n            if torch.isnan(inv_exp_s).any():\r\n                raise RuntimeError('Scale factor has NaN entries')\r\n            x_change = x_change * inv_exp_s - t\r\n        else:\r\n            exp_s = s.exp()\r\n            if torch.isnan(exp_s).any():\r\n                raise RuntimeError('Scale factor has NaN entries')\r\n            x_change = (x_change + t) * exp_s\r\n\r\n            # Add log-determinant of the Jacobian\r\n            sldj += s.view(s.size(0), s.size(1), -1).sum(-1)\r\n\r\n        if self.reverse_mask:\r\n            x = torch.cat((x_id, x_change), dim=2)\r\n        else:\r\n            x = torch.cat((x_change, x_id), dim=2)\r\n\r\n        return x, sldj\r\n\r\n\r\nclass Rescale(nn.Module):\r\n    \"\"\"Per-channel rescaling. Need a proper `nn.Module` so we can wrap it\r\n    with `torch.nn.utils.weight_norm`.\r\n    Args:\r\n        num_channels (int): Number of channels in the input.\r\n    \"\"\"\r\n\r\n    def __init__(self, num_channels):\r\n        super(Rescale, self).__init__()\r\n        self.weight = nn.Parameter(torch.ones(num_channels))\r\n\r\n    def forward(self, x):\r\n        x = self.weight * x\r\n        return x\r\n\r\n\r\nclass BatchMultiHeadGraphAttention(nn.Module):\r\n    def __init__(self, n_head, f_in, f_out, attn_dropout, bias=True):\r\n        super(BatchMultiHeadGraphAttention, self).__init__()\r\n        self.n_head = n_head\r\n        self.f_in = f_in\r\n        self.f_out = f_out\r\n        self.w = nn.Parameter(torch.Tensor(n_head, f_in, f_out))\r\n        self.a_src = nn.Parameter(torch.Tensor(n_head, f_out, 1))\r\n        self.a_dst = nn.Parameter(torch.Tensor(n_head, f_out, 1))\r\n\r\n        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\r\n        self.softmax = nn.Softmax(dim=-1)\r\n        self.dropout = nn.Dropout(attn_dropout)\r\n        if bias:\r\n            self.bias = nn.Parameter(torch.Tensor(f_out))\r\n            nn.init.constant_(self.bias, 0)\r\n        else:\r\n            self.register_parameter(\"bias\", None)\r\n\r\n        nn.init.xavier_uniform_(self.w, gain=1.414)\r\n        nn.init.xavier_uniform_(self.a_src, gain=1.414)\r\n        nn.init.xavier_uniform_(self.a_dst, gain=1.414)\r\n\r\n    def forward(self, h):\r\n        bs, n = h.size()[:2]\r\n        h_prime = torch.matmul(h.unsqueeze(1), self.w)\r\n        attn_src = torch.matmul(h_prime, self.a_src)\r\n        attn_dst = torch.matmul(h_prime, self.a_dst)\r\n        attn = attn_src.expand(-1, -1, -1, n) + attn_dst.expand(-1, -1, -1, n).permute(\r\n            0, 1, 3, 2\r\n        )\r\n        attn = self.leaky_relu(attn)\r\n        attn = self.softmax(attn)\r\n        attn = self.dropout(attn)\r\n        output = torch.matmul(attn, h_prime)\r\n        if self.bias is not None:\r\n            return output + self.bias, attn\r\n        else:\r\n            return output, attn\r\n\r\n    def __repr__(self):\r\n        return (\r\n                self.__class__.__name__\r\n                + \" (\"\r\n                + str(self.n_head)\r\n                + \" -> \"\r\n                + str(self.f_in)\r\n                + \" -> \"\r\n                + str(self.f_out)\r\n                + \")\"\r\n        )\r\n\r\n\r\nclass GAT(nn.Module):\r\n    def __init__(self, n_units, n_heads, dropout=0.2, alpha=0.2):\r\n        super(GAT, self).__init__()\r\n        self.n_layer = len(n_units) - 1\r\n        self.dropout = dropout\r\n        self.layer_stack = nn.ModuleList()\r\n\r\n        for i in range(self.n_layer):\r\n            f_in = n_units[i] * n_heads[i - 1] if i else n_units[i]\r\n            self.layer_stack.append(\r\n                BatchMultiHeadGraphAttention(\r\n                    n_heads[i], f_in=f_in, f_out=n_units[i + 1], attn_dropout=dropout\r\n                )\r\n            )\r\n\r\n        self.norm_list = [\r\n            torch.nn.InstanceNorm1d(32).cuda(),\r\n            torch.nn.InstanceNorm1d(64).cuda(),\r\n        ]\r\n\r\n    def forward(self, x):\r\n        bs, n = x.size()[:2]\r\n        for i, gat_layer in enumerate(self.layer_stack):\r\n            x = self.norm_list[i](x.permute(0, 2, 1)).permute(0, 2, 1)\r\n            x, attn = gat_layer(x)\r\n            if i + 1 == self.n_layer:\r\n                x = x.squeeze(dim=1)\r\n            else:\r\n                x = F.elu(x.transpose(1, 2).contiguous().view(bs, n, -1))\r\n                x = F.dropout(x, self.dropout, training=self.training)\r\n        else:\r\n            return x\r\n\r\n\r\nclass GATEncoder(nn.Module):\r\n    def __init__(self, n_units, n_heads, dropout, alpha):\r\n        super(GATEncoder, self).__init__()\r\n        self.gat_net = GAT(n_units, n_heads, dropout, alpha)\r\n\r\n    def forward(self, obs_traj_embedding, seq_start_end):\r\n        graph_embeded_data = []\r\n        for start, end in seq_start_end.data:\r\n            curr_seq_embedding_traj = obs_traj_embedding[:, start:end, :]\r\n            curr_seq_graph_embedding = self.gat_net(curr_seq_embedding_traj)\r\n            graph_embeded_data.append(curr_seq_graph_embedding)\r\n        graph_embeded_data = torch.cat(graph_embeded_data, dim=1)\r\n        return graph_embeded_data\r\n\r\n\r\nclass LSTMCell(nn.Module):\r\n    def __init__(self, input_size, hidden_size):\r\n        super(LSTMCell, self).__init__()\r\n        self.input_size = input_size\r\n        self.hidden_size = hidden_size\r\n        self.weight_ih = nn.Parameter(torch.randn(4 * hidden_size, input_size))\r\n        self.weight_hh = nn.Parameter(torch.randn(4 * hidden_size, hidden_size))\r\n        self.bias_ih = nn.Parameter(torch.randn(4 * hidden_size))\r\n        self.bias_hh = nn.Parameter(torch.randn(4 * hidden_size))\r\n\r\n    def forward(self, input, state):\r\n        hx, cx = state\r\n        gates = (torch.mm(input, self.weight_ih.t()) + self.bias_ih + torch.mm(hx, self.weight_hh.t()) + self.bias_hh)\r\n        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\r\n\r\n        ingate = F.hardsigmoid(ingate)\r\n        forgetgate = F.hardsigmoid(forgetgate)\r\n        cellgate = F.hardtanh(cellgate)\r\n        outgate = F.hardsigmoid(outgate)\r\n\r\n        cy = (forgetgate * cx) + (ingate * cellgate)\r\n        hy = outgate * F.hardtanh(cy)\r\n\r\n        return hy, cy\r\n\r\n\r\nclass Encoder(nn.Module):\r\n    def __init__(\r\n            self,\r\n            obs_len,\r\n            fut_len,\r\n            n_coordinates,\r\n            traj_lstm_hidden_size,\r\n            n_units,\r\n            n_heads,\r\n            graph_network_out_dims,\r\n            dropout,\r\n            alpha,\r\n            graph_lstm_hidden_size,\r\n            add_confidence=True,\r\n    ):\r\n        super(Encoder, self).__init__()\r\n\r\n        self.obs_len = obs_len\r\n        self.fut_len = fut_len\r\n\r\n        self.gatencoder = GATEncoder(\r\n            n_units=n_units, n_heads=n_heads, dropout=dropout, alpha=alpha\r\n        )\r\n\r\n        self.graph_lstm_hidden_size = graph_lstm_hidden_size\r\n        self.traj_lstm_hidden_size = traj_lstm_hidden_size\r\n        self.n_coordinates = n_coordinates\r\n        self.add_confidence = add_confidence\r\n\r\n        self.traj_lstm_model = LSTMCell(\r\n            n_coordinates + add_confidence,\r\n            traj_lstm_hidden_size\r\n        )\r\n        self.graph_lstm_model = LSTMCell(\r\n            graph_network_out_dims,\r\n            graph_lstm_hidden_size\r\n        )\r\n\r\n        self.traj_hidden2pos = nn.Linear(\r\n            traj_lstm_hidden_size,\r\n            n_coordinates\r\n        )\r\n        self.traj_gat_hidden2pos = nn.Linear(\r\n            traj_lstm_hidden_size + graph_lstm_hidden_size,\r\n            n_coordinates\r\n        )\r\n\r\n        self._initialize_weights()\r\n\r\n    def _initialize_weights(self):\r\n        for m in self.modules():\r\n            if isinstance(m, nn.LSTMCell):\r\n                m.weight_hh.data.normal_(0, 0.1)\r\n                m.weight_ih.data.normal_(0, 0.1)\r\n                m.bias_hh.data.zero_()\r\n                m.bias_ih.data.zero_()\r\n            elif isinstance(m, nn.Linear):\r\n                m.weight.data.normal_(0, 0.1)\r\n                m.bias.data.zero_()\r\n\r\n    def init_hidden_traj_lstm(self, batch):\r\n        return (\r\n            torch.randn(batch, self.traj_lstm_hidden_size).cuda(),\r\n            torch.randn(batch, self.traj_lstm_hidden_size).cuda(),\r\n        )\r\n\r\n    def init_hidden_graph_lstm(self, batch):\r\n        return (\r\n            torch.randn(batch, self.graph_lstm_hidden_size).cuda(),\r\n            torch.randn(batch, self.graph_lstm_hidden_size).cuda(),\r\n        )\r\n\r\n    def forward(\r\n            self,\r\n            obs_traj_rel,\r\n            seq_start_end,\r\n            training_step=3,\r\n    ):\r\n\r\n        num_peds = obs_traj_rel.shape[1]\r\n        traj_lstm_h_t, traj_lstm_c_t = self.init_hidden_traj_lstm(num_peds)\r\n        graph_lstm_h_t, graph_lstm_c_t = self.init_hidden_graph_lstm(num_peds)\r\n        pred_traj_rel = []\r\n        traj_lstm_hidden_states = []\r\n        graph_lstm_hidden_states = []\r\n\r\n        # traj_lstm (used in step 1,2,3)\r\n        for i in range(self.obs_len):\r\n            traj_lstm_h_t, traj_lstm_c_t = self.traj_lstm_model(\r\n                obs_traj_rel[i], (traj_lstm_h_t, traj_lstm_c_t)\r\n            )\r\n            if training_step == \"P1\":\r\n                output = self.traj_hidden2pos(traj_lstm_h_t)\r\n                pred_traj_rel += [output]\r\n            else:\r\n                traj_lstm_hidden_states += [traj_lstm_h_t]\r\n\r\n        # graph_lstm (used in step 2,3)\r\n        if training_step != \"P1\":\r\n            graph_lstm_input = self.gatencoder(\r\n                torch.stack(traj_lstm_hidden_states), seq_start_end\r\n            )\r\n            for i in range(self.obs_len):\r\n                graph_lstm_h_t, graph_lstm_c_t = self.graph_lstm_model(\r\n                    graph_lstm_input[i], (graph_lstm_h_t, graph_lstm_c_t)\r\n                )\r\n                if training_step == \"P2\":\r\n                    encoded_before_noise_hidden = torch.cat(\r\n                        (traj_lstm_hidden_states[i], graph_lstm_h_t), dim=1\r\n                    )\r\n                    output = self.traj_gat_hidden2pos(encoded_before_noise_hidden)\r\n                    pred_traj_rel += [output]\r\n                else:\r\n                    graph_lstm_hidden_states += [graph_lstm_h_t]\r\n\r\n        if training_step in [\"P1\", \"P2\"]:\r\n            return torch.stack(pred_traj_rel)\r\n\r\n        else:\r\n            encoded_before_noise_hidden = torch.cat((traj_lstm_hidden_states[-1], graph_lstm_hidden_states[-1]), dim=1)\r\n\r\n            return encoded_before_noise_hidden\r\n\r\n\r\nclass Predictor(nn.Module):\r\n    def __init__(\r\n            self,\r\n            obs_len,\r\n            fut_len,\r\n            n_coordinates,\r\n            s_dim,\r\n            z_dim,\r\n            teacher_forcing_ratio=0.5,\r\n            hidden_dims=None,\r\n            noise_dim=(8,),\r\n            noise_type=\"gaussian\",\r\n    ):\r\n        super(Predictor, self).__init__()\r\n\r\n        # if hidden_dims is None:\r\n        #     hidden_dims = [8]\r\n        #\r\n        # modules = []\r\n        # in_channels = s_dim + z_dim\r\n        # for h_dim in hidden_dims:\r\n        #     modules.append(\r\n        #         nn.Sequential(\r\n        #             nn.Linear(in_channels, h_dim),\r\n        #             nn.LeakyReLU())\r\n        #     )\r\n        #     in_channels = h_dim\r\n        #\r\n        # modules.append(nn.Linear(hidden_dims[-1], s_dim + z_dim))\r\n        #\r\n        # self.mapping = nn.Sequential(*modules)\r\n\r\n        self.obs_len = obs_len\r\n        self.fut_len = fut_len\r\n        self.teacher_forcing_ratio = teacher_forcing_ratio\r\n\r\n        self.n_coordinates = n_coordinates\r\n        self.pred_lstm_hidden_size = z_dim + s_dim\r\n        self.pred_hidden2pos = nn.Linear(self.pred_lstm_hidden_size, n_coordinates)\r\n        self.pred_lstm_model = LSTMCell(n_coordinates, self.pred_lstm_hidden_size)\r\n        self.noise_dim = noise_dim\r\n        self.noise_type = noise_type\r\n\r\n        self._initialize_weights()\r\n\r\n    def _initialize_weights(self):\r\n        for m in self.modules():\r\n            if isinstance(m, nn.LSTMCell):\r\n                m.weight_hh.data.normal_(0, 0.1)\r\n                m.weight_ih.data.normal_(0, 0.1)\r\n                m.bias_hh.data.zero_()\r\n                m.bias_ih.data.zero_()\r\n            elif isinstance(m, nn.Linear):\r\n                m.weight.data.normal_(0, 0.1)\r\n                m.bias.data.zero_()\r\n\r\n    def add_noise(self, _input, seq_start_end):\r\n        noise_shape = (seq_start_end.size(0),) + self.noise_dim\r\n        z_decoder = get_noise(noise_shape, self.noise_type)\r\n\r\n        _list = []\r\n        for idx, (start, end) in enumerate(seq_start_end):\r\n            start = start.item()\r\n            end = end.item()\r\n            _vec = z_decoder[idx].view(1, -1)\r\n            _to_cat = _vec.repeat(_input.shape[0], end - start, 1)\r\n            _list_cat = torch.cat([_input[:, start:end, :], _to_cat], dim=2)\r\n            _list.append(_list_cat)\r\n        decoder_h = torch.cat(_list, dim=1)\r\n\r\n        return decoder_h\r\n\r\n    def forward(\r\n            self,\r\n            obs_traj_rel,\r\n            fut_traj_rel,\r\n            seq_start_end,\r\n            pred_lstm_hidden,\r\n    ):\r\n\r\n        input_t = obs_traj_rel[self.obs_len - 1, :, :self.n_coordinates].repeat(len(pred_lstm_hidden), 1, 1)\r\n        output = input_t\r\n        # pred_lstm_hidden = self.mapping(pred_lstm_hidden)\r\n        # pred_lstm_hidden = self.add_noise(pred_lstm_hidden, seq_start_end)\r\n        pred_lstm_c_t = torch.zeros_like(pred_lstm_hidden).cuda()\r\n        pred_q_rel = []\r\n        if self.training:\r\n            for i in range(self.fut_len):\r\n                if i >= 1:\r\n                    teacher_force = random.random() < self.teacher_forcing_ratio\r\n                    if teacher_force:\r\n                        input_t = fut_traj_rel[i - 1, :, :self.n_coordinates]  # with teacher help\r\n                    else:\r\n                        input_t = output\r\n\r\n                # average over s and z\r\n                output = []\r\n                pred_lstm_hidden_list, pred_lstm_c_t_list = [], []\r\n                for j in range(len(pred_lstm_hidden)):\r\n                    h, c = self.pred_lstm_model(input_t[j], (pred_lstm_hidden[j], pred_lstm_c_t[j]))\r\n                    pred_lstm_hidden_list += [h]\r\n                    pred_lstm_c_t_list += [c]\r\n                    output += [self.pred_hidden2pos(h)]\r\n\r\n                pred_lstm_hidden = torch.stack(pred_lstm_hidden_list)\r\n                pred_lstm_c_t = torch.stack(pred_lstm_c_t_list)\r\n                output = torch.stack(output)\r\n                pred_q_rel += [output]\r\n\r\n            return torch.stack(pred_q_rel)\r\n\r\n        else:\r\n            pred_traj_rel = []\r\n            for i in range(self.fut_len):\r\n                input_t = output\r\n\r\n                # average over s and z\r\n                output = []\r\n                pred_lstm_hidden_list, pred_lstm_c_t_list = [], []\r\n                for j in range(len(pred_lstm_hidden)):\r\n                    h, c = self.pred_lstm_model(input_t[j], (pred_lstm_hidden[j], pred_lstm_c_t[j]))\r\n                    pred_lstm_hidden_list += [h]\r\n                    pred_lstm_c_t_list += [c]\r\n                    output += [self.pred_hidden2pos(h)]\r\n\r\n                pred_lstm_hidden = torch.stack(pred_lstm_hidden_list)\r\n                pred_lstm_c_t = torch.stack(pred_lstm_c_t_list)\r\n                output = torch.stack(output)\r\n                pred_traj_rel += [output]\r\n\r\n            return torch.stack(pred_traj_rel)\r\n\r\n\r\nclass Decoder(nn.Module):\r\n    def __init__(\r\n            self,\r\n            obs_len,\r\n            n_coordinates,\r\n            z_dim,\r\n            s_dim,\r\n            hidden_dims=None,\r\n            var_p=0.5\r\n    ):\r\n        super(Decoder, self).__init__()\r\n\r\n        # if hidden_dims is None:\r\n        #     hidden_dims = [8]\r\n        #\r\n        # modules = []\r\n        # in_channels = s_dim + z_dim\r\n        # for h_dim in hidden_dims:\r\n        #     modules.append(\r\n        #         nn.Sequential(\r\n        #             nn.Linear(in_channels, h_dim),\r\n        #             nn.LeakyReLU())\r\n        #     )\r\n        #     in_channels = h_dim\r\n        #\r\n        # modules.append(nn.Linear(hidden_dims[-1], s_dim + z_dim))\r\n        # self.mapping = nn.Sequential(*modules)\r\n\r\n        self.obs_len = obs_len\r\n        self.n_coordinates = n_coordinates\r\n        self.pred_lstm_hidden_size = z_dim + s_dim\r\n        self.pred_hidden2pos = nn.Linear(self.pred_lstm_hidden_size, n_coordinates)\r\n        self.pred_lstm_model = LSTMCell(n_coordinates, self.pred_lstm_hidden_size)\r\n\r\n        self._initialize_weights()\r\n\r\n    def _initialize_weights(self):\r\n        for m in self.modules():\r\n            if isinstance(m, nn.LSTMCell):\r\n                m.weight_hh.data.normal_(0, 0.1)\r\n                m.weight_ih.data.normal_(0, 0.1)\r\n                m.bias_hh.data.zero_()\r\n                m.bias_ih.data.zero_()\r\n            elif isinstance(m, nn.Linear):\r\n                m.weight.data.normal_(0, 0.1)\r\n                m.bias.data.zero_()\r\n\r\n    def forward(\r\n            self,\r\n            obs_traj_rel,\r\n            pred_lstm_hidden,\r\n    ):\r\n\r\n        pred_traj_rel = []\r\n        # pred_lstm_hidden = self.mapping(pred_lstm_hidden)\r\n        pred_lstm_c_t = torch.zeros_like(pred_lstm_hidden).cuda()\r\n        for i in range(self.obs_len):\r\n            if i >= 1:\r\n                input_t = obs_traj_rel[i - 1, :, :self.n_coordinates].repeat(len(pred_lstm_hidden), 1, 1)\r\n            else:\r\n                input_t = obs_traj_rel[0, :, :self.n_coordinates].repeat(len(pred_lstm_hidden), 1, 1)\r\n\r\n            # average over s and z\r\n            output = []\r\n            pred_lstm_hidden_list, pred_lstm_c_t_list = [], []\r\n            for j in range(len(pred_lstm_hidden)):\r\n                h, c = self.pred_lstm_model(input_t[j], (pred_lstm_hidden[j], pred_lstm_c_t[j]))\r\n                pred_lstm_hidden_list += [h]\r\n                pred_lstm_c_t_list += [c]\r\n                output += [self.pred_hidden2pos(h)]\r\n\r\n            pred_lstm_hidden = torch.stack(pred_lstm_hidden_list)\r\n            pred_lstm_c_t = torch.stack(pred_lstm_c_t_list)\r\n            output = torch.stack(output)\r\n            pred_traj_rel += [output]\r\n\r\n        return torch.stack(pred_traj_rel)\r\n\r\n\r\nclass Mapping(nn.Module):\r\n    def __init__(self,\r\n                 traj_lstm_hidden_size: int,\r\n                 graph_lstm_hidden_size: int,\r\n                 s_dim: int,\r\n                 hidden_dims=None,\r\n                 **kwargs) -> None:\r\n        super(Mapping, self).__init__()\r\n\r\n        if hidden_dims is None:\r\n            hidden_dims = [8]\r\n\r\n        modules = []\r\n        in_channels = traj_lstm_hidden_size + graph_lstm_hidden_size\r\n        for h_dim in hidden_dims:\r\n            modules.append(\r\n                nn.Sequential(\r\n                    nn.Linear(in_channels, h_dim),\r\n                    nn.LeakyReLU())\r\n            )\r\n            in_channels = h_dim\r\n\r\n        self.mapping = nn.Sequential(*modules)\r\n\r\n        self.s_dim = s_dim\r\n        self.fc_mu = nn.Linear(hidden_dims[-1], s_dim)\r\n        self.fc_logvar = nn.Linear(hidden_dims[-1], s_dim)\r\n\r\n        self._initialize_weights()\r\n\r\n    def _initialize_weights(self):\r\n        for m in self.modules():\r\n            if isinstance(m, nn.LSTMCell):\r\n                m.weight_hh.data.normal_(0, 0.1)\r\n                m.weight_ih.data.normal_(0, 0.1)\r\n                m.bias_hh.data.zero_()\r\n                m.bias_ih.data.zero_()\r\n            elif isinstance(m, nn.Linear):\r\n                m.weight.data.normal_(0, 0.1)\r\n                m.bias.data.zero_()\r\n\r\n    def forward(self, hidden_states, mode=\"normal\"):\r\n        if mode == \"normal\":\r\n            s_vec = self.fc_mu(self.mapping(hidden_states))\r\n\r\n            return s_vec\r\n        else:\r\n            mu = self.fc_mu(self.mapping(hidden_states))\r\n            logvar = self.fc_logvar(self.mapping(hidden_states))\r\n            ps = MultivariateNormal(mu, torch.diag_embed(torch.exp(logvar)))\r\n\r\n            return ps\r\n\r\n\r\nclass SimpleStyleEncoder(nn.Module):\r\n    def __init__(self, hidden_size):\r\n        super(SimpleStyleEncoder, self).__init__()\r\n\r\n        # style encoder\r\n        self.encoder = nn.Sequential(\r\n            nn.Linear(40, hidden_size * 4),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_size * 4, hidden_size * 2)\r\n        )\r\n\r\n    def forward(self, style_input):\r\n        # for batch size 68\r\n        # style 20 x 128 x 2\r\n        style_input = torch.stack(style_input.split(2, dim=1), dim=1)[:, :, 1, :]  # 20 x 64 x 2\r\n        style_input = torch.permute(style_input, (1, 0, 2))  # 64 x 20 x 2\r\n        style_input = torch.flatten(style_input, 1)  # 64 x 40\r\n\r\n        # MLP\r\n        style_seq = self.encoder(style_input)\r\n        encoded = torch.stack(style_seq.split(style_seq.shape[1] // 2, dim=1), dim=1)\r\n        encoded = encoded.flatten(start_dim=0, end_dim=1)\r\n\r\n        return encoded\r\n\r\n\r\nclass SimpleEncoder(nn.Module):\r\n    def __init__(\r\n            self,\r\n            obs_len,\r\n            hidden_size,\r\n            number_agents,\r\n            add_confidence,\r\n    ):\r\n        super(SimpleEncoder, self).__init__()\r\n\r\n        # num of frames per sequence\r\n        self.obs_len = obs_len\r\n        self.number_agents = number_agents\r\n\r\n        self.mlp = nn.Sequential(\r\n            nn.Linear(obs_len * number_agents * (2 + add_confidence), hidden_size * 4),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_size * 4, hidden_size * 4),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_size * 4, hidden_size * number_agents),\r\n        )\r\n\r\n        self.mu = nn.Linear(hidden_size, hidden_size)\r\n        self.logvar = nn.Linear(hidden_size, hidden_size)\r\n\r\n    def forward(self, obs_traj_rel):\r\n        splits = obs_traj_rel.split(self.number_agents, dim=1)\r\n        if splits[-1].shape[1] != splits[0].shape[1]:\r\n            splits = splits[:-1]\r\n        obs_traj_rel = torch.stack(splits, dim=1)\r\n        obs_traj_rel = torch.permute(obs_traj_rel, (1, 2, 0, 3))\r\n        obs_traj_rel = obs_traj_rel.flatten(start_dim=1)\r\n\r\n        encoded = self.mlp(obs_traj_rel)\r\n\r\n        encoded = torch.stack(encoded.split(encoded.shape[1] // self.number_agents, dim=1), dim=1)\r\n        encoded = encoded.flatten(start_dim=0, end_dim=1)\r\n\r\n        return encoded\r\n\r\n\r\nclass SimpleDecoder(nn.Module):\r\n    def __init__(\r\n            self,\r\n            seq_len,\r\n            hidden_size,\r\n            number_of_agents,\r\n    ):\r\n        super(SimpleDecoder, self).__init__()\r\n\r\n        # num of frames per sequence\r\n        self.seq_len = seq_len\r\n\r\n        self.noise_fixed = False\r\n\r\n        self.mlp = nn.Sequential(\r\n            nn.Linear(hidden_size * number_of_agents, hidden_size * 4),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_size * 4, hidden_size * 8),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_size * 8, hidden_size * 16),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_size * 16, hidden_size * 32),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_size * 32, 2 * seq_len * number_of_agents)\r\n        )\r\n\r\n        self.number_of_agents = number_of_agents\r\n\r\n    def forward(self, latent_space):\r\n        traj_lstm_hidden_state = torch.stack(latent_space.split(self.number_of_agents, dim=1), dim=1)\r\n        out = traj_lstm_hidden_state.flatten(start_dim=2)\r\n\r\n        out = self.mlp(out)\r\n\r\n        out = torch.reshape(out, (out.shape[0], out.shape[1], self.number_of_agents, self.seq_len, 2))\r\n\r\n        out = out.flatten(start_dim=1, end_dim=2)\r\n\r\n        out = torch.permute(out, (2, 0, 1, 3))\r\n\r\n        return out\r\n\r\n\r\nclass CRMF(nn.Module):\r\n    def __init__(self, args):\r\n        super(CRMF, self).__init__()\r\n\r\n        if args.best_k == 1 and args.decoupled_loss:\r\n            raise ValueError(\"best_k must be greater than one in decoupled loss\")\r\n\r\n        self.dataset_name = args.dataset_name\r\n        self.model_name = args.model_name\r\n        self.obs_len = args.obs_len\r\n        self.z_dim = args.z_dim\r\n        self.fut_len = args.fut_len\r\n        self.num_samples = args.num_samples\r\n        self.n_coordinates = args.n_coordinates\r\n        self.contrastive = args.contrastive\r\n        self.decoupled_loss = args.decoupled_loss\r\n        self.best_k = args.best_k\r\n\r\n        self.num_envs = args.num_envs\r\n        self.pi_priore = nn.Parameter(-1 * torch.ones(args.num_envs))\r\n        self.logvar_priors = nn.Parameter(torch.randn(args.num_envs, args.s_dim))\r\n        self.mean_priors = nn.Parameter(torch.zeros(args.num_envs, args.s_dim))\r\n        self.gmm = GMM(n_components=args.num_envs, covariance_type='diag')\r\n        self.beta_scheduler = get_beta(0, 1500, 1000)\r\n        self.iter = 1\r\n\r\n        self.coupling_layers_z = nn.ModuleList([\r\n            CouplingLayer(args.z_dim, reverse_mask=False),\r\n            CouplingLayer(args.z_dim, reverse_mask=True),\r\n            CouplingLayer(args.z_dim, reverse_mask=False)\r\n        ])\r\n\r\n        self.coupling_layers_s = nn.ModuleList([\r\n            CouplingLayer(args.s_dim, reverse_mask=False),\r\n            CouplingLayer(args.s_dim, reverse_mask=True),\r\n            CouplingLayer(args.s_dim, reverse_mask=False)\r\n        ])\r\n\r\n        self.pw = MultivariateNormal(torch.zeros(args.z_dim).cuda(), torch.diag(torch.ones(args.z_dim).cuda()))\r\n\r\n        self.ps = []\r\n        for i in range(self.num_envs):\r\n            self.ps += [MultivariateNormal(i * torch.ones(args.s_dim).cuda(),\r\n                                           torch.diag((i + 1) * torch.ones(args.s_dim).cuda()))]\r\n\r\n        self.x_to_z = Mapping(2, 0, args.z_dim)\r\n        self.x_to_s = Mapping(2, 0, args.s_dim)\r\n        self.cont_classifier = nn.Sequential(nn.Linear(args.s_dim, 32),\r\n                                             nn.ReLU(),\r\n                                             nn.Linear(32, 8),\r\n                                             )\r\n\r\n        if args.model_name == \"lstm\":\r\n\r\n            self.variant_encoder = Encoder(args.obs_len, args.fut_len, args.n_coordinates,\r\n                                           args.traj_lstm_hidden_size, args.n_units, args.n_heads,\r\n                                           args.graph_network_out_dims, args.dropout, args.alpha,\r\n                                           args.graph_lstm_hidden_size, args.add_confidence)\r\n\r\n            self.invariant_encoder = Encoder(args.obs_len, args.fut_len, args.n_coordinates,\r\n                                             args.traj_lstm_hidden_size, args.n_units, args.n_heads,\r\n                                             args.graph_network_out_dims, args.dropout, args.alpha,\r\n                                             args.graph_lstm_hidden_size, args.add_confidence)\r\n\r\n            self.past_decoder = Decoder(args.obs_len, args.n_coordinates, args.z_dim, args.s_dim)\r\n\r\n            self.future_decoder = Predictor(args.obs_len, args.fut_len, args.n_coordinates, args.s_dim,\r\n                                            args.z_dim, args.teachingratio)\r\n\r\n        elif args.model_name == \"mlp\":\r\n            self.variant_encoder = SimpleEncoder(args.obs_len, 2,\r\n                                                 NUMBER_PERSONS, args.add_confidence)\r\n\r\n            self.invariant_encoder = SimpleEncoder(args.obs_len, 2,\r\n                                                   NUMBER_PERSONS, args.add_confidence)\r\n\r\n            self.past_decoder = Decoder(args.obs_len, args.n_coordinates, args.z_dim, args.s_dim)\r\n\r\n            self.future_decoder = Predictor(args.obs_len, args.fut_len, args.n_coordinates, args.s_dim,\r\n                                            args.z_dim, args.teachingratio)\r\n\r\n            # self.past_decoder = SimpleDecoder(\r\n            #     args.obs_len,\r\n            #     args.s_dim,\r\n            #     NUMBER_PERSONS,\r\n            # )\r\n            #\r\n            # self.future_decoder = SimpleDecoder(\r\n            #     args.fut_len,\r\n            #     args.s_dim,\r\n            #     NUMBER_PERSONS,\r\n            # )\r\n\r\n        else:\r\n            raise ValueError('Unrecognized model name \"%s\"' % args.model_name)\r\n\r\n    def forward(self, batch, training_step, **kwargs):\r\n        if self.dataset_name in ('eth', 'hotel', 'univ', 'zara1', 'zara2'):\r\n            obs_traj, fut_traj, obs_traj_rel, fut_traj_rel, seq_start_end, = batch\r\n\r\n        elif 'synthetic' in self.dataset_name or self.dataset_name in ['synthetic', 'v2', 'v2full', 'v4']:\r\n            obs_traj, fut_traj, obs_traj_rel, fut_traj_rel, seq_start_end, augm_data, seq_start_end_augm = batch\r\n        else:\r\n            raise ValueError('Unrecognized dataset name \"%s\"' % self.dataset_name)\r\n\r\n        if self.training:\r\n            if training_step in [\"P1\", \"P2\"]:\r\n                pred_past_rel1 = self.variant_encoder(obs_traj_rel, seq_start_end, training_step)\r\n                pred_past_rel2 = self.invariant_encoder(obs_traj_rel, seq_start_end, training_step)\r\n\r\n                return pred_past_rel1, pred_past_rel2\r\n\r\n            elif training_step == \"P3\":\r\n                if self.model_name == \"lstm\":\r\n                    z_vec = self.x_to_z(self.invariant_encoder(obs_traj_rel, seq_start_end, training_step),\r\n                                        mode=\"normal\")\r\n                    s_vec = self.x_to_s(self.variant_encoder(obs_traj_rel, seq_start_end, training_step), mode=\"normal\")\r\n                else:\r\n                    z_vec = self.x_to_z(self.invariant_encoder(obs_traj_rel), mode=\"normal\")\r\n                    s_vec = self.x_to_s(self.variant_encoder(obs_traj_rel), mode=\"normal\")\r\n\r\n                if self.model_name == \"lstm\":\r\n                    pred_past_rel = self.past_decoder(obs_traj_rel, torch.cat((z_vec, s_vec), dim=1))\r\n                elif self.model_name == \"mlp\":\r\n                    # pred_past_rel = self.past_decoder(torch.cat((z_vec.unsqueeze(0), s_vec.unsqueeze(0)), dim=2)).squeeze(1)\r\n                    pred_past_rel= self.past_decoder(obs_traj_rel, torch.cat((z_vec, s_vec), dim=1))\r\n\r\n                if self.model_name == \"lstm\":\r\n                    pred_fut_rel = self.future_decoder(obs_traj_rel, fut_traj_rel, seq_start_end,\r\n                                                       torch.cat((z_vec, s_vec), dim=1))\r\n                if self.model_name == \"mlp\":\r\n                    pred_fut_rel= self.future_decoder(obs_traj_rel, fut_traj_rel, seq_start_end,\r\n                                                       torch.cat((z_vec, s_vec), dim=1))\r\n\r\n                return pred_past_rel, pred_fut_rel\r\n\r\n            elif training_step == \"P4\":\r\n                if self.model_name == \"lstm\":\r\n                    s_vec = self.x_to_s(self.variant_encoder(obs_traj_rel, seq_start_end, training_step), mode=\"normal\")\r\n                else:\r\n                    s_vec = self.x_to_s(self.variant_encoder(obs_traj_rel), mode=\"normal\")\r\n\r\n                return s_vec\r\n\r\n            else:\r\n                pe = Categorical(logits=self.pi_priore)\r\n                if self.model_name == \"lstm\":\r\n                    q_zgx = self.x_to_z(self.invariant_encoder(obs_traj_rel, seq_start_end, training_step),\r\n                                        mode=\"variational\")\r\n                    q_sgx = self.x_to_s(self.variant_encoder(obs_traj_rel, seq_start_end, training_step),\r\n                                        mode=\"variational\")\r\n                elif self.model_name == \"mlp\":\r\n                    q_zgx = self.x_to_z(self.invariant_encoder(obs_traj_rel), mode=\"variational\")\r\n                    q_sgx = self.x_to_s(self.variant_encoder(obs_traj_rel), mode=\"variational\")\r\n\r\n                s_vec = q_sgx.rsample([self.num_samples, ])\r\n                z_vec = q_zgx.rsample([self.num_samples, ])\r\n\r\n                sldj = torch.zeros((self.num_samples, z_vec.shape[1]), device=z_vec.device)\r\n                s_vec_c = s_vec\r\n                for coupling in self.coupling_layers_s:\r\n                    s_vec_c, sldj = coupling(s_vec_c, sldj)\r\n\r\n                # calculate p(s|e)\r\n                Et = []\r\n                for j in range(self.num_envs):\r\n                    psge = self.ps[j]\r\n                    log_psge = psge.log_prob(s_vec_c)\r\n                    log_pe = pe.log_prob(torch.tensor(j).cuda())\r\n                    Et.append(torch.exp(log_psge) * torch.exp(log_pe))\r\n\r\n                log_ps = torch.log(torch.stack(Et).sum(0) + 1e-16) + sldj\r\n                log_ps_zeros = torch.zeros_like(log_ps, device=log_ps.device)\r\n                if log_ps.mean() == torch.tensor(- math.inf):\r\n                    log_ps = log_ps_zeros\r\n\r\n                # calculate log(q(z|x))\r\n                log_qzgx = q_zgx.log_prob(z_vec)\r\n\r\n                # calculate log(q(s|x))\r\n                log_qsgx = q_sgx.log_prob(s_vec)\r\n\r\n                # calculate log(p(z))\r\n                sldj = torch.zeros((self.num_samples, z_vec.shape[1]), device=z_vec.device)\r\n                z_vec_c = z_vec\r\n                for coupling in self.coupling_layers_z:\r\n                    z_vec_c, sldj = coupling(z_vec_c, sldj)\r\n                log_pz = self.pw.log_prob(z_vec_c) + sldj\r\n\r\n                # calculate log(p(x|z,s))\r\n                if self.model_name == \"lstm\":\r\n                    px = self.past_decoder(obs_traj_rel, torch.cat((z_vec, s_vec), dim=2))\r\n                elif self.model_name == \"mlp\":\r\n                    px = self.past_decoder(obs_traj_rel, torch.cat((z_vec, s_vec), dim=2))\r\n\r\n                log_px = - l2_loss(px, obs_traj_rel, mode=\"raw\") - 0.5 * 2 * self.obs_len * torch.log(\r\n                    torch.tensor(2 * math.pi)) - 0.5 * self.obs_len * torch.log(torch.tensor(0.25))\r\n\r\n                if self.decoupled_loss:\r\n                    s_vec = q_sgx.rsample([self.best_k, ])\r\n                    z_vec = q_zgx.rsample([self.best_k, ])\r\n\r\n                    # calculate q(y|x)\r\n                    if self.model_name == \"lstm\":\r\n                        py = self.future_decoder(obs_traj_rel, fut_traj_rel, seq_start_end,\r\n                                                 torch.cat((z_vec, s_vec), dim=2))\r\n                    if self.model_name == \"mlp\":\r\n                        py = self.future_decoder(obs_traj_rel, fut_traj_rel, seq_start_end,\r\n                                                 torch.cat((z_vec, s_vec), dim=2))\r\n\r\n                    log_py = py\r\n                else:\r\n\r\n                    # calculate q(y|x)\r\n                    if self.model_name == \"lstm\":\r\n                        py = self.future_decoder(obs_traj_rel, fut_traj_rel, seq_start_end, torch.cat((z_vec, s_vec), dim=2))\r\n                    if self.model_name == \"mlp\":\r\n                        py = self.future_decoder(obs_traj_rel, fut_traj_rel, seq_start_end, torch.cat((z_vec, s_vec), dim=2))\r\n\r\n                    log_py = - l2_loss(py, fut_traj_rel, mode=\"raw\") - 0.5 * 2 * self.fut_len * torch.log(\r\n                        torch.tensor(2 * math.pi)) - 0.5 * self.fut_len * torch.log(torch.tensor(0.25))\r\n\r\n                if self.contrastive:\r\n                    low_dim = self.cont_classifier(s_vec)\r\n                    low_dim = F.normalize(low_dim, dim=2)\r\n                else:\r\n                    low_dim = None\r\n\r\n                if self.decoupled_loss:\r\n                    E1 = (log_px).mean(0)\r\n                    E2 = (log_ps - log_qsgx).mean(0)\r\n                    E3 = (log_pz - log_qzgx).mean(0)\r\n\r\n                else:\r\n                    E1 = torch.multiply(torch.exp(log_py), log_px).mean(0)\r\n                    E2 = torch.multiply(torch.exp(log_py), log_ps - log_qsgx).mean(0)\r\n                    E3 = torch.multiply(torch.exp(log_py), log_pz - log_qzgx).mean(0)\r\n\r\n                return log_py, E1, E2, E3, low_dim\r\n\r\n        else:\r\n            if training_step == \"P7\":\r\n                if self.model_name == \"lstm\":\r\n                    q_zgx = self.x_to_z(self.invariant_encoder(obs_traj_rel, seq_start_end, training_step),\r\n                                        mode=\"variational\")\r\n                    q_sgx = self.x_to_s(self.variant_encoder(obs_traj_rel, seq_start_end, training_step),\r\n                                        mode=\"variational\")\r\n                elif self.model_name == \"mlp\":\r\n                    q_zgx = self.x_to_z(self.invariant_encoder(obs_traj_rel), mode=\"variational\")\r\n                    q_sgx = self.x_to_s(self.variant_encoder(obs_traj_rel), mode=\"variational\")\r\n\r\n                return q_zgx, q_sgx\r\n\r\n            else:\r\n                if self.model_name == \"lstm\":\r\n                    q_zgx = self.x_to_z(self.invariant_encoder(obs_traj_rel, seq_start_end, training_step),\r\n                                        mode=\"variational\")\r\n                    q_sgx = self.x_to_s(self.variant_encoder(obs_traj_rel, seq_start_end, training_step),\r\n                                        mode=\"variational\")\r\n                elif self.model_name == \"mlp\":\r\n                    q_zgx = self.x_to_z(self.invariant_encoder(obs_traj_rel), mode=\"variational\")\r\n                    q_sgx = self.x_to_s(self.variant_encoder(obs_traj_rel), mode=\"variational\")\r\n\r\n                # calculate q(y|theta, x)\r\n                z_vec = q_zgx.rsample([self.num_samples, ])\r\n                s_vec = q_sgx.rsample([self.num_samples, ])\r\n                if self.model_name == \"lstm\":\r\n                    q = self.future_decoder(obs_traj_rel, fut_traj_rel, seq_start_end, torch.cat((z_vec, s_vec), dim=2))\r\n                elif self.model_name == \"mlp\":\r\n                    q = self.future_decoder(obs_traj_rel, fut_traj_rel, seq_start_end, torch.cat((z_vec, s_vec), dim=2))\r\n\r\n                return q[:, 0, :, :]\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/models.py b/models.py
--- a/models.py	(revision 371096bbe8b6e74baaa7825a994810e279f663d8)
+++ b/models.py	(date 1672708834671)
@@ -774,8 +774,8 @@
             self.ps += [MultivariateNormal(i * torch.ones(args.s_dim).cuda(),
                                            torch.diag((i + 1) * torch.ones(args.s_dim).cuda()))]
 
-        self.x_to_z = Mapping(2, 0, args.z_dim)
-        self.x_to_s = Mapping(2, 0, args.s_dim)
+        self.x_to_z = Mapping(args.traj_lstm_hidden_size, args.graph_lstm_hidden_size, args.z_dim)
+        self.x_to_s = Mapping(args.traj_lstm_hidden_size, args.graph_lstm_hidden_size, args.s_dim)
         self.cont_classifier = nn.Sequential(nn.Linear(args.s_dim, 32),
                                              nn.ReLU(),
                                              nn.Linear(32, 8),
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project version=\"4\">\r\n  <component name=\"ChangeListManager\">\r\n    <list default=\"true\" id=\"8147b731-440c-4981-a21f-e4c8b1f0cd9a\" name=\"Changes\" comment=\"Experiments\">\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/misc.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/misc.xml\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_11_17_2022_12_09_PM__Changes_.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_11_17_2022_12_09_PM__Changes_.xml\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_2022-11-18,_4_44_p_m__[Changes]1/shelved.patch\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_2022-11-18__4_44_p_m___Changes_.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_2022-11-18__4_44_p_m___Changes_.xml\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_2022-11-18__4_44_p_m___Changes_1.xml\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_11_9_2022_10_12_PM__Changes_.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_11_9_2022_10_12_PM__Changes_.xml\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/workspace.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/Tensorboard.ipynb\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/Tensorboard.ipynb\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/log/train.log\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/log/train.log\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/models.py\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E1/P4/CRMF_epoch_1188.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E1/P4/CRMF_epoch_401.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E1/P4/CRMF_epoch_402.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E1/P4/CRMF_epoch_403.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E1/P4/CRMF_epoch_404.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E1/P4/CRMF_epoch_405.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E1/P4/CRMF_epoch_406.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E1/P4/CRMF_epoch_407.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E1/P4/CRMF_epoch_408.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E1/P4/CRMF_epoch_409.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E1/P5/CRMF_epoch_1201.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E1/P5/CRMF_epoch_1202.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E3_joint/P4/CRMF_epoch_1200.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E3_joint/P5/CRMF_epoch_1301.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E3_joint/P6/CRMF_epoch_1497.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E3_joint_64dimension/P4/CRMF_epoch_1200.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E3_joint_64dimension/P5/CRMF_epoch_1400.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E3_joint_64dimension/P6/CRMF_epoch_1547.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E4_q/P3/CRMF_epoch_850.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/models/E4_q/P4/CRMF_epoch_1050.pth.tar\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/parser_file.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/parser_file.py\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-07-19 TensorBoard.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-07-27 TensorBoard.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-07-33 TensorBoard.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-07-39 TensorBoard.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-08-08 TensorBoard.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-08-13 TensorBoard.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-08-17 TensorBoard.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-08-25 TensorBoard.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E2_complex_beta_withoutz/events.out.tfevents.1668820224.zahra-ThinkPad-P15-Gen-2i.502147.0\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint/CRMF_risk_irm_5.0_batch_hom_data_eth_ds_0_bk_20_ep_(150, 100, 150, 800, 100, 50)_shuffle_true_seed_72/events.out.tfevents.1668906133.zahra-ThinkPad-P15-Gen-2i.775334.0\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint/CRMF_risk_irm_5.0_batch_hom_data_eth_ds_0_bk_20_ep_(150, 100, 150, 800, 100, 50)_shuffle_true_seed_72/events.out.tfevents.1668927818.zahra-ThinkPad-P15-Gen-2i.2542816.0\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint/ade.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint/adeo.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint/elbo.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint/hotel.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint/loss.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint/pred.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint/univ.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint/zara1.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint/zara2.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint_64_dimension/New Text Document.txt\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint_64_dimension/ade.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint_64_dimension/adeo.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint_64_dimension/e_loss.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint_64_dimension/elbo.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint_64_dimension/hotel.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint_64_dimension/pred.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint_64_dimension/univ.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint_64_dimension/zara1.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E3_joint_64_dimension/zara2.png\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/E4_q/CRMF_risk_irm_5.0_batch_hom_data_eth_ds_0_bk_20_ep_(150, 100, 300, 200, 100)_shuffle_true_seed_72/events.out.tfevents.1669430022.gra1184.184179.0\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/Ebeta_fixed_learning rate/events.out.tfevents.1668801034.zahra-ThinkPad-P15-Gen-2i.670101.0\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/Eonecycle_200/events.out.tfevents.1668747604.zahra-ThinkPad-P15-Gen-2i.3924938.0\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/Eonecycle_300/events.out.tfevents.1668791888.zahra-ThinkPad-P15-Gen-2i.5816.0\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/runs/~$Notes.docx\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/runs/~$Notes.docx\" afterDir=\"false\" />\r\n    </list>\r\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\r\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\r\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\r\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\r\n  </component>\r\n  <component name=\"FileTemplateManagerImpl\">\r\n    <option name=\"RECENT_TEMPLATES\">\r\n      <list>\r\n        <option value=\"Python Script\" />\r\n      </list>\r\n    </option>\r\n  </component>\r\n  <component name=\"Git.Settings\">\r\n    <option name=\"RECENT_BRANCH_BY_REPOSITORY\">\r\n      <map>\r\n        <entry key=\"$PROJECT_DIR$\" value=\"DT\" />\r\n      </map>\r\n    </option>\r\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\r\n  </component>\r\n  <component name=\"GithubProjectSettings\">\r\n    <option name=\"branchProtectionPatterns\">\r\n      <list>\r\n        <option value=\"master\" />\r\n      </list>\r\n    </option>\r\n  </component>\r\n  <component name=\"MarkdownSettingsMigration\">\r\n    <option name=\"stateVersion\" value=\"1\" />\r\n  </component>\r\n  <component name=\"ProjectId\" id=\"2HIAGvCj0b6BkQ5ayMuWDeDrSYY\" />\r\n  <component name=\"ProjectLevelVcsManager\" settingsEditedManually=\"true\" />\r\n  <component name=\"ProjectViewState\">\r\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\r\n    <option name=\"showLibraryContents\" value=\"true\" />\r\n  </component>\r\n  <component name=\"PropertiesComponent\">{\r\n  &quot;keyToString&quot;: {\r\n    &quot;RunOnceActivity.OpenProjectViewOnStart&quot;: &quot;true&quot;,\r\n    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,\r\n    &quot;WebServerToolWindowFactoryState&quot;: &quot;false&quot;,\r\n    &quot;last_opened_file_path&quot;: &quot;C:/UWaterloo/PhD_thesis/motion_forecasting/codes/causalmotion-main/style/train.py&quot;,\r\n    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,\r\n    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;\r\n  }\r\n}</component>\r\n  <component name=\"RunManager\" selected=\"Python.evaluate_model\">\r\n    <configuration name=\"distributions\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\r\n      <module name=\"CRMF\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <envs>\r\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\r\n      </envs>\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/distributions.py\" />\r\n      <option name=\"PARAMETERS\" value=\"\" />\r\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\r\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\r\n      <option name=\"MODULE_MODE\" value=\"false\" />\r\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\r\n      <option name=\"INPUT_FILE\" value=\"\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <configuration name=\"evaluate_model\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\r\n      <module name=\"CRMF\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <envs>\r\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\r\n      </envs>\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/evaluate_model.py\" />\r\n      <option name=\"PARAMETERS\" value=\"\" />\r\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\r\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\r\n      <option name=\"MODULE_MODE\" value=\"false\" />\r\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\r\n      <option name=\"INPUT_FILE\" value=\"\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <configuration name=\"invariance\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\r\n      <module name=\"CRMF\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <envs>\r\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\r\n      </envs>\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/invariance.py\" />\r\n      <option name=\"PARAMETERS\" value=\"\" />\r\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\r\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\r\n      <option name=\"MODULE_MODE\" value=\"false\" />\r\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\r\n      <option name=\"INPUT_FILE\" value=\"\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <configuration name=\"results\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\r\n      <module name=\"CRMF\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <envs>\r\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\r\n      </envs>\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/results.py\" />\r\n      <option name=\"PARAMETERS\" value=\"\" />\r\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\r\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\r\n      <option name=\"MODULE_MODE\" value=\"false\" />\r\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\r\n      <option name=\"INPUT_FILE\" value=\"\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <configuration name=\"train\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\r\n      <module name=\"CRMF\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <envs>\r\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\r\n      </envs>\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/train.py\" />\r\n      <option name=\"PARAMETERS\" value=\"\" />\r\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\r\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\r\n      <option name=\"MODULE_MODE\" value=\"false\" />\r\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\r\n      <option name=\"INPUT_FILE\" value=\"\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <recent_temporary>\r\n      <list>\r\n        <item itemvalue=\"Python.evaluate_model\" />\r\n        <item itemvalue=\"Python.train\" />\r\n        <item itemvalue=\"Python.results\" />\r\n        <item itemvalue=\"Python.invariance\" />\r\n        <item itemvalue=\"Python.distributions\" />\r\n      </list>\r\n    </recent_temporary>\r\n  </component>\r\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\r\n  <component name=\"TaskManager\">\r\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\r\n      <changelist id=\"8147b731-440c-4981-a21f-e4c8b1f0cd9a\" name=\"Changes\" comment=\"\" />\r\n      <created>1667962131599</created>\r\n      <option name=\"number\" value=\"Default\" />\r\n      <option name=\"presentableId\" value=\"Default\" />\r\n      <updated>1667962131599</updated>\r\n      <workItem from=\"1667962133126\" duration=\"3158000\" />\r\n      <workItem from=\"1667965423442\" duration=\"14042000\" />\r\n      <workItem from=\"1668103527142\" duration=\"9238000\" />\r\n      <workItem from=\"1668113554483\" duration=\"9483000\" />\r\n      <workItem from=\"1668188593721\" duration=\"24064000\" />\r\n      <workItem from=\"1668280011795\" duration=\"20838000\" />\r\n      <workItem from=\"1668361022894\" duration=\"18561000\" />\r\n      <workItem from=\"1668385121155\" duration=\"9013000\" />\r\n      <workItem from=\"1668443724873\" duration=\"34005000\" />\r\n      <workItem from=\"1668544348636\" duration=\"11075000\" />\r\n      <workItem from=\"1668887765193\" duration=\"21673000\" />\r\n      <workItem from=\"1668966972913\" duration=\"2639000\" />\r\n      <workItem from=\"1669137246838\" duration=\"7027000\" />\r\n      <workItem from=\"1672294286229\" duration=\"7812000\" />\r\n      <workItem from=\"1672383569433\" duration=\"8892000\" />\r\n      <workItem from=\"1672473343807\" duration=\"4883000\" />\r\n    </task>\r\n    <task id=\"LOCAL-00001\" summary=\"Finetune completed\">\r\n      <created>1667968720588</created>\r\n      <option name=\"number\" value=\"00001\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00001\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1667968720588</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00002\" summary=\"Finetune completed\">\r\n      <created>1668103730039</created>\r\n      <option name=\"number\" value=\"00002\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00002\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668103730039</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00003\" summary=\"Finetune completed\">\r\n      <created>1668104402694</created>\r\n      <option name=\"number\" value=\"00003\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00003\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668104402694</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00004\" summary=\"Finetune completed\">\r\n      <created>1668104584281</created>\r\n      <option name=\"number\" value=\"00004\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00004\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668104584281</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00005\" summary=\"Finetune completed\">\r\n      <created>1668113946515</created>\r\n      <option name=\"number\" value=\"00005\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00005\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668113946515</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00006\" summary=\"Finetune completed\">\r\n      <created>1668115250936</created>\r\n      <option name=\"number\" value=\"00006\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00006\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668115250936</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00007\" summary=\"Finetune completed\">\r\n      <created>1668219013728</created>\r\n      <option name=\"number\" value=\"00007\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00007\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668219013728</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00008\" summary=\"Finetune completed\">\r\n      <created>1668220779257</created>\r\n      <option name=\"number\" value=\"00008\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00008\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668220779257</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00009\" summary=\"Finetune completed\">\r\n      <created>1668221775701</created>\r\n      <option name=\"number\" value=\"00009\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00009\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668221775701</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00010\" summary=\"Finetune completed\">\r\n      <created>1668224494801</created>\r\n      <option name=\"number\" value=\"00010\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00010\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668224494801</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00011\" summary=\"Finetune completed\">\r\n      <created>1668226094285</created>\r\n      <option name=\"number\" value=\"00011\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00011\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668226094285</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00012\" summary=\"Finetune completed\">\r\n      <created>1668227945871</created>\r\n      <option name=\"number\" value=\"00012\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00012\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668227945871</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00013\" summary=\"Finetune completed\">\r\n      <created>1668228170979</created>\r\n      <option name=\"number\" value=\"00013\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00013\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668228170979</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00014\" summary=\"Finetune completed\">\r\n      <created>1668280159093</created>\r\n      <option name=\"number\" value=\"00014\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00014\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668280159093</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00015\" summary=\"Added RNVP prior\">\r\n      <created>1668288288821</created>\r\n      <option name=\"number\" value=\"00015\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00015\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668288288821</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00016\" summary=\"Added RNVP prior\">\r\n      <created>1668297804098</created>\r\n      <option name=\"number\" value=\"00016\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00016\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668297804098</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00017\" summary=\"Added RNVP prior\">\r\n      <created>1668298020814</created>\r\n      <option name=\"number\" value=\"00017\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00017\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668298020814</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00018\" summary=\"Added RNVP prior\">\r\n      <created>1668300013429</created>\r\n      <option name=\"number\" value=\"00018\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00018\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668300013429</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00019\" summary=\"Added RNVP prior\">\r\n      <created>1668302208211</created>\r\n      <option name=\"number\" value=\"00019\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00019\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668302208212</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00020\" summary=\"Added RNVP prior\">\r\n      <created>1668365128077</created>\r\n      <option name=\"number\" value=\"00020\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00020\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668365128077</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00021\" summary=\"Added RNVP prior\">\r\n      <created>1668370461760</created>\r\n      <option name=\"number\" value=\"00021\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00021\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668370461760</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00022\" summary=\"Different training\">\r\n      <created>1668382815610</created>\r\n      <option name=\"number\" value=\"00022\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00022\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668382815610</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00023\" summary=\"Different training\">\r\n      <created>1668385484864</created>\r\n      <option name=\"number\" value=\"00023\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00023\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668385484864</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00024\" summary=\"Corrected theta convergence\">\r\n      <created>1668390475601</created>\r\n      <option name=\"number\" value=\"00024\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00024\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668390475601</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00025\" summary=\"Corrected theta convergence\">\r\n      <created>1668390596963</created>\r\n      <option name=\"number\" value=\"00025\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00025\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668390596963</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00026\" summary=\"Corrected theta convergence\">\r\n      <created>1668390811340</created>\r\n      <option name=\"number\" value=\"00026\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00026\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668390811340</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00027\" summary=\"Corrected theta convergence\">\r\n      <created>1668400370348</created>\r\n      <option name=\"number\" value=\"00027\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00027\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668400370348</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00028\" summary=\"Corrected theta convergence\">\r\n      <created>1668446498251</created>\r\n      <option name=\"number\" value=\"00028\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00028\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668446498251</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00029\" summary=\"Corrected theta convergence\">\r\n      <created>1668455384327</created>\r\n      <option name=\"number\" value=\"00029\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00029\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668455384327</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00030\" summary=\"Corrected theta convergence\">\r\n      <created>1668459008586</created>\r\n      <option name=\"number\" value=\"00030\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00030\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668459008586</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00031\" summary=\"Corrected theta convergence\">\r\n      <created>1668472315831</created>\r\n      <option name=\"number\" value=\"00031\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00031\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668472315831</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00032\" summary=\"Corrected theta convergence\">\r\n      <created>1668479484839</created>\r\n      <option name=\"number\" value=\"00032\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00032\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668479484839</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00033\" summary=\"Corrected theta convergence\">\r\n      <created>1668808110153</created>\r\n      <option name=\"number\" value=\"00033\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00033\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668808110153</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00034\" summary=\"Corrected theta convergence\">\r\n      <created>1668808830559</created>\r\n      <option name=\"number\" value=\"00034\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00034\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668808830559</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00035\" summary=\"Corrected theta convergence\">\r\n      <created>1668813059061</created>\r\n      <option name=\"number\" value=\"00035\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00035\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668813059061</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00036\" summary=\"added lr_schedulers\">\r\n      <created>1668813067764</created>\r\n      <option name=\"number\" value=\"00036\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00036\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668813067764</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00037\" summary=\"added lr_schedulers\">\r\n      <created>1668820179803</created>\r\n      <option name=\"number\" value=\"00037\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00037\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668820179803</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00038\" summary=\"joint training\">\r\n      <created>1668968494846</created>\r\n      <option name=\"number\" value=\"00038\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00038\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1668968494846</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00039\" summary=\"Updated model\">\r\n      <created>1669086543150</created>\r\n      <option name=\"number\" value=\"00039\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00039\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1669086543150</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00040\" summary=\"Deleted P3 and removed flow priors\">\r\n      <created>1669342712821</created>\r\n      <option name=\"number\" value=\"00040\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00040\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1669342712821</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00041\" summary=\"Added q model\">\r\n      <created>1669425714225</created>\r\n      <option name=\"number\" value=\"00041\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00041\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1669425714225</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00042\" summary=\"Added q model\">\r\n      <created>1669428342843</created>\r\n      <option name=\"number\" value=\"00042\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00042\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1669428342843</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00043\" summary=\"lr_scheduler in utils.py\">\r\n      <created>1669431333997</created>\r\n      <option name=\"number\" value=\"00043\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00043\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1669431333997</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00044\" summary=\"E_q4\">\r\n      <created>1669507555544</created>\r\n      <option name=\"number\" value=\"00044\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00044\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1669507555544</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00045\" summary=\"Added contrastive learning codes\">\r\n      <created>1672436612212</created>\r\n      <option name=\"number\" value=\"00045\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00045\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1672436612212</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00046\" summary=\"Experiments\">\r\n      <created>1672436746621</created>\r\n      <option name=\"number\" value=\"00046\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00046\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1672436746621</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00047\" summary=\"Experiments\">\r\n      <created>1672474634274</created>\r\n      <option name=\"number\" value=\"00047\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00047\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1672474634274</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00048\" summary=\"Experiments\">\r\n      <created>1672474643796</created>\r\n      <option name=\"number\" value=\"00048\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00048\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1672474643796</updated>\r\n    </task>\r\n    <option name=\"localTasksCounter\" value=\"49\" />\r\n    <servers />\r\n  </component>\r\n  <component name=\"TypeScriptGeneratedFilesManager\">\r\n    <option name=\"version\" value=\"3\" />\r\n  </component>\r\n  <component name=\"Vcs.Log.Tabs.Properties\">\r\n    <option name=\"TAB_STATES\">\r\n      <map>\r\n        <entry key=\"MAIN\">\r\n          <value>\r\n            <State />\r\n          </value>\r\n        </entry>\r\n      </map>\r\n    </option>\r\n  </component>\r\n  <component name=\"VcsManagerConfiguration\">\r\n    <MESSAGE value=\"Finetune completed\" />\r\n    <MESSAGE value=\"Added RNVP prior\" />\r\n    <MESSAGE value=\"Different training\" />\r\n    <MESSAGE value=\"Corrected theta convergence\" />\r\n    <MESSAGE value=\"added lr_schedulers\" />\r\n    <MESSAGE value=\"joint training\" />\r\n    <MESSAGE value=\"Updated model\" />\r\n    <MESSAGE value=\"Deleted P3 and removed flow priors\" />\r\n    <MESSAGE value=\"Added q model\" />\r\n    <MESSAGE value=\"lr_scheduler in utils.py\" />\r\n    <MESSAGE value=\"E_q4\" />\r\n    <MESSAGE value=\"Added contrastive learning codes\" />\r\n    <MESSAGE value=\"Experiments\" />\r\n    <option name=\"LAST_COMMIT_MESSAGE\" value=\"Experiments\" />\r\n  </component>\r\n  <component name=\"XDebuggerManager\">\r\n    <breakpoint-manager>\r\n      <breakpoints>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/test.py</url>\r\n          <line>5</line>\r\n          <option name=\"timeStamp\" value=\"29\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/results.py</url>\r\n          <line>18</line>\r\n          <option name=\"timeStamp\" value=\"42\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/invariance.py</url>\r\n          <line>93</line>\r\n          <option name=\"timeStamp\" value=\"43\" />\r\n        </line-breakpoint>\r\n      </breakpoints>\r\n    </breakpoint-manager>\r\n    <watches-manager>\r\n      <configuration name=\"PythonConfigurationType\">\r\n        <watch expression=\"optimizers['par']\" />\r\n        <watch expression=\"optimizers['par']\" />\r\n      </configuration>\r\n    </watches-manager>\r\n  </component>\r\n  <component name=\"com.intellij.coverage.CoverageDataManagerImpl\">\r\n    <SUITE FILE_PATH=\"coverage/CRMF$train.coverage\" NAME=\"train Coverage Results\" MODIFIED=\"1672440543104\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/CRMF$results.coverage\" NAME=\"results Coverage Results\" MODIFIED=\"1668895584912\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/CRMF$evaluate_model.coverage\" NAME=\"evaluate_model Coverage Results\" MODIFIED=\"1672533621727\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/CRMF$a5.coverage\" NAME=\"a5 Coverage Results\" MODIFIED=\"1667872384207\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/CRMF$invariance.coverage\" NAME=\"invariance Coverage Results\" MODIFIED=\"1672012912771\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/CRMF$test.coverage\" NAME=\"test Coverage Results\" MODIFIED=\"1668451807866\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/CRMF$distributions.coverage\" NAME=\"distributions Coverage Results\" MODIFIED=\"1667958311916\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n  </component>\r\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	(revision 371096bbe8b6e74baaa7825a994810e279f663d8)
+++ b/.idea/workspace.xml	(date 1672710262666)
@@ -1,72 +1,11 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
   <component name="ChangeListManager">
-    <list default="true" id="8147b731-440c-4981-a21f-e4c8b1f0cd9a" name="Changes" comment="Experiments">
-      <change beforePath="$PROJECT_DIR$/.idea/misc.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/misc.xml" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_11_17_2022_12_09_PM__Changes_.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_11_17_2022_12_09_PM__Changes_.xml" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_2022-11-18,_4_44_p_m__[Changes]1/shelved.patch" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_2022-11-18__4_44_p_m___Changes_.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_2022-11-18__4_44_p_m___Changes_.xml" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_2022-11-18__4_44_p_m___Changes_1.xml" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_11_9_2022_10_12_PM__Changes_.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_11_9_2022_10_12_PM__Changes_.xml" afterDir="false" />
+    <list default="true" id="8147b731-440c-4981-a21f-e4c8b1f0cd9a" name="Changes" comment="added variety loss">
       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/Tensorboard.ipynb" beforeDir="false" afterPath="$PROJECT_DIR$/Tensorboard.ipynb" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/log/train.log" beforeDir="false" afterPath="$PROJECT_DIR$/log/train.log" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/models.py" beforeDir="false" afterPath="$PROJECT_DIR$/models.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E1/P4/CRMF_epoch_1188.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E1/P4/CRMF_epoch_401.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E1/P4/CRMF_epoch_402.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E1/P4/CRMF_epoch_403.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E1/P4/CRMF_epoch_404.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E1/P4/CRMF_epoch_405.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E1/P4/CRMF_epoch_406.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E1/P4/CRMF_epoch_407.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E1/P4/CRMF_epoch_408.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E1/P4/CRMF_epoch_409.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E1/P5/CRMF_epoch_1201.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E1/P5/CRMF_epoch_1202.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E3_joint/P4/CRMF_epoch_1200.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E3_joint/P5/CRMF_epoch_1301.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E3_joint/P6/CRMF_epoch_1497.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E3_joint_64dimension/P4/CRMF_epoch_1200.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E3_joint_64dimension/P5/CRMF_epoch_1400.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E3_joint_64dimension/P6/CRMF_epoch_1547.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E4_q/P3/CRMF_epoch_850.pth.tar" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/models/E4_q/P4/CRMF_epoch_1050.pth.tar" beforeDir="false" />
       <change beforePath="$PROJECT_DIR$/parser_file.py" beforeDir="false" afterPath="$PROJECT_DIR$/parser_file.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-07-19 TensorBoard.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-07-27 TensorBoard.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-07-33 TensorBoard.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-07-39 TensorBoard.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-08-08 TensorBoard.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-08-13 TensorBoard.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-08-17 TensorBoard.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E2_complex_beta_withoutz/Screenshot 2022-11-19 at 17-08-25 TensorBoard.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E2_complex_beta_withoutz/events.out.tfevents.1668820224.zahra-ThinkPad-P15-Gen-2i.502147.0" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint/CRMF_risk_irm_5.0_batch_hom_data_eth_ds_0_bk_20_ep_(150, 100, 150, 800, 100, 50)_shuffle_true_seed_72/events.out.tfevents.1668906133.zahra-ThinkPad-P15-Gen-2i.775334.0" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint/CRMF_risk_irm_5.0_batch_hom_data_eth_ds_0_bk_20_ep_(150, 100, 150, 800, 100, 50)_shuffle_true_seed_72/events.out.tfevents.1668927818.zahra-ThinkPad-P15-Gen-2i.2542816.0" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint/ade.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint/adeo.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint/elbo.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint/hotel.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint/loss.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint/pred.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint/univ.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint/zara1.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint/zara2.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint_64_dimension/New Text Document.txt" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint_64_dimension/ade.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint_64_dimension/adeo.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint_64_dimension/e_loss.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint_64_dimension/elbo.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint_64_dimension/hotel.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint_64_dimension/pred.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint_64_dimension/univ.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint_64_dimension/zara1.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E3_joint_64_dimension/zara2.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/E4_q/CRMF_risk_irm_5.0_batch_hom_data_eth_ds_0_bk_20_ep_(150, 100, 300, 200, 100)_shuffle_true_seed_72/events.out.tfevents.1669430022.gra1184.184179.0" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/Ebeta_fixed_learning rate/events.out.tfevents.1668801034.zahra-ThinkPad-P15-Gen-2i.670101.0" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/Eonecycle_200/events.out.tfevents.1668747604.zahra-ThinkPad-P15-Gen-2i.3924938.0" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/runs/Eonecycle_300/events.out.tfevents.1668791888.zahra-ThinkPad-P15-Gen-2i.5816.0" beforeDir="false" />
       <change beforePath="$PROJECT_DIR$/runs/~$Notes.docx" beforeDir="false" afterPath="$PROJECT_DIR$/runs/~$Notes.docx" afterDir="false" />
     </list>
     <option name="SHOW_DIALOG" value="false" />
@@ -260,6 +199,9 @@
       <workItem from="1672294286229" duration="7812000" />
       <workItem from="1672383569433" duration="8892000" />
       <workItem from="1672473343807" duration="4883000" />
+      <workItem from="1672564287482" duration="2009000" />
+      <workItem from="1672599652397" duration="4829000" />
+      <workItem from="1672708787974" duration="790000" />
     </task>
     <task id="LOCAL-00001" summary="Finetune completed">
       <created>1667968720588</created>
@@ -597,7 +539,14 @@
       <option name="project" value="LOCAL" />
       <updated>1672474643796</updated>
     </task>
-    <option name="localTasksCounter" value="49" />
+    <task id="LOCAL-00049" summary="added variety loss">
+      <created>1672565246369</created>
+      <option name="number" value="00049" />
+      <option name="presentableId" value="LOCAL-00049" />
+      <option name="project" value="LOCAL" />
+      <updated>1672565246369</updated>
+    </task>
+    <option name="localTasksCounter" value="50" />
     <servers />
   </component>
   <component name="TypeScriptGeneratedFilesManager">
@@ -628,7 +577,8 @@
     <MESSAGE value="E_q4" />
     <MESSAGE value="Added contrastive learning codes" />
     <MESSAGE value="Experiments" />
-    <option name="LAST_COMMIT_MESSAGE" value="Experiments" />
+    <MESSAGE value="added variety loss" />
+    <option name="LAST_COMMIT_MESSAGE" value="added variety loss" />
   </component>
   <component name="XDebuggerManager">
     <breakpoint-manager>
@@ -658,9 +608,9 @@
     </watches-manager>
   </component>
   <component name="com.intellij.coverage.CoverageDataManagerImpl">
-    <SUITE FILE_PATH="coverage/CRMF$train.coverage" NAME="train Coverage Results" MODIFIED="1672440543104" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/CRMF$train.coverage" NAME="train Coverage Results" MODIFIED="1672565214245" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/CRMF$results.coverage" NAME="results Coverage Results" MODIFIED="1668895584912" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/CRMF$evaluate_model.coverage" NAME="evaluate_model Coverage Results" MODIFIED="1672533621727" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/CRMF$evaluate_model.coverage" NAME="evaluate_model Coverage Results" MODIFIED="1672608246283" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/CRMF$a5.coverage" NAME="a5 Coverage Results" MODIFIED="1667872384207" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/CRMF$invariance.coverage" NAME="invariance Coverage Results" MODIFIED="1672012912771" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/CRMF$test.coverage" NAME="test Coverage Results" MODIFIED="1668451807866" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
Index: Tensorboard.ipynb
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>{\r\n \"cells\": [\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"metadata\": {\r\n    \"collapsed\": true\r\n   },\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"%load_ext tensorboard\\n\",\r\n    \"tensorboard --logdir='./runs/E6/CRMF_batch_het_data_v4_ds_0_bk_20_ep_(50, 20, 20, 1, 20, 1000)_shuffle_true_seed_1/'\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"outputs\": [],\r\n   \"source\": [],\r\n   \"metadata\": {\r\n    \"collapsed\": false\r\n   }\r\n  }\r\n ],\r\n \"metadata\": {\r\n  \"kernelspec\": {\r\n   \"display_name\": \"Python 3\",\r\n   \"language\": \"python\",\r\n   \"name\": \"python3\"\r\n  },\r\n  \"language_info\": {\r\n   \"codemirror_mode\": {\r\n    \"name\": \"ipython\",\r\n    \"version\": 2\r\n   },\r\n   \"file_extension\": \".py\",\r\n   \"mimetype\": \"text/x-python\",\r\n   \"name\": \"python\",\r\n   \"nbconvert_exporter\": \"python\",\r\n   \"pygments_lexer\": \"ipython2\",\r\n   \"version\": \"2.7.6\"\r\n  }\r\n },\r\n \"nbformat\": 4,\r\n \"nbformat_minor\": 0\r\n}\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Tensorboard.ipynb b/Tensorboard.ipynb
--- a/Tensorboard.ipynb	(revision 371096bbe8b6e74baaa7825a994810e279f663d8)
+++ b/Tensorboard.ipynb	(date 1672602383310)
@@ -9,7 +9,7 @@
    "outputs": [],
    "source": [
     "%load_ext tensorboard\n",
-    "tensorboard --logdir='./runs/E6/CRMF_batch_het_data_v4_ds_0_bk_20_ep_(50, 20, 20, 1, 20, 1000)_shuffle_true_seed_1/'"
+    "tensorboard --logdir='./runs/E8/CRMF_batch_het_data_v4_ds_0_bk_20_ep_(50, 20, 20, 1, 20, 1000)_shuffle_true_seed_1/'"
    ]
   },
   {
